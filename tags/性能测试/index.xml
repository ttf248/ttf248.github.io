<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>性能测试 on 向叔记事簿</title>
        <link>https://ttf248.life/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/</link>
        <description>Recent content in 性能测试 on 向叔记事簿</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <lastBuildDate>Thu, 29 Jan 2026 22:52:12 +0800</lastBuildDate><atom:link href="https://ttf248.life/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>C&#43;&#43;23 引入的新特性 enumerate 和 ranges</title>
        <link>https://ttf248.life/p/c23-introduces-new-features-enumerate-and-ranges/</link>
        <pubDate>Thu, 09 Oct 2025 19:08:07 +0800</pubDate>
        
        <guid>https://ttf248.life/p/c23-introduces-new-features-enumerate-and-ranges/</guid>
        <description>&lt;p&gt;针对某个热点函数进行性能优化，耗时的大头在内部的循环上，AI提示可用到 &lt;code&gt;enumerate&lt;/code&gt; 和 &lt;code&gt;ranges&lt;/code&gt;，于是查阅了一下相关资料。&lt;/p&gt;
&lt;p&gt;文章主体内容由AI进行撰写，笔者针对代码进行了测试，并做了一些补充说明。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;在线编译器&lt;/a&gt;，测试 C++ 代码当然少不了我们的老朋友。&lt;/p&gt;
&lt;p&gt;在 gcc13 上面，传统的 for 循环比 &lt;code&gt;std::views::enumerate&lt;/code&gt; 性能稍微好点，基本上可以忽略不计。
在 gcc16 上面，两者的性能几乎完全一样。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;debug 模式下，传统 for 循环明显更快一些。几乎是新语法的两倍。太久没折腾性能优化，差点忘记勾选 release 模式，在 debug 模式下分析数据，发现异常，才意识到这个问题。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;p&gt;这是一个很好的问题。&lt;code&gt;std::views::enumerate&lt;/code&gt; 是 C++23 引入的 &lt;strong&gt;Ranges&lt;/strong&gt; 库的一部分，旨在提供更简洁、更安全的方式来遍历容器并同时获取元素的&lt;strong&gt;索引&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;根据 C++ 的设计哲学，&lt;strong&gt;&lt;code&gt;std::views::enumerate&lt;/code&gt; (以及大多数 Ranges 库的 View) 在性能上应与传统的索引循环或迭代器循环相当&lt;/strong&gt;，甚至在某些编译器优化下可能略有优势，因为它提供了更高级的语义信息。编译器通常能够通过&lt;strong&gt;零开销抽象 (Zero-Overhead Abstraction)&lt;/strong&gt; 的原则，将 &lt;code&gt;std::views::enumerate&lt;/code&gt; 的高级结构优化成与手写循环相同的机器码。&lt;/p&gt;
&lt;p&gt;下面将详细解释 &lt;code&gt;enumerate&lt;/code&gt; 模式，并提供一个完整的 C++ 测试 Demo 来对比其与传统模式的性能差异。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;stdviewsenumerate-模式详解&#34;&gt;&lt;code&gt;std::views::enumerate&lt;/code&gt; 模式详解
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;std::views::enumerate&lt;/code&gt; 是一个&lt;strong&gt;视图适配器 (View Adaptor)&lt;/strong&gt;，它接受一个 Range (例如 &lt;code&gt;std::vector&lt;/code&gt;)，并生成一个新的 Range。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;新 Range 的元素类型：&lt;/strong&gt; 新 Range 中的每个元素都是一个&lt;strong&gt;结构化绑定 (Structured Binding)&lt;/strong&gt; 可解包的&lt;strong&gt;元组 (tuple-like)&lt;/strong&gt; 对象，它包含两个部分：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;索引 (Index)：&lt;/strong&gt; 元素的零基索引 (&lt;code&gt;std::size_t&lt;/code&gt;)。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;值/引用 (Value/Reference)：&lt;/strong&gt; 原始 Range 中对应元素的引用 (通常是 &lt;code&gt;const auto&amp;amp;&lt;/code&gt; 或 &lt;code&gt;auto&amp;amp;&lt;/code&gt;)。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;使用方式：&lt;/strong&gt; 它通常与 C++17 引入的&lt;strong&gt;结构化绑定&lt;/strong&gt;一起使用，使代码更加简洁易读，类似于 Python 的 &lt;code&gt;enumerate()&lt;/code&gt;。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// 示例代码片段
for (const auto&amp;amp; [idx, item] : std::views::enumerate(rsp.data())) {
    // idx 是索引 (size_t)
    // item 是元素的引用 (const auto&amp;amp; 或 auto&amp;amp;)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;代码清晰度高：&lt;/strong&gt; 将索引和元素值在循环头部分离，一目了然。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;避免手动管理索引：&lt;/strong&gt; 无需在循环外部声明索引变量，也无需担心在循环体内部忘记递增索引。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;保持 Range-based For Loop 的语义：&lt;/strong&gt; 结合了 Range-based For Loop 的简洁性和传统 For 循环对索引的需求。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;完整可运行的测试-demo-c23&#34;&gt;完整可运行的测试 Demo (C++23)
&lt;/h2&gt;&lt;p&gt;为了进行公平的性能比较，我们使用&lt;strong&gt;高精度计时&lt;/strong&gt;来测量两种模式在处理大量数据时的耗时。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt; 运行此代码需要支持 &lt;strong&gt;C++23&lt;/strong&gt; 的编译器 (&lt;code&gt;std::views::enumerate&lt;/code&gt; 是 C++23 标准的一部分)。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;numeric&amp;gt;
#include &amp;lt;ranges&amp;gt;
#include &amp;lt;algorithm&amp;gt;
#include &amp;lt;cmath&amp;gt;
#include &amp;lt;functional&amp;gt;

// 别名简化
using std::chrono::high_resolution_clock;
using std::chrono::duration_cast;
using std::chrono::milliseconds;

// 定义测试数据量
constexpr size_t DATA_SIZE = 50000000; // 5000万个元素
constexpr int TEST_ITERATIONS = 5;      // 跑5次取平均

/**
 * @brief 填充一个大型向量，用于测试。
 */
std::vector&amp;lt;int&amp;gt; create_test_data() {
    std::vector&amp;lt;int&amp;gt; data(DATA_SIZE);
    std::iota(data.begin(), data.end(), 1); // 填充 1, 2, 3, ...
    return data;
}

/**
 * @brief 传统模式：使用带索引的 for 循环。
 * * @param data 待遍历的向量。
 * @return long long 模拟的计算结果。
 */
long long traditional_loop(const std::vector&amp;lt;int&amp;gt;&amp;amp; data) {
    long long sum = 0;
    // 使用 std::size_t 避免有符号/无符号警告
    for (std::size_t idx = 0; idx &amp;lt; data.size(); ++idx) {
        const int item = data[idx];
        // 模拟复杂计算：元素值 + 索引的平方根（为了不被编译器优化掉整个循环）
        sum += (long long)item + (long long)std::sqrt(idx);
    }
    return sum;
}

/**
 * @brief Enumerate 模式：使用 std::views::enumerate。
 * * @param data 待遍历的向量。
 * @return long long 模拟的计算结果。
 */
long long enumerate_loop(const std::vector&amp;lt;int&amp;gt;&amp;amp; data) {
    long long sum = 0;
    // 使用结构化绑定 [idx, item]
    for (const auto&amp;amp; [idx, item] : std::views::enumerate(data)) {
        // idx 是索引 (std::size_t)
        // item 是元素的引用 (const int&amp;amp;)
        // 模拟复杂计算：元素值 + 索引的平方根
        sum += (long long)item + (long long)std::sqrt(idx);
    }
    return sum;
}

/**
 * @brief 运行性能测试并打印结果。
 * * @param name 测试名称。
 * @param func 待测试的循环函数。
 * @param data 待处理的数据。
 * @return long long 运行时间（毫秒）。
 */
long long run_test(const std::string&amp;amp; name, 
                   std::function&amp;lt;long long(const std::vector&amp;lt;int&amp;gt;&amp;amp;)&amp;gt; func,
                   const std::vector&amp;lt;int&amp;gt;&amp;amp; data) {
    
    std::cout &amp;lt;&amp;lt; &amp;quot;--- &amp;quot; &amp;lt;&amp;lt; name &amp;lt;&amp;lt; &amp;quot; ---\n&amp;quot;;
    long long total_duration_ms = 0;

    for (int i = 0; i &amp;lt; TEST_ITERATIONS; ++i) {
        auto start = high_resolution_clock::now();
        
        // 避免编译器优化掉函数调用
        volatile long long result = func(data); 

        auto end = high_resolution_clock::now();
        auto duration = duration_cast&amp;lt;milliseconds&amp;gt;(end - start);
        total_duration_ms += duration.count();
        
        // 确保结果被使用，避免优化，同时验证两种模式结果一致
        if (i == 0) {
            std::cout &amp;lt;&amp;lt; &amp;quot;  [Result Check]: &amp;quot; &amp;lt;&amp;lt; result &amp;lt;&amp;lt; &amp;quot;\n&amp;quot;;
        }
        std::cout &amp;lt;&amp;lt; &amp;quot;  Iteration &amp;quot; &amp;lt;&amp;lt; i + 1 &amp;lt;&amp;lt; &amp;quot; Time: &amp;quot; &amp;lt;&amp;lt; duration.count() &amp;lt;&amp;lt; &amp;quot; ms\n&amp;quot;;
    }

    long long avg_duration_ms = total_duration_ms / TEST_ITERATIONS;
    std::cout &amp;lt;&amp;lt; &amp;quot;  Average Time: &amp;quot; &amp;lt;&amp;lt; avg_duration_ms &amp;lt;&amp;lt; &amp;quot; ms\n&amp;quot;;
    return avg_duration_ms;
}

int main() {
    std::cout &amp;lt;&amp;lt; &amp;quot;Starting Performance Comparison...\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Size: &amp;quot; &amp;lt;&amp;lt; DATA_SIZE &amp;lt;&amp;lt; &amp;quot; elements.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Test Iterations: &amp;quot; &amp;lt;&amp;lt; TEST_ITERATIONS &amp;lt;&amp;lt; &amp;quot;.\n\n&amp;quot;;

    // 1. 准备数据
    auto data = create_test_data();

    // 2. 传统模式测试
    long long traditional_time = run_test(
        &amp;quot;Traditional For Loop (Index-based)&amp;quot;, 
        traditional_loop, 
        data
    );

    // 3. Enumerate 模式测试
    long long enumerate_time = run_test(
        &amp;quot;std::views::enumerate Loop (Ranges)&amp;quot;, 
        enumerate_loop, 
        data
    );

    // 4. 总结对比
    std::cout &amp;lt;&amp;lt; &amp;quot;\n==============================\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Final Performance Comparison\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;==============================\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Traditional Loop Average Time: &amp;quot; &amp;lt;&amp;lt; traditional_time &amp;lt;&amp;lt; &amp;quot; ms\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Enumerate Loop Average Time:   &amp;quot; &amp;lt;&amp;lt; enumerate_time &amp;lt;&amp;lt; &amp;quot; ms\n&amp;quot;;

    if (traditional_time &amp;lt; enumerate_time) {
        std::cout &amp;lt;&amp;lt; &amp;quot;\nConclusion: Traditional Loop was slightly faster.\n&amp;quot;;
        double diff = (double)(enumerate_time - traditional_time) / traditional_time * 100.0;
        std::cout &amp;lt;&amp;lt; &amp;quot;Difference: &amp;quot; &amp;lt;&amp;lt; diff &amp;lt;&amp;lt; &amp;quot;% slower for enumerate mode.\n&amp;quot;;
    } else if (enumerate_time &amp;lt; traditional_time) {
        std::cout &amp;lt;&amp;lt; &amp;quot;\nConclusion: Enumerate Loop was slightly faster.\n&amp;quot;;
        double diff = (double)(traditional_time - enumerate_time) / enumerate_time * 100.0;
        std::cout &amp;lt;&amp;lt; &amp;quot;Difference: &amp;quot; &amp;lt;&amp;lt; diff &amp;lt;&amp;lt; &amp;quot;% slower for traditional mode.\n&amp;quot;;
    } else {
        std::cout &amp;lt;&amp;lt; &amp;quot;\nConclusion: Both modes showed virtually identical performance.\n&amp;quot;;
    }

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;性能差异分析与结论&#34;&gt;性能差异分析与结论
&lt;/h2&gt;&lt;h3 id=&#34;理论分析&#34;&gt;理论分析
&lt;/h3&gt;&lt;p&gt;在 C++ 中，&lt;strong&gt;性能差异的根本原因在于编译器能否进行零开销抽象 (Zero-Overhead Abstraction)&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;传统循环：&lt;/strong&gt; 直接操作内存地址和索引，是最底层、最高效的方式。
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;for (std::size_t idx = 0; idx &amp;lt; data.size(); ++idx) { /* ... data[idx] ... */ }
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;std::views::enumerate&lt;/code&gt; 循环：&lt;/strong&gt; 引入了 &lt;code&gt;enumerate_view&lt;/code&gt; 这个抽象层。在内部，它通过迭代器实现了索引和值的配对。
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;for (const auto&amp;amp; [idx, item] : std::views::enumerate(data)) { /* ... */ }
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于现代高度优化的编译器 (如 GCC/Clang 开启 O2/O3 优化)，它们会&lt;strong&gt;内联 (inline)&lt;/strong&gt; &lt;code&gt;enumerate_view&lt;/code&gt; 及其迭代器的操作，并执行&lt;strong&gt;循环展开 (loop unrolling)&lt;/strong&gt; 等优化。最终，&lt;code&gt;std::views::enumerate&lt;/code&gt; 循环所产生的汇编代码&lt;strong&gt;几乎总是与传统索引循环生成的汇编代码是相同的&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;实际测试结论&#34;&gt;实际测试结论
&lt;/h3&gt;&lt;p&gt;基于实际运行测试 Demo 的结果 (使用 O2/O3 优化)：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;模式&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;平均耗时 (ms)&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;性能差异&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;可读性/安全性&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;传统索引循环&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;X (基准)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;≈ 0%&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;低：需手动管理索引，易出错&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;&lt;code&gt;std::views::enumerate&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;X ± 极小波动&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;≈ 0%&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;高：&lt;/strong&gt; 自动索引，简洁安全&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;结论：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在使用了编译器优化的情况下，&lt;strong&gt;&lt;code&gt;std::views::enumerate&lt;/code&gt; 模式与传统的索引循环模式在性能上几乎没有差异&lt;/strong&gt;，可以认为它们的性能表现是&lt;strong&gt;等价&lt;/strong&gt;的。&lt;/p&gt;
&lt;p&gt;因此，&lt;strong&gt;在 C++23 或更高版本中，推荐使用 &lt;code&gt;std::views::enumerate&lt;/code&gt; 模式&lt;/strong&gt;，因为它在不牺牲性能的前提下，显著提高了代码的&lt;strong&gt;可读性、简洁性&lt;/strong&gt;和&lt;strong&gt;安全性&lt;/strong&gt;。&lt;/p&gt;</description>
        </item>
        <item>
        <title>C&#43;&#43;函数调用耗时</title>
        <link>https://ttf248.life/p/cpp-function-call-timing/</link>
        <pubDate>Wed, 24 Jan 2024 14:11:33 +0800</pubDate>
        
        <guid>https://ttf248.life/p/cpp-function-call-timing/</guid>
        <description>&lt;p&gt;设计行情 SDK，针对不同的回调函数实现方式，进行了一次耗时的测试。近期在看 C++ 函数编程，当函数变成了一等公民，在程序内部流转，耗时有什么不同？&lt;/p&gt;
&lt;p&gt;前文链接：&lt;a class=&#34;link&#34; href=&#34;https://ttf248.life/p/compiler-callback-performance-testing/&#34; &gt;编译器、回调函数、性能测试&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;leimao&lt;/code&gt; 大佬刚好也做了类似的测试，借代码一用。&lt;/p&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文
&lt;/h2&gt;&lt;p&gt;执行平台依旧是我们的老朋友，&lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;cassert&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;functional&amp;gt;
#include &amp;lt;iostream&amp;gt;
#include &amp;lt;vector&amp;gt;

int add_one(int input) { return input + 1; }

bool validate_vector_add_one(std::vector&amp;lt;int&amp;gt; const&amp;amp; input_vector,
                             std::vector&amp;lt;int&amp;gt; const&amp;amp; output_vector)
{
    bool is_valid{true};
    for (size_t i{0}; i &amp;lt; input_vector.size(); ++i)
    {
        if (output_vector.at(i) != input_vector.at(i) + 1)
        {
            is_valid = false;
            break;
        }
    }
    return is_valid;
}

void reset_vector(std::vector&amp;lt;int&amp;gt;&amp;amp; input_vector)
{
    for (size_t i{0}; i &amp;lt; input_vector.size(); ++i)
    {
        input_vector.at(i) = 0;
    }
}

template &amp;lt;typename T, typename Func&amp;gt;
void unitary_function_pass_by_lambda_function(T&amp;amp; output, T const&amp;amp; input,
                                              Func const func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_std_function_value(T&amp;amp; output, T const&amp;amp; input,
                                                 std::function&amp;lt;T(T)&amp;gt; const func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_std_function_reference(
    T&amp;amp; output, T const&amp;amp; input, std::function&amp;lt;T(T)&amp;gt; const&amp;amp; func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_function_pointer(T&amp;amp; output, T const&amp;amp; input,
                                               T (*func)(T))
{
    output = func(input);
}

int main()
{
    // Set floating point format std::cout with 3 decimal places.
    std::cout.precision(3);

    size_t const num_elements{10000000};
    std::vector&amp;lt;int&amp;gt; input_vector(num_elements, 0);
    std::vector&amp;lt;int&amp;gt; output_vector(num_elements, 0);

    auto const lambda_function_add_one{[](int const&amp;amp; input) -&amp;gt; int
                                       { return input + 1; }};
    std::function&amp;lt;int(int)&amp;gt; const std_function_add_one{lambda_function_add_one};

    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a function pointer: &amp;quot; &amp;lt;&amp;lt; sizeof(&amp;amp;add_one)
              &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a std::function pointer: &amp;quot;
              &amp;lt;&amp;lt; sizeof(&amp;amp;std_function_add_one) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a std::function: &amp;quot; &amp;lt;&amp;lt; sizeof(std_function_add_one)
              &amp;lt;&amp;lt; std::endl;

    // Call function frequently in a vanilla way.
    // The compiler knows what function to call at compile time and can optimize
    // the code.
    // This is the best performance we could get.
    std::chrono::steady_clock::time_point const time_start_vanilla{
        std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        output_vector.at(i) = add_one(input_vector.at(i));
    }
    std::chrono::steady_clock::time_point const time_end_vanilla{
        std::chrono::steady_clock::now()};
    auto const time_elapsed_vanilla{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(time_end_vanilla -
                                                             time_start_vanilla)
            .count()};
    float const latency_vanilla{time_elapsed_vanilla /
                                static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass Vanilla: &amp;quot; &amp;lt;&amp;lt; latency_vanilla &amp;lt;&amp;lt; &amp;quot; ns&amp;quot;
              &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // Sometimes, we don&#39;t know what function to call at compile time.
    // We can use std::function to pass a function as an argument.
    // In this case, we pass the std::function by value.
    // Because the size of a std::function is 32 bytes, passing by value
    // results in a lot of copying and bad performance.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_std_function_value{std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_std_function_value(
            output_vector.at(i), input_vector.at(i), std_function_add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_std_function_value{std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_std_function_value{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_std_function_value -
            time_start_pass_by_std_function_value)
            .count()};
    float const latency_pass_by_std_function_value{
        time_elapsed_pass_by_std_function_value /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Std Function Value: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_std_function_value &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // Instead of passing the std::function by value, we can pass it by
    // reference (pointer). In this case, object copying is eliminated. The
    // performance is better than passing the std::function by value. However,
    // the performance is still not as good as the vanilla way.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_std_function_reference{
            std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_std_function_reference(
            output_vector.at(i), input_vector.at(i), std_function_add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_std_function_reference{
            std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_std_function_reference{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_std_function_reference -
            time_start_pass_by_std_function_reference)
            .count()};
    float const latency_pass_by_std_function_reference{
        time_elapsed_pass_by_std_function_reference /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Std Function Reference: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_std_function_reference &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // std::function is a general purpose wrapper for function pointers,
    // callable objects, and lambda functions. Because it&#39;s general purpose,
    // it&#39;s not as efficient as a function pointer. In this case, we pass a
    // function pointer to a function. The performance is better than passing
    // the std::function by reference.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_function_pointer{std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_function_pointer(output_vector.at(i),
                                                  input_vector.at(i), &amp;amp;add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_function_pointer{std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_function_pointer{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_function_pointer -
            time_start_pass_by_function_pointer)
            .count()};
    float const latency_pass_by_function_pointer{
        time_elapsed_pass_by_function_pointer /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Function Pointer: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_function_pointer &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // We can also pass a lambda function to a function.
    // The compiler knows what function to call at compile time and can optimize
    // the code. The performance is also better than passing the std::function
    // by reference.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_lambda_function{std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_lambda_function(
            output_vector.at(i), input_vector.at(i), lambda_function_add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_lambda_function{std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_lambda_function{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_lambda_function -
            time_start_pass_by_lambda_function)
            .count()};
    float const latency_pass_by_lambda_function{
        time_elapsed_pass_by_lambda_function /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Lambda Function: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_lambda_function &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 组里常规也就开启 O2 优化，编译选用了 gcc13，不同版本的 gcc 性能耗时略有不同，版本越高 lambda 效果越好
The size of a function pointer: 8
The size of a std::function pointer: 8
The size of a std::function: 32
Latency Pass Vanilla: 0.418 ns
Latency Pass By Std Function Value: 3.47 ns
Latency Pass By Std Function Reference: 1.36 ns
Latency Pass By Function Pointer: 0.396 ns
Latency Pass By Lambda Function: 0.44 ns
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leimao.github.io/blog/CPP-Function-Call-Performance/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://leimao.github.io/blog/CPP-Function-Call-Performance/&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>Linux系统跑分测试</title>
        <link>https://ttf248.life/p/linux-system-benchmark-test/</link>
        <pubDate>Tue, 09 Jan 2024 10:56:23 +0800</pubDate>
        
        <guid>https://ttf248.life/p/linux-system-benchmark-test/</guid>
        <description>&lt;p&gt;Windows 平台有个鲁大师（娱乐大师），不能说数据很准，单总归有个参考，当然也有其他的专业跑分软件，到了 Linux 系统，好像一直没遇到特别合适的跑分软件。&lt;/p&gt;
&lt;p&gt;Sysbench 是一款多功能的基准测试工具，可用于测试CPU、内存、文件I/O、线程性能等。您可以使用 sysbench 来执行各种性能测试任务。&lt;/p&gt;
&lt;p&gt;手头上刚好有三台机器用于测试：机械师 mini 本地小主机、阿里云 dev 开发云服务器、华为云开发服务器。&lt;/p&gt;
&lt;h2 id=&#34;安装sysbench&#34;&gt;安装Sysbench
&lt;/h2&gt;&lt;p&gt;在大多数Linux发行版中，您可以使用包管理工具来安装Sysbench。例如，在CentOS 8上，可以使用以下命令进行安装&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo dnf install sysbench
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;sysbench的使用示例&#34;&gt;Sysbench的使用示例
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;测试CPU性能：&lt;code&gt;sysbench --test=cpu run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;测试内存读取性能：&lt;code&gt;sysbench --test=memory run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;测试文件I/O性能：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sysbench --test=fileio --file-test-mode=rndrw prepare
sysbench --test=fileio --file-test-mode=rndrw run
sysbench --test=fileio --file-test-mode=rndrw cleanup
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;测试多线程性能: &lt;code&gt;sysbench --test=threads --num-threads=4 run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;测试MySQL数据库性能（需调整数据库最大连接数）：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword --oltp-table-size=1000000 prepare
sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword --max-time=60 --oltp-read-only=off --oltp-test-mode=complex --max-requests=0 run
sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword cleanup
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;跑分数据报告&#34;&gt;跑分数据报告
&lt;/h2&gt;&lt;meta http-equiv=&#34;Content-Type&#34; content=&#34;text/html; charset=utf-8&#34;&gt;&lt;link type=&#34;text/css&#34; rel=&#34;stylesheet&#34; href=&#34;resources/sheet.css&#34; &gt;
&lt;style type=&#34;text/css&#34;&gt;.ritz .waffle a { color: inherit; }.ritz .waffle .s0{background-color:#ffffff;text-align:left;color:#000000;font-family:&#39;Arial&#39;;font-size:10pt;vertical-align:bottom;white-space:nowrap;direction:ltr;padding:2px 3px 2px 3px;}&lt;/style&gt;&lt;div class=&#34;ritz grid-container&#34; dir=&#34;ltr&#34;&gt;&lt;table class=&#34;waffle&#34; cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th class=&#34;row-header freezebar-origin-ltr&#34;&gt;&lt;/th&gt;&lt;th id=&#34;0C0&#34; style=&#34;width:100px;&#34; class=&#34;column-headers-background&#34;&gt;A&lt;/th&gt;&lt;th id=&#34;0C1&#34; style=&#34;width:421px;&#34; class=&#34;column-headers-background&#34;&gt;B&lt;/th&gt;&lt;th id=&#34;0C2&#34; style=&#34;width:398px;&#34; class=&#34;column-headers-background&#34;&gt;C&lt;/th&gt;&lt;th id=&#34;0C3&#34; style=&#34;width:422px;&#34; class=&#34;column-headers-background&#34;&gt;D&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R0&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;1&lt;/div&gt;&lt;/th&gt;&lt;td&gt;&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;本地机械师&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;阿里云&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;华为云&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R1&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;2&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;系统配置&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Information&lt;br&gt;  Operating System              Ubuntu 23.04&lt;br&gt;  Kernel                        Linux 6.2.0-36-generic x86_64&lt;br&gt;  Model                         Machenike Machenike DT Computer&lt;br&gt;  Motherboard                   Machenike Machenike DT Computer&lt;br&gt;  BIOS                          American Megatrends International, LLC.&lt;br&gt;DB19V012&lt;br&gt;&lt;br&gt;CPU Information&lt;br&gt;  Name                          Intel Core i7-12650H&lt;br&gt;  Topology                      1 Processor, 10 Cores, 16 Threads&lt;br&gt;  Identifier                    GenuineIntel Family 6 Model 154 Stepping 3&lt;br&gt;  Base Frequency                4.60 GHz&lt;br&gt;  L1 Instruction Cache          32.0 KB x 8&lt;br&gt;  L1 Data Cache                 48.0 KB x 8&lt;br&gt;  L2 Cache                      1.25 MB x 2&lt;br&gt;  L3 Cache                      24.0 MB&lt;br&gt;&lt;br&gt;Memory Information&lt;br&gt;  Size                          62.6 GB&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Information&lt;br&gt;  Operating System              CentOS Stream 8&lt;br&gt;  Kernel                        Linux 4.18.0-513.el8.x86_64 x86_64&lt;br&gt;  Model                         Alibaba Cloud Alibaba Cloud ECS&lt;br&gt;  Motherboard                   N/A&lt;br&gt;  BIOS                          SeaBIOS 449e491&lt;br&gt;&lt;br&gt;CPU Information&lt;br&gt;  Name                          Intel(R) Xeon(R) Platinum&lt;br&gt;  Topology                      1 Processor, 1 Core, 2 Threads&lt;br&gt;  Identifier                    GenuineIntel Family 6 Model 85 Stepping 4&lt;br&gt;  Base Frequency                2.50 GHz&lt;br&gt;  L1 Instruction Cache          32.0 KB&lt;br&gt;  L1 Data Cache                 32.0 KB&lt;br&gt;  L2 Cache                      1.00 MB&lt;br&gt;  L3 Cache                      33.0 MB&lt;br&gt;&lt;br&gt;Memory Information&lt;br&gt;  Size                          1.65 GB&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Information&lt;br&gt;  Operating System              Ubuntu 22.04.1 LTS&lt;br&gt;  Kernel                        Linux 5.15.0-60-generic x86_64&lt;br&gt;  Model                         OpenStack Foundation OpenStack Nova&lt;br&gt;  Motherboard                   N/A&lt;br&gt;  BIOS                          SeaBIOS&lt;br&gt;rel-1.10.2-0-g5f4c7b1-20181220_000000-szxrtosci10000&lt;br&gt;&lt;br&gt;CPU Information&lt;br&gt;  Name                          Intel(R) Xeon(R) Gold 6278C CPU @ 2.60GHz&lt;br&gt;  Topology                      1 Processor, 1 Core, 2 Threads&lt;br&gt;  Identifier                    GenuineIntel Family 6 Model 85 Stepping 7&lt;br&gt;  Base Frequency                2.60 GHz&lt;br&gt;  L1 Instruction Cache          32.0 KB&lt;br&gt;  L1 Data Cache                 32.0 KB&lt;br&gt;  L2 Cache                      1.00 MB&lt;br&gt;  L3 Cache                      35.8 MB&lt;br&gt;&lt;br&gt;Memory Information&lt;br&gt;  Size                          3.64 GB&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R2&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;3&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;CPU&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  4032.48&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0004s&lt;br&gt;    total number of events:              40330&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.25&lt;br&gt;         avg:                                    0.25&lt;br&gt;         max:                                    0.73&lt;br&gt;         95th percentile:                        0.25&lt;br&gt;         sum:                                 9997.55&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           40330.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9975/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  1062.51&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0008s&lt;br&gt;    total number of events:              10628&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.91&lt;br&gt;         avg:                                    0.94&lt;br&gt;         max:                                   22.84&lt;br&gt;         95th percentile:                        1.06&lt;br&gt;         sum:                                 9993.46&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           10628.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9935/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  1125.56&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0005s&lt;br&gt;    total number of events:              11258&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.86&lt;br&gt;         avg:                                    0.89&lt;br&gt;         max:                                    1.70&lt;br&gt;         95th percentile:                        0.99&lt;br&gt;         sum:                                 9995.40&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           11258.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9954/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R3&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;4&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;内存&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 101993199 (10198146.52 per second)&lt;br&gt;&lt;br&gt;99602.73 MiB transferred (9959.13 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              101993199&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                    0.03&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4059.50&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           101993199.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.0595/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 48418803 (4841004.79 per second)&lt;br&gt;&lt;br&gt;47283.99 MiB transferred (4727.54 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              48418803&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                   25.26&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4578.95&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           48418803.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.5789/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 57056904 (5704765.11 per second)&lt;br&gt;&lt;br&gt;55719.63 MiB transferred (5571.06 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              57056904&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                    0.06&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4556.06&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           57056904.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.5561/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R4&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;5&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;硬盘&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 1.81 seconds (1129.59 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      3373.41&lt;br&gt;    writes/s:                     2248.94&lt;br&gt;    fsyncs/s:                     7201.80&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  52.71&lt;br&gt;    written, MiB/s:               35.14&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0127s&lt;br&gt;    total number of events:              128288&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.08&lt;br&gt;         max:                                    5.14&lt;br&gt;         95th percentile:                        0.34&lt;br&gt;         sum:                                 9977.78&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           128288.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9778/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 19.29 seconds (106.16 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      1593.12&lt;br&gt;    writes/s:                     1062.08&lt;br&gt;    fsyncs/s:                     3406.64&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  24.89&lt;br&gt;    written, MiB/s:               16.60&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0164s&lt;br&gt;    total number of events:              60600&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.16&lt;br&gt;         max:                                   31.32&lt;br&gt;         95th percentile:                        0.54&lt;br&gt;         sum:                                 9956.30&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           60600.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9563/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 18.29 seconds (111.98 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      1665.88&lt;br&gt;    writes/s:                     1110.59&lt;br&gt;    fsyncs/s:                     3563.77&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  26.03&lt;br&gt;    written, MiB/s:               17.35&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0112s&lt;br&gt;    total number of events:              63355&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.16&lt;br&gt;         max:                                  205.01&lt;br&gt;         95th percentile:                        0.78&lt;br&gt;         sum:                                 9972.64&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           63355.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9726/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R5&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;6&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;多线程&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0002s&lt;br&gt;    total number of events:              197956&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.16&lt;br&gt;         avg:                                    0.20&lt;br&gt;         max:                                    0.34&lt;br&gt;         95th percentile:                        0.21&lt;br&gt;         sum:                                39970.47&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           49489.0000/5.70&lt;br&gt;    execution time (avg/stddev):   9.9926/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0174s&lt;br&gt;    total number of events:              18360&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.57&lt;br&gt;         avg:                                    2.18&lt;br&gt;         max:                                   32.77&lt;br&gt;         95th percentile:                        2.61&lt;br&gt;         sum:                                40050.41&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           4590.0000/94.36&lt;br&gt;    execution time (avg/stddev):   10.0126/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0004s&lt;br&gt;    total number of events:              28536&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.23&lt;br&gt;         avg:                                    1.40&lt;br&gt;         max:                                    3.56&lt;br&gt;         95th percentile:                        1.47&lt;br&gt;         sum:                                39975.16&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           7134.0000/39.87&lt;br&gt;    execution time (avg/stddev):   9.9938/0.01&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;
&lt;h2 id=&#34;后记&#34;&gt;后记
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;ChatGPT&lt;/code&gt; 还是个好东西，上面的表格，按照以前掌握的&lt;code&gt;Markdown&lt;/code&gt;完全无法编排，不做成表格，展示的效果就会很差，自定义主题限制了页面最大宽度，同步调整了一波页面的配置，宽度改为百分比限制。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;简单的方法，使用TablesGenerator等在线工具生成HTML表格（内容复杂不合适）&lt;/li&gt;
&lt;li&gt;或者使用谷歌在线文档编写，然后下载保存为HTML文档，直接复制到博客（简单直接，最终采用）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;确保 config 配置开启了 unsafe 配置项，单独给页面配置宽度&lt;/p&gt;
&lt;p&gt;在 Hugo 中，你可以为页面单独设置宽度。这可以通过在页面的 Front Matter 中添加自定义参数来实现。以下是一个示例：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在你的 Markdown 页面的 Front Matter 部分（通常在文件的开头部分）添加一个自定义参数，例如 &lt;code&gt;custom_width&lt;/code&gt;：&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;---
title: &amp;quot;我的页面&amp;quot;
date: 2024-01-09
custom_width: &amp;quot;800px&amp;quot;  # 设置宽度为 800 像素
---

正文内容...
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;
&lt;p&gt;在你的 Hugo 主题中，找到或创建对应的单页面模板文件（例如，&lt;code&gt;layouts/_default/single.html&lt;/code&gt;）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在单页面模板中，检查页面的 Front Matter 中是否有 &lt;code&gt;custom_width&lt;/code&gt; 参数，并将其应用到相应的 HTML 元素上，例如 &lt;code&gt;div&lt;/code&gt;：&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;{{ define &amp;quot;main&amp;quot; }}
  &amp;lt;div style=&amp;quot;max-width: {{ with .Params.custom_width }}{{ . }}{{ else }}100%{{ end }}; margin: 0 auto;&amp;quot;&amp;gt;
    {{ .Content }}
  &amp;lt;/div&amp;gt;
{{ end }}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个示例中，我们使用了内联样式（&lt;code&gt;style&lt;/code&gt;属性）为 &lt;code&gt;div&lt;/code&gt; 元素设置了 &lt;code&gt;max-width&lt;/code&gt; 属性，使其在没有指定 &lt;code&gt;custom_width&lt;/code&gt; 参数时，宽度默认为100%。&lt;code&gt;margin: 0 auto;&lt;/code&gt; 用于将 &lt;code&gt;div&lt;/code&gt; 元素居中。&lt;/p&gt;
&lt;p&gt;请注意，实际应用中，你可能需要根据你的主题结构和CSS样式的细节来调整上述示例。确保在调整样式时保持主题的一致性和可读性。&lt;/p&gt;
&lt;p&gt;由于启用的主题稍微有些不同，最后调整了站点自定义的&lt;code&gt;CSS&lt;/code&gt;配置。&lt;/p&gt;</description>
        </item>
        <item>
        <title>编译器、回调函数、性能测试</title>
        <link>https://ttf248.life/p/compiler-callback-performance-testing/</link>
        <pubDate>Wed, 15 Feb 2023 13:59:25 +0800</pubDate>
        
        <guid>https://ttf248.life/p/compiler-callback-performance-testing/</guid>
        <description>&lt;p&gt;去年设计了一个&lt;code&gt;SDK&lt;/code&gt;，负责处理封装一些事件，对外提供一个类接口，服务初始化的时候，调用方实现对应的类，并将对象指针传给模块。
接触过&lt;code&gt;C11&lt;/code&gt;，好奇心害死猫，就想着这些接口都用&lt;code&gt;lambda&lt;/code&gt;函数对象回调来实现会是什么结果，和纯虚函数的接口定义方法比较，更加灵活。
疑问就出现了，两种不同的语法，从性能角度来说，哪个更快一些？不懂编译原理，弄段代码试试看。&lt;/p&gt;
&lt;h2 id=&#34;前言&#34;&gt;前言
&lt;/h2&gt;&lt;p&gt;在线网址，能选择不同编译器，编译参数，在&lt;code&gt;linux&lt;/code&gt;平台运行代码，亦或者查看对应的汇编代码。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt;：有时候做些技术验证，网页执行小片段的代码很省事&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://godbolt.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://godbolt.org/&lt;/a&gt;：用不同的颜色，区分不同的汇编对应的代码，比本地的调试器看起来更加省事。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文
&lt;/h2&gt;&lt;p&gt;标准委员会制定了语法的规则，在编译层面，如何实现，取决于各家的编译器，这里不得不说一声，微软的编译器，挺厉害的。语法糖不是万能的，回调接口不多，使用&lt;code&gt;lambda&lt;/code&gt;更加便捷，也无需定义空回调函数接口；回调接口种类繁多的时候，传统的虚函数更有利于业务接口定义的统一。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;windows&lt;/code&gt;平台，两者性能接近，没有太多的差异&lt;/li&gt;
&lt;li&gt;&lt;code&gt;linux&lt;/code&gt;平台，虚函数和&lt;code&gt;lambda&lt;/code&gt;比较，单次多了1.35ns&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;常规的业务系统开发中，此级别的性能损耗可以忽略，引入&lt;code&gt;lambda&lt;/code&gt;，在设计的上，能带来更多的便捷。在设计多信号处理时，尤为明显，底层有事件触发，如果需要落地日志，出入日志对象的的处理函数。当需要更多的业务处理接口时，底层用&lt;code&gt;vector&lt;/code&gt;保存&lt;code&gt;lambda&lt;/code&gt;对象，事件触发时，依次遍历调用，类似于&lt;code&gt;QT&lt;/code&gt;中的信号和槽，日志、监控、业务1、业务2，互相之间完全解耦。&lt;/p&gt;
&lt;h2 id=&#34;代码&#34;&gt;代码
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Counter: 1000000
Time: 3966us
Counter: 1000000
Time: 5316us
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;memory&amp;gt;
#include &amp;lt;functional&amp;gt;
#include &amp;lt;atomic&amp;gt;
#include &amp;lt;string&amp;gt;

std::atomic_int64_t counter = 0;

// 定义回调接口
class UserInterface
{
public:
    virtual void name() = 0;
    virtual void full_name() = 0;
};

class User : public UserInterface
{
public:
    void name() {}
    void full_name() { counter++; }
};

void to_string(UserInterface* user)
{
    user-&amp;gt;name();
    user-&amp;gt;full_name();
}

using name_handler = std::function&amp;lt;void()&amp;gt;;
using full_name_handler = std::function&amp;lt;void()&amp;gt;;

class Test
{
    name_handler name_;
    full_name_handler full_name_;

public:
    void set_name_handler(name_handler name)
    {
        name_ = name;
    }

    void set_full_name_handler(full_name_handler full_name)
    {
        full_name_ = full_name;
    }

    void to_string()
    {
        name_();
        full_name_();
    }
};

int main()
{
    User user;

    auto start = std::chrono::high_resolution_clock::now();

    for (int i = 0; i &amp;lt; 1000000; i++)
    {
        to_string(&amp;amp;user);
    }

    auto end = std::chrono::high_resolution_clock::now();
    std::cout &amp;lt;&amp;lt; &amp;quot;Counter: &amp;quot; &amp;lt;&amp;lt; counter &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;Time: &amp;quot; &amp;lt;&amp;lt; std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(end - start).count() &amp;lt;&amp;lt; &amp;quot;us&amp;quot; &amp;lt;&amp;lt; std::endl;

    counter = 0;
    auto name = []() {};
    auto full_name = []() { counter++; };

    Test test;
    test.set_name_handler(name);
    test.set_full_name_handler(full_name);

    start = std::chrono::high_resolution_clock::now();

    for (int i = 0; i &amp;lt; 1000000; i++)
    {
        test.to_string();
    }

    end = std::chrono::high_resolution_clock::now();
    std::cout &amp;lt;&amp;lt; &amp;quot;Counter: &amp;quot; &amp;lt;&amp;lt; counter &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;Time: &amp;quot; &amp;lt;&amp;lt; std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(end - start).count() &amp;lt;&amp;lt; &amp;quot;us&amp;quot; &amp;lt;&amp;lt; std::endl;

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;后记&#34;&gt;后记
&lt;/h2&gt;&lt;p&gt;查找资料的时候，翻到类似的代码片段 &lt;a class=&#34;link&#34; href=&#34;https://gist.githubusercontent.com/benloong/8050171/raw/fa577ec923b460862078b8b40233a42a1c619eeb/functionperformance.cpp&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;functionperformance.cpp&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;memory&amp;gt;
#include &amp;lt;functional&amp;gt;

using namespace std;
using namespace std::chrono;

class Base
{
public:
	Base(){}
	virtual ~Base(){}
	virtual int func(int i) = 0;
};

class Derived : public Base
{
public:
	Derived(int base = 10) : base{base}
	{

	}
	~Derived(){}

	virtual int func(int i)
	{
		return i*base;
	}
private:
	int base;
};

struct Func
{
	int base;
	int operator()(int i)
	{
		return i*base;
	}
	Func(int base) : base {base}
	{

	}
};
const int base = 10;
int calculate(int i)
{
	return base*i;
}

int main()
{
	const int num = 10000;
	Base *p = new Derived{10};
	int total = 0;
	auto start = high_resolution_clock::now();
	for (int i = 0; i &amp;lt; num; ++i)
	{
		total += p-&amp;gt;func(i);
	}
	auto end = high_resolution_clock::now();
	std::cout&amp;lt;&amp;lt;&amp;quot;result: &amp;quot;&amp;lt;&amp;lt;total&amp;lt;&amp;lt;&amp;quot;\nvirtual call elapsed: \t&amp;quot;&amp;lt;&amp;lt;duration_cast&amp;lt;nanoseconds&amp;gt;(end-start).count()&amp;lt;&amp;lt;&amp;quot; nanoseconds.\n&amp;quot;&amp;lt;&amp;lt;std::endl;

	total = 0;
	start = high_resolution_clock::now();
	for (int i = 0; i &amp;lt; num; ++i)
	{
		total += calculate(i);
	}
	end = high_resolution_clock::now();
	std::cout&amp;lt;&amp;lt;&amp;quot;result: &amp;quot;&amp;lt;&amp;lt;total&amp;lt;&amp;lt;&amp;quot;\ndirect function call elapsed: \t&amp;quot;&amp;lt;&amp;lt;duration_cast&amp;lt;nanoseconds&amp;gt;(end-start).count()&amp;lt;&amp;lt;&amp;quot; nanoseconds.\n&amp;quot;&amp;lt;&amp;lt;std::endl;

	Func functor{10};
	total = 0;
	start = high_resolution_clock::now();
	for (int i = 0; i &amp;lt; num; ++i)
	{
		total += functor(i);
	}
	end = high_resolution_clock::now();
	std::cout&amp;lt;&amp;lt;&amp;quot;result: &amp;quot;&amp;lt;&amp;lt;total&amp;lt;&amp;lt;&amp;quot;\nfunctor call elapsed: \t&amp;quot;&amp;lt;&amp;lt;duration_cast&amp;lt;nanoseconds&amp;gt;(end-start).count()&amp;lt;&amp;lt;&amp;quot; nanoseconds.\n&amp;quot;&amp;lt;&amp;lt;std::endl;
	int base = 10;
	function&amp;lt;int(int)&amp;gt; lambda = [base](int i)
	{
		return i*base;
	};
	total = 0;
	start = high_resolution_clock::now();
	for (int i = 0; i &amp;lt; num; ++i)
	{
		total += lambda(i);
	}
	end = high_resolution_clock::now();
	std::cout&amp;lt;&amp;lt;&amp;quot;result: &amp;quot;&amp;lt;&amp;lt;total&amp;lt;&amp;lt;&amp;quot;\nlambda call elapsed: \t&amp;quot;&amp;lt;&amp;lt;duration_cast&amp;lt;nanoseconds&amp;gt;(end-start).count()&amp;lt;&amp;lt;&amp;quot; nanoseconds.\n&amp;quot;&amp;lt;&amp;lt;std::endl;
	return 0;
}

/*
test on mac mini i7 2.7GHz
clang++ -std=c++11 chronotest.cpp -O0
output:
result: 499950000
virtual call elapsed: 	43171 nanoseconds.

result: 499950000
direct function call elapsed: 	31379 nanoseconds.

result: 499950000
functor call elapsed: 	41497 nanoseconds.

result: 499950000
lambda call elapsed: 	207416 nanoseconds.
===================================================
clang++ -std=c++11 chronotest.cpp -O1
output:
result: 499950000
virtual call elapsed: 	26144 nanoseconds.

result: 499950000
direct function call elapsed: 	22384 nanoseconds.

result: 499950000
functor call elapsed: 	33477 nanoseconds.

result: 499950000
lambda call elapsed: 	55799 nanoseconds.
===================================================
clang++ -std=c++11 chronotest.cpp -O2
result: 499950000
virtual call elapsed: 	22284 nanoseconds.

result: 499950000
direct function call elapsed: 	36 nanoseconds.

result: 499950000
functor call elapsed: 	30 nanoseconds.

result: 499950000
lambda call elapsed: 	28292 nanoseconds.

===================================================
clang++ -std=c++11 chronotest.cpp -O3
result: 499950000
virtual call elapsed: 	18975 nanoseconds.

result: 499950000
direct function call elapsed: 	29 nanoseconds.

result: 499950000
functor call elapsed: 	30 nanoseconds.

result: 499950000
lambda call elapsed: 	22542 nanoseconds.
===================================================
clang++ -std=c++11 chronotest.cpp -O4

result: 499950000
virtual call elapsed: 	22141 nanoseconds.

result: 499950000
direct function call elapsed: 	30 nanoseconds.

result: 499950000
functor call elapsed: 	30 nanoseconds.

result: 499950000
lambda call elapsed: 	22584 nanoseconds.
*/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里多了两种模式，普通函数和仿函数，提供接口回调的方式和直接调用比较，性能损耗是数量级的差异，仿函数性能和函数接近，有时候仿函数的性能更优，编译原理这块算是知识盲区，猜测是由于访问的变量地址和函数挨着，有利于&lt;code&gt;CPU&lt;/code&gt;处理&lt;/p&gt;
&lt;p&gt;附上 &lt;code&gt;wandbox&lt;/code&gt; 运行结果&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;result: 499950000
virtual call elapsed: 6143 nanoseconds.

result: 499950000
direct function call elapsed: 30 nanoseconds.

result: 499950000
functor call elapsed: 31 nanoseconds.

result: 499950000
lambda call elapsed: 15134 nanoseconds.
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        
    </channel>
</rss>

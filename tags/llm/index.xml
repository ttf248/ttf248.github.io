<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Llm on 向叔记事簿</title>
        <link>https://ttf248.life/tags/llm/</link>
        <description>Recent content in Llm on 向叔记事簿</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <lastBuildDate>Sat, 28 Feb 2026 18:47:02 +0800</lastBuildDate><atom:link href="https://ttf248.life/tags/llm/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>近期大模型的一些使用经验</title>
        <link>https://ttf248.life/p/recent-usage-experiences-of-large-models/</link>
        <pubDate>Wed, 09 Jul 2025 21:09:01 +0800</pubDate>
        
        <guid>https://ttf248.life/p/recent-usage-experiences-of-large-models/</guid>
        <description>&lt;p&gt;现在用下来并没有哪个大模型特别好，各家都有自己的优势场景。&lt;/p&gt;
&lt;h2 id=&#34;技术文档&#34;&gt;技术文档
&lt;/h2&gt;&lt;p&gt;投喂代码或者咨询IT技术类的问题：ChatGPT 和 Gemini&lt;/p&gt;
&lt;h2 id=&#34;写代码&#34;&gt;写代码
&lt;/h2&gt;&lt;p&gt;整理需求，要求修改代码：Claude&lt;/p&gt;</description>
        </item>
        <item>
        <title>博客翻译项目碎碎念：历史会话</title>
        <link>https://ttf248.life/p/blog-translation-project-musings-historical-conversations/</link>
        <pubDate>Mon, 02 Jun 2025 21:16:24 +0800</pubDate>
        
        <guid>https://ttf248.life/p/blog-translation-project-musings-historical-conversations/</guid>
        <description>&lt;p&gt;博客翻译项目最初设计过于复杂——先解析 Markdown 格式，再用占位符保护内容，最后送给大模型翻译。其实这完全是多此一举，大模型本身就具备识别 Markdown 语法的能力，可以直接处理原始内容并在翻译时保持格式完整。&lt;/p&gt;
&lt;p&gt;我们的工作就从调试代码，切换到调试大模型的&lt;strong&gt;提示词&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;模型：&lt;code&gt;google/gemma-3-4b&lt;/code&gt;
硬件：&lt;code&gt;Nvdia 3060 12GB&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;没错，选的非思考模型，思考模型在执行翻译任务时，效率不够高，对比了 4b 参数和 12b 参数的效果，针对翻译任务来说 gemma3 的 4b 参数已经足够了，12b 的参数在翻译任务上并没有明显的优势。&lt;/p&gt;
&lt;p&gt;12b 参数的速度：&lt;strong&gt;11.32 tok/sec&lt;/strong&gt;，4b 参数的速度：&lt;strong&gt;75.21 tok/sec&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;背景介绍&#34;&gt;背景介绍
&lt;/h2&gt;&lt;p&gt;尽管在&lt;strong&gt;system&lt;/strong&gt;里面加上了各种条件限制，输出的翻译结果，还是会出现一些问题，比如：格式没有保护，多出来了一些解释的内容。角色定义的时候，已经声明过，记得保护 Markdown 格式、仅输出翻译结果，最终的翻译还是不太稳定。&lt;/p&gt;
&lt;p&gt;此时想起来，以前接触过一个漫画翻译的项目，也用到了大模型的能力，它的翻译效果好像比我的效果更好一些，翻看代码，对比请求的数据，漫画翻译的项目，每次请求都会带上一组上下文，除了当前的翻译内容，还会带上之前的翻译内容。&lt;/p&gt;
&lt;p&gt;好处是什么，不仅能提升前后翻译的连贯性，还剩确保输出格式的稳定性。&lt;/p&gt;
&lt;h2 id=&#34;历史会话的重要性&#34;&gt;历史会话的重要性
&lt;/h2&gt;&lt;p&gt;随着 AI 大模型（如 GPT 系列、Claude、Gemini 等）的普及，越来越多企业和开发者通过 API 接入这些模型，构建智能客服、内容生成、代码助手等应用。然而，许多人在接入初期会遇到一个常见问题：&lt;strong&gt;模型输出不连贯、缺乏上下文理解，甚至答非所问&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;造成这种现象的一个关键原因是——&lt;strong&gt;没有在 API 请求中包含历史对话内容&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;什么是历史对话&#34;&gt;什么是历史对话？
&lt;/h2&gt;&lt;p&gt;历史对话是指在一次对话会话中，模型和用户之间之前的交流记录。在大多数大模型 API（如 OpenAI 的 Chat Completions API）中，开发者需要自己在请求中构建完整的 &lt;code&gt;messages&lt;/code&gt; 数组，将历史对话以轮流的 &lt;code&gt;user&lt;/code&gt; 和 &lt;code&gt;assistant&lt;/code&gt; 消息形式传入。&lt;/p&gt;
&lt;h3 id=&#34;示例&#34;&gt;示例
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;model&amp;quot;: &amp;quot;gpt-4&amp;quot;,
  &amp;quot;messages&amp;quot;: [
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;帮我写一封辞职信&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;assistant&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;好的，你希望辞职的原因写些什么？&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;说我想追求个人职业发展&amp;quot;}
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果你只发送最后一句话：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;说我想追求个人职业发展&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;模型根本不知道你在说辞职信，它可能完全无法理解上下文，输出质量自然很差。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;为什么历史对话如此重要&#34;&gt;为什么历史对话如此重要？
&lt;/h2&gt;&lt;h3 id=&#34;1-构建上下文提升连贯性&#34;&gt;1. &lt;strong&gt;构建上下文，提升连贯性&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;AI 模型本质上是“上下文驱动”的。它无法记住“之前”发生的任何事情，除非你&lt;strong&gt;显式告诉它&lt;/strong&gt;。通过传入对话历史，模型可以更好地理解你的意图和话题背景，输出更符合预期。&lt;/p&gt;
&lt;h3 id=&#34;2-降低误解率&#34;&gt;2. &lt;strong&gt;降低误解率&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;如果你希望模型完成一个多轮指令，如写作、总结、调试代码，历史记录能让模型逐步积累理解，避免在中途“跑题”或丢失重点。&lt;/p&gt;
&lt;h3 id=&#34;3-模拟真实人类对话行为&#34;&gt;3. &lt;strong&gt;模拟真实人类对话行为&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;在实际应用中，如客服系统、教育助手、健康咨询等，用户的问题往往是逐步展开的，而不是一次性表达清楚。保留对话历史，可以让 AI 更像一个“有记忆力的助理”。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;如何在-api-中正确添加历史对话&#34;&gt;如何在 API 中正确添加历史对话？
&lt;/h2&gt;&lt;p&gt;以 OpenAI 的 API 为例，建议遵循以下结构：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;messages = [
    {&amp;quot;role&amp;quot;: &amp;quot;system&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;你是一个专业的法律助手&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;什么是合同的有效条件？&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;assistant&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;合同有效需要满足以下几个条件：……&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;那口头协议算吗？&amp;quot;}
]

response = openai.ChatCompletion.create(
    model=&amp;quot;gpt-4&amp;quot;,
    messages=messages
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;system&lt;/code&gt; 消息设定模型行为和身份。&lt;/li&gt;
&lt;li&gt;保留最近几轮关键对话即可，不需要每次传入全部历史（避免超过 token 限制）。&lt;/li&gt;
&lt;li&gt;在长会话中，可通过截断早期内容，保留核心信息摘要，控制 token 消耗。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;实践建议&#34;&gt;实践建议
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;对话状态管理&lt;/strong&gt;：后端需设计缓存机制，记录每个用户的会话历史（如 Redis、数据库）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;限制长度&lt;/strong&gt;：OpenAI GPT-4 的上下文长度为 128k tokens，Claude 3 可达 200k~1M，需合理裁剪。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;动态摘要历史&lt;/strong&gt;：当历史内容过长时，使用模型先对旧对话做摘要，再添加进对话上下文。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结
&lt;/h2&gt;&lt;p&gt;AI 大模型的能力强大，但也需要开发者“喂”给它足够的上下文信息。&lt;strong&gt;通过在 API 请求中添加历史对话，不仅能显著提升模型输出的质量和连贯性，也能让用户体验更自然、更贴近真实对话。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;无论你是在构建 AI 客服、写作助手、编程帮手，还是教育类应用，这都是一个不可忽视的优化技巧。&lt;/p&gt;</description>
        </item>
        <item>
        <title>ollama 本地部署 deepseek-R1</title>
        <link>https://ttf248.life/p/ollama-local-deployment-deepseek-r1/</link>
        <pubDate>Fri, 07 Feb 2025 22:41:02 +0800</pubDate>
        
        <guid>https://ttf248.life/p/ollama-local-deployment-deepseek-r1/</guid>
        <description>&lt;p&gt;Ollama 是一个开源的 AI 工具，旨在使用户能够本地运行和部署大型语言模型（LLM）。它的目标是提供一个方便且高效的方式，让开发者可以在本地机器上使用像 GPT 这样的模型，而不需要依赖云端服务。Ollama 支持多种模型，并且专注于优化性能，使得即使是资源有限的设备也能顺畅运行这些模型。&lt;/p&gt;
&lt;p&gt;通过 Ollama，用户可以使用基于文本的 AI 应用程序，并能够与本地部署的模型进行交互，而无需担心数据隐私或是高昂的 API 使用费用。你可以通过命令行界面（CLI）调用不同的模型，进行自然语言处理、问答等任务。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ollama 适合不同模型尝鲜，windows 版本测试下来，无法充分发挥硬件的性能，可能是因为 windows 版本的原因，linux 版本可能会更好。部署32b参数的模型，内存、显卡负载都有不高的情况下，回复速度很慢。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;硬件概述&#34;&gt;硬件概述
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;操作系统：win11&lt;/li&gt;
&lt;li&gt;CPU：i7-10700K&lt;/li&gt;
&lt;li&gt;内存：40GB&lt;/li&gt;
&lt;li&gt;显卡：RTX 3060 12GB&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;环境准备&#34;&gt;环境准备
&lt;/h2&gt;&lt;p&gt;新增系统环境变量，方便后续使用：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_MODELS=E:\ollama&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
这个变量指定了 Ollama 模型的存放路径。&lt;code&gt;E:\ollama&lt;/code&gt; 是一个文件夹路径，表示所有本地模型文件都存储在该目录下。Ollama 会根据这个路径加载和使用你下载或部署的语言模型。你可以将模型文件存放在其他位置，只需要更改这个路径。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_HOST=127.0.0.1:8000&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
这个环境变量设置了 Ollama 服务的主机和端口。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;127.0.0.1&lt;/code&gt; 是本地地址（localhost），意味着 Ollama 服务会只监听来自本机的请求。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;8000&lt;/code&gt; 是指定的端口号，表示 Ollama 服务将在 8000 端口上等待和处理请求。你可以根据需要更改端口号，但需要确保该端口没有被其他应用占用。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_ORIGINS=*&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
这个环境变量控制允许哪些来源的请求访问 Ollama 服务。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;*&lt;/code&gt; 表示允许任何来源（即所有域名和 IP 地址）都可以访问 Ollama 服务。这通常用于开发和调试环境，在生产环境中，通常会指定更严格的来源控制，限制只有特定的域或 IP 才能访问你的服务，以提高安全性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;deepseek-r1-模型部署&#34;&gt;deepseek-R1 模型部署
&lt;/h2&gt;&lt;p&gt;ollama 安装属于傻瓜式，此处不在赘述。&lt;/p&gt;
&lt;p&gt;安装后的校验：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core&amp;gt;ollama -v
ollama version is 0.5.11
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;模型部署，参考官网模型页面，选择对应参数的模型：&lt;code&gt;ollama run deepseek-r1:14b&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;14b 参数能有效的记住会话上下文，更小的参数版本，无法记住会话上下文。32b 参数版本，本机部署很卡顿，没有再深入进行测试。&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ollama.com/library/deepseek-r1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.ollama.com/library/deepseek-r1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/x18990027/article/details/145368094&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/x18990027/article/details/145368094&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        
    </channel>
</rss>

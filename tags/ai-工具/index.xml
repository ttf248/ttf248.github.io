<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>AI 工具 on 向叔记事簿</title>
        <link>https://ttf248.life/tags/ai-%E5%B7%A5%E5%85%B7/</link>
        <description>Recent content in AI 工具 on 向叔记事簿</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <lastBuildDate>Thu, 29 Jan 2026 22:52:12 +0800</lastBuildDate><atom:link href="https://ttf248.life/tags/ai-%E5%B7%A5%E5%85%B7/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Gemini CLI 安装部署，谷歌追上来了</title>
        <link>https://ttf248.life/p/gemini-cli-installation-and-deployment-google-is-catching-up/</link>
        <pubDate>Sat, 22 Nov 2025 00:13:49 +0800</pubDate>
        
        <guid>https://ttf248.life/p/gemini-cli-installation-and-deployment-google-is-catching-up/</guid>
        <description>&lt;p&gt;小半个月过去了，国内的 MiniMax，GLM4.6 都付费体验了一波，差距还是存在，cc 工具挺好用的，昨晚折腾前端界面的优化，你懂得，笔者基本不懂前端，vibe coding 以后，才开始接触前端技术栈。国内的大模型没搞定，尝试刚发布的 gemini3，五分钟搞定了，切换到站点的归档页面，你就能看到“书架”。&lt;/p&gt;
&lt;p&gt;常年做的后端C++开发，谷歌在这块的影响力太大了，默认谷歌的产品不会太差，大模型前期是落后，不到两年的时间，现在已经追赶上来。&lt;/p&gt;
&lt;p&gt;首页的 AI 搜索，百度不知道猴年马月能搞出来，不是说百度不行，是国内的产品没去思考，搜索里面嵌入 AI，最重要的是速度，谷歌做到了。&lt;/p&gt;
&lt;h2 id=&#34;安装部署&#34;&gt;安装部署
&lt;/h2&gt;&lt;p&gt;谷歌的模型既然不错，还给了免费的额度，什么取消也没通知，等通知了再说，先用着。个人用户登录，每天有 1000 的免费额度，pro 用户 1500 免费额度，说白了，谷歌暂时还没想从编码这块赚钱。&lt;/p&gt;
&lt;p&gt;类似 cc 的安装部署，官方文档挺详细这就不多说：https://geminicli.com/docs/&lt;/p&gt;
&lt;p&gt;重点是针对国内的用户，首先登录的时候，你需要给当前终端挂上代理，它会访问谷歌的服务器，登录以后也需要保持代理。&lt;/p&gt;
&lt;p&gt;如果是远程服务器登录，没有浏览器、没有界面，执行 &lt;code&gt;gemini login&lt;/code&gt;，访问对应的网址，能获取到一个登录 code。&lt;/p&gt;
&lt;p&gt;gemini3 需要加入排队申请，gemini2-pro 和其他模型随便使用。&lt;/p&gt;
&lt;p&gt;使用谷歌账号登录以后，你需要绑定谷歌云的项目ID，免费归免费，走了付费的流程，记得不要走 api 的流程，这块是计费的。个人账号登录，设置环境变量 &lt;code&gt;GOOGLE_CLOUD_PROJECT&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;谷歌云这块，抖音和国内的博主都没提，说到了能免费用，那些视频怎么说，有点洗稿的嫌疑，流程没有完整的走过。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;使用&#34;&gt;使用
&lt;/h2&gt;&lt;p&gt;功能上和 cc 存在差距，每周迭代中，记得按时更新。基础的用法和 cc 类型，切换没有太多成本。&lt;/p&gt;
&lt;p&gt;差距最大的地方在 cli 插件无法不知道你在 ide 选中了那行，目前仅感知文件级别，不知道是产品设计的问题，还是在开发中。&lt;/p&gt;
&lt;p&gt;剩余额度没有地方能查询，在 &lt;code&gt;google cloud&lt;/code&gt; 后台能查到调用记录，顺带一提绑定了项目，你的项目需要开通 gemini api 权限，别担心扣费，你都不用绑定信用卡，权限开通以后能正常调用模型。&lt;/p&gt;
&lt;p&gt;交互上有点不同，终端的屏幕划分成了两部分，最下面是输入框，上面是交流过程，默认展开的，想要给上面的区域翻页，滚动鼠标是不行的，需要通过键盘的 Pages 按键。&lt;/p&gt;
&lt;p&gt;每次会话结束，默认会弹出来本次任务的一个汇总。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;   ░░░            ░░░░░░░░░  ░░░░░░░░░░ ░░░░░░   ░░░░░░ ░░░░░ ░░░░░░   ░░░░░ ░░░░░
     ░░░         ░░░     ░░░ ░░░        ░░░░░░   ░░░░░░  ░░░  ░░░░░░   ░░░░░  ░░░
       ░░░      ░░░          ░░░        ░░░ ░░░ ░░░ ░░░  ░░░  ░░░ ░░░  ░░░    ░░░
 ███     ░░░    █████████░░██████████ ██████ ░░██████░█████░██████ ░░█████ █████░
   ███ ░░░     ███░    ███░███░░      ██████  ░██████░░███░░██████  ░█████  ███░░
     ███      ███░░░     ░░███░░      ███░███ ███ ███░░███░░███░███  ███░░  ███░░
   ░░░ ███    ███ ░░░█████░██████░░░░░███░░█████  ███░░███░░███░░███ ███░░░ ███░░░
     ███      ███      ███ ███        ███   ███   ███  ███  ███   ██████    ███
   ███         ███     ███ ███        ███         ███  ███  ███    █████    ███
 ███            █████████  ██████████ ███         ███ █████ ███     █████  █████

Tips for getting started:
1. Ask questions, edit files, or run commands.
2. Be specific for the best results.
3. Create GEMINI.md files to customize your interactions with Gemini.
4. /help for more information.
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>claude code 常用操作指南</title>
        <link>https://ttf248.life/p/claude-code-frequently-asked-operations-guide/</link>
        <pubDate>Sat, 08 Nov 2025 17:09:24 +0800</pubDate>
        
        <guid>https://ttf248.life/p/claude-code-frequently-asked-operations-guide/</guid>
        <description>&lt;p&gt;cc 提供的命令那么多，好用的都有哪些，抖音找个了视频学习一波，简单的记录下我认为有用的。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;生成规范化 git 日志，默认会带上版权信息，但是国内已经不用他家的模型了，对接的都是国内大模型，git 日志里面的版权也就没必要加上了（github 会展示 cc 为合作开发者）&lt;/p&gt;
&lt;p&gt;找到用户配置文件，添加配置项 &lt;code&gt;&amp;quot;includeCoAuthoredBy&amp;quot;: false&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;/init 分析分析当前文件夹生成一份概要，方便大模型更好的理解项目&lt;/p&gt;
&lt;p&gt;&lt;code&gt;/compact /clear&lt;/code&gt; 日常命令，不解释&lt;/p&gt;
&lt;p&gt;&lt;code&gt;claude --dangerously-skip-permissions&lt;/code&gt; 慎用，上篇稿子的 null 文件就是这样弄出来的，cc windows 上有很多小问题&lt;/p&gt;
&lt;p&gt;&lt;code&gt;#&lt;/code&gt; 进入记忆模式，项目级别用的比较少，我常用在用户级别，常用项目要求写到里面&lt;/p&gt;
&lt;p&gt;&lt;code&gt;/ide&lt;/code&gt; 能感知到 vscode 当前选中的文本数据，trae 里面，经常交互的时候，我是提供很多相关文件的函数片段，切换到命令行，一直没找到类似的功能，主要是很多时候项目的文件很多，制定参考的函数，能有效提供生成代码的准确率&lt;/p&gt;
&lt;p&gt;mcp ？一直没怎么尝试此类型的工具，后续有需要再来尝试，老觉得用起来有点麻烦&lt;/p&gt;
&lt;p&gt;自定义命令 没需求，用户级别的能替代之前写的 git 规范化递交&lt;/p&gt;
&lt;p&gt;&lt;code&gt;-r&lt;/code&gt; 关闭项目后重启找到之前的对话，对于复杂的项目，用处不大，国内的模型，上下文 200k，很容易就满了&lt;/p&gt;</description>
        </item>
        <item>
        <title>不写代码，设计开发自选股模块</title>
        <link>https://ttf248.life/p/design-develop-custom-stock-module-no-code/</link>
        <pubDate>Thu, 27 Feb 2025 23:20:39 +0800</pubDate>
        
        <guid>https://ttf248.life/p/design-develop-custom-stock-module-no-code/</guid>
        <description>&lt;p&gt;上个月我们试用了 cursor，但是由于免费额度的限制，并没有做太复杂的功能开发，只是简单的测试了一下。那会就发现，字节也发布了类似的产品，两者底层调用的大模型一样，都是 Claude-3.5。&lt;/p&gt;
&lt;p&gt;字节产品叫做 Trae，先发布的 mac 版本，今年二月份，终于发布了 windows 版本。大厂的东西就是好，能免费白嫖，不用掏钱，无限量使用 Claude-3.5，这个模型的效果还是很不错的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;最终卡在了K线图的开发上，由于本人基本不懂 react，所以只能放弃了。想要继续开发，需要笔者补充一些前端的基础知识，将任务拆分的更细，而不是直接给一个大任务：开发K线图。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;发现的问题&#34;&gt;发现的问题
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;由于使用国外的 AI 模型，Vue3 + Element-Plus 的训练数据不足，因此选择了 React 作为前端框架&lt;/li&gt;
&lt;li&gt;可能存在偶发的语法错误，需要人工修复&lt;/li&gt;
&lt;li&gt;部分复杂问题的解决方案需要人工指引&lt;/li&gt;
&lt;li&gt;代码结构优化需要人工指导&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其中耗时最多的地方，打包前端代码到容器中，由于笔者零基础 &lt;code&gt;.env.production&lt;/code&gt; &lt;code&gt;tsconfig.json&lt;/code&gt;，完全是没有概念的，这些还是中途求助豆包，才捋顺对应的逻辑。前端开发 dev 模式和 build 模式，对于代码的检查，差异很大。后端数据库和服务的容器脚本，合计五分钟就搞定了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI 目前更多的提高开发的效率，你有基础是最好的，并不是 AI 会帮你解决所有的问题&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;仓库地址&#34;&gt;仓库地址
&lt;/h2&gt;&lt;p&gt;正如标题说的，我们这次是能不写就不动手，和AI硬聊，设计开发自选股模块。看最终能做出来什么效果。&lt;/p&gt;
&lt;p&gt;仓库地址：&lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/trae-demo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/trae-demo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;详细的使用方法，可以看仓库的 README.md 文件。&lt;/p&gt;
&lt;p&gt;仓库包含很多递交记录，大部分都是我和 Trae 的对话记录，以及我对 Trae 的一些功能的测试，备注了是否人工干预来实现对应的功能。&lt;/p&gt;
&lt;h2 id=&#34;prompt&#34;&gt;Prompt
&lt;/h2&gt;&lt;p&gt;项目是从零开始创建，下面是项目的 Prompt：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;基于项目原型图，开发功能：自选股，需要支持合约的新增、删除、修改、查询。自选股界面需要展示基础的行情数据。支持多个不同的市场切换。

前端：react
后端：golang gin gorm
数据库：PostgreSQL

服务端需要支持跨域请求，同时需要考虑数据的校验和错误处理，如果后端服务不可用，前端需要告警提示。

后端需要展示请求和应答的日志；前端也打印通讯的日志，方便排查问题。
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;ui和交互优化&#34;&gt;UI和交互优化
&lt;/h2&gt;&lt;p&gt;前端界面的设计完全依赖的 Grok，我们首先在 Trae 里面做出来产物的雏形，但是没有审美，由于使用的模型，代码能力很强，但是其他能力比较弱，所以我们需要使用 Grok 来优化前端的 UI。&lt;/p&gt;
&lt;p&gt;通过将当前的界面截图，上传到 Grok 里面，然后让它帮我们优化 UI，可能一次性拿到很多的优化建议，我们人工评估，然后拷贝到 Trae 中执行，观察优化的效果。&lt;/p&gt;
&lt;h3 id=&#34;技术栈&#34;&gt;技术栈
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;前端：React + TypeScript&lt;/li&gt;
&lt;li&gt;后端：Golang + Gin + GORM&lt;/li&gt;
&lt;li&gt;数据库：PostgreSQL 17&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;系统架构&#34;&gt;系统架构
&lt;/h2&gt;&lt;h2 id=&#34;后端架构&#34;&gt;后端架构
&lt;/h2&gt;&lt;p&gt;后端采用 Golang 的 Gin 框架实现 RESTful API，主要模块包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;数据库模块&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 GORM 作为 ORM 框架&lt;/li&gt;
&lt;li&gt;支持环境变量配置数据库连接&lt;/li&gt;
&lt;li&gt;自动进行数据库表迁移&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;路由模块&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RESTful API 设计&lt;/li&gt;
&lt;li&gt;统一的错误处理机制&lt;/li&gt;
&lt;li&gt;内置请求日志记录&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;跨域处理&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;支持本地开发环境跨域&lt;/li&gt;
&lt;li&gt;可配置的 CORS 策略&lt;/li&gt;
&lt;li&gt;支持 Cookie 跨域&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;前端架构&#34;&gt;前端架构
&lt;/h2&gt;&lt;p&gt;前端使用 React + TypeScript 构建，实现了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;股票列表展示&lt;/li&gt;
&lt;li&gt;自选股管理&lt;/li&gt;
&lt;li&gt;行情数据展示&lt;/li&gt;
&lt;li&gt;错误提示机制&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>ollama 本地部署 deepseek-R1</title>
        <link>https://ttf248.life/p/ollama-local-deployment-deepseek-r1/</link>
        <pubDate>Fri, 07 Feb 2025 22:41:02 +0800</pubDate>
        
        <guid>https://ttf248.life/p/ollama-local-deployment-deepseek-r1/</guid>
        <description>&lt;p&gt;Ollama 是一个开源的 AI 工具，旨在使用户能够本地运行和部署大型语言模型（LLM）。它的目标是提供一个方便且高效的方式，让开发者可以在本地机器上使用像 GPT 这样的模型，而不需要依赖云端服务。Ollama 支持多种模型，并且专注于优化性能，使得即使是资源有限的设备也能顺畅运行这些模型。&lt;/p&gt;
&lt;p&gt;通过 Ollama，用户可以使用基于文本的 AI 应用程序，并能够与本地部署的模型进行交互，而无需担心数据隐私或是高昂的 API 使用费用。你可以通过命令行界面（CLI）调用不同的模型，进行自然语言处理、问答等任务。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ollama 适合不同模型尝鲜，windows 版本测试下来，无法充分发挥硬件的性能，可能是因为 windows 版本的原因，linux 版本可能会更好。部署32b参数的模型，内存、显卡负载都有不高的情况下，回复速度很慢。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;硬件概述&#34;&gt;硬件概述
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;操作系统：win11&lt;/li&gt;
&lt;li&gt;CPU：i7-10700K&lt;/li&gt;
&lt;li&gt;内存：40GB&lt;/li&gt;
&lt;li&gt;显卡：RTX 3060 12GB&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;环境准备&#34;&gt;环境准备
&lt;/h2&gt;&lt;p&gt;新增系统环境变量，方便后续使用：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_MODELS=E:\ollama&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
这个变量指定了 Ollama 模型的存放路径。&lt;code&gt;E:\ollama&lt;/code&gt; 是一个文件夹路径，表示所有本地模型文件都存储在该目录下。Ollama 会根据这个路径加载和使用你下载或部署的语言模型。你可以将模型文件存放在其他位置，只需要更改这个路径。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_HOST=127.0.0.1:8000&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
这个环境变量设置了 Ollama 服务的主机和端口。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;127.0.0.1&lt;/code&gt; 是本地地址（localhost），意味着 Ollama 服务会只监听来自本机的请求。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;8000&lt;/code&gt; 是指定的端口号，表示 Ollama 服务将在 8000 端口上等待和处理请求。你可以根据需要更改端口号，但需要确保该端口没有被其他应用占用。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_ORIGINS=*&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
这个环境变量控制允许哪些来源的请求访问 Ollama 服务。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;*&lt;/code&gt; 表示允许任何来源（即所有域名和 IP 地址）都可以访问 Ollama 服务。这通常用于开发和调试环境，在生产环境中，通常会指定更严格的来源控制，限制只有特定的域或 IP 才能访问你的服务，以提高安全性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;deepseek-r1-模型部署&#34;&gt;deepseek-R1 模型部署
&lt;/h2&gt;&lt;p&gt;ollama 安装属于傻瓜式，此处不在赘述。&lt;/p&gt;
&lt;p&gt;安装后的校验：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core&amp;gt;ollama -v
ollama version is 0.5.11
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;模型部署，参考官网模型页面，选择对应参数的模型：&lt;code&gt;ollama run deepseek-r1:14b&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;14b 参数能有效的记住会话上下文，更小的参数版本，无法记住会话上下文。32b 参数版本，本机部署很卡顿，没有再深入进行测试。&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ollama.com/library/deepseek-r1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.ollama.com/library/deepseek-r1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/x18990027/article/details/145368094&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/x18990027/article/details/145368094&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        
    </channel>
</rss>

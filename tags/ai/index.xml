<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>ai on 向叔记事簿</title>
        <link>https://ttf248.life/tags/ai/</link>
        <description>Recent content in ai on 向叔记事簿</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language><atom:link href="https://ttf248.life/tags/ai/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Claude4发布，尝试开发：hugo标签、超链接翻译助手</title>
        <link>https://ttf248.life/p/claude-4-release-and-experimentation-hugo-tags-hyperlink-translation-assistant/</link>
        <pubDate>Sat, 24 May 2025 03:05:31 +0800</pubDate>
        
        <guid>https://ttf248.life/p/claude-4-release-and-experimentation-hugo-tags-hyperlink-translation-assistant/</guid>
        <description>&lt;p&gt;本站点基于 hugo 开发，但是笔者一直用的都是中文标题，导致生成的文章超链接不太友好，说人话就是，发出去的时候，看起来不太友好，中文的字符在超链接中会被转义成 %E4%BD%A0%E5%A5%BD 这种形式，虽然可以通过设置 slug 来解决，但是每次都要手动设置，太麻烦了。&lt;/p&gt;
&lt;p&gt;所以，今天尝试用 Claude4 来开发一个翻译助手，自动将中文标题转换为英文 slug，并且在文章中添加超链接。这样就可以避免手动设置了。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;claude4 真香，上下文的能力大幅提升，复杂任务的处理效率也大幅提升。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;项目地址&#34;&gt;项目地址
&lt;/h2&gt;&lt;p&gt;国内项目地址：&lt;a class=&#34;link&#34; href=&#34;https://cnb.cool/ttf248/hugo-slug-auto&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://cnb.cool/ttf248/hugo-slug-auto&lt;/a&gt;
国外项目地址：&lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/hugo-slug-auto&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/hugo-slug-auto&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;代码实现&#34;&gt;代码实现
&lt;/h2&gt;&lt;p&gt;先说一下实现思路：我们需要扫描所有文章，提取标签信息和文章标题，然后调用本地的大模型（如 gemma-3-12b-it）进行翻译。&lt;/p&gt;
&lt;p&gt;在实际开发中，与前代大模型相比，&lt;code&gt;Claude4&lt;/code&gt; 展现了几个显著的亮点。由于功能需求较多，&lt;code&gt;Claude4&lt;/code&gt; 自动设计了交互式菜单，全面考虑了各种使用场景。例如，在标签处理方面，&lt;code&gt;Claude4&lt;/code&gt; 不仅支持标签的统计与分析，还包括分类统计，甚至能够检测&lt;strong&gt;无标签文章&lt;/strong&gt;。此外，它还提供了&lt;strong&gt;预览&lt;/strong&gt;和生成标签页面的功能。&lt;/p&gt;
&lt;p&gt;无论是对接本地大模型、新增翻译缓存，还是进行大范围的代码重构，&lt;code&gt;Claude4&lt;/code&gt; 都一次性完成，几乎没有出现任何问题。尽管项目规模不大，但包含了许多小功能。以往在开发过程中，大模型经常会遗忘前面的内容，而这次的 &lt;code&gt;Claude4&lt;/code&gt; 表现非常出色，&lt;strong&gt;几乎没有出现遗忘上下文的情况&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;简而言之，智能程度提高了，后续准备切换到 &lt;code&gt;Claude4&lt;/code&gt; 进行更多的开发工作，作为日常编码的主力模型。&lt;/p&gt;
&lt;h2 id=&#34;翻译缓存&#34;&gt;翻译缓存
&lt;/h2&gt;&lt;p&gt;这个点单说，除了减少大模型调用次数，实际本地跑 12b 模型，效率挺高，不耽误事，但是如果每次都要调用大模型，还是会有点慢的。其次就是，为了固定文章的连接，如果执行全量更新操作，文章的标题很长，偶尔就会出现，两次翻译出来的结果不一样的情况，导致文章的链接变了，这个就很尴尬了。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;=== 博客标签管理工具 ===

📊 数据查看
  1. 标签统计与分析
  2. 分类统计
  3. 无标签文章

🏷️  标签页面管理
  4. 预览标签页面
  5. 生成标签页面

📝 文章Slug管理
  6. 预览文章Slug
  7. 生成文章Slug

💾 缓存管理
  8. 查看缓存状态
  9. 预览全量翻译缓存
 10. 生成全量翻译缓存
 11. 清空翻译缓存

  0. 退出程序
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;hugo-标签自动化管理工具&#34;&gt;Hugo 标签自动化管理工具
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;🚀 一款专为Hugo博客设计的智能标签管理工具，支持AI翻译、本地缓存和友好的交互界面&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;-核心特色&#34;&gt;✨ 核心特色
&lt;/h2&gt;&lt;h3 id=&#34;-ai智能翻译&#34;&gt;🤖 AI智能翻译
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;基于LM Studio的本地AI模型翻译&lt;/li&gt;
&lt;li&gt;中文标签自动转换为SEO友好的英文slug&lt;/li&gt;
&lt;li&gt;支持批量翻译，提高处理效率&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;-智能缓存系统&#34;&gt;💾 智能缓存系统
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;本地JSON缓存，避免重复翻译&lt;/li&gt;
&lt;li&gt;自动检测缓存状态，节省API调用&lt;/li&gt;
&lt;li&gt;支持缓存管理和清理功能&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;-友好交互界面&#34;&gt;🎯 友好交互界面
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;直观的命令行菜单系统&lt;/li&gt;
&lt;li&gt;彩色输出，清晰易读&lt;/li&gt;
&lt;li&gt;预览功能，安全可靠&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;-数据分析统计&#34;&gt;📊 数据分析统计
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;标签使用频率分析&lt;/li&gt;
&lt;li&gt;分类统计与可视化&lt;/li&gt;
&lt;li&gt;无标签文章检测&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;-快速开始&#34;&gt;🚀 快速开始
&lt;/h2&gt;&lt;h3 id=&#34;环境要求&#34;&gt;环境要求
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Go 1.21+&lt;/li&gt;
&lt;li&gt;LM Studio (可选，用于AI翻译)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;安装运行&#34;&gt;安装运行
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 克隆项目
git clone https://github.com/ttf248/hugo-slug-auto.git
cd hugo-slug-auto

# 安装依赖
go mod tidy

# 运行工具
go run main.go [content目录路径]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;基本使用&#34;&gt;基本使用
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;标签分析&lt;/strong&gt;: 查看博客标签使用统计&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;生成标签页面&lt;/strong&gt;: 为每个标签创建专门的页面&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;文章Slug管理&lt;/strong&gt;: 为文章标题生成SEO友好的URL&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;缓存管理&lt;/strong&gt;: 查看和管理翻译缓存&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;-项目架构&#34;&gt;📁 项目架构
&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;hugo-slug-auto/
├── main.go              # 主程序入口
├── models/              # 数据模型
├── scanner/             # 文章扫描解析
├── stats/               # 统计分析
├── translator/          # AI翻译模块
├── generator/           # 内容生成器
├── display/             # 界面显示
└── docs/               # 详细文档
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;-主要功能&#34;&gt;🎮 主要功能
&lt;/h2&gt;&lt;h3 id=&#34;标签管理&#34;&gt;标签管理
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;📊 标签统计分析&lt;/li&gt;
&lt;li&gt;🏷️ 自动生成标签页面&lt;/li&gt;
&lt;li&gt;🔄 批量翻译处理&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;文章管理&#34;&gt;文章管理
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;📝 Slug自动生成&lt;/li&gt;
&lt;li&gt;🔍 文章内容分析&lt;/li&gt;
&lt;li&gt;📋 批量处理支持&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;智能特性&#34;&gt;智能特性
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;🤖 AI驱动的翻译&lt;/li&gt;
&lt;li&gt;💾 智能缓存机制&lt;/li&gt;
&lt;li&gt;🎯 精准内容识别&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;-文档链接&#34;&gt;📚 文档链接
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;docs/installation.md&#34; &gt;安装配置指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;docs/usage.md&#34; &gt;功能使用说明&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;docs/api.md&#34; &gt;API接口文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;docs/troubleshooting.md&#34; &gt;故障排除&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;-贡献指南&#34;&gt;🤝 贡献指南
&lt;/h2&gt;&lt;p&gt;欢迎提交Issue和Pull Request！详细说明请查看 &lt;a class=&#34;link&#34; href=&#34;docs/contributing.md&#34; &gt;贡献指南&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;-许可证&#34;&gt;📄 许可证
&lt;/h2&gt;&lt;p&gt;MIT License - 详见 &lt;a class=&#34;link&#34; href=&#34;LICENSE&#34; &gt;LICENSE&lt;/a&gt; 文件&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;⭐ 如果这个项目对您有帮助，请给个Star支持一下！&lt;/p&gt;</description>
        </item>
        <item>
        <title>AI用多了，有点后遗症</title>
        <link>https://ttf248.life/p/ai-overuse-side-effects/</link>
        <pubDate>Wed, 14 May 2025 19:39:50 +0800</pubDate>
        
        <guid>https://ttf248.life/p/ai-overuse-side-effects/</guid>
        <description>&lt;p&gt;自从新建了&lt;code&gt;AI 灵感碰撞坊&lt;/code&gt;，很多有的没的东西，都在试着用AI记录，发布出来，静下来自己思考的东西，反而越来越少了，以后需要稍微控制下此栏目的产出，整合为月刊的形式不错，每月发布一篇就行。&lt;/p&gt;
&lt;p&gt;这就像是某种后遗症，或者说是副作用，效率是提高了，但是思考的深度和广度却下降了。&lt;/p&gt;
&lt;h2 id=&#34;效率提升不可否认&#34;&gt;效率提升：不可否认
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;鱼的七秒钟见闻&lt;/code&gt;以前这个栏目维护的不多，有些热点事件，由于懒并没与去互联网搜索资料、整理记录下来，现在有了各种AI工具，整理好大纲就行，AI能做到自动联网搜索记录相关的事件，生成我需要的文章，简单的整理下格式，发布出来就行。&lt;/p&gt;
&lt;p&gt;这就像是一个懒人福音，效率提高了不少，甚至可以说是事半功倍。&lt;/p&gt;
&lt;p&gt;抛开写稿子，写代码的时候，效率提升是实打实的，很多代码的编写，以前是需要详细阅读API接口文档说明，现在直接跳过，这种跳过相当的有必要，熟悉API属于&lt;code&gt;体力劳动&lt;/code&gt;，而不是&lt;code&gt;脑力劳动&lt;/code&gt;，AI来搞定这部分内容，刚刚好。&lt;/p&gt;
&lt;h2 id=&#34;垃圾内容&#34;&gt;垃圾内容
&lt;/h2&gt;&lt;p&gt;很多稿子，内容质量不高，不能说没有东西，读起来怎么说，没有烟火气息，是我以前不喜欢的风格，味同嚼蜡。&lt;/p&gt;
&lt;p&gt;换个角度来说，AI生成的内容，确实是有点像是流水线生产出来的东西，缺乏灵魂。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;新时代的互联网垃圾&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;遗忘性&#34;&gt;遗忘性
&lt;/h2&gt;&lt;p&gt;此类型的稿子，都是AI生成的，读者的情况不清楚，但是时间长了，我自己的印象也会模糊，甚至是忘记了。&lt;/p&gt;
&lt;p&gt;类似的问题，写代码的时候也会发生，不翻看代码提交记录，根本不知道自己当时是怎么想的，为什么要这么写。特别是代码通过和AI反复沟通，最后生成的代码，和最初的想法差别很大，甚至是完全不一样。&lt;/p&gt;
&lt;h2 id=&#34;搜索&#34;&gt;搜索
&lt;/h2&gt;&lt;p&gt;最近打开谷歌、百度的次数明显减少了，很多问题用AI来搜索，交互也好、搜索的结果也好，都比传统的搜索引擎要好很多。&lt;/p&gt;
&lt;p&gt;现在让我们祭奠下不知道是否还活着的&lt;code&gt;bing ai&lt;/code&gt;，属于大厂里面最早发布的，能联网搜索的AI工具。&lt;/p&gt;
&lt;p&gt;谷歌用的少了，访问&lt;code&gt;stackoverflow&lt;/code&gt;的次数也少了，很多问题直接问AI就行了，这网站也逐渐要被时代所淘汰。&lt;/p&gt;
&lt;h2 id=&#34;结尾&#34;&gt;结尾
&lt;/h2&gt;&lt;p&gt;笔者还在维护的博客，原本也没多少访问量，现在就更不指望了，更多是个记录的地方，写给自己看的。&lt;/p&gt;</description>
        </item>
        <item>
        <title>不写代码，设计开发自选股模块</title>
        <link>https://ttf248.life/p/no-code-design-develop-custom-stock-module/</link>
        <pubDate>Thu, 27 Feb 2025 23:20:39 +0800</pubDate>
        
        <guid>https://ttf248.life/p/no-code-design-develop-custom-stock-module/</guid>
        <description>&lt;p&gt;上个月我们试用了 cursor，但是由于免费额度的限制，并没有做太复杂的功能开发，只是简单的测试了一下。那会就发现，字节也发布了类似的产品，两者底层调用的大模型一样，都是 Claude-3.5。&lt;/p&gt;
&lt;p&gt;字节产品叫做 Trae，先发布的 mac 版本，今年二月份，终于发布了 windows 版本。大厂的东西就是好，能免费白嫖，不用掏钱，无限量使用 Claude-3.5，这个模型的效果还是很不错的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;最终卡在了K线图的开发上，由于本人基本不懂 react，所以只能放弃了。想要继续开发，需要笔者补充一些前端的基础知识，将任务拆分的更细，而不是直接给一个大任务：开发K线图。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;发现的问题&#34;&gt;发现的问题
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;由于使用国外的 AI 模型，Vue3 + Element-Plus 的训练数据不足，因此选择了 React 作为前端框架&lt;/li&gt;
&lt;li&gt;可能存在偶发的语法错误，需要人工修复&lt;/li&gt;
&lt;li&gt;部分复杂问题的解决方案需要人工指引&lt;/li&gt;
&lt;li&gt;代码结构优化需要人工指导&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其中耗时最多的地方，打包前端代码到容器中，由于笔者零基础 &lt;code&gt;.env.production&lt;/code&gt; &lt;code&gt;tsconfig.json&lt;/code&gt;，完全是没有概念的，这些还是中途求助豆包，才捋顺对应的逻辑。前端开发 dev 模式和 build 模式，对于代码的检查，差异很大。后端数据库和服务的容器脚本，合计五分钟就搞定了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI 目前更多的提高开发的效率，你有基础是最好的，并不是 AI 会帮你解决所有的问题&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;仓库地址&#34;&gt;仓库地址
&lt;/h2&gt;&lt;p&gt;正如标题说的，我们这次是能不写就不动手，和AI硬聊，设计开发自选股模块。看最终能做出来什么效果。&lt;/p&gt;
&lt;p&gt;仓库地址：&lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/trae-demo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/trae-demo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;详细的使用方法，可以看仓库的 README.md 文件。&lt;/p&gt;
&lt;p&gt;仓库包含很多递交记录，大部分都是我和 Trae 的对话记录，以及我对 Trae 的一些功能的测试，备注了是否人工干预来实现对应的功能。&lt;/p&gt;
&lt;h2 id=&#34;prompt&#34;&gt;Prompt
&lt;/h2&gt;&lt;p&gt;项目是从零开始创建，下面是项目的 Prompt：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;基于项目原型图，开发功能：自选股，需要支持合约的新增、删除、修改、查询。自选股界面需要展示基础的行情数据。支持多个不同的市场切换。

前端：react
后端：golang gin gorm
数据库：PostgreSQL

服务端需要支持跨域请求，同时需要考虑数据的校验和错误处理，如果后端服务不可用，前端需要告警提示。

后端需要展示请求和应答的日志；前端也打印通讯的日志，方便排查问题。
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;ui和交互优化&#34;&gt;UI和交互优化
&lt;/h2&gt;&lt;p&gt;前端界面的设计完全依赖的 Grok，我们首先在 Trae 里面做出来产物的雏形，但是没有审美，由于使用的模型，代码能力很强，但是其他能力比较弱，所以我们需要使用 Grok 来优化前端的 UI。&lt;/p&gt;
&lt;p&gt;通过将当前的界面截图，上传到 Grok 里面，然后让它帮我们优化 UI，可能一次性拿到很多的优化建议，我们人工评估，然后拷贝到 Trae 中执行，观察优化的效果。&lt;/p&gt;
&lt;h3 id=&#34;技术栈&#34;&gt;技术栈
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;前端：React + TypeScript&lt;/li&gt;
&lt;li&gt;后端：Golang + Gin + GORM&lt;/li&gt;
&lt;li&gt;数据库：PostgreSQL 17&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;系统架构&#34;&gt;系统架构
&lt;/h2&gt;&lt;h2 id=&#34;后端架构&#34;&gt;后端架构
&lt;/h2&gt;&lt;p&gt;后端采用 Golang 的 Gin 框架实现 RESTful API，主要模块包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;数据库模块&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 GORM 作为 ORM 框架&lt;/li&gt;
&lt;li&gt;支持环境变量配置数据库连接&lt;/li&gt;
&lt;li&gt;自动进行数据库表迁移&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;路由模块&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RESTful API 设计&lt;/li&gt;
&lt;li&gt;统一的错误处理机制&lt;/li&gt;
&lt;li&gt;内置请求日志记录&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;跨域处理&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;支持本地开发环境跨域&lt;/li&gt;
&lt;li&gt;可配置的 CORS 策略&lt;/li&gt;
&lt;li&gt;支持 Cookie 跨域&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;前端架构&#34;&gt;前端架构
&lt;/h2&gt;&lt;p&gt;前端使用 React + TypeScript 构建，实现了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;股票列表展示&lt;/li&gt;
&lt;li&gt;自选股管理&lt;/li&gt;
&lt;li&gt;行情数据展示&lt;/li&gt;
&lt;li&gt;错误提示机制&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>AI发展两年：有点类似Docker发布前的状态</title>
        <link>https://ttf248.life/p/ai-development-two-years-docker-pre-release/</link>
        <pubDate>Thu, 20 Feb 2025 18:16:37 +0800</pubDate>
        
        <guid>https://ttf248.life/p/ai-development-two-years-docker-pre-release/</guid>
        <description>&lt;p&gt;人工智能（AI）近年来无疑是技术领域最为热议的话题之一，尤其是在过去的两年里，AI技术得到了飞速的进展。无论是深度学习、自然语言处理，还是计算机视觉、自动化决策系统，AI的应用场景层出不穷。然而，尽管技术不断取得突破，AI仍然面临着一个类似于Docker发布前的瓶颈——缺乏一个杀手级的应用来真正引爆市场。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Prompt: 编写文章：AI发展两年，有点类似 docker 发布前的状态，缺乏一个杀手级应用，基于现有的技术，弄出来一个完美的落地场景，docker 是没用到太多新技术，但是整套方案很合理，改变了运维、开发的工作流程&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;ai发展现状技术已经成熟但应用尚需突破&#34;&gt;AI发展现状：技术已经成熟，但应用尚需突破
&lt;/h2&gt;&lt;p&gt;从技术层面来看，AI在过去的两年里已经取得了相当大的进展。无论是OpenAI推出的GPT系列模型，还是Google的BERT、DeepMind的Alpha系列，AI的处理能力已经远超之前的预期。尤其是自然语言处理领域，GPT-4等模型不仅具备了强大的生成能力，还在理解和推理上展现了令人惊叹的表现。&lt;/p&gt;
&lt;p&gt;然而，尽管技术日新月异，AI在实际应用上的落地却面临一定的挑战。与Docker发布前的状态类似，虽然AI的潜力巨大，但目前尚未出现一个真正能够广泛普及、改变产业的杀手级应用。大家都在谈论AI的前景，却未必能够找到一个可以直接带来革命性改变的应用场景。很多AI应用仍然停留在初步的尝试阶段，且大部分需要进一步的整合与优化。&lt;/p&gt;
&lt;h2 id=&#34;docker与ai的相似性技术不一定是创新方案才是关键&#34;&gt;Docker与AI的相似性：技术不一定是创新，方案才是关键
&lt;/h2&gt;&lt;p&gt;如果回顾Docker发布前的历史，我们不难发现，当时的技术环境和AI的发展现状有诸多相似之处。Docker发布之前，容器技术并不是新鲜事物，早期的LXC（Linux Containers）和虚拟化技术都具备了容器化的基本能力。但Docker通过对现有技术的巧妙整合和优化，提出了一种更简单、直观且高效的方案。这套方案并没有引入颠覆性的技术，但却解决了许多运维和开发过程中的痛点，极大地简化了软件的部署、扩展和管理流程。&lt;/p&gt;
&lt;p&gt;同样，AI领域也面临类似的情形。目前的AI技术虽然已不再是“新鲜事物”，但要想真正实现大规模的应用，仍然需要一个完美的落地场景，像Docker一样，将现有技术融合并优化，形成一个合理的应用方案。AI的杀手级应用，可能并不依赖于全新的技术突破，而是如何通过整合现有的技术，解决实际业务中的痛点和需求。&lt;/p&gt;
&lt;h2 id=&#34;如何找到ai的docker时刻&#34;&gt;如何找到AI的“Docker时刻”？
&lt;/h2&gt;&lt;p&gt;要让AI技术真正得到广泛应用，需要从几个方面着手：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;实际场景的深度挖掘&lt;/strong&gt;&lt;br&gt;
目前，许多AI的应用场景仍然偏向于实验性质，缺乏大规模的实际落地。例如，AI客服、智能推荐等领域虽然应用广泛，但其功能仍有许多局限，尚未能突破行业的瓶颈。真正的突破，可能来自于那些被传统方法困扰已久的行业，比如医疗、制造业、物流等领域，AI可以通过更高效的数据处理、预测分析，帮助企业在这些复杂的场景中提升效率和降低成本。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;产品化与易用性&lt;/strong&gt;&lt;br&gt;
类似于Docker通过简化容器化流程来提升运维的效率，AI产品的易用性同样至关重要。AI的普及不仅仅是技术的普及，更是其产品化的普及。将AI集成到日常工作流中，让用户在不需要深入理解技术的前提下，能够轻松使用这些工具，这是AI落地的重要一步。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;生态建设与标准化&lt;/strong&gt;&lt;br&gt;
任何一项新技术的广泛应用，都离不开生态的建设。Docker之所以能快速崛起，正是因为它的开放性和兼容性，使得开发者能够轻松地与各种云平台、工具和服务对接。同样，AI的未来也依赖于生态系统的建设。AI的标准化、模型的共享、数据的开放，以及技术的可集成性，都将影响AI是否能够形成广泛的行业应用。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;结语ai的未来充满可能性但仍需更完善的落地方案&#34;&gt;结语：AI的未来充满可能性，但仍需更完善的落地方案
&lt;/h2&gt;&lt;p&gt;尽管AI的技术在过去两年里取得了长足的进步，但目前它依然处于“没有杀手级应用”的阶段。与Docker发布前的容器化技术相似，AI需要一个合理的应用场景，将现有的技术与业务需求深度融合，才能真正实现大规模的应用和普及。技术创新固然重要，但能够简化流程、提高效率的解决方案，更能推动技术的普及与发展。&lt;/p&gt;
&lt;p&gt;未来，AI可能会像Docker一样，不是通过颠覆性的技术突破，而是通过整合现有的技术，打造出一个完美的应用场景，最终改变我们工作和生活的方式。&lt;/p&gt;</description>
        </item>
        <item>
        <title>ollama 本地部署 deepseek-R1</title>
        <link>https://ttf248.life/p/ollama-local-deployment-deepseek-r1/</link>
        <pubDate>Fri, 07 Feb 2025 22:41:02 +0800</pubDate>
        
        <guid>https://ttf248.life/p/ollama-local-deployment-deepseek-r1/</guid>
        <description>&lt;p&gt;Ollama 是一个开源的 AI 工具，旨在使用户能够本地运行和部署大型语言模型（LLM）。它的目标是提供一个方便且高效的方式，让开发者可以在本地机器上使用像 GPT 这样的模型，而不需要依赖云端服务。Ollama 支持多种模型，并且专注于优化性能，使得即使是资源有限的设备也能顺畅运行这些模型。&lt;/p&gt;
&lt;p&gt;通过 Ollama，用户可以使用基于文本的 AI 应用程序，并能够与本地部署的模型进行交互，而无需担心数据隐私或是高昂的 API 使用费用。你可以通过命令行界面（CLI）调用不同的模型，进行自然语言处理、问答等任务。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ollama 适合不同模型尝鲜，windows 版本测试下来，无法充分发挥硬件的性能，可能是因为 windows 版本的原因，linux 版本可能会更好。部署32b参数的模型，内存、显卡负载都有不高的情况下，回复速度很慢。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;硬件概述&#34;&gt;硬件概述
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;操作系统：win11&lt;/li&gt;
&lt;li&gt;CPU：i7-10700K&lt;/li&gt;
&lt;li&gt;内存：40GB&lt;/li&gt;
&lt;li&gt;显卡：RTX 3060 12GB&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;环境准备&#34;&gt;环境准备
&lt;/h2&gt;&lt;p&gt;新增系统环境变量，方便后续使用：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_MODELS=E:\ollama&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
这个变量指定了 Ollama 模型的存放路径。&lt;code&gt;E:\ollama&lt;/code&gt; 是一个文件夹路径，表示所有本地模型文件都存储在该目录下。Ollama 会根据这个路径加载和使用你下载或部署的语言模型。你可以将模型文件存放在其他位置，只需要更改这个路径。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_HOST=127.0.0.1:8000&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
这个环境变量设置了 Ollama 服务的主机和端口。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;127.0.0.1&lt;/code&gt; 是本地地址（localhost），意味着 Ollama 服务会只监听来自本机的请求。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;8000&lt;/code&gt; 是指定的端口号，表示 Ollama 服务将在 8000 端口上等待和处理请求。你可以根据需要更改端口号，但需要确保该端口没有被其他应用占用。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_ORIGINS=*&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
这个环境变量控制允许哪些来源的请求访问 Ollama 服务。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;*&lt;/code&gt; 表示允许任何来源（即所有域名和 IP 地址）都可以访问 Ollama 服务。这通常用于开发和调试环境，在生产环境中，通常会指定更严格的来源控制，限制只有特定的域或 IP 才能访问你的服务，以提高安全性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;deepseek-r1-模型部署&#34;&gt;deepseek-R1 模型部署
&lt;/h2&gt;&lt;p&gt;ollama 安装属于傻瓜式，此处不在赘述。&lt;/p&gt;
&lt;p&gt;安装后的校验：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core&amp;gt;ollama -v
ollama version is 0.5.11
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;模型部署，参考官网模型页面，选择对应参数的模型：&lt;code&gt;ollama run deepseek-r1:14b&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;14b 参数能有效的记住会话上下文，更小的参数版本，无法记住会话上下文。32b 参数版本，本机部署很卡顿，没有再深入进行测试。&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ollama.com/library/deepseek-r1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.ollama.com/library/deepseek-r1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/x18990027/article/details/145368094&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/x18990027/article/details/145368094&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>DeepSeek 春节前突然爆火，英伟达股票暴跌：背后的机构操作与大模型思维链</title>
        <link>https://ttf248.life/p/deepseek-chinese-new-year-nvidia-stock-drop-institutional-operations-large-language-model-chain/</link>
        <pubDate>Fri, 07 Feb 2025 20:36:05 +0800</pubDate>
        
        <guid>https://ttf248.life/p/deepseek-chinese-new-year-nvidia-stock-drop-institutional-operations-large-language-model-chain/</guid>
        <description>&lt;p&gt;春节前夕，DeepSeek 一度成为热议话题，短短几天内便在社交媒体上引起了广泛关注。这种突然的爆火，不仅让人惊讶，还带动了市场的连锁反应。与此同时，英伟达的股票却迎来了暴跌，许多投资者对其前景产生了疑虑，部分机构在此期间进行了大规模的做空操作，似乎一切都指向了一个“精心策划”的局面。&lt;/p&gt;
&lt;h3 id=&#34;deepseek-的爆火短时间内迅速成为焦点&#34;&gt;&lt;strong&gt;DeepSeek 的爆火：短时间内迅速成为焦点&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;DeepSeek 是一个基于 AI 的工具，专注于对深度学习模型的优化，尤其是在自然语言处理（NLP）和图像生成领域的应用。春节前的几天，这个项目突然间受到大量投资者和技术从业者的关注。其背后团队的表现以及所展示的技术成果，让许多人对这个项目产生了强烈的兴趣。无论是在开发者社区，还是社交媒体平台上，关于 DeepSeek 的讨论几乎占据了技术圈的所有话题。&lt;/p&gt;
&lt;p&gt;然而，DeepSeek 的突然爆火并非偶然。经过分析，很多人开始怀疑这背后可能涉及到了某些机构的操作。尤其是在其爆火之后，英伟达股价出现了明显的下跌，显然有一些因素在推动着这一变化。&lt;/p&gt;
&lt;h3 id=&#34;英伟达股票暴跌做空操作的幕后推手&#34;&gt;&lt;strong&gt;英伟达股票暴跌：做空操作的幕后推手&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;英伟达，这家全球领先的图形处理单元（GPU）制造商，一直以来是许多大模型和 AI 计算的关键硬件提供商。随着 AI 市场的快速发展，英伟达的股票长期以来表现强劲，甚至成为了许多投资者青睐的对象。然而，随着 DeepSeek 的爆火和市场对其技术的高度关注，英伟达股票却迎来了暴跌。&lt;/p&gt;
&lt;p&gt;这一现象的背后，或许涉及到了机构投资者的做空策略。在过去几年中，随着 AI 技术的普及，英伟达的股价已被高度推高，很多投资者开始认为其股价存在过度炒作的风险。尤其是在 DeepSeek 这样的技术爆火之后，一些机构可能通过做空英伟达的股票，获得了可观的利润。通过精确的市场时机把握和对 DeepSeek 影响力的预判，这些机构成功地从中获利。&lt;/p&gt;
&lt;h3 id=&#34;大模型思维链的接触从结果到过程&#34;&gt;&lt;strong&gt;大模型思维链的接触：从“结果”到“过程”&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;在传统的人工智能应用中，许多从业者和投资者更多关注的是 AI 模型的“结果”——例如生成的图片、文本等直接的产出。而在与 DeepSeek 相关的讨论中，越来越多的人开始意识到，大模型背后所隐藏的思维链才是更值得关注的核心内容。过去，我们只能看到模型输出的结果，但现在，我们更需要去理解其背后的逻辑、算法以及如何通过调整这些因素来优化模型的表现。&lt;/p&gt;
&lt;p&gt;这种思维方式的转变，实际上是对 AI 研究和应用的一种深入思考。从简单的黑箱操作，到真正理解模型内部运作机制的转变，让许多技术人员和投资者都开始重新审视人工智能的未来发展方向。DeepSeek 的火爆，恰恰是这一思维链的突破性应用，它让人们开始关注整个模型的构建和优化过程，而不仅仅是最终的输出结果。&lt;/p&gt;
&lt;h3 id=&#34;总结&#34;&gt;&lt;strong&gt;总结&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;DeepSeek 的突然爆火，英伟达股票的暴跌，以及市场背后机构的做空操作，这一切背后似乎都是一个精心设计的局。通过对大模型思维链的深入理解，我们可以看到，AI 技术的应用不仅仅是表面现象的堆砌，更是对模型内部逻辑的深入挖掘和优化。随着技术的进步，未来我们或许将看到更多类似 DeepSeek 这样的创新工具，推动 AI 研究和应用向更高层次发展。&lt;/p&gt;
&lt;p&gt;这种现象不仅让我们看到了 AI 技术的巨大潜力，也促使我们开始思考技术背后的商业博弈和资本运作。接下来的市场走势如何，将会是技术与资本博弈的持续焦点。&lt;/p&gt;</description>
        </item>
        <item>
        <title>Cursor AI 编程 IDE 试用</title>
        <link>https://ttf248.life/p/cursor-ai-programming-ide-trial/</link>
        <pubDate>Thu, 23 Jan 2025 19:30:13 +0800</pubDate>
        
        <guid>https://ttf248.life/p/cursor-ai-programming-ide-trial/</guid>
        <description>&lt;p&gt;转眼又是一年过去了，工作上的最大的变动，还是AI参与度明显提高了，相当以往来说，不同的开发语言之间切换，需要开发者熟悉的各种语言不同的 api 接口，现在这些基础代码都可以通过 AI 生成代码了，对于开发者来说，就是一个很大的福音。&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;早在 23 年的时候，整过两篇简单的入门介绍，转眼已经到了 25 年，怎么说呢，并没有感知到显著的进步，还是需要开发有自己的认知，能合理的拆分任务，当然，最重要的是识别 AI 生成的代码是否存在 bug。&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;Github copilot
&lt;/h2&gt;&lt;p&gt;忘记是是哪天了，看到资料说新加坡部署了服务器，国内使用，再也不用长期挂梯子，当然，登录的时候，还是需要挂个梯子，不过这个梯子只需要登录的时候用一下，之后就可以关闭了。&lt;/p&gt;
&lt;p&gt;日常用的更多的也是 Github copilot，这个插件，可以直接在 vscode、visual studio 中直接使用。不用两个软件之间切换。相对于 ChatGPT，Github copilot 对于项目的支持更好，交互上更友好，能你能选择部分本地的文件投喂，&lt;strong&gt;“训练”AI&lt;/strong&gt;，这样生成的代码更符合你的项目。&lt;/p&gt;
&lt;h2 id=&#34;cursor-ai&#34;&gt;Cursor AI
&lt;/h2&gt;&lt;p&gt;最近看到了一个新的 AI 编程 IDE，Cursor AI，这个 IDE 也是基于 Github copilot 的，不过这个 IDE 更加的智能，可以帮你直接创建文件。&lt;/p&gt;
&lt;p&gt;简单的用了一下，感觉还是不错的，不过对于现有项目的理解还是不够，本地项目文件多的时候，大的重构优化调整，还是需要&lt;strong&gt;开发者拆分任务&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;附上一个例子：切换到 curso 的工程模式，输入内容：新建个人简历网页，支持多个不同风格切换，记得填充一些个人信息用于数据展示。&lt;/p&gt;
&lt;p&gt;经过几次来回的&lt;strong&gt;拉扯&lt;/strong&gt;，你就能拿到如下的网页，当然，这个网页还是比较简单的，不过对于新手来说，还是很不错的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;目前注册用户能免费试用 150 次高级 api，付费用户限制 5000 次高级 api&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://ttf248.life/cursor/index.html&#34; &gt;个人简历&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>AI编程和任务拆解</title>
        <link>https://ttf248.life/p/ai-programming-and-task-decomposition/</link>
        <pubDate>Fri, 22 Dec 2023 08:44:26 +0800</pubDate>
        
        <guid>https://ttf248.life/p/ai-programming-and-task-decomposition/</guid>
        <description>&lt;p&gt;两年前给站点添加代码区域的拷贝功能，前后折腾了小半天，最终渲染效果有点不如意，作为半吊子前端开发，也没想着改进，能用就行，今年用&lt;code&gt;AI&lt;/code&gt;开发了小程序，对于前端的开发也更加熟悉了，重构一波（AI重新设计）。&lt;/p&gt;
&lt;p&gt;悟道：任务拆解开，很多小任务，&lt;code&gt;AI&lt;/code&gt;开发起来还是顺手的。已经倒闭的小程序，&lt;code&gt;75%&lt;/code&gt;代码由&lt;code&gt;AI&lt;/code&gt;提供，拆解了多个任务交付，人工进行项目代码的&lt;code&gt;组装&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&#34;前文&#34;&gt;前文
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://ttf248.github.io/post/2022/001-%E4%BB%A5%E4%B8%BA%E5%BE%88%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%8B%E6%83%85%E5%A2%9E%E5%8A%A0%E4%B8%80%E4%B8%AA%E4%BB%A3%E7%A0%81%E5%A4%8D%E5%88%B6%E6%8C%89%E9%92%AE/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;以为很简单的事情，增加一个代码复制按钮&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;promot&lt;/strong&gt;: 设计 css 和 JavaScript 代码，定位网页元素 class=&amp;ldquo;highlight&amp;rdquo;，这个元素的容器内，添加一个 复制按钮，实现复制代码的功能&lt;/p&gt;
&lt;p&gt;给的第一稿代码一眼看上去就有问题，重新生成一稿，基本可用，复制的内容不对，有冗余的文字，再次引导优化，人工指定核心的颜色设计，包含哪些特效&lt;/p&gt;
&lt;p&gt;了解到您对按钮的尺寸和颜色有特定的要求，我们可以重新设计按钮的样式以适应这些要求。以下是一个调整后的 CSS 样式，其中包括了您提供的颜色方案，并对按钮的尺寸进行了优化：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.copy-btn {
  position: absolute;
  top: 2px; /* 调整位置 */
  right: 2px;
  padding: 3px 6px; /* 缩小尺寸 */
  font-size: 12px; /* 减小字体大小 */
  background-color: #8FD1E1; /* 按钮背景色 */
  color: #272822; /* 文字颜色 */
  border: 1px solid #272822; /* 边框颜色 */
  border-radius: 3px; /* 圆角 */
  cursor: pointer;
  opacity: 0.7; /* 默认半透明 */
  transition: opacity 0.3s ease, background-color 0.3s ease; /* 平滑过渡效果 */
}

.copy-btn:hover {
  opacity: 1; /* 鼠标悬停时不透明 */
  background-color: #A3D4E5; /* 鼠标悬停时的背景色 */
}

.highlight {
  position: relative;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在这个样式中，我减小了按钮的尺寸和字体大小，使其更加精致。同时，按钮的默认状态是半透明的，当鼠标悬停在按钮上时，它会变为不透明，并且背景色会变得稍微亮一些，以提供视觉反馈。这样的设计既符合您的颜色要求，又保持了现代化和用户友好的特点。&lt;/p&gt;
&lt;p&gt;对应的提供了一份更简单的 &lt;code&gt;JavaScript&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-JavaScript&#34;&gt;document.addEventListener(&#39;DOMContentLoaded&#39;, function() {
  // 查找所有 .highlight 元素
  const highlights = document.querySelectorAll(&#39;.highlight&#39;);

  highlights.forEach(function(highlight) {
    // 创建复制按钮
    const copyBtn = document.createElement(&#39;button&#39;);
    copyBtn.textContent = &#39;复制&#39;;
    copyBtn.classList.add(&#39;copy-btn&#39;);

    // 将按钮添加到每个 .highlight 元素中
    highlight.appendChild(copyBtn);

    // 添加点击事件监听器
    copyBtn.addEventListener(&#39;click&#39;, function() {
      // 假设 .highlight 下的第一个 &amp;lt;code&amp;gt; 元素包含要复制的代码
      const code = highlight.querySelector(&#39;code&#39;) ? highlight.querySelector(&#39;code&#39;).textContent : &#39;&#39;;

      navigator.clipboard.writeText(code).then(() =&amp;gt; {
        // 显示复制成功信息
        copyBtn.textContent = &#39;已复制!&#39;;
        setTimeout(() =&amp;gt; {
          copyBtn.textContent = &#39;复制&#39;;
        }, 2000);
      }).catch(err =&amp;gt; {
        console.error(&#39;复制失败: &#39;, err);
      });
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;后记&#34;&gt;后记
&lt;/h2&gt;&lt;p&gt;虽说我更期望在代码区域的右上角，顶部区域新增复制按钮，由于对前端不够了解，无法基于关键词准确描述功能，和&lt;code&gt;AI&lt;/code&gt;来回折腾几个回合也没有达到预期。&lt;/p&gt;
&lt;p&gt;就是不知道随着时间的发展，&lt;code&gt;AI&lt;/code&gt;对于程序开发会有多大的影响。&lt;/p&gt;</description>
        </item>
        <item>
        <title>Prompt 工程师</title>
        <link>https://ttf248.life/p/prompt-engineer/</link>
        <pubDate>Sun, 26 Mar 2023 20:46:53 +0800</pubDate>
        
        <guid>https://ttf248.life/p/prompt-engineer/</guid>
        <description>&lt;p&gt;就如当年学习搜索引擎的技巧，我们也需要学习一些和&lt;code&gt;AI&lt;/code&gt;沟通的技巧，给出合理且充分的限定条件，高效的获取需要的答案。&lt;/p&gt;
&lt;p&gt;如果你换个角度呢，当前的&lt;code&gt;AI&lt;/code&gt;属于一个记忆力很好的小孩子，它拥有过目不忘的能力，有抄作业的能力。我们需要做的是学会如何正确、有效的和&lt;code&gt;AI&lt;/code&gt;沟通，精准的描述需求，帮助&lt;code&gt;AI&lt;/code&gt;生成预期的结果。&lt;/p&gt;
&lt;h2 id=&#34;科普&#34;&gt;科普
&lt;/h2&gt;&lt;p&gt;火出天际的&lt;code&gt;AI&lt;/code&gt;确切的说&lt;code&gt;Generative Pre-Training&lt;/code&gt;，直译过来就是生成式的预训练。它是一种基于互联网可用数据训练的文本生成深度学习模型，用于问答、文本摘要生成、机器翻译、分类、代码生成和对话 AI 等任务。目前已经有 GPT-1、GPT-2、GPT-3 和 GPT-4 等不同版本的模型，每个版本都比前一个版本更大、更强大。&lt;/p&gt;
&lt;h2 id=&#34;到底有没有智能&#34;&gt;到底有没有智能
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;相似度足够高，准确率也就越高&lt;/li&gt;
&lt;li&gt;基础的、重复性的工作，进过特定训练，不再需要人工的介入&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;生成式AI是一种利用现有的文本、音频、图像等数据来创建新内容的技术。它可以用于文本生成、语音合成、图像生成、对话系统等多种任务。生成式AI的逻辑性取决于它的训练数据和模型结构。一般来说，生成式AI可以在一定程度上遵循语法、逻辑和常识，但也可能出现错误、偏差或不真实的内容。因此，生成式AI的输出需要人类的判断和验证，不能盲目相信或使用。&lt;/p&gt;
&lt;h2 id=&#34;prompt-工程师&#34;&gt;Prompt 工程师
&lt;/h2&gt;&lt;p&gt;时间河流不会逆流，人需要学会适应潮流。你可以认为&lt;code&gt;AI&lt;/code&gt;不智能，没有逻辑性，它经常写出来不能用的代码。&lt;/p&gt;
&lt;p&gt;如果你换个角度呢，当前的&lt;code&gt;AI&lt;/code&gt;属于一个记忆力很好的小孩子，它拥有过目不忘的能力，有抄作业的能力。我们需要做的是学会如何正确、有效的和&lt;code&gt;AI&lt;/code&gt;沟通，精准的描述需求，帮助&lt;code&gt;AI&lt;/code&gt;生成预期的结果。&lt;/p&gt;
&lt;h2 id=&#34;对话模式&#34;&gt;对话模式
&lt;/h2&gt;&lt;p&gt;两年前&lt;code&gt;Github Copilot&lt;/code&gt;发布，谁也想不到两年后，&lt;code&gt;OpenAI&lt;/code&gt;横空出世，让人类认知到了大语言模型的能力。&lt;/p&gt;
&lt;p&gt;基于&lt;strong&gt;基于注释的编程&lt;/strong&gt;和&lt;strong&gt;基于对话的编程&lt;/strong&gt;，交互逻辑上完全不同，对话的模式，小白用户的交互体验友好，此处必须提到&lt;code&gt;NewBing&lt;/code&gt;在每个问题之后，给出的追问提示，微软在尝试引导用户，获取&lt;code&gt;AI&lt;/code&gt;知识库里面，更多的内容。&lt;/p&gt;
&lt;h2 id=&#34;举个栗子&#34;&gt;举个栗子
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;场景&lt;/strong&gt;：高铁旅途时间漫漫，编码是个不错的选择。流量有限的情况下，处理几个图片，获取了图片素材，下载软件处理图片稍微有点奢侈，网络条件也不允许。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;需求&lt;/strong&gt;：有一批图片素材，带透明背景图，用来作为小程序的导航栏，选中的状态是彩色的，没选中的状态是黑白的，素材都是彩色的，需要预处理一下。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Prompt&lt;/strong&gt;：编写一段 python 代码，从一个文件夹中读取所有的图片，将图片转换成黑白，维持透明背景，保存图片的时候，优化图片的质量，减少文件体积，同时在控制台展示，优化前后的文件体积大小对比&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 导入必要的库
import os
import PIL
from PIL import Image

# 定义一个函数，将图片转换成黑白，维持透明背景，保存图片，并返回文件体积
def convert_and_save(image_file):
    # 打开图片
    image = Image.open(image_file)
    # 获取图片的模式，如果是 RGBA 模式，说明有透明背景
    mode = image.mode
    if mode == &amp;quot;RGBA&amp;quot;:
        # 创建一个和图片大小一致的白色背景图片
        background = Image.new(&amp;quot;RGB&amp;quot;, image.size, (255, 255, 255))
        # 将原图片粘贴到白色背景上，忽略透明像素
        background.paste(image, mask=image.split()[3])
        # 将合成的图片转换成灰度模式
        gray_image = background.convert(&amp;quot;L&amp;quot;)
        # 将灰度图片再转换成 RGBA 模式，以便保留透明背景
        final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
    else:
        # 如果不是 RGBA 模式，直接将图片转换成灰度模式
        final_image = image.convert(&amp;quot;L&amp;quot;)
    # 获取原图片的文件名和扩展名
    file_name, file_ext = os.path.splitext(image_file)
    # 定义新图片的文件名，添加 _bw 后缀表示黑白
    new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # 保存新图片，并优化质量，减少文件体积
    final_image.save(new_file_name, optimize=True)
    # 获取原图片和新图片的文件体积，并返回
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return old_size, new_size

# 定义一个文件夹路径，存放所有的图片
folder_path = &amp;quot;images&amp;quot;
# 遍历文件夹中的所有文件
for file in os.listdir(folder_path):
    # 拼接完整的文件路径
    file_path = os.path.join(folder_path, file)
    # 判断是否是图片文件，根据扩展名判断，可以根据需要添加或修改扩展名
    if file_path.endswith((&amp;quot;.png&amp;quot;, &amp;quot;.jpg&amp;quot;, &amp;quot;.jpeg&amp;quot;, &amp;quot;.gif&amp;quot;)):
        # 调用函数，转换并保存图片，并获取文件体积
        old_size, new_size = convert_and_save(file_path)
        # 在控制台展示优化前后的文件体积大小对比
        print(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;AI&lt;/code&gt;迅速给出了答案，看着很漂亮，用起来也没问题，经验丰富的程序源，会觉得下面的代码不够通用，也没法上生产环境：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;参数固定了&lt;/li&gt;
&lt;li&gt;没有日志文件，信息都打印在控制台&lt;/li&gt;
&lt;li&gt;图片处理的任务，适合多线程模型&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;NewBing&lt;/code&gt;登场，依据提示，选择了一个问题：&lt;strong&gt;这段代码有什么可以改进的地方吗&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这次给的答案，实话，完全超出了预期，一般程序员能想到的优化措施，&lt;code&gt;AI&lt;/code&gt;都给出对应的建议&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;这段代码可能还有一些可以改进的地方，比如：

可以使用 argparse 库，让用户可以通过命令行参数指定文件夹路径和扩展名，而不是写死在代码里。
可以使用 logging 库，记录程序的运行情况，而不是直接打印到控制台。
可以使用 try-except 语句，捕获可能出现的异常，比如文件打开失败，图片转换失败等，并做相应的处理。
可以使用 multiprocessing 库，利用多核处理器，加速图片的转换和保存过程。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;很友好的应答，考虑到部署的环境存在差异，允许不支持多进程&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;当然，我很乐意帮你修改一下代码。我尝试添加了 argparse, logging 和 try-except 语句，但没有添加 multiprocessing 库，因为我不确定你的电脑是否支持多核处理。修改后的代码如下：
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 导入必要的库
import argparse
import logging
import multiprocessing
import os

from PIL import Image


# 定义一个函数，将图片转换成黑白，维持透明背景，保存图片，并返回文件体积
def convert_and_save(image_file):
    # 打开图片
    try:
        image = Image.open(image_file)
    except Exception as e:
        logging.error(f&amp;quot;Failed to open {image_file}: {e}&amp;quot;)
        return None, None
    # 获取图片的模式，如果是 RGBA 模式，说明有透明背景
    mode = image.mode
    if mode == &amp;quot;RGBA&amp;quot;:
        # 创建一个和图片大小一致的白色背景图片
        background = Image.new(&amp;quot;RGB&amp;quot;, image.size, (255, 255, 255))
        # 将原图片粘贴到白色背景上，忽略透明像素
        background.paste(image, mask=image.split()[3])
        # 将合成的图片转换成灰度模式
        gray_image = background.convert(&amp;quot;L&amp;quot;)
        # 将灰度图片再转换成 RGBA 模式，以便保留透明背景
        final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
    else:
        # 如果不是 RGBA 模式，直接将图片转换成灰度模式
        final_image = image.convert(&amp;quot;L&amp;quot;)
    # 获取原图片的文件名和扩展名
    file_name, file_ext = os.path.splitext(image_file)
    # 定义新图片的文件名，添加 _bw 后缀表示黑白
    new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # 保存新图片，并优化质量，减少文件体积
    try:
        final_image.save(new_file_name, optimize=True)
    except Exception as e:
        logging.error(f&amp;quot;Failed to save {new_file_name}: {e}&amp;quot;)
        return None, None
    # 获取原图片和新图片的文件体积，并返回
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return file_name, old_size, new_size

# 定义一个函数，解析命令行参数，并返回文件夹路径和扩展名列表
def parse_args():
    # 创建一个解析器对象
    parser = argparse.ArgumentParser(description=&amp;quot;Convert images to black and white and optimize quality.&amp;quot;)
    # 添加一个必选的位置参数，表示文件夹路径
    parser.add_argument(&amp;quot;folder_path&amp;quot;, help=&amp;quot;The path of the folder that contains the images.&amp;quot;)
    # 添加一个可选的参数，表示扩展名列表，默认为 png, jpg, jpeg 和 gif
    parser.add_argument(&amp;quot;-e&amp;quot;, &amp;quot;--extensions&amp;quot;, nargs=&amp;quot;+&amp;quot;, default=[&amp;quot;.png&amp;quot;, &amp;quot;.jpg&amp;quot;, &amp;quot;.jpeg&amp;quot;, &amp;quot;.gif&amp;quot;], help=&amp;quot;The extensions of the image files.&amp;quot;)
    # 解析命令行参数，并返回结果对象
    args = parser.parse_args()
    return args.folder_path, args.extensions

# 定义一个函数，打印优化前后的文件体积大小对比
def print_result(result):
    # 如果结果不为空，说明转换和保存成功
    if result:
        # 解包结果为文件名和文件体积元组
        if len(result) == 3:
            file, old_size, new_size = result
            # 在控制台展示优化前后的文件体积大小对比
            logging.info(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)
        else:
            logging.info(f&amp;quot;{result}&amp;quot;)

# 配置日志记录器，将日志输出到控制台和文件中，设置日志等级为 INFO
logging.basicConfig(level=logging.INFO,
                    format=&amp;quot;%(asctime)s %(levelname)s %(message)s&amp;quot;,
                    handlers=[logging.StreamHandler(),
                              logging.FileHandler(&amp;quot;log.txt&amp;quot;)])

# 调用函数，获取文件夹路径和扩展名列表
folder_path, extensions = parse_args()

if __name__ == &amp;quot;__main__&amp;quot;:
    # Windows 需要这个函数的原因是 Windows 缺乏 fork() 函数（这不完全正确）。
    # 因此，在 Windows 上，fork() 是通过创建一个新的进程来模拟的，这个新的进程中运行的代码，在 Linux 上是在子进程中运行的。
    # 由于这些代码要在技术上无关的进程中运行，所以它必须在运行之前被传递到那里。
    # 传递的方式是先将它们序列化，然后通过管道从原始进程发送到新的进程。
    # 另外，这个新的进程被通知它必须运行通过管道传递的代码，通过向它传递 --multiprocessing-fork 命令行参数。
    # 如果你看一下 freeze_support() 函数的实现，它的任务是检查它运行在哪个进程中，是否应该运行通过管道传递的代码
    multiprocessing.freeze_support()

    # 创建一个进程池，根据电脑的核心数自动分配进程
    pool = multiprocessing.Pool()
    # 创建一个空列表，用于存放异步任务的结果对象
    results = []
    # 遍历文件夹中的所有文件
    for file in os.listdir(folder_path):
        # 拼接完整的文件路径
        file_path = os.path.join(folder_path, file)
        # 判断是否是图片文件，根据扩展名判断，可以根据需要修改扩展名列表
        if any(file_path.endswith(ext) for ext in extensions):
            # 调用函数，转换并保存图片，并获取文件体积，使用异步方式，不阻塞主进程
            result = pool.apply_async(convert_and_save, args=(file_path,), callback=print_result)
            # 将结果对象添加到列表中
            results.append((file, result))
    # 关闭进程池，不再接受新的任务
    pool.close()
    # 等待所有的任务完成
    pool.join()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;后记&#34;&gt;后记
&lt;/h2&gt;&lt;p&gt;由于本地开发是&lt;code&gt;windows&lt;/code&gt;系统，&lt;code&gt;AI&lt;/code&gt;第一次给出的答案，并没有加上&lt;code&gt;main&lt;/code&gt;函数，也没有&lt;code&gt;multiprocessing.freeze_support&lt;/code&gt;。通过追问发生的报错，修复了代码。&lt;/p&gt;
&lt;p&gt;就如当年学习搜索引擎的技巧，我们也需要学习一些和&lt;code&gt;AI&lt;/code&gt;沟通的技巧，给出合理且充分的限定条件，高效的获取需要的答案。&lt;/p&gt;
&lt;p&gt;注意：&lt;strong&gt;如果你是个编程新手，基于给出的注释，还有看不懂的地方，可以继续追问相关代码&lt;/strong&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>AI辅助编程，生产力的进化</title>
        <link>https://ttf248.life/p/ai-assisted-programming-productivity-evolution/</link>
        <pubDate>Tue, 28 Feb 2023 17:05:17 +0800</pubDate>
        
        <guid>https://ttf248.life/p/ai-assisted-programming-productivity-evolution/</guid>
        <description>&lt;p&gt;&lt;code&gt;GitHub Copilot&lt;/code&gt; 发布也不到两年时间，&lt;code&gt;ChatGPT&lt;/code&gt; 问世了，不是很懂背后的原理，都用了一段时间。两个工具的辅助层面完全不同，但是都做到了大幅提高生产力。&lt;/p&gt;
&lt;p&gt;太复杂的事情，&lt;code&gt;AI&lt;/code&gt;还做不到，毕竟他们没有逻辑，有套路的或者说范式固定的事情，训练的语料足够，&lt;code&gt;AI&lt;/code&gt;的效果能打个九分。&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;github copilot
&lt;/h2&gt;&lt;p&gt;发布的时候，看着官网的介绍&lt;code&gt;demo&lt;/code&gt;，不是很智能，试用了一下，不是很好用，放弃了。&lt;/p&gt;
&lt;p&gt;2022年前，闲来无事，切换到新版本体验一下，效果已经不错了，就是国内的速度有点慢，大概率是网络的原因。&lt;code&gt;Python&lt;/code&gt;之类的语言，依据注释写出来的代码都还不错，比我自己查资料然后编写的速度快了很多。&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;Github Copilot&lt;/code&gt;还停留在程序员，也就是开发的角度来设计产品，你需要懂的如何编程，慢慢的通过注释来引导AI辅助编程。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ChatGPT&lt;/code&gt; 走到了下一个层面，&lt;strong&gt;让外行人也能迅速上手&lt;/strong&gt;。对话聊天交互式的设计，你完全可以提出问题，描述需求，不懂的地方，继续提问。&lt;/p&gt;
&lt;p&gt;简单来个例子，知道分词的概念，但是不知道如何编码，想要计算字符串的相似度：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Python 分词计算 維天運通 LOGORY 和 合肥維天運通信息科技股份有限公司 两个字符串的相似度；
比较前，统一处理字符串，英文转换为小写；
第二个字符中如果能找到第一个字符的首字符，将第二个字符串截位，截位的长度为第一个字符串的长度
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;你好，这是Bing。😊&lt;/p&gt;
&lt;p&gt;根据网上的信息123，Python 分词计算可以使用 jieba 库来实现。jieba 库支持三种分词模式：精确模式、全模式和搜索引擎模式。你可以根据你的需求选择合适的模式。&lt;/p&gt;
&lt;p&gt;为了比较两个字符串的相似度，你需要先对它们进行分词，然后计算它们的词向量或者编辑距离等指标。你可以使用 numpy 或者 scipy 等库来进行数学运算。&lt;/p&gt;
&lt;p&gt;为了统一处理字符串，英文转换为小写，你可以使用 Python 的内置函数 lower() 来实现。&lt;/p&gt;
&lt;p&gt;为了截取第二个字符串，你可以使用 Python 的切片操作符 [ ] 来实现。&lt;/p&gt;
&lt;p&gt;以下是一个可能的代码示例：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import jieba
import numpy as np
from scipy.spatial.distance import cosine

# 定义两个字符串
str1 = &amp;quot;維天運通 LOGORY&amp;quot;
str2 = &amp;quot;合肥維天運通信息科技股份有限公司&amp;quot;

# 统一处理字符串，英文转换为小写
str1 = str1.lower()
str2 = str2.lower()

# 找到第二个字符串中第一个字符的位置
index = str2.find(str1[0])

# 如果找到了，截取第二个字符串
if index != -1:
    str2 = str2[index:index+len(str1)]

# 使用 jieba 库进行分词
words1 = list(jieba.cut(str1))
words2 = list(jieba.cut(str2))

# 计算两个字符串的词向量（以词频作为权重）
vector1 = np.zeros(len(words1))
vector2 = np.zeros(len(words1))

for i, word in enumerate(words1):
    vector1[i] += 1 # 统计第一个字符串中每个词出现的次数
    if word in words2:
        vector2[i] += 1 # 统计第二个字符串中每个词出现的次数

# 计算两个字符串的相似度（以余弦距离作为指标）
similarity = 1 - cosine(vector1, vector2)

print(&amp;quot;两个字符串的相似度是：&amp;quot;, similarity)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;更进一步，咨询运行的结果，恭喜你，发现问题了，结果是瞎编的，它并没有实际运行代码，但是会给你一个不错的结果&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;栗子&#34;&gt;栗子
&lt;/h3&gt;&lt;p&gt;提问：sql 语句，查出产品代码表中，产品代码在这个区间 80000-89999 的记录&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;你好，这是 Bing。😊

根据搜索结果12，你可以使用 SQL BETWEEN 运算符来选择给定区间内的值。BETWEEN 运算符包含了开始和结束的值。

你需要先指定要查询的表名和列名，然后在 WHERE 子句中使用 BETWEEN 运算符和区间值。

例如，如果你要查询产品代码表中，产品代码在 80000 到 89999 之间的记录，你可以使用以下语句：

SELECT * FROM product_code
WHERE code BETWEEN 80000 AND 89999;
这里，* 表示选择所有列3。如果你只想选择特定的列，比如产品名称和价格，你可以用逗号分隔它们，如下：

SELECT name, price FROM product_code
WHERE code BETWEEN 80000 AND 89999;
希望这能帮助到你。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;继续提问，否定它：产品代码是字符串，你的代码错了&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;抱歉，我没有注意到产品代码是字符串。如果是这样的话，你需要在区间值两边加上单引号，如下：

SELECT * FROM product_code
WHERE code BETWEEN &#39;80000&#39; AND &#39;89999&#39;;
请原谅我的错误。🙏
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;恭喜你，它会认错的。&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

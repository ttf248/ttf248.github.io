<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Ai on 向叔记事簿</title>
        <link>https://ttf248.life/tags/ai/</link>
        <description>Recent content in Ai on 向叔记事簿</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <lastBuildDate>Thu, 20 Feb 2025 19:25:41 +0800</lastBuildDate><atom:link href="https://ttf248.life/tags/ai/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>AI发展两年：有点类似Docker发布前的状态</title>
        <link>https://ttf248.life/p/ai%E5%8F%91%E5%B1%95%E4%B8%A4%E5%B9%B4%E6%9C%89%E7%82%B9%E7%B1%BB%E4%BC%BCdocker%E5%8F%91%E5%B8%83%E5%89%8D%E7%9A%84%E7%8A%B6%E6%80%81/</link>
        <pubDate>Thu, 20 Feb 2025 18:16:37 +0800</pubDate>
        
        <guid>https://ttf248.life/p/ai%E5%8F%91%E5%B1%95%E4%B8%A4%E5%B9%B4%E6%9C%89%E7%82%B9%E7%B1%BB%E4%BC%BCdocker%E5%8F%91%E5%B8%83%E5%89%8D%E7%9A%84%E7%8A%B6%E6%80%81/</guid>
        <description>&lt;p&gt;人工智能（AI）近年来无疑是技术领域最为热议的话题之一，尤其是在过去的两年里，AI技术得到了飞速的进展。无论是深度学习、自然语言处理，还是计算机视觉、自动化决策系统，AI的应用场景层出不穷。然而，尽管技术不断取得突破，AI仍然面临着一个类似于Docker发布前的瓶颈——缺乏一个杀手级的应用来真正引爆市场。&lt;/p&gt;
&lt;h2 id=&#34;ai发展现状技术已经成熟但应用尚需突破&#34;&gt;AI发展现状：技术已经成熟，但应用尚需突破
&lt;/h2&gt;&lt;p&gt;从技术层面来看，AI在过去的两年里已经取得了相当大的进展。无论是OpenAI推出的GPT系列模型，还是Google的BERT、DeepMind的Alpha系列，AI的处理能力已经远超之前的预期。尤其是自然语言处理领域，GPT-4等模型不仅具备了强大的生成能力，还在理解和推理上展现了令人惊叹的表现。&lt;/p&gt;
&lt;p&gt;然而，尽管技术日新月异，AI在实际应用上的落地却面临一定的挑战。与Docker发布前的状态类似，虽然AI的潜力巨大，但目前尚未出现一个真正能够广泛普及、改变产业的杀手级应用。大家都在谈论AI的前景，却未必能够找到一个可以直接带来革命性改变的应用场景。很多AI应用仍然停留在初步的尝试阶段，且大部分需要进一步的整合与优化。&lt;/p&gt;
&lt;h2 id=&#34;docker与ai的相似性技术不一定是创新方案才是关键&#34;&gt;Docker与AI的相似性：技术不一定是创新，方案才是关键
&lt;/h2&gt;&lt;p&gt;如果回顾Docker发布前的历史，我们不难发现，当时的技术环境和AI的发展现状有诸多相似之处。Docker发布之前，容器技术并不是新鲜事物，早期的LXC（Linux Containers）和虚拟化技术都具备了容器化的基本能力。但Docker通过对现有技术的巧妙整合和优化，提出了一种更简单、直观且高效的方案。这套方案并没有引入颠覆性的技术，但却解决了许多运维和开发过程中的痛点，极大地简化了软件的部署、扩展和管理流程。&lt;/p&gt;
&lt;p&gt;同样，AI领域也面临类似的情形。目前的AI技术虽然已不再是“新鲜事物”，但要想真正实现大规模的应用，仍然需要一个完美的落地场景，像Docker一样，将现有技术融合并优化，形成一个合理的应用方案。AI的杀手级应用，可能并不依赖于全新的技术突破，而是如何通过整合现有的技术，解决实际业务中的痛点和需求。&lt;/p&gt;
&lt;h2 id=&#34;如何找到ai的docker时刻&#34;&gt;如何找到AI的“Docker时刻”？
&lt;/h2&gt;&lt;p&gt;要让AI技术真正得到广泛应用，需要从几个方面着手：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;实际场景的深度挖掘&lt;/strong&gt;&lt;br&gt;
目前，许多AI的应用场景仍然偏向于实验性质，缺乏大规模的实际落地。例如，AI客服、智能推荐等领域虽然应用广泛，但其功能仍有许多局限，尚未能突破行业的瓶颈。真正的突破，可能来自于那些被传统方法困扰已久的行业，比如医疗、制造业、物流等领域，AI可以通过更高效的数据处理、预测分析，帮助企业在这些复杂的场景中提升效率和降低成本。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;产品化与易用性&lt;/strong&gt;&lt;br&gt;
类似于Docker通过简化容器化流程来提升运维的效率，AI产品的易用性同样至关重要。AI的普及不仅仅是技术的普及，更是其产品化的普及。将AI集成到日常工作流中，让用户在不需要深入理解技术的前提下，能够轻松使用这些工具，这是AI落地的重要一步。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;生态建设与标准化&lt;/strong&gt;&lt;br&gt;
任何一项新技术的广泛应用，都离不开生态的建设。Docker之所以能快速崛起，正是因为它的开放性和兼容性，使得开发者能够轻松地与各种云平台、工具和服务对接。同样，AI的未来也依赖于生态系统的建设。AI的标准化、模型的共享、数据的开放，以及技术的可集成性，都将影响AI是否能够形成广泛的行业应用。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;结语ai的未来充满可能性但仍需更完善的落地方案&#34;&gt;结语：AI的未来充满可能性，但仍需更完善的落地方案
&lt;/h2&gt;&lt;p&gt;尽管AI的技术在过去两年里取得了长足的进步，但目前它依然处于“没有杀手级应用”的阶段。与Docker发布前的容器化技术相似，AI需要一个合理的应用场景，将现有的技术与业务需求深度融合，才能真正实现大规模的应用和普及。技术创新固然重要，但能够简化流程、提高效率的解决方案，更能推动技术的普及与发展。&lt;/p&gt;
&lt;p&gt;未来，AI可能会像Docker一样，不是通过颠覆性的技术突破，而是通过整合现有的技术，打造出一个完美的应用场景，最终改变我们工作和生活的方式。&lt;/p&gt;</description>
        </item>
        <item>
        <title>ollama 本地部署 deepseek-R1</title>
        <link>https://ttf248.life/p/ollama-%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2-deepseek-r1/</link>
        <pubDate>Fri, 07 Feb 2025 22:41:02 +0800</pubDate>
        
        <guid>https://ttf248.life/p/ollama-%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2-deepseek-r1/</guid>
        <description>&lt;p&gt;Ollama 是一个开源的 AI 工具，旨在使用户能够本地运行和部署大型语言模型（LLM）。它的目标是提供一个方便且高效的方式，让开发者可以在本地机器上使用像 GPT 这样的模型，而不需要依赖云端服务。Ollama 支持多种模型，并且专注于优化性能，使得即使是资源有限的设备也能顺畅运行这些模型。&lt;/p&gt;
&lt;p&gt;通过 Ollama，用户可以使用基于文本的 AI 应用程序，并能够与本地部署的模型进行交互，而无需担心数据隐私或是高昂的 API 使用费用。你可以通过命令行界面（CLI）调用不同的模型，进行自然语言处理、问答等任务。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ollama 适合不同模型尝鲜，windows 版本测试下来，无法充分发挥硬件的性能，可能是因为 windows 版本的原因，linux 版本可能会更好。部署32b参数的模型，内存、显卡负载都有不高的情况下，回复速度很慢。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;硬件概述&#34;&gt;硬件概述
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;操作系统：win11&lt;/li&gt;
&lt;li&gt;CPU：i7-10700K&lt;/li&gt;
&lt;li&gt;内存：40GB&lt;/li&gt;
&lt;li&gt;显卡：RTX 3060 12GB&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;环境准备&#34;&gt;环境准备
&lt;/h2&gt;&lt;p&gt;新增系统环境变量，方便后续使用：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_MODELS=E:\ollama&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
这个变量指定了 Ollama 模型的存放路径。&lt;code&gt;E:\ollama&lt;/code&gt; 是一个文件夹路径，表示所有本地模型文件都存储在该目录下。Ollama 会根据这个路径加载和使用你下载或部署的语言模型。你可以将模型文件存放在其他位置，只需要更改这个路径。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_HOST=127.0.0.1:8000&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
这个环境变量设置了 Ollama 服务的主机和端口。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;127.0.0.1&lt;/code&gt; 是本地地址（localhost），意味着 Ollama 服务会只监听来自本机的请求。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;8000&lt;/code&gt; 是指定的端口号，表示 Ollama 服务将在 8000 端口上等待和处理请求。你可以根据需要更改端口号，但需要确保该端口没有被其他应用占用。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_ORIGINS=*&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
这个环境变量控制允许哪些来源的请求访问 Ollama 服务。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;*&lt;/code&gt; 表示允许任何来源（即所有域名和 IP 地址）都可以访问 Ollama 服务。这通常用于开发和调试环境，在生产环境中，通常会指定更严格的来源控制，限制只有特定的域或 IP 才能访问你的服务，以提高安全性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;deepseek-r1-模型部署&#34;&gt;deepseek-R1 模型部署
&lt;/h2&gt;&lt;p&gt;ollama 安装属于傻瓜式，此处不在赘述。&lt;/p&gt;
&lt;p&gt;安装后的校验：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core&amp;gt;ollama -v
ollama version is 0.5.11
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;模型部署，参考官网模型页面，选择对应参数的模型：&lt;code&gt;ollama run deepseek-r1:14b&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;14b 参数能有效的记住会话上下文，更小的参数版本，无法记住会话上下文。32b 参数版本，本机部署很卡顿，没有再深入进行测试。&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ollama.com/library/deepseek-r1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.ollama.com/library/deepseek-r1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/x18990027/article/details/145368094&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/x18990027/article/details/145368094&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>DeepSeek 春节前突然爆火，英伟达股票暴跌：背后的机构操作与大模型思维链</title>
        <link>https://ttf248.life/p/deepseek-%E6%98%A5%E8%8A%82%E5%89%8D%E7%AA%81%E7%84%B6%E7%88%86%E7%81%AB%E8%8B%B1%E4%BC%9F%E8%BE%BE%E8%82%A1%E7%A5%A8%E6%9A%B4%E8%B7%8C%E8%83%8C%E5%90%8E%E7%9A%84%E6%9C%BA%E6%9E%84%E6%93%8D%E4%BD%9C%E4%B8%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%80%9D%E7%BB%B4%E9%93%BE/</link>
        <pubDate>Fri, 07 Feb 2025 20:36:05 +0800</pubDate>
        
        <guid>https://ttf248.life/p/deepseek-%E6%98%A5%E8%8A%82%E5%89%8D%E7%AA%81%E7%84%B6%E7%88%86%E7%81%AB%E8%8B%B1%E4%BC%9F%E8%BE%BE%E8%82%A1%E7%A5%A8%E6%9A%B4%E8%B7%8C%E8%83%8C%E5%90%8E%E7%9A%84%E6%9C%BA%E6%9E%84%E6%93%8D%E4%BD%9C%E4%B8%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%80%9D%E7%BB%B4%E9%93%BE/</guid>
        <description>&lt;p&gt;春节前夕，DeepSeek 一度成为热议话题，短短几天内便在社交媒体上引起了广泛关注。这种突然的爆火，不仅让人惊讶，还带动了市场的连锁反应。与此同时，英伟达的股票却迎来了暴跌，许多投资者对其前景产生了疑虑，部分机构在此期间进行了大规模的做空操作，似乎一切都指向了一个“精心策划”的局面。&lt;/p&gt;
&lt;h3 id=&#34;deepseek-的爆火短时间内迅速成为焦点&#34;&gt;&lt;strong&gt;DeepSeek 的爆火：短时间内迅速成为焦点&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;DeepSeek 是一个基于 AI 的工具，专注于对深度学习模型的优化，尤其是在自然语言处理（NLP）和图像生成领域的应用。春节前的几天，这个项目突然间受到大量投资者和技术从业者的关注。其背后团队的表现以及所展示的技术成果，让许多人对这个项目产生了强烈的兴趣。无论是在开发者社区，还是社交媒体平台上，关于 DeepSeek 的讨论几乎占据了技术圈的所有话题。&lt;/p&gt;
&lt;p&gt;然而，DeepSeek 的突然爆火并非偶然。经过分析，很多人开始怀疑这背后可能涉及到了某些机构的操作。尤其是在其爆火之后，英伟达股价出现了明显的下跌，显然有一些因素在推动着这一变化。&lt;/p&gt;
&lt;h3 id=&#34;英伟达股票暴跌做空操作的幕后推手&#34;&gt;&lt;strong&gt;英伟达股票暴跌：做空操作的幕后推手&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;英伟达，这家全球领先的图形处理单元（GPU）制造商，一直以来是许多大模型和 AI 计算的关键硬件提供商。随着 AI 市场的快速发展，英伟达的股票长期以来表现强劲，甚至成为了许多投资者青睐的对象。然而，随着 DeepSeek 的爆火和市场对其技术的高度关注，英伟达股票却迎来了暴跌。&lt;/p&gt;
&lt;p&gt;这一现象的背后，或许涉及到了机构投资者的做空策略。在过去几年中，随着 AI 技术的普及，英伟达的股价已被高度推高，很多投资者开始认为其股价存在过度炒作的风险。尤其是在 DeepSeek 这样的技术爆火之后，一些机构可能通过做空英伟达的股票，获得了可观的利润。通过精确的市场时机把握和对 DeepSeek 影响力的预判，这些机构成功地从中获利。&lt;/p&gt;
&lt;h3 id=&#34;大模型思维链的接触从结果到过程&#34;&gt;&lt;strong&gt;大模型思维链的接触：从“结果”到“过程”&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;在传统的人工智能应用中，许多从业者和投资者更多关注的是 AI 模型的“结果”——例如生成的图片、文本等直接的产出。而在与 DeepSeek 相关的讨论中，越来越多的人开始意识到，大模型背后所隐藏的思维链才是更值得关注的核心内容。过去，我们只能看到模型输出的结果，但现在，我们更需要去理解其背后的逻辑、算法以及如何通过调整这些因素来优化模型的表现。&lt;/p&gt;
&lt;p&gt;这种思维方式的转变，实际上是对 AI 研究和应用的一种深入思考。从简单的黑箱操作，到真正理解模型内部运作机制的转变，让许多技术人员和投资者都开始重新审视人工智能的未来发展方向。DeepSeek 的火爆，恰恰是这一思维链的突破性应用，它让人们开始关注整个模型的构建和优化过程，而不仅仅是最终的输出结果。&lt;/p&gt;
&lt;h3 id=&#34;总结&#34;&gt;&lt;strong&gt;总结&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;DeepSeek 的突然爆火，英伟达股票的暴跌，以及市场背后机构的做空操作，这一切背后似乎都是一个精心设计的局。通过对大模型思维链的深入理解，我们可以看到，AI 技术的应用不仅仅是表面现象的堆砌，更是对模型内部逻辑的深入挖掘和优化。随着技术的进步，未来我们或许将看到更多类似 DeepSeek 这样的创新工具，推动 AI 研究和应用向更高层次发展。&lt;/p&gt;
&lt;p&gt;这种现象不仅让我们看到了 AI 技术的巨大潜力，也促使我们开始思考技术背后的商业博弈和资本运作。接下来的市场走势如何，将会是技术与资本博弈的持续焦点。&lt;/p&gt;</description>
        </item>
        <item>
        <title>Cursor AI 编程 IDE 试用</title>
        <link>https://ttf248.life/p/cursor-ai-%E7%BC%96%E7%A8%8B-ide-%E8%AF%95%E7%94%A8/</link>
        <pubDate>Thu, 23 Jan 2025 19:30:13 +0800</pubDate>
        
        <guid>https://ttf248.life/p/cursor-ai-%E7%BC%96%E7%A8%8B-ide-%E8%AF%95%E7%94%A8/</guid>
        <description>&lt;p&gt;转眼又是一年过去了，工作上的最大的变动，还是AI参与度明显提高了，相当以往来说，不同的开发语言之间切换，需要开发者熟悉的各种语言不同的 api 接口，现在这些基础代码都可以通过 AI 生成代码了，对于开发者来说，就是一个很大的福音。&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;早在 23 年的时候，整过两篇简单的入门介绍，转眼已经到了 25 年，怎么说呢，并没有感知到显著的进步，还是需要开发有自己的认知，能合理的拆分任务，当然，最重要的是识别 AI 生成的代码是否存在 bug。&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;Github copilot
&lt;/h2&gt;&lt;p&gt;忘记是是哪天了，看到资料说新加坡部署了服务器，国内使用，再也不用长期挂梯子，当然，登录的时候，还是需要挂个梯子，不过这个梯子只需要登录的时候用一下，之后就可以关闭了。&lt;/p&gt;
&lt;p&gt;日常用的更多的也是 Github copilot，这个插件，可以直接在 vscode、visual studio 中直接使用。不用两个软件之间切换。相对于 ChatGPT，Github copilot 对于项目的支持更好，交互上更友好，能你能选择部分本地的文件投喂，&lt;strong&gt;“训练”AI&lt;/strong&gt;，这样生成的代码更符合你的项目。&lt;/p&gt;
&lt;h2 id=&#34;cursor-ai&#34;&gt;Cursor AI
&lt;/h2&gt;&lt;p&gt;最近看到了一个新的 AI 编程 IDE，Cursor AI，这个 IDE 也是基于 Github copilot 的，不过这个 IDE 更加的智能，可以帮你直接创建文件。&lt;/p&gt;
&lt;p&gt;简单的用了一下，感觉还是不错的，不过对于现有项目的理解还是不够，本地项目文件多的时候，大的重构优化调整，还是需要&lt;strong&gt;开发者拆分任务&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;附上一个例子：切换到 curso 的工程模式，输入内容：新建个人简历网页，支持多个不同风格切换，记得填充一些个人信息用于数据展示。&lt;/p&gt;
&lt;p&gt;经过几次来回的&lt;strong&gt;拉扯&lt;/strong&gt;，你就能拿到如下的网页，当然，这个网页还是比较简单的，不过对于新手来说，还是很不错的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;目前注册用户能免费试用 150 次高级 api，付费用户限制 5000 次高级 api&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://ttf248.life/cursor/index.html&#34; &gt;个人简历&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>AI编程和任务拆解</title>
        <link>https://ttf248.life/p/ai%E7%BC%96%E7%A8%8B%E5%92%8C%E4%BB%BB%E5%8A%A1%E6%8B%86%E8%A7%A3/</link>
        <pubDate>Fri, 22 Dec 2023 08:44:26 +0800</pubDate>
        
        <guid>https://ttf248.life/p/ai%E7%BC%96%E7%A8%8B%E5%92%8C%E4%BB%BB%E5%8A%A1%E6%8B%86%E8%A7%A3/</guid>
        <description>&lt;p&gt;两年前给站点添加代码区域的拷贝功能，前后折腾了小半天，最终渲染效果有点不如意，作为半吊子前端开发，也没想着改进，能用就行，今年用&lt;code&gt;AI&lt;/code&gt;开发了小程序，对于前端的开发也更加熟悉了，重构一波（AI重新设计）。&lt;/p&gt;
&lt;p&gt;悟道：任务拆解开，很多小任务，&lt;code&gt;AI&lt;/code&gt;开发起来还是顺手的。已经倒闭的小程序，&lt;code&gt;75%&lt;/code&gt;代码由&lt;code&gt;AI&lt;/code&gt;提供，拆解了多个任务交付，人工进行项目代码的&lt;code&gt;组装&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&#34;前文&#34;&gt;前文
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://ttf248.github.io/post/2022/001-%E4%BB%A5%E4%B8%BA%E5%BE%88%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%8B%E6%83%85%E5%A2%9E%E5%8A%A0%E4%B8%80%E4%B8%AA%E4%BB%A3%E7%A0%81%E5%A4%8D%E5%88%B6%E6%8C%89%E9%92%AE/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;以为很简单的事情，增加一个代码复制按钮&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;promot&lt;/strong&gt;: 设计 css 和 JavaScript 代码，定位网页元素 class=&amp;ldquo;highlight&amp;rdquo;，这个元素的容器内，添加一个 复制按钮，实现复制代码的功能&lt;/p&gt;
&lt;p&gt;给的第一稿代码一眼看上去就有问题，重新生成一稿，基本可用，复制的内容不对，有冗余的文字，再次引导优化，人工指定核心的颜色设计，包含哪些特效&lt;/p&gt;
&lt;p&gt;了解到您对按钮的尺寸和颜色有特定的要求，我们可以重新设计按钮的样式以适应这些要求。以下是一个调整后的 CSS 样式，其中包括了您提供的颜色方案，并对按钮的尺寸进行了优化：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.copy-btn {
  position: absolute;
  top: 2px; /* 调整位置 */
  right: 2px;
  padding: 3px 6px; /* 缩小尺寸 */
  font-size: 12px; /* 减小字体大小 */
  background-color: #8FD1E1; /* 按钮背景色 */
  color: #272822; /* 文字颜色 */
  border: 1px solid #272822; /* 边框颜色 */
  border-radius: 3px; /* 圆角 */
  cursor: pointer;
  opacity: 0.7; /* 默认半透明 */
  transition: opacity 0.3s ease, background-color 0.3s ease; /* 平滑过渡效果 */
}

.copy-btn:hover {
  opacity: 1; /* 鼠标悬停时不透明 */
  background-color: #A3D4E5; /* 鼠标悬停时的背景色 */
}

.highlight {
  position: relative;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在这个样式中，我减小了按钮的尺寸和字体大小，使其更加精致。同时，按钮的默认状态是半透明的，当鼠标悬停在按钮上时，它会变为不透明，并且背景色会变得稍微亮一些，以提供视觉反馈。这样的设计既符合您的颜色要求，又保持了现代化和用户友好的特点。&lt;/p&gt;
&lt;p&gt;对应的提供了一份更简单的 &lt;code&gt;JavaScript&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-JavaScript&#34;&gt;document.addEventListener(&#39;DOMContentLoaded&#39;, function() {
  // 查找所有 .highlight 元素
  const highlights = document.querySelectorAll(&#39;.highlight&#39;);

  highlights.forEach(function(highlight) {
    // 创建复制按钮
    const copyBtn = document.createElement(&#39;button&#39;);
    copyBtn.textContent = &#39;复制&#39;;
    copyBtn.classList.add(&#39;copy-btn&#39;);

    // 将按钮添加到每个 .highlight 元素中
    highlight.appendChild(copyBtn);

    // 添加点击事件监听器
    copyBtn.addEventListener(&#39;click&#39;, function() {
      // 假设 .highlight 下的第一个 &amp;lt;code&amp;gt; 元素包含要复制的代码
      const code = highlight.querySelector(&#39;code&#39;) ? highlight.querySelector(&#39;code&#39;).textContent : &#39;&#39;;

      navigator.clipboard.writeText(code).then(() =&amp;gt; {
        // 显示复制成功信息
        copyBtn.textContent = &#39;已复制!&#39;;
        setTimeout(() =&amp;gt; {
          copyBtn.textContent = &#39;复制&#39;;
        }, 2000);
      }).catch(err =&amp;gt; {
        console.error(&#39;复制失败: &#39;, err);
      });
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;后记&#34;&gt;后记
&lt;/h2&gt;&lt;p&gt;虽说我更期望在代码区域的右上角，顶部区域新增复制按钮，由于对前端不够了解，无法基于关键词准确描述功能，和&lt;code&gt;AI&lt;/code&gt;来回折腾几个回合也没有达到预期。&lt;/p&gt;
&lt;p&gt;就是不知道随着时间的发展，&lt;code&gt;AI&lt;/code&gt;对于程序开发会有多大的影响。&lt;/p&gt;</description>
        </item>
        <item>
        <title>Prompt 工程师</title>
        <link>https://ttf248.life/p/prompt-%E5%B7%A5%E7%A8%8B%E5%B8%88/</link>
        <pubDate>Sun, 26 Mar 2023 20:46:53 +0800</pubDate>
        
        <guid>https://ttf248.life/p/prompt-%E5%B7%A5%E7%A8%8B%E5%B8%88/</guid>
        <description>&lt;p&gt;就如当年学习搜索引擎的技巧，我们也需要学习一些和&lt;code&gt;AI&lt;/code&gt;沟通的技巧，给出合理且充分的限定条件，高效的获取需要的答案。&lt;/p&gt;
&lt;p&gt;如果你换个角度呢，当前的&lt;code&gt;AI&lt;/code&gt;属于一个记忆力很好的小孩子，它拥有过目不忘的能力，有抄作业的能力。我们需要做的是学会如何正确、有效的和&lt;code&gt;AI&lt;/code&gt;沟通，精准的描述需求，帮助&lt;code&gt;AI&lt;/code&gt;生成预期的结果。&lt;/p&gt;
&lt;h2 id=&#34;科普&#34;&gt;科普
&lt;/h2&gt;&lt;p&gt;火出天际的&lt;code&gt;AI&lt;/code&gt;确切的说&lt;code&gt;Generative Pre-Training&lt;/code&gt;，直译过来就是生成式的预训练。它是一种基于互联网可用数据训练的文本生成深度学习模型，用于问答、文本摘要生成、机器翻译、分类、代码生成和对话 AI 等任务。目前已经有 GPT-1、GPT-2、GPT-3 和 GPT-4 等不同版本的模型，每个版本都比前一个版本更大、更强大。&lt;/p&gt;
&lt;h2 id=&#34;到底有没有智能&#34;&gt;到底有没有智能
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;相似度足够高，准确率也就越高&lt;/li&gt;
&lt;li&gt;基础的、重复性的工作，进过特定训练，不再需要人工的介入&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;生成式AI是一种利用现有的文本、音频、图像等数据来创建新内容的技术。它可以用于文本生成、语音合成、图像生成、对话系统等多种任务。生成式AI的逻辑性取决于它的训练数据和模型结构。一般来说，生成式AI可以在一定程度上遵循语法、逻辑和常识，但也可能出现错误、偏差或不真实的内容。因此，生成式AI的输出需要人类的判断和验证，不能盲目相信或使用。&lt;/p&gt;
&lt;h2 id=&#34;prompt-工程师&#34;&gt;Prompt 工程师
&lt;/h2&gt;&lt;p&gt;时间河流不会逆流，人需要学会适应潮流。你可以认为&lt;code&gt;AI&lt;/code&gt;不智能，没有逻辑性，它经常写出来不能用的代码。&lt;/p&gt;
&lt;p&gt;如果你换个角度呢，当前的&lt;code&gt;AI&lt;/code&gt;属于一个记忆力很好的小孩子，它拥有过目不忘的能力，有抄作业的能力。我们需要做的是学会如何正确、有效的和&lt;code&gt;AI&lt;/code&gt;沟通，精准的描述需求，帮助&lt;code&gt;AI&lt;/code&gt;生成预期的结果。&lt;/p&gt;
&lt;h2 id=&#34;对话模式&#34;&gt;对话模式
&lt;/h2&gt;&lt;p&gt;两年前&lt;code&gt;Github Copilot&lt;/code&gt;发布，谁也想不到两年后，&lt;code&gt;OpenAI&lt;/code&gt;横空出世，让人类认知到了大语言模型的能力。&lt;/p&gt;
&lt;p&gt;基于&lt;strong&gt;基于注释的编程&lt;/strong&gt;和&lt;strong&gt;基于对话的编程&lt;/strong&gt;，交互逻辑上完全不同，对话的模式，小白用户的交互体验友好，此处必须提到&lt;code&gt;NewBing&lt;/code&gt;在每个问题之后，给出的追问提示，微软在尝试引导用户，获取&lt;code&gt;AI&lt;/code&gt;知识库里面，更多的内容。&lt;/p&gt;
&lt;h2 id=&#34;举个栗子&#34;&gt;举个栗子
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;场景&lt;/strong&gt;：高铁旅途时间漫漫，编码是个不错的选择。流量有限的情况下，处理几个图片，获取了图片素材，下载软件处理图片稍微有点奢侈，网络条件也不允许。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;需求&lt;/strong&gt;：有一批图片素材，带透明背景图，用来作为小程序的导航栏，选中的状态是彩色的，没选中的状态是黑白的，素材都是彩色的，需要预处理一下。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Prompt&lt;/strong&gt;：编写一段 python 代码，从一个文件夹中读取所有的图片，将图片转换成黑白，维持透明背景，保存图片的时候，优化图片的质量，减少文件体积，同时在控制台展示，优化前后的文件体积大小对比&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 导入必要的库
import os
import PIL
from PIL import Image

# 定义一个函数，将图片转换成黑白，维持透明背景，保存图片，并返回文件体积
def convert_and_save(image_file):
    # 打开图片
    image = Image.open(image_file)
    # 获取图片的模式，如果是 RGBA 模式，说明有透明背景
    mode = image.mode
    if mode == &amp;quot;RGBA&amp;quot;:
        # 创建一个和图片大小一致的白色背景图片
        background = Image.new(&amp;quot;RGB&amp;quot;, image.size, (255, 255, 255))
        # 将原图片粘贴到白色背景上，忽略透明像素
        background.paste(image, mask=image.split()[3])
        # 将合成的图片转换成灰度模式
        gray_image = background.convert(&amp;quot;L&amp;quot;)
        # 将灰度图片再转换成 RGBA 模式，以便保留透明背景
        final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
    else:
        # 如果不是 RGBA 模式，直接将图片转换成灰度模式
        final_image = image.convert(&amp;quot;L&amp;quot;)
    # 获取原图片的文件名和扩展名
    file_name, file_ext = os.path.splitext(image_file)
    # 定义新图片的文件名，添加 _bw 后缀表示黑白
    new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # 保存新图片，并优化质量，减少文件体积
    final_image.save(new_file_name, optimize=True)
    # 获取原图片和新图片的文件体积，并返回
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return old_size, new_size

# 定义一个文件夹路径，存放所有的图片
folder_path = &amp;quot;images&amp;quot;
# 遍历文件夹中的所有文件
for file in os.listdir(folder_path):
    # 拼接完整的文件路径
    file_path = os.path.join(folder_path, file)
    # 判断是否是图片文件，根据扩展名判断，可以根据需要添加或修改扩展名
    if file_path.endswith((&amp;quot;.png&amp;quot;, &amp;quot;.jpg&amp;quot;, &amp;quot;.jpeg&amp;quot;, &amp;quot;.gif&amp;quot;)):
        # 调用函数，转换并保存图片，并获取文件体积
        old_size, new_size = convert_and_save(file_path)
        # 在控制台展示优化前后的文件体积大小对比
        print(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;AI&lt;/code&gt;迅速给出了答案，看着很漂亮，用起来也没问题，经验丰富的程序源，会觉得下面的代码不够通用，也没法上生产环境：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;参数固定了&lt;/li&gt;
&lt;li&gt;没有日志文件，信息都打印在控制台&lt;/li&gt;
&lt;li&gt;图片处理的任务，适合多线程模型&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;NewBing&lt;/code&gt;登场，依据提示，选择了一个问题：&lt;strong&gt;这段代码有什么可以改进的地方吗&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这次给的答案，实话，完全超出了预期，一般程序员能想到的优化措施，&lt;code&gt;AI&lt;/code&gt;都给出对应的建议&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;这段代码可能还有一些可以改进的地方，比如：

可以使用 argparse 库，让用户可以通过命令行参数指定文件夹路径和扩展名，而不是写死在代码里。
可以使用 logging 库，记录程序的运行情况，而不是直接打印到控制台。
可以使用 try-except 语句，捕获可能出现的异常，比如文件打开失败，图片转换失败等，并做相应的处理。
可以使用 multiprocessing 库，利用多核处理器，加速图片的转换和保存过程。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;很友好的应答，考虑到部署的环境存在差异，允许不支持多进程&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;当然，我很乐意帮你修改一下代码。我尝试添加了 argparse, logging 和 try-except 语句，但没有添加 multiprocessing 库，因为我不确定你的电脑是否支持多核处理。修改后的代码如下：
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 导入必要的库
import argparse
import logging
import multiprocessing
import os

from PIL import Image


# 定义一个函数，将图片转换成黑白，维持透明背景，保存图片，并返回文件体积
def convert_and_save(image_file):
    # 打开图片
    try:
        image = Image.open(image_file)
    except Exception as e:
        logging.error(f&amp;quot;Failed to open {image_file}: {e}&amp;quot;)
        return None, None
    # 获取图片的模式，如果是 RGBA 模式，说明有透明背景
    mode = image.mode
    if mode == &amp;quot;RGBA&amp;quot;:
        # 创建一个和图片大小一致的白色背景图片
        background = Image.new(&amp;quot;RGB&amp;quot;, image.size, (255, 255, 255))
        # 将原图片粘贴到白色背景上，忽略透明像素
        background.paste(image, mask=image.split()[3])
        # 将合成的图片转换成灰度模式
        gray_image = background.convert(&amp;quot;L&amp;quot;)
        # 将灰度图片再转换成 RGBA 模式，以便保留透明背景
        final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
    else:
        # 如果不是 RGBA 模式，直接将图片转换成灰度模式
        final_image = image.convert(&amp;quot;L&amp;quot;)
    # 获取原图片的文件名和扩展名
    file_name, file_ext = os.path.splitext(image_file)
    # 定义新图片的文件名，添加 _bw 后缀表示黑白
    new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # 保存新图片，并优化质量，减少文件体积
    try:
        final_image.save(new_file_name, optimize=True)
    except Exception as e:
        logging.error(f&amp;quot;Failed to save {new_file_name}: {e}&amp;quot;)
        return None, None
    # 获取原图片和新图片的文件体积，并返回
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return file_name, old_size, new_size

# 定义一个函数，解析命令行参数，并返回文件夹路径和扩展名列表
def parse_args():
    # 创建一个解析器对象
    parser = argparse.ArgumentParser(description=&amp;quot;Convert images to black and white and optimize quality.&amp;quot;)
    # 添加一个必选的位置参数，表示文件夹路径
    parser.add_argument(&amp;quot;folder_path&amp;quot;, help=&amp;quot;The path of the folder that contains the images.&amp;quot;)
    # 添加一个可选的参数，表示扩展名列表，默认为 png, jpg, jpeg 和 gif
    parser.add_argument(&amp;quot;-e&amp;quot;, &amp;quot;--extensions&amp;quot;, nargs=&amp;quot;+&amp;quot;, default=[&amp;quot;.png&amp;quot;, &amp;quot;.jpg&amp;quot;, &amp;quot;.jpeg&amp;quot;, &amp;quot;.gif&amp;quot;], help=&amp;quot;The extensions of the image files.&amp;quot;)
    # 解析命令行参数，并返回结果对象
    args = parser.parse_args()
    return args.folder_path, args.extensions

# 定义一个函数，打印优化前后的文件体积大小对比
def print_result(result):
    # 如果结果不为空，说明转换和保存成功
    if result:
        # 解包结果为文件名和文件体积元组
        if len(result) == 3:
            file, old_size, new_size = result
            # 在控制台展示优化前后的文件体积大小对比
            logging.info(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)
        else:
            logging.info(f&amp;quot;{result}&amp;quot;)

# 配置日志记录器，将日志输出到控制台和文件中，设置日志等级为 INFO
logging.basicConfig(level=logging.INFO,
                    format=&amp;quot;%(asctime)s %(levelname)s %(message)s&amp;quot;,
                    handlers=[logging.StreamHandler(),
                              logging.FileHandler(&amp;quot;log.txt&amp;quot;)])

# 调用函数，获取文件夹路径和扩展名列表
folder_path, extensions = parse_args()

if __name__ == &amp;quot;__main__&amp;quot;:
    # Windows 需要这个函数的原因是 Windows 缺乏 fork() 函数（这不完全正确）。
    # 因此，在 Windows 上，fork() 是通过创建一个新的进程来模拟的，这个新的进程中运行的代码，在 Linux 上是在子进程中运行的。
    # 由于这些代码要在技术上无关的进程中运行，所以它必须在运行之前被传递到那里。
    # 传递的方式是先将它们序列化，然后通过管道从原始进程发送到新的进程。
    # 另外，这个新的进程被通知它必须运行通过管道传递的代码，通过向它传递 --multiprocessing-fork 命令行参数。
    # 如果你看一下 freeze_support() 函数的实现，它的任务是检查它运行在哪个进程中，是否应该运行通过管道传递的代码
    multiprocessing.freeze_support()

    # 创建一个进程池，根据电脑的核心数自动分配进程
    pool = multiprocessing.Pool()
    # 创建一个空列表，用于存放异步任务的结果对象
    results = []
    # 遍历文件夹中的所有文件
    for file in os.listdir(folder_path):
        # 拼接完整的文件路径
        file_path = os.path.join(folder_path, file)
        # 判断是否是图片文件，根据扩展名判断，可以根据需要修改扩展名列表
        if any(file_path.endswith(ext) for ext in extensions):
            # 调用函数，转换并保存图片，并获取文件体积，使用异步方式，不阻塞主进程
            result = pool.apply_async(convert_and_save, args=(file_path,), callback=print_result)
            # 将结果对象添加到列表中
            results.append((file, result))
    # 关闭进程池，不再接受新的任务
    pool.close()
    # 等待所有的任务完成
    pool.join()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;后记&#34;&gt;后记
&lt;/h2&gt;&lt;p&gt;由于本地开发是&lt;code&gt;windows&lt;/code&gt;系统，&lt;code&gt;AI&lt;/code&gt;第一次给出的答案，并没有加上&lt;code&gt;main&lt;/code&gt;函数，也没有&lt;code&gt;multiprocessing.freeze_support&lt;/code&gt;。通过追问发生的报错，修复了代码。&lt;/p&gt;
&lt;p&gt;就如当年学习搜索引擎的技巧，我们也需要学习一些和&lt;code&gt;AI&lt;/code&gt;沟通的技巧，给出合理且充分的限定条件，高效的获取需要的答案。&lt;/p&gt;
&lt;p&gt;注意：&lt;strong&gt;如果你是个编程新手，基于给出的注释，还有看不懂的地方，可以继续追问相关代码&lt;/strong&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>AI辅助编程，生产力的进化</title>
        <link>https://ttf248.life/p/ai%E8%BE%85%E5%8A%A9%E7%BC%96%E7%A8%8B%E7%94%9F%E4%BA%A7%E5%8A%9B%E7%9A%84%E8%BF%9B%E5%8C%96/</link>
        <pubDate>Tue, 28 Feb 2023 17:05:17 +0800</pubDate>
        
        <guid>https://ttf248.life/p/ai%E8%BE%85%E5%8A%A9%E7%BC%96%E7%A8%8B%E7%94%9F%E4%BA%A7%E5%8A%9B%E7%9A%84%E8%BF%9B%E5%8C%96/</guid>
        <description>&lt;p&gt;&lt;code&gt;GitHub Copilot&lt;/code&gt; 发布也不到两年时间，&lt;code&gt;ChatGPT&lt;/code&gt; 问世了，不是很懂背后的原理，都用了一段时间。两个工具的辅助层面完全不同，但是都做到了大幅提高生产力。&lt;/p&gt;
&lt;p&gt;太复杂的事情，&lt;code&gt;AI&lt;/code&gt;还做不到，毕竟他们没有逻辑，有套路的或者说范式固定的事情，训练的语料足够，&lt;code&gt;AI&lt;/code&gt;的效果能打个九分。&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;github copilot
&lt;/h2&gt;&lt;p&gt;发布的时候，看着官网的介绍&lt;code&gt;demo&lt;/code&gt;，不是很智能，试用了一下，不是很好用，放弃了。&lt;/p&gt;
&lt;p&gt;2022年前，闲来无事，切换到新版本体验一下，效果已经不错了，就是国内的速度有点慢，大概率是网络的原因。&lt;code&gt;Python&lt;/code&gt;之类的语言，依据注释写出来的代码都还不错，比我自己查资料然后编写的速度快了很多。&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;Github Copilot&lt;/code&gt;还停留在程序员，也就是开发的角度来设计产品，你需要懂的如何编程，慢慢的通过注释来引导AI辅助编程。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ChatGPT&lt;/code&gt; 走到了下一个层面，&lt;strong&gt;让外行人也能迅速上手&lt;/strong&gt;。对话聊天交互式的设计，你完全可以提出问题，描述需求，不懂的地方，继续提问。&lt;/p&gt;
&lt;p&gt;简单来个例子，知道分词的概念，但是不知道如何编码，想要计算字符串的相似度：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Python 分词计算 維天運通 LOGORY 和 合肥維天運通信息科技股份有限公司 两个字符串的相似度；
比较前，统一处理字符串，英文转换为小写；
第二个字符中如果能找到第一个字符的首字符，将第二个字符串截位，截位的长度为第一个字符串的长度
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;你好，这是Bing。😊&lt;/p&gt;
&lt;p&gt;根据网上的信息123，Python 分词计算可以使用 jieba 库来实现。jieba 库支持三种分词模式：精确模式、全模式和搜索引擎模式。你可以根据你的需求选择合适的模式。&lt;/p&gt;
&lt;p&gt;为了比较两个字符串的相似度，你需要先对它们进行分词，然后计算它们的词向量或者编辑距离等指标。你可以使用 numpy 或者 scipy 等库来进行数学运算。&lt;/p&gt;
&lt;p&gt;为了统一处理字符串，英文转换为小写，你可以使用 Python 的内置函数 lower() 来实现。&lt;/p&gt;
&lt;p&gt;为了截取第二个字符串，你可以使用 Python 的切片操作符 [ ] 来实现。&lt;/p&gt;
&lt;p&gt;以下是一个可能的代码示例：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import jieba
import numpy as np
from scipy.spatial.distance import cosine

# 定义两个字符串
str1 = &amp;quot;維天運通 LOGORY&amp;quot;
str2 = &amp;quot;合肥維天運通信息科技股份有限公司&amp;quot;

# 统一处理字符串，英文转换为小写
str1 = str1.lower()
str2 = str2.lower()

# 找到第二个字符串中第一个字符的位置
index = str2.find(str1[0])

# 如果找到了，截取第二个字符串
if index != -1:
    str2 = str2[index:index+len(str1)]

# 使用 jieba 库进行分词
words1 = list(jieba.cut(str1))
words2 = list(jieba.cut(str2))

# 计算两个字符串的词向量（以词频作为权重）
vector1 = np.zeros(len(words1))
vector2 = np.zeros(len(words1))

for i, word in enumerate(words1):
    vector1[i] += 1 # 统计第一个字符串中每个词出现的次数
    if word in words2:
        vector2[i] += 1 # 统计第二个字符串中每个词出现的次数

# 计算两个字符串的相似度（以余弦距离作为指标）
similarity = 1 - cosine(vector1, vector2)

print(&amp;quot;两个字符串的相似度是：&amp;quot;, similarity)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;更进一步，咨询运行的结果，恭喜你，发现问题了，结果是瞎编的，它并没有实际运行代码，但是会给你一个不错的结果&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;栗子&#34;&gt;栗子
&lt;/h3&gt;&lt;p&gt;提问：sql 语句，查出产品代码表中，产品代码在这个区间 80000-89999 的记录&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;你好，这是 Bing。😊

根据搜索结果12，你可以使用 SQL BETWEEN 运算符来选择给定区间内的值。BETWEEN 运算符包含了开始和结束的值。

你需要先指定要查询的表名和列名，然后在 WHERE 子句中使用 BETWEEN 运算符和区间值。

例如，如果你要查询产品代码表中，产品代码在 80000 到 89999 之间的记录，你可以使用以下语句：

SELECT * FROM product_code
WHERE code BETWEEN 80000 AND 89999;
这里，* 表示选择所有列3。如果你只想选择特定的列，比如产品名称和价格，你可以用逗号分隔它们，如下：

SELECT name, price FROM product_code
WHERE code BETWEEN 80000 AND 89999;
希望这能帮助到你。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;继续提问，否定它：产品代码是字符串，你的代码错了&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;抱歉，我没有注意到产品代码是字符串。如果是这样的话，你需要在区间值两边加上单引号，如下：

SELECT * FROM product_code
WHERE code BETWEEN &#39;80000&#39; AND &#39;89999&#39;;
请原谅我的错误。🙏
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;恭喜你，它会认错的。&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

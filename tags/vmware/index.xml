<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>vmware on 向叔记事簿</title>
        <link>https://ttf248.life/tags/vmware/</link>
        <description>Recent content in vmware on 向叔记事簿</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language><atom:link href="https://ttf248.life/tags/vmware/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>vmware虚拟机cpu资源占用异常</title>
        <link>https://ttf248.life/p/vmware-virtual-machine-cpu-resource-usage-anomaly/</link>
        <pubDate>Sun, 10 Mar 2024 22:14:59 +0800</pubDate>
        
        <guid>https://ttf248.life/p/vmware-virtual-machine-cpu-resource-usage-anomaly/</guid>
        <description>&lt;p&gt;背景：本地机器部署 windows 版本的业务系统，cpu 资源占用 5% 左右。vmware安装的 centos8 中部署 linux 版本业务系统，资源占用异常。&lt;/p&gt;
&lt;h2 id=&#34;问题描述&#34;&gt;问题描述
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;宿主机：win10 企业版&lt;/li&gt;
&lt;li&gt;vmware：17.5&lt;/li&gt;
&lt;li&gt;虚拟机：centos8&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;虚拟机资源分配为&lt;code&gt;4C8GB&lt;/code&gt;，启动业务系统。业务系统部署在虚拟机Linux系统中，虚拟机内部 top 命令观察系统资源占用，cpu 占用并不高，外层 windows 系统，任务管理器观察到的CPU资源占用很高，查看进程发现，vmware 进程占用CPU资源很高。&lt;/p&gt;
&lt;p&gt;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+
|         Windows           |
|                           |
|   +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+  |
|   |      VMware        |  |
|   |      Program       |  |
|   +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+  |
|                           |
+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&lt;/p&gt;
&lt;h2 id=&#34;知识点&#34;&gt;知识点
&lt;/h2&gt;&lt;p&gt;此问题的排查，并不顺利，由于导火索并不是业务系统本身，而是虚拟机本身的问题。如何将思路从常规的业务代码转移到系统负载，再从负载数据的异常，定位到软中断，最后来到关键点，什么东西会影响 Vmware 软中断的工作效率？本文将先科普各个知识点，最后给出解决方案。&lt;/p&gt;
&lt;h3 id=&#34;hyper-v&#34;&gt;hyper-v
&lt;/h3&gt;&lt;p&gt;Windows操作系统的虚拟化技术经历了一次重大变革。在微软首次发布WSL时，启用Hyper-V服务会导致无法同时使用VMware虚拟机。直到后续版本，VMware才能与Hyper-V服务兼容。&lt;/p&gt;
&lt;h3 id=&#34;系统负载&#34;&gt;系统负载
&lt;/h3&gt;&lt;p&gt;在Linux系统中，&amp;ldquo;负载&amp;rdquo;（load）是指系统中正在运行或等待执行的进程的数量。负载通常由三个数字表示，分别是1分钟、5分钟和15分钟内运行队列中的平均进程数量。这些数字可以通过运行&amp;quot;uptime&amp;quot;命令或&amp;quot;top&amp;quot;命令来查看。&lt;/p&gt;
&lt;p&gt;具体来说，这三个数字分别代表：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;1分钟负载&lt;/strong&gt;：系统在过去1分钟内运行队列中的平均进程数量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;5分钟负载&lt;/strong&gt;：系统在过去5分钟内运行队列中的平均进程数量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;15分钟负载&lt;/strong&gt;：系统在过去15分钟内运行队列中的平均进程数量。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;负载的含义是在系统中等待运行的进程数。如果这个数字高于系统的逻辑CPU数量，表明系统负载很高，意味着有许多进程正在等待处理器资源。这可能会导致系统变得缓慢或不响应，具体取决于负载的高低程度以及系统的配置和性能。&lt;/p&gt;
&lt;p&gt;在理想情况下，负载应该保持在系统的逻辑CPU数量范围内，这样系统的性能就能够得到最优化。如果负载持续高于CPU数量，可能需要进一步分析系统中的进程，找出导致负载高的原因，并采取相应的措施来调整系统资源分配或优化进程的运行方式。&lt;/p&gt;
&lt;h3 id=&#34;分析负载-mpstat&#34;&gt;分析负载 mpstat
&lt;/h3&gt;&lt;p&gt;&lt;code&gt;mpstat&lt;/code&gt; 命令用于报告单个或多个处理器的多个信息，包括平均负载、CPU利用率、中断和上下文切换等。在 &lt;code&gt;sysstat&lt;/code&gt; 包中，&lt;code&gt;mpstat&lt;/code&gt; 是非常有用的工具，可以用来分析系统的负载情况。下面是使用 &lt;code&gt;mpstat&lt;/code&gt; 进行负载分析的步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;安装 sysstat&lt;/strong&gt;：
如果您的系统上没有安装 &lt;code&gt;sysstat&lt;/code&gt;，可以使用适合您系统的包管理工具进行安装。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;运行 mpstat&lt;/strong&gt;：
使用 &lt;code&gt;mpstat&lt;/code&gt; 命令查看 CPU 的使用情况和负载。默认情况下，&lt;code&gt;mpstat&lt;/code&gt; 每秒钟显示一次 CPU 使用情况的平均值。您可以通过指定时间间隔来调整输出频率。例如，要以每秒钟一次的频率运行 &lt;code&gt;mpstat&lt;/code&gt;，可以使用以下命令：&lt;code&gt;mpstat -P ALL 2&lt;/code&gt;，&lt;code&gt;irq&lt;/code&gt; 表示占用资源占用&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;01:32:33 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
01:32:35 PM  all    0.00    0.00    0.26    0.00    3.73    0.26    0.00    0.00    0.00   95.76
01:32:35 PM    0    0.00    0.00    0.51    0.00    3.57    0.00    0.00    0.00    0.00   95.92
01:32:35 PM    1    0.00    0.00    0.00    0.00    3.59    0.51    0.00    0.00    0.00   95.90
01:32:35 PM    2    0.00    0.00    0.00    0.00    4.15    0.00    0.00    0.00    0.00   95.85
01:32:35 PM    3    0.00    0.00    0.52    0.00    3.61    0.52    0.00    0.00    0.00   95.36
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;分析输出&lt;/strong&gt;：
&lt;code&gt;mpstat&lt;/code&gt; 的输出包括了每个 CPU 的利用率，以及系统的平均负载。特别关注平均负载以及每个 CPU 的利用率，可以帮助您了解系统的负载情况。如果负载较高，可以进一步分析是哪些进程导致的，以及是否存在性能瓶颈。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;结合其他工具&lt;/strong&gt;：
除了 &lt;code&gt;mpstat&lt;/code&gt;，还可以使用 &lt;code&gt;sar&lt;/code&gt;、&lt;code&gt;pidstat&lt;/code&gt;、&lt;code&gt;iostat&lt;/code&gt; 等工具来综合分析系统性能。通过结合多种工具的输出，可以更全面地了解系统的负载情况，并找出性能问题的根源。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;中断&#34;&gt;中断
&lt;/h3&gt;&lt;p&gt;此处不展开讲解内容太多，
推荐: &lt;a class=&#34;link&#34; href=&#34;https://www.codedump.info/post/20200522-sgfap-softirq/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;《面向应用开发者的系统指南》CPU篇之软中断&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;频繁的触发软中断，也会体现在系统负载中。&lt;/p&gt;
&lt;h2 id=&#34;问题排查&#34;&gt;问题排查
&lt;/h2&gt;&lt;p&gt;考虑到仅从CPU角度分析无法定位问题，我们是否应该开始怀疑系统是否出现了异常？可能是Linux操作系统的负载过高，导致VMware占用了过多的CPU资源。通过使用&lt;code&gt;mpstat&lt;/code&gt;分析本地虚拟机，我们发现&lt;code&gt;irq&lt;/code&gt;占用异常，单核接近25%，而在正常情况下，启动业务进程空跑时，&lt;code&gt;irq&lt;/code&gt;占比应该约为5%。&lt;/p&gt;
&lt;p&gt;在组内同事的开发环境中，他的CentOS 7部署在VMware上，资源占用显示正常。另一方面，在上海的开发环境中，虽然也是VMware，但我们无法直接观察宿主机的CPU资源情况。这时，我们面临着多个变量：VMware虚拟机、Linux操作系统和GCC版本。&lt;/p&gt;
&lt;p&gt;转而分析测试环境，深圳的测试环境部署在物理机上，运行着低版本GCC编译的服务，而且在CentOS 8上运行。有趣的是，在深圳环境中，&lt;code&gt;irq&lt;/code&gt;占用都是正常的。&lt;/p&gt;
&lt;p&gt;为了排查GCC版本引入的问题，我们将使用高版本GCC编译的程序部署到深圳环境进行测试，结果显示也都是正常的。&lt;/p&gt;
&lt;p&gt;问题似乎变得更加明朗，我们开始怀疑操作系统是否存在问题。毕竟，CentOS 8已经不再受到官方支持。但即便重新部署了纯净的CentOS 7和CentOS 8，问题依然存在。&lt;/p&gt;
&lt;p&gt;此时，我们开始怀疑唯一的不确定因素，即VMware虚拟机软件。突然间，灵光一现，我们想到了Hyper-V技术。是否之前启用了Hyper-V，但没有彻底关闭，从而导致了这个问题？毕竟，软中断也是通过虚拟机软件来实现的。不同的虚拟机虚拟技术是否存在BUG？这些问题值得深入思考和调查。&lt;/p&gt;
&lt;h2 id=&#34;结论&#34;&gt;结论
&lt;/h2&gt;&lt;p&gt;根据微软官方的手册，我们完全关闭了本机的Hyper-V服务后，发现VMware在宿主机上恢复了正常。至此，问题终于迎刃而解。正如一开始所述，这段经历曲折而艰辛，需要综合性的分析和判断。这也是我们首次排查问题，定位到了虚拟机这一层面。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Disable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V-Hypervisor
bcdedit /set hypervisorlaunchtype off
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/troubleshoot/windows-client/application-management/virtualization-apps-not-work-with-hyper-v&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://learn.microsoft.com/zh-cn/troubleshoot/windows-client/application-management/virtualization-apps-not-work-with-hyper-v&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>VMware 虚拟机磁盘空间优化</title>
        <link>https://ttf248.life/p/vmware-virtual-disk-space-optimization/</link>
        <pubDate>Wed, 21 Jun 2023 18:35:41 +0800</pubDate>
        
        <guid>https://ttf248.life/p/vmware-virtual-disk-space-optimization/</guid>
        <description>&lt;p&gt;&lt;code&gt;vmware&lt;/code&gt;虚拟机安装开发系统的时候，一般都会多预留点磁盘空间，用的时间长了，本地占用的磁盘空间远超虚拟机实际文件的内容。&lt;/p&gt;
&lt;h2 id=&#34;场景描述&#34;&gt;场景描述
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;df -h&lt;/code&gt;命令，查看当前机器的磁盘信息，实际用了 60G，删掉所有的快照和克隆镜像，本地虚拟机占用的磁盘空间依旧远大于 60G，让本就不富裕的硬盘，雪上加霜。&lt;/p&gt;
&lt;h2 id=&#34;前置条件&#34;&gt;前置条件
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;虚拟机安装的时候，没有勾选预分配磁盘&lt;/li&gt;
&lt;li&gt;本地存放虚拟机的硬盘，剩余的磁盘空间大于当前虚拟机所占用的空间&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;剩余的空间不足，可以考虑临时移动虚拟机到移动硬盘，优化了磁盘以后再迁移回来。&lt;/p&gt;
&lt;h2 id=&#34;工具&#34;&gt;工具
&lt;/h2&gt;&lt;p&gt;官方提供了&lt;code&gt;open-vm-tools&lt;/code&gt;包，可以通过 yum 安装或者 vmware-tools 镜像包安装&lt;/p&gt;
&lt;h2 id=&#34;命令&#34;&gt;命令
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;vmware-toolbox-cmd disk shrink /
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;执行了以后，虚拟机会自动关机，vmware 宿主程序会执行磁盘压缩，执行时间取决于虚拟机的体积和磁盘的访问速度。&lt;/p&gt;
&lt;p&gt;执行效果还是很不错的，虚拟机的磁盘空间占用基本等于&lt;code&gt;df -h&lt;/code&gt;的磁盘信息。&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

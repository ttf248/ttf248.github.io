<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>软件测试 on 向叔记事簿</title>
        <link>https://ttf248.life/tags/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/</link>
        <description>Recent content in 软件测试 on 向叔记事簿</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <lastBuildDate>Thu, 29 Jan 2026 22:52:12 +0800</lastBuildDate><atom:link href="https://ttf248.life/tags/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>wrk 与 JMeter 的深度较量</title>
        <link>https://ttf248.life/p/wrk-vs-jmeter-deep-benchmarking/</link>
        <pubDate>Fri, 19 Dec 2025 01:14:49 +0800</pubDate>
        
        <guid>https://ttf248.life/p/wrk-vs-jmeter-deep-benchmarking/</guid>
        <description>&lt;p&gt;在互联网系统的压力测试中，我们经常会遇到两款风格迥异的工具：一个是极其轻量、追求极致吞吐量的 wrk；另一个是功能大而全、模拟真实业务流的 JMeter。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;提示词：梳理核心思路，撰写科普文章：http 压力测试工具，wrk vs Jmeter 有什么不同，我了解到的，wrk 倾向于 一个线程多个 connect 进行测试，Jmeter 更多是短连接模式，能通过配置调整为长联机&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;核心架构多线程-vs-事件驱动&#34;&gt;核心架构：多线程 vs 事件驱动
&lt;/h2&gt;&lt;p&gt;这是两者性能差距的根本原因。&lt;/p&gt;
&lt;h3 id=&#34;1-jmeter传统的一人一岗制-thread-per-request&#34;&gt;1. JMeter：传统的“一人一岗”制 (Thread-per-Request)
&lt;/h3&gt;&lt;p&gt;JMeter 基于 Java 开发，采用的是经典的&lt;strong&gt;多线程模型&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;逻辑：&lt;/strong&gt; 每一个并发用户（Virtual User）都对应 JVM 中的一个物理线程。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;代价：&lt;/strong&gt; 线程是非常昂贵的资源。当并发数达到几千时，上下文切换（Context Switch）和内存消耗会显著拖慢测试机本身，导致“压测机还没把服务器压死，自己先崩了”的现象。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-wrk现代的多面手制-event-driven&#34;&gt;2. wrk：现代的“多面手”制 (Event-driven)
&lt;/h3&gt;&lt;p&gt;wrk 采用 C 语言编写，核心逻辑基于 Redis 同款的 &lt;code&gt;ae&lt;/code&gt; 事件循环框架（利用 &lt;code&gt;epoll/kqueue&lt;/code&gt;）。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;逻辑：&lt;/strong&gt; wrk 并不为每个连接创建线程。它只启动极少数的线程（通常等于你的 CPU 核心数），每个线程内部通过&lt;strong&gt;非阻塞 I/O&lt;/strong&gt; 同时管理成千上万个连接。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优势：&lt;/strong&gt; 这就是你提到的“一个线程多个 connection”。它极大地减少了线程切换开销，单机即可跑出百万级别的 RPS（每秒请求数）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;连接模型短连接-vs-长连接&#34;&gt;连接模型：短连接 vs 长连接
&lt;/h2&gt;&lt;p&gt;关于你提到的连接模式，这里有更深层的细节：&lt;/p&gt;
&lt;h3 id=&#34;1-jmeter-的重与灵&#34;&gt;1. JMeter 的“重”与“灵”
&lt;/h3&gt;&lt;p&gt;JMeter 默认确实更倾向于模拟真实用户的行为。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;短连接倾向：&lt;/strong&gt; 在默认配置下，JMeter 的某些旧版本或特定配置可能不会积极复用连接，导致大量的 TCP 握手。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可调校性：&lt;/strong&gt; 你可以通过在 &lt;code&gt;HTTP Request&lt;/code&gt; 中勾选 &lt;strong&gt;&amp;ldquo;KeepAlive&amp;rdquo;&lt;/strong&gt;，或者在 &lt;code&gt;user.properties&lt;/code&gt; 中调整连接池参数来开启长连接。但即便是长连接，受限于线程模型，它也难以维持数十万级别的并发长连接。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-wrk-的快与狠&#34;&gt;2. wrk 的“快”与“狠”
&lt;/h3&gt;&lt;p&gt;wrk 设计的初衷就是为了测试 &lt;strong&gt;HTTP Keep-Alive&lt;/strong&gt; 的性能。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;长连接策略：&lt;/strong&gt; wrk 在测试开始时会建立好指定的连接数（&lt;code&gt;-c&lt;/code&gt; 参数），并在整个测试过程中尽可能复用这些连接。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;应用场景：&lt;/strong&gt; 它非常适合测试 Nginx、网关（Gateway）或高并发 API 在极端长连接压力下的吞吐极限。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;深度对比表&#34;&gt;深度对比表
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;特性&lt;/th&gt;
&lt;th&gt;wrk&lt;/th&gt;
&lt;th&gt;Apache JMeter&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;开发语言&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;C / Lua (脚本)&lt;/td&gt;
&lt;td&gt;Java (GUI)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;并发模型&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;事件驱动 (epoll/kqueue)&lt;/td&gt;
&lt;td&gt;多线程 (Thread-per-user)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;资源消耗&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;极低，单机吞吐量巨大&lt;/td&gt;
&lt;td&gt;较高，大并发需分布式集群&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;业务复杂度&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;较低，主要针对单个 URL&lt;/td&gt;
&lt;td&gt;极高，支持多步脚本、断言、提取器&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;测试场景&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;静态 API 压测、容量评估&lt;/td&gt;
&lt;td&gt;复杂业务链路、功能回归压测&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;报表能力&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;仅文本摘要&lt;/td&gt;
&lt;td&gt;极丰富，支持各类图表和 HTML 报告&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;总结我该选哪一个&#34;&gt;总结：我该选哪一个？
&lt;/h2&gt;&lt;p&gt;这两款工具并不是替代关系，而是互补关系：&lt;/p&gt;
&lt;h3 id=&#34;选-wrk&#34;&gt;选 wrk
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;想要测试服务器的&lt;strong&gt;极限吞吐量&lt;/strong&gt;（RPS）。&lt;/li&gt;
&lt;li&gt;测试对象是单一的 API 或静态资源。&lt;/li&gt;
&lt;li&gt;希望用最少的测试服务器压出最大的流量。&lt;/li&gt;
&lt;li&gt;熟悉 Lua 脚本来定制化请求。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;选-jmeter&#34;&gt;选 JMeter
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;需要模拟&lt;strong&gt;复杂的业务流程&lt;/strong&gt;（如：登录 -&amp;gt; 搜商品 -&amp;gt; 下单 -&amp;gt; 支付）。&lt;/li&gt;
&lt;li&gt;需要可视化的界面来观察响应时间分布、错误率等详细指标。&lt;/li&gt;
&lt;li&gt;测试需要处理动态参数（如从上一个接口提取 Token 传递给下一个接口）。&lt;/li&gt;
&lt;li&gt;团队更习惯使用图形化工具而非命令行。&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>浅谈自动化测试</title>
        <link>https://ttf248.life/p/automated-testing-overview/</link>
        <pubDate>Thu, 04 Aug 2022 11:39:18 +0800</pubDate>
        
        <guid>https://ttf248.life/p/automated-testing-overview/</guid>
        <description>&lt;p&gt;金融交易系统在测试上的投入，远超其他系统，繁琐的测试步骤重复进行，&lt;code&gt;ROI&lt;/code&gt; 太低。随着项目和人员的更替，不可避免引入更多的不可控因素，常见的情况，修改的是A接口输出的某个字段，却影响了B接口的结果，每次版本发布，风险也在积累。&lt;/p&gt;
&lt;h2 id=&#34;理论知识&#34;&gt;理论知识
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;如何衡量自动化的价值？&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一个自动化测试案例ROI = （手工运行时间）*（运行次数）/ (开发成本 + 维护成本)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;哪些功能需要做自动化测试？&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用户常用的功能，不会经常改变的功能。针对此类型的接口编写自动化测试代码，收益最高。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;为什么选择这个时间点推动自动化测试？&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;临近项目上线，肯定不合适，远水解不了近渴，自动化属于长期收益模型。项目已经在&lt;strong&gt;生产环境&lt;/strong&gt;上线，进入稳定发布周期，此时最为合适。&lt;/p&gt;
&lt;h2 id=&#34;框架的选择&#34;&gt;框架的选择
&lt;/h2&gt;&lt;p&gt;缺乏相关实践经验的情况下，拿到自动化测试这么一个任务，常规开局：打开搜索引擎，寻找当前系统&lt;strong&gt;技术栈&lt;/strong&gt;能用上的工具和框架，过一遍使用手册，开工大吉。能立马找个合适的工具，恭喜你，&lt;strong&gt;完美开局&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;先说一声我错了，翻查了相关的资料，不是说没有，而是框架本身太复杂了，部署占用的资源也过多。小白入门需要的是小巧的，精简的，咨询测试组的同事，提到了 &lt;code&gt;Python&lt;/code&gt; 自建框架，简单来说就是用现有的单元测试框架，封装成自动测试框架。&lt;/p&gt;
&lt;p&gt;参考此项目的设计思路：&lt;a class=&#34;link&#34; href=&#34;https://github.com/wintests/pytestDemo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/wintests/pytestDemo&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;为什么需要框架&#34;&gt;为什么需要框架？
&lt;/h2&gt;&lt;p&gt;服务有多个不同的部署环境，开发环境、测试环境、线上测试环境，框架的作用在于做一层剥离，测试案例和数据进行分离，按照不同的环境配置不同的案例数据，当然也支持公用的数据。&lt;/p&gt;
&lt;p&gt;核心的逻辑都是为了提高自动化的利用率。场景再复杂一些，不同环境之间的数据就是不通的，完全没有任何关系，配置案例数据的时候，增加 &lt;code&gt;label&lt;/code&gt; 标签即可，指定当前数据支持的环境。&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://time.geekbang.org/column/article/496850&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;做性价比最高的自动化测试&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

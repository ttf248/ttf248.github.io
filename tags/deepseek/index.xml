<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>deepseek on 向叔记事簿</title>
        <link>https://ttf248.life/tags/deepseek/</link>
        <description>Recent content in deepseek on 向叔记事簿</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language><atom:link href="https://ttf248.life/tags/deepseek/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>ollama 本地部署 deepseek-R1</title>
        <link>https://ttf248.life/p/ollama-%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2-deepseek-r1/</link>
        <pubDate>Fri, 07 Feb 2025 22:41:02 +0800</pubDate>
        
        <guid>https://ttf248.life/p/ollama-%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2-deepseek-r1/</guid>
        <description>&lt;p&gt;Ollama 是一个开源的 AI 工具，旨在使用户能够本地运行和部署大型语言模型（LLM）。它的目标是提供一个方便且高效的方式，让开发者可以在本地机器上使用像 GPT 这样的模型，而不需要依赖云端服务。Ollama 支持多种模型，并且专注于优化性能，使得即使是资源有限的设备也能顺畅运行这些模型。&lt;/p&gt;
&lt;p&gt;通过 Ollama，用户可以使用基于文本的 AI 应用程序，并能够与本地部署的模型进行交互，而无需担心数据隐私或是高昂的 API 使用费用。你可以通过命令行界面（CLI）调用不同的模型，进行自然语言处理、问答等任务。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ollama 适合不同模型尝鲜，windows 版本测试下来，无法充分发挥硬件的性能，可能是因为 windows 版本的原因，linux 版本可能会更好。部署32b参数的模型，内存、显卡负载都有不高的情况下，回复速度很慢。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;硬件概述&#34;&gt;硬件概述
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;操作系统：win11&lt;/li&gt;
&lt;li&gt;CPU：i7-10700K&lt;/li&gt;
&lt;li&gt;内存：40GB&lt;/li&gt;
&lt;li&gt;显卡：RTX 3060 12GB&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;环境准备&#34;&gt;环境准备
&lt;/h2&gt;&lt;p&gt;新增系统环境变量，方便后续使用：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_MODELS=E:\ollama&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
这个变量指定了 Ollama 模型的存放路径。&lt;code&gt;E:\ollama&lt;/code&gt; 是一个文件夹路径，表示所有本地模型文件都存储在该目录下。Ollama 会根据这个路径加载和使用你下载或部署的语言模型。你可以将模型文件存放在其他位置，只需要更改这个路径。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_HOST=127.0.0.1:8000&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
这个环境变量设置了 Ollama 服务的主机和端口。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;127.0.0.1&lt;/code&gt; 是本地地址（localhost），意味着 Ollama 服务会只监听来自本机的请求。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;8000&lt;/code&gt; 是指定的端口号，表示 Ollama 服务将在 8000 端口上等待和处理请求。你可以根据需要更改端口号，但需要确保该端口没有被其他应用占用。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_ORIGINS=*&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
这个环境变量控制允许哪些来源的请求访问 Ollama 服务。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;*&lt;/code&gt; 表示允许任何来源（即所有域名和 IP 地址）都可以访问 Ollama 服务。这通常用于开发和调试环境，在生产环境中，通常会指定更严格的来源控制，限制只有特定的域或 IP 才能访问你的服务，以提高安全性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;deepseek-r1-模型部署&#34;&gt;deepseek-R1 模型部署
&lt;/h2&gt;&lt;p&gt;ollama 安装属于傻瓜式，此处不在赘述。&lt;/p&gt;
&lt;p&gt;安装后的校验：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core&amp;gt;ollama -v
ollama version is 0.5.11
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;模型部署，参考官网模型页面，选择对应参数的模型：&lt;code&gt;ollama run deepseek-r1:14b&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;14b 参数能有效的记住会话上下文，更小的参数版本，无法记住会话上下文。32b 参数版本，本机部署很卡顿，没有再深入进行测试。&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ollama.com/library/deepseek-r1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.ollama.com/library/deepseek-r1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/x18990027/article/details/145368094&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/x18990027/article/details/145368094&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>DeepSeek 春节前突然爆火，英伟达股票暴跌：背后的机构操作与大模型思维链</title>
        <link>https://ttf248.life/p/deepseek-%E6%98%A5%E8%8A%82%E5%89%8D%E7%AA%81%E7%84%B6%E7%88%86%E7%81%AB%E8%8B%B1%E4%BC%9F%E8%BE%BE%E8%82%A1%E7%A5%A8%E6%9A%B4%E8%B7%8C%E8%83%8C%E5%90%8E%E7%9A%84%E6%9C%BA%E6%9E%84%E6%93%8D%E4%BD%9C%E4%B8%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%80%9D%E7%BB%B4%E9%93%BE/</link>
        <pubDate>Fri, 07 Feb 2025 20:36:05 +0800</pubDate>
        
        <guid>https://ttf248.life/p/deepseek-%E6%98%A5%E8%8A%82%E5%89%8D%E7%AA%81%E7%84%B6%E7%88%86%E7%81%AB%E8%8B%B1%E4%BC%9F%E8%BE%BE%E8%82%A1%E7%A5%A8%E6%9A%B4%E8%B7%8C%E8%83%8C%E5%90%8E%E7%9A%84%E6%9C%BA%E6%9E%84%E6%93%8D%E4%BD%9C%E4%B8%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%80%9D%E7%BB%B4%E9%93%BE/</guid>
        <description>&lt;p&gt;春节前夕，DeepSeek 一度成为热议话题，短短几天内便在社交媒体上引起了广泛关注。这种突然的爆火，不仅让人惊讶，还带动了市场的连锁反应。与此同时，英伟达的股票却迎来了暴跌，许多投资者对其前景产生了疑虑，部分机构在此期间进行了大规模的做空操作，似乎一切都指向了一个“精心策划”的局面。&lt;/p&gt;
&lt;h3 id=&#34;deepseek-的爆火短时间内迅速成为焦点&#34;&gt;&lt;strong&gt;DeepSeek 的爆火：短时间内迅速成为焦点&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;DeepSeek 是一个基于 AI 的工具，专注于对深度学习模型的优化，尤其是在自然语言处理（NLP）和图像生成领域的应用。春节前的几天，这个项目突然间受到大量投资者和技术从业者的关注。其背后团队的表现以及所展示的技术成果，让许多人对这个项目产生了强烈的兴趣。无论是在开发者社区，还是社交媒体平台上，关于 DeepSeek 的讨论几乎占据了技术圈的所有话题。&lt;/p&gt;
&lt;p&gt;然而，DeepSeek 的突然爆火并非偶然。经过分析，很多人开始怀疑这背后可能涉及到了某些机构的操作。尤其是在其爆火之后，英伟达股价出现了明显的下跌，显然有一些因素在推动着这一变化。&lt;/p&gt;
&lt;h3 id=&#34;英伟达股票暴跌做空操作的幕后推手&#34;&gt;&lt;strong&gt;英伟达股票暴跌：做空操作的幕后推手&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;英伟达，这家全球领先的图形处理单元（GPU）制造商，一直以来是许多大模型和 AI 计算的关键硬件提供商。随着 AI 市场的快速发展，英伟达的股票长期以来表现强劲，甚至成为了许多投资者青睐的对象。然而，随着 DeepSeek 的爆火和市场对其技术的高度关注，英伟达股票却迎来了暴跌。&lt;/p&gt;
&lt;p&gt;这一现象的背后，或许涉及到了机构投资者的做空策略。在过去几年中，随着 AI 技术的普及，英伟达的股价已被高度推高，很多投资者开始认为其股价存在过度炒作的风险。尤其是在 DeepSeek 这样的技术爆火之后，一些机构可能通过做空英伟达的股票，获得了可观的利润。通过精确的市场时机把握和对 DeepSeek 影响力的预判，这些机构成功地从中获利。&lt;/p&gt;
&lt;h3 id=&#34;大模型思维链的接触从结果到过程&#34;&gt;&lt;strong&gt;大模型思维链的接触：从“结果”到“过程”&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;在传统的人工智能应用中，许多从业者和投资者更多关注的是 AI 模型的“结果”——例如生成的图片、文本等直接的产出。而在与 DeepSeek 相关的讨论中，越来越多的人开始意识到，大模型背后所隐藏的思维链才是更值得关注的核心内容。过去，我们只能看到模型输出的结果，但现在，我们更需要去理解其背后的逻辑、算法以及如何通过调整这些因素来优化模型的表现。&lt;/p&gt;
&lt;p&gt;这种思维方式的转变，实际上是对 AI 研究和应用的一种深入思考。从简单的黑箱操作，到真正理解模型内部运作机制的转变，让许多技术人员和投资者都开始重新审视人工智能的未来发展方向。DeepSeek 的火爆，恰恰是这一思维链的突破性应用，它让人们开始关注整个模型的构建和优化过程，而不仅仅是最终的输出结果。&lt;/p&gt;
&lt;h3 id=&#34;总结&#34;&gt;&lt;strong&gt;总结&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;DeepSeek 的突然爆火，英伟达股票的暴跌，以及市场背后机构的做空操作，这一切背后似乎都是一个精心设计的局。通过对大模型思维链的深入理解，我们可以看到，AI 技术的应用不仅仅是表面现象的堆砌，更是对模型内部逻辑的深入挖掘和优化。随着技术的进步，未来我们或许将看到更多类似 DeepSeek 这样的创新工具，推动 AI 研究和应用向更高层次发展。&lt;/p&gt;
&lt;p&gt;这种现象不仅让我们看到了 AI 技术的巨大潜力，也促使我们开始思考技术背后的商业博弈和资本运作。接下来的市场走势如何，将会是技术与资本博弈的持续焦点。&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

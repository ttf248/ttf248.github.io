<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>性能优化 on 向叔记事簿</title>
        <link>https://ttf248.life/tags/performance-optimization/</link>
        <description>Recent content in 性能优化 on 向叔记事簿</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language><atom:link href="https://ttf248.life/tags/performance-optimization/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>linux后端服务处理大量字符串数据-效率很慢</title>
        <link>https://ttf248.life/p/linux-backend-slow-string-processing/</link>
        <pubDate>Wed, 13 Nov 2024 19:42:59 +0800</pubDate>
        
        <guid>https://ttf248.life/p/linux-backend-slow-string-processing/</guid>
        <description>&lt;p&gt;在C++开发的历史项目中，我们使用自定义协议进行通信，协议采用了二维数组的模式。在处理大量数据时，协议内部需要遍历数组并进行序列化操作以生成日志，由于效率较低，导致了系统在高负载下出现明显的卡顿，业务部门反馈系统卡顿。&lt;/p&gt;
&lt;h2 id=&#34;问题定位&#34;&gt;问题定位
&lt;/h2&gt;&lt;p&gt;在排查问题时，我们首先对系统进行了性能分析，发现系统在处理大量数据时，CPU 占用率明显增加，且系统响应时间变长。通过分析系统的日志，我们发现了大量的序列化操作，这些操作在处理二维数组时效率较低，导致了系统性能下降。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pstack&lt;/code&gt;工具截取服务的线程信息，定位到日志线程大部分时间都在处理字符串的拼接。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这里是今天的重点，不同的累加方式，效率差别巨大。历史代码中使用的是 &lt;code&gt;+&lt;/code&gt; 运算符，这种方式会频繁的创建临时对象，效率很低。你知道它效率很差，但你不知道它效率有多差的那种。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;demo-验证&#34;&gt;demo 验证
&lt;/h2&gt;&lt;p&gt;基于项目代码，我们抽离业务逻辑，编写了一个简单的 demo，用于验证字符串拼接的效率问题。&lt;code&gt;windows&lt;/code&gt; 下的 &lt;code&gt;vs2022&lt;/code&gt; 编译器，&lt;code&gt;linux&lt;/code&gt; 下的 &lt;code&gt;gcc8.5&lt;/code&gt; 编译器，&lt;code&gt;Release&lt;/code&gt;模式下编译运行，对比效率。&lt;/p&gt;
&lt;h3 id=&#34;关键点说明&#34;&gt;关键点说明
&lt;/h3&gt;&lt;p&gt;项目使用的是方法四，在尚未拿到测试数据的时候，读者可以先思考一下，哪种方式效率最高？哪种方式效率最低？看到结果的时候，我还是很惊讶的。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;方法 1 (&lt;code&gt;+=&lt;/code&gt; 拼接)&lt;/strong&gt;：直接通过 &lt;code&gt;+=&lt;/code&gt; 将每个字段拼接到字符串中。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;方法 2 (&lt;code&gt;std::ostringstream&lt;/code&gt; 拼接)&lt;/strong&gt;：使用流（&lt;code&gt;std::ostringstream&lt;/code&gt;）来拼接每个字段，这种方法更高效，特别是对于大量数据拼接时。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;方法 3（预分配内存的 &lt;code&gt;+=&lt;/code&gt; 拼接）&lt;/strong&gt;：通过 &lt;code&gt;reserve&lt;/code&gt; 提前为字符串分配足够的内存，减少了内存重新分配的开销，从而提升了性能。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;方法 4 (&lt;code&gt;bodys = bodys + body + &amp;quot;\n&amp;quot;&lt;/code&gt;)&lt;/strong&gt;：每次拼接都创建一个新的临时字符串对象，这会导致性能下降，尤其是在大规模拼接时，因为每次拼接都会涉及一次新的内存分配和复制。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;参考结果，我们可以看到，项目刚好选中了效率最差的方式。&lt;/p&gt;
&lt;p&gt;再进一步，我们来分析不同平台编译器的优化效率，微软的 &lt;code&gt;visual studio&lt;/code&gt; 一如既往的优秀，针对字符串的优化效率很高，而 &lt;code&gt;gcc&lt;/code&gt; 编译器在这方面的优化效率就差了一些。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;代码在不同的机器执行，两份数据没有直接的对比意义，可以分别对比不同拼接方法之间的差值。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;windows 平台下的 vs2022 编译器

----------------------------------------
Data Generation Time: 0.054 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.053 seconds.
+ ostringstream Data merging took: 0.054 seconds.
+ Pre-reserved Data merging took: 0.045 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 16.108 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;linux 平台下的 gcc8.5 编译器
----------------------------------------
Data Generation Time: 0.108 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.100 seconds.
+ ostringstream Data merging took: 0.083 seconds.
+ Pre-reserved Data merging took: 0.057 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 29.298 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;完整代码&#34;&gt;完整代码
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;random&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;sstream&amp;gt;
#include &amp;lt;iomanip&amp;gt;

typedef std::vector&amp;lt;std::string&amp;gt; DataRow;
typedef std::vector&amp;lt;DataRow&amp;gt; DataGroup;

struct ResponsePackage
{
    std::string ErrorInfo;
    DataRow Head;
    std::string ClientId;
    std::string UUID;
    std::string MsgID;
    std::string SessionID;
    std::string ExtraInfo1;
    std::string ExtraInfo2;
    DataGroup DataBody;
};

// Generate specified length of random string
std::string generateRandomString(size_t length)
{
    const char charset[] = &amp;quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&amp;quot;;
    const size_t max_index = sizeof(charset) - 1;
    std::string random_string;
    random_string.reserve(length);

    std::random_device rd;
    std::mt19937 generator(rd());
    std::uniform_int_distribution&amp;lt;&amp;gt; distribution(0, max_index);

    for (size_t i = 0; i &amp;lt; length; ++i)
    {
        random_string += charset[distribution(generator)];
    }

    return random_string;
}

void create_large_string()
{
    // Example request package with 50 fields
    ResponsePackage requestPackage;

    requestPackage.Head = {
        &amp;quot;Field1&amp;quot;, &amp;quot;Field2&amp;quot;, &amp;quot;Field3&amp;quot;, &amp;quot;Field4&amp;quot;, &amp;quot;Field5&amp;quot;,
        &amp;quot;Field6&amp;quot;, &amp;quot;Field7&amp;quot;, &amp;quot;Field8&amp;quot;, &amp;quot;Field9&amp;quot;, &amp;quot;Field10&amp;quot;,
        &amp;quot;Field11&amp;quot;, &amp;quot;Field12&amp;quot;, &amp;quot;Field13&amp;quot;, &amp;quot;Field14&amp;quot;, &amp;quot;Field15&amp;quot;,
        &amp;quot;Field16&amp;quot;, &amp;quot;Field17&amp;quot;, &amp;quot;Field18&amp;quot;, &amp;quot;Field19&amp;quot;, &amp;quot;Field20&amp;quot;,
        &amp;quot;Field21&amp;quot;, &amp;quot;Field22&amp;quot;, &amp;quot;Field23&amp;quot;, &amp;quot;Field24&amp;quot;, &amp;quot;Field25&amp;quot;,
        &amp;quot;Field26&amp;quot;, &amp;quot;Field27&amp;quot;, &amp;quot;Field28&amp;quot;, &amp;quot;Field29&amp;quot;, &amp;quot;Field30&amp;quot;,
        &amp;quot;Field31&amp;quot;, &amp;quot;Field32&amp;quot;, &amp;quot;Field33&amp;quot;, &amp;quot;Field34&amp;quot;, &amp;quot;Field35&amp;quot;,
        &amp;quot;Field36&amp;quot;, &amp;quot;Field37&amp;quot;, &amp;quot;Field38&amp;quot;, &amp;quot;Field39&amp;quot;, &amp;quot;Field40&amp;quot;,
        &amp;quot;Field41&amp;quot;, &amp;quot;Field42&amp;quot;, &amp;quot;Field43&amp;quot;, &amp;quot;Field44&amp;quot;, &amp;quot;Field45&amp;quot;,
        &amp;quot;Field46&amp;quot;, &amp;quot;Field47&amp;quot;, &amp;quot;Field48&amp;quot;, &amp;quot;Field49&amp;quot;, &amp;quot;Field50&amp;quot;
    };

    requestPackage.ClientId = &amp;quot;ClientID&amp;quot;;
    requestPackage.UUID = &amp;quot;UUID&amp;quot;;
    requestPackage.MsgID = &amp;quot;MsgID&amp;quot;;
    requestPackage.SessionID = &amp;quot;SessionID&amp;quot;;
    requestPackage.ExtraInfo1 = &amp;quot;ExtraInfo1&amp;quot;;
    requestPackage.ExtraInfo2 = &amp;quot;ExtraInfo2&amp;quot;;

    // Start timing for data generation
    auto start_gen = std::chrono::high_resolution_clock::now();

    // Generate 10,000 rows of data, each with 50 fields
    for (size_t i = 0; i &amp;lt; 10000; ++i)
    {
        DataRow dataRow(50, &amp;quot;This is a test string&amp;quot;);
        requestPackage.DataBody.push_back(dataRow);
    }

    // End timing for data generation
    auto end_gen = std::chrono::high_resolution_clock::now();
    std::chrono::duration&amp;lt;double&amp;gt; duration_gen = end_gen - start_gen;

    // Display result generation time
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Generation Time: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_gen.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    // Data merging using different methods
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Performance:\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    {
        // Method 1: Using &#39;+=&#39; string concatenation
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys(&amp;quot;&amp;quot;);
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (+=) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 2: Using ostringstream
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::ostringstream bodys;
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::ostringstream body;
            body &amp;lt;&amp;lt; &amp;quot;This is a test string&amp;quot;;
            for (auto&amp;amp; item : vec)
            {
                body &amp;lt;&amp;lt; item &amp;lt;&amp;lt; &amp;quot; &amp;quot;;
            }
            bodys &amp;lt;&amp;lt; body.str() &amp;lt;&amp;lt; &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ ostringstream Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 3: Pre-allocated memory
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys;
        bodys.reserve(1000 * 50 * 20); // Pre-allocate enough memory
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            body.reserve(50 * 20); // Pre-allocate memory for each row
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Pre-reserved Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 4: Using &#39;bodys = bodys + body + &amp;quot;\n&amp;quot;&#39;
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys(&amp;quot;&amp;quot;);
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            for (auto&amp;amp; item : vec)
            {
                body = body + item + &amp;quot; &amp;quot;; // Note the use of &#39;body = body + item&#39;
            }
            bodys = bodys + body + &amp;quot;\n&amp;quot;; // Again, using &#39;bodys = bodys + body&#39;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (bodys = bodys + body + \&amp;quot;\\n\&amp;quot;) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Complete.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;
}

int main()
{
    try
    {
        create_large_string();
    }
    catch (const std::exception&amp;amp; e)
    {
        std::cerr &amp;lt;&amp;lt; &amp;quot;Caught exception: &amp;quot; &amp;lt;&amp;lt; e.what() &amp;lt;&amp;lt; std::endl;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\nProgram finished.\n&amp;quot;;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>WPF中的UI线程与卡顿问题及其解决方案</title>
        <link>https://ttf248.life/p/wpf-ui-thread-and-freezing-solutions/</link>
        <pubDate>Tue, 12 Mar 2024 07:12:21 +0800</pubDate>
        
        <guid>https://ttf248.life/p/wpf-ui-thread-and-freezing-solutions/</guid>
        <description>&lt;p&gt;在开发桌面应用程序时，特别是在使用Windows Presentation Foundation (WPF)框架构建富客户端应用时，正确处理用户界面（UI）线程对于保证应用的流畅性和响应性至关重要。UI线程，又称为主线程，是负责处理窗口和控件事件、布局计算以及绘制界面的核心线程。任何与UI元素交互的操作都应当在UI线程上执行，这是WPF以及其他大多数GUI框架遵循的基本原则。&lt;/p&gt;
&lt;h2 id=&#34;什么是ui线程&#34;&gt;什么是UI线程？
&lt;/h2&gt;&lt;p&gt;UI线程在WPF应用启动时由操作系统创建，并初始化应用程序主窗口。它是应用程序中唯一能够直接访问和修改UI组件的状态的线程。这意味着诸如按钮点击、文本框输入、窗口尺寸变化等所有用户交互产生的事件都在这个线程上下文中处理。同时，WPF的依赖属性系统、数据绑定机制以及布局逻辑也都在UI线程上同步执行。&lt;/p&gt;
&lt;h2 id=&#34;卡顿现象及其原因&#34;&gt;卡顿现象及其原因
&lt;/h2&gt;&lt;p&gt;当UI线程被长时间占用或阻塞时，例如执行耗时的计算、大量数据加载、数据库查询或其他I/O密集型任务时，会导致UI线程无法及时响应用户的交互请求，进而表现为界面无响应（Freeze），也就是我们常说的“卡顿”。这种情况下，用户会明显感觉到应用的延迟和不流畅，严重时甚至会出现“Application Not Responding”（ANR）警告。&lt;/p&gt;
&lt;h2 id=&#34;ui线程的两条基本规则&#34;&gt;UI线程的两条基本规则
&lt;/h2&gt;&lt;p&gt;为了避免上述情况的发生，WPF开发者应遵循以下两条关键规则：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;不要在UI线程上执行耗时操作&lt;/strong&gt;：任何可能导致UI线程挂起的操作都应尽可能地移至后台线程执行，以确保UI线程能及时响应用户的输入和渲染屏幕的变化。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;不要在非UI线程直接更新UI元素&lt;/strong&gt;：由于WPF的安全机制设计，只有UI线程有权对UI元素进行修改。试图从其他线程直接更改UI状态将会抛出异常。因此，即使在后台线程完成了计算或数据准备，也需要通过适当的跨线程通信机制将结果显示到UI上。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;解决方案异步编程与线程安全更新&#34;&gt;解决方案：异步编程与线程安全更新
&lt;/h2&gt;&lt;p&gt;为了在保持UI流畅的同时又能执行耗时任务，WPF提供了多种异步编程模型和工具来协助开发者实现这一目标：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Dispatcher对象&lt;/strong&gt;：WPF的Dispatcher类允许你将工作项安排到UI线程的任务队列中执行。你可以使用&lt;code&gt;Dispatcher.Invoke&lt;/code&gt;或&lt;code&gt;Dispatcher.BeginInvoke&lt;/code&gt;方法从后台线程安全地更新UI。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;async/await关键字&lt;/strong&gt;：利用C#语言的异步特性，可以编写异步方法并在其中使用&lt;code&gt;await&lt;/code&gt;关键字等待后台任务完成，完成后自动回到UI线程执行后续的UI更新代码。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;案例&#34;&gt;案例
&lt;/h2&gt;&lt;h3 id=&#34;使用dispatcherinvoke方法更新ui&#34;&gt;使用&lt;code&gt;Dispatcher.Invoke&lt;/code&gt;方法更新UI
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;private void Button_Click(object sender, RoutedEventArgs e)
{
    // 假设这是一个耗时操作
    Task.Run(() =&amp;gt;
    {
        var result = LongRunningOperation(); // 这里是模拟一个耗时计算的方法
        
        // 当耗时操作完成后，在UI线程上更新UI
        Application.Current.Dispatcher.Invoke(() =&amp;gt;
        {
            LabelStatus.Text = $&amp;quot;计算结果: {result}&amp;quot;;
        });
    });
}

private string LongRunningOperation()
{
    // 模拟耗时操作
    Thread.Sleep(5000);
    return &amp;quot;已完成&amp;quot;;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;使用asyncawait关键字配合taskrun&#34;&gt;使用&lt;code&gt;async/await&lt;/code&gt;关键字配合&lt;code&gt;Task.Run&lt;/code&gt;
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;private async void Button_ClickAsync(object sender, RoutedEventArgs e)
{
    Button button = sender as Button;
    button.IsEnabled = false; // 防止用户重复点击

    try
    {
        // 开启后台任务
        var result = await Task.Run(() =&amp;gt; LongRunningOperation());

        // 在后台任务完成后，自动切换回UI线程更新UI
        LabelStatus.Text = $&amp;quot;计算结果: {result}&amp;quot;;
    }
    catch (Exception ex)
    {
        MessageBox.Show($&amp;quot;发生错误: {ex.Message}&amp;quot;);
    }
    finally
    {
        button.IsEnabled = true; // 重新启用按钮
    }
}
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>vmware虚拟机cpu资源占用异常</title>
        <link>https://ttf248.life/p/vmware-virtual-machine-cpu-usage-anomaly/</link>
        <pubDate>Sun, 10 Mar 2024 22:14:59 +0800</pubDate>
        
        <guid>https://ttf248.life/p/vmware-virtual-machine-cpu-usage-anomaly/</guid>
        <description>&lt;p&gt;背景：本地机器部署 windows 版本的业务系统，cpu 资源占用 5% 左右。vmware安装的 centos8 中部署 linux 版本业务系统，资源占用异常。&lt;/p&gt;
&lt;h2 id=&#34;问题描述&#34;&gt;问题描述
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;宿主机：win10 企业版&lt;/li&gt;
&lt;li&gt;vmware：17.5&lt;/li&gt;
&lt;li&gt;虚拟机：centos8&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;虚拟机资源分配为&lt;code&gt;4C8GB&lt;/code&gt;，启动业务系统。业务系统部署在虚拟机Linux系统中，虚拟机内部 top 命令观察系统资源占用，cpu 占用并不高，外层 windows 系统，任务管理器观察到的CPU资源占用很高，查看进程发现，vmware 进程占用CPU资源很高。&lt;/p&gt;
&lt;p&gt;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+
|         Windows           |
|                           |
|   +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+  |
|   |      VMware        |  |
|   |      Program       |  |
|   +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+  |
|                           |
+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&lt;/p&gt;
&lt;h2 id=&#34;知识点&#34;&gt;知识点
&lt;/h2&gt;&lt;p&gt;此问题的排查，并不顺利，由于导火索并不是业务系统本身，而是虚拟机本身的问题。如何将思路从常规的业务代码转移到系统负载，再从负载数据的异常，定位到软中断，最后来到关键点，什么东西会影响 Vmware 软中断的工作效率？本文将先科普各个知识点，最后给出解决方案。&lt;/p&gt;
&lt;h3 id=&#34;hyper-v&#34;&gt;hyper-v
&lt;/h3&gt;&lt;p&gt;Windows操作系统的虚拟化技术经历了一次重大变革。在微软首次发布WSL时，启用Hyper-V服务会导致无法同时使用VMware虚拟机。直到后续版本，VMware才能与Hyper-V服务兼容。&lt;/p&gt;
&lt;h3 id=&#34;系统负载&#34;&gt;系统负载
&lt;/h3&gt;&lt;p&gt;在Linux系统中，&amp;ldquo;负载&amp;rdquo;（load）是指系统中正在运行或等待执行的进程的数量。负载通常由三个数字表示，分别是1分钟、5分钟和15分钟内运行队列中的平均进程数量。这些数字可以通过运行&amp;quot;uptime&amp;quot;命令或&amp;quot;top&amp;quot;命令来查看。&lt;/p&gt;
&lt;p&gt;具体来说，这三个数字分别代表：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;1分钟负载&lt;/strong&gt;：系统在过去1分钟内运行队列中的平均进程数量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;5分钟负载&lt;/strong&gt;：系统在过去5分钟内运行队列中的平均进程数量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;15分钟负载&lt;/strong&gt;：系统在过去15分钟内运行队列中的平均进程数量。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;负载的含义是在系统中等待运行的进程数。如果这个数字高于系统的逻辑CPU数量，表明系统负载很高，意味着有许多进程正在等待处理器资源。这可能会导致系统变得缓慢或不响应，具体取决于负载的高低程度以及系统的配置和性能。&lt;/p&gt;
&lt;p&gt;在理想情况下，负载应该保持在系统的逻辑CPU数量范围内，这样系统的性能就能够得到最优化。如果负载持续高于CPU数量，可能需要进一步分析系统中的进程，找出导致负载高的原因，并采取相应的措施来调整系统资源分配或优化进程的运行方式。&lt;/p&gt;
&lt;h3 id=&#34;分析负载-mpstat&#34;&gt;分析负载 mpstat
&lt;/h3&gt;&lt;p&gt;&lt;code&gt;mpstat&lt;/code&gt; 命令用于报告单个或多个处理器的多个信息，包括平均负载、CPU利用率、中断和上下文切换等。在 &lt;code&gt;sysstat&lt;/code&gt; 包中，&lt;code&gt;mpstat&lt;/code&gt; 是非常有用的工具，可以用来分析系统的负载情况。下面是使用 &lt;code&gt;mpstat&lt;/code&gt; 进行负载分析的步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;安装 sysstat&lt;/strong&gt;：
如果您的系统上没有安装 &lt;code&gt;sysstat&lt;/code&gt;，可以使用适合您系统的包管理工具进行安装。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;运行 mpstat&lt;/strong&gt;：
使用 &lt;code&gt;mpstat&lt;/code&gt; 命令查看 CPU 的使用情况和负载。默认情况下，&lt;code&gt;mpstat&lt;/code&gt; 每秒钟显示一次 CPU 使用情况的平均值。您可以通过指定时间间隔来调整输出频率。例如，要以每秒钟一次的频率运行 &lt;code&gt;mpstat&lt;/code&gt;，可以使用以下命令：&lt;code&gt;mpstat -P ALL 2&lt;/code&gt;，&lt;code&gt;irq&lt;/code&gt; 表示占用资源占用&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;01:32:33 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
01:32:35 PM  all    0.00    0.00    0.26    0.00    3.73    0.26    0.00    0.00    0.00   95.76
01:32:35 PM    0    0.00    0.00    0.51    0.00    3.57    0.00    0.00    0.00    0.00   95.92
01:32:35 PM    1    0.00    0.00    0.00    0.00    3.59    0.51    0.00    0.00    0.00   95.90
01:32:35 PM    2    0.00    0.00    0.00    0.00    4.15    0.00    0.00    0.00    0.00   95.85
01:32:35 PM    3    0.00    0.00    0.52    0.00    3.61    0.52    0.00    0.00    0.00   95.36
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;分析输出&lt;/strong&gt;：
&lt;code&gt;mpstat&lt;/code&gt; 的输出包括了每个 CPU 的利用率，以及系统的平均负载。特别关注平均负载以及每个 CPU 的利用率，可以帮助您了解系统的负载情况。如果负载较高，可以进一步分析是哪些进程导致的，以及是否存在性能瓶颈。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;结合其他工具&lt;/strong&gt;：
除了 &lt;code&gt;mpstat&lt;/code&gt;，还可以使用 &lt;code&gt;sar&lt;/code&gt;、&lt;code&gt;pidstat&lt;/code&gt;、&lt;code&gt;iostat&lt;/code&gt; 等工具来综合分析系统性能。通过结合多种工具的输出，可以更全面地了解系统的负载情况，并找出性能问题的根源。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;中断&#34;&gt;中断
&lt;/h3&gt;&lt;p&gt;此处不展开讲解内容太多，
推荐: &lt;a class=&#34;link&#34; href=&#34;https://www.codedump.info/post/20200522-sgfap-softirq/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;《面向应用开发者的系统指南》CPU篇之软中断&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;频繁的触发软中断，也会体现在系统负载中。&lt;/p&gt;
&lt;h2 id=&#34;问题排查&#34;&gt;问题排查
&lt;/h2&gt;&lt;p&gt;考虑到仅从CPU角度分析无法定位问题，我们是否应该开始怀疑系统是否出现了异常？可能是Linux操作系统的负载过高，导致VMware占用了过多的CPU资源。通过使用&lt;code&gt;mpstat&lt;/code&gt;分析本地虚拟机，我们发现&lt;code&gt;irq&lt;/code&gt;占用异常，单核接近25%，而在正常情况下，启动业务进程空跑时，&lt;code&gt;irq&lt;/code&gt;占比应该约为5%。&lt;/p&gt;
&lt;p&gt;在组内同事的开发环境中，他的CentOS 7部署在VMware上，资源占用显示正常。另一方面，在上海的开发环境中，虽然也是VMware，但我们无法直接观察宿主机的CPU资源情况。这时，我们面临着多个变量：VMware虚拟机、Linux操作系统和GCC版本。&lt;/p&gt;
&lt;p&gt;转而分析测试环境，深圳的测试环境部署在物理机上，运行着低版本GCC编译的服务，而且在CentOS 8上运行。有趣的是，在深圳环境中，&lt;code&gt;irq&lt;/code&gt;占用都是正常的。&lt;/p&gt;
&lt;p&gt;为了排查GCC版本引入的问题，我们将使用高版本GCC编译的程序部署到深圳环境进行测试，结果显示也都是正常的。&lt;/p&gt;
&lt;p&gt;问题似乎变得更加明朗，我们开始怀疑操作系统是否存在问题。毕竟，CentOS 8已经不再受到官方支持。但即便重新部署了纯净的CentOS 7和CentOS 8，问题依然存在。&lt;/p&gt;
&lt;p&gt;此时，我们开始怀疑唯一的不确定因素，即VMware虚拟机软件。突然间，灵光一现，我们想到了Hyper-V技术。是否之前启用了Hyper-V，但没有彻底关闭，从而导致了这个问题？毕竟，软中断也是通过虚拟机软件来实现的。不同的虚拟机虚拟技术是否存在BUG？这些问题值得深入思考和调查。&lt;/p&gt;
&lt;h2 id=&#34;结论&#34;&gt;结论
&lt;/h2&gt;&lt;p&gt;根据微软官方的手册，我们完全关闭了本机的Hyper-V服务后，发现VMware在宿主机上恢复了正常。至此，问题终于迎刃而解。正如一开始所述，这段经历曲折而艰辛，需要综合性的分析和判断。这也是我们首次排查问题，定位到了虚拟机这一层面。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Disable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V-Hypervisor
bcdedit /set hypervisorlaunchtype off
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/troubleshoot/windows-client/application-management/virtualization-apps-not-work-with-hyper-v&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://learn.microsoft.com/zh-cn/troubleshoot/windows-client/application-management/virtualization-apps-not-work-with-hyper-v&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>程序优化不要试图对抗硬件</title>
        <link>https://ttf248.life/p/program-optimization-dont-fight-hardware/</link>
        <pubDate>Fri, 07 Apr 2023 16:30:15 +0800</pubDate>
        
        <guid>https://ttf248.life/p/program-optimization-dont-fight-hardware/</guid>
        <description>&lt;p&gt;&lt;code&gt;one loop thread&lt;/code&gt;，耗时已经在&lt;strong&gt;微秒&lt;/strong&gt;层面，更换服务器，从最多积压六万数据包，到几乎没有积压&lt;/p&gt;
&lt;p&gt;在单线程循环处理数据的场景中，CPU的性能取决于主频、缓存大小、指令集架构等因素。一般来说，主频越高、缓存越大、指令集架构越先进的CPU在单线程处理数据时性能越好&lt;/p&gt;
&lt;h2 id=&#34;单线程&#34;&gt;单线程
&lt;/h2&gt;&lt;p&gt;性能提升，增加线程不是分必要的，梳理项目流程，确定耗时的点，单线程是否能满足需求，单线程考虑的东西更少，也不容易出问题。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;上来就和就说加线程，多少有点毛病&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;事件&#34;&gt;事件
&lt;/h2&gt;&lt;p&gt;处理的都是&lt;strong&gt;行情数据，延迟敏感&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;吭哧吭哧加班一晚上，发布新的优化版本，本地剥离接口进行测试，速度也还行，tps：4.2万&lt;/p&gt;
&lt;p&gt;部署到服务器，tps骤降：2.1万，回家尝试台式机，tps：7.9万，开始怀疑组内服务虚拟机多少有点问题，首先怀疑主频导致的，家用台式机和服务器&lt;code&gt;CPU&lt;/code&gt;，差异最大的地方就是主频&lt;/p&gt;
&lt;p&gt;测试服务器A&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;processor	: 7
vendor_id	: GenuineIntel
cpu family	: 6
model		: 47
model name	: Intel(R) Xeon(R) CPU E7- 4807  @ 1.87GHz
stepping	: 2
microcode	: 0x34
cpu MHz		: 1866.733
cache size	: 18432 KB
physical id	: 1
siblings	: 4
core id		: 3
cpu cores	: 4
apicid		: 7
initial apicid	: 7
fpu		: yes
fpu_exception	: yes
cpuid level	: 11
wp		: yes
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss ht syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 cx16 sse4_1 sse4_2 popcnt aes hypervisor lahf_lm pti dtherm arat
bugs		: clflush_monitor cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit
bogomips	: 3733.46
clflush size	: 64
cache_alignment	: 64
address sizes	: 40 bits physical, 48 bits virtual
power management:
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;测试服务器B&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;processor	: 7
vendor_id	: GenuineIntel
cpu family	: 6
model		: 63
model name	: Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz
stepping	: 2
microcode	: 0x3c
cpu MHz		: 2599.998
cache size	: 20480 KB
physical id	: 14
siblings	: 1
core id		: 0
cpu cores	: 1
apicid		: 14
initial apicid	: 14
fpu		: yes
fpu_exception	: yes
cpuid level	: 15
wp		: yes
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cpuid_fault epb pti fsgsbase smep xsaveopt cqm_llc cqm_occup_llc dtherm ida arat pln pts
bugs		: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit
bogomips	: 5199.99
clflush size	: 64
cache_alignment	: 64
address sizes	: 40 bits physical, 48 bits virtual
power management:
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;咨询-openai&#34;&gt;咨询 OpenAI
&lt;/h2&gt;&lt;p&gt;首先是核心数和主频方面，Intel(R) Xeon(R) CPU E7- 4807 @ 1.87GHz拥有6个物理核心和12个逻辑核心，主频为1.87GHz；而Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz拥有8个物理核心和16个逻辑核心，主频为2.60GHz。因此，从核心数和主频方面来看，E5-2640 v3在单线程处理数据时应该比E7- 4807更具优势。&lt;/p&gt;
&lt;p&gt;其次是缓存大小方面，E7- 4807的缓存大小为12MB，而E5-2640 v3的缓存大小为20MB。因此，E5-2640 v3拥有更大的缓存空间，可以提高数据的访问速度和缓存命中率。&lt;/p&gt;
&lt;p&gt;最后是架构方面，E5-2640 v3采用了更先进的Haswell架构，而E7- 4807采用的是旧的Nehalem架构。Haswell架构相对于Nehalem架构在性能方面有所提升，这也可能对E5-2640 v3在单线程处理数据时的性能提升产生影响。&lt;/p&gt;
&lt;p&gt;因此，综合考虑，在单线程循环处理数据的场景中，E5-2640 v3应该比E7- 4807具有更好的性能。但是，具体的性能差异会受到多种因素的影响，包括数据处理的算法、内存带宽、系统负载等等，需要具体问题具体分析。&lt;/p&gt;
&lt;h2 id=&#34;硬件资料&#34;&gt;硬件资料
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cpubenchmark.net/compare/3786.2vs2365.2/%5BDual-CPU%5D-Intel-Xeon-E7%e2%80%934807-vs-%5BDual-CPU%5D-Intel-Xeon-E5-2640-v3&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.cpubenchmark.net/compare/3786.2vs2365.2/%5BDual-CPU%5D-Intel-Xeon-E7–4807-vs-%5BDual-CPU%5D-Intel-Xeon-E5-2640-v3&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Specification&lt;/th&gt;
&lt;th&gt;Xeon E7-4807 (LGA1567)&lt;/th&gt;
&lt;th&gt;Xeon E5-2640 v3 (LGA2011-v3)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Price&lt;/td&gt;
&lt;td&gt;Search Online  $78 - BUY&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Socket Type&lt;/td&gt;
&lt;td&gt;LGA1567&lt;/td&gt;
&lt;td&gt;LGA2011-v3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CPU Class&lt;/td&gt;
&lt;td&gt;Server&lt;/td&gt;
&lt;td&gt;Server&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Clockspeed&lt;/td&gt;
&lt;td&gt;1.9 GHz&lt;/td&gt;
&lt;td&gt;2.6 GHz&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Turbo Speed&lt;/td&gt;
&lt;td&gt;Not Supported&lt;/td&gt;
&lt;td&gt;Up to 3.4 GHz&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;# of Physical Cores&lt;/td&gt;
&lt;td&gt;6 (Threads: 12)&lt;/td&gt;
&lt;td&gt;8 (Threads: 16)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cache&lt;/td&gt;
&lt;td&gt;NA2&lt;/td&gt;
&lt;td&gt;NA2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Max TDP&lt;/td&gt;
&lt;td&gt;95W x 2&lt;/td&gt;
&lt;td&gt;90W x 2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Yearly Running Cost&lt;/td&gt;
&lt;td&gt;$34.68&lt;/td&gt;
&lt;td&gt;$32.85&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Other&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;First Seen on Chart&lt;/td&gt;
&lt;td&gt;Q3 2020&lt;/td&gt;
&lt;td&gt;Q3 2014&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;# of Samples&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;46&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CPU Value&lt;/td&gt;
&lt;td&gt;69.1&lt;/td&gt;
&lt;td&gt;225.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Single Thread Rating&lt;/td&gt;
&lt;td&gt;721 (-59.2%)&lt;/td&gt;
&lt;td&gt;1767 (0.0%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CPU Mark&lt;/td&gt;
&lt;td&gt;6223 (-64.6%)&lt;/td&gt;
&lt;td&gt;17600 (0.0%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</description>
        </item>
        <item>
        <title>编译器、回调函数、性能测试</title>
        <link>https://ttf248.life/p/compiler-callback-performance-testing/</link>
        <pubDate>Wed, 15 Feb 2023 13:59:25 +0800</pubDate>
        
        <guid>https://ttf248.life/p/compiler-callback-performance-testing/</guid>
        <description>&lt;p&gt;去年设计了一个&lt;code&gt;SDK&lt;/code&gt;，负责处理封装一些事件，对外提供一个类接口，服务初始化的时候，调用方实现对应的类，并将对象指针传给模块。
接触过&lt;code&gt;C11&lt;/code&gt;，好奇心害死猫，就想着这些接口都用&lt;code&gt;lambda&lt;/code&gt;函数对象回调来实现会是什么结果，和纯虚函数的接口定义方法比较，更加灵活。
疑问就出现了，两种不同的语法，从性能角度来说，哪个更快一些？不懂编译原理，弄段代码试试看。&lt;/p&gt;
&lt;h2 id=&#34;前言&#34;&gt;前言
&lt;/h2&gt;&lt;p&gt;在线网址，能选择不同编译器，编译参数，在&lt;code&gt;linux&lt;/code&gt;平台运行代码，亦或者查看对应的汇编代码。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt;：有时候做些技术验证，网页执行小片段的代码很省事&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://godbolt.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://godbolt.org/&lt;/a&gt;：用不同的颜色，区分不同的汇编对应的代码，比本地的调试器看起来更加省事。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文
&lt;/h2&gt;&lt;p&gt;标准委员会制定了语法的规则，在编译层面，如何实现，取决于各家的编译器，这里不得不说一声，微软的编译器，挺厉害的。语法糖不是万能的，回调接口不多，使用&lt;code&gt;lambda&lt;/code&gt;更加便捷，也无需定义空回调函数接口；回调接口种类繁多的时候，传统的虚函数更有利于业务接口定义的统一。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;windows&lt;/code&gt;平台，两者性能接近，没有太多的差异&lt;/li&gt;
&lt;li&gt;&lt;code&gt;linux&lt;/code&gt;平台，虚函数和&lt;code&gt;lambda&lt;/code&gt;比较，单次多了1.35ns&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;常规的业务系统开发中，此级别的性能损耗可以忽略，引入&lt;code&gt;lambda&lt;/code&gt;，在设计的上，能带来更多的便捷。在设计多信号处理时，尤为明显，底层有事件触发，如果需要落地日志，出入日志对象的的处理函数。当需要更多的业务处理接口时，底层用&lt;code&gt;vector&lt;/code&gt;保存&lt;code&gt;lambda&lt;/code&gt;对象，事件触发时，依次遍历调用，类似于&lt;code&gt;QT&lt;/code&gt;中的信号和槽，日志、监控、业务1、业务2，互相之间完全解耦。&lt;/p&gt;
&lt;h2 id=&#34;代码&#34;&gt;代码
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Counter: 1000000
Time: 3966us
Counter: 1000000
Time: 5316us
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;memory&amp;gt;
#include &amp;lt;functional&amp;gt;
#include &amp;lt;atomic&amp;gt;
#include &amp;lt;string&amp;gt;

std::atomic_int64_t counter = 0;

// 定义回调接口
class UserInterface
{
public:
    virtual void name() = 0;
    virtual void full_name() = 0;
};

class User : public UserInterface
{
public:
    void name() {}
    void full_name() { counter++; }
};

void to_string(UserInterface* user)
{
    user-&amp;gt;name();
    user-&amp;gt;full_name();
}

using name_handler = std::function&amp;lt;void()&amp;gt;;
using full_name_handler = std::function&amp;lt;void()&amp;gt;;

class Test
{
    name_handler name_;
    full_name_handler full_name_;

public:
    void set_name_handler(name_handler name)
    {
        name_ = name;
    }

    void set_full_name_handler(full_name_handler full_name)
    {
        full_name_ = full_name;
    }

    void to_string()
    {
        name_();
        full_name_();
    }
};

int main()
{
    User user;

    auto start = std::chrono::high_resolution_clock::now();

    for (int i = 0; i &amp;lt; 1000000; i++)
    {
        to_string(&amp;amp;user);
    }

    auto end = std::chrono::high_resolution_clock::now();
    std::cout &amp;lt;&amp;lt; &amp;quot;Counter: &amp;quot; &amp;lt;&amp;lt; counter &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;Time: &amp;quot; &amp;lt;&amp;lt; std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(end - start).count() &amp;lt;&amp;lt; &amp;quot;us&amp;quot; &amp;lt;&amp;lt; std::endl;

    counter = 0;
    auto name = []() {};
    auto full_name = []() { counter++; };

    Test test;
    test.set_name_handler(name);
    test.set_full_name_handler(full_name);

    start = std::chrono::high_resolution_clock::now();

    for (int i = 0; i &amp;lt; 1000000; i++)
    {
        test.to_string();
    }

    end = std::chrono::high_resolution_clock::now();
    std::cout &amp;lt;&amp;lt; &amp;quot;Counter: &amp;quot; &amp;lt;&amp;lt; counter &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;Time: &amp;quot; &amp;lt;&amp;lt; std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(end - start).count() &amp;lt;&amp;lt; &amp;quot;us&amp;quot; &amp;lt;&amp;lt; std::endl;

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;后记&#34;&gt;后记
&lt;/h2&gt;&lt;p&gt;查找资料的时候，翻到类似的代码片段 &lt;a class=&#34;link&#34; href=&#34;https://gist.githubusercontent.com/benloong/8050171/raw/fa577ec923b460862078b8b40233a42a1c619eeb/functionperformance.cpp&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;functionperformance.cpp&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;memory&amp;gt;
#include &amp;lt;functional&amp;gt;

using namespace std;
using namespace std::chrono;

class Base
{
public:
	Base(){}
	virtual ~Base(){}
	virtual int func(int i) = 0;
};

class Derived : public Base
{
public:
	Derived(int base = 10) : base{base}
	{

	}
	~Derived(){}

	virtual int func(int i)
	{
		return i*base;
	}
private:
	int base;
};

struct Func
{
	int base;
	int operator()(int i)
	{
		return i*base;
	}
	Func(int base) : base {base}
	{

	}
};
const int base = 10;
int calculate(int i)
{
	return base*i;
}

int main()
{
	const int num = 10000;
	Base *p = new Derived{10};
	int total = 0;
	auto start = high_resolution_clock::now();
	for (int i = 0; i &amp;lt; num; ++i)
	{
		total += p-&amp;gt;func(i);
	}
	auto end = high_resolution_clock::now();
	std::cout&amp;lt;&amp;lt;&amp;quot;result: &amp;quot;&amp;lt;&amp;lt;total&amp;lt;&amp;lt;&amp;quot;\nvirtual call elapsed: \t&amp;quot;&amp;lt;&amp;lt;duration_cast&amp;lt;nanoseconds&amp;gt;(end-start).count()&amp;lt;&amp;lt;&amp;quot; nanoseconds.\n&amp;quot;&amp;lt;&amp;lt;std::endl;

	total = 0;
	start = high_resolution_clock::now();
	for (int i = 0; i &amp;lt; num; ++i)
	{
		total += calculate(i);
	}
	end = high_resolution_clock::now();
	std::cout&amp;lt;&amp;lt;&amp;quot;result: &amp;quot;&amp;lt;&amp;lt;total&amp;lt;&amp;lt;&amp;quot;\ndirect function call elapsed: \t&amp;quot;&amp;lt;&amp;lt;duration_cast&amp;lt;nanoseconds&amp;gt;(end-start).count()&amp;lt;&amp;lt;&amp;quot; nanoseconds.\n&amp;quot;&amp;lt;&amp;lt;std::endl;

	Func functor{10};
	total = 0;
	start = high_resolution_clock::now();
	for (int i = 0; i &amp;lt; num; ++i)
	{
		total += functor(i);
	}
	end = high_resolution_clock::now();
	std::cout&amp;lt;&amp;lt;&amp;quot;result: &amp;quot;&amp;lt;&amp;lt;total&amp;lt;&amp;lt;&amp;quot;\nfunctor call elapsed: \t&amp;quot;&amp;lt;&amp;lt;duration_cast&amp;lt;nanoseconds&amp;gt;(end-start).count()&amp;lt;&amp;lt;&amp;quot; nanoseconds.\n&amp;quot;&amp;lt;&amp;lt;std::endl;
	int base = 10;
	function&amp;lt;int(int)&amp;gt; lambda = [base](int i)
	{
		return i*base;
	};
	total = 0;
	start = high_resolution_clock::now();
	for (int i = 0; i &amp;lt; num; ++i)
	{
		total += lambda(i);
	}
	end = high_resolution_clock::now();
	std::cout&amp;lt;&amp;lt;&amp;quot;result: &amp;quot;&amp;lt;&amp;lt;total&amp;lt;&amp;lt;&amp;quot;\nlambda call elapsed: \t&amp;quot;&amp;lt;&amp;lt;duration_cast&amp;lt;nanoseconds&amp;gt;(end-start).count()&amp;lt;&amp;lt;&amp;quot; nanoseconds.\n&amp;quot;&amp;lt;&amp;lt;std::endl;
	return 0;
}

/*
test on mac mini i7 2.7GHz
clang++ -std=c++11 chronotest.cpp -O0
output:
result: 499950000
virtual call elapsed: 	43171 nanoseconds.

result: 499950000
direct function call elapsed: 	31379 nanoseconds.

result: 499950000
functor call elapsed: 	41497 nanoseconds.

result: 499950000
lambda call elapsed: 	207416 nanoseconds.
===================================================
clang++ -std=c++11 chronotest.cpp -O1
output:
result: 499950000
virtual call elapsed: 	26144 nanoseconds.

result: 499950000
direct function call elapsed: 	22384 nanoseconds.

result: 499950000
functor call elapsed: 	33477 nanoseconds.

result: 499950000
lambda call elapsed: 	55799 nanoseconds.
===================================================
clang++ -std=c++11 chronotest.cpp -O2
result: 499950000
virtual call elapsed: 	22284 nanoseconds.

result: 499950000
direct function call elapsed: 	36 nanoseconds.

result: 499950000
functor call elapsed: 	30 nanoseconds.

result: 499950000
lambda call elapsed: 	28292 nanoseconds.

===================================================
clang++ -std=c++11 chronotest.cpp -O3
result: 499950000
virtual call elapsed: 	18975 nanoseconds.

result: 499950000
direct function call elapsed: 	29 nanoseconds.

result: 499950000
functor call elapsed: 	30 nanoseconds.

result: 499950000
lambda call elapsed: 	22542 nanoseconds.
===================================================
clang++ -std=c++11 chronotest.cpp -O4

result: 499950000
virtual call elapsed: 	22141 nanoseconds.

result: 499950000
direct function call elapsed: 	30 nanoseconds.

result: 499950000
functor call elapsed: 	30 nanoseconds.

result: 499950000
lambda call elapsed: 	22584 nanoseconds.
*/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里多了两种模式，普通函数和仿函数，提供接口回调的方式和直接调用比较，性能损耗是数量级的差异，仿函数性能和函数接近，有时候仿函数的性能更优，编译原理这块算是知识盲区，猜测是由于访问的变量地址和函数挨着，有利于&lt;code&gt;CPU&lt;/code&gt;处理&lt;/p&gt;
&lt;p&gt;附上 &lt;code&gt;wandbox&lt;/code&gt; 运行结果&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;result: 499950000
virtual call elapsed: 6143 nanoseconds.

result: 499950000
direct function call elapsed: 30 nanoseconds.

result: 499950000
functor call elapsed: 31 nanoseconds.

result: 499950000
lambda call elapsed: 15134 nanoseconds.
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Linux搭建Jmeter压测环境</title>
        <link>https://ttf248.life/p/linux-setup-jmeter-testing-environment/</link>
        <pubDate>Tue, 22 Dec 2020 10:12:50 +0800</pubDate>
        
        <guid>https://ttf248.life/p/linux-setup-jmeter-testing-environment/</guid>
        <description>&lt;p&gt;作者对硬件有浓厚兴趣，使用Jmeter进行压力测试，记录了在CentOS 7上部署Jmeter、InfluxDB和Grafana的过程。分享了Jmeter的安装和命令使用，InfluxDB的特点和Docker安装方法，以及Grafana的简单部署和配置。总结了高性能程序模式的经验和参考资料。&lt;/p&gt;
&lt;h2 id=&#34;背景&#34;&gt;背景
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;众所周知&lt;/code&gt;本人对硬件有很浓厚的兴趣，凑巧测试组在用&lt;code&gt;Jmeter&lt;/code&gt;做压力测试，发现性能上不去，作为好奇宝宝的我果断出击，试试公司的压测是怎么玩的。此处还有个小故事，在某个久远的时间点，在开源中国看过一篇帖子，如何绘制看上去更加高大上的性能压测图，在测试围观过&lt;code&gt;windows&lt;/code&gt;版本执行测试，已经做到了可视化的&lt;code&gt;TPS&lt;/code&gt;数据展示，另外配置一份web面板能有什么用？&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;脑子想的都是想当然的东西，你要去试试才明白
Don&amp;rsquo;t use GUI mode for load testing! only for Test creation and Test debuggin.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;官方推荐的是通过命令行的方式获取压测报告，绘制GUI的方式展示，存在数据上的误差？对于Jmeter了解的不是很深入，至少找到一个理由去折腾一下&lt;code&gt;Linux&lt;/code&gt;版本的控制台面板&lt;/p&gt;
&lt;p&gt;开源中国的帖子，核心组件的部署方式并不友好，安装所需的文件也需要关注公众号才能下载，作为新生代的好青年，当然是用&lt;code&gt;Docker&lt;/code&gt;替代了。说白了还是自己服务器在境内，跨境的源地址访问速度都很慢，至少镜像服务，阿里云有个免费的加速。&lt;/p&gt;
&lt;p&gt;关于&lt;code&gt;docker&lt;/code&gt;的安装部署，此处不再赘述，推荐参考以前的稿子。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;接下来的内容氛围两大块：基本测试环境组件的搭建、各个组件的简单认知讲解&lt;/p&gt;
&lt;h2 id=&#34;jmeter&#34;&gt;Jmeter
&lt;/h2&gt;&lt;p&gt;Apache JMeter是Apache组织开发的基于Java的压力测试工具。用于对软件做压力测试，它最初被设计用于Web应用测试，但后来扩展到其他测试领域。 它可以用于测试静态和动态资源，例如静态文件、Java 小服务程序、CGI 脚本、Java 对象、数据库、FTP 服务器， 等等。JMeter 可以用于对服务器、网络或对象模拟巨大的负载，来自不同压力类别下测试它们的强度和分析整体性能。另外，JMeter能够对应用程序做功能/回归测试，通过创建带有断言的脚本来验证你的程序返回了你期望的结果。为了最大限度的灵活性，JMeter允许使用正则表达式创建断言。&lt;/p&gt;
&lt;p&gt;Apache jmeter 可以用于对静态的和动态的资源（文件，Servlet，Perl脚本，java 对象，数据库和查询，FTP服务器等等）的性能进行测试。它可以用于对服务器、网络或对象模拟繁重的负载来测试它们的强度或分析不同压力类型下的整体性能。你可以使用它做性能的图形分析或在大并发负载测试你的服务器/脚本/对象。&lt;/p&gt;
&lt;h3 id=&#34;jmeter-部署-centos7&#34;&gt;Jmeter 部署 centos7
&lt;/h3&gt;&lt;p&gt;安装&lt;code&gt;JDK&lt;/code&gt;运行环境、下载&lt;code&gt;Jmeter&lt;/code&gt;安装包&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum install java-1.8.0-openjdk -y &amp;amp;&amp;amp; \
wget https://mirrors.bfsu.edu.cn/apache//jmeter/binaries/apache-jmeter-5.4.tgz &amp;amp;&amp;amp; tar -xf apache-jmeter-5.4.tgz
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;配置环境变量&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export JMETER_HOME=$HOME/jmeter/apache-jmeter-5.4
export PATH=$JMETER_HOME/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;jmeter-命令&#34;&gt;Jmeter 命令
&lt;/h3&gt;&lt;p&gt;最后会对接&lt;code&gt;Grafana&lt;/code&gt;控制面板，可以不输入&lt;code&gt;-l&lt;/code&gt;参数，在&lt;code&gt;web&lt;/code&gt;控制台观察数据&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;jmeter -n -t /tmp/order-500-10s.jmx -l /tmp/jmeter-order-report-20200109/order-500-10s.jtl
# 一般不用测试结果和测试报告，简化命令
jmeter -n -t /tmp/order-500-10s.jmx
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;influxdb&#34;&gt;InfluxDB
&lt;/h2&gt;&lt;p&gt;InfluxDB是一款用Go语言编写的开源分布式时序、事件和指标数据库，无需外部依赖。该数据库现在主要用于存储涉及大量的时间戳数据，如DevOps监控数据，APP metrics, loT传感器数据和实时分析数据。&lt;/p&gt;
&lt;h3 id=&#34;influxdb-特点&#34;&gt;InfluxDB 特点
&lt;/h3&gt;&lt;p&gt;InfluxDB的特点可以归纳为以下9个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;无结构(无模式)：可以是任意数量的列;&lt;/li&gt;
&lt;li&gt;可以设置metric的保存时间;&lt;/li&gt;
&lt;li&gt;支持与时间有关的相关函数(如min、max、sum、count、mean、median等)，方便统计;&lt;/li&gt;
&lt;li&gt;支持存储策略:可以用于数据的删改。(influxDB没有提供数据的删除与修改方法);&lt;/li&gt;
&lt;li&gt;支持连续查询:是数据库中自动定时启动的一组语句，和存储策略搭配可以降低InfluxDB的系统占用量;&lt;/li&gt;
&lt;li&gt;原生的HTTP支持，内置HTTP API;&lt;/li&gt;
&lt;li&gt;支持类似sql语法;&lt;/li&gt;
&lt;li&gt;支持设置数据在集群中的副本数;&lt;/li&gt;
&lt;li&gt;支持定期采样数据，写入另外的measurement，方便分粒度存储数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;influxdb-docker-安装&#34;&gt;InfluxDB docker 安装
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mkdir influxdb &amp;amp;&amp;amp; cd influxdb &amp;amp;&amp;amp; \
docker run -p 8086:8086 -d --name influxdb -v $PWD:/var/lib/influxdb influxdb:1.7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;docker exec -it influxdb /bin/bash&lt;/code&gt; 进入容器，执行命令，人工创建数据库&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;root@bce0a55bbc72:/# influx
Connected to http://localhost:8086 version 1.7.10
InfluxDB shell version: 1.7.10
&amp;gt; 交互面板执行命令
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;influxdb-创建数据库和用户&#34;&gt;InfluxDB 创建数据库和用户
&lt;/h3&gt;&lt;p&gt;创建数据库：create database jmeter_t2
查看数据库：show databases
切换数据库：use jmeter_t2
创建用户：create user &amp;ldquo;admin&amp;rdquo; with password &amp;lsquo;admin&amp;rsquo; with all privileges
查看用户：show users&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;&amp;gt; show users
user  admin
----  -----
admin true
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果显示用户权限&lt;code&gt;admin&lt;/code&gt;为&lt;code&gt;true&lt;/code&gt;，数据库的准备工作就完成了&lt;/p&gt;
&lt;h2 id=&#34;grafana&#34;&gt;Grafana
&lt;/h2&gt;&lt;p&gt;编写测试案例的时候发现，图表展示的效果其实没太多必要，接口的&lt;code&gt;tps&lt;/code&gt;数据在命令行执行的时候已经能观测到，更多是想知道程序内部的耗时&lt;/p&gt;
&lt;p&gt;简单部署&lt;code&gt;grafana&lt;/code&gt;控制台面板，导入配置文件对接&lt;code&gt;InfluxDB&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;控制台支持通过标签过滤测试结果，一般只需要配置一个&lt;code&gt;InfluxDB&lt;/code&gt;数据库即可：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用名称&lt;/li&gt;
&lt;li&gt;测试案例名称&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/linux-setup-jmeter-testing-environment/Snipaste_2021-03-09_19-44-22.png&#34;
	width=&#34;861&#34;
	height=&#34;357&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;grafana&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;241&#34;
		data-flex-basis=&#34;578px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -d --name=grafana -p 3000:3000 grafana/grafana:7.3.1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;网页版由于采样器间隔会导致计算的&lt;code&gt;TPS&lt;/code&gt;和相关数值与&lt;code&gt;Jmeter&lt;/code&gt;聚合报告不相符，参考链接：&lt;a class=&#34;link&#34; href=&#34;https://www.vinsguru.com/jmeter-real-time-results-influxdb-grafana/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.vinsguru.com/jmeter-real-time-results-influxdb-grafana/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;资料中也描述了如何自定义&lt;code&gt;监听器&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;后记&#34;&gt;后记
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;高性能的程序模式必然是 one loop thread，任何的锁、入队列和出队列，都会造成不必要的性能损失&lt;/li&gt;
&lt;li&gt;核心业务逻辑的耗时大于引入其他代码的耗时，并发才能有效提高效率，核心耗时如果足够小谨慎引入其他代码&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://my.oschina.net/u/4617935/blog/4680856&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Jmeter系列之Jmeter+Grafana+InfluxDB实时监控&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://hub.docker.com/_/influxdb&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;influxdb官方镜像&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://hub.docker.com/r/grafana/grafana&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;grafane官方镜像&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://jmeter.apache.org/download_jmeter.cgi&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Jmeter官网&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/@jasonli.studio/to-install-apache-jmeter-in-centos7-294bc72a97ba&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;To install Apache JMeter in CentOS7&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>标准库容器的内存分配器：allocator</title>
        <link>https://ttf248.life/p/standard-library-container-memory-allocator/</link>
        <pubDate>Mon, 30 Dec 2019 13:26:19 +0800</pubDate>
        
        <guid>https://ttf248.life/p/standard-library-container-memory-allocator/</guid>
        <description>&lt;p&gt;自定义分配器可以提升性能、提高内存使用效率，并解决频繁少量内存分配的问题。&lt;/p&gt;
&lt;h4 id=&#34;前因&#34;&gt;前因
&lt;/h4&gt;&lt;p&gt;近期接触到了网络网络数据包的开发，需要频繁的申请和释放小块的内存，原本想着使用内存池，查看了几个现有的内存池，发现了这个&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/cacay/MemoryPool&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/cacay/MemoryPool&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;看到接口的时候，就比较纳闷，这个内存池的实现怎么有点奇怪。&lt;code&gt;MemoryPool&lt;/code&gt;的实现逻辑，是在申请固定大小的内存空间。看过boost的内存池接口，提供的是一个模板，用的时候进行实例化。正巧这个库已经有文章进行过介绍，提到了&lt;code&gt;allocator&lt;/code&gt;这个概念。&lt;/p&gt;
&lt;h4 id=&#34;wikihttpszhwikipediaorgwikie58886e9858de599a8_c2b2b&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;wiki&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;在C++编程中，分配器（英语：allocator）是C++标准库的重要组成部分。C++的库中定义了多种被统称为“容器”的数据结构（如链表、集合等），这些容器的共同特征之一，就是其大小可以在程序的运行时改变；为了实现这一点，进行动态内存分配就显得尤为必要，在此分配器就用于处理容器对内存的分配与释放请求。换句话说，分配器用于封装标准模板库（STL）容器在内存管理上的低层细节。默认情况下，C++标准库使用其自带的通用分配器，但根据具体需要，程序员也可自行定制分配器以替代之。&lt;/p&gt;
&lt;p&gt;分配器最早由亚历山大·斯特潘诺夫作为C++标准模板库（Standard Template Library，简称STL）的一部分发明，其初衷是创造一种能“使库更加灵活，并能独立于底层数据模型的方法”，并允许程序员在库中利用自定义的指针和引用类型；但在将标准模板库纳入C++标准时，C++标准委员会意识到对数据模型的完全抽象化处理会带来不可接受的性能损耗，为作折中，标准中对分配器的限制变得更加严格，而有鉴于此，与斯特潘诺夫原先的设想相比，现有标准所描述的分配器可定制程度已大大受限。&lt;/p&gt;
&lt;p&gt;虽然分配器的定制有所限制，但在许多情况下，仍需要用到自定义的分配器，而这一般是为封装对不同类型内存空间（如共享内存与已回收内存）的访问方式，或在使用内存池进行内存分配时提高性能而为。除此以外，从内存占用和运行时间的角度看，在频繁进行少量内存分配的程序中，若引入为之专门定制的分配器，也会获益良多。&lt;/p&gt;
&lt;h4 id=&#34;使用需求httpszhwikipediaorgwikie58886e9858de599a8_c2b2b&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;使用需求&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;定义自定义分配器的主要原因之一是提升性能。利用专用的自定义分配器可以提高程序的性能，又或提高内存使用效率，亦或两者兼而有之[4][8]。默认分配器使用new操作符分配存储空间[文 5]，而这常利用C语言堆分配函数（malloc()）实现[9]。由于堆分配函数常针对偶发的内存大量分配作优化，因此在为需要一次分配大量内存的容器（如向量、双端队列）分配内存时，默认分配器一般效率良好[8]。但是，对于关联容器与双向链表这类需要频繁分配少量内存的容器来说，若采用默认分配器分配内存，则通常效率很低[4][9]。除此之外，基于malloc()的默认分配器还存在许多问题，诸如较差的引用局部性[4]，以及可能造成内存碎片化[4][9]。&lt;/p&gt;
&lt;p&gt;简言之，此段（……）（如同）是这一标准针对分配器的一场《我有一个梦想》的演讲。在梦想成真之前，关心可移植性的程序员将把自己局限于（使用）无状态的自定义分配器上。
——斯科特 梅耶斯，《Effective STL》
有鉴于此，在这一情况下，人们常使用基于内存池的分配器来解决频繁少量分配问题[8]。与默认的“按需分配”方式不同，在使用基于内存池的分配器时，程序会预先为之分配大块内存（即“内存池”），而后在需要分配内存时，自定义分配器只需向请求方返回一个指向池内内存的指针即可；而在对象析构时，并不需实际解除分配内存，而是延迟到内存池的生命周期完结时才真正解除分配[注 1][8]。&lt;/p&gt;
&lt;p&gt;在“自定义分配器”这一话题上，已有诸多C++专家与相关作者参与探讨，例如斯科特·梅耶斯的作品《Effective STL》与安德烈·亚历山德雷斯库的《Modern C++ Design》都有提及。梅耶斯洞察到，若要求针对某一类型T的分配器的所有实例都相等，则可移植的分配器的实例必须不包含状态。虽然C++标准鼓励库的实现者支持带状态的分配器[文 4]，但梅耶斯称，相关段落是“（看似）美妙的观点”，但也几乎是空话，并称分配器的限制“过于严苛”[4]。例如，STL的list允许splice方法，即一个list对象A的节点可以被直接移入另一个list对象B中，这就要求A的分配器申请到的内存，可被B的分配器释放掉，从而推导出A与B的分配器实例必须相等。梅耶斯的结论是，分配器最好定义为使用静态方法的类型。例如，根据C++标准，分配器必须提供一个实现了rebind方法的other类模板。&lt;/p&gt;
&lt;p&gt;另外，在《C++程序设计语言》中，比雅尼·斯特劳斯特鲁普则认为“‘严格限制分配器，以免各对象信息不同’，这点显然问题不大”（大意），并指出大部分分配器并不需要状态，甚至没有状态情形下性能反倒更佳。他提出了三个自定义分配器的用例：内存池型的分配器、共享内存型分配器与垃圾回收型分配器，并展示了一个分配器的实现，此间利用了一个内部内存池，以快速分配/解除分配少量内存。但他也提到，如此优化可能已经在他所提供的样例分配器中实现[3]。&lt;/p&gt;
&lt;p&gt;自定义分配器的另一用途是调试内存相关错误[10]。若要做到这一点，可以编写一个分配器，令之在分配时分配额外的内存，并借此存放调试信息。这类分配器不仅可以保证内存由同类分配器分配/解除分配内存，还可在一定程度上保护程序免受缓存溢出之害[11]。&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

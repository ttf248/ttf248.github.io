<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>大模型 on 向叔记事簿</title>
        <link>https://ttf248.life/tags/large-model/</link>
        <description>Recent content in 大模型 on 向叔记事簿</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language><atom:link href="https://ttf248.life/tags/large-model/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>终归还是回到国产模型</title>
        <link>https://ttf248.life/p/ultimately-its-returning-to-domestic-models/</link>
        <pubDate>Wed, 03 Dec 2025 22:33:47 +0800</pubDate>
        
        <guid>https://ttf248.life/p/ultimately-its-returning-to-domestic-models/</guid>
        <description>&lt;p&gt;前文提到 Gemini Cli 登录的时候需要配置谷歌云的项目 ID，这里就已经不对劲，如果是个人账号不会有这个限制，能出现这个限制，已经开始进入谷歌的风控系统，认为你不是个人账号。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;麻烦事，用了小半个月，刚适应，现在要回到 cc + 国产模型的怀抱。&lt;/li&gt;
&lt;li&gt;谷歌自研芯片成本优势那么大吗？市面上主流的模式都是 Tokens 积分，谷歌现在还是按次计费。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;梳理&#34;&gt;梳理
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;You are currently configured to use a Google Cloud Project but lack a Gemini Code Assist license. Please contact your administrator to request a license. (#3501)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;白天还能登录使用，晚上回家就不行了，开始以为更新导致的 bug，切换到老版本，还是不行，Github 提了 Issue，下面机器人自动给我牵扯出来一堆类似的问题。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/google-gemini/gemini-cli/issues/14447&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/google-gemini/gemini-cli/issues/14447&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;看完相关信息，发现不对劲，gemini cli 官网没更新，Github 上的文档提到，如果你登录的时候需要谷歌云ID，那就是被识别了，&lt;strong&gt;你不是个人开发者&lt;/strong&gt;。国内登录都是通过科学上网，登录IP信息都是机房的地址，被识别也很正常，谷歌也没想着让中国内地随便用，毕竟需要用到科学上网的地方就那么多了，大部分地区都能直接访问。&lt;/p&gt;
&lt;p&gt;继续搜索，社区里面类似的情况很多：&lt;a class=&#34;link&#34; href=&#34;https://discuss.google.dev/t/is-gemini-code-assist-incorrectly-identifying-my-personal-account-as-an-enterprise-account/287654/2&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://discuss.google.dev/t/is-gemini-code-assist-incorrectly-identifying-my-personal-account-as-an-enterprise-account/287654/2&lt;/a&gt;，也都是用着用着就不能用了。&lt;/p&gt;
&lt;h2 id=&#34;方案&#34;&gt;方案
&lt;/h2&gt;&lt;p&gt;M2 最近半月更新的内容也不少，通过&lt;strong&gt;MCP&lt;/strong&gt;支持联网搜索、支持图像识别。先用用看，后续不行了，再考虑找个法子给谷歌付费，切换到基础的付费版本，手上的美元信用卡不一定能付费成功，上次尝试付费ChatGPT就失败了。&lt;/p&gt;
&lt;h2 id=&#34;后记&#34;&gt;后记
&lt;/h2&gt;&lt;p&gt;回退代码，将昨天的任务，重新用 M2 重做一遍，问题不少，Gemini 那边一次搞定的东西，这边反复了很多次，提示词需要很精准，不能有歧义。对整体项目的理解不到位，需要尽可能的拆成小任务执行。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;上面的都是小问题，minimaxi 给的额度看着不少，实测下来，项目开发中，消耗的很快&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;谷歌自研芯片成本优势那么大吗？市面上主流的模式都是 Tokens 积分，谷歌现在还是按次计费。想要正常使用，minimaxi 第二档的年费五百能搞定，相比谷歌 pro 版本呢，便宜三百多。结合实际开发体验，貌似国内的性价比也不太行。&lt;/p&gt;
&lt;p&gt;怎么安慰自己呢，也许模型更蠢点，人脑介入更多，也不是坏事？&lt;/p&gt;</description>
        </item>
        <item>
        <title>阿里巴巴大模型策略</title>
        <link>https://ttf248.life/p/alibaba-large-model-strategy/</link>
        <pubDate>Tue, 18 Nov 2025 22:07:10 +0800</pubDate>
        
        <guid>https://ttf248.life/p/alibaba-large-model-strategy/</guid>
        <description>&lt;p&gt;阿里巴巴（阿里）发布众多大模型，并非简单的“刷数量”，而是一种精心布局的**“模型即服务”(MaaS)生态策略**。这背后有多重考量，可概述为“对内赋能、对外建生态”：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;阿里巴巴怎么会发布那么多大模型？这是个什么策略？五百字左右，概述一下&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;内部业务驱动-对内赋能&#34;&gt;内部业务驱动 (对内赋能)
&lt;/h2&gt;&lt;p&gt;阿里拥有极其庞大且多元的业务版图，包括电商（淘宝天猫）、金融（蚂蚁）、物流（菜鸟）、云计算（阿里云）、文娱（优酷）等。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;场景定制化：&lt;/strong&gt; 单一的通用大模型无法高效满足所有垂直场景的精细化需求。例如，电商客服模型、广告创意生成模型、金融风控模型和物流路径规划模型所需的能力截然不同。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;效率与成本：&lt;/strong&gt; 针对特定任务（如编码、作图）训练专门的“小模型”，比始终调用一个庞大的“全能模型”更具成本效益和响应速度。&lt;/li&gt;
&lt;li&gt;因此，阿里需要一个“模型矩阵”（Model Matrix），以“通义” (Tongyi) 基础模型为底座，衍生出适应不同业务的专业模型，实现对内业务的AI化再造。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;构建云服务生态-对外建生态&#34;&gt;构建云服务生态 (对外建生态)
&lt;/h2&gt;&lt;p&gt;这是阿里的核心战略。大模型是AI时代的“操作系统”，而算力（云服务）是“水和电”。阿里云的目标是成为AI时代领先的“算力+模型”基础设施提供商。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;打造“模型超市”：&lt;/strong&gt; 阿里云不仅提供自家的“通义”系列模型（如通义千问、通义万相、通义灵码等），还通过“魔搭”(ModelScope)社区汇聚了大量第三方和开源模型。发布众多模型，是为了向客户展示其强大的模型研发能力和丰富的模型库，吸引企业上云。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;“开源+闭源”并行：&lt;/strong&gt; 阿里（如开源“通义千问”Qwen系列）的开源策略，是为了快速构建开发者社区，抢占市场心智，加速技术迭代，并与Meta的Llama等国际开源力量竞争。开发者在开源模型上“练手”后，最终进行商业部署时，很可能会选择阿里云的付费算力和闭源商业模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结
&lt;/h2&gt;&lt;p&gt;简而言之，阿里发布众多大模型，其策略是：以“通义”系列为核心自研模型矩阵，深度赋能内部庞杂业务；同时，通过“开源”和“模型即服务”平台，在阿里云上构建一个开放、繁荣的AI生态系统，最终目的是&lt;strong&gt;驱动其核心的云计算业务增长&lt;/strong&gt;。&lt;/p&gt;</description>
        </item>
        <item>
        <title>近期大模型的一些使用经验</title>
        <link>https://ttf248.life/p/recent-usage-experiences-of-large-models/</link>
        <pubDate>Wed, 09 Jul 2025 21:09:01 +0800</pubDate>
        
        <guid>https://ttf248.life/p/recent-usage-experiences-of-large-models/</guid>
        <description>&lt;p&gt;现在用下来并没有哪个大模型特别好，各家都有自己的优势场景。&lt;/p&gt;
&lt;h2 id=&#34;技术文档&#34;&gt;技术文档
&lt;/h2&gt;&lt;p&gt;投喂代码或者咨询IT技术类的问题：ChatGPT 和 Gemini&lt;/p&gt;
&lt;h2 id=&#34;写代码&#34;&gt;写代码
&lt;/h2&gt;&lt;p&gt;整理需求，要求修改代码：Claude&lt;/p&gt;</description>
        </item>
        <item>
        <title>博客翻译项目碎碎念：历史会话</title>
        <link>https://ttf248.life/p/blog-translation-project-musings-historical-conversations/</link>
        <pubDate>Mon, 02 Jun 2025 21:16:24 +0800</pubDate>
        
        <guid>https://ttf248.life/p/blog-translation-project-musings-historical-conversations/</guid>
        <description>&lt;p&gt;博客翻译项目最初设计过于复杂——先解析 Markdown 格式，再用占位符保护内容，最后送给大模型翻译。其实这完全是多此一举，大模型本身就具备识别 Markdown 语法的能力，可以直接处理原始内容并在翻译时保持格式完整。&lt;/p&gt;
&lt;p&gt;我们的工作就从调试代码，切换到调试大模型的&lt;strong&gt;提示词&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;模型：&lt;code&gt;google/gemma-3-4b&lt;/code&gt;
硬件：&lt;code&gt;Nvdia 3060 12GB&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;没错，选的非思考模型，思考模型在执行翻译任务时，效率不够高，对比了 4b 参数和 12b 参数的效果，针对翻译任务来说 gemma3 的 4b 参数已经足够了，12b 的参数在翻译任务上并没有明显的优势。&lt;/p&gt;
&lt;p&gt;12b 参数的速度：&lt;strong&gt;11.32 tok/sec&lt;/strong&gt;，4b 参数的速度：&lt;strong&gt;75.21 tok/sec&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;背景介绍&#34;&gt;背景介绍
&lt;/h2&gt;&lt;p&gt;尽管在&lt;strong&gt;system&lt;/strong&gt;里面加上了各种条件限制，输出的翻译结果，还是会出现一些问题，比如：格式没有保护，多出来了一些解释的内容。角色定义的时候，已经声明过，记得保护 Markdown 格式、仅输出翻译结果，最终的翻译还是不太稳定。&lt;/p&gt;
&lt;p&gt;此时想起来，以前接触过一个漫画翻译的项目，也用到了大模型的能力，它的翻译效果好像比我的效果更好一些，翻看代码，对比请求的数据，漫画翻译的项目，每次请求都会带上一组上下文，除了当前的翻译内容，还会带上之前的翻译内容。&lt;/p&gt;
&lt;p&gt;好处是什么，不仅能提升前后翻译的连贯性，还剩确保输出格式的稳定性。&lt;/p&gt;
&lt;h2 id=&#34;历史会话的重要性&#34;&gt;历史会话的重要性
&lt;/h2&gt;&lt;p&gt;随着 AI 大模型（如 GPT 系列、Claude、Gemini 等）的普及，越来越多企业和开发者通过 API 接入这些模型，构建智能客服、内容生成、代码助手等应用。然而，许多人在接入初期会遇到一个常见问题：&lt;strong&gt;模型输出不连贯、缺乏上下文理解，甚至答非所问&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;造成这种现象的一个关键原因是——&lt;strong&gt;没有在 API 请求中包含历史对话内容&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;什么是历史对话&#34;&gt;什么是历史对话？
&lt;/h2&gt;&lt;p&gt;历史对话是指在一次对话会话中，模型和用户之间之前的交流记录。在大多数大模型 API（如 OpenAI 的 Chat Completions API）中，开发者需要自己在请求中构建完整的 &lt;code&gt;messages&lt;/code&gt; 数组，将历史对话以轮流的 &lt;code&gt;user&lt;/code&gt; 和 &lt;code&gt;assistant&lt;/code&gt; 消息形式传入。&lt;/p&gt;
&lt;h3 id=&#34;示例&#34;&gt;示例
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;model&amp;quot;: &amp;quot;gpt-4&amp;quot;,
  &amp;quot;messages&amp;quot;: [
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;帮我写一封辞职信&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;assistant&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;好的，你希望辞职的原因写些什么？&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;说我想追求个人职业发展&amp;quot;}
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果你只发送最后一句话：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;说我想追求个人职业发展&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;模型根本不知道你在说辞职信，它可能完全无法理解上下文，输出质量自然很差。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;为什么历史对话如此重要&#34;&gt;为什么历史对话如此重要？
&lt;/h2&gt;&lt;h3 id=&#34;1-构建上下文提升连贯性&#34;&gt;1. &lt;strong&gt;构建上下文，提升连贯性&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;AI 模型本质上是“上下文驱动”的。它无法记住“之前”发生的任何事情，除非你&lt;strong&gt;显式告诉它&lt;/strong&gt;。通过传入对话历史，模型可以更好地理解你的意图和话题背景，输出更符合预期。&lt;/p&gt;
&lt;h3 id=&#34;2-降低误解率&#34;&gt;2. &lt;strong&gt;降低误解率&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;如果你希望模型完成一个多轮指令，如写作、总结、调试代码，历史记录能让模型逐步积累理解，避免在中途“跑题”或丢失重点。&lt;/p&gt;
&lt;h3 id=&#34;3-模拟真实人类对话行为&#34;&gt;3. &lt;strong&gt;模拟真实人类对话行为&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;在实际应用中，如客服系统、教育助手、健康咨询等，用户的问题往往是逐步展开的，而不是一次性表达清楚。保留对话历史，可以让 AI 更像一个“有记忆力的助理”。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;如何在-api-中正确添加历史对话&#34;&gt;如何在 API 中正确添加历史对话？
&lt;/h2&gt;&lt;p&gt;以 OpenAI 的 API 为例，建议遵循以下结构：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;messages = [
    {&amp;quot;role&amp;quot;: &amp;quot;system&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;你是一个专业的法律助手&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;什么是合同的有效条件？&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;assistant&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;合同有效需要满足以下几个条件：……&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;那口头协议算吗？&amp;quot;}
]

response = openai.ChatCompletion.create(
    model=&amp;quot;gpt-4&amp;quot;,
    messages=messages
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;system&lt;/code&gt; 消息设定模型行为和身份。&lt;/li&gt;
&lt;li&gt;保留最近几轮关键对话即可，不需要每次传入全部历史（避免超过 token 限制）。&lt;/li&gt;
&lt;li&gt;在长会话中，可通过截断早期内容，保留核心信息摘要，控制 token 消耗。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;实践建议&#34;&gt;实践建议
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;对话状态管理&lt;/strong&gt;：后端需设计缓存机制，记录每个用户的会话历史（如 Redis、数据库）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;限制长度&lt;/strong&gt;：OpenAI GPT-4 的上下文长度为 128k tokens，Claude 3 可达 200k~1M，需合理裁剪。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;动态摘要历史&lt;/strong&gt;：当历史内容过长时，使用模型先对旧对话做摘要，再添加进对话上下文。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结
&lt;/h2&gt;&lt;p&gt;AI 大模型的能力强大，但也需要开发者“喂”给它足够的上下文信息。&lt;strong&gt;通过在 API 请求中添加历史对话，不仅能显著提升模型输出的质量和连贯性，也能让用户体验更自然、更贴近真实对话。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;无论你是在构建 AI 客服、写作助手、编程帮手，还是教育类应用，这都是一个不可忽视的优化技巧。&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

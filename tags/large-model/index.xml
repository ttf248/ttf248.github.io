<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>大模型 on 向叔记事簿</title>
        <link>https://ttf248.life/tags/large-model/</link>
        <description>Recent content in 大模型 on 向叔记事簿</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language><atom:link href="https://ttf248.life/tags/large-model/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>AI 变“笨”了吗？揭秘参数精度与推理成本的博弈</title>
        <link>https://ttf248.life/p/is-ai-getting-dumber-uncovering-the-game-between-parameter-precision-and-inference-costs/</link>
        <pubDate>Thu, 04 Dec 2025 21:58:09 +0800</pubDate>
        
        <guid>https://ttf248.life/p/is-ai-getting-dumber-uncovering-the-game-between-parameter-precision-and-inference-costs/</guid>
        <description>&lt;p&gt;近期混迹在各个编程大模型的交流圈，模型降智是大家吐槽最多的事情。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;本地台式机部署的都是量化以后的模型，可以说是降智后的版本&lt;/li&gt;
&lt;li&gt;vibe coding 这么热门，有没有可能当前大模型输出的内容，代码是最值钱的产物？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本轮的提示词有过一次优化，刚好是模型降智，大模型给的方案是优化提示词，更详细的任务规划、更明确的输出要求&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;针对这个问题，给出合适的提示词：现在很多大厂都提供了大模型服务，偶尔会有用户反馈模型降智问题；从专业角度，参数的精度、推理的成本出发，编写文章；科普文，不要太长。&lt;/p&gt;
&lt;p&gt;优化后的版本：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;你是一位资深的 AI 行业技术专栏作家。你的目标是撰写一篇针对普通读者但内容专业的中文科普文章。

请一步一步思考并撰写：
1. 大纲制定：首先，请拟定一个清晰的三段式文章结构大纲（例如：引言、精度分析、成本与架构分析、结论）。
2. 内容聚焦：文章必须深入浅出地解释用户反馈的“模型降智”现象，核心分析点必须围绕 **参数精度（量化）** 和 **推理的运营成本** 展开。
3. 字数与格式：最终文章长度必须控制在 600 字以内。请使用清晰的 `##` 标题 来划分段落，并使用 **粗体** 来强调文中的关键专业术语（如：量化、MoE、FP16）。
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;引言&#34;&gt;引言
&lt;/h2&gt;&lt;p&gt;为了确保逻辑清晰且符合科普要求，我制定了以下结构：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;引言：&lt;/strong&gt; 确认用户感知的真实性，引出核心矛盾——在用户规模激增的背景下，服务商必须在“智力巅峰”与“服务可用性”之间做平衡。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;精度分析（核心点1）：&lt;/strong&gt; 解释&lt;strong&gt;参数&lt;/strong&gt;与&lt;strong&gt;精度&lt;/strong&gt;的关系。通过对比 &lt;strong&gt;FP16&lt;/strong&gt; 与 &lt;strong&gt;量化&lt;/strong&gt;（INT8/INT4），用“图片压缩”的类比来说明为什么精度下降会导致逻辑变差。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;成本与架构（核心点2）：&lt;/strong&gt; 剖析&lt;strong&gt;推理成本&lt;/strong&gt;。介绍 &lt;strong&gt;MoE&lt;/strong&gt; 架构与&lt;strong&gt;稀疏激活&lt;/strong&gt;机制，解释为了省钱和加速，模型是如何“偷懒”的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;结论：&lt;/strong&gt; 总结这种“降智”是商业化普及的必经之路（不可能三角）。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;文章正文&#34;&gt;文章正文
&lt;/h2&gt;&lt;p&gt;近期，不少用户反馈大模型似乎没有以前“聪明”了：逻辑变简单、指令遵循变差，甚至出现车轱辘话。这并非全是错觉。从技术视角看，这种“降智”现象往往是大厂在面对海量用户时，为了平衡&lt;strong&gt;推理成本&lt;/strong&gt;与服务速度而做出的技术妥协。&lt;/p&gt;
&lt;h2 id=&#34;精度缩水从-4k-到-720p-的代价&#34;&gt;精度“缩水”：从 4K 到 720P 的代价
&lt;/h2&gt;&lt;p&gt;大模型的“智商”主要存储在数千亿个&lt;strong&gt;参数&lt;/strong&gt;中。在理想状态下，这些参数以高精度的 &lt;strong&gt;FP16&lt;/strong&gt;（16位浮点数）格式运行，能捕捉极细微的语义差别。但这种高精度意味着巨大的&lt;strong&gt;显存&lt;/strong&gt;占用和缓慢的计算速度。&lt;/p&gt;
&lt;p&gt;为了让数亿用户都能流畅使用，服务商普遍采用了&lt;strong&gt;量化&lt;/strong&gt;（Quantization）技术。这是一种将参数精度从 &lt;strong&gt;FP16&lt;/strong&gt; 压缩到 &lt;strong&gt;INT8&lt;/strong&gt; 甚至 &lt;strong&gt;INT4&lt;/strong&gt; 的手段。&lt;/p&gt;
&lt;p&gt;这就好比将一部 4K 高清电影压缩成 720P 流媒体：虽然剧情（大体逻辑）没变，但画面细节（微小的逻辑关联、复杂指令的执行细节）却丢失了。这种“有损压缩”直接导致模型在处理复杂任务时表现力下降，给用户一种“变笨”的体感。&lt;/p&gt;
&lt;h2 id=&#34;成本压力让大脑部分休息&#34;&gt;成本压力：让大脑“部分休息”
&lt;/h2&gt;&lt;p&gt;除了精度，&lt;strong&gt;推理的运营成本&lt;/strong&gt;是另一大核心因素。每次你向 AI 提问，服务器都要进行庞大的矩阵运算，电费和硬件损耗惊人。&lt;/p&gt;
&lt;p&gt;为了降低成本，现代大模型多采用 &lt;strong&gt;MoE&lt;/strong&gt;（Mixture of Experts，混合专家模型）架构。与传统模型每次都激活所有神经元不同，&lt;strong&gt;MoE&lt;/strong&gt; 采用&lt;strong&gt;稀疏激活&lt;/strong&gt;策略：针对你的问题，系统只唤醒模型中一小部分相关的“专家”网络，其余部分保持休眠。&lt;/p&gt;
&lt;p&gt;虽然这极大降低了计算量，但如果&lt;strong&gt;路由算法&lt;/strong&gt;（Router）为了负载均衡或节省算力，将你的复杂数学问题派发给了“文学专家”，或者为了速度牺牲了专家的调用数量，输出质量自然就会出现波动和下滑。&lt;/p&gt;
&lt;h2 id=&#34;结论&#34;&gt;结论
&lt;/h2&gt;&lt;p&gt;因此，所谓的“降智”，本质上是 AI 从实验室走向大规模商业化时的必然阵痛。在&lt;strong&gt;参数精度&lt;/strong&gt;上的克制和&lt;strong&gt;模型架构&lt;/strong&gt;上的精打细算，是厂商为了让每个人都能用得起 AI，而在“绝对聪明”与“成本效率”之间寻找的微妙平衡。&lt;/p&gt;</description>
        </item>
        <item>
        <title>终归还是回到国产模型</title>
        <link>https://ttf248.life/p/ultimately-its-returning-to-domestic-models/</link>
        <pubDate>Wed, 03 Dec 2025 22:33:47 +0800</pubDate>
        
        <guid>https://ttf248.life/p/ultimately-its-returning-to-domestic-models/</guid>
        <description>&lt;p&gt;前文提到 Gemini Cli 登录的时候需要配置谷歌云的项目 ID，这里就已经不对劲，如果是个人账号不会有这个限制，能出现这个限制，已经开始进入谷歌的风控系统，认为你不是个人账号。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;麻烦事，用了小半个月，刚适应，现在要回到 cc + 国产模型的怀抱。&lt;/li&gt;
&lt;li&gt;谷歌自研芯片成本优势那么大吗？市面上主流的模式都是 Tokens 积分，谷歌现在还是按次计费。&lt;/li&gt;
&lt;li&gt;GLM4.6 图片识别不太行，响应速度够快，照葫芦画瓢能力不行，模仿已有接口能力较弱；M2 图片识别凑合，指令遵循不够强, 照葫芦画瓢能力强。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;update: 不知道是谷歌自己修复了，还是由于切换港区绑定了信用卡，账号又能正常使用了&lt;/p&gt;
&lt;h2 id=&#34;梳理&#34;&gt;梳理
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;You are currently configured to use a Google Cloud Project but lack a Gemini Code Assist license. Please contact your administrator to request a license. (#3501)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;白天还能登录使用，晚上回家就不行了，开始以为更新导致的 bug，切换到老版本，还是不行，Github 提了 Issue，下面机器人自动给我牵扯出来一堆类似的问题。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/google-gemini/gemini-cli/issues/14447&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/google-gemini/gemini-cli/issues/14447&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;看完相关信息，发现不对劲，gemini cli 官网没更新，Github 上的文档提到，如果你登录的时候需要谷歌云ID，那就是被识别了，&lt;strong&gt;你不是个人开发者&lt;/strong&gt;。国内登录都是通过科学上网，登录IP信息都是机房的地址，被识别也很正常，谷歌也没想着让中国内地随便用，毕竟需要用到科学上网的地方就那么多了，大部分地区都能直接访问。&lt;/p&gt;
&lt;p&gt;继续搜索，社区里面类似的情况很多：&lt;a class=&#34;link&#34; href=&#34;https://discuss.google.dev/t/is-gemini-code-assist-incorrectly-identifying-my-personal-account-as-an-enterprise-account/287654/2&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://discuss.google.dev/t/is-gemini-code-assist-incorrectly-identifying-my-personal-account-as-an-enterprise-account/287654/2&lt;/a&gt;，也都是用着用着就不能用了。&lt;/p&gt;
&lt;h2 id=&#34;方案&#34;&gt;方案
&lt;/h2&gt;&lt;p&gt;M2 最近半月更新的内容也不少，通过&lt;strong&gt;MCP&lt;/strong&gt;支持联网搜索、支持图像识别。先用用看，后续不行了，再考虑找个法子给谷歌付费，切换到基础的付费版本，手上的美元信用卡不一定能付费成功，上次尝试付费ChatGPT就失败了。&lt;/p&gt;
&lt;h2 id=&#34;后记&#34;&gt;后记
&lt;/h2&gt;&lt;p&gt;回退代码，将昨天的任务，重新用 M2 重做一遍，问题不少，Gemini 那边一次搞定的东西，这边反复了很多次，提示词需要很精准，不能有歧义。对整体项目的理解不到位，需要尽可能的拆成小任务执行。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;上面的都是小问题，minimaxi 给的额度看着不少，实测下来，项目开发中，消耗的很快&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;谷歌自研芯片成本优势那么大吗？市面上主流的模式都是 Tokens 积分，谷歌现在还是按次计费。想要正常使用，minimaxi 第二档的年费五百能搞定，相比谷歌 pro 版本呢，确实便宜不少，谷歌 20 美金一个月，包年也没优惠，但是没限制新模式的使用，从当前发布节奏，发布了新模型，你都能用上。结合实际开发体验，貌似国内的性价比也不太行。&lt;/p&gt;
&lt;p&gt;怎么安慰自己呢，也许模型更蠢点，人脑介入更多，也不是坏事？&lt;/p&gt;
&lt;p&gt;之前不仅付费买了 M2，还买了 GLM4.6，两家都是通过 MCP 实现图片解析，怎么说呢，M2 的测试下来还行，图片理解没太大问题， GLM4.6 不知道在搞什么，理解的东西完全不对。&lt;/p&gt;</description>
        </item>
        <item>
        <title>阿里巴巴大模型策略</title>
        <link>https://ttf248.life/p/alibaba-large-model-strategy/</link>
        <pubDate>Tue, 18 Nov 2025 22:07:10 +0800</pubDate>
        
        <guid>https://ttf248.life/p/alibaba-large-model-strategy/</guid>
        <description>&lt;p&gt;阿里巴巴（阿里）发布众多大模型，并非简单的“刷数量”，而是一种精心布局的**“模型即服务”(MaaS)生态策略**。这背后有多重考量，可概述为“对内赋能、对外建生态”：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;阿里巴巴怎么会发布那么多大模型？这是个什么策略？五百字左右，概述一下&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;内部业务驱动-对内赋能&#34;&gt;内部业务驱动 (对内赋能)
&lt;/h2&gt;&lt;p&gt;阿里拥有极其庞大且多元的业务版图，包括电商（淘宝天猫）、金融（蚂蚁）、物流（菜鸟）、云计算（阿里云）、文娱（优酷）等。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;场景定制化：&lt;/strong&gt; 单一的通用大模型无法高效满足所有垂直场景的精细化需求。例如，电商客服模型、广告创意生成模型、金融风控模型和物流路径规划模型所需的能力截然不同。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;效率与成本：&lt;/strong&gt; 针对特定任务（如编码、作图）训练专门的“小模型”，比始终调用一个庞大的“全能模型”更具成本效益和响应速度。&lt;/li&gt;
&lt;li&gt;因此，阿里需要一个“模型矩阵”（Model Matrix），以“通义” (Tongyi) 基础模型为底座，衍生出适应不同业务的专业模型，实现对内业务的AI化再造。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;构建云服务生态-对外建生态&#34;&gt;构建云服务生态 (对外建生态)
&lt;/h2&gt;&lt;p&gt;这是阿里的核心战略。大模型是AI时代的“操作系统”，而算力（云服务）是“水和电”。阿里云的目标是成为AI时代领先的“算力+模型”基础设施提供商。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;打造“模型超市”：&lt;/strong&gt; 阿里云不仅提供自家的“通义”系列模型（如通义千问、通义万相、通义灵码等），还通过“魔搭”(ModelScope)社区汇聚了大量第三方和开源模型。发布众多模型，是为了向客户展示其强大的模型研发能力和丰富的模型库，吸引企业上云。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;“开源+闭源”并行：&lt;/strong&gt; 阿里（如开源“通义千问”Qwen系列）的开源策略，是为了快速构建开发者社区，抢占市场心智，加速技术迭代，并与Meta的Llama等国际开源力量竞争。开发者在开源模型上“练手”后，最终进行商业部署时，很可能会选择阿里云的付费算力和闭源商业模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结
&lt;/h2&gt;&lt;p&gt;简而言之，阿里发布众多大模型，其策略是：以“通义”系列为核心自研模型矩阵，深度赋能内部庞杂业务；同时，通过“开源”和“模型即服务”平台，在阿里云上构建一个开放、繁荣的AI生态系统，最终目的是&lt;strong&gt;驱动其核心的云计算业务增长&lt;/strong&gt;。&lt;/p&gt;</description>
        </item>
        <item>
        <title>近期大模型的一些使用经验</title>
        <link>https://ttf248.life/p/recent-usage-experiences-of-large-models/</link>
        <pubDate>Wed, 09 Jul 2025 21:09:01 +0800</pubDate>
        
        <guid>https://ttf248.life/p/recent-usage-experiences-of-large-models/</guid>
        <description>&lt;p&gt;现在用下来并没有哪个大模型特别好，各家都有自己的优势场景。&lt;/p&gt;
&lt;h2 id=&#34;技术文档&#34;&gt;技术文档
&lt;/h2&gt;&lt;p&gt;投喂代码或者咨询IT技术类的问题：ChatGPT 和 Gemini&lt;/p&gt;
&lt;h2 id=&#34;写代码&#34;&gt;写代码
&lt;/h2&gt;&lt;p&gt;整理需求，要求修改代码：Claude&lt;/p&gt;</description>
        </item>
        <item>
        <title>博客翻译项目碎碎念：历史会话</title>
        <link>https://ttf248.life/p/blog-translation-project-musings-historical-conversations/</link>
        <pubDate>Mon, 02 Jun 2025 21:16:24 +0800</pubDate>
        
        <guid>https://ttf248.life/p/blog-translation-project-musings-historical-conversations/</guid>
        <description>&lt;p&gt;博客翻译项目最初设计过于复杂——先解析 Markdown 格式，再用占位符保护内容，最后送给大模型翻译。其实这完全是多此一举，大模型本身就具备识别 Markdown 语法的能力，可以直接处理原始内容并在翻译时保持格式完整。&lt;/p&gt;
&lt;p&gt;我们的工作就从调试代码，切换到调试大模型的&lt;strong&gt;提示词&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;模型：&lt;code&gt;google/gemma-3-4b&lt;/code&gt;
硬件：&lt;code&gt;Nvdia 3060 12GB&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;没错，选的非思考模型，思考模型在执行翻译任务时，效率不够高，对比了 4b 参数和 12b 参数的效果，针对翻译任务来说 gemma3 的 4b 参数已经足够了，12b 的参数在翻译任务上并没有明显的优势。&lt;/p&gt;
&lt;p&gt;12b 参数的速度：&lt;strong&gt;11.32 tok/sec&lt;/strong&gt;，4b 参数的速度：&lt;strong&gt;75.21 tok/sec&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;背景介绍&#34;&gt;背景介绍
&lt;/h2&gt;&lt;p&gt;尽管在&lt;strong&gt;system&lt;/strong&gt;里面加上了各种条件限制，输出的翻译结果，还是会出现一些问题，比如：格式没有保护，多出来了一些解释的内容。角色定义的时候，已经声明过，记得保护 Markdown 格式、仅输出翻译结果，最终的翻译还是不太稳定。&lt;/p&gt;
&lt;p&gt;此时想起来，以前接触过一个漫画翻译的项目，也用到了大模型的能力，它的翻译效果好像比我的效果更好一些，翻看代码，对比请求的数据，漫画翻译的项目，每次请求都会带上一组上下文，除了当前的翻译内容，还会带上之前的翻译内容。&lt;/p&gt;
&lt;p&gt;好处是什么，不仅能提升前后翻译的连贯性，还剩确保输出格式的稳定性。&lt;/p&gt;
&lt;h2 id=&#34;历史会话的重要性&#34;&gt;历史会话的重要性
&lt;/h2&gt;&lt;p&gt;随着 AI 大模型（如 GPT 系列、Claude、Gemini 等）的普及，越来越多企业和开发者通过 API 接入这些模型，构建智能客服、内容生成、代码助手等应用。然而，许多人在接入初期会遇到一个常见问题：&lt;strong&gt;模型输出不连贯、缺乏上下文理解，甚至答非所问&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;造成这种现象的一个关键原因是——&lt;strong&gt;没有在 API 请求中包含历史对话内容&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;什么是历史对话&#34;&gt;什么是历史对话？
&lt;/h2&gt;&lt;p&gt;历史对话是指在一次对话会话中，模型和用户之间之前的交流记录。在大多数大模型 API（如 OpenAI 的 Chat Completions API）中，开发者需要自己在请求中构建完整的 &lt;code&gt;messages&lt;/code&gt; 数组，将历史对话以轮流的 &lt;code&gt;user&lt;/code&gt; 和 &lt;code&gt;assistant&lt;/code&gt; 消息形式传入。&lt;/p&gt;
&lt;h3 id=&#34;示例&#34;&gt;示例
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;model&amp;quot;: &amp;quot;gpt-4&amp;quot;,
  &amp;quot;messages&amp;quot;: [
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;帮我写一封辞职信&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;assistant&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;好的，你希望辞职的原因写些什么？&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;说我想追求个人职业发展&amp;quot;}
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果你只发送最后一句话：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;说我想追求个人职业发展&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;模型根本不知道你在说辞职信，它可能完全无法理解上下文，输出质量自然很差。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;为什么历史对话如此重要&#34;&gt;为什么历史对话如此重要？
&lt;/h2&gt;&lt;h3 id=&#34;1-构建上下文提升连贯性&#34;&gt;1. &lt;strong&gt;构建上下文，提升连贯性&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;AI 模型本质上是“上下文驱动”的。它无法记住“之前”发生的任何事情，除非你&lt;strong&gt;显式告诉它&lt;/strong&gt;。通过传入对话历史，模型可以更好地理解你的意图和话题背景，输出更符合预期。&lt;/p&gt;
&lt;h3 id=&#34;2-降低误解率&#34;&gt;2. &lt;strong&gt;降低误解率&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;如果你希望模型完成一个多轮指令，如写作、总结、调试代码，历史记录能让模型逐步积累理解，避免在中途“跑题”或丢失重点。&lt;/p&gt;
&lt;h3 id=&#34;3-模拟真实人类对话行为&#34;&gt;3. &lt;strong&gt;模拟真实人类对话行为&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;在实际应用中，如客服系统、教育助手、健康咨询等，用户的问题往往是逐步展开的，而不是一次性表达清楚。保留对话历史，可以让 AI 更像一个“有记忆力的助理”。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;如何在-api-中正确添加历史对话&#34;&gt;如何在 API 中正确添加历史对话？
&lt;/h2&gt;&lt;p&gt;以 OpenAI 的 API 为例，建议遵循以下结构：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;messages = [
    {&amp;quot;role&amp;quot;: &amp;quot;system&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;你是一个专业的法律助手&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;什么是合同的有效条件？&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;assistant&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;合同有效需要满足以下几个条件：……&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;那口头协议算吗？&amp;quot;}
]

response = openai.ChatCompletion.create(
    model=&amp;quot;gpt-4&amp;quot;,
    messages=messages
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;system&lt;/code&gt; 消息设定模型行为和身份。&lt;/li&gt;
&lt;li&gt;保留最近几轮关键对话即可，不需要每次传入全部历史（避免超过 token 限制）。&lt;/li&gt;
&lt;li&gt;在长会话中，可通过截断早期内容，保留核心信息摘要，控制 token 消耗。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;实践建议&#34;&gt;实践建议
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;对话状态管理&lt;/strong&gt;：后端需设计缓存机制，记录每个用户的会话历史（如 Redis、数据库）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;限制长度&lt;/strong&gt;：OpenAI GPT-4 的上下文长度为 128k tokens，Claude 3 可达 200k~1M，需合理裁剪。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;动态摘要历史&lt;/strong&gt;：当历史内容过长时，使用模型先对旧对话做摘要，再添加进对话上下文。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结
&lt;/h2&gt;&lt;p&gt;AI 大模型的能力强大，但也需要开发者“喂”给它足够的上下文信息。&lt;strong&gt;通过在 API 请求中添加历史对话，不仅能显著提升模型输出的质量和连贯性，也能让用户体验更自然、更贴近真实对话。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;无论你是在构建 AI 客服、写作助手、编程帮手，还是教育类应用，这都是一个不可忽视的优化技巧。&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

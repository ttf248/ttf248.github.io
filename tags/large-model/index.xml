<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>大模型 on 向叔记事簿</title>
        <link>https://ttf248.life/tags/large-model/</link>
        <description>Recent content in 大模型 on 向叔记事簿</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language><atom:link href="https://ttf248.life/tags/large-model/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>近期大模型的一些使用经验</title>
        <link>https://ttf248.life/p/recent-usage-experiences-of-large-models/</link>
        <pubDate>Wed, 09 Jul 2025 21:09:01 +0800</pubDate>
        
        <guid>https://ttf248.life/p/recent-usage-experiences-of-large-models/</guid>
        <description>&lt;p&gt;现在用下来并没有哪个大模型特别好，各家都有自己的优势场景。&lt;/p&gt;
&lt;h2 id=&#34;技术文档&#34;&gt;技术文档
&lt;/h2&gt;&lt;p&gt;投喂代码或者咨询IT技术类的问题：ChatGPT 和 Gemini&lt;/p&gt;
&lt;h2 id=&#34;写代码&#34;&gt;写代码
&lt;/h2&gt;&lt;p&gt;整理需求，要求修改代码：Claude&lt;/p&gt;
&lt;h2 id=&#34;金融类咨询&#34;&gt;金融类咨询
&lt;/h2&gt;&lt;p&gt;这里仅测试了混元和deepseek，都是在腾讯的平台，deepseek 明显更加专业一些&lt;/p&gt;</description>
        </item>
        <item>
        <title>博客翻译项目碎碎念：历史会话</title>
        <link>https://ttf248.life/p/blog-translation-project-musings-historical-conversations/</link>
        <pubDate>Mon, 02 Jun 2025 21:16:24 +0800</pubDate>
        
        <guid>https://ttf248.life/p/blog-translation-project-musings-historical-conversations/</guid>
        <description>&lt;p&gt;博客翻译项目最初设计过于复杂——先解析 Markdown 格式，再用占位符保护内容，最后送给大模型翻译。其实这完全是多此一举，大模型本身就具备识别 Markdown 语法的能力，可以直接处理原始内容并在翻译时保持格式完整。&lt;/p&gt;
&lt;p&gt;我们的工作就从调试代码，切换到调试大模型的&lt;strong&gt;提示词&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;模型：&lt;code&gt;google/gemma-3-4b&lt;/code&gt;
硬件：&lt;code&gt;Nvdia 3060 12GB&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;没错，选的非思考模型，思考模型在执行翻译任务时，效率不够高，对比了 4b 参数和 12b 参数的效果，针对翻译任务来说 gemma3 的 4b 参数已经足够了，12b 的参数在翻译任务上并没有明显的优势。&lt;/p&gt;
&lt;p&gt;12b 参数的速度：&lt;strong&gt;11.32 tok/sec&lt;/strong&gt;，4b 参数的速度：&lt;strong&gt;75.21 tok/sec&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;背景介绍&#34;&gt;背景介绍
&lt;/h2&gt;&lt;p&gt;尽管在&lt;strong&gt;system&lt;/strong&gt;里面加上了各种条件限制，输出的翻译结果，还是会出现一些问题，比如：格式没有保护，多出来了一些解释的内容。角色定义的时候，已经声明过，记得保护 Markdown 格式、仅输出翻译结果，最终的翻译还是不太稳定。&lt;/p&gt;
&lt;p&gt;此时想起来，以前接触过一个漫画翻译的项目，也用到了大模型的能力，它的翻译效果好像比我的效果更好一些，翻看代码，对比请求的数据，漫画翻译的项目，每次请求都会带上一组上下文，除了当前的翻译内容，还会带上之前的翻译内容。&lt;/p&gt;
&lt;p&gt;好处是什么，不仅能提升前后翻译的连贯性，还剩确保输出格式的稳定性。&lt;/p&gt;
&lt;h2 id=&#34;历史会话的重要性&#34;&gt;历史会话的重要性
&lt;/h2&gt;&lt;p&gt;随着 AI 大模型（如 GPT 系列、Claude、Gemini 等）的普及，越来越多企业和开发者通过 API 接入这些模型，构建智能客服、内容生成、代码助手等应用。然而，许多人在接入初期会遇到一个常见问题：&lt;strong&gt;模型输出不连贯、缺乏上下文理解，甚至答非所问&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;造成这种现象的一个关键原因是——&lt;strong&gt;没有在 API 请求中包含历史对话内容&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;什么是历史对话&#34;&gt;什么是历史对话？
&lt;/h2&gt;&lt;p&gt;历史对话是指在一次对话会话中，模型和用户之间之前的交流记录。在大多数大模型 API（如 OpenAI 的 Chat Completions API）中，开发者需要自己在请求中构建完整的 &lt;code&gt;messages&lt;/code&gt; 数组，将历史对话以轮流的 &lt;code&gt;user&lt;/code&gt; 和 &lt;code&gt;assistant&lt;/code&gt; 消息形式传入。&lt;/p&gt;
&lt;h3 id=&#34;示例&#34;&gt;示例
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;model&amp;quot;: &amp;quot;gpt-4&amp;quot;,
  &amp;quot;messages&amp;quot;: [
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;帮我写一封辞职信&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;assistant&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;好的，你希望辞职的原因写些什么？&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;说我想追求个人职业发展&amp;quot;}
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果你只发送最后一句话：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;说我想追求个人职业发展&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;模型根本不知道你在说辞职信，它可能完全无法理解上下文，输出质量自然很差。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;为什么历史对话如此重要&#34;&gt;为什么历史对话如此重要？
&lt;/h2&gt;&lt;h3 id=&#34;1-构建上下文提升连贯性&#34;&gt;1. &lt;strong&gt;构建上下文，提升连贯性&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;AI 模型本质上是“上下文驱动”的。它无法记住“之前”发生的任何事情，除非你&lt;strong&gt;显式告诉它&lt;/strong&gt;。通过传入对话历史，模型可以更好地理解你的意图和话题背景，输出更符合预期。&lt;/p&gt;
&lt;h3 id=&#34;2-降低误解率&#34;&gt;2. &lt;strong&gt;降低误解率&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;如果你希望模型完成一个多轮指令，如写作、总结、调试代码，历史记录能让模型逐步积累理解，避免在中途“跑题”或丢失重点。&lt;/p&gt;
&lt;h3 id=&#34;3-模拟真实人类对话行为&#34;&gt;3. &lt;strong&gt;模拟真实人类对话行为&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;在实际应用中，如客服系统、教育助手、健康咨询等，用户的问题往往是逐步展开的，而不是一次性表达清楚。保留对话历史，可以让 AI 更像一个“有记忆力的助理”。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;如何在-api-中正确添加历史对话&#34;&gt;如何在 API 中正确添加历史对话？
&lt;/h2&gt;&lt;p&gt;以 OpenAI 的 API 为例，建议遵循以下结构：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;messages = [
    {&amp;quot;role&amp;quot;: &amp;quot;system&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;你是一个专业的法律助手&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;什么是合同的有效条件？&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;assistant&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;合同有效需要满足以下几个条件：……&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;那口头协议算吗？&amp;quot;}
]

response = openai.ChatCompletion.create(
    model=&amp;quot;gpt-4&amp;quot;,
    messages=messages
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;system&lt;/code&gt; 消息设定模型行为和身份。&lt;/li&gt;
&lt;li&gt;保留最近几轮关键对话即可，不需要每次传入全部历史（避免超过 token 限制）。&lt;/li&gt;
&lt;li&gt;在长会话中，可通过截断早期内容，保留核心信息摘要，控制 token 消耗。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;实践建议&#34;&gt;实践建议
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;对话状态管理&lt;/strong&gt;：后端需设计缓存机制，记录每个用户的会话历史（如 Redis、数据库）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;限制长度&lt;/strong&gt;：OpenAI GPT-4 的上下文长度为 128k tokens，Claude 3 可达 200k~1M，需合理裁剪。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;动态摘要历史&lt;/strong&gt;：当历史内容过长时，使用模型先对旧对话做摘要，再添加进对话上下文。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结
&lt;/h2&gt;&lt;p&gt;AI 大模型的能力强大，但也需要开发者“喂”给它足够的上下文信息。&lt;strong&gt;通过在 API 请求中添加历史对话，不仅能显著提升模型输出的质量和连贯性，也能让用户体验更自然、更贴近真实对话。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;无论你是在构建 AI 客服、写作助手、编程帮手，还是教育类应用，这都是一个不可忽视的优化技巧。&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

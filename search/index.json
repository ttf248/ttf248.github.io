[{"content":"从什么版本开始的我也不清楚，但是在Windows 11中，磁盘清理工具已经有了很大的改进，变得更加智能了。\n重点它是官方的工具，不会误删文件，不会有广告，不会有弹窗，不会有后台进程，不会有任何不必要的东西。\n在Windows 11中，可以通过设置-系统-存储-临时文件来打开磁盘清理工具。\n普通用户选择清理建议即可，系统会根据你的使用情况，给出一些建议。\n笔者作为一个开发者，磁盘上有很多临时文件，所以选择临时文件，里面包含了很多临时文件，比如Visual Studio的临时文件，Windows Update的临时文件等等。\n","date":"2025-01-06T19:29:45+08:00","permalink":"https://ttf248.github.io/p/windows%E8%87%AA%E5%B8%A6%E7%9A%84%E7%A3%81%E7%9B%98%E6%B8%85%E7%90%86%E5%B7%A5%E5%85%B7%E5%AD%98%E5%82%A8/","title":"Windows自带的磁盘清理工具：存储"},{"content":"国内服务器部署docker，部署以后，如果公司没有提供镜像中心，开发首先要做的就是配置一个国内的镜像加速地址。巧了今天有台服务器，配置了镜像加速地址，但是发现拉取镜像的时候，一直拉取不到。\n报错信息：Error response from daemon: Get \u0026quot;https://registry-1.docker.io/v2/\u0026quot;: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\n20250106 时隔两天，所有的服务器都恢复了，这事居然不上热搜，国内所有的镜像代理都挂了\n故障排查与修复尝试 起初，尝试切换至其他镜像加速地址，期望借此解决问题，然而事与愿违，问题依旧。\n紧接着，着手修改本地 DNS 配置，试图从网络解析层面找到突破口，遗憾的是，经过一番调试，故障依然存在。\n此时，本地网络的稳定性已备受质疑，于是果断切换至手机热点，试图绕过可能存在的本地网络故障点，可结果还是令人沮丧，问题毫无改善迹象。\n问题蔓延 手头尚有几台部署于国内的服务器，且均安装了 Docker 环境。尝试在这些服务器上拉取镜像，本以为能另辟蹊径，结果发现无一例外，均无法成功拉取，所反馈的报错信息如出一辙，这表明问题并非局限于某一台设备。\n进一步探究发现，镜像代理似乎瞬间失灵，在这紧急关头，迅速切换至境外机器进行尝试，令人稍感欣慰的是，镜像拉取在此处恢复正常，这意味着问题大概率出在国内的网络链路或相关配置上。\n策略调整：迂回解决 鉴于国内直接拉取镜像的途径已被重重阻碍，而国外镜像却能正常访问，为尽快推进项目，决定采取迂回战术。首先切换至国外服务器，顺利拉取所需镜像，随后将其推送至国内镜像仓库，以此搭建起一座“数据桥梁”。\n与此同时，同步对 Dockerfile 文件进行修改，将镜像地址替换为适配国内环境的地址，再重新构建镜像，最终成功部署。\n","date":"2025-01-04T18:29:25+08:00","permalink":"https://ttf248.github.io/p/docker-%E5%9B%BD%E5%86%85%E9%95%9C%E5%83%8F%E4%BB%A3%E7%90%86%E5%A4%B1%E6%95%88/","title":"Docker 国内镜像代理失效"},{"content":"电竞产业，在过去十余年中经历了迅猛的发展，成为了全球范围内不可忽视的文化现象。特别是以《英雄联盟》（League of Legends，简称LOL）为代表的MOBA类游戏，它不仅为玩家提供了竞技的乐趣，也为资本注入了强大的动力，推动着一系列电竞平台和赛事的蓬勃发展。然而，这一切随着资本的涌入和泛娱乐产业的崛起，也进入了一个逐渐衰退的阶段。熊猫TV的兴起与陨落、斗鱼与虎牙的竞争，标志着“野蛮资本时代”的落幕，电竞行业的天时地利人和似乎也都开始发生变化。\n第一章：电竞的崛起与资本注入 1.1 初期的电子竞技：从草根到职业化\n早期的电竞产业起步相对草根，尤其是中国市场。许多玩家凭借对游戏的热爱，参与到《星际争霸》、Dota等游戏的竞技中。然而，电竞的真正崛起始于《英雄联盟》的发布与推广。自2011年《英雄联盟》正式进入中国市场后，电竞逐渐从一个小众圈子发展为大众文化的一部分。特别是在2013年起，LPL（中国职业联赛）逐步形成，英雄联盟成为了中国电竞产业的顶梁柱。\n1.2 资本疯狂涌入：熊猫TV与电竞直播平台的兴起\n2015年，是中国电竞行业的一个分水岭。资本的涌入让电竞从单纯的竞技赛事，转向了更为庞大的产业链。熊猫TV作为代表之一，成为了资本过剩的产物。由王思聪（熊猫直播的创始人之一）投资的熊猫TV迅速崛起，以其创新的内容与庞大的投资吸引了大量观众和用户。然而，这也正是资本“野蛮”流入的典型例子——资本对市场的疯狂追逐往往缺乏耐性和长远眼光。熊猫TV的资金和人力投入虽然短期内取得了一定成绩，但因为管理问题和过度依赖资本的高烧，最终在2019年宣告破产。\n1.3 直播平台竞争：斗鱼与虎牙的“资本大战”\n熊猫TV的陨落并未导致电竞直播行业的衰退，反而推动了斗鱼和虎牙等平台的崛起。斗鱼和虎牙两大直播平台迅速成为电竞行业的领军者，彼此竞争也愈发激烈。斗鱼早期凭借《英雄联盟》职业赛事的直播，以及对顶级主播的签约，成为了电竞直播的标杆。而虎牙则通过加大对电竞赛事的投入以及自身平台的多元化布局，逐渐缩小了与斗鱼的差距。\n在这一过程中，资本再次发挥了巨大的作用。斗鱼于2018年成功上市，虎牙则于同年也进行了IPO。资本的快速流动带来了行业的高度集中，也导致了平台之间在主播、版权等方面的激烈竞争，形成了“资本大战”。\n第二章：泛娱乐化与电竞的融合 2.1 泛娱乐化浪潮：资金流向多元化娱乐项目\n随着资本对电竞行业的重注，电竞平台的内容逐渐泛娱乐化。电竞主播不仅局限于比赛解说和赛事直播，他们开始拓展到唱歌、跳舞、直播互动等多种娱乐形式。平台上的内容更加丰富，逐步形成了以电竞为核心，但又包含多种娱乐元素的内容生态。\n然而，泛娱乐化也带来了问题——电竞原本专注的游戏文化逐渐被边缘化，取而代之的是娱乐至上的趋势。这种趋势让一些原本深爱电竞文化的观众产生了离场的情绪，而资本也开始将更多的目光转向其他娱乐领域。资本的过度涌入与逐利性让电竞产业的本质逐渐变得模糊，原本以竞技为核心的价值理念开始弱化。\n2.2 泛娱乐行业的崛起：资本的撤退与转型\n随着短视频平台、直播平台以及娱乐圈等其他泛娱乐产业的崛起，资本逐渐将资金从电竞转向了更为广泛的娱乐内容。在这个过程中，腾讯、阿里巴巴、字节跳动等巨头也不再单纯依靠电竞项目作为盈利来源，而是加大了在电影、音乐、短视频等领域的投资。特别是字节跳动的崛起，通过抖音等短视频平台的爆发式增长，使得电竞的风头被其他娱乐内容所掩盖。\n第三章：英雄联盟的“青黄不接”：时代红利消退 自2011年《英雄联盟》进入中国市场以来，它几乎是中国电竞行业的代名词，成就了无数职业选手、战队和赛事，也催生了一个庞大的电竞产业链。然而，十多年过去了，《英雄联盟》作为中国电竞的领军项目，已经进入了“青黄不接”的阶段。尤其是在最近几年，《英雄联盟》的影响力正在逐渐下滑，甚至出现了明显的衰退迹象。\n3.1 玩家群体的“断层”\n最为明显的变化便是玩家群体的断层。最初，电竞的快速发展依靠的是大量青少年玩家的支持，他们中的许多人因为《英雄联盟》而成为了职业玩家或观众。那一代网瘾少年，几乎是在“时代红利”下成长起来的，他们沉浸于LOL带来的竞技魅力之中，也因此推动了整个行业的快速扩张。然而，随着时间的推移，这些玩家逐渐长大，进入了社会，开始转向其他生活和职业方向。与此同时，新一代的年轻玩家对《英雄联盟》的兴趣并不如当年的热烈，电竞的受众群体已经出现了明显的年龄偏差和兴趣下降。\n3.2 游戏内容的“疲软”\n《英雄联盟》经过多次更新和改版，虽然依然保持着一定的竞技魅力，但游戏本身的内容创新已经显得有些力不从心。每年发布的版本更新、英雄平衡调整以及新玩法的引入，似乎都未能从根本上解决玩家对新鲜感的需求。与此同时，MOBA类游戏的市场逐渐饱和，其他类型的游戏（如《王者荣耀》、《和平精英》）迅速崛起，分流了大量原本属于《英雄联盟》的玩家。这种竞争态势，让《英雄联盟》始终无法摆脱“追赶者”的角色。\n结语：电竞产业的未来何去何从？ 电竞产业更像是凭空而起的高楼，过多的资金在互联网行业中游荡，他们在寻找着下一个风口，而电竞产业也成为了他们的目标之一。依托着国内的人口红利，电竞产业在短时间内取得了巨大的成功，但这种成功并不是建立在稳固的基础之上。资本的过度涌入、人才的短缺、游戏内容的疲软，这些问题都在阻碍着电竞产业的健康发展。\n大学时代以前，游戏玩的并不是很多，可以说联盟算是伴随了一代人的成长，总决赛看了那么多，作为一个局外人，对比中韩的选手，特别是 Faker，国内的选手，在大赛期间，总是有一种畏首畏尾的感觉，我也知道选手的心理压力很大，但是这个行业也发展了十多年，选手的心理问题，理应被团队重视，但是并没有，国内的玩法还是依靠选手自身的天赋。\n","date":"2024-12-31T07:19:39+08:00","permalink":"https://ttf248.github.io/p/%E9%87%8E%E8%9B%AE%E8%B5%84%E6%9C%AC%E6%97%B6%E4%BB%A3%E7%9A%84%E8%90%BD%E5%B9%95%E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9F%E7%94%B5%E7%AB%9E%E6%97%B6%E4%BB%A3%E7%BB%88%E7%BB%93/","title":"野蛮资本时代的落幕：英雄联盟电竞时代终结"},{"content":"要说什么时候游戏玩起来最开心，小时候偷偷用家里的电视玩坦克大战、超级玛丽、魂斗罗，还是和堂弟偷偷用家里的电脑玩帝国时代，亦或者是到了大学，和室友一起玩鬼泣、英雄联盟？\n小时候没有生活的烦恼，玩的时候，真的就是全身心的投入其中，那种沉浸感，是长大后再也找不到的。\n随着时代的变化和社会的进步，曾经活跃在虚拟世界中的我们逐渐意识到，那个曾经充满欢乐和竞争的游戏平台，似乎正在远离我们的生活。游戏社交链接的断开，伴随着玩家逐渐脱线，不仅仅是由于技术的进步和游戏本身的更替，更是因为我们生活重心的转变。随着年龄的增长，我们开始忙于结婚、生子，生活的主线逐渐从个人娱乐转向了家庭责任。今天，让我们聊聊这股趋势背后的深层原因。\n游戏社交的消失：虚拟世界与现实世界的拉锯战 在很多人的青春岁月里，游戏不仅仅是娱乐，它是一种社交方式。一款热门的多人在线游戏，不仅仅提供了游戏内的挑战和竞争，也连接了世界各地的玩家，构建了一个个虚拟的社交圈。在那个时代，和朋友们一起打副本、组队PK，是生活中的一部分。那些深夜语音聊天、互相分享日常的时光，成了我们记忆中的一部分。\n然而，随着时间的推移，越来越多的玩家发现，这种虚拟社交的体验并没有永恒的吸引力。随着游戏的更新换代，社交平台的多样化，玩家们逐渐在游戏外的社交圈找到了更多的互动方式。游戏中的朋友，逐渐消失在我们生活的视野之外，很多原本活跃在游戏中的社交链接，也在无形中断裂。\n游戏与责任：成年后生活的重心转变 进入成年后，生活中的责任开始逐渐增多。许多年轻人曾经在游戏中投入大量时间，但随着职业生涯的开始，或者是与伴侣共同生活、组建家庭，这些以前看似不可或缺的娱乐活动，开始受到现实生活中责任的挤压。结婚、生子，甚至是照顾父母，这些生活中的重大责任，让人不得不在精力和时间上做出选择。\n游戏成为了过去式，取而代之的是家庭生活的优先级。许多曾经在游戏中“奋斗”的年轻人，逐渐发现，现实中的生活才是最重要的课题。特别是有了孩子以后，生活的重心彻底偏向家庭，游戏逐渐被挤压到了生活的边缘。\n从游戏到家庭：生活中的变化是怎样影响我们的娱乐方式 在我们的生活经历中，家庭是最重要的组成部分之一。而一旦进入家庭生活，时间和精力的划分就变得更加具体而有限。为了照顾孩子、陪伴配偶，许多年轻父母发现，他们已经没有足够的时间去关注自己曾经热爱的游戏。甚至有时，他们甚至不再追逐游戏的更新与新鲜感。逐渐地，社交平台和线下的亲友互动成为了更多人交际的首选。\n这并非意味着我们完全放弃了娱乐活动，而是选择了更加符合当前生活阶段的方式。许多原本习惯通过游戏维持联系的朋友，可能因为生活轨迹的不同，选择通过其他方式保持联系，比如家庭聚会、聚餐、短途旅游等。\n虚拟世界的告别：我们如何看待这一转变？ 对于许多曾经沉浸在游戏中的人来说，和游戏社交的告别并不容易。毕竟，那个曾经为我们带来欢乐与成就感的虚拟世界，早已成为了我们记忆的一部分。然而，告别并非意味着彻底割舍，而是随着生活的变化，我们开始做出不同的选择，去平衡自己在现实生活中的角色。随着年龄的增长，我们从青涩的少年成长为有责任的成年人，游戏虽然仍然有其价值，但已经不能再作为生活的主旋律。\n实际上，这种转变也体现了人类适应力的一个方面——我们能够根据不同的阶段调整我们的关注点和生活方式。当责任和家庭成为生活的核心时，游戏社交不再是优先选择，而是成为一种偶尔的休闲方式。\n未来的游戏：或许会迎来另一波的“归属感” 当然，随着社会发展和技术的进步，游戏的形式和内容也在不断进化。比如，现在的多人在线游戏已经开始向更加轻松和灵活的方式发展，甚至有一些设计上更加注重家庭互动和亲子关系的游戏。未来，也许我们会看到更多游戏形式，能够更好地融入家庭生活，并且为玩家提供更加健康、平衡的社交体验。\n就像许多人在谈到“小时候的游戏”时，仍然充满怀念与热情，未来的我们或许也能在某个不经意的瞬间，重新捡起那些曾经的游戏，带着新的理解与体悟，再次走进那个虚拟的世界。\n生活在变化，但热爱依旧 无论是游戏还是家庭，生活的变迁始终伴随着我们成长。在这个过程中，我们逐渐意识到，尽管虚拟世界带给我们无尽的快乐和刺激，但最终，我们还是会回到现实，回到那个最温暖的地方——家庭。我们不必为脱离游戏而感到遗憾，因为生活中的每一阶段都有其独特的意义。而这些变化，正是让我们成为更完整的人的一部分。\n","date":"2024-12-31T07:11:05+08:00","permalink":"https://ttf248.github.io/p/%E4%BB%8E%E6%B8%B8%E6%88%8F%E5%88%B0%E5%AE%B6%E5%BA%AD%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E4%BB%AC%E5%9C%A8%E9%95%BF%E5%A4%A7%E5%90%8E%E6%B8%90%E6%B8%90%E8%84%B1%E7%A6%BB%E4%BA%86%E8%99%9A%E6%8B%9F%E4%B8%96%E7%95%8C/","title":"从游戏到家庭：为什么我们在长大后渐渐脱离了虚拟世界"},{"content":"懂王再次当选美国总统，也将虚拟货币带回大众的视野中。港交所也一直在积极部署相关的业务，这里简单记录一下港交所的虚拟货币发展史。\n翻看相关合约清单的详情资料，发现最初引入的并不是现货而是期货，这也是合理的，因为期货市场的流动性更好，更容易引入机构投资者。而后引入的现货ETF，也是合理的，因为ETF是一种更容易接受的投资工具。\n虚拟货币清单 港交所的行情数据中并没有提供标识，区分合约是否为虚拟货币，但是可以通过合约的名称来判断。官网的交易清单中，倒是提供了对应的子类别virtualasset。\nhttps://www.hkex.com.hk/Market-Data/Securities-Prices/Exchange-Traded-Products?sc_lang=en\u0026amp;asset=virtualasset\n2022年12月16日 香港交易所歡迎亞洲首批加密資產ETF上市 香港交易及結算所有限公司（香港交易所）今天（星期五）歡迎亞洲首批加密資產ETF上市，進一步擴大其產品生態圈，為香港及國際投資者提供更多選擇。\n今天上市的兩隻新ETF — 南方東英比特幣期貨ETF（股份代號：3066）及南方東英以太幣期貨ETF（股份代號：3068）由南方東英資產管理有限公司管理，分別追蹤在芝加哥商品交易所（芝商所）交易的標準化、現金結算的比特幣期貨合約及以太幣期貨合約。\n香港交易所首席營運總監及市場聯席主管姚嘉仁表示：「今天上市的兩隻加密資產ETF，為香港日益豐富多元的交易所買賣產品生態圈錦上添花。這些新産品將首次在亞洲為投資者提供參與數碼資產投資的機會，亦反映了我們對數碼經濟的關注和市場的需求。我們期待在未來幾個月將迎來更多主題式 ETF 和數碼資產新產品。」\nETF是香港交易所旗下市場發展最快的業務之一，產品種類於2022年亦不斷拓展，愈趨多元化，包括於年內推出了首隻元宇宙ETF、首隻碳期貨ETF及首隻區塊鏈ETF，更首次將ETF納入滬深港通。\n此外，香港交易所買賣產品（ETP，包括ETF和槓桿及反向產品）今年首十一個月的平均每日成交金額為118億元，較去年同期的78億元大增50%，反映ETP愈來愈受投資者歡迎。截至2022年11月，於香港交易所上市的ETP共有168隻，市值達3,735億元。\n2024年4月30日 香港交易所歡迎首批虛擬資產現貨ETF上市 香港交易結算所有限公司（香港交易所）今天（星期二）歡迎亞洲首批虛擬資產現貨ETF 上市，增加香港市場的產品種類及為投資者提供更豐富的選擇，鞏固香港作為亞洲領先ETF 市場的地位。\n香港交易所證券產品發展主管羅博仁說：「今天新上市的虛擬資產現貨 ETF 將豐富香港交易所多元及活躍的ETF市場生態圈，為投資者提供新資產類別的投資機會。繼一年前成功推出虛擬資產期貨ETF後，亞洲首批虛擬資產現貨 ETF將進一步提升香港交易所買賣產品的產品種類及流動性。我們期待繼續與市場持份者緊密合作，在我們國際化的市場引入更多新產品。」\n首批虛擬資產期貨ETF在2022年上市後備受投資者青睞，交投暢旺。在香港上市的三隻虛擬資產期貨ETF的日均成交量由2023年的890萬元增加至2024年第一季的5,130萬元，同時亦吸引了 5.29 億元的資金流入。\n交易所買賣產品（包括ETF、槓桿及反向產品）是香港交易所增長最快的市場之一，產品種類在過去一年亦不斷增加。2023年及2024首季新增的16隻ETF產品包括亞太區首隻沙特阿拉伯ETF、香港首批備兌認購期權ETF，目前在香港上市的ETF共有179隻。\n2024年10月28日 香港交易所將推出虛擬資產指數系列 香港交易及結算所有限公司（香港交易所）今日（星期一）宣布，將於2024年11月15日推出香港交易所虛擬資產指數系列（指數系列），為虛擬資產這個快速興起的資產類別提供可靠的基準價格，支持香港發展成為亞洲領先的數字資產中心。\n該指數系列將為比特幣和以太幣在亞洲時區的定價提供透明且可靠的基準，致力於為虛擬資產提供統一參考價格，解決該類資產在全球交易所之間價格差異。\n香港交易所集團行政總裁陳翊庭表示：「我們很高興推出香港交易所虛擬資產指數系列，以滿足區域內對這一快速興起的資產類別的需求。通過提供透明可靠的實時基準，我們希望能夠幫助投資者做出明智的投資決策，從而支持虛擬資產生態圈的健康發展，鞏固香港作為國際金融中心的地位。」\n該指數系列的推出是香港交易所致力探索新興領域的一部分，一方面支持香港金融科技的發展，同時亦為投資者在不斷變化的市場環境中提供重要的基準工具和解決方案。\n指數系列將包括比特幣和以太幣的參考指數以及參考匯率。\n參考指數以比特幣或以太幣的24小時交易量加權的基準現貨價格為基礎，並依據多家主要虛擬資產交易所的匯總市場價格計算，且即時以美元計價。而參考匯率是為金融產品結算而設計，於香港時間每日下午4:00計算。\n該指數系列將會是香港開發的第一個符合歐盟基準法規（BMR）的虛擬資產指數系列，由位於英國注冊的基準管理機構與虛擬資產資料及指數提供商 CCData 共同管理和計算。\n香港特別行政區政府於2022年發布了關於虛擬資產發展的政策聲明，希望在香港培育一個充滿活力的虛擬資產產業和生態圈。香港交易所虛擬資產指數系列的推出將通過提供實時數據和亞洲時區的每日參考價格，幫助公眾增加對虛擬資產投資趨勢的理解。\n有關指數系列的設計和計算方法的更多細節將適時公布。\n参考资料 https://www.hkex.com.hk/news/news-release/2022/221216news?sc_lang=zh-hk https://www.hkex.com.hk/News/News-Release/2024/240430news?sc_lang=zh-HK https://www.hkex.com.hk/News/News-Release/2024/241028news?sc_lang=zh-HK ","date":"2024-12-31T07:00:28+08:00","permalink":"https://ttf248.github.io/p/%E9%A6%99%E6%B8%AF%E4%BA%A4%E6%98%93%E6%89%80%E8%99%9A%E6%8B%9F%E8%B4%A7%E5%B8%81%E5%8F%91%E5%B1%95%E5%8F%B2/","title":"香港交易所，虚拟货币发展史"},{"content":"华泰柏瑞沪深300ETF等公告下调综合费率至同类最低一档。\n11月19日，华泰柏瑞基金公告，为更好地满足广大投资者的投资理财需求，自11月22日起，调低华泰柏瑞沪深300ETF及其联接基金的管理费率、托管费率，并修订相应基金合同中的有关内容。\n调整后，华泰柏瑞沪深300ETF及其联接基金的年管理费率降至0.15%，年托管费率降至0.05%，全部调至指数基金的最低一档费率。\n几乎同时，业内规模前列的华夏沪深300ETF、华夏上证50ETF、南方中证500ETF、嘉实沪深300ETF、易方达创业板ETF等亦公告调低管理费和托管费，费率全部降至0.15%和0.05%。\n与以往多数ETF降费不同的是，这一次降费由市场中具备规模优势品种的主动出击，对行业后续影响会较大。交易所数据显示，截至11月18日，华泰柏瑞沪深300ETF规模超过3700亿元，是当前市场上规模居首的ETF。\n规模最大的一批超级ETF率先降费，显示了其让利给投资者的主动意愿，也让投资者能以更高的性价比投资人气和流动性良好的基金产品。\n业内观点认为，具有规模优势的ETF降费，一方面，有利于发挥公募基金普惠金融的服务功能，更大面积地帮助投资者降低持有成本，提升收益空间和投资获得感；\n另一方面，低费率也有利于进一步提升产品本身的竞争力，在流动性虹吸效应和成本运营优势的加持下，产品有望吸引更多中长期增量资金入市，助建“长钱长投”的良好生态。\n近年来，凭借着交易灵活、透明度高、流动性强、投资门槛低等独特优势，宽基ETF已经成为资金低位入市、“长钱长投”的主要通道。\n本次降费，可能成为某种程度的“加速器”，让A股市场的长钱入场更加通畅。\n后记 笔者定投的天弘基金还没发公告，不过也应该会跟进。如果不更新，就要考虑换基金了。\n原管理费：0.5%，托管费：0.1%。新管理费：0.15%，托管费：0.05%。这个降幅还是很大的。\n","date":"2024-11-21T03:08:48+08:00","permalink":"https://ttf248.github.io/p/%E9%99%8D%E8%B4%B9%E4%BA%86%E9%99%8D%E8%B4%B9%E4%BA%86%E5%9B%BD%E5%86%85%E8%B6%85%E5%A4%A7%E5%9E%8Betf%E6%89%B9%E9%87%8F%E9%99%8D%E8%B4%B9%E4%BA%86/","title":"降费了，降费了，国内超大型ETF批量降费了"},{"content":"大锤正在落下。\n投顾服务搭上短视频的东风后，或正在驶入快车道。\n今年9月下旬，A股行情呈现一片火热后，抖音荐股受到了各方的关注。\n先后有“大蓝”等多位财经主播在抖音走红，间接对资本市场造成了一定的波动。\n但一众迅速走红的财经主播背后力量也不容忽视，那就是第三方投顾服务公司。\n据了解，不少第三方投顾服务公司在短视频运营多个账号，通过投流吸引用户观看投教视频，提升用户购买相应投顾产品的热情。\n更有传言称，某第三方投顾公司仅仅今年10月便斩获10亿元收入，超过今年上半年的收入。\n但“好日子”正在面临更多变数。\n11月以来，多部门先后发文，要求证券服务机构加强自媒体账号的合规管理。\n11月15日晚，同花顺（300033.SZ）公告称子公司由于直播业务涉及暗示推荐个股等行为而被证监局处罚。 这或许都在向市场释放监管从严的信号。 九方智投（9636.HK）等一众第三方投顾服务机构的展业或许也将面临更多压力。\n监管严密盯梢 抖音等短视频平台的兴起，放大了情绪声音，也间接对交易行为造成影响。\n据巨量算数监测，在成交额创新高的9月27日至10月8日，抖音A股关键词搜索指数从423.84万飞升至1277.86万，膨胀了两倍多。\n如此境况下，第三方投顾机构“推波助澜”的行为，正在引起监管部门的关注。\n投顾机构人员在直播中通过各种方式推荐个股，是高频违规行为。\n11月8日，广东证监局对某公司直播中存在“暗示推荐个股”等情形做出了暂停新增客户的监管措施。\n11月14日晚，广东证券期货业协会发文《直播管控不到位，机构被暂停业务》，直指部分具有证券咨询资格的机构在直播展业过程中存在管控不到位等情况，且直播过程中存在推荐个股的行为。\n“杜绝直播荐股行为。直播属于公众媒体传播，直播人员无论是否登记为证券投资顾问，均不得在直播过程中推荐个股。”广东证券期货业协会指出。\n这不是孤例。\n此前的11月7日，上海证监局披露的罚单中，也有一例涉及在社交媒体平台非法荐股。\n经监管调查发现，海顺证券投资咨询有限公司上海分公司投顾人员王永，通过微信视频号公开发布具有误导性的视频内容，这违背了从业规范。\n上海证监局就此对王永采取出具警示函的监督管理措施。\n据信风（ID:TradeWind01）了解，还有部分不具备资格的投顾机构采取挂靠券商的方式在抖音推荐股票，现已被停播。\n“行业有人在抖音直播，实际上是挂靠在券商下面的，这样就有投资顾问资格了，然后线上直播引流，线下卖投顾组合产品。”华南一位投顾从业人士向信风（ID:TradeWind01）表示，“但是后来因为直播中推荐股票，被发现了，所以就被停播了。正规的券商一般就是投教直播会说板块情况，但不会涉及到个股。”\n目前监管正在对社交媒体非法荐股保持高度关注。\n例如深圳证监局通知近期，行业内出现个别机构或个人利用自媒体违规荐股等违规行为，为进一步规范辖区证券投资咨询机构自媒体运营管理，各机构要进一步加强公司自媒体运营管理。\n这或许给一众第三方投顾服务机构的展业带来更多挑战。\n“流量生意”是非 被短视频吸引入市的股民是否赚到钱不得而知，但作为“卖水人”的第三方投顾服务公司在二级市场的身价已经水涨船高。\n作为“在线投教第一股”，九方智投的市值从今年9月初的28.78亿元飙升至11月13日收盘的124.64亿元，49个交易日内涨幅已经高达333.08%。\n半年报显示，今年上半年九方智投在抖音、小红书等社交媒体平台进行品牌曝光，截止今年6月末已经有488个账户和0.46亿关注者。\n例如作为九方智投的首席投资顾问，“洪帮主”在抖音上的粉丝数达226万。\n“我们深耕MCN运营，以用户为中心，协同推动流量、品牌与产品的全面发展。”九方智投指出，“通过深度融合直播、短视频等新媒体工具，借助AI技术，构建起粉丝网路，并积极探索电商模式，有效实现流量的高效转化。”\n九方智投的投顾课程包覆盖了几十元到十余万元的不同价格带。其中最贵的课程包系超级投资家，定价为13.96万元/半年，内含独家观点、投顾私享服务等。\n不过九方智投的投顾产品退款率在10%以上。\n2024年上半年，九方智投旗舰系列、九方智投擒龙系列的退款率分别达到14.7%、18.5%。\n但在监管风暴下，九方智投的展业是否会受到影响，仍待进一步关注。\n近期有媒体报道称近期九方智投等第三方投顾公司旗下的账号受到了影响。\n11月7日，有媒体报道称“洪帮主”被暂停直播。\n不过11月15日下午信风（ID:TradeWind01）搜索该账号发现，在“洪帮主”的直播界面仍然可以预约11月18日的直播。\n同时还有市场消息称，有关部门已经进场九方智投检查。\n但接近九方智投人士告诉信风（ID:TradeWind01），相关检查属于常规检查，已经结束。\n这不是近期被卷入此轮监管风暴传闻的唯一一家公司。\n有消息称，同花顺涉非法荐股被立案，或将暂停展业。 对此，同花顺11月15日回应称“不存在非法荐股情况，不存在被立案调查。” 不过当天晚上，同花顺就宣布子公司浙江同花顺云软件有限公司由于直播业务推广过程中合规管控不到位, 且存在暗示推荐个股等情形而被浙江证监局处以暂停新增客户3个月等处罚。 这背后，或许也意味着监管部门对于抖音直播等社交媒体平台上的荐股内容的关注正在进一步升级。\n事实上，短视频的蛋糕也吸引着不少券商，但受限于合规要求，目前券商对此仍较为谨慎。\n某券商人士告诉信风（ID:TradeWind01），公司在探索短视频运营、引流的方法，还组织人员前往短视频平台公司进行学习，但受限于合规要求，目前仍处于探索阶段。\n事实上，监管的种种合规要求背后，是因为短视频平台的内容具有明显的情绪化色彩，但投资更多需要市场参与者保持理性来对待，二者存在天然的冲突。\n若放纵情绪的力量影响资本市场，容易引发市场的剧烈波动，有悖于资本市场的长期健康发展。\n证券持牌机构究竟应以何种方式拥抱短视频时代的到来，才能避免“踩红线”，对各方显然是一道难解的题。\n","date":"2024-11-21T02:59:18+08:00","permalink":"https://ttf248.github.io/p/%E4%B8%89%E6%96%B9%E6%8A%95%E9%A1%BE%E7%9B%91%E7%AE%A1%E5%8D%87%E6%B8%A9%E6%8A%96%E9%9F%B3%E7%82%92%E8%82%A1%E5%B9%95%E5%90%8E%E8%B5%A2%E5%AE%B6%E8%BF%8E%E6%9D%A5%E6%95%B4%E8%82%83/","title":"三方投顾监管升温，“抖音炒股”幕后赢家迎来整肃？"},{"content":"CentOS Stream是红帽企业Linux发行之前的上游开源开发平台‌。 首次关注到开源操作系统生命周期 redhat and centos life cycle\n到期了，有什么问题呢？除了安全问题，dnf 不能用了，我也是最近安装工具的时候，发现 dnf 失败，检查镜像源，发现是 CentOS 8 Stream 到期了。\nCentOS Stream简介 定位与角色‌ CentOS Stream位于Fedora Linux（上游开发）和RHEL（Red Hat Enterprise Linux，下游开发）之间，充当着桥梁的角色。\n它可以被视为是用来体验最新红帽系Linux特性的一个版本，适合尝鲜使用。‌\n诞生与背景‌ 随着时间的推移，Red Hat公司开始寻求更加有效的方式来发展其企业级Linux平台，于是推出了CentOS Stream。\n‌CentOS 8在2021年年底结束维护后，CentOS Stream作为其继承者继续更新，并成为CentOS项目的未来发展方向。‌\n特点与优势‌ CentOS Stream是一个滚动发布的Linux发行版，提供更快捷的更新。它为社区、合作伙伴和客户的参与提供了更高的透明度和更多机会，使得用户可以更快、更直接地为红帽企业Linux做贡献。‌\nCentOS Stream的内容是Red Hat有意收录于下个稳定版RHEL的软件，因此它能为社群成员提供一个稳定的ABI/API进行开发及测试之用。\n使用场景与目标用户‌ CentOS Stream适合那些希望继续获得最新Linux特性更新的CentOS用户，以及希望参与红帽企业Linux开发的开发人员和合作伙伴。‌\n它也旨在协助社群中的成员、Red Hat伙伴及其他人在一个较稳定及可预测的Linux生态环境下充分利用创新的开源程序。\n到期时间 Release Released Active Support Security Support Latest 9 3 years ago (15 Sep 2021) Ends in 2 years and 6 months (31 May 2027) Ends in 2 years and 6 months (31 May 2027) 9 8 5 years ago (24 Sep 2019) Ended 5 months and 3 weeks ago (31 May 2024) Ended 5 months and 3 weeks ago (31 May 2024) 8 解决方案 懒得折腾升级的问题，选用了ubuntu24.04长期支持版本。\n","date":"2024-11-16T23:24:50+08:00","permalink":"https://ttf248.github.io/p/centos-8-stream-eol/","title":"CentOS 8 Stream EOL"},{"content":"翻看历史提交记录，站点切换过很多次主题，每次切换主题都会有一些自定义的修改，这里记录一下自定义修改主题的思路。笔者的Github也有个仓库，短暂的维护过even主题，后来由于强迫症，非想要升级hugo编译器到最新版本，导致even主题不兼容，所以又切换到了stack主题。\nHugo的模块化 提到模块化，大家可能会想到的是Nginx模块，IDEA插件等等。 通常是我可以通过上传一些模块，来满足我的差异化需求。 之所以大家都喜欢这种模块，主要是因为足够灵活，不用费太大的劲就可以满足自身的需求。 因为很多时候，虽然大体上差不多，但总有一些细节上的差异。 这也正说明软件的复杂度，除了技术上的复杂度，还有业务上的复杂度。 大多数情况下，我们面对的主要是业务复杂度。 这也正是在软件领域，对”隔行如隔山”这句俗语最好的阐述。 如今，不仅互联网行业，金融行业，就算传统的制造业，都已经使用上了信息化系统，来帮助企业的生产和管理。 同样是请假系统，哪怕在同样的行业，不同的公司，都会有所差异。\n而Hugo的模块和大家印象中的模块有点不一样，并不是以功能为单位，来满足差异化需求。 而是以目录结构为主，来识别相同的结构。\n资料链接：07. Hugo架构 — Hugo的模块\n[[imports]] path = \u0026quot;github.com/CaiJimmy/hugo-theme-stack/v3\u0026quot; git submodule 方式依旧能用，本文不建议使用，如果引入主题的发生了更新，维护起来会比较麻烦，要单独的 git 仓库管理主题。\n主题的修改逻辑 有了前面模块化的基础概念理解，再来理解自定义主题，就简单那很多了，hugo现在的主题，也是多个不同的模块组装起来的，我们想要修改其中一个模块，找到对应的模板文件，修改即可。\n摘取自stack官方文档：\nUsing this method, there won\u0026rsquo;t be any file under themes directory. In order to modify the theme, you will have to copy the file you want to modify to the same directory under layouts directory.\nFor example, in order to modify the themes/hugo-theme-stack/layouts/partials/head/custom.html file, you will have to copy it to layouts/partials/head/custom.html and modify it there (copy the code from theme\u0026rsquo;s repository). The same applies to assets and static directories。\n如何找到模板文件 正统思路 翻阅主题的源码文件，理解主题的设计思路，找到对应的模板文件，修改即可。\n粗暴思路 笔者并不是很懂前端代码，所以有时候会采用粗暴的方式，比如直接在浏览器中打开对应的页面，找到想要修改的地方，通过审查元素的方式，定位到css name，主题源码中搜索，找到对应的文件，复制一份到站点目录，修改即可。\n小技巧 官方默认就提供了一个文件，用于自定义样式，我们需要改造的地方地方，可以通过拆分多个文件，custom.scss 文件引入我们其他的文件，这样可以更好的管理样式文件。\n汇总修改内容(6h) 现在已经是AI编码的元年，详细的内容，这里就不详细贴出来了，只是简单的列举一下，本站点的一些修改内容，比如调整复制按钮的样式，重新设置代码的块的样式，ChatGPT都是能轻松搞定的。\n整体：全局文字样式，沿用以前 even 融合 info cn 的显示风格，中文友好 首页：右侧导航增加鼠标交互动画 首页：文章新增摘要预览（耗时颇多，用了取巧的办法实现） 滚动栏：美化了一下滚动栏的样式 代码块：引入了 highlight.js 代码高亮插件，美化代码块样式 文章详情：部分内容属于转载，新增原作者信息展示，原链接展示 归档页面：顶部的分类图片，移除主题自带的颜色蒙版，显示原图 归档页面：新增了按照年份的分类的统计展示面板 归档页面：两栏显示布局 stack 主题的组件复用率很高，也导致首页文章新增摘要预览耗时颇多，改了对应的组件，文章的详情页面也随之发生了变动，导致正文重复展示内容，golang 模板的语法也不是很熟悉，所以花费了不少时间，组件之间的参数传递一直没搞定，最后通过取巧的办法，主页单独引入JavaScript脚本，通过自定义特殊变量，来实现摘要预览。\n有时候代码复用率太高也是个问题，会导致修改一个地方，其他地方也会受到影响，所以在修改主题的时候，一定要注意，不要破坏原有的逻辑。\n评论区 这哥们的修改更加完善：https://blog.reincarnatey.net/2024/0719-better-waline/\n本站点简单的启用了 Waline 评论系统，stack 主题默认支持 Waline，只需要在 config.toml 中配置即可。\n推荐首页邮箱联系、本站点不开放评论区\n","date":"2024-11-15T22:01:17+08:00","permalink":"https://ttf248.github.io/p/hugo-module%E8%87%AA%E5%AE%9A%E4%B9%89%E4%BF%AE%E6%94%B9%E4%B8%BB%E9%A2%98%E6%80%9D%E8%B7%AF%E8%AE%B2%E8%A7%A3/","title":"Hugo Module自定义修改主题：思路讲解"},{"content":"最近抖音上的大冰老师很火，经常能刷到视频的切片账号，都是直播的里面的一些内容。有位连麦的听众问道：“大冰老师，我想把西安的房子卖了，回到老家躺平？”大冰老师回答：“你现在年龄，三十出头，你没法子躺平，你的父母在变老的路上，你的孩子还没成家立业，回到老家你还需要应付小县城里面的婆罗门”。\n先不说观点是非对错，婆罗门这个词是什么意思呢？\n县城婆罗门：小地方的“大人物” 在许多小县城里，大家总会说起一些“县城婆罗门”——这些人的存在，仿佛是地方社会的一种象征。他们往往不是什么真正的宗教人物，也没有拥有“高大上”的头衔，而是一些看似普通但又举足轻重的人物。他们代表的是小地方里的“权力、地位与话语权”，是那个县城里某个阶层的象征。\n什么是“县城婆罗门”？ 首先，我们得弄明白，“婆罗门”原本是印度社会中的最高阶层，代表着智慧、权威和精神上的至高无上。而在中国的县城中，“县城婆罗门”这个词，并没有那么复杂的宗教背景，它更多地是一种社会现象的比喻。\n简单来说，“县城婆罗门”可以理解为县城中的一些“文化权威”，比如那些老师、医生、当地的知名商人、官员等等。虽然他们的职位看似平凡，但在县城这种较为封闭的环境中，他们拥有的是相对较高的社会地位，或者说，他们的意见和行为在当地有着不容忽视的影响力。\n谁是“县城婆罗门”？ 在县城里，几乎每个行业都有这样的“婆罗门”。他们可能是：\n教育工作者：尤其是一些在地方上有着几十年教龄的老师，可能并不是什么名校毕业生，但他们深知如何通过知识建立威信，受到了广泛的尊敬。 地方政府官员：县城的副县长、科级干部等，他们掌控着一定的资源与权力，哪怕他们的职位不高，但因其权力范围局限，也能成为地方的“婆罗门”。 本地的“企业家”：一些县城里的老板，虽然规模并不大，但他们手中握有一定的财富，拥有了地方话语权。他们或许经营着一两家本地知名的小企业，在县城中有着不小的影响力。 这些人，虽然与大城市里的名流或高官相比，地位不算显赫，但在县城这个小社会里，他们的地位几乎等同于“文化长者”或“权力中心”。\n“县城婆罗门”的地位，如何影响社会？ 要理解“县城婆罗门”的真正意义，我们必须从县城的特殊环境来考量。在这个地方，信息流通不如大城市那么快，社会阶层的流动也较为固定。这里的“婆罗门”们，往往是因为长期深耕当地，积累了声望、知识和人脉。他们影响着地方的政治、经济、文化等各个方面。\n文化影响力：在小地方，尤其是教育系统可能没那么发达，普通人也没有太多的选择空间。当地的文化“婆罗门”通过课堂上的知识传递、媒体的讲解、乃至社交场合的言传身教，悄然塑造了地方的文化氛围。\n社会资源的集中：由于县城的人口和资源有限，这些“婆罗门”往往是地方资源的主要掌控者之一。无论是社会福利、政策落实，还是某些项目的审批，都少不了他们的影响。他们的话语权和决定权，使得他们在地方社会中占据了一席之地。\n人际关系的网状结构：在一个相对封闭的小社会里，人际关系往往至关重要。这些“县城婆罗门”通过建立强大的社交网络，控制了信息流通和资源分配，因此能在关键时刻起到决定性的作用。\n“县城婆罗门”背后的隐喻 虽然“县城婆罗门”常常是受到尊敬和崇拜的，但这种“高高在上”的地位也并非没有问题。在现代社会里，我们不难发现，许多县城的“婆罗门”可能并没有真正的能力和创新精神，而是通过世袭关系、资源垄断等方式，保持着自己的位置。随着信息化的发展，这些“婆罗门”的权力逐渐被打破，新的社会流动性开始影响着小县城的面貌。\n总的来说，“县城婆罗门”是一个很有趣的社会现象，体现了地方社会中的权力和文化结构。尽管他们的“权力”可能并不直接威胁到国家的治理，但在地方范围内，他们无疑是举足轻重的人物。在这个信息流通迅速、社会变革加速的时代，县城里的这些“婆罗门”们也许正在面临着前所未有的挑战。\n结语 本来都不会有这篇稿子，就是好奇婆罗门是什么，然后扔给了kimi，结果还挺搞笑的，我能看到网页端已经搜索出来了结果，但是瞬间就变成了相关内容无法展示，然后我就想，这个词是不是有什么特殊的意义，然后我就扔给了ChatGPT,就有了这篇文章。\n","date":"2024-11-13T23:02:25+08:00","permalink":"https://ttf248.github.io/p/%E5%8E%BF%E5%9F%8E%E5%A9%86%E7%BD%97%E9%97%A8%E5%B0%8F%E5%9C%B0%E6%96%B9%E7%9A%84%E5%A4%A7%E4%BA%BA%E7%89%A9/","title":"县城婆罗门：小地方的“大人物”"},{"content":"在C++开发的历史项目中，我们使用自定义协议进行通信，协议采用了二维数组的模式。在处理大量数据时，协议内部需要遍历数组并进行序列化操作以生成日志，由于效率较低，导致了系统在高负载下出现明显的卡顿，业务部门反馈系统卡顿。\n问题定位 在排查问题时，我们首先对系统进行了性能分析，发现系统在处理大量数据时，CPU 占用率明显增加，且系统响应时间变长。通过分析系统的日志，我们发现了大量的序列化操作，这些操作在处理二维数组时效率较低，导致了系统性能下降。\npstack工具截取服务的线程信息，定位到日志线程大部分时间都在处理字符串的拼接。\n这里是今天的重点，不同的累加方式，效率差别巨大。历史代码中使用的是 + 运算符，这种方式会频繁的创建临时对象，效率很低。你知道它效率很差，但你不知道它效率有多差的那种。\ndemo 验证 基于项目代码，我们抽离业务逻辑，编写了一个简单的 demo，用于验证字符串拼接的效率问题。windows 下的 vs2022 编译器，linux 下的 gcc8.5 编译器，Release模式下编译运行，对比效率。\n关键点说明 项目使用的是方法四，在尚未拿到测试数据的时候，读者可以先思考一下，哪种方式效率最高？哪种方式效率最低？看到结果的时候，我还是很惊讶的。\n方法 1 (+= 拼接)：直接通过 += 将每个字段拼接到字符串中。 方法 2 (std::ostringstream 拼接)：使用流（std::ostringstream）来拼接每个字段，这种方法更高效，特别是对于大量数据拼接时。 方法 3（预分配内存的 += 拼接）：通过 reserve 提前为字符串分配足够的内存，减少了内存重新分配的开销，从而提升了性能。 方法 4 (bodys = bodys + body + \u0026quot;\\n\u0026quot;)：每次拼接都创建一个新的临时字符串对象，这会导致性能下降，尤其是在大规模拼接时，因为每次拼接都会涉及一次新的内存分配和复制。 参考结果，我们可以看到，项目刚好选中了效率最差的方式。\n再进一步，我们来分析不同平台编译器的优化效率，微软的 visual studio 一如既往的优秀，针对字符串的优化效率很高，而 gcc 编译器在这方面的优化效率就差了一些。\n代码在不同的机器执行，两份数据没有直接的对比意义，可以分别对比不同拼接方法之间的差值。\nwindows 平台下的 vs2022 编译器 ---------------------------------------- Data Generation Time: 0.054 seconds. ---------------------------------------- ---------------------------------------- Data Merging Performance: ---------------------------------------- + Data merging (+=) took: 0.053 seconds. + ostringstream Data merging took: 0.054 seconds. + Pre-reserved Data merging took: 0.045 seconds. + Data merging (bodys = bodys + body + \u0026quot;\\n\u0026quot;) took: 16.108 seconds. ---------------------------------------- Data Merging Complete. ---------------------------------------- Program finished. linux 平台下的 gcc8.5 编译器 ---------------------------------------- Data Generation Time: 0.108 seconds. ---------------------------------------- ---------------------------------------- Data Merging Performance: ---------------------------------------- + Data merging (+=) took: 0.100 seconds. + ostringstream Data merging took: 0.083 seconds. + Pre-reserved Data merging took: 0.057 seconds. + Data merging (bodys = bodys + body + \u0026quot;\\n\u0026quot;) took: 29.298 seconds. ---------------------------------------- Data Merging Complete. ---------------------------------------- Program finished. 完整代码 #include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;random\u0026gt; #include \u0026lt;chrono\u0026gt; #include \u0026lt;sstream\u0026gt; #include \u0026lt;iomanip\u0026gt; typedef std::vector\u0026lt;std::string\u0026gt; DataRow; typedef std::vector\u0026lt;DataRow\u0026gt; DataGroup; struct ResponsePackage { std::string ErrorInfo; DataRow Head; std::string ClientId; std::string UUID; std::string MsgID; std::string SessionID; std::string ExtraInfo1; std::string ExtraInfo2; DataGroup DataBody; }; // Generate specified length of random string std::string generateRandomString(size_t length) { const char charset[] = \u0026quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\u0026quot;; const size_t max_index = sizeof(charset) - 1; std::string random_string; random_string.reserve(length); std::random_device rd; std::mt19937 generator(rd()); std::uniform_int_distribution\u0026lt;\u0026gt; distribution(0, max_index); for (size_t i = 0; i \u0026lt; length; ++i) { random_string += charset[distribution(generator)]; } return random_string; } void create_large_string() { // Example request package with 50 fields ResponsePackage requestPackage; requestPackage.Head = { \u0026quot;Field1\u0026quot;, \u0026quot;Field2\u0026quot;, \u0026quot;Field3\u0026quot;, \u0026quot;Field4\u0026quot;, \u0026quot;Field5\u0026quot;, \u0026quot;Field6\u0026quot;, \u0026quot;Field7\u0026quot;, \u0026quot;Field8\u0026quot;, \u0026quot;Field9\u0026quot;, \u0026quot;Field10\u0026quot;, \u0026quot;Field11\u0026quot;, \u0026quot;Field12\u0026quot;, \u0026quot;Field13\u0026quot;, \u0026quot;Field14\u0026quot;, \u0026quot;Field15\u0026quot;, \u0026quot;Field16\u0026quot;, \u0026quot;Field17\u0026quot;, \u0026quot;Field18\u0026quot;, \u0026quot;Field19\u0026quot;, \u0026quot;Field20\u0026quot;, \u0026quot;Field21\u0026quot;, \u0026quot;Field22\u0026quot;, \u0026quot;Field23\u0026quot;, \u0026quot;Field24\u0026quot;, \u0026quot;Field25\u0026quot;, \u0026quot;Field26\u0026quot;, \u0026quot;Field27\u0026quot;, \u0026quot;Field28\u0026quot;, \u0026quot;Field29\u0026quot;, \u0026quot;Field30\u0026quot;, \u0026quot;Field31\u0026quot;, \u0026quot;Field32\u0026quot;, \u0026quot;Field33\u0026quot;, \u0026quot;Field34\u0026quot;, \u0026quot;Field35\u0026quot;, \u0026quot;Field36\u0026quot;, \u0026quot;Field37\u0026quot;, \u0026quot;Field38\u0026quot;, \u0026quot;Field39\u0026quot;, \u0026quot;Field40\u0026quot;, \u0026quot;Field41\u0026quot;, \u0026quot;Field42\u0026quot;, \u0026quot;Field43\u0026quot;, \u0026quot;Field44\u0026quot;, \u0026quot;Field45\u0026quot;, \u0026quot;Field46\u0026quot;, \u0026quot;Field47\u0026quot;, \u0026quot;Field48\u0026quot;, \u0026quot;Field49\u0026quot;, \u0026quot;Field50\u0026quot; }; requestPackage.ClientId = \u0026quot;ClientID\u0026quot;; requestPackage.UUID = \u0026quot;UUID\u0026quot;; requestPackage.MsgID = \u0026quot;MsgID\u0026quot;; requestPackage.SessionID = \u0026quot;SessionID\u0026quot;; requestPackage.ExtraInfo1 = \u0026quot;ExtraInfo1\u0026quot;; requestPackage.ExtraInfo2 = \u0026quot;ExtraInfo2\u0026quot;; // Start timing for data generation auto start_gen = std::chrono::high_resolution_clock::now(); // Generate 10,000 rows of data, each with 50 fields for (size_t i = 0; i \u0026lt; 10000; ++i) { DataRow dataRow(50, \u0026quot;This is a test string\u0026quot;); requestPackage.DataBody.push_back(dataRow); } // End timing for data generation auto end_gen = std::chrono::high_resolution_clock::now(); std::chrono::duration\u0026lt;double\u0026gt; duration_gen = end_gen - start_gen; // Display result generation time std::cout \u0026lt;\u0026lt; \u0026quot;\\n----------------------------------------\\n\u0026quot;; std::cout \u0026lt;\u0026lt; \u0026quot;Data Generation Time: \u0026quot; \u0026lt;\u0026lt; std::fixed \u0026lt;\u0026lt; std::setprecision(3) \u0026lt;\u0026lt; duration_gen.count() \u0026lt;\u0026lt; \u0026quot; seconds.\\n\u0026quot;; std::cout \u0026lt;\u0026lt; \u0026quot;----------------------------------------\\n\u0026quot;; // Data merging using different methods std::cout \u0026lt;\u0026lt; \u0026quot;\\n----------------------------------------\\n\u0026quot;; std::cout \u0026lt;\u0026lt; \u0026quot;Data Merging Performance:\\n\u0026quot;; std::cout \u0026lt;\u0026lt; \u0026quot;----------------------------------------\\n\u0026quot;; { // Method 1: Using '+=' string concatenation auto start_merge = std::chrono::high_resolution_clock::now(); std::string bodys(\u0026quot;\u0026quot;); for (auto\u0026amp; vec : requestPackage.DataBody) { std::string body(\u0026quot;This is a test string\u0026quot;); for (auto\u0026amp; item : vec) { body += item + \u0026quot; \u0026quot;; } bodys += body + \u0026quot;\\n\u0026quot;; } auto end_merge = std::chrono::high_resolution_clock::now(); std::chrono::duration\u0026lt;double\u0026gt; duration_merge = end_merge - start_merge; std::cout \u0026lt;\u0026lt; \u0026quot;+ Data merging (+=) took: \u0026quot; \u0026lt;\u0026lt; std::fixed \u0026lt;\u0026lt; std::setprecision(3) \u0026lt;\u0026lt; duration_merge.count() \u0026lt;\u0026lt; \u0026quot; seconds.\\n\u0026quot;; } { // Method 2: Using ostringstream auto start_merge = std::chrono::high_resolution_clock::now(); std::ostringstream bodys; for (auto\u0026amp; vec : requestPackage.DataBody) { std::ostringstream body; body \u0026lt;\u0026lt; \u0026quot;This is a test string\u0026quot;; for (auto\u0026amp; item : vec) { body \u0026lt;\u0026lt; item \u0026lt;\u0026lt; \u0026quot; \u0026quot;; } bodys \u0026lt;\u0026lt; body.str() \u0026lt;\u0026lt; \u0026quot;\\n\u0026quot;; } auto end_merge = std::chrono::high_resolution_clock::now(); std::chrono::duration\u0026lt;double\u0026gt; duration_merge = end_merge - start_merge; std::cout \u0026lt;\u0026lt; \u0026quot;+ ostringstream Data merging took: \u0026quot; \u0026lt;\u0026lt; std::fixed \u0026lt;\u0026lt; std::setprecision(3) \u0026lt;\u0026lt; duration_merge.count() \u0026lt;\u0026lt; \u0026quot; seconds.\\n\u0026quot;; } { // Method 3: Pre-allocated memory auto start_merge = std::chrono::high_resolution_clock::now(); std::string bodys; bodys.reserve(1000 * 50 * 20); // Pre-allocate enough memory for (auto\u0026amp; vec : requestPackage.DataBody) { std::string body(\u0026quot;This is a test string\u0026quot;); body.reserve(50 * 20); // Pre-allocate memory for each row for (auto\u0026amp; item : vec) { body += item + \u0026quot; \u0026quot;; } bodys += body + \u0026quot;\\n\u0026quot;; } auto end_merge = std::chrono::high_resolution_clock::now(); std::chrono::duration\u0026lt;double\u0026gt; duration_merge = end_merge - start_merge; std::cout \u0026lt;\u0026lt; \u0026quot;+ Pre-reserved Data merging took: \u0026quot; \u0026lt;\u0026lt; std::fixed \u0026lt;\u0026lt; std::setprecision(3) \u0026lt;\u0026lt; duration_merge.count() \u0026lt;\u0026lt; \u0026quot; seconds.\\n\u0026quot;; } { // Method 4: Using 'bodys = bodys + body + \u0026quot;\\n\u0026quot;' auto start_merge = std::chrono::high_resolution_clock::now(); std::string bodys(\u0026quot;\u0026quot;); for (auto\u0026amp; vec : requestPackage.DataBody) { std::string body(\u0026quot;This is a test string\u0026quot;); for (auto\u0026amp; item : vec) { body = body + item + \u0026quot; \u0026quot;; // Note the use of 'body = body + item' } bodys = bodys + body + \u0026quot;\\n\u0026quot;; // Again, using 'bodys = bodys + body' } auto end_merge = std::chrono::high_resolution_clock::now(); std::chrono::duration\u0026lt;double\u0026gt; duration_merge = end_merge - start_merge; std::cout \u0026lt;\u0026lt; \u0026quot;+ Data merging (bodys = bodys + body + \\\u0026quot;\\\\n\\\u0026quot;) took: \u0026quot; \u0026lt;\u0026lt; std::fixed \u0026lt;\u0026lt; std::setprecision(3) \u0026lt;\u0026lt; duration_merge.count() \u0026lt;\u0026lt; \u0026quot; seconds.\\n\u0026quot;; } std::cout \u0026lt;\u0026lt; \u0026quot;\\n----------------------------------------\\n\u0026quot;; std::cout \u0026lt;\u0026lt; \u0026quot;Data Merging Complete.\\n\u0026quot;; std::cout \u0026lt;\u0026lt; \u0026quot;----------------------------------------\\n\u0026quot;; } int main() { try { create_large_string(); } catch (const std::exception\u0026amp; e) { std::cerr \u0026lt;\u0026lt; \u0026quot;Caught exception: \u0026quot; \u0026lt;\u0026lt; e.what() \u0026lt;\u0026lt; std::endl; } std::cout \u0026lt;\u0026lt; \u0026quot;\\nProgram finished.\\n\u0026quot;; return 0; } ","date":"2024-11-13T19:42:59+08:00","permalink":"https://ttf248.github.io/p/linux%E5%90%8E%E7%AB%AF%E6%9C%8D%E5%8A%A1%E5%A4%84%E7%90%86%E5%A4%A7%E9%87%8F%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%95%B0%E6%8D%AE-%E6%95%88%E7%8E%87%E5%BE%88%E6%85%A2/","title":"linux后端服务处理大量字符串数据-效率很慢"},{"content":"在C++中，lambda表达式是一种方便的匿名函数，可以捕获外部变量并在其体内使用。这使得lambda成为一种灵活的编程工具。不过，lambda表达式的参数生命周期是一个需要特别关注的方面，尤其是在捕获和传递参数时\n1. Lambda表达式的参数生命周期 Lambda表达式的参数生命周期通常与其他C++函数一样。函数的参数在函数调用时存在，函数调用结束时，参数生命周期结束。然而，由于lambda表达式可能会捕获外部变量，因此参数的生命周期也受到捕获方式的影响。\n2. 捕获与参数生命周期的关系 2.1 捕获外部变量 C++的lambda表达式允许通过两种方式捕获外部变量：\n按值捕获：通过值捕获，外部变量的值被复制到lambda内部，lambda内的副本生命周期由lambda的生命周期控制。 按引用捕获：通过引用捕获，外部变量的引用会保留，lambda内的引用指向原始外部变量，生命周期取决于外部变量。 int x = 10; auto lambda_by_value = [x]() { std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; std::endl; }; // 捕获x的副本 auto lambda_by_reference = [\u0026amp;x]() { std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; std::endl; }; // 捕获x的引用 lambda_by_value(); // 打印10 lambda_by_reference(); // 打印10 对于捕获的变量，生命周期如下：\n按值捕获：捕获时外部变量的值被复制到lambda，lambda生命周期结束时，复制的副本被销毁。 按引用捕获：lambda持有外部变量的引用，外部变量必须在lambda使用之前有效，否则会导致未定义行为。 2.2 Lambda参数 Lambda的参数与常规函数参数类似，它们的生命周期仅限于lambda函数体内。也就是说，lambda参数会在lambda调用时被创建，并且在lambda调用结束后，参数的生命周期也结束。\nauto lambda = [](int a, int b) { std::cout \u0026lt;\u0026lt; a + b \u0026lt;\u0026lt; std::endl; }; lambda(5, 10); // a和b在这里是lambda的参数 在这个例子中，a 和 b 是lambda表达式的参数，它们在lambda调用时创建，并在lambda执行结束后销毁。\n3. 捕获外部变量时的生命周期问题 3.1 捕获的变量是否能在lambda外部有效 按值捕获：即使外部变量在lambda调用后销毁，lambda内部依然持有外部变量的副本。因此，lambda内部的副本可以安全使用，即使外部变量已经不再存在。 int x = 10; auto lambda = [x]() { std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; std::endl; }; x = 20; // x 在lambda调用后修改 lambda(); // 打印10，捕获的是x的副本 按引用捕获：如果捕获的是外部变量的引用，lambda内部对该引用的访问依赖于外部变量的生命周期。如果外部变量在lambda执行之前就销毁了，那么会出现悬空引用的问题，导致未定义行为。 int x = 10; auto lambda = [\u0026amp;x]() { std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; std::endl; }; x = 20; // x 在lambda调用前修改 lambda(); // 打印20，捕获的是x的引用 如果lambda的执行顺序不确定，确保捕获的外部变量在lambda执行时仍然有效非常重要。\n","date":"2024-11-13T19:23:02+08:00","permalink":"https://ttf248.github.io/p/c-%E4%B8%ADlambd%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%8F%82%E6%95%B0%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/","title":"C++中lambd表达式参数生命周期"},{"content":"书接上回，回来发现 Ghub 有更新，有点小开心，客服说的问题驱动无法正常加载的问题能搞定了，结果折腾一圈，重装卸载，还是不能正常使用。\n背景 继续联系客服咨询处理处理方案，结果被告知，能有工程师远程协助，但是工程师的上班时间和我自己的上班时间一模一样，无奈下只能放弃，翻看上次排查问题留下的资料，准备尝试手动安装驱动。\n获取驱动安装包 罗技官方并没有单独提供设备的驱动安装包，我如何才能拿到驱动文件呢？\n配合上次重装系统留下的系统镜像安装包，我们可以在本地虚拟机中重装一次系统，再纯净的系统中，我们单独部署一份Ghub，将耳机设备介入到虚拟机中，找到驱动的路径，拷贝出来即可。\n相关的路径：\nC:\\ProgramData\\LGHUB C:\\Windows\\System32\\DriverStore\\FileRepository\\logi_audio.inf_amd64_010b035044e24be4 设备管理器 重点是第二个路径怎么找到的，我们先简单梳理一波 Win11 系统如何手动管理驱动文件。这块内容，通过控制变量法来识别的，通过不断的插拔设备，在虚拟机里面分析设备管理器中的设备信息，识别到耳机合计有三个驱动需要处理。其中有两个驱动是系统自带的，只有一个是罗技提供的。\n上图中的第二个驱动，是由罗技提供的，我们分析设备现在的驱动程序，再虚拟机里面翻找所有的驱动路径，当然你首先需要找到 logi 开头的文件，然后进行文件的对比，你就能定位到驱动的文件件，拷贝整个文件夹，你就拿到了驱动安装包\n安装驱动 还在在设备管理器的界面，点击：更新驱动，点击：浏览我的电脑查找驱动，进入到如下界面：\n当然你打开的时候，只能看到一个驱动，那就是普通的USB驱动，选择从磁盘安装，路径就是我们前面拷贝出来的文件夹，安装以后，选择的下拉清单中，就能多出来罗技特有的驱动，将设备驱动切换到新安装的驱动即可。\n人体学设备驱动 这块的驱动文件都是系统提供的，你只需要检查设备的驱动前面是否存在感叹号，如果存在感叹号，进入驱动选择界面，随意切换一个其他类型的驱动，然后再改回来即可恢复正常\n完工 耳机麦克风的音量恢复正常，熟悉的耳返功能也回来了。\n","date":"2024-06-05T07:20:17+08:00","permalink":"https://ttf248.github.io/p/win11-logitech-g431-%E8%80%B3%E6%9C%BA%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85/","title":"Win11 Logitech G431 耳机驱动安装"},{"content":"如果完全不懂这些东西，第一时间联系官方的客服也就不会折腾好几个小时。\n正文 最近，我家里用于开发的台式电脑C盘空间不够用了，特意拿出了一块256GB的半退役固态硬盘单独给C盘使用，奈何经常瞎折腾。自从搬到上海后一直忙于各种事务，终于在上周抽空重装了系统。\n重装系统过程很顺利，日常软件的安装和开发环境的部署也都没有出现问题。几天后，我打算放松一下，玩几局游戏，这时才想起鼠标和耳机的驱动还没有安装。这两个设备都是罗技的，所以我下载了GHUB软件，它可以自动识别硬件并安装驱动。\n然而，意外发生了。鼠标的驱动安装顺利，但耳机的驱动一直显示“加载中”。我怀疑可能是最新版的Windows 11系统与罗技的驱动不兼容，导致安装失败。于是，我开始查找资料，尝试手动安装驱动，但问题依旧没有解决。\n简单科普一下，这两个设备的驱动分别起什么作用。\n鼠标的驱动主要用于调节鼠标的移动速度等功能。宏功能我很少用，只需恢复以前记得的参数即可。 耳机的驱动则主要用于耳返功能，这在团队语音时非常有用，可以让我听到自己讲话的声音。虽然系统的麦克风设置里有类似的侦听功能，但效果不如驱动实现得好。 尽管我反复尝试，耳机的驱动始终无法正常加载。今天，我终于想到可以找客服问问情况，看看是否有解决方案。客服告诉我，最近他们的服务器出了问题，导致驱动下载异常。他们正在处理这个问题，让我不要着急，等下次更新后问题就能解决了。\n虽然还没能解决耳机驱动的问题，但至少知道了原因，希望问题能尽快得到解决。\n鼠标驱动设置 ","date":"2024-05-31T21:46:12+08:00","permalink":"https://ttf248.github.io/p/%E7%BD%97%E6%8A%80%E8%80%B3%E6%9C%BA%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85%E5%A4%B1%E8%B4%A5/","title":"罗技耳机驱动安装失败"},{"content":" 取消商品房利率下限 明日起下调公积金利率0.25% 首套首付比例降至15% 3000亿元保障性住房再贷款 取消全国层面首套住房和二套住房商业性个人住房贷款利率政策下限 中国人民银行上海总部，各省、自治区、直辖市及计划单列市分行；各国有商业银行，中国邮政储蓄银行，各股份制商业银行：\n为落实党中央、国务院决策部署，适应我国房地产市场供求关系的新变化、人民群众对优质住房的新期待，促进房地产市场平稳健康发展，现就调整商业性个人住房贷款利率政策有关事项通知如下：\n一、取消全国层面首套住房和二套住房商业性个人住房贷款利率政策下限。\n二、中国人民银行各省级分行按照因城施策原则，指导各省级市场利率定价自律机制，根据辖区内各城市房地产市场形势及当地政府调控要求，自主确定是否设定辖区内各城市商业性个人住房贷款利率下限及下限水平（如有）。\n三、银行业金融机构应根据各省级市场利率定价自律机制确定的利率下限（如有），结合本机构经营状况、客户风险状况等因素，合理确定每笔贷款的具体利率水平。\n下调个人住房公积金贷款利率0.25个百分点 中国人民银行上海总部，各省、自治区、直辖市及计划单列市分行；各政策性银行、国有商业银行，中国邮政储蓄银行，各股份制商业银行：\n中国人民银行决定，自2024年5月18日起，下调个人住房公积金贷款利率0.25个百分点，5年以下（含5年）和5年以上首套个人住房公积金贷款利率分别调整为2.35%和2.85%，5年以下（含5年）和5年以上第二套个人住房公积金贷款利率分别调整为不低于2.775%和3.325%。\n首付款比例调整为不低于15% 中国人民银行上海总部，各省、自治区、直辖市及计划单列市分行；国家金融监督管理总局各监管局；各国有商业银行，中国邮政储蓄银行，各股份制商业银行：\n为落实党中央、国务院决策部署，适应我国房地产市场供求关系的新变化、人民群众对优质住房的新期待，促进房地产市场平稳健康发展，现就个人住房贷款政策有关事项通知如下：\n对于贷款购买商品住房的居民家庭，首套住房商业性个人住房贷款最低首付款比例调整为不低于15%，二套住房商业性个人住房贷款最低首付款比例调整为不低于25%。\n在此基础上，中国人民银行各省级分行、国家金融监督管理总局各派出机构根据城市政府调控要求，按照因城施策原则，自主确定辖区各城市首套和二套住房商业性个人住房贷款最低首付款比例下限。\n央行将设立3000亿保障性住房再贷款 下午4点，住房城乡建设部、自然资源部、中国人民银行、国家金融监督管理总局四部门齐聚国务院政策例行吹风会，介绍切实做好保交房工作配套政策有关情况。\n会上，中国人民银行副行长陶玲宣布，央行将设立3000亿保障性住房再贷款，支持地方国有企业以合理价格收购已建成未出售商品房，用作配售型或配租型保障性住房，预计将带动银行贷款5000亿元。\n据央行介绍，保障性住房再贷款期限一年可展期4次，利率1.75%，面向21家全国性银行，激励银行向城市政府选定的地方国有企业发放贷款，收购已建成未出售商品房用作保障性住房。所收购的商品房严格限定在房地产企业已建成未出售的商品房。\n关于此政策，近期央行将出台《关于设立保障性住房再贷款有关事宜的通知》。\n","date":"2024-05-17T20:42:25+08:00","permalink":"https://ttf248.github.io/p/%E4%BF%83%E8%BF%9B%E6%88%BF%E5%9C%B0%E4%BA%A7%E5%A4%AE%E8%A1%8C%E8%BF%9E%E5%8F%91%E5%9B%9B%E6%8B%9B/","title":"促进房地产、央行连发四招"},{"content":"最近，家中的装修项目让日常开销激增。平常也都在用信用卡，账单周期内还钱，虽然手头上有足够的现金，但更倾向于将这些现金存放在货币基金中，以获得一些额外的利息收入。同时，为了确保财务的稳定性，设置了自动还款功能，以便到期时能够及时偿还信用卡账单。\n银行现状：存款增加，贷款减少 在经济不确定性增加的情况下，人们更倾向于储蓄而不是消费或投资。这导致银行的存款量增加，但同时也意味着银行需要支付更多的利息给存款人。另一方面，由于消费和投资活动的减少，贷款需求降低，银行难以通过发放贷款来获取利息收入。\n为了吸引和留住客户，银行不得不提供更有竞争力的存款利率，这进一步压缩了银行的利差空间。同时，为了刺激经济增长和消费，中央银行可能会采取降低基准利率的政策，这也会影响到银行的贷款利率，进而影响银行的盈利能力。\n银行营销策略：培养用户习惯 最近快到了还款的日子。首先，交通银行联系我，提供了一年期的免费分期服务，不收取任何利息。紧接着，招商银行也提供了分期利息打2.5折的优惠，折算成年化利率仅为1.9%。面对这样的优惠，我选择了接受两家银行的分期服务。\n我意识到银行为了培养用户习惯，真的不惜下血本。按照银行流水的定义，我应该属于银行的优质客户。在当前银行资金放贷难的背景下，通过培养我的分期意识，银行实际上是在为未来我可能出现的资金周转困难做准备，届时他们就能从我这里赚取更多的利息收入。毕竟，众所周知，信用卡账单分析的利息并不低。\n银行通过提供免费分期服务和低利率分期优惠，不仅增加了信用卡的使用频率和额度，还在用户心中树立了积极的形象。这种策略的转变体现了银行对市场变化的快速响应和对客户需求的深入理解。通过这种方式，银行不仅解决了资金放贷难的问题，还为未来的盈利做好铺垫，赚钱不是只看当下，放眼未来才能长长久久。\n个人财务管理的重要性 尽管银行的分期优惠听起来很诱人，但作为用户，用户应当认识到过度依赖信用卡分期可能会带来的风险。我们应该充分考虑自身的还款能力和未来的资金需求，避免因短期的财务便利而陷入长期的债务困境。个人财务管理的关键在于平衡当前的需求与未来的规划。\n","date":"2024-03-31T01:33:48+08:00","permalink":"https://ttf248.github.io/p/%E9%93%B6%E8%A1%8C%E8%90%A5%E9%94%80%E7%AD%96%E7%95%A5%E4%B8%8E%E4%B8%AA%E4%BA%BA%E8%B4%A2%E5%8A%A1%E7%AE%A1%E7%90%86%E7%9A%84%E5%B9%B3%E8%A1%A1%E8%89%BA%E6%9C%AF/","title":"银行营销策略与个人财务管理的平衡艺术"},{"content":"在当今数字时代，游戏已经不仅仅是一种简单的娱乐方式，而是成为了人们日常生活中不可或缺的一部分。从心理学的角度来看，游戏在不同年龄段的人们心理发展中扮演着不同的角色，同时也与社交娱乐紧密相连。\n心理状态 年轻人处于探索自我和建立身份的阶段，游戏为他们提供了一个低成本的尝试和探索环境。通过游戏，他们可以尝试不同的角色和生活，满足好奇心和探索欲。而随着年龄的增长，个人的兴趣和价值观逐渐稳定，游戏可能不再符合他们的生活目标和兴趣点。\n社交属性 同时，游戏也成为了社交活动的一部分，特别是对年轻人而言。他们通过游戏结交朋友和建立社交网络，游戏成为了社交的桥梁。然而，随着年龄的增长，人们的社交圈逐渐稳定，社交需求可能通过其他更成熟的方式得到满足，游戏在社交中的作用相对减弱。\n社交属性：带妹 在国内，由于恋爱教育的不足，小时候父母只会让你好好学习，毕业了立马就让你恋爱，这个现象很常见。\n因为学业、工作繁忙或缺乏交往技巧，在现实生活中未能建立起稳定的情感关系，从而感到孤独和渴望被关注。游戏中的“带妹”行为为他们提供了一个释放这种渴望的出口，通过帮助和保护女性玩家，他们能体验到被需要和被重视的感觉，获得情感上的满足。\n同时，游戏中的互动规则明确、环境可控，相比现实生活的复杂性和不确定性，游戏提供了一种确定性和安全感，减少了对现实交往中不确定性的恐惧。然而，长期依赖游戏中的虚拟满足感可能会影响他们在现实生活中建立和维护健康情感关系的能力\n现实压力 游戏提供了一个虚拟的世界，让玩家可以暂时逃避现实中的压力、挑战或不愉快的情绪。特别是对于那些面临学业压力、家庭问题或人际关系挑战的年轻人来说，游戏可能成为他们寻求安慰和放松的一种途径。\n游戏通常设计得让玩家在完成任务、提升等级或击败对手时获得成就感和认可。年轻人可能会沉迷于游戏中，因为他们在游戏中能够获得一种被赞赏和认可的感觉，这种感觉在他们现实生活中可能较为缺乏\n年龄增加以后不喜欢玩了 年轻时，个人面临的社会责任和压力相对较小，有更多时间和精力投入到游戏中。随着步入职场、成立家庭等社会责任的增加，时间和精力变得更加宝贵，游戏可能被视为一种时间消耗，而不是优先选择的休闲方式。\n随着年龄的增长，人们的认知能力和兴趣点也会发生变化。年轻时可能对动作快速、画面华丽的游戏感兴趣，而随着阅历的增加，可能更偏好策略性、故事性强或者有深度的游戏。如果市场上的游戏不能满足这些变化的需求，兴趣自然会减少。\n","date":"2024-03-30T15:07:45+08:00","permalink":"https://ttf248.github.io/p/%E6%B8%B8%E6%88%8F%E7%9A%84%E5%A4%9A%E7%BB%B4%E5%BF%83%E7%90%86%E5%8F%91%E5%B1%95%E4%B8%8E%E7%A4%BE%E4%BA%A4%E5%A8%B1%E4%B9%90%E7%9A%84%E4%BA%A4%E6%B1%87%E7%82%B9/","title":"游戏的多维：心理发展与社交娱乐的交汇点"},{"content":"人民币汇率的异动和大盘下跌可能与全球央行的动态、瑞士央行的意外降息、美国经济数据的表现以及市场对通胀和降息预期的调整有关。这些因素共同作用于外汇市场和股市，导致了人民币汇率的波动和A股市场的下跌。\n根据您提供的链接内容，2024年3月22日，人民币汇率出现了显著的波动。以下是详细情况：\n美元兑离岸人民币汇率突破：当日开盘时，人民币走弱，美元兑离岸人民币盘中升破7.24至7.24926，美元兑在岸人民币盘中升破7.22至7.22360，双双突破2023年11月17日以来的新高。截至财联社记者发稿时，美元兑离岸人民币突破了7.26关口，最低报7.2639，且趋势未止。\n央行中间价调整：3月22日，央行公布人民币对美元中间价报7.1004，调贬62个基点，调整幅度有所扩大。\nA股市场反应：受多种因素影响，当日A股三大指数低开低走，跌幅均超过1%。\n外汇市场波动原因：香港一投资机构资深外汇交易员表示，外汇市场波动主要是因为瑞士央行意外降息提振了美元，加上美国经济强劲、通胀粘性可能推迟降息，导致美元指数上涨。\n全球央行动态：本周是全球市场的“超级央行周”，美国、日本、英国、澳大利亚等多国央行都将在本周公布利率决议。瑞士央行意外宣布降息，成为G10货币央行自疫情爆发以来的首个降息行动，这打破了市场平衡。\n人民币走势预测：光大银行金融市场部研究员周茂华表示，尽管近期人民币有所波动，但整体幅度明显小于美元等主要货币，短期波动不会改变年内人民币稳中趋升的走势。\n","date":"2024-03-23T00:31:13+08:00","permalink":"https://ttf248.github.io/p/%E4%BA%BA%E6%B0%91%E5%B8%81%E6%B1%87%E7%8E%87%E5%87%BA%E7%8E%B0%E4%BA%86%E6%98%BE%E8%91%97%E7%9A%84%E6%B3%A2%E5%8A%A8%E7%AA%81%E7%A0%B47.26/","title":"人民币汇率出现了显著的波动，突破7.26"},{"content":"在 Python 编程中，字典是一种非常强大的数据结构，它允许我们将键值对关联起来，并以高效的方式查找和操作这些数据。当我们尝试在字典中存储自定义对象时，通常会遇到一个关键概念：Python 中的对象赋值实际上是引用赋值，而非对象本身的深拷贝。这意味着将自定义对象放入字典时，字典中存储的是对该对象的引用，而非对象的一个全新副本。\n存储自定义对象的基本示例 假设我们有一个简单的 Person 类：\nclass Person: def __init__(self, name, age): self.name = name self.age = age # 创建一个 Person 对象 p1 = Person(\u0026quot;Alice\u0026quot;, 30) # 将对象存储到字典中 people_dict = {} people_dict[\u0026quot;alice\u0026quot;] = p1 在这个例子中，people_dict 字典现在包含一个键为 \u0026quot;alice\u0026quot; 的项，其值是对 Person 类型的 p1 对象的引用。如果我们修改 p1 的属性：\np1.age = 31 那么通过字典访问这个对象时，我们会发现其年龄也被更新了：\nprint(people_dict[\u0026quot;alice\u0026quot;].age) # 输出：31 这是因为字典中存储的并不是 Person 对象的独立副本，而是指向同一内存地址的引用。\n深拷贝与浅拷贝的区别 在涉及嵌套数据结构或自定义对象时，这种引用行为可能会导致意外的结果。例如，如果自定义对象中包含可变类型的属性（如列表或另一个自定义对象），直接将这样的对象存入字典并对其进行修改，会影响到通过字典获取的对象。\nclass Address: def __init__(self, street, city): self.street = street self.city = city class Person: def __init__(self, name, age, address): self.name = name self.age = age self.address = address address = Address(\u0026quot;Main St.\u0026quot;, \u0026quot;Springfield\u0026quot;) p1 = Person(\u0026quot;Bob\u0026quot;, 40, address) people_dict[\u0026quot;bob\u0026quot;] = p1 # 修改原始地址对象 address.city = \u0026quot;Shelbyville\u0026quot; # 字典中的人的地址也变了 print(people_dict[\u0026quot;bob\u0026quot;].address.city) # 输出：Shelbyville 解决办法：深拷贝\n为了避免这种共享状态带来的问题，有时我们需要确保字典存储的是对象的一个完整副本，而不是引用。Python 提供了 copy 模块中的 deepcopy 函数来实现这一目标：\nimport copy # 使用深拷贝存储对象 people_dict[\u0026quot;bob_deepcopy\u0026quot;] = copy.deepcopy(p1) # 此时即使修改原始地址对象，深拷贝的对象不会受影响 address.city = \u0026quot;Capital City\u0026quot; print(people_dict[\u0026quot;bob\u0026quot;].address.city) # 输出：Capital City print(people_dict[\u0026quot;bob_deepcopy\u0026quot;].address.city) # 输出：Shelbyville 总之，在 Python 中利用字典存储自定义对象时，务必注意默认情况下存储的是对象引用。对于那些需要保持独立状态的情况，请使用 deepcopy 进行深拷贝，以避免因共享引用而导致的意料之外的数据变化。\n","date":"2024-03-22T01:08:05+08:00","permalink":"https://ttf248.github.io/p/python-%E5%AD%97%E5%85%B8%E5%AD%98%E5%82%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E4%B8%8E%E6%B7%B1%E6%8B%B7%E8%B4%9D%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7/","title":"Python 字典存储自定义对象：引用与深拷贝的重要性"},{"content":"315 实际上没有报道鸡骨泥，这个问题本身在混淆央视 3·15 晚会的官方曝光和同期发生的其他食品安全热点事件。\n知乎回答：新闻学 315晚会一共提了九个厂家，里面并没有淀粉肠，而现在搞得那些被提名的大品牌完全没热度，倒是把淀粉肠这种国民级（全国各地小吃街基本都会有并且摊位量应该也是第一）的小吃拉出来说事感觉淀粉肠完全就是被拉出来背锅的，我找了网上的新闻来源就是一个央广网在3.15那天发了个调查火腿肠的新闻，但也只是列出了几家厂家的成分，并且几个厂家也并不是主要生产淀粉肠的厂家，成分上并看不出什么毛病，然后这个b记者通过一个工厂员工说有时候用的是鸡骨泥替代鸡肉也就是听说，然后她就去淘宝问宠物食品店卖鸡骨泥的商家，人能不能吃？，这不是sb问题吗？人家一个宠物食品敢说让你人吃？然后后面就传谣传成淀粉肠里含的都有鸡骨泥，鸡骨泥人不能吃。\n现在搞得估计很多工厂都要关门，全国几十万的小摊贩都面临货砸手里没生意干的地步。\n人间真实 据潇湘晨报17日报道，3月16日，河南三门峡，“淀粉肠塌房”的第二天，有大娘出摊卖淀粉肠，但2小时过去后仍无人问津，最后自己默默把淀粉肠吃了。拍摄者称，他自己平时吃淀粉肠一次能吃四五根，但是得知淀粉肠里面有鸡骨泥后坚决不吃了。当天他好奇被曝光后还会不会有人买淀粉肠，结果看到摊贩2小时没卖出一根。\n阿姨哪里知道什么淀粉肠事件，她只知道今天突然没人买她的烤肠了。 大娘没错，她只是为了养家糊口，大娘甚至都不知道产品有没有问题、是不是合格，也不知道什么是骨泥，她们不知道网络，只是作为底层的人想办法活着。 淀粉肠是塌方了，但是为此买单的是一个个底层营业者。这是一个痛苦的过程。 知乎回答：监管不利 几年前的一个下午，我和一位北漂同事去吃午饭，路过一个卖烤肠、铁板里脊的小摊。\n我随口说了句：“现在这样的黑科技淀粉肠、里脊肉还有会吃吗？”因为在我的观念里，上一次吃淀粉火腿肠已经是大概十几年前了。\n同事犹豫了下，然后委婉的说：“可能因为你生活在大城市吧。其实在我们家乡那种小地方，榨菜、方便面、火腿肠，就是每天的日常生活。\n“我上学时候，只有考了满分，我爸才会路上让我吃一次烤肠。不是因为不卫生，而是的烤肠毕竟要1.5元，能买2斤青菜了。\n“像是称呼方便面、碳酸饮料、辣条为“垃圾食品”的说法，我是到了北京上学后才听说的。”\n我意识到了自己刚才无心话语中的傲慢，默默不再说话。但这件事给我印象很深。\n实际上，这才是中国大部分百姓的日常。\n他们的生活里，没有高大上的“地中海饮食”、“绿色有机蔬菜”、“非转基因大豆”。他们只关心能否买到一些便宜又好吃的蔬菜、肉类、零食，全家人享受下不多的幸福时刻。\n至于货架上的东西，是什么成分构成的、是不是会毒害他们的健康、有没有什么奇特的化学成分。\n本来就不是他们应该关心和懂的。\n他们就是朴素的相信，如果有问题的东西，应该有人管不会出现在货架上的。\n但看了一场315，大家才发现并不是。\n市场里的电子秤、加油站的汽油泵，会藏着高科技改装主板，需要UP主冒着挨打的风险拍下视频，监管人员才能“恍然大悟”的去查处；\n直播间的梅菜肉、小摊上的淀粉肠，原来用的是烂肉、骨粉，需要央视的记者卧底调查拍下录像，才会有人去核实，调查货源去向；\n电视频道、机场广告里面大肆宣传的“保健酒”，需要有人拍摄了视频揭了所有老底，才会一夜间紧急撤下，消失在市民面前。\n一年一次的315，每次抽奖一样的弄掉五六个卖了许久的产品，足够么？\n那些已经吃过、买过的消费者，又去找谁呢。\n","date":"2024-03-18T00:31:58+08:00","permalink":"https://ttf248.github.io/p/%E6%B7%80%E7%B2%89%E8%82%A0%E5%92%8C%E8%B7%AF%E8%BE%B9%E5%B0%8F%E6%91%8A-%E8%B5%84%E6%9C%AC%E7%9A%84%E6%96%B0%E9%97%BB%E5%BD%B1%E5%93%8D%E5%8A%9B/","title":"淀粉肠和路边小摊: 资本的新闻影响力"},{"content":"想要家里的网络快如闪电？关键在于了解网线的选择、光猫和路由器的配置，还有那些不起眼的小细节。这篇博客将带你轻松了解如何用六类网线打造千兆网络，以及如何通过简单的设备检查和配置，确保你的网络速度不受束缚。让我们一起探索，让家里的网速飞起来！\n第一章：深入剖析网络传输介质 当我们谈论实现千兆网络接入时，承载信息高速传输的载体——网线起着至关重要的作用。下面将对五类、六类和七类网线进行详细的解读：\n1. 五类网线（CAT5） 五类网线，也称为CAT5，是较早普及的一种双绞线类型，每对线芯通过精密的螺旋结构设计来减少串扰。它主要适用于10/100Mbps的快速以太网，最大传输频率约100MHz，虽然在过去曾广泛应用，但对于当前追求千兆乃至更高速度的需求而言，五类网线由于物理限制无法满足要求。\n2. 六类网线（CAT6） 随着技术发展，六类网线应运而生。相比五类网线，六类线材采用了更严格的制造标准和更先进的结构设计，显著提高了抗干扰能力和传输效率，可支持高达1Gbps的传输速率，并且在理想条件下，传输距离可以达到100米，这恰好符合千兆网络的接入需求。\n3. 七类网线（CAT7） 七类网线则代表着当前双绞线技术的尖端水准。它不仅在传输速率上有飞跃式提升，理论上可支持最高10Gbps的超高速率，而且在设计上加入了完整的屏蔽系统，包括每个线对之间的屏蔽以及整体外层的屏蔽，从而极大地降低了外部电磁干扰和近端串扰，保障了数据传输的稳定性与准确性。不过，七类网线主要用于未来的万兆以太网或者特定的高要求场景。\n在搭建千兆家庭网络环境中，为了充分释放千兆光纤的潜力，选用六类网线是最为经济且高效的选择。同时，确保所有连接线材的质量合格，并严格按照标准接线方式操作，也是确保网络性能的重要环节。\n第二章：深挖网络中枢设备——光猫、路由器LAN口带宽的影响 光猫及其LAN口带宽的重要性 光猫，全称光纤调制解调器，是家庭宽带接入的核心设备，它的功能在于将光纤中的光信号转化为数字信号，供家庭网络设备使用。对于千兆光纤用户来说，光猫是否支持千兆传输显得尤为重要。如果光猫的WAN口只支持百兆，那么即使入户光纤速率再高，也会因为这个瓶颈而被限制在百兆以内。同样地，光猫的LAN口也需要具备千兆输出能力，否则连接在其上的路由器或其他设备，无法获取到真正的千兆速率。\n路由器LAN口带宽的作用 路由器的LAN口负责将接收到的数据分发到各个终端设备。当路由器的LAN口仅为百兆时，即便其他设备配置再好，也只能实现百兆速率的局域网通信。因此，在构建千兆家庭网络时，确保路由器的WAN口能够接收千兆数据，并且LAN口也能提供千兆级别的数据输出能力，这样才能使家中所有的智能设备享受到高速网络带来的流畅体验。\n此外，需要注意的是，部分老旧或低端路由器可能存在LAN口速率自动协商机制，这意味着即使路由器本身支持千兆，也可能因线路、设备兼容性等原因降级为百兆模式。因此，正确配置路由器参数，启用强制千兆模式，并配合千兆交换机或直连设备，是实现全千兆网络的关键步骤之一。\n在升级为千兆光纤后，务必检查并更换为千兆光猫和千兆路由器，确保所有设备接口均达到千兆级别。\n第三章：潜藏之谜——一根断裂的子线如何影响千兆网络速度 子线故障与网络性能下降 在测速期间网络始终保持连接，没有出现明显的断网状况。由于是新入户部署的宽带，弱电箱里面很杂乱，时不时还在调整光猫的走线，电源接口插排的位置，偶发性出现过测速达到千兆。\n依据前面的资料，我们已经分析排查了网线型号、光猫 lan 口速度，最终发现罪魁祸首竟是网线内部的一根棕色子线断裂。\n断裂的原因：师傅来安装水晶头的时候，这根网线用力稍微猛了一点，导致一根子线断了一半，没有彻底断开，后续重新调整光猫位置的时候，不断的移动位置，导致彻底断裂。\n六类网线八根线的功能解析 六类网线遵循TIA/EIA-568-B标准，包含八根双绞线，颜色编码如下：\n白橙 / 橙 白绿 / 绿 白蓝 / 蓝 白棕 / 棕 在千兆以太网（1000BASE-T）的标准下，这八根线中有四对线同时工作，具体分工如下：\n白橙与橙这对线（1\u0026amp;2），用于发送数据（Tx+/-）； 白绿与绿这对线（3\u0026amp;6），用于接收数据（Rx+/-）； 白蓝与蓝这对线（4\u0026amp;5）以及白棕与棕这对线（7\u0026amp;8），在千兆以太网中原本并非主用，但在某些高级应用（例如，部分PoE供电或未来的技术扩展）中可能会启用。而在传统的百兆网络中，确实只需要使用1、2、3、6这四根线即可。 断裂子线对网络速度的影响 在上述情况下，倘若一根褐色的子线（即棕线或棕白线）断裂，理论上在千兆网络环境下确实会造成速度下降，因为千兆网络需要所有四对线同时进行双向传输以实现满速。但是，由于家庭网络设备往往存在自动协商功能，当检测到线缆出现问题时，会退回到能够正常工作的较低速率模式，也就是百兆模式，这就解释了为何即使有一根子线断裂，网络还能保持连接并工作在百兆速度上。\n简言之，尽管一根棕色子线断裂不影响百兆网络的基本运行，但在千兆网络环境下，它却足以成为限制网络速度的关键因素。直至进行深入诊断和修复，才能真正发挥千兆光纤的全部潜能。这也提醒我们在遇到类似情况时，不应忽视任何潜在的网络基础设施问题，即使是看似不影响基本连接的小故障，也可能成为高速网络体验的隐形障碍。\n","date":"2024-03-18T00:29:02+08:00","permalink":"https://ttf248.github.io/p/%E6%96%B0%E5%AE%89%E8%A3%85%E7%9A%84%E5%8D%83%E5%85%86%E5%85%A5%E6%88%B7%E5%85%89%E7%BA%A4%E4%B8%BA%E4%BD%95%E6%B5%8B%E9%80%9F%E4%BB%85%E8%BE%BE%E7%99%BE%E5%85%86/","title":"新安装的千兆入户光纤，为何测速仅达百兆？"},{"content":"在开发桌面应用程序时，特别是在使用Windows Presentation Foundation (WPF)框架构建富客户端应用时，正确处理用户界面（UI）线程对于保证应用的流畅性和响应性至关重要。UI线程，又称为主线程，是负责处理窗口和控件事件、布局计算以及绘制界面的核心线程。任何与UI元素交互的操作都应当在UI线程上执行，这是WPF以及其他大多数GUI框架遵循的基本原则。\n什么是UI线程？ UI线程在WPF应用启动时由操作系统创建，并初始化应用程序主窗口。它是应用程序中唯一能够直接访问和修改UI组件的状态的线程。这意味着诸如按钮点击、文本框输入、窗口尺寸变化等所有用户交互产生的事件都在这个线程上下文中处理。同时，WPF的依赖属性系统、数据绑定机制以及布局逻辑也都在UI线程上同步执行。\n卡顿现象及其原因 当UI线程被长时间占用或阻塞时，例如执行耗时的计算、大量数据加载、数据库查询或其他I/O密集型任务时，会导致UI线程无法及时响应用户的交互请求，进而表现为界面无响应（Freeze），也就是我们常说的“卡顿”。这种情况下，用户会明显感觉到应用的延迟和不流畅，严重时甚至会出现“Application Not Responding”（ANR）警告。\nUI线程的两条基本规则 为了避免上述情况的发生，WPF开发者应遵循以下两条关键规则：\n不要在UI线程上执行耗时操作：任何可能导致UI线程挂起的操作都应尽可能地移至后台线程执行，以确保UI线程能及时响应用户的输入和渲染屏幕的变化。 不要在非UI线程直接更新UI元素：由于WPF的安全机制设计，只有UI线程有权对UI元素进行修改。试图从其他线程直接更改UI状态将会抛出异常。因此，即使在后台线程完成了计算或数据准备，也需要通过适当的跨线程通信机制将结果显示到UI上。 解决方案：异步编程与线程安全更新 为了在保持UI流畅的同时又能执行耗时任务，WPF提供了多种异步编程模型和工具来协助开发者实现这一目标：\nDispatcher对象：WPF的Dispatcher类允许你将工作项安排到UI线程的任务队列中执行。你可以使用Dispatcher.Invoke或Dispatcher.BeginInvoke方法从后台线程安全地更新UI。 async/await关键字：利用C#语言的异步特性，可以编写异步方法并在其中使用await关键字等待后台任务完成，完成后自动回到UI线程执行后续的UI更新代码。 案例 使用Dispatcher.Invoke方法更新UI private void Button_Click(object sender, RoutedEventArgs e) { // 假设这是一个耗时操作 Task.Run(() =\u0026gt; { var result = LongRunningOperation(); // 这里是模拟一个耗时计算的方法 // 当耗时操作完成后，在UI线程上更新UI Application.Current.Dispatcher.Invoke(() =\u0026gt; { LabelStatus.Text = $\u0026quot;计算结果: {result}\u0026quot;; }); }); } private string LongRunningOperation() { // 模拟耗时操作 Thread.Sleep(5000); return \u0026quot;已完成\u0026quot;; } 使用async/await关键字配合Task.Run private async void Button_ClickAsync(object sender, RoutedEventArgs e) { Button button = sender as Button; button.IsEnabled = false; // 防止用户重复点击 try { // 开启后台任务 var result = await Task.Run(() =\u0026gt; LongRunningOperation()); // 在后台任务完成后，自动切换回UI线程更新UI LabelStatus.Text = $\u0026quot;计算结果: {result}\u0026quot;; } catch (Exception ex) { MessageBox.Show($\u0026quot;发生错误: {ex.Message}\u0026quot;); } finally { button.IsEnabled = true; // 重新启用按钮 } } ","date":"2024-03-12T07:12:21+08:00","permalink":"https://ttf248.github.io/p/wpf%E4%B8%AD%E7%9A%84ui%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%8D%A1%E9%A1%BF%E9%97%AE%E9%A2%98%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","title":"WPF中的UI线程与卡顿问题及其解决方案"},{"content":"在同一段业务代码的情况下，程序在 CentOS 7 环境下编译并运行正常，但当切换到 CentOS 8 并使用更新版的 GCC 进行编译时，程序却发生了崩溃。值得注意的是，问题只在 Release 模式下出现，Debug 模式则完全没有问题。这是我们第一次遇到类似的情况，经过三天的排查，最终找到了问题的根源。\n问题定位 通过一番排查，问题的症结在于 函数缺少返回值。在 Release 模式下，GCC 新版本会进行更多的优化，这导致了原本没有显式返回值的函数在执行过程中出现了未知的逻辑，从而引发了崩溃。我们的结论是，编译器的警告不容忽视，尤其是在老项目中，部分警告可能被无视，但也应当避免屏蔽所有警告。\n环境说明 CentOS 7 GCC版本：\ngcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39) Copyright © 2015 Free Software Foundation, Inc. CentOS 8 GCC版本：\ngcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-21) Copyright (C) 2018 Free Software Foundation, Inc. 崩溃现象 我们在分析程序崩溃的堆栈时，看到的堆栈信息如下：\n[New LWP 1385902] [Thread debugging using libthread_db enabled] Using host libthread_db library \u0026quot;/lib64/libthread_db.so.1\u0026quot;. Core was generated by `./pstack_main`. Program terminated with signal SIGSEGV, Segmentation fault. #0 0x00007ffe894b4420 in ?? () (gdb) bt #0 0x00007ffe894b4420 in ?? () #1 0x00000000004008e9 in main () 这个堆栈看上去并不直观，崩溃函数的栈信息居然显示为一个 ??，这让问题的排查变得更加复杂。\n代码示例 为了更好地理解问题，下面是重现崩溃的最小代码示例：\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;map\u0026gt; int test() { std::cout \u0026lt;\u0026lt; \u0026quot;1\u0026quot; \u0026lt;\u0026lt; std::endl; } int main() { test(); return 0; } 该代码中的 test() 函数显然没有显式返回一个值，而它的返回类型是 int。根据 C++ 规范，当一个函数声明为 int 类型时，必须有一个返回值，否则就可能导致未定义行为。\n编译警告 在我们的项目中，CMake 脚本屏蔽了许多编译时警告，其中就包括了以下警告信息：\n/root/pstack/main.cpp: In function ‘int test()’: /root/pstack/main.cpp:7:1: warning: no return statement in function returning non-void [-Wreturn-type] 这一警告表明 test() 函数没有返回值，而这正是问题的根源。高版本的 GCC（如 8.5.0）在优化代码时可能会对这种未定义的行为做出不稳定的优化，从而导致程序崩溃。\n汇编代码差异 为了解释 GCC 编译器优化行为的差异，我们对比了不同版本 GCC 生成的汇编代码：\nGCC 4.8.5 生成的汇编代码：\n汇编代码较为冗长，且包含了对标准输出流（如 std::cout）的处理逻辑。这表明编译器进行了更保守的优化，未对 test() 函数中缺失返回值的问题做过多优化，可能因此避免了崩溃。\nGCC 8.5.0 生成的汇编代码：\n新版本的 GCC 进行了更多的优化，减少了代码量。然而，这种优化可能使得缺少返回值的函数执行时行为不确定，从而导致程序崩溃。\n结论 通过这次问题排查，我们深刻认识到，在 C++ 中，函数返回值必须明确，特别是在函数声明为 int 时，必须提供一个返回值。对于使用较旧版本编译器的项目，升级到新版本的 GCC 时，可能会遇到更多的优化和更严格的警告机制。因此，我们建议在编译时 不要屏蔽所有警告，而是应该有选择性地处理它们，尤其是函数返回值、类型匹配等常见问题。\n最终，通过为 test() 函数添加一个返回值，问题得以解决，程序恢复了正常的运行。\n","date":"2024-03-10T23:19:06+08:00","permalink":"https://ttf248.github.io/p/%E5%8D%87%E7%BA%A7gcc%E7%89%88%E6%9C%AC%E5%AF%BC%E8%87%B4%E7%A8%8B%E5%BA%8F%E5%B4%A9%E6%BA%83%E4%BB%A3%E7%A0%81%E4%B8%8D%E8%A7%84%E8%8C%83%E7%9A%84%E9%9A%90%E6%82%A3/","title":"升级GCC版本导致程序崩溃：代码不规范的隐患"},{"content":"背景：本地机器部署 windows 版本的业务系统，cpu 资源占用 5% 左右。vmware安装的 centos8 中部署 linux 版本业务系统，资源占用异常。\n问题描述 宿主机：win10 企业版 vmware：17.5 虚拟机：centos8 虚拟机资源分配为4C8GB，启动业务系统。业务系统部署在虚拟机Linux系统中，虚拟机内部 top 命令观察系统资源占用，cpu 占用并不高，外层 windows 系统，任务管理器观察到的CPU资源占用很高，查看进程发现，vmware 进程占用CPU资源很高。\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;+ | Windows | | | | +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+ | | | VMware | | | | Program | | | +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+ | | | +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;+\n知识点 此问题的排查，并不顺利，由于导火索并不是业务系统本身，而是虚拟机本身的问题。如何将思路从常规的业务代码转移到系统负载，再从负载数据的异常，定位到软中断，最后来到关键点，什么东西会影响 Vmware 软中断的工作效率？本文将先科普各个知识点，最后给出解决方案。\nhyper-v Windows操作系统的虚拟化技术经历了一次重大变革。在微软首次发布WSL时，启用Hyper-V服务会导致无法同时使用VMware虚拟机。直到后续版本，VMware才能与Hyper-V服务兼容。\n系统负载 在Linux系统中，\u0026ldquo;负载\u0026rdquo;（load）是指系统中正在运行或等待执行的进程的数量。负载通常由三个数字表示，分别是1分钟、5分钟和15分钟内运行队列中的平均进程数量。这些数字可以通过运行\u0026quot;uptime\u0026quot;命令或\u0026quot;top\u0026quot;命令来查看。\n具体来说，这三个数字分别代表：\n1分钟负载：系统在过去1分钟内运行队列中的平均进程数量。 5分钟负载：系统在过去5分钟内运行队列中的平均进程数量。 15分钟负载：系统在过去15分钟内运行队列中的平均进程数量。 负载的含义是在系统中等待运行的进程数。如果这个数字高于系统的逻辑CPU数量，表明系统负载很高，意味着有许多进程正在等待处理器资源。这可能会导致系统变得缓慢或不响应，具体取决于负载的高低程度以及系统的配置和性能。\n在理想情况下，负载应该保持在系统的逻辑CPU数量范围内，这样系统的性能就能够得到最优化。如果负载持续高于CPU数量，可能需要进一步分析系统中的进程，找出导致负载高的原因，并采取相应的措施来调整系统资源分配或优化进程的运行方式。\n分析负载 mpstat mpstat 命令用于报告单个或多个处理器的多个信息，包括平均负载、CPU利用率、中断和上下文切换等。在 sysstat 包中，mpstat 是非常有用的工具，可以用来分析系统的负载情况。下面是使用 mpstat 进行负载分析的步骤：\n安装 sysstat： 如果您的系统上没有安装 sysstat，可以使用适合您系统的包管理工具进行安装。\n运行 mpstat： 使用 mpstat 命令查看 CPU 的使用情况和负载。默认情况下，mpstat 每秒钟显示一次 CPU 使用情况的平均值。您可以通过指定时间间隔来调整输出频率。例如，要以每秒钟一次的频率运行 mpstat，可以使用以下命令：mpstat -P ALL 2，irq 表示占用资源占用\n01:32:33 PM CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 01:32:35 PM all 0.00 0.00 0.26 0.00 3.73 0.26 0.00 0.00 0.00 95.76 01:32:35 PM 0 0.00 0.00 0.51 0.00 3.57 0.00 0.00 0.00 0.00 95.92 01:32:35 PM 1 0.00 0.00 0.00 0.00 3.59 0.51 0.00 0.00 0.00 95.90 01:32:35 PM 2 0.00 0.00 0.00 0.00 4.15 0.00 0.00 0.00 0.00 95.85 01:32:35 PM 3 0.00 0.00 0.52 0.00 3.61 0.52 0.00 0.00 0.00 95.36 分析输出： mpstat 的输出包括了每个 CPU 的利用率，以及系统的平均负载。特别关注平均负载以及每个 CPU 的利用率，可以帮助您了解系统的负载情况。如果负载较高，可以进一步分析是哪些进程导致的，以及是否存在性能瓶颈。\n结合其他工具： 除了 mpstat，还可以使用 sar、pidstat、iostat 等工具来综合分析系统性能。通过结合多种工具的输出，可以更全面地了解系统的负载情况，并找出性能问题的根源。\n中断 此处不展开讲解内容太多， 推荐: 《面向应用开发者的系统指南》CPU篇之软中断\n频繁的触发软中断，也会体现在系统负载中。\n问题排查 考虑到仅从CPU角度分析无法定位问题，我们是否应该开始怀疑系统是否出现了异常？可能是Linux操作系统的负载过高，导致VMware占用了过多的CPU资源。通过使用mpstat分析本地虚拟机，我们发现irq占用异常，单核接近25%，而在正常情况下，启动业务进程空跑时，irq占比应该约为5%。\n在组内同事的开发环境中，他的CentOS 7部署在VMware上，资源占用显示正常。另一方面，在上海的开发环境中，虽然也是VMware，但我们无法直接观察宿主机的CPU资源情况。这时，我们面临着多个变量：VMware虚拟机、Linux操作系统和GCC版本。\n转而分析测试环境，深圳的测试环境部署在物理机上，运行着低版本GCC编译的服务，而且在CentOS 8上运行。有趣的是，在深圳环境中，irq占用都是正常的。\n为了排查GCC版本引入的问题，我们将使用高版本GCC编译的程序部署到深圳环境进行测试，结果显示也都是正常的。\n问题似乎变得更加明朗，我们开始怀疑操作系统是否存在问题。毕竟，CentOS 8已经不再受到官方支持。但即便重新部署了纯净的CentOS 7和CentOS 8，问题依然存在。\n此时，我们开始怀疑唯一的不确定因素，即VMware虚拟机软件。突然间，灵光一现，我们想到了Hyper-V技术。是否之前启用了Hyper-V，但没有彻底关闭，从而导致了这个问题？毕竟，软中断也是通过虚拟机软件来实现的。不同的虚拟机虚拟技术是否存在BUG？这些问题值得深入思考和调查。\n结论 根据微软官方的手册，我们完全关闭了本机的Hyper-V服务后，发现VMware在宿主机上恢复了正常。至此，问题终于迎刃而解。正如一开始所述，这段经历曲折而艰辛，需要综合性的分析和判断。这也是我们首次排查问题，定位到了虚拟机这一层面。\nDisable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V-Hypervisor bcdedit /set hypervisorlaunchtype off https://learn.microsoft.com/zh-cn/troubleshoot/windows-client/application-management/virtualization-apps-not-work-with-hyper-v ","date":"2024-03-10T22:14:59+08:00","permalink":"https://ttf248.github.io/p/vmware%E8%99%9A%E6%8B%9F%E6%9C%BAcpu%E8%B5%84%E6%BA%90%E5%8D%A0%E7%94%A8%E5%BC%82%E5%B8%B8/","title":"vmware虚拟机cpu资源占用异常"},{"content":"本文旨在揭示在C++编程中不正确使用std::map容器可能导致程序崩溃，通过中括号操作符尝试访问不存在的键时，会自动添加一个空元素。我们将深入剖析这一误解，并通过实例代码展示其潜在风险。\n存储简单值不会有什么问题，但如果存储的是指针，那么就会有问题。因为指针是一个地址，如果没有初始化，那么这个地址是不确定的，这样就会导致程序崩溃。\n正文 在C++标准库中，std::map是一种关联容器，它按照键（key）的升序存储元素，并提供了高效的关键字查找功能。然而，新手开发者有时会因为对std::map中括号操作符 [] 的行为理解有误而陷入困境。实际上，当使用 [] 访问一个不存在的键时，std::map 会插入一个新的键值对，且默认构造函数将会用来初始化该键对应的值类型。\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;map\u0026gt; int main() { std::map\u0026lt;std::string, int\u0026gt; myMap; // 错误的用法：假设这里试图访问一个不存在的键并认为会得到0 std::cout \u0026lt;\u0026lt; \u0026quot;Value for 'nonexistent_key': \u0026quot; \u0026lt;\u0026lt; myMap[\u0026quot;nonexistent_key\u0026quot;] \u0026lt;\u0026lt; std::endl; // 实际上，上述行代码创建了一个新的键值对，其中值被默认初始化为int的默认值（通常是0） return 0; } 以上代码虽然没有直接导致程序崩溃，但这种隐式的插入行为在某些情况下可能导致意料之外的副作用，例如资源泄漏或不符合预期的状态变更。更糟糕的是，在多线程环境下并发访问未初始化的内存区域，甚至可能导致程序崩溃。\n为了防止此类问题，推荐使用 std::map::find() 或 std::map::count() 方法来检查键是否存在，或者利用 std::map::insert() 明确地插入元素：\nstd::map\u0026lt;std::string, int\u0026gt; safeMap; if (safeMap.count(\u0026quot;nonexistent_key\u0026quot;) == 0) { std::cout \u0026lt;\u0026lt; \u0026quot;Key does not exist.\u0026quot; \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026quot;Value for existing key: \u0026quot; \u0026lt;\u0026lt; safeMap[\u0026quot;nonexistent_key\u0026quot;] \u0026lt;\u0026lt; std::endl; } // 或者明确插入一个键值对，指定初始值 safeMap.insert({ \u0026quot;new_key\u0026quot;, 0 }); 如果 map 容器内部保存的对象为指针类型，自动插入元素的行为将保存一个未初始化的指针，调用到此指针的任何操作都将导致程序崩溃。\n","date":"2024-03-10T22:03:06+08:00","permalink":"https://ttf248.github.io/p/c-%E7%BC%96%E7%A8%8B%E4%B8%AD%E7%9A%84%E9%99%B7%E9%98%B1%E9%94%99%E8%AF%AF%E4%BD%BF%E7%94%A8stdmap%E5%AF%BC%E8%87%B4%E7%A8%8B%E5%BA%8F%E5%B4%A9%E6%BA%83%E8%AF%A6%E8%A7%A3/","title":"C++编程中的陷阱：错误使用`std::map`导致程序崩溃详解"},{"content":"在软件开发和运维中，经常会遇到进程假死的情况，这种情况会导致系统性能下降或者服务不可用。本文介绍如何使用 pstack 工具来排查进程假死问题，通过分析进程的堆栈信息，找出问题的原因并解决。\n背景：风控系统子服务出现假死，导致风控服务不可用。由于缺乏服务可用性监控，无法及时发现进程假死的情况，导致系统不可用。\n正文 进程假死是指进程停止响应，但并没有退出的状态。这种情况可能由于多种原因引起，比如死锁、资源耗尽、异常等。为了解决这类问题，我们可以使用 pstack 工具来分析进程的堆栈信息，找出问题的根源。\n步骤 pstack 是一个常用的工具，通常随着 gdb（GNU 调试器）一起提供。你可以通过以下命令安装它：\nsudo apt-get install gdb 获取进程ID：首先，我们需要获取假死进程的进程ID（PID）。可以使用 ps 命令来列出所有进程，并找到需要排查的进程ID。 使用 pstack 工具分析进程堆栈，一旦获取到进程ID，就可以使用 pstack 工具来获取该进程的堆栈信息。运行以下命令：\npstack \u0026lt;PID\u0026gt; 这将输出该进程的堆栈信息，显示出当前正在执行的函数调用序列。通过分析这些信息，可以发现进程停滞的位置，进而定位问题。\n分析堆栈信息，通过查看堆栈信息，可以找到导致进程假死的原因。可能会发现一些死锁情况、无限循环或者其他异常情况。根据具体情况采取相应的措施，比如释放锁、修复代码逻辑等。\n案例 简单 demo，main 函数启动以后，新建子线程，实际执行函数进入死循环，导致程序无法正常结束，陷入假死的状态。\ncmake_minimum_required(VERSION 3.0.0) project(pstack_main VERSION 0.1.0 LANGUAGES C CXX) include(CTest) enable_testing() # 查找线程库 find_package(Threads REQUIRED) add_executable(pstack_main main.cpp) # 链接线程库 target_link_libraries(pstack_main PRIVATE Threads::Threads) set(CPACK_PROJECT_NAME ${PROJECT_NAME}) set(CPACK_PROJECT_VERSION ${PROJECT_VERSION}) include(CPack) #include \u0026lt;iostream\u0026gt; #include \u0026lt;thread\u0026gt; #include \u0026lt;chrono\u0026gt; void infiniteLoop() { while (true) { // 主线程进入死循环 } } int main() { std::thread thread(infiniteLoop); // 创建一个线程，执行死循环函数 thread.join(); // 等待线程结束 return 0; } 启动程序，执行 pstack 结果：\nThread 2 (Thread 0x7eff3619b700 (LWP 1315017)): #0 infiniteLoop () at /root/pstack/main.cpp:6 #1 0x0000000000402ca9 in std::__invoke_impl\u0026lt;void, void (*)()\u0026gt; (__f=@0x2260eb8: 0x4029a6 \u0026lt;infiniteLoop()\u0026gt;) at /usr/include/c++/8/bits/invoke.h:60 #2 0x0000000000402b02 in std::__invoke\u0026lt;void (*)()\u0026gt; (__fn=@0x2260eb8: 0x4029a6 \u0026lt;infiniteLoop()\u0026gt;) at /usr/include/c++/8/bits/invoke.h:95 #3 0x0000000000403150 in std::thread::_Invoker\u0026lt;std::tuple\u0026lt;void (*)()\u0026gt; \u0026gt;::_M_invoke\u0026lt;0ul\u0026gt; (this=0x2260eb8) at /usr/include/c++/8/thread:244 #4 0x0000000000403126 in std::thread::_Invoker\u0026lt;std::tuple\u0026lt;void (*)()\u0026gt; \u0026gt;::operator() (this=0x2260eb8) at /usr/include/c++/8/thread:253 #5 0x000000000040310a in std::thread::_State_impl\u0026lt;std::thread::_Invoker\u0026lt;std::tuple\u0026lt;void (*)()\u0026gt; \u0026gt; \u0026gt;::_M_run (this=0x2260eb0) at /usr/include/c++/8/thread:196 #6 0x00007eff36bceb23 in execute_native_thread_routine () from /lib64/libstdc++.so.6 #7 0x00007eff36ea91ca in start_thread () from /lib64/libpthread.so.0 #8 0x00007eff361d58d3 in clone () from /lib64/libc.so.6 Thread 1 (Thread 0x7eff372e1740 (LWP 1315016)): #0 0x00007eff36eaa6cd in __pthread_timedjoin_ex () from /lib64/libpthread.so.0 #1 0x00007eff36bceda7 in std::thread::join() () from /lib64/libstdc++.so.6 #2 0x00000000004029d2 in main () at /root/pstack/main.cpp:13 可以看到，进程假死的原因是死循环，主线程进入死循环，子线程无法退出，导致进程假死。\n","date":"2024-02-24T23:55:59+08:00","permalink":"https://ttf248.github.io/p/pstack%E6%8E%92%E6%9F%A5%E8%BF%9B%E7%A8%8B%E5%81%87%E6%AD%BB/","title":"pstack排查进程假死"},{"content":"如果说当年按照家里的规划，老老实实读电网，没有出来写代码，我可能会是一个标准的乖乖男。\n扫去记忆里的灰尘，起因还是临近春节，和室友的一次聊天，顺带梳理了一波这些年的历程。\n章节一 高考的成绩不能说好，也不能说差，混了一个211毕业了，按照老爸最初的规划，我应该好好读电网，然后回到老家市区的供电局工作。前面也有稿子提到过，怎么一步步走上IT这条路，有一点里面忘记提了：金钱观、自控力。\n初一还在村镇的学校，初二家里就安排转学到了市区，如同刘姥姥到了大观园，多少有些没有适应市区的繁华，小时候没有去过几次电影院，确切的说，没有和爸妈一起去过几次电影院，倒是家里的亲戚带我去过。上天总会给你留下幸运，那会认识了几个臭味相投哥们，虽说后面联系少了，那段少年的时光现在来看也是美好的。在周末补习以后，一起收拾教室里面的塑料瓶，能够熟练的一脚踩扁然后装进书包，带回去找我妈存着，积攒的差不多了，找个收废品的处理掉。一起下象棋、打羽毛球、玩斗地主，输了的惩罚做几个俯卧撑，那会还有点小庆幸，老爸从小就带着我做各种运动。从这会开始，，金钱观稍微有点不对，稍微有点自卑，但是这些小不幸都是一闪而过，家里也不是说揭不开锅，确实没有多少零花钱，和周围的同学有时候玩不到一起，特别是周末，父母的努力是肉眼能看到的，我们从村里搬出来，到了市区。此时种子已经埋下，静待发芽。\n头脑简单的我，读书期间总体是非常快乐的，就如很多人毕业后才能体会到的，读书其实不算一件难事，投入和产出转化起来比较容易。\n叠加小时候帝国时代的记忆，到了大学期间，触碰到了笔记本电脑，如同潘多拉的魔盒打开，接触到了游戏，也和游戏商人这个角色产生了联系。最初的时候，我就是一个底层的销售人员，从上游进货，然后靠着自己社群的渠道，慢慢销售手里的货物，赚点小钱，到了后面，逐步明白整个链路的运转逻辑。我们销售的货物，不过是上游程序批量孵化的，他们的成本趋近于零。此时，路已经开始有点歪了，专业里面还有细分的专业，左边是电网，右边是自动化（很杂、芯片编程、工厂电气自动化），我明白程序能赚钱，还不是小钱，渠道上游确实赚了很多，加上以前有着编程的底子，开始东搞、西搞，弄了点小钱，在分专业的时候，自然而然我选择的是自动化。打了大三的专业课，很多我都没去，天天脑子里面就想着写代码搞钱。\n去年的文章里面提过，带着对黑客的美好憧憬接触的编程，非科班的IT凭着仁爱，搞了汇编、渗透、游戏外挂、dll劫持和盗号，熟悉和了解各种黑产、灰产；父母教会了做人，法律还是规劝住了我，路没有彻底走歪。\n前文链接：那时少年\n大学期间也谈过一次恋爱，回过头来看，更多是对于电视剧里面爱情的向往，心智不成熟的我，那会尚且无法明白如何爱一个人，更无法做到：成家立业。\n章节二 时代的洪流中，我是也是幸运的，大学的一通折腾，我当然不可能去考研，毕业就参加了工作，趁着IT的东风，工作也是顺顺当当的。已经是工作的第八个年头，行业的热钱消失，终归开始了落幕，有时候也会怀疑，当初的选择是不是错了，当初听老爸的进入电网也许是个更好的选择。如果是在工作的前面五年，可能还有这样的想法，后面就也就慢慢消失了。校招入了恒生，五年没有更换公司，不论是技术的认知、行业的认识，亦或是自己的能力的认知，都存在一定的缺陷。听从杭州总部的安排，去了深圳分公司，经历了一次职场斗争（事后才梳理清楚脉络，两边都输了，最后的赢家是董事会），抱着对技术的热爱，回到了杭州，带着点年少一点不自知，从杭州撤了，跑到了上海。\n原本计划回杭州安家、落户、买房，利率最高点、房价最高峰，入场就要被套住，家底薄折腾不起，真让我扛着房贷结婚的压力，叠加行业下行，情绪上容易不稳定。\n章节三 出来那么多年，见识了那么多事，自己也蠢过，也浪过，目前尚且安好。经历一些事，经历一些人，总归是慢慢长大了，如果一直在家待着，性格里面的缺陷不知会以何种形式爆发出来。\n","date":"2024-02-08T10:30:43+08:00","permalink":"https://ttf248.github.io/p/%E5%87%BA%E6%9D%A5%E8%B5%B0%E8%B5%B0%E6%80%BB%E5%BD%92%E6%98%AF%E5%A5%BD%E7%9A%84/","title":"出来走走总归是好的"},{"content":"设计行情 SDK，针对不同的回调函数实现方式，进行了一次耗时的测试。近期在看 C++ 函数编程，当函数变成了一等公民，在程序内部流转，耗时有什么不同？\n前文链接：编译器、回调函数、性能测试\nleimao 大佬刚好也做了类似的测试，借代码一用。\n正文 执行平台依旧是我们的老朋友，https://wandbox.org/\n#include \u0026lt;cassert\u0026gt; #include \u0026lt;chrono\u0026gt; #include \u0026lt;functional\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; int add_one(int input) { return input + 1; } bool validate_vector_add_one(std::vector\u0026lt;int\u0026gt; const\u0026amp; input_vector, std::vector\u0026lt;int\u0026gt; const\u0026amp; output_vector) { bool is_valid{true}; for (size_t i{0}; i \u0026lt; input_vector.size(); ++i) { if (output_vector.at(i) != input_vector.at(i) + 1) { is_valid = false; break; } } return is_valid; } void reset_vector(std::vector\u0026lt;int\u0026gt;\u0026amp; input_vector) { for (size_t i{0}; i \u0026lt; input_vector.size(); ++i) { input_vector.at(i) = 0; } } template \u0026lt;typename T, typename Func\u0026gt; void unitary_function_pass_by_lambda_function(T\u0026amp; output, T const\u0026amp; input, Func const func) { output = func(input); } template \u0026lt;typename T\u0026gt; void unitary_function_pass_by_std_function_value(T\u0026amp; output, T const\u0026amp; input, std::function\u0026lt;T(T)\u0026gt; const func) { output = func(input); } template \u0026lt;typename T\u0026gt; void unitary_function_pass_by_std_function_reference( T\u0026amp; output, T const\u0026amp; input, std::function\u0026lt;T(T)\u0026gt; const\u0026amp; func) { output = func(input); } template \u0026lt;typename T\u0026gt; void unitary_function_pass_by_function_pointer(T\u0026amp; output, T const\u0026amp; input, T (*func)(T)) { output = func(input); } int main() { // Set floating point format std::cout with 3 decimal places. std::cout.precision(3); size_t const num_elements{10000000}; std::vector\u0026lt;int\u0026gt; input_vector(num_elements, 0); std::vector\u0026lt;int\u0026gt; output_vector(num_elements, 0); auto const lambda_function_add_one{[](int const\u0026amp; input) -\u0026gt; int { return input + 1; }}; std::function\u0026lt;int(int)\u0026gt; const std_function_add_one{lambda_function_add_one}; std::cout \u0026lt;\u0026lt; \u0026quot;The size of a function pointer: \u0026quot; \u0026lt;\u0026lt; sizeof(\u0026amp;add_one) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026quot;The size of a std::function pointer: \u0026quot; \u0026lt;\u0026lt; sizeof(\u0026amp;std_function_add_one) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026quot;The size of a std::function: \u0026quot; \u0026lt;\u0026lt; sizeof(std_function_add_one) \u0026lt;\u0026lt; std::endl; // Call function frequently in a vanilla way. // The compiler knows what function to call at compile time and can optimize // the code. // This is the best performance we could get. std::chrono::steady_clock::time_point const time_start_vanilla{ std::chrono::steady_clock::now()}; for (size_t i{0}; i \u0026lt; num_elements; ++i) { output_vector.at(i) = add_one(input_vector.at(i)); } std::chrono::steady_clock::time_point const time_end_vanilla{ std::chrono::steady_clock::now()}; auto const time_elapsed_vanilla{ std::chrono::duration_cast\u0026lt;std::chrono::nanoseconds\u0026gt;(time_end_vanilla - time_start_vanilla) .count()}; float const latency_vanilla{time_elapsed_vanilla / static_cast\u0026lt;float\u0026gt;(num_elements)}; std::cout \u0026lt;\u0026lt; \u0026quot;Latency Pass Vanilla: \u0026quot; \u0026lt;\u0026lt; latency_vanilla \u0026lt;\u0026lt; \u0026quot; ns\u0026quot; \u0026lt;\u0026lt; std::endl; assert(validate_vector_add_one(input_vector, output_vector)); reset_vector(output_vector); // Sometimes, we don't know what function to call at compile time. // We can use std::function to pass a function as an argument. // In this case, we pass the std::function by value. // Because the size of a std::function is 32 bytes, passing by value // results in a lot of copying and bad performance. std::chrono::steady_clock::time_point const time_start_pass_by_std_function_value{std::chrono::steady_clock::now()}; for (size_t i{0}; i \u0026lt; num_elements; ++i) { unitary_function_pass_by_std_function_value( output_vector.at(i), input_vector.at(i), std_function_add_one); } std::chrono::steady_clock::time_point const time_end_pass_by_std_function_value{std::chrono::steady_clock::now()}; auto const time_elapsed_pass_by_std_function_value{ std::chrono::duration_cast\u0026lt;std::chrono::nanoseconds\u0026gt;( time_end_pass_by_std_function_value - time_start_pass_by_std_function_value) .count()}; float const latency_pass_by_std_function_value{ time_elapsed_pass_by_std_function_value / static_cast\u0026lt;float\u0026gt;(num_elements)}; std::cout \u0026lt;\u0026lt; \u0026quot;Latency Pass By Std Function Value: \u0026quot; \u0026lt;\u0026lt; latency_pass_by_std_function_value \u0026lt;\u0026lt; \u0026quot; ns\u0026quot; \u0026lt;\u0026lt; std::endl; assert(validate_vector_add_one(input_vector, output_vector)); reset_vector(output_vector); // Instead of passing the std::function by value, we can pass it by // reference (pointer). In this case, object copying is eliminated. The // performance is better than passing the std::function by value. However, // the performance is still not as good as the vanilla way. std::chrono::steady_clock::time_point const time_start_pass_by_std_function_reference{ std::chrono::steady_clock::now()}; for (size_t i{0}; i \u0026lt; num_elements; ++i) { unitary_function_pass_by_std_function_reference( output_vector.at(i), input_vector.at(i), std_function_add_one); } std::chrono::steady_clock::time_point const time_end_pass_by_std_function_reference{ std::chrono::steady_clock::now()}; auto const time_elapsed_pass_by_std_function_reference{ std::chrono::duration_cast\u0026lt;std::chrono::nanoseconds\u0026gt;( time_end_pass_by_std_function_reference - time_start_pass_by_std_function_reference) .count()}; float const latency_pass_by_std_function_reference{ time_elapsed_pass_by_std_function_reference / static_cast\u0026lt;float\u0026gt;(num_elements)}; std::cout \u0026lt;\u0026lt; \u0026quot;Latency Pass By Std Function Reference: \u0026quot; \u0026lt;\u0026lt; latency_pass_by_std_function_reference \u0026lt;\u0026lt; \u0026quot; ns\u0026quot; \u0026lt;\u0026lt; std::endl; assert(validate_vector_add_one(input_vector, output_vector)); reset_vector(output_vector); // std::function is a general purpose wrapper for function pointers, // callable objects, and lambda functions. Because it's general purpose, // it's not as efficient as a function pointer. In this case, we pass a // function pointer to a function. The performance is better than passing // the std::function by reference. std::chrono::steady_clock::time_point const time_start_pass_by_function_pointer{std::chrono::steady_clock::now()}; for (size_t i{0}; i \u0026lt; num_elements; ++i) { unitary_function_pass_by_function_pointer(output_vector.at(i), input_vector.at(i), \u0026amp;add_one); } std::chrono::steady_clock::time_point const time_end_pass_by_function_pointer{std::chrono::steady_clock::now()}; auto const time_elapsed_pass_by_function_pointer{ std::chrono::duration_cast\u0026lt;std::chrono::nanoseconds\u0026gt;( time_end_pass_by_function_pointer - time_start_pass_by_function_pointer) .count()}; float const latency_pass_by_function_pointer{ time_elapsed_pass_by_function_pointer / static_cast\u0026lt;float\u0026gt;(num_elements)}; std::cout \u0026lt;\u0026lt; \u0026quot;Latency Pass By Function Pointer: \u0026quot; \u0026lt;\u0026lt; latency_pass_by_function_pointer \u0026lt;\u0026lt; \u0026quot; ns\u0026quot; \u0026lt;\u0026lt; std::endl; assert(validate_vector_add_one(input_vector, output_vector)); reset_vector(output_vector); // We can also pass a lambda function to a function. // The compiler knows what function to call at compile time and can optimize // the code. The performance is also better than passing the std::function // by reference. std::chrono::steady_clock::time_point const time_start_pass_by_lambda_function{std::chrono::steady_clock::now()}; for (size_t i{0}; i \u0026lt; num_elements; ++i) { unitary_function_pass_by_lambda_function( output_vector.at(i), input_vector.at(i), lambda_function_add_one); } std::chrono::steady_clock::time_point const time_end_pass_by_lambda_function{std::chrono::steady_clock::now()}; auto const time_elapsed_pass_by_lambda_function{ std::chrono::duration_cast\u0026lt;std::chrono::nanoseconds\u0026gt;( time_end_pass_by_lambda_function - time_start_pass_by_lambda_function) .count()}; float const latency_pass_by_lambda_function{ time_elapsed_pass_by_lambda_function / static_cast\u0026lt;float\u0026gt;(num_elements)}; std::cout \u0026lt;\u0026lt; \u0026quot;Latency Pass By Lambda Function: \u0026quot; \u0026lt;\u0026lt; latency_pass_by_lambda_function \u0026lt;\u0026lt; \u0026quot; ns\u0026quot; \u0026lt;\u0026lt; std::endl; assert(validate_vector_add_one(input_vector, output_vector)); reset_vector(output_vector); } # 组里常规也就开启 O2 优化，编译选用了 gcc13，不同版本的 gcc 性能耗时略有不同，版本越高 lambda 效果越好 The size of a function pointer: 8 The size of a std::function pointer: 8 The size of a std::function: 32 Latency Pass Vanilla: 0.418 ns Latency Pass By Std Function Value: 3.47 ns Latency Pass By Std Function Reference: 1.36 ns Latency Pass By Function Pointer: 0.396 ns Latency Pass By Lambda Function: 0.44 ns 参考资料 https://leimao.github.io/blog/CPP-Function-Call-Performance/\n","date":"2024-01-24T14:11:33+08:00","permalink":"https://ttf248.github.io/p/c-%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E8%80%97%E6%97%B6/","title":"C++函数调用耗时"},{"content":"关于字节序的科普 主机序、网络序，通过调试器，直接观察\n计算机领域历史原因形成的某些设计习惯，跟马屁股宽度决定火箭推进器宽度的道理是一样的，没必要硬去分析里面的“优势”“劣势”，纯粹只是历史习惯。\n原文链接 作者：北极 链接：https://www.zhihu.com/question/637413724/answer/3346032134 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n正文转载 现如今的大小端状况，是历史习惯+商业化的结果，跟技术本身关系不大。ARM 可以设置成大端也可以设置成小端。TCP/IP 头至今仍然是大端（网络字节序）。存储领域也有很多存储协议/规范以大端方式保存数据。\n所以题主的三个问题，在今天看来：\n计算机为什么普遍采用小端存储？\u0026ndash;\u0026gt; 不正确。 为什么低字节存储在低地址的小端方式比大端方式效率更高? \u0026ndash;\u0026gt; 效率并不会更高。 任何以当前技术来论证这三个问题的，都属于先射箭后画靶子的行为。\n但是如果说大端或者小端的选择，在计算机发展历史上，确实是有一定客观因素的：主机字节序（小端）的优势：小端的加法器比较好做，如果做一个8位*4的加法器，只需要一个8位加法器，然后依次从低到高循环加上所有字节就可以了，进位的电路非常简单，而如果是大端，则需要一次加载32位，否则无法进行计算。现在来看，一次加载8位还是32位，区别不大，但是在几十年前，存储器的价格昂贵，自然是越简单越好，所以主机字节序选择小端是基于成本的考虑。网络字节序（大端）的优势：早年设备的缓存很小，先接收高字节能快速的判断报文信息：包长度（需要准备多大缓存）、地址范围（IP地址是从前到后匹配的）。早年的网络设备的缓存都是以字节为单位的，先取高字节确实是会更快一些。所以网络设备使用大端，也是基于成本的考虑。\n所以，字节序的选择，在历史上，大多数是应用场景和成本的考虑更多（比如：PPC/MIPS更适合做网络设备），而后来的技术发展过程中，由于兼容性的原因，大小端的配置沿用至今。\n在今天看来，这些优势已经完全不存在了，仅仅只是历史习惯。\n","date":"2024-01-24T10:43:05+08:00","permalink":"https://ttf248.github.io/p/%E8%BD%AC%E8%BD%BD%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%BA%E4%BB%80%E4%B9%88%E6%99%AE%E9%81%8D%E9%87%87%E7%94%A8%E5%B0%8F%E7%AB%AF%E5%AD%98%E5%82%A8/","title":"转载：计算机为什么普遍采用小端存储"},{"content":"心血来潮，琢磨找找新壁纸，习惯黑色系列，部分区域彩色即可，桌面需要放置图标，其他色系作壁纸，图标就不清晰了。\n盯着上面的汇编代码思考一波，没看懂，尝试扔给AI，解释了指令，没有解释场景，必然是某个特殊场景用到的指令，常规代码不是这样的。\nAI此时不如搜索引擎了，汇编的知识储备不足。\n壁纸 汇编代码 PUSHFD MOV DWORD PTR [ESP],0X100 POPFD 实际应用场景\nbool IsDebugged() { __try { __asm { pushfd mov dword ptr [esp], 0x100 popfd nop } return true; } __except(GetExceptionCode() == EXCEPTION_SINGLE_STEP ? EXCEPTION_EXECUTE_HANDLER : EXCEPTION_CONTINUE_EXECUTION) { return false; } } 解释说明 TrapFlag是标志寄存器中的一个标志位，当这个标志位被设置时，会抛出异常SINGLE_STEP，因为如果我们跟踪代码，这个标志位会被调试器清零，所以我们看不到这个异常。\n实际测试时发现，如果直接步过检测调试的函数，那么调试不会被检测到，只有步入检测函数执行时才会检测到(资料查询，尚未实际验证)\n参考资料 中文的相关资料，都是基于网站的英文稿子翻译，站点科普了很多种反调试的技术。\nhttps://anti-debug.checkpoint.com/ https://song-10.gitee.io/2021/08/08/Reverse-2021-08-08-anti-debug/ ","date":"2024-01-23T19:46:36+08:00","permalink":"https://ttf248.github.io/p/%E7%A8%8B%E5%BA%8F%E5%A6%82%E4%BD%95%E5%8F%8D%E8%B0%83%E8%AF%95/","title":"程序如何反调试"},{"content":"最近有人咨询，如何下载焦点访谈的视频，脑子里面想着十有八九又是 m3u8 方式加密，洒洒水了，简单处理下。\n下载器 https://github.com/nilaoda/N_m3u8DL-CLI\nm3u8 downloader 开源的命令行m3u8/HLS/dash下载器，支持普通AES-128-CBC解密，多线程，自定义请求头等. 支持简体中文,繁体中文和英文. English Supported.\n浏览器插件 Live Stream Downloader\n蜜汁自信 拿到地址，以为搞定了，结果啥也不是，无法正常解析分段内容，查询资料，发现官方处理了下载地址，需要人工进行一定的替换，将插件解析到的 key 人工复制替换到下面的链接中\nhttps://newcntv.qcloudcdn.com/asp/hls/2000/0303000a/3/default/***********************/2000.m3u8 截止 2024年1月，地址测试有效，后续如有变动，自行分析网页。\n历史地址备份：https://hlswx.cntv.kcdnvip.com/asp/hls/main/0303000a/3/default/一串字符/main.m3u8?maxbr=2000\n参考资料 http://jln.cn/post/517.html\n","date":"2024-01-23T19:23:35+08:00","permalink":"https://ttf248.github.io/p/%E5%A6%82%E4%BD%95%E4%B8%8B%E8%BD%BD%E7%84%A6%E7%82%B9%E8%AE%BF%E8%B0%88/cctv%E8%A7%86%E9%A2%91%E6%96%87%E4%BB%B6/","title":"如何下载焦点访谈/CCTV视频文件"},{"content":"公司安全策略调整，机械师 mini最终还是搬迁回家作为备用服务器，顺带重装机器系统，ubuntu 切换到了windows server，由于激活的手段不正规，自己家里用，好像不激活也没事\n非常规方式激活，触发了微软的检测（正常运行了半个月），服务器开机一小时，自动关机，翻了一圈系统日志，才发现是盗版导致的。\n没辙，再次重装系统，SqlServer也面临重装，每次弄都比较蛋疼，文件权限管控严格，导致无法正常附加数据库。\n报错信息 系统重装以后，SqlServer在附加数据库中可能会出现5120，操作系统错误拒绝访问。\n处理脚本 前文链接：批量更新本地Git仓库，没错又是这个熟悉的脚本，改造一下，我们遍历文件夹的同时修改文件的权限，当前用于拥有完全编辑的权限。\n网上的教程大部分都是让你手动修改，他们每次只需要修改几个文件吗？我每次都需要处理一批文件，全部手动处理，人会自闭的。\n$currentUserName = [System.Security.Principal.WindowsIdentity]::GetCurrent().Name [Console]::OutputEncoding = [System.Text.Encoding]::UTF8 $rootDirectory = \u0026quot;D:\\data\\2013_RujiaInfo\u0026quot; Get-ChildItem -Path $rootDirectory -Recurse | ForEach-Object { $itemPath = $_.FullName if ($_ -is [System.IO.DirectoryInfo]) { $icaclsResult = icacls $itemPath /setowner \u0026quot;$currentUserName\u0026quot; 2\u0026gt;\u0026amp;1 if ($LASTEXITCODE -eq 0) { Write-Host \u0026quot;已更改文件夹 $itemPath 的所有者为 $currentUserName\u0026quot; # 授予当前用户写入权限 Invoke-Expression \u0026quot;icacls `\u0026quot;$itemPath`\u0026quot; /grant `\u0026quot;$($currentUserName):(OI)(CI)F`\u0026quot;\u0026quot; Write-Host \u0026quot;已授予 $currentUserName 编辑文件夹的权限\u0026quot; } else { Write-Host \u0026quot;无法更改文件夹 $itemPath 的所有者。错误信息: $icaclsResult\u0026quot; } } else { $takeownResult = icacls $itemPath /setowner \u0026quot;$currentUserName\u0026quot; 2\u0026gt;\u0026amp;1 if ($LASTEXITCODE -eq 0) { # 授予当前用户写入权限 Invoke-Expression \u0026quot;icacls `\u0026quot;$itemPath`\u0026quot; /grant `\u0026quot;$($currentUserName):(F)`\u0026quot;\u0026quot; Write-Host \u0026quot;已授予 $currentUserName 编辑文件的权限\u0026quot; } else { Write-Host \u0026quot;无法更改文件 $itemPath 的所有者。错误信息: $takeownResult\u0026quot; } } } ","date":"2024-01-23T19:06:36+08:00","permalink":"https://ttf248.github.io/p/%E6%89%B9%E9%87%8F%E4%BF%AE%E6%94%B9sqlserver%E6%95%B0%E6%8D%AE%E5%BA%93%E7%A3%81%E7%9B%98%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90/","title":"批量修改SqlServer数据库磁盘文件权限"},{"content":"Windows 平台有个鲁大师（娱乐大师），不能说数据很准，单总归有个参考，当然也有其他的专业跑分软件，到了 Linux 系统，好像一直没遇到特别合适的跑分软件。\nSysbench 是一款多功能的基准测试工具，可用于测试CPU、内存、文件I/O、线程性能等。您可以使用 sysbench 来执行各种性能测试任务。\n手头上刚好有三台机器用于测试：机械师 mini 本地小主机、阿里云 dev 开发云服务器、华为云开发服务器。\n安装Sysbench 在大多数Linux发行版中，您可以使用包管理工具来安装Sysbench。例如，在CentOS 8上，可以使用以下命令进行安装\nsudo dnf install sysbench Sysbench的使用示例 测试CPU性能：sysbench --test=cpu run 测试内存读取性能：sysbench --test=memory run 测试文件I/O性能： sysbench --test=fileio --file-test-mode=rndrw prepare sysbench --test=fileio --file-test-mode=rndrw run sysbench --test=fileio --file-test-mode=rndrw cleanup 测试多线程性能: sysbench --test=threads --num-threads=4 run 测试MySQL数据库性能（需调整数据库最大连接数）： sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword --oltp-table-size=1000000 prepare sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword --max-time=60 --oltp-read-only=off --oltp-test-mode=complex --max-requests=0 run sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword cleanup 跑分数据报告 ABCD1本地机械师阿里云华为云2系统配置System Information\nOperating System Ubuntu 23.04\nKernel Linux 6.2.0-36-generic x86_64\nModel Machenike Machenike DT Computer\nMotherboard Machenike Machenike DT Computer\nBIOS American Megatrends International, LLC.\nDB19V012\nCPU Information\nName Intel Core i7-12650H\nTopology 1 Processor, 10 Cores, 16 Threads\nIdentifier GenuineIntel Family 6 Model 154 Stepping 3\nBase Frequency 4.60 GHz\nL1 Instruction Cache 32.0 KB x 8\nL1 Data Cache 48.0 KB x 8\nL2 Cache 1.25 MB x 2\nL3 Cache 24.0 MB\nMemory Information\nSize 62.6 GBSystem Information\nOperating System CentOS Stream 8\nKernel Linux 4.18.0-513.el8.x86_64 x86_64\nModel Alibaba Cloud Alibaba Cloud ECS\nMotherboard N/A\nBIOS SeaBIOS 449e491\nCPU Information\nName Intel(R) Xeon(R) Platinum\nTopology 1 Processor, 1 Core, 2 Threads\nIdentifier GenuineIntel Family 6 Model 85 Stepping 4\nBase Frequency 2.50 GHz\nL1 Instruction Cache 32.0 KB\nL1 Data Cache 32.0 KB\nL2 Cache 1.00 MB\nL3 Cache 33.0 MB\nMemory Information\nSize 1.65 GBSystem Information\nOperating System Ubuntu 22.04.1 LTS\nKernel Linux 5.15.0-60-generic x86_64\nModel OpenStack Foundation OpenStack Nova\nMotherboard N/A\nBIOS SeaBIOS\nrel-1.10.2-0-g5f4c7b1-20181220_000000-szxrtosci10000\nCPU Information\nName Intel(R) Xeon(R) Gold 6278C CPU @ 2.60GHz\nTopology 1 Processor, 1 Core, 2 Threads\nIdentifier GenuineIntel Family 6 Model 85 Stepping 7\nBase Frequency 2.60 GHz\nL1 Instruction Cache 32.0 KB\nL1 Data Cache 32.0 KB\nL2 Cache 1.00 MB\nL3 Cache 35.8 MB\nMemory Information\nSize 3.64 GB3CPUsysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)\nRunning the test with following options:\nNumber of threads: 1\nInitializing random number generator from current time\nPrime numbers limit: 10000\nInitializing worker threads...\nThreads started!\nCPU speed:\nevents per second: 4032.48\nGeneral statistics:\ntotal time: 10.0004s\ntotal number of events: 40330\nLatency (ms):\nmin: 0.25\navg: 0.25\nmax: 0.73\n95th percentile: 0.25\nsum: 9997.55\nThreads fairness:\nevents (avg/stddev): 40330.0000/0.00\nexecution time (avg/stddev): 9.9975/0.00sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)\nRunning the test with following options:\nNumber of threads: 1\nInitializing random number generator from current time\nPrime numbers limit: 10000\nInitializing worker threads...\nThreads started!\nCPU speed:\nevents per second: 1062.51\nGeneral statistics:\ntotal time: 10.0008s\ntotal number of events: 10628\nLatency (ms):\nmin: 0.91\navg: 0.94\nmax: 22.84\n95th percentile: 1.06\nsum: 9993.46\nThreads fairness:\nevents (avg/stddev): 10628.0000/0.00\nexecution time (avg/stddev): 9.9935/0.00sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)\nRunning the test with following options:\nNumber of threads: 1\nInitializing random number generator from current time\nPrime numbers limit: 10000\nInitializing worker threads...\nThreads started!\nCPU speed:\nevents per second: 1125.56\nGeneral statistics:\ntotal time: 10.0005s\ntotal number of events: 11258\nLatency (ms):\nmin: 0.86\navg: 0.89\nmax: 1.70\n95th percentile: 0.99\nsum: 9995.40\nThreads fairness:\nevents (avg/stddev): 11258.0000/0.00\nexecution time (avg/stddev): 9.9954/0.004内存Running the test with following options:\nNumber of threads: 1\nInitializing random number generator from current time\nRunning memory speed test with the following options:\nblock size: 1KiB\ntotal size: 102400MiB\noperation: write\nscope: global\nInitializing worker threads...\nThreads started!\nTotal operations: 101993199 (10198146.52 per second)\n99602.73 MiB transferred (9959.13 MiB/sec)\nGeneral statistics:\ntotal time: 10.0001s\ntotal number of events: 101993199\nLatency (ms):\nmin: 0.00\navg: 0.00\nmax: 0.03\n95th percentile: 0.00\nsum: 4059.50\nThreads fairness:\nevents (avg/stddev): 101993199.0000/0.00\nexecution time (avg/stddev): 4.0595/0.00Running the test with following options:\nNumber of threads: 1\nInitializing random number generator from current time\nRunning memory speed test with the following options:\nblock size: 1KiB\ntotal size: 102400MiB\noperation: write\nscope: global\nInitializing worker threads...\nThreads started!\nTotal operations: 48418803 (4841004.79 per second)\n47283.99 MiB transferred (4727.54 MiB/sec)\nGeneral statistics:\ntotal time: 10.0001s\ntotal number of events: 48418803\nLatency (ms):\nmin: 0.00\navg: 0.00\nmax: 25.26\n95th percentile: 0.00\nsum: 4578.95\nThreads fairness:\nevents (avg/stddev): 48418803.0000/0.00\nexecution time (avg/stddev): 4.5789/0.00Running the test with following options:\nNumber of threads: 1\nInitializing random number generator from current time\nRunning memory speed test with the following options:\nblock size: 1KiB\ntotal size: 102400MiB\noperation: write\nscope: global\nInitializing worker threads...\nThreads started!\nTotal operations: 57056904 (5704765.11 per second)\n55719.63 MiB transferred (5571.06 MiB/sec)\nGeneral statistics:\ntotal time: 10.0001s\ntotal number of events: 57056904\nLatency (ms):\nmin: 0.00\navg: 0.00\nmax: 0.06\n95th percentile: 0.00\nsum: 4556.06\nThreads fairness:\nevents (avg/stddev): 57056904.0000/0.00\nexecution time (avg/stddev): 4.5561/0.005硬盘2147483648 bytes written in 1.81 seconds (1129.59 MiB/sec).\nRunning the test with following options:\nNumber of threads: 1\nInitializing random number generator from current time\nExtra file open flags: (none)\n128 files, 16MiB each\n2GiB total file size\nBlock size 16KiB\nNumber of IO requests: 0\nRead/Write ratio for combined random IO test: 1.50\nPeriodic FSYNC enabled, calling fsync() each 100 requests.\nCalling fsync() at the end of test, Enabled.\nUsing synchronous I/O mode\nDoing random r/w test\nInitializing worker threads...\nThreads started!\nFile operations:\nreads/s: 3373.41\nwrites/s: 2248.94\nfsyncs/s: 7201.80\nThroughput:\nread, MiB/s: 52.71\nwritten, MiB/s: 35.14\nGeneral statistics:\ntotal time: 10.0127s\ntotal number of events: 128288\nLatency (ms):\nmin: 0.00\navg: 0.08\nmax: 5.14\n95th percentile: 0.34\nsum: 9977.78\nThreads fairness:\nevents (avg/stddev): 128288.0000/0.00\nexecution time (avg/stddev): 9.9778/0.002147483648 bytes written in 19.29 seconds (106.16 MiB/sec).\nRunning the test with following options:\nNumber of threads: 1\nInitializing random number generator from current time\nExtra file open flags: (none)\n128 files, 16MiB each\n2GiB total file size\nBlock size 16KiB\nNumber of IO requests: 0\nRead/Write ratio for combined random IO test: 1.50\nPeriodic FSYNC enabled, calling fsync() each 100 requests.\nCalling fsync() at the end of test, Enabled.\nUsing synchronous I/O mode\nDoing random r/w test\nInitializing worker threads...\nThreads started!\nFile operations:\nreads/s: 1593.12\nwrites/s: 1062.08\nfsyncs/s: 3406.64\nThroughput:\nread, MiB/s: 24.89\nwritten, MiB/s: 16.60\nGeneral statistics:\ntotal time: 10.0164s\ntotal number of events: 60600\nLatency (ms):\nmin: 0.00\navg: 0.16\nmax: 31.32\n95th percentile: 0.54\nsum: 9956.30\nThreads fairness:\nevents (avg/stddev): 60600.0000/0.00\nexecution time (avg/stddev): 9.9563/0.002147483648 bytes written in 18.29 seconds (111.98 MiB/sec).\nRunning the test with following options:\nNumber of threads: 1\nInitializing random number generator from current time\nExtra file open flags: (none)\n128 files, 16MiB each\n2GiB total file size\nBlock size 16KiB\nNumber of IO requests: 0\nRead/Write ratio for combined random IO test: 1.50\nPeriodic FSYNC enabled, calling fsync() each 100 requests.\nCalling fsync() at the end of test, Enabled.\nUsing synchronous I/O mode\nDoing random r/w test\nInitializing worker threads...\nThreads started!\nFile operations:\nreads/s: 1665.88\nwrites/s: 1110.59\nfsyncs/s: 3563.77\nThroughput:\nread, MiB/s: 26.03\nwritten, MiB/s: 17.35\nGeneral statistics:\ntotal time: 10.0112s\ntotal number of events: 63355\nLatency (ms):\nmin: 0.00\navg: 0.16\nmax: 205.01\n95th percentile: 0.78\nsum: 9972.64\nThreads fairness:\nevents (avg/stddev): 63355.0000/0.00\nexecution time (avg/stddev): 9.9726/0.006多线程Running the test with following options:\nNumber of threads: 4\nInitializing random number generator from current time\nInitializing worker threads...\nThreads started!\nGeneral statistics:\ntotal time: 10.0002s\ntotal number of events: 197956\nLatency (ms):\nmin: 0.16\navg: 0.20\nmax: 0.34\n95th percentile: 0.21\nsum: 39970.47\nThreads fairness:\nevents (avg/stddev): 49489.0000/5.70\nexecution time (avg/stddev): 9.9926/0.00Running the test with following options:\nNumber of threads: 4\nInitializing random number generator from current time\nInitializing worker threads...\nThreads started!\nGeneral statistics:\ntotal time: 10.0174s\ntotal number of events: 18360\nLatency (ms):\nmin: 0.57\navg: 2.18\nmax: 32.77\n95th percentile: 2.61\nsum: 40050.41\nThreads fairness:\nevents (avg/stddev): 4590.0000/94.36\nexecution time (avg/stddev): 10.0126/0.00Running the test with following options:\nNumber of threads: 4\nInitializing random number generator from current time\nInitializing worker threads...\nThreads started!\nGeneral statistics:\ntotal time: 10.0004s\ntotal number of events: 28536\nLatency (ms):\nmin: 0.23\navg: 1.40\nmax: 3.56\n95th percentile: 1.47\nsum: 39975.16\nThreads fairness:\nevents (avg/stddev): 7134.0000/39.87\nexecution time (avg/stddev): 9.9938/0.01 后记 ChatGPT 还是个好东西，上面的表格，按照以前掌握的Markdown完全无法编排，不做成表格，展示的效果就会很差，自定义主题限制了页面最大宽度，同步调整了一波页面的配置，宽度改为百分比限制。\n简单的方法，使用TablesGenerator等在线工具生成HTML表格（内容复杂不合适） 或者使用谷歌在线文档编写，然后下载保存为HTML文档，直接复制到博客（简单直接，最终采用） 确保 config 配置开启了 unsafe 配置项，单独给页面配置宽度\n在 Hugo 中，你可以为页面单独设置宽度。这可以通过在页面的 Front Matter 中添加自定义参数来实现。以下是一个示例：\n在你的 Markdown 页面的 Front Matter 部分（通常在文件的开头部分）添加一个自定义参数，例如 custom_width： --- title: \u0026quot;我的页面\u0026quot; date: 2024-01-09 custom_width: \u0026quot;800px\u0026quot; # 设置宽度为 800 像素 --- 正文内容... 在你的 Hugo 主题中，找到或创建对应的单页面模板文件（例如，layouts/_default/single.html）。\n在单页面模板中，检查页面的 Front Matter 中是否有 custom_width 参数，并将其应用到相应的 HTML 元素上，例如 div：\n{{ define \u0026quot;main\u0026quot; }} \u0026lt;div style=\u0026quot;max-width: {{ with .Params.custom_width }}{{ . }}{{ else }}100%{{ end }}; margin: 0 auto;\u0026quot;\u0026gt; {{ .Content }} \u0026lt;/div\u0026gt; {{ end }} 这个示例中，我们使用了内联样式（style属性）为 div 元素设置了 max-width 属性，使其在没有指定 custom_width 参数时，宽度默认为100%。margin: 0 auto; 用于将 div 元素居中。\n请注意，实际应用中，你可能需要根据你的主题结构和CSS样式的细节来调整上述示例。确保在调整样式时保持主题的一致性和可读性。\n由于启用的主题稍微有些不同，最后调整了站点自定义的CSS配置。\n","date":"2024-01-09T10:56:23+08:00","permalink":"https://ttf248.github.io/p/linux%E7%B3%BB%E7%BB%9F%E8%B7%91%E5%88%86%E6%B5%8B%E8%AF%95/","title":"Linux系统跑分测试"},{"content":"习惯更新软件版本，不知道从哪个版本的Git开始，禁止从Http仓库拉取代码\nfatal: Unencrypted HTTP is not supported for GitLab. Ensure the repository remote URL is using HTTPS 背景介绍 环境：Windows 平台，一直用的都是小乌龟来操作git，配置秘钥也是通过小乌龟来处理的，之前弄过一次脚本，批量更新本地的仓库\n前文链接：批量更新本地Git仓库\n今天回家执行代码更新的时候，出现了前面的报错，仓库无法正常更新了，本想着Git应该提供了配置，让我继续使用http的协议更新仓库，找了一圈，也没翻到对应的配置项。\n最简单的解决方案当然是切换成ssh协议来更新仓库，公司配置的gitlab短期内不会提供https协议。\n遗留问题 前面编写批量更新本地仓库脚本的是时候，本来想着使用ssh的方式拉取仓库，也没细查是因为什么，通过小乌龟配置的git配置信息并没有同步到 config 中，导致通过命令行执行\ngit pull #提示没有权限，无法正常更新仓库 通过命令检查秘钥配置也是正确的：ssh -T git@gitlab.yintech.net\n如果你使用Git小乌龟（TortoiseGit）能够正常拉取代码，但在命令行中使用 git pull 命令时提示秘钥不对，这可能是因为Git小乌龟使用的是PuTTY的SSH密钥，而命令行使用的是OpenSSH的SSH密钥。\n小乌龟的秘钥配置，不会从系统 .ssh 文件夹读取秘钥文件信息，而是通过界面仓库配置的时候，单独配置秘钥文件的路径，有用的小技巧：拉取的第一个仓库配置了秘钥即可让其余仓库都复用这个秘钥文件，PuTTY 加载秘钥以后，不会立即退出，而是启动了一个代理服务。\n通过调整全局配置，不使用系统默认的ssh配置，这样配置后，Git Bash 将使用 TortoisePlink 进行 SSH 操作。这种配置适用于使用 TortoiseGit 自带的 PuTTY 工具的情况。\ngit config --global core.sshCommand \u0026quot;'C:/Program Files/TortoiseGit/bin/TortoisePlink.exe' -batch -ssh\u0026quot; 上面配置的执行文件文件路径自行修改到对应的小乌龟路径，由于配置的完整路径，无需添加路径到系统环境变量中。\n","date":"2024-01-08T21:22:04+08:00","permalink":"https://ttf248.github.io/p/git%E7%A6%81%E7%94%A8http%E4%BB%93%E5%BA%93/","title":"Git禁用http仓库"},{"content":"两年前给站点添加代码区域的拷贝功能，前后折腾了小半天，最终渲染效果有点不如意，作为半吊子前端开发，也没想着改进，能用就行，今年用AI开发了小程序，对于前端的开发也更加熟悉了，重构一波（AI重新设计）。\n悟道：任务拆解开，很多小任务，AI开发起来还是顺手的。已经倒闭的小程序，75%代码由AI提供，拆解了多个任务交付，人工进行项目代码的组装。\n前文 以为很简单的事情，增加一个代码复制按钮\n正文 promot: 设计 css 和 JavaScript 代码，定位网页元素 class=\u0026ldquo;highlight\u0026rdquo;，这个元素的容器内，添加一个 复制按钮，实现复制代码的功能\n给的第一稿代码一眼看上去就有问题，重新生成一稿，基本可用，复制的内容不对，有冗余的文字，再次引导优化，人工指定核心的颜色设计，包含哪些特效\n了解到您对按钮的尺寸和颜色有特定的要求，我们可以重新设计按钮的样式以适应这些要求。以下是一个调整后的 CSS 样式，其中包括了您提供的颜色方案，并对按钮的尺寸进行了优化：\n.copy-btn { position: absolute; top: 2px; /* 调整位置 */ right: 2px; padding: 3px 6px; /* 缩小尺寸 */ font-size: 12px; /* 减小字体大小 */ background-color: #8FD1E1; /* 按钮背景色 */ color: #272822; /* 文字颜色 */ border: 1px solid #272822; /* 边框颜色 */ border-radius: 3px; /* 圆角 */ cursor: pointer; opacity: 0.7; /* 默认半透明 */ transition: opacity 0.3s ease, background-color 0.3s ease; /* 平滑过渡效果 */ } .copy-btn:hover { opacity: 1; /* 鼠标悬停时不透明 */ background-color: #A3D4E5; /* 鼠标悬停时的背景色 */ } .highlight { position: relative; } 在这个样式中，我减小了按钮的尺寸和字体大小，使其更加精致。同时，按钮的默认状态是半透明的，当鼠标悬停在按钮上时，它会变为不透明，并且背景色会变得稍微亮一些，以提供视觉反馈。这样的设计既符合您的颜色要求，又保持了现代化和用户友好的特点。\n对应的提供了一份更简单的 JavaScript：\ndocument.addEventListener('DOMContentLoaded', function() { // 查找所有 .highlight 元素 const highlights = document.querySelectorAll('.highlight'); highlights.forEach(function(highlight) { // 创建复制按钮 const copyBtn = document.createElement('button'); copyBtn.textContent = '复制'; copyBtn.classList.add('copy-btn'); // 将按钮添加到每个 .highlight 元素中 highlight.appendChild(copyBtn); // 添加点击事件监听器 copyBtn.addEventListener('click', function() { // 假设 .highlight 下的第一个 \u0026lt;code\u0026gt; 元素包含要复制的代码 const code = highlight.querySelector('code') ? highlight.querySelector('code').textContent : ''; navigator.clipboard.writeText(code).then(() =\u0026gt; { // 显示复制成功信息 copyBtn.textContent = '已复制!'; setTimeout(() =\u0026gt; { copyBtn.textContent = '复制'; }, 2000); }).catch(err =\u0026gt; { console.error('复制失败: ', err); }); }); }); }); 后记 虽说我更期望在代码区域的右上角，顶部区域新增复制按钮，由于对前端不够了解，无法基于关键词准确描述功能，和AI来回折腾几个回合也没有达到预期。\n就是不知道随着时间的发展，AI对于程序开发会有多大的影响。\n","date":"2023-12-22T08:44:26+08:00","permalink":"https://ttf248.github.io/p/ai%E7%BC%96%E7%A8%8B%E5%92%8C%E4%BB%BB%E5%8A%A1%E6%8B%86%E8%A7%A3/","title":"AI编程和任务拆解"},{"content":"东方甄选小作文事件是一起由于东方甄选官方账号否认主播董宇辉是所有小作文的作者而引发的网络风波。到底真相如何，已经无从考证，公司权谋的斗争将这个事情推上了风口浪尖。\n鱼的七秒钟记忆，以后都交付给AI撰写，尝试了Bing AI和ChatGPT plus，前者给的资料更加完整，搜索引擎的获取的资料还是更多一些，输出的博文内容不够完整，格式比较僵硬；后者通过关键词获取内容，生成的内容不是那么完整，但是能获取完整的博文内容，如果给出参考资料的网址，能优化生成的稿子。\n正文 东方甄选小作文事件是一场围绕版权和创作归属的争议，从2023年12月5日开始，涉及主播董宇辉与东方甄选的一系列互动。这场风波不仅揭示了商业运作的复杂性，也引发了对当代商业文化和网络社会的深刻反思\n2023年12月5日：事件起点 东方甄选发布了一段预热视频，主播董宇辉朗诵的“小作文”迅速走红。 东方甄选在视频评论中声明，这些小作文多数由文案团队创作，并非全部出自董宇辉之手。 2023年12月13日：董宇辉的回应 董宇辉发表长文，反对以“饭圈”名义污名化任何人，表明自己对事件的立场。 2023年12月14日：管理层的回应 东方甄选CEO孙东旭发布道歉视频，承认公司管理上的漏洞。 东方甄选董事长俞敏洪也对事件进行回应，向董宇辉表达歉意。 2023年12月16日：重大决策 东方甄选官方宣布免去孙东旭的CEO职务，俞敏洪兼任。 同日，俞敏洪发表致歉信，表示将解除直播间拉黑的网友。 2023年12月18日：董宇辉的新角色 新东方教育科技集团任命董宇辉为新东方教育科技集团董事长文化助理，兼任新东方文旅集团副总裁。 俞敏洪透露，将与董宇辉成立工作室，开辟新的直播账号和直播间。 结论与反思 这场风波不仅是一场关于版权和创作归属的争议，更深层次地反映了文化与商业的碰撞。在数字化、碎片化的时代背景下，内容创作的版权归属成为了一个值得深思的话题。东方甄选小作文事件，不仅是一场媒体风波，更是对当代商业文化和网络社会的一次深刻反思。\n作为观察者，我们应该如何看待这种文化与商业的碰撞？在追求商业利益的同时，我们又该如何保护和尊重创作者的劳动成果？这些问题，值得我们每一个人深思。\n","date":"2023-12-20T18:57:25+08:00","permalink":"https://ttf248.github.io/p/%E4%B8%9C%E6%96%B9%E7%94%84%E9%80%89%E5%B0%8F%E4%BD%9C%E6%96%87%E9%A3%8E%E6%B3%A2%E4%B8%80%E5%9C%BA%E6%96%87%E5%8C%96%E4%B8%8E%E5%95%86%E4%B8%9A%E7%9A%84%E7%A2%B0%E6%92%9E/","title":"东方甄选小作文风波：一场文化与商业的碰撞"},{"content":"氪金类型的游戏，这里不做讨论，游戏圈子里面，这种统称：人民币战士，不需要对游戏设定的理解，需要你有个殷实的钱包。他们享受的乐趣在于周围小弟的前呼后拥，屠城的快感。\n有着广大受众的竞技游戏，比如：英雄联盟、DOTA、王者荣耀、绝地求生，这类型的游戏，世界观设定完整、游戏赛事已经进入良性循环的状态。\n在游戏设计中，心理学确实是一个关键领域，而社交心理学尤为重要。理解人们的行为、需求和动机可以帮助设计更吸引人的游戏体验。关于\u0026quot;装逼\u0026quot;和社交心理学之间的关系，我们可以从以下几个角度来看：\n社交认同感： 人们往往寻求在社交群体中建立认同感。在游戏中，如果设计能够让玩家感到自己在某方面很出色，能够引起其他玩家的注意，这可能会提高他们的社交认同感。这可能表现为炫耀技能、展示获得的奖励等。\n社交竞争： 一些游戏采用了社交竞争的元素，鼓励玩家在社交网络中展示他们的成就。这可以通过排行榜、成就系统或多人对战等方式来实现。这样的设计激发了玩家间的竞争心理，可能会导致一些玩家表现得更为出色以获得社交认可。\n自我展示： 有些游戏允许玩家通过自定义角色、虚拟物品等方式进行自我展示。这种自我展示不仅仅是为了炫耀，还可以是一种表达个性和社交交流的方式。\n团队合作： 一些游戏注重团队合作，通过社交互动来达到游戏目标。在这样的情境中，装逼的行为可能并不被鼓励，而是强调团队协作和相互支持。\n心理奖励系统： 游戏设计可以采用心理奖励系统，激发玩家积极的社交行为。例如，给予玩家奖励或特权，以鼓励他们积极参与社交互动。\n总体而言，游戏设计中的社交心理学可以被用来塑造玩家之间的互动和社交体验。装逼行为在一些情境下可能存在，但游戏设计师通常会努力平衡这种行为，以确保游戏体验对所有玩家都是积极和有趣的。\n想到哪里写到哪里，没有完整的大纲，稍微有点乱。\n作者常玩的英雄联盟，算是我们这代人的青春记忆，大部分的家长都不喜欢孩子玩游戏，因为他们没有深入的了解体会过这类型的游戏，当然也和游戏设定有关系，每局游戏都是新的开始、对于很多孩子来说，玩的时候，并没有带入太多的思考，属于自行探索的玩法，这种模式下，游戏的输赢，更多取决于孩子本身的游戏天赋。依据笔者的实际体验，相当多一部分的玩家属于此类型，对于他们来说。\n最大的成本不是金钱，而是时间。\n游戏里面也有娱乐模式，用以满足娱乐玩家的需求。\n英雄联盟这种竞技游戏对于笔者来说，更多的是圆了一个三国梦。开局你兜里两手空空，靠着自己的理解，补刀、发育，花费经济，布控视野，设局埋伏对面，更多的是用脑子玩游戏，没有那种绝佳的游戏天赋，也能玩的很开心。统领全局的掌控感，逆风翻盘的愉悦感。还有很多弹幕常说的云玩家，他们已经不玩游戏了，但是每次到世界赛期间，他们还是会观看比赛。\n这里就不得不提，游戏时间。指的不是单局游戏的时间，而是你上号的时间，周末的下午、每天工作日的晚上七点到晚上十点之间，你会发现和队友大部分情况都能正常沟通，你发出去的信号，队友能理解，能收到回应。换到其他时间，比如说通宵游戏，你碰到的更多就是网瘾少年，顺风的情况，无事发生，逆风的情况下，他们能问候你的全家，隔着屏幕你都能感受到那股子戾气。\n本身就是从事IT行业，游戏这些东西接触的很多，玩的也多，各种类型的玩过，对于竞技游戏，一直习惯用脑子玩，而是不是拼反应速度，天赋摆在这里，和职业的对比，或者小年轻对比，反应还是慢一些，习惯的是开黑，然后接管队伍的指挥权。最初玩的时候，就是读书那会，YY工会的老大哥们带着玩的。\n现在游戏的环境怎么说呢，都比较浮躁，没有之前那种纯粹\n上了年级以后，高分段的对局，玩下来真的很累，全程都是高度集中，思考对面谋划，如何化解对面的设局，属于那种，你打完都不想继续的状态。\n真说你玩的很厉害，如果不打职业比赛，对于人生轨迹来说，并没有什么作用，能作为社交的手段，但是无法谋生，立足于社会。\n单机游戏和网络游戏是两种不同类型的游戏，它们在玩法、体验和技术上存在显著差异。以下是理解单机游戏和网络游戏之间区别的一些关键方面：\n连接方式：\n单机游戏（Offline/Single-player）： 这种游戏是在本地设备上独自玩的，不需要互联网连接。玩家可以在没有网络连接的情况下享受游戏体验。 网络游戏（Online/Multiplayer）： 这类游戏通常需要互联网连接，因为玩家要与其他玩家进行实时互动。网络游戏可以是多人合作或对抗性的，涉及到在线社交和竞技。 玩家互动：\n单机游戏： 玩家主要与游戏内的人工智能、预设的任务或敌对元素互动。游戏体验通常更加个人化，受到游戏内设计和故事情节的影响。 网络游戏： 玩家可以与来自世界各地的其他真实玩家互动。这可能包括合作完成任务、对抗或竞技比赛，以及社交元素如聊天、公会系统等。 游戏设计和内容：\n单机游戏： 游戏设计更侧重于提供一个完整的、独立的故事情节和游戏体验。游戏内容通常是预先设计好的，玩家在游戏中探索、解谜或战斗。 网络游戏： 游戏设计需要考虑到实时互动和玩家之间的竞争或协作。游戏的内容可能更动态，包括定期更新、在线事件和社交互动。 技术要求：\n单机游戏： 通常可以在离线状态下运行，对设备性能和互联网连接的要求相对较低。 网络游戏： 需要较强的互联网连接，而且对服务器和网络性能有较高的要求，以确保实时互动的顺畅进行。 商业模式：\n单机游戏： 通常采用一次性购买或下载的商业模式，玩家购买游戏后即可在本地设备上完整地玩游戏。 网络游戏： 可能采用免费游玩、广告、道具购买或订阅等多种商业模式，以维持服务器运营和不断更新游戏内容。 理解这些区别有助于玩家在选择游戏时明确自己的偏好，并使游戏设计者更好地满足玩家的期望。\n","date":"2023-12-11T10:26:22+08:00","permalink":"https://ttf248.github.io/p/%E6%B8%B8%E6%88%8F%E5%BF%83%E7%90%86%E5%AD%A6%E7%AB%9E%E6%8A%80%E6%B8%B8%E6%88%8F/","title":"游戏心理学：竞技游戏"},{"content":"趁着双十一搞活动，阿里云新入手了一台服务器：经济适用版本，99一年，配置不高，作为跳板机代理家里的服务也是不错的，活动持续到2026年。\n特意选了上海地区的服务器，低延迟代理家里的机器，win11 和 windows server 2022，server 版本是后面部署的，使用的时候，突然收到拒绝访问的消息，本来以为是服务器更新，等会就能恢复正常。隔了五分钟，再去尝试，依旧拒绝登录，检索相关的报错，提示有人正在尝试登录，并且由于密码错误次数太多，现在无法登录。\n以前也是接触过安防攻击的脚本，立马就想到了，这些登录大概率不是正常的行为，是有人在攻击服务，尝试暴力破解登录服务器。服务器防火墙设置图省事，没有设置白名单，代理了两台机器的 3389 端口，在公网里面暴露出来，就和鱼塘里面的鱼饵差不多。既然知道了是脚本小子在攻击，接下来的事情就简单了，设置防火墙白名单，仅允许公司的IP地址和家里的IP地址访问代理服务。\nfrps代理服务端以前也没配置运行日志，开启日志后，给我看乐了，全国各地的代理IP，都在尝试登录家里的服务器，还好有一台是 server 版本，让我意识到了问题，不然 win11 那台机器，迟早别攻破，密码设置的比较简单。\n2023/11/17 16:51:14 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [101.43.98.211:50486] 2023/11/17 16:51:14 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [218.93.202.63:56970] 2023/11/17 16:51:14 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [222.179.106.174:60812] 2023/11/17 16:51:15 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [58.16.204.238:2839] 2023/11/17 16:51:15 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [124.223.47.24:50274] 2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [43.248.128.22:55883] 2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [43.143.53.138:56955] 2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [43.228.7.250:61550] 2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [125.76.228.9:55842] 2023/11/17 16:51:17 [I] [proxy.go:204] [4dfcc2259937dcb9] [winserver-remote] get a user connection [91.240.118.187:49326] 2023/11/17 16:51:17 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [91.240.118.187:49324] 2023/11/17 16:51:17 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [89.248.163.79:51712] 2023/11/17 16:51:18 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [218.63.75.24:62387] 2023/11/17 16:51:19 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [103.186.109.227:51396] 2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [116.233.234.104:51567] 2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [222.187.193.202:51585] 2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [59.48.98.42:57489] 2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [146.56.241.134:53558] 2023/11/17 16:51:21 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [222.179.106.174:30620] 2023/11/17 16:51:23 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [183.14.214.51:62128] 捎带手，查了下linux服务的登录日志，除开阿里云这台机器，还有朋友一台华为云的机器\nsudo grep \u0026quot;Failed password\u0026quot; /var/log/secure centos系列 sudo grep \u0026quot;Failed password\u0026quot; /var/log/auth.log ubuntu系列 Nov 16 04:46:34 aliyun-sh sshd[156625]: Failed password for root from 120.55.164.64 port 53410 ssh2 Nov 16 04:46:34 aliyun-sh sshd[156623]: Failed password for root from 111.16.215.122 port 36548 ssh2 Nov 16 04:46:58 aliyun-sh sshd[156630]: Failed password for invalid user share from 139.9.233.78 port 53872 ssh2 Nov 16 04:47:23 aliyun-sh sshd[156634]: Failed password for invalid user spark from 139.9.233.78 port 36134 ssh2 Nov 16 04:47:26 aliyun-sh sshd[156636]: Failed password for root from 120.55.164.64 port 46142 ssh2 Nov 16 04:47:47 aliyun-sh sshd[156640]: Failed password for root from 111.16.215.122 port 42962 ssh2 Nov 16 04:48:24 aliyun-sh sshd[156652]: Failed password for root from 120.55.164.64 port 38868 ssh2 Nov 16 04:48:25 aliyun-sh sshd[156654]: Failed password for root from 111.16.215.122 port 46164 ssh2 Nov 16 04:48:39 aliyun-sh sshd[156657]: Failed password for invalid user test from 139.9.233.78 port 39386 ssh2 Nov 16 04:48:50 aliyun-sh sshd[156659]: Failed password for root from 111.16.215.122 port 38892 ssh2 Nov 16 04:48:53 aliyun-sh sshd[156662]: Failed password for root from 120.55.164.64 port 49348 ssh2 Nov 16 04:48:53 aliyun-sh sshd[156664]: Failed password for invalid user test from 139.9.233.78 port 49864 ssh2 Nov 16 04:50:02 aliyun-sh sshd[156672]: Failed password for root from 111.16.215.122 port 45294 ssh2 Nov 16 04:50:30 aliyun-sh sshd[156680]: Failed password for invalid user zabbix from 139.9.233.78 port 52206 ssh2 Nov 16 04:50:50 aliyun-sh sshd[156683]: Failed password for root from 120.55.164.64 port 34820 ssh2 Nov 16 04:50:51 aliyun-sh sshd[156685]: Failed password for root from 111.16.215.122 port 58978 ssh2 Nov 16 04:51:18 aliyun-sh sshd[156689]: Failed password for root from 120.55.164.64 port 45306 ssh2 Nov 16 04:51:25 aliyun-sh sshd[156692]: Failed password for root from 111.16.215.122 port 33938 ssh2 华为云这台机器开启的时间比较长，已经开始进入字典爆破的中期，各种奇怪的用户都开始出现。\nNov 16 20:30:35 hecs-411458 sshd[182965]: Failed password for invalid user oeh from 39.129.9.180 port 26459 ssh2 Nov 16 20:32:17 hecs-411458 sshd[182967]: Failed password for invalid user dnu from 39.129.9.180 port 27079 ssh2 Nov 16 20:34:12 hecs-411458 sshd[182971]: Failed password for invalid user rq from 39.129.9.180 port 27742 ssh2 Nov 16 20:36:07 hecs-411458 sshd[182979]: Failed password for invalid user zw from 39.129.9.180 port 28415 ssh2 Nov 16 20:37:59 hecs-411458 sshd[182981]: Failed password for invalid user egi from 39.129.9.180 port 29068 ssh2 Nov 16 20:39:52 hecs-411458 sshd[182984]: Failed password for invalid user bjb from 39.129.9.180 port 29723 ssh2 Nov 16 20:41:53 hecs-411458 sshd[182988]: Failed password for invalid user hna from 39.129.9.180 port 30375 ssh2 Nov 16 20:43:46 hecs-411458 sshd[182994]: Failed password for invalid user gar from 39.129.9.180 port 31036 ssh2 Nov 16 20:45:40 hecs-411458 sshd[183003]: Failed password for invalid user mze from 39.129.9.180 port 31703 ssh2 Nov 16 20:47:35 hecs-411458 sshd[183007]: Failed password for invalid user tmh from 39.129.9.180 port 32381 ssh2 Nov 16 21:23:01 hecs-411458 sshd[183047]: Failed password for invalid user amax from 112.4.65.118 port 41188 ssh2 Nov 16 22:31:20 hecs-411458 sshd[183116]: Failed password for root from 211.228.203.123 port 60213 ssh2 Nov 16 22:53:44 hecs-411458 sshd[183162]: Failed password for root from 112.132.249.164 port 39272 ssh2 Nov 17 11:44:26 hecs-411458 sshd[184811]: Failed password for invalid user jsh from 43.157.103.27 port 54608 ssh2 Nov 17 11:47:23 hecs-411458 sshd[184818]: Failed password for invalid user mrunal from 43.157.103.27 port 50448 ssh2 Nov 17 11:48:46 hecs-411458 sshd[184820]: Failed password for invalid user robertsheen from 43.157.103.27 port 50560 ssh2 后记 开发自用的服务器，windows 公网访问需要设置白名单，linux 建议禁止密码登录，开启秘钥文件登录。\n","date":"2023-11-20T15:08:53+08:00","permalink":"https://ttf248.github.io/p/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%84%9A%E6%9C%AC%E5%B0%8F%E5%AD%90/","title":"云服务器和脚本小子"},{"content":"组里的项目之间存在依赖关系，由于历史原因，并未使用submodule维护项目的依赖，日常开发需要手动依次更新仓库代码，否则可能碰到各种奇怪的问题。\n参考网上的资料，结构基本都类似，本地手动维护一份仓库目录：git_list.txt，编写脚本遍历目录，一次执行更新，以后开工前先执行下脚本\nlinux create new file: batch_pull.sh\n#!/bin/bash echo \u0026quot;============ 更新仓库 ===================\u0026quot; # 检查 git_list.txt 是否存在 if [ ! -f \u0026quot;git_list.txt\u0026quot; ]; then echo \u0026quot;git_list.txt 文件不存在！请创建并添加要拉取的 git 仓库 URL。\u0026quot; exit 1 else echo \u0026quot;============ 检测到了 git 仓库清单文件 ====\u0026quot; fi # 逐行读取 git_list.txt 中的 URL，并执行拉取操作 while read -r url; do if [ -d \u0026quot;$url\u0026quot; ]; then cd \u0026quot;$url\u0026quot; || continue git pull cd .. echo \u0026quot;Pull $url 完成！\u0026quot; echo \u0026quot;========================================\u0026quot; else echo \u0026quot;目录 $url 不存在，跳过拉取。\u0026quot; fi done \u0026lt; \u0026quot;git_list.txt\u0026quot; windows create a new file: batch_pull.bat\n@echo off chcp 65001 \u0026gt; nul rem 进入脚本所在目录 cd /d \u0026quot;%~dp0\u0026quot; rem 检查 git_list.txt 是否存在 if not exist \u0026quot;git_list.txt\u0026quot; ( echo git_list.txt 文件不存在！请创建并添加要拉取的 git 仓库 URL。 exit /b 1 ) else ( echo ============ 检测到了 git 仓库清单文件 ==== ) rem 逐行读取 git_list.txt 中的 URL，并执行拉取操作 for /f %%i in (git_list.txt) do ( if exist \u0026quot;%%i\u0026quot; ( pushd \u0026quot;%%i\u0026quot; git pull popd echo Pull %%i 完成！ echo ======================================== ) else ( echo 目录 %%i 不存在，跳过拉取。 ) ) 历史遗留问题 顺带处理重装系统以后碰到的git文件夹权限文件：Fatal error \u0026ldquo;unsafe repository (\u0026rsquo;/home/repon\u0026rsquo; is owned by someone else)\u0026rdquo;\n网上建议的做法大多来源自stack overflow:\n仓库目录添加信任: git config --global --add safe.directory /home/repon 手动修改配置文件.gitconfig，指定目录添加信任 [safe] directory = /home/repon 上面的方式处理以后，仓库更新是正常了，每次执行git pull控制台都有很多警告信息，提示用户所有者错误\n台式机重装系统 开发的机器，太久没有重装系统，系统盘垃圾文件爆炸，没辙，抽空重装了一波系统，再次碰到这个权限的问题，以前的脚本跑不通，修改的权限不完整\n用上新的方案，直接添加*，这样git会自动信任所有目录\ngit config --global --add safe.directory \u0026quot;*\u0026quot; 不知道是用户权限的问题，还是大家没习惯windows平台其实也有类似chown的命令，修改文件夹所有者，当然如果你的目录不多，手动修改所有者也行，但是这台工作电脑添加了域信息，不知道是公司部署的域存在异常，还是本地系统设置存在异常，用户清单中，找不到登录所用的用户，最后还是通过命令行处理的。\n管理员权限，执行powershell脚本change_ower.ps1，记得调整脚本文件编码为gbk，中文操作系统，这样才不会乱码\n# 获取当前用户的用户名 $currentUserName = [System.Security.Principal.WindowsIdentity]::GetCurrent().Name # 设置 PowerShell 的字符编码为 UTF-8 [Console]::OutputEncoding = [System.Text.Encoding]::UTF8 # 要更改所有者的根目录路径 $rootDirectory = \u0026quot;G:\\workspace\u0026quot; # 替换为实际的目录路径 # 递归遍历目录并更改文件和文件夹的所有者 Get-ChildItem -Path $rootDirectory -Recurse | ForEach-Object { $itemPath = $_.FullName # 检查是文件还是文件夹 if ($_ -is [System.IO.DirectoryInfo]) { # 如果是文件夹，使用 icacls 更改所有者权限 $icaclsResult = icacls $itemPath /setowner \u0026quot;$currentUserName\u0026quot; 2\u0026gt;\u0026amp;1 if ($LASTEXITCODE -eq 0) { Write-Host \u0026quot;已更改文件夹 $itemPath 的所有者为 $currentUserName\u0026quot; } else { Write-Host \u0026quot;无法更改文件夹 $itemPath 的所有者。错误信息: $icaclsResult\u0026quot; } } else { # 如果是文件，使用 icacls 更改所有者权限 $takeownResult = icacls $itemPath /setowner \u0026quot;$currentUserName\u0026quot; 2\u0026gt;\u0026amp;1 if ($LASTEXITCODE -eq 0) { # Write-Host \u0026quot;已更改文件 $itemPath 的所有者为 $currentUserName\u0026quot; } else { Write-Host \u0026quot;无法更改文件 $itemPath 的所有者。错误信息: $takeownResult\u0026quot; } } } 不出意外的还是出现了预料之外的情况，脚本执行输出的中文信息乱，尝试设置控制台的字符编码，调整脚本编码，输出的都是乱码，脑子那会大概率不清醒了，试着启用 控制面板-区域-语言设置的 beta 功能，全局开启 Unicode 编码，脚本执行是正常了，好几个开发软件都无法正常工作，回头梳理资料才想起来，调整脚本文件的编码，设置为 gbk\n资料 https://ganzhixiong.com/p/f1b9f4fc/ https://stackoverflow.com/questions/71901632/fatal-error-unsafe-repository-home-repon-is-owned-by-someone-else ","date":"2023-10-19T14:16:22+08:00","permalink":"https://ttf248.github.io/p/%E6%89%B9%E9%87%8F%E6%9B%B4%E6%96%B0%E6%9C%AC%E5%9C%B0git%E4%BB%93%E5%BA%93%E5%92%8C%E5%8E%86%E5%8F%B2%E9%81%97%E7%95%99%E7%9A%84%E6%9D%83%E9%99%90%E9%97%AE%E9%A2%98/","title":"批量更新本地Git仓库和历史遗留的权限问题"},{"content":"小程序开发设计的坑还没填上，新挖一个WPF，最近公司也动荡了一波，异地协同办公沟通总归效率总归有点不如意，索性承接了客户端界面的开发。\nWPF 推荐 WPF 微软官网学习资料 WPF 基础总结(学习建议) WPF 中文网 WPF 个人总结和学习推荐 WPF 界面设计用到的很多概念，类似于网页前端设计，尽可能的剥离UI设计和业务逻辑，让UI的设计能独立出来，也是互联网公司期望的分工方式。今年刚好折腾过小程序，很多概念上的东西都是通用的，上手也就比较轻松，这些算是现代UI设计中的道，掌握了基础的框架概念，后面的路不容易走歪。\n以前有Winform开发经验的读者，推荐阅读：WPF 基础总结(学习建议)，篇幅不长，适合有经验的读者规划学习路线\n零基础的读者推荐阅读：WPF 中文网，从零开始介绍基础的概念、发展的历史、底层类的认知逻辑。这个网站说来也是巧了，今年八月份作者刚发布的，用来吸引读者购买课程，和我这边的时间刚好对上了，如果再晚一点，和我大概率也就没有缘分了。\n想要最正统的学习资料，当然是微软官网的资料，有些枯燥，新读者需要有耐心。\n经典的电子书籍也有很多，不是很推荐，日常工作的事情也多，静下来看书的时间并不是很多，很难一下子就进入看书的状态，带着项目练习更合适一些。\nC# 和.net 发布历史 想对于以前学习的语言，最近几年，发布的新特性稍微有点多，语法的版本每年都在迭代。\nhttps://en.wikipedia.org/wiki/C_Sharp_(programming_language)\n官方学习资料：\nhttps://learn.microsoft.com/zh-cn/dotnet/csharp/ https://learn.microsoft.com/zh-cn/dotnet/core/tutorials/with-visual-studio?pivots=dotnet-7-0 ","date":"2023-10-17T10:49:24+08:00","permalink":"https://ttf248.github.io/p/wpf%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/","title":"WPF学习资料"},{"content":"中共中央政治局：要加大国有企业、金融领域反腐败力度，深入纠治“四风”\n中共中央政治局 中共中央政治局9月27日召开会议，审议《关于二十届中央第一轮巡视情况的综合报告》。中共中央总书记习近平主持会议。会议强调，要以巡视整改为契机，进一步加强党的全面领导，督促被巡视党组织提高政治站位，认真履行党中央赋予的职责使命，不断增强国有企业核心功能和核心竞争力，夯实中国特色社会主义的重要物质基础和政治基础，加大金融企业服务实体经济和国家战略力度，推动高质量发展。要统筹发展和安全，树牢底线思维、极限思维，采取有力措施防范化解重大风险，牢牢守住安全底线。要推动全面从严治党向纵深发展，压紧压实党委（党组）书记第一责任人责任、领导班子成员“一岗双责”、纪检监察机构监督责任，突出加强对各级“一把手”的监督，加大国有企业、金融领域反腐败力度，深入纠治“四风”，深化以案促改、以案促治，一体推进不敢腐、不能腐、不想腐。要认真贯彻新时代党的组织路线，加强领导班子建设、干部人才队伍建设和基层党组织建设。要综合用好巡视成果，深化改革、完善制度，推进源头治理，促进标本兼治。（新华社）\n造成重大金融风险！中国银行原党委书记、董事长刘连舸被开除党籍 据中央纪委国家监委网站，经中共中央批准，中央纪委国家监委对中国银行股份有限公司原党委书记、董事长刘连舸严重违纪违法问题进行了立案审查调查。 经查，刘连舸丧失理想信念，背弃初心使命，落实党中央决策部署不坚决、打折扣，弃守金融风险防控职责，大肆违规插手信贷项目，违法发放贷款，造成重大金融风险，履行全面从严治党主体责任不力，严重破坏所在单位政治生态，私自携带违禁书刊入境，处心积虑对抗组织审查；无视中央八项规定精神，违规收受礼品礼金、出入私人会所、接受滑雪和旅游安排，长期借用管理对象车辆；不按规定报告个人有关事项，在组织函询时不如实说明问题，徇私录用调整提拔干部；违规经商办企业；违规干预资金借贷，私自留存涉密资料；道德败坏，家风不正，对亲属失管失教；毫无纪法底线，擅权妄为，“靠金融吃金融”，利用职务便利为他人在贷款融资、项目合作等方面谋利，并非法收受巨额财物。\n刘连舸严重违反党的政治纪律、组织纪律、廉洁纪律、工作纪律和生活纪律，构成严重职务违法并涉嫌受贿、违法发放贷款犯罪，且在党的十八大后不收敛、不收手，性质严重，影响恶劣，应予严肃处理。依据《中国共产党纪律处分条例》《中华人民共和国监察法》《中华人民共和国公职人员政务处分法》等有关规定，经中央纪委常委会会议研究并报中共中央批准，决定给予刘连舸开除党籍处分；按规定取消其享受的待遇；终止其党的二十大代表资格；收缴其违纪违法所得；将其涉嫌犯罪问题移送检察机关依法审查起诉，所涉财物一并移送。\n中国光大集团原党委书记、董事长李晓鹏严重违纪违法被开除党籍和公职。（央视新闻） 中央纪委国家监委网站通报，据贵州省纪委监委消息：贵州银行原党委书记、董事长李志明涉嫌严重违纪违法，目前正接受贵州省纪委监委纪律审查和监察调查。 时隔八年，汇金增持四大行 10月11日，工商银行、农业银行、中国银行、建设银行四大国有商业银行分别发布公告，获汇金公司增持，分别为2761万股、3727万股、2489万股、1838万股；汇金公司拟在未来6个月内继续在二级市场增持四大行。\n","date":"2023-10-09T14:53:35+08:00","permalink":"https://ttf248.github.io/p/%E9%87%91%E8%9E%8D%E5%8F%8D%E8%85%90%E7%9A%84%E5%BA%8F%E5%B9%95/","title":"金融反腐的序幕"},{"content":"主播送 IPhone？小程序排名奖励？各种直播平台的礼物抽奖？\n上面三个看着没有太多关联的东西，实质上都是免费流量变现的不同模式，有点金融游戏的意思。\n平台抽奖获取礼物 常规的场景中，用户重置获取平台货币，购买礼物送给心怡的主播，各家平台还有另外一种玩法，用户获取了平台货币以后，不再直接送礼，可以花费一定量的货币，参与抽奖活动，获取限定的高价礼物。\n此时已经出现问题了，线上抽奖简单理解就是平台开赌场，参与人数足够多，肯定是不会亏本的。屌丝用户机带着搏一搏的心态，想着中个大奖，再去送礼，有面子、当大哥！\n主播送礼（实物） 前文提到的平台抽奖针对的是用户自身的行文，主播每个月都有流水任务、人气任务；开启送礼抽奖的玩法，粉丝送指定的礼物、或者送指定金额的礼物，就有机会参与抽奖，礼物可能是高端手机、或者现金红包。\n对于人气高的大主播而言，这个活动很赚钱，等于就是临时发起的零元购，参与的人数足够多，主播也是赚钱的。这里就考验了主播的运营能力。\n当然还有一种玩法，给的奖励很高（现金价值），很多户外主播就是这种玩法，变相的线上赌博了。直播的内容没人在乎，用户只关心自己是不是能中奖。\n除开秀场类型的主播，通过PK模式，诱导粉丝消费充值，普通的游戏主播，很难带动玩家的消费情绪，打游戏和看直播都是消遣的方式，并不想产生额外的金钱支出，特别是竞技类游戏，抽奖的方式，可以培养用户的充值习惯、消费习惯、偶尔还能冲动消费（送很多，想中奖）。\n小程序排名奖励 设计一个小程序，弄一些没什么用的流程，或者提供部分游戏相关的辅助服务。前面这些都是掩护，为了通过腾讯的审核，小程序里面的玩法带上排名机制。用户通过浏览激励广告，完成任务，赢取积分，后台依据积分设置排名，排名较高的用户获取指定的奖励。\n核心逻辑：广告收入 \u0026gt; 运营成本 + 奖励费用\n小程序也有正常运行的方式，提供合理的服务，通过适当的广告赚取收入，赚的可能不多，但是涓涓细流，也是可以的。\n","date":"2023-09-19T07:04:35+08:00","permalink":"https://ttf248.github.io/p/%E6%B5%81%E9%87%8F%E5%8F%98%E7%8E%B0%E7%9A%84%E5%95%86%E4%B8%9A%E6%A8%A1%E5%BC%8F%E6%8A%BD%E5%A5%96/","title":"流量变现的商业模式：抽奖"},{"content":"办公室新入手一台mini主机，想着配置配置环境方便，在家偶尔也有访问的需求，临时部署内网穿透。按照以往的经验，部署frp服务，指定端口转发，需要一台公网的服务器，连接的质量取决于公网服务器的宽带质量。折腾一点新鲜的Zerotier虚拟机局域网，类似于VPN，本地新建虚拟网卡，所有的机器都加入到一个虚拟网络中。\n什么是 Zerotier ZeroTier是一种软件定义的广域网络（SD-WAN）解决方案，它允许用户在不同地理位置的设备之间创建安全的虚拟网络。通过ZeroTier，您可以轻松地将多台计算机、服务器和设备连接到一个虚拟的、加密的网络中，就好像它们在同一局域网中一样。这可以帮助程序员和IT专业人员在不同地点之间安全地共享数据和资源，而无需复杂的网络设置和VPN配置。\nZerotier网络：Zerotier网络是一个虚拟的、全球性的局域网络，允许不同设备通过互联网连接在一起，就好像它们在同一个物理网络上一样。这个网络可以包含多个子网，所有设备都通过Zerotier的技术连接在一起。\n行星服务器：行星服务器是Zerotier网络的关键组件之一。它是全球性的，负责维护和管理整个Zerotier网络的拓扑结构、路由信息和网络状态。行星服务器起到全局的网络控制中心作用，但不直接传输数据。用户的设备需要连接至少一个行星服务器来参与Zerotier网络。\n中转服务器：中转服务器是Zerotier网络中的辅助节点，用于帮助设备之间建立直接通信通道。当设备之间无法直接连接时，它们可以通过中转服务器来传输数据。这有助于提高网络的可达性和性能。中转服务器通常位于全球各地，充当数据传输的中转点。\n总的来说，Zerotier通过行星服务器和中转服务器的协助，使设备能够在全球范围内创建虚拟的局域网络，实现安全、快速的设备之间通信。行星服务器负责全局网络管理，而中转服务器则帮助设备在需要时建立通信连接。\n安装部署 访问 ZeroTier 官方网站（https://www.zerotier.com/）以获取安装文件和文档。 根据您的操作系统下载和安装ZeroTier One客户端。支持Windows、macOS、Linux和许多其他平台。 安装完成后，启动ZeroTier One客户端。 注册一个ZeroTier账户，如果您还没有账户的话。您可以在客户端中创建一个账户。 登录您的ZeroTier账户并创建一个新的网络。网络将会有一个唯一的16位ID，您需要记住它。 在您的设备上加入这个网络。您可以在客户端中输入网络ID或使用QR码扫描功能。 安装并配置ZeroTier客户端的设备将会被添加到同一虚拟网络中。这些设备之间现在可以直接通信，就好像它们在同一局域网中一样。 您可以在ZeroTier的控制面板中管理网络设置、添加设备和监视网络流量等。 安装部署 moon 国内运营商很多都禁止了UDP打洞，frp服务稳定，由于走的tcp协议，Zerotier部署中转服务器也能实现类似的效果，防火墙需要开放udp 9993。\ncurl -s https://install.zerotier.com/ | sudo bash 检查安装是否成功\nzerotier-cli info 加入到局域网\nzerotier-cli join network-id 创建 moon\ncd /var/lib/zerotier-one \u0026amp;\u0026amp; sudo zerotier-idtool initmoon identity.public \u0026gt; moon.json 编辑配置文件，调整stableEndpoints节点，\u0026ldquo;服务器公网ip/9993\u0026rdquo;\n生成签名配置，创建moons.d文件夹，前面文件文件移动到此，重启服务\nsudo zerotier-idtool genmoon moon.json mkdir moons.d \u0026amp;\u0026amp; mv 000000eb444ec0d8.moon moons.d/ systemctl restart zerotier-one.service 客户端节点加入 moon 服务器, id 取自前面 json 配置文件中的 id 字段\nzerotier-cli.bat orbit ztaddr ztaddr # 观察是否出现新的 mooon 节点，id 和信息为服务器配置的相同 [root@idv-36f9d5 ~]# zerotier-cli listpeers 200 listpeers \u0026lt;ztaddr\u0026gt; \u0026lt;path\u0026gt; \u0026lt;latency\u0026gt; \u0026lt;version\u0026gt; \u0026lt;role\u0026gt; 200 listpeers 0cccb***** 35.236.*.*/64393;110;10726 327 1.6.3 LEAF 200 listpeers 3a46f***** 185.180.*.*/9993;110;757 -1 - PLANET 200 listpeers 3ed7c***** 39.97.*.*/9993;172;79 32 1.6.3 MOON 200 listpeers 4f838***** - -1 - LEAF 200 listpeers 62f86***** 50.7.*.*/9993;110;4796 351 - PLANET 200 listpeers 778cd***** 103.195.*.*/9993;5148;4887 253 - PLANET 200 listpeers 992fc***** 195.181.*.*/9993;10161;4921 226 - PLANET 200 listpeers 9d2b5***** - -1 - LEAF windows 平台通过管理员权限启动终端，通过 zerotier-cli.bat 命令行操作，Linux 平台通过 zerotier-cli 操作；peers 子命令查看连接、listpeers查看所有节点，能正常展示 moon 节点表示加入成功\n如何卸载 Windows平台如何卸载不再赘述，常规操作，通过控制面板卸载即可，我们重点说下ubuntu。\n通过dpkg删除zerotier-one服务 sudo dpkg -P zerotier-one 删除zerotier-one文件夹，该文件夹存储了address地址，删除后再次安装会获得新的address地址 sudo rm -rf /var/lib/zerotier-one/ 后记 原本都是已经卸载了，服务器到了，没有合适的服务作为代理节点，阿里云搞业绩，提供了开发特供服务器，配置不高，99一年，价格实惠，弄了两年。看中的就是服务器提供的带宽。\n参考资料 https://www.wnark.com/archives/152.html https://www.cnblogs.com/Yogile/p/12642423.html ","date":"2023-09-19T04:58:03+08:00","permalink":"https://ttf248.github.io/p/%E5%BC%82%E5%9C%B0%E5%B1%80%E5%9F%9F%E7%BD%91zerotier/","title":"异地局域网ZeroTier"},{"content":"vmware虚拟机安装开发系统的时候，一般都会多预留点磁盘空间，用的时间长了，本地占用的磁盘空间远超虚拟机实际文件的内容。\n场景描述 df -h命令，查看当前机器的磁盘信息，实际用了 60G，删掉所有的快照和克隆镜像，本地虚拟机占用的磁盘空间依旧远大于 60G，让本就不富裕的硬盘，雪上加霜。\n前置条件 虚拟机安装的时候，没有勾选预分配磁盘 本地存放虚拟机的硬盘，剩余的磁盘空间大于当前虚拟机所占用的空间 剩余的空间不足，可以考虑临时移动虚拟机到移动硬盘，优化了磁盘以后再迁移回来。\n工具 官方提供了open-vm-tools包，可以通过 yum 安装或者 vmware-tools 镜像包安装\n命令 vmware-toolbox-cmd disk shrink / 执行了以后，虚拟机会自动关机，vmware 宿主程序会执行磁盘压缩，执行时间取决于虚拟机的体积和磁盘的访问速度。\n执行效果还是很不错的，虚拟机的磁盘空间占用基本等于df -h的磁盘信息。\n","date":"2023-06-21T18:35:41+08:00","permalink":"https://ttf248.github.io/p/vmware-%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4%E4%BC%98%E5%8C%96/","title":"VMware 虚拟机磁盘空间优化"},{"content":"国内的资料，基本都在推荐秋叶大佬的一键部署包，想着都是基于Python的开源项目，部署也不会很复杂，试试从零开始。\n折腾AI生成图，特意更换了显卡，3060 12g入门版本；服役七年的960光荣下线\n核心的pytorch cuda安装，以前编写pyhton游戏辅助脚本时，本地安装过，没想到还是碰到坑，cuda加密一直无法激活。\n待处理 1.重新规划文章结构，先介绍 pytorch，版本的对应关系，如何查看版本 2.本地如何从零开始新建虚拟环境，部署 Pytorch 3.翻译稿子，从零开始 stable diffusion https://stable-diffusion-art.com/install-windows/ 4.整理参考资料\n步骤 用中文搜索可能找不到相关一步一步安装的教程。在Google里面你用英文去搜索，有很多类似的教程，就是从零开始。介绍了一下，我们需要安装git，然后又说明了一下，我们需要安装python。然后就是你去把仓库下载过来，直接双击脚本搞定了。\nhttps://github.com/AUTOMATIC1111/stable-diffusion-webui\n详细的使用和答疑，翻看issues，https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki\n我也不知道为什么就没人解释这个仓库是干嘛的。其实从名字也不难看出来，它是一个界面控制台，让我们用起来更方便。实际上在安装的时候，他会去下载官方的仓库内容，获取实际的SD代码。\n仓库呢同时也做了一个安装启动脚本。会自动识别当前文件夹，是否有Python虚拟环境。如果有的话默认使用当前路径的的python。\n如果是纯小白用户，建议看一下：https://stable-diffusion-art.com/install-windows/\npytorch https://pytorch.org/get-started/locally/\n这里才是我今天想说的，首先你不要听他们的步骤直接启动脚本。Python通过requirement文件去安装依赖库，这个都是小问题。核心就是你的显卡版本驱动的版本，需要和pytorch对应。这个呢，也有很多人介绍相应的关系，网上找一找就有了。\n参考：https://blog.csdn.net/weixin_40660408/article/details/129896700\n创建一个虚拟环境对，就是一个空的虚拟环境，你在里面直接先去官网执行脚本，把pytorch安装好了。\npython -c \u0026quot;import torch; print(torch.version.cuda)\u0026quot; python -c \u0026quot;import torch; print(torch.__version__, torch.cuda.is_available())\u0026quot; 上面两个脚本可以检查一下你需要安装的cuda版本，也能检查一下你安装是否成功了。\n这里不建议花里胡哨的操作，你先按照官方页面的逻辑复制过来，直接安装就好了，直接pip去安装，你的pytorch很有可能失败，或者没有激活cuda。\npip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 重点：文件夹的路径不要有乱七八糟的东西，不然很有可能导致pytorch无法使用。\n中间来来回回安装了很多次，也尝试了把官方的安装文件下载下来手动去安装。就是想着升级一下2.0的版本，因为官方的文档说2.0速度会快一些。但是之前用的不多，也不知道Python的版本和这个是不是有影响。中间呢也查看了官方的手册，说的是建议用3.8的版本。这里就产生了一个小冲突，之前用过一键安装部署包，它里面是3.10的版本。最后就是从零开始先新建文件夹，创建虚拟环境，确保torch已经安装成功了。\n然后把这个安装好的虚拟环境移动到web UI的文件夹里面。这个时候再去启动脚本安装，其他的依赖问题就不大了。\n移动后，需要执行：python -m pip install \u0026ndash;upgrade \u0026ndash;force-reinstall pip，修复一下 pip\n可能看起来挺莫名其妙的，但是这个地方折腾了挺久的。因为它一直无法正确的识别我torch。为了排除所有的干扰因素，才想到先安装它，再去安装其他的依赖库。\nXformers 建议开启，能加速图像生成和减少现存占用，副作用，同一组参数，生成的图像相对不是那么稳定\nstable-diffusion-webui:Xformers\nhuggingface optimization\nOptimization Ratio Time taken Torch active/reserved Sys VRAM 100.00% 2m 57.03s 7440/10058 MiB 12288/12288 MiB (100.0%) 51.02% 1m 29.21s 4547/7164 MiB 9298/12288 MiB (75.67%) ((masterpiece)),((best quality)),((high detial)),((realistic,)) Industrial age city, deep canyons in the middle,chinese architectural streets,bazaars, Bridges, (rainy days:1.2), (steampunk:0.8), chinese architecture Negative prompt: nsfw,((cowboy)),(((pubic))), ((((pubic_hair))))sketch, duplicate, ugly, huge eyes, text, logo, monochrome, worst face, (bad and mutated hands:1.3), (worst quality:2.0), (low quality:2.0), (blurry:2.0), horror, geometry, bad_prompt, (bad hands), (missing fingers), multiple limbs, bad anatomy, (interlocked fingers:1.2), Ugly Fingers, (extra digit and hands and fingers and legs and arms:1.4), crown braid, ((2girl)), (deformed fingers:1.2), (long fingers:1.2),succubus wings,horn,succubus horn,succubus hairstyle, (bad-artist-anime), bad-artist, bad hand, borrowed character, text focus, watermark, sample watermark, character watermark, lofter username, photo date watermark, movie poster, magazine cover, journal, cover, cover page, doujin cover, album cover, manga cover, brand name imitation, EasyNegative,Tights, silk stockings,shorts Steps: 35, Sampler: DPM adaptive, CFG scale: 5.5, Seed: 2223996555, Size: 1088x1088, Model hash: 543bcbc212, Model: base_Anything-V3.0-pruned, Clip skip: 2, ENSD: 31337 后记 为什么不是推荐那个一键部署包，因为他那个包里面，有部分设置是作者私人定制过的，和官方原模原样的是不一样的。如果你是初学者，你可能不知道为什么要设置那些参数最好的逻辑还是先用官方给的。随着你用的时间越来越长，多去看看官方的手册，你就知道哪些参数需要调整了。\n显卡的选择 数据货币矿难之后, 显卡的价格相对来说不是那么高了，普通的入门玩家，3060和3060ti之间抉择，一般都会推荐大显存12G版本的3060，毕竟能生成更大分辨率的图，为什么需要更大的分辨率，因为你可以在生成的时候，把分辨率调大，这样生成的图像就会更加清晰，更加细腻。如果你是想要生成一些小图，那么8G的显存也是够用的。\n还有一点，高清放大选项，具化细节，让画面细节更加丰富，也需要更多的显存。\n以下是NVIDIA GeForce GTX 970、GeForce RTX 3060 Ti、GeForce RTX 3060、GeForce RTX 3080和GeForce RTX 3080 Ti的单精度（FP32）、半精度（FP16）和双精度（FP64）浮点数计算能力的规格汇总表：\n显卡型号 发布年份 单精度浮点数计算能力（TFLOPS） 半精度浮点数计算能力（TFLOPS） 双精度浮点数计算能力（TFLOPS） GeForce GTX 970 2014 3.49 87.2 0.109 GeForce RTX 3060 Ti 2020 16.2 32.4 0.51 GeForce RTX 3060 2021 12.7 25.4 0.39 GeForce RTX 3080 2020 29.8 58.9 0.93 GeForce RTX 3080 Ti 2021 34.8 68.7 1.36 摘录来的，各种显卡性能测试数据\n更新 间隔半年，本来还想再梳理一下安装步骤，科普更多的基础概念，结果发现，普通人玩AI画图，真就是基于大佬给的图片参数，进行参数调整，或者基于已有的图片，进行格式化的重新渲染。\n中间有过项目，尝试用AI来绘制小程序的UI素材，结果折腾半天，效果都不如意，不如我直接从官方的小程序拉资源图片。\n","date":"2023-04-13T00:23:54+08:00","permalink":"https://ttf248.github.io/p/stable-diffusion-%E4%BB%8E%E9%9B%B6%E5%AE%89%E8%A3%85%E7%9A%84%E6%81%A9%E6%80%A8%E6%83%85%E4%BB%87/","title":"Stable-diffusion-从零安装的恩怨情仇"},{"content":"one loop thread，耗时已经在微秒层面，更换服务器，从最多积压六万数据包，到几乎没有积压\n在单线程循环处理数据的场景中，CPU的性能取决于主频、缓存大小、指令集架构等因素。一般来说，主频越高、缓存越大、指令集架构越先进的CPU在单线程处理数据时性能越好\n单线程 性能提升，增加线程不是分必要的，梳理项目流程，确定耗时的点，单线程是否能满足需求，单线程考虑的东西更少，也不容易出问题。\n上来就和就说加线程，多少有点毛病\n事件 处理的都是行情数据，延迟敏感\n吭哧吭哧加班一晚上，发布新的优化版本，本地剥离接口进行测试，速度也还行，tps：4.2万\n部署到服务器，tps骤降：2.1万，回家尝试台式机，tps：7.9万，开始怀疑组内服务虚拟机多少有点问题，首先怀疑主频导致的，家用台式机和服务器CPU，差异最大的地方就是主频\n测试服务器A\nprocessor\t: 7 vendor_id\t: GenuineIntel cpu family\t: 6 model\t: 47 model name\t: Intel(R) Xeon(R) CPU E7- 4807 @ 1.87GHz stepping\t: 2 microcode\t: 0x34 cpu MHz\t: 1866.733 cache size\t: 18432 KB physical id\t: 1 siblings\t: 4 core id\t: 3 cpu cores\t: 4 apicid\t: 7 initial apicid\t: 7 fpu\t: yes fpu_exception\t: yes cpuid level\t: 11 wp\t: yes flags\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss ht syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 cx16 sse4_1 sse4_2 popcnt aes hypervisor lahf_lm pti dtherm arat bugs\t: clflush_monitor cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit bogomips\t: 3733.46 clflush size\t: 64 cache_alignment\t: 64 address sizes\t: 40 bits physical, 48 bits virtual power management: 测试服务器B\nprocessor\t: 7 vendor_id\t: GenuineIntel cpu family\t: 6 model\t: 63 model name\t: Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz stepping\t: 2 microcode\t: 0x3c cpu MHz\t: 2599.998 cache size\t: 20480 KB physical id\t: 14 siblings\t: 1 core id\t: 0 cpu cores\t: 1 apicid\t: 14 initial apicid\t: 14 fpu\t: yes fpu_exception\t: yes cpuid level\t: 15 wp\t: yes flags\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cpuid_fault epb pti fsgsbase smep xsaveopt cqm_llc cqm_occup_llc dtherm ida arat pln pts bugs\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit bogomips\t: 5199.99 clflush size\t: 64 cache_alignment\t: 64 address sizes\t: 40 bits physical, 48 bits virtual power management: 咨询 OpenAI 首先是核心数和主频方面，Intel(R) Xeon(R) CPU E7- 4807 @ 1.87GHz拥有6个物理核心和12个逻辑核心，主频为1.87GHz；而Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz拥有8个物理核心和16个逻辑核心，主频为2.60GHz。因此，从核心数和主频方面来看，E5-2640 v3在单线程处理数据时应该比E7- 4807更具优势。\n其次是缓存大小方面，E7- 4807的缓存大小为12MB，而E5-2640 v3的缓存大小为20MB。因此，E5-2640 v3拥有更大的缓存空间，可以提高数据的访问速度和缓存命中率。\n最后是架构方面，E5-2640 v3采用了更先进的Haswell架构，而E7- 4807采用的是旧的Nehalem架构。Haswell架构相对于Nehalem架构在性能方面有所提升，这也可能对E5-2640 v3在单线程处理数据时的性能提升产生影响。\n因此，综合考虑，在单线程循环处理数据的场景中，E5-2640 v3应该比E7- 4807具有更好的性能。但是，具体的性能差异会受到多种因素的影响，包括数据处理的算法、内存带宽、系统负载等等，需要具体问题具体分析。\n硬件资料 https://www.cpubenchmark.net/compare/3786.2vs2365.2/%5BDual-CPU%5D-Intel-Xeon-E7–4807-vs-%5BDual-CPU%5D-Intel-Xeon-E5-2640-v3\nSpecification Xeon E7-4807 (LGA1567) Xeon E5-2640 v3 (LGA2011-v3) Price Search Online $78 - BUY Socket Type LGA1567 LGA2011-v3 CPU Class Server Server Clockspeed 1.9 GHz 2.6 GHz Turbo Speed Not Supported Up to 3.4 GHz # of Physical Cores 6 (Threads: 12) 8 (Threads: 16) Cache NA2 NA2 Max TDP 95W x 2 90W x 2 Yearly Running Cost $34.68 $32.85 Other First Seen on Chart Q3 2020 Q3 2014 # of Samples 1 46 CPU Value 69.1 225.6 Single Thread Rating 721 (-59.2%) 1767 (0.0%) CPU Mark 6223 (-64.6%) 17600 (0.0%) ","date":"2023-04-07T16:30:15+08:00","permalink":"https://ttf248.github.io/p/%E7%A8%8B%E5%BA%8F%E4%BC%98%E5%8C%96%E4%B8%8D%E8%A6%81%E8%AF%95%E5%9B%BE%E5%AF%B9%E6%8A%97%E7%A1%AC%E4%BB%B6/","title":"程序优化不要试图对抗硬件"},{"content":"就如当年学习搜索引擎的技巧，我们也需要学习一些和AI沟通的技巧，给出合理且充分的限定条件，高效的获取需要的答案。\n如果你换个角度呢，当前的AI属于一个记忆力很好的小孩子，它拥有过目不忘的能力，有抄作业的能力。我们需要做的是学会如何正确、有效的和AI沟通，精准的描述需求，帮助AI生成预期的结果。\n科普 火出天际的AI确切的说Generative Pre-Training，直译过来就是生成式的预训练。它是一种基于互联网可用数据训练的文本生成深度学习模型，用于问答、文本摘要生成、机器翻译、分类、代码生成和对话 AI 等任务。目前已经有 GPT-1、GPT-2、GPT-3 和 GPT-4 等不同版本的模型，每个版本都比前一个版本更大、更强大。\n到底有没有智能 相似度足够高，准确率也就越高 基础的、重复性的工作，进过特定训练，不再需要人工的介入 生成式AI是一种利用现有的文本、音频、图像等数据来创建新内容的技术。它可以用于文本生成、语音合成、图像生成、对话系统等多种任务。生成式AI的逻辑性取决于它的训练数据和模型结构。一般来说，生成式AI可以在一定程度上遵循语法、逻辑和常识，但也可能出现错误、偏差或不真实的内容。因此，生成式AI的输出需要人类的判断和验证，不能盲目相信或使用。\nPrompt 工程师 时间河流不会逆流，人需要学会适应潮流。你可以认为AI不智能，没有逻辑性，它经常写出来不能用的代码。\n如果你换个角度呢，当前的AI属于一个记忆力很好的小孩子，它拥有过目不忘的能力，有抄作业的能力。我们需要做的是学会如何正确、有效的和AI沟通，精准的描述需求，帮助AI生成预期的结果。\n对话模式 两年前Github Copilot发布，谁也想不到两年后，OpenAI横空出世，让人类认知到了大语言模型的能力。\n基于基于注释的编程和基于对话的编程，交互逻辑上完全不同，对话的模式，小白用户的交互体验友好，此处必须提到NewBing在每个问题之后，给出的追问提示，微软在尝试引导用户，获取AI知识库里面，更多的内容。\n举个栗子 场景：高铁旅途时间漫漫，编码是个不错的选择。流量有限的情况下，处理几个图片，获取了图片素材，下载软件处理图片稍微有点奢侈，网络条件也不允许。\n需求：有一批图片素材，带透明背景图，用来作为小程序的导航栏，选中的状态是彩色的，没选中的状态是黑白的，素材都是彩色的，需要预处理一下。\nPrompt：编写一段 python 代码，从一个文件夹中读取所有的图片，将图片转换成黑白，维持透明背景，保存图片的时候，优化图片的质量，减少文件体积，同时在控制台展示，优化前后的文件体积大小对比\n# 导入必要的库 import os import PIL from PIL import Image # 定义一个函数，将图片转换成黑白，维持透明背景，保存图片，并返回文件体积 def convert_and_save(image_file): # 打开图片 image = Image.open(image_file) # 获取图片的模式，如果是 RGBA 模式，说明有透明背景 mode = image.mode if mode == \u0026quot;RGBA\u0026quot;: # 创建一个和图片大小一致的白色背景图片 background = Image.new(\u0026quot;RGB\u0026quot;, image.size, (255, 255, 255)) # 将原图片粘贴到白色背景上，忽略透明像素 background.paste(image, mask=image.split()[3]) # 将合成的图片转换成灰度模式 gray_image = background.convert(\u0026quot;L\u0026quot;) # 将灰度图片再转换成 RGBA 模式，以便保留透明背景 final_image = gray_image.convert(\u0026quot;RGBA\u0026quot;) else: # 如果不是 RGBA 模式，直接将图片转换成灰度模式 final_image = image.convert(\u0026quot;L\u0026quot;) # 获取原图片的文件名和扩展名 file_name, file_ext = os.path.splitext(image_file) # 定义新图片的文件名，添加 _bw 后缀表示黑白 new_file_name = file_name + \u0026quot;_bw\u0026quot; + file_ext # 保存新图片，并优化质量，减少文件体积 final_image.save(new_file_name, optimize=True) # 获取原图片和新图片的文件体积，并返回 old_size = os.path.getsize(image_file) new_size = os.path.getsize(new_file_name) return old_size, new_size # 定义一个文件夹路径，存放所有的图片 folder_path = \u0026quot;images\u0026quot; # 遍历文件夹中的所有文件 for file in os.listdir(folder_path): # 拼接完整的文件路径 file_path = os.path.join(folder_path, file) # 判断是否是图片文件，根据扩展名判断，可以根据需要添加或修改扩展名 if file_path.endswith((\u0026quot;.png\u0026quot;, \u0026quot;.jpg\u0026quot;, \u0026quot;.jpeg\u0026quot;, \u0026quot;.gif\u0026quot;)): # 调用函数，转换并保存图片，并获取文件体积 old_size, new_size = convert_and_save(file_path) # 在控制台展示优化前后的文件体积大小对比 print(f\u0026quot;{file}: {old_size} bytes -\u0026gt; {new_size} bytes\u0026quot;) AI迅速给出了答案，看着很漂亮，用起来也没问题，经验丰富的程序源，会觉得下面的代码不够通用，也没法上生产环境：\n参数固定了 没有日志文件，信息都打印在控制台 图片处理的任务，适合多线程模型 NewBing登场，依据提示，选择了一个问题：这段代码有什么可以改进的地方吗\n这次给的答案，实话，完全超出了预期，一般程序员能想到的优化措施，AI都给出对应的建议\n这段代码可能还有一些可以改进的地方，比如： 可以使用 argparse 库，让用户可以通过命令行参数指定文件夹路径和扩展名，而不是写死在代码里。 可以使用 logging 库，记录程序的运行情况，而不是直接打印到控制台。 可以使用 try-except 语句，捕获可能出现的异常，比如文件打开失败，图片转换失败等，并做相应的处理。 可以使用 multiprocessing 库，利用多核处理器，加速图片的转换和保存过程。 很友好的应答，考虑到部署的环境存在差异，允许不支持多进程\n当然，我很乐意帮你修改一下代码。我尝试添加了 argparse, logging 和 try-except 语句，但没有添加 multiprocessing 库，因为我不确定你的电脑是否支持多核处理。修改后的代码如下： # 导入必要的库 import argparse import logging import multiprocessing import os from PIL import Image # 定义一个函数，将图片转换成黑白，维持透明背景，保存图片，并返回文件体积 def convert_and_save(image_file): # 打开图片 try: image = Image.open(image_file) except Exception as e: logging.error(f\u0026quot;Failed to open {image_file}: {e}\u0026quot;) return None, None # 获取图片的模式，如果是 RGBA 模式，说明有透明背景 mode = image.mode if mode == \u0026quot;RGBA\u0026quot;: # 创建一个和图片大小一致的白色背景图片 background = Image.new(\u0026quot;RGB\u0026quot;, image.size, (255, 255, 255)) # 将原图片粘贴到白色背景上，忽略透明像素 background.paste(image, mask=image.split()[3]) # 将合成的图片转换成灰度模式 gray_image = background.convert(\u0026quot;L\u0026quot;) # 将灰度图片再转换成 RGBA 模式，以便保留透明背景 final_image = gray_image.convert(\u0026quot;RGBA\u0026quot;) else: # 如果不是 RGBA 模式，直接将图片转换成灰度模式 final_image = image.convert(\u0026quot;L\u0026quot;) # 获取原图片的文件名和扩展名 file_name, file_ext = os.path.splitext(image_file) # 定义新图片的文件名，添加 _bw 后缀表示黑白 new_file_name = file_name + \u0026quot;_bw\u0026quot; + file_ext # 保存新图片，并优化质量，减少文件体积 try: final_image.save(new_file_name, optimize=True) except Exception as e: logging.error(f\u0026quot;Failed to save {new_file_name}: {e}\u0026quot;) return None, None # 获取原图片和新图片的文件体积，并返回 old_size = os.path.getsize(image_file) new_size = os.path.getsize(new_file_name) return file_name, old_size, new_size # 定义一个函数，解析命令行参数，并返回文件夹路径和扩展名列表 def parse_args(): # 创建一个解析器对象 parser = argparse.ArgumentParser(description=\u0026quot;Convert images to black and white and optimize quality.\u0026quot;) # 添加一个必选的位置参数，表示文件夹路径 parser.add_argument(\u0026quot;folder_path\u0026quot;, help=\u0026quot;The path of the folder that contains the images.\u0026quot;) # 添加一个可选的参数，表示扩展名列表，默认为 png, jpg, jpeg 和 gif parser.add_argument(\u0026quot;-e\u0026quot;, \u0026quot;--extensions\u0026quot;, nargs=\u0026quot;+\u0026quot;, default=[\u0026quot;.png\u0026quot;, \u0026quot;.jpg\u0026quot;, \u0026quot;.jpeg\u0026quot;, \u0026quot;.gif\u0026quot;], help=\u0026quot;The extensions of the image files.\u0026quot;) # 解析命令行参数，并返回结果对象 args = parser.parse_args() return args.folder_path, args.extensions # 定义一个函数，打印优化前后的文件体积大小对比 def print_result(result): # 如果结果不为空，说明转换和保存成功 if result: # 解包结果为文件名和文件体积元组 if len(result) == 3: file, old_size, new_size = result # 在控制台展示优化前后的文件体积大小对比 logging.info(f\u0026quot;{file}: {old_size} bytes -\u0026gt; {new_size} bytes\u0026quot;) else: logging.info(f\u0026quot;{result}\u0026quot;) # 配置日志记录器，将日志输出到控制台和文件中，设置日志等级为 INFO logging.basicConfig(level=logging.INFO, format=\u0026quot;%(asctime)s %(levelname)s %(message)s\u0026quot;, handlers=[logging.StreamHandler(), logging.FileHandler(\u0026quot;log.txt\u0026quot;)]) # 调用函数，获取文件夹路径和扩展名列表 folder_path, extensions = parse_args() if __name__ == \u0026quot;__main__\u0026quot;: # Windows 需要这个函数的原因是 Windows 缺乏 fork() 函数（这不完全正确）。 # 因此，在 Windows 上，fork() 是通过创建一个新的进程来模拟的，这个新的进程中运行的代码，在 Linux 上是在子进程中运行的。 # 由于这些代码要在技术上无关的进程中运行，所以它必须在运行之前被传递到那里。 # 传递的方式是先将它们序列化，然后通过管道从原始进程发送到新的进程。 # 另外，这个新的进程被通知它必须运行通过管道传递的代码，通过向它传递 --multiprocessing-fork 命令行参数。 # 如果你看一下 freeze_support() 函数的实现，它的任务是检查它运行在哪个进程中，是否应该运行通过管道传递的代码 multiprocessing.freeze_support() # 创建一个进程池，根据电脑的核心数自动分配进程 pool = multiprocessing.Pool() # 创建一个空列表，用于存放异步任务的结果对象 results = [] # 遍历文件夹中的所有文件 for file in os.listdir(folder_path): # 拼接完整的文件路径 file_path = os.path.join(folder_path, file) # 判断是否是图片文件，根据扩展名判断，可以根据需要修改扩展名列表 if any(file_path.endswith(ext) for ext in extensions): # 调用函数，转换并保存图片，并获取文件体积，使用异步方式，不阻塞主进程 result = pool.apply_async(convert_and_save, args=(file_path,), callback=print_result) # 将结果对象添加到列表中 results.append((file, result)) # 关闭进程池，不再接受新的任务 pool.close() # 等待所有的任务完成 pool.join() 后记 由于本地开发是windows系统，AI第一次给出的答案，并没有加上main函数，也没有multiprocessing.freeze_support。通过追问发生的报错，修复了代码。\n就如当年学习搜索引擎的技巧，我们也需要学习一些和AI沟通的技巧，给出合理且充分的限定条件，高效的获取需要的答案。\n注意：如果你是个编程新手，基于给出的注释，还有看不懂的地方，可以继续追问相关代码\n","date":"2023-03-26T20:46:53+08:00","permalink":"https://ttf248.github.io/p/prompt-%E5%B7%A5%E7%A8%8B%E5%B8%88/","title":"Prompt 工程师"},{"content":"微信小程序介绍与开发准备\n为什么会有小程序 更好的体验：内嵌网页加载缓慢、白屏；原生应用的体验，更快速的加载 规范与管理：对于微信来说，接入和管理 在小程序发布之前，微信发布过一个SDK叫做JSSDK，开放部分的微信原生能力：微信支付、卡券。但是开发者基于网页开发语言的逻辑来进行开发，能绕过微信的一些监管。小程序有一套自己的描述语言。\n什么是小程序 小程序是一种不需要下载安装即可使用的应用，它实现了应用触手可及的梦想\n用户扫一扫或者搜一下即可打开应用，也体现了用完即走的理念\n用户不用关系是否安装太多应用的问题。应用将无处不在，随时可用，但又无需安装卸载\n小程序和移动应用的区别 无需安装、不占内存、易传播：扫码、小程序卡片、搜一搜\n小程序能做什么 内容工具：知乎热榜、微博热门、摩拜单车、今日头条、腾讯地图、腾讯翻译 零售：拼多多、京东购物、蘑菇街、每日优鲜、小米商城、屈臣氏 游戏：跳一跳、欢乐斗地主、欢乐麻将、斗鱼直播、YY直播 课程内容2018年的，到了现在，部分应用厂商已经倒闭了\n开发准备 注册小程序账号：正常填写信息即可注册，邮箱点击激活链接 信息登记 登录小程序管理后台 完善小程序信息 绑定开发者：个人开发者，登录的微信号为管理员账号，无需额外的绑定操作 邮箱有一定的限制，需要一个新的邮箱，但是QQ邮箱能申请别名，微信后台并不会校验。尝试过后，小程序的名字比较麻烦，但凡涉及到了商标，就容易审核失败。\n服务类目可以选择，也能自定义添加，一个小程序能添加五个类目。\n设置里面能查看小程序的ID信息，也能开启消息推送，启用了消息推送就能使用消息模板功能。\n开发者工具（笔者自述） 正常下载安装，没什么特殊注意事项，简单了解，直接游客模式进入，如果想启用手机调试，也就是手机查看小程序的开发版本，需要登录小程序的开发者账号，然后点击设置，在项目详情里面切换到指定的小程序ID\n代码结构 js: 交互逻辑 json：数据配置 wxml：界面的元素 wxss：界面的样式 ","date":"2023-03-24T21:59:11+08:00","permalink":"https://ttf248.github.io/p/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%83%8C%E6%99%AF%E5%92%8C%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/","title":"微信小程序背景和开发环境"},{"content":"行政通知，办公位变动，从原本的二楼，迁移到十五楼，普普通通的一次工位迁移\n设计感 迁徙 收市打包、轻车熟路，新的工位，调整电脑布线，舒服的姿势开始工作\n(ÒωÓױ)！，接上网线，组里常用的服务器，不能访问了，试着切换无线网络，访问又正常了\n起初呢以为是服务器网段设置问题，新的工位的有线网络，不在防火墙配置的名单里面，联系IT同事调整下就好了；这个网段呢，不止一台服务器，试着访问其他服务器，都是正常的，逐渐产生疑惑？专业的事情交给专业的人来处理，最后运维部门的同事定位到，由于这台服务器部署了docker，服务的默认网络docker0和办公室有线网络配置的网段冲突了，导致发过去的数据包，都收不到应答，被路由给了docker服务。\n其他服务器都没部署docker服务，也就这台，我比较常用，偶尔用容器部署一些测试服务，没想到还能碰到这个场景。后来细想想，由于整个集团都在一个办公大楼里面，IT部门的同事划分网段，用到了172打头的地址也不奇怪。\ndocker0 # vim /etc/docker/daemon.json { \u0026quot;bip\u0026quot;:\u0026quot;172.200.0.1/24\u0026quot; } 重启下服务，切换到新的网络，服务器恢复正常访问。\n参考资料 Docker从入门到实践-docker0\n","date":"2023-03-11T01:42:05+08:00","permalink":"https://ttf248.github.io/p/%E5%8A%9E%E5%85%AC%E5%AE%A4%E8%BF%81%E7%A7%BB%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%97%A0%E6%B3%95%E8%AE%BF%E9%97%AE%E4%BA%86/","title":"办公室迁移，服务器无法访问了"},{"content":"提到嵌入式，脑海里还是当年学校实验室的51单片机和飞思卡尔。\nLPA3399Pro 是一款基于瑞芯微RK3399Pro平台开发的视觉主机，针对需要大量视觉运算场景的便携式运算主机。它内置NPU计算单元，具有3.0TOPS算力，支持多种算法模型。\nRV1109 是瑞芯微人工智能下机器视觉分支的SoC，内置独立NPU。 RV1109可提供1TOPS算力。\nSystem on Chip SoC 是 System on a Chip 的缩写，意为“片上系统”。它是一种将多个电子系统集成到一个芯片上的技术。这种技术可以大大减小电子产品的体积和重量，同时提高性能和降低功耗。\nSoC（System on a Chip）和 CPU（Central Processing Unit）都是计算机系统中的重要组成部分，但它们之间有一些区别。\nCPU 是计算机系统中的核心处理器，负责执行程序指令。它通常只包含运算单元、控制单元和寄存器等基本部件。\nSoC 则是将多个电子系统集成到一个芯片上，除了包含 CPU 外，还可以集成其他组件，如内存、图形处理器、输入/输出接口等。这样可以大大减小电子产品的体积和重量，同时提高性能和降低功耗。\n总之，CPU 是 SoC 的一个组成部分，而 SoC 则是一个更为复杂、集成度更高的电子系统。\nMicrocontroller Unit SoC（System on a Chip）和 MCU（Microcontroller Unit）都是将多个电子系统集成到一个芯片上的技术，但它们之间也有一些区别。\nMCU 是一种微控制器，通常包含一个 CPU、内存、输入/输出接口等基本部件。它通常用于控制其他电子设备，如家用电器、汽车电子系统等。\nSoC 则是将更多的电子系统集成到一个芯片上，除了包含 MCU 的基本部件外，还可以集成其他组件，如图形处理器、无线通信模块等。这样可以大大减小电子产品的体积和重量，同时提高性能和降低功耗。\n总之，MCU 是一种简单的微控制器，而 SoC 则是一个更为复杂、集成度更高的电子系统。\n","date":"2023-03-07T13:42:36+08:00","permalink":"https://ttf248.github.io/p/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%85%A5%E9%97%A8%E7%AF%871-%E4%B8%93%E4%B8%9A%E5%90%8D%E8%AF%8D/","title":"嵌入式入门篇1-专业名词"},{"content":"GitHub Copilot 发布也不到两年时间，ChatGPT 问世了，不是很懂背后的原理，都用了一段时间。两个工具的辅助层面完全不同，但是都做到了大幅提高生产力。\n太复杂的事情，AI还做不到，毕竟他们没有逻辑，有套路的或者说范式固定的事情，训练的语料足够，AI的效果能打个九分。\ngithub copilot 发布的时候，看着官网的介绍demo，不是很智能，试用了一下，不是很好用，放弃了。\n2022年前，闲来无事，切换到新版本体验一下，效果已经不错了，就是国内的速度有点慢，大概率是网络的原因。Python之类的语言，依据注释写出来的代码都还不错，比我自己查资料然后编写的速度快了很多。\nChatGPT Github Copilot还停留在程序员，也就是开发的角度来设计产品，你需要懂的如何编程，慢慢的通过注释来引导AI辅助编程。\nChatGPT 走到了下一个层面，让外行人也能迅速上手。对话聊天交互式的设计，你完全可以提出问题，描述需求，不懂的地方，继续提问。\n简单来个例子，知道分词的概念，但是不知道如何编码，想要计算字符串的相似度：\nPython 分词计算 維天運通 LOGORY 和 合肥維天運通信息科技股份有限公司 两个字符串的相似度； 比较前，统一处理字符串，英文转换为小写； 第二个字符中如果能找到第一个字符的首字符，将第二个字符串截位，截位的长度为第一个字符串的长度 你好，这是Bing。😊\n根据网上的信息123，Python 分词计算可以使用 jieba 库来实现。jieba 库支持三种分词模式：精确模式、全模式和搜索引擎模式。你可以根据你的需求选择合适的模式。\n为了比较两个字符串的相似度，你需要先对它们进行分词，然后计算它们的词向量或者编辑距离等指标。你可以使用 numpy 或者 scipy 等库来进行数学运算。\n为了统一处理字符串，英文转换为小写，你可以使用 Python 的内置函数 lower() 来实现。\n为了截取第二个字符串，你可以使用 Python 的切片操作符 [ ] 来实现。\n以下是一个可能的代码示例：\nimport jieba import numpy as np from scipy.spatial.distance import cosine # 定义两个字符串 str1 = \u0026quot;維天運通 LOGORY\u0026quot; str2 = \u0026quot;合肥維天運通信息科技股份有限公司\u0026quot; # 统一处理字符串，英文转换为小写 str1 = str1.lower() str2 = str2.lower() # 找到第二个字符串中第一个字符的位置 index = str2.find(str1[0]) # 如果找到了，截取第二个字符串 if index != -1: str2 = str2[index:index+len(str1)] # 使用 jieba 库进行分词 words1 = list(jieba.cut(str1)) words2 = list(jieba.cut(str2)) # 计算两个字符串的词向量（以词频作为权重） vector1 = np.zeros(len(words1)) vector2 = np.zeros(len(words1)) for i, word in enumerate(words1): vector1[i] += 1 # 统计第一个字符串中每个词出现的次数 if word in words2: vector2[i] += 1 # 统计第二个字符串中每个词出现的次数 # 计算两个字符串的相似度（以余弦距离作为指标） similarity = 1 - cosine(vector1, vector2) print(\u0026quot;两个字符串的相似度是：\u0026quot;, similarity) 更进一步，咨询运行的结果，恭喜你，发现问题了，结果是瞎编的，它并没有实际运行代码，但是会给你一个不错的结果\n栗子 提问：sql 语句，查出产品代码表中，产品代码在这个区间 80000-89999 的记录\n你好，这是 Bing。😊 根据搜索结果12，你可以使用 SQL BETWEEN 运算符来选择给定区间内的值。BETWEEN 运算符包含了开始和结束的值。 你需要先指定要查询的表名和列名，然后在 WHERE 子句中使用 BETWEEN 运算符和区间值。 例如，如果你要查询产品代码表中，产品代码在 80000 到 89999 之间的记录，你可以使用以下语句： SELECT * FROM product_code WHERE code BETWEEN 80000 AND 89999; 这里，* 表示选择所有列3。如果你只想选择特定的列，比如产品名称和价格，你可以用逗号分隔它们，如下： SELECT name, price FROM product_code WHERE code BETWEEN 80000 AND 89999; 希望这能帮助到你。 继续提问，否定它：产品代码是字符串，你的代码错了\n抱歉，我没有注意到产品代码是字符串。如果是这样的话，你需要在区间值两边加上单引号，如下： SELECT * FROM product_code WHERE code BETWEEN '80000' AND '89999'; 请原谅我的错误。🙏 恭喜你，它会认错的。\n","date":"2023-02-28T17:05:17+08:00","permalink":"https://ttf248.github.io/p/ai%E8%BE%85%E5%8A%A9%E7%BC%96%E7%A8%8B%E7%94%9F%E4%BA%A7%E5%8A%9B%E7%9A%84%E8%BF%9B%E5%8C%96/","title":"AI辅助编程，生产力的进化"},{"content":"不常用，但是很有用的git命令\n重装系统导致windows上文件夹所有者信息变更 新版本git增加了安全性校验，提示不安全，导致无法继续操作\ngit config --global --add safe.directory git config --global --add safe.directory \u0026quot;*\u0026quot; 新电脑保存账号密码信息 git config --global credential.helper store 如果保存的信息需要更新，先清理老的凭证\ngit config --system --unset credential.helper ","date":"2023-02-17T10:08:57+08:00","permalink":"https://ttf248.github.io/p/%E5%87%A0%E4%B8%AA%E4%B8%8D%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB/","title":"几个不常用GIT命令汇总"},{"content":"港交所12月13日宣布，旗下证券市场即将推出“港币-人民币双柜台模式”(以下称“双柜台模式”)及双柜台庄家机制，进一步支持人民币柜台在香港上市、交易及结算。\n双柜台模式及双柜台庄家机制 港交所称，待监管机构批准及市场准备就绪后，各项新措施的登记程序预计可于2023年上半年开始推行。在双柜台模式下，港交所将优化相关交易及结算安排，让投资者可以互换同一个发行人发行的港币柜台及人民币柜台证券。\n为提升人民币柜台的流动性及收窄两个柜台之间的价差，香港交易所将引入双柜台庄家机制，待相关法例经立法会通过后，从事流通量供应活动的市场庄家在进行特定交易时可以豁免印花税。与此同时，各项新措施也将为后续内地投资者通过港股通交易以人民币定价的证券做好前期准备工作。\n“推出港币-人民币双柜台模式及双柜台庄家机制是我们市场发展的重要举措。配合我们的其他市场举措，这一安排将有助吸引更多双柜台证券在香港上市，与港交所现有的内地产品发挥良好的协同效应。港交所致力于积极推动人民币国际化进程和不断提升香港作为全球领先离岸人民币中心的地位。”香港交易所首席营运总监及市场联席主管姚嘉仁表示。\n据悉，港股现行的上市、交易、结算及交收安排亦将大致适用于双柜台模式下的人民币柜台证券。港交所将适时公布双柜台模式的实施日期以及符合纳入庄家机制的合资格双柜台证券名单。\n如何识别港币-人民币交易柜台 港交所文件显示，港币-人民币双柜台交易安排将大致遵循现有股票代码分配计划，即港币柜台的股票代码以“0”开始的5位数字，而人民币柜台的股票代码以“8”开始的5位数字。港币及人民币柜台股票代码的最后四位数将相同。人民币柜台的股票简称将后缀“-R”。\n交易安排方面，在人民币及港币柜台的证券为相同类别且可互相转换的基础上，若其中一个柜台（如港币柜台）是可以进行卖空的指定证券，另一个柜台（如人民币柜台）也可以按照交易所规则被纳入为可进行卖空的指定证券，相应地，两个柜台均会在交易所公布的可进行卖空的指定证券名单中。\n鉴于两个柜台的股票属于同一类别，且可相互转换，购买或以港币持有该股票，以人民币卖出都将被视为持货沽售，反之亦然。两个柜台之间的结算时间是T+2。\n对于符合卖空资格的指定股票，比如以港币借入股票，随后在人民币柜台卖出，将被视为有担保的卖空，反之亦然。\n值得一提的是，在双柜台模式下，由于人民币柜台仅供交易及结算，故不会向人民币柜台提供实物股票存入或提取服务，实物股票只可存入港币柜台之后再转换至人民币柜台。同样，人民币柜台需转换至港币柜台之后才可以提取实物股票。\n相关交易结算及交收的费用，所有香港结算费用，除代收股息服务费及代收利息服务费之外，都以港元计算及收取。代收股息服务费及代收利息服务费是以有关证券所采用的合资格货币计算。\n参考资料 HKD-RMB-Dual-Counter-Model 来源：香港交易所脈搏/HKEx Pulse、券商中国\n","date":"2023-02-16T20:25:47+08:00","permalink":"https://ttf248.github.io/p/%E6%B8%AF%E5%B8%81%E4%BA%BA%E6%B0%91%E5%B8%81%E5%8F%8C%E6%9F%9C%E5%8F%B0%E6%A8%A1%E5%BC%8F/","title":"港币、人民币双柜台模式"},{"content":"去年设计了一个SDK，负责处理封装一些事件，对外提供一个类接口，服务初始化的时候，调用方实现对应的类，并将对象指针传给模块。 接触过C11，好奇心害死猫，就想着这些接口都用lambda函数对象回调来实现会是什么结果，和纯虚函数的接口定义方法比较，更加灵活。 疑问就出现了，两种不同的语法，从性能角度来说，哪个更快一些？不懂编译原理，弄段代码试试看。\n前言 在线网址，能选择不同编译器，编译参数，在linux平台运行代码，亦或者查看对应的汇编代码。\nhttps://wandbox.org/：有时候做些技术验证，网页执行小片段的代码很省事 https://godbolt.org/：用不同的颜色，区分不同的汇编对应的代码，比本地的调试器看起来更加省事。 正文 标准委员会制定了语法的规则，在编译层面，如何实现，取决于各家的编译器，这里不得不说一声，微软的编译器，挺厉害的。语法糖不是万能的，回调接口不多，使用lambda更加便捷，也无需定义空回调函数接口；回调接口种类繁多的时候，传统的虚函数更有利于业务接口定义的统一。\nwindows平台，两者性能接近，没有太多的差异 linux平台，虚函数和lambda比较，单次多了1.35ns 常规的业务系统开发中，此级别的性能损耗可以忽略，引入lambda，在设计的上，能带来更多的便捷。在设计多信号处理时，尤为明显，底层有事件触发，如果需要落地日志，出入日志对象的的处理函数。当需要更多的业务处理接口时，底层用vector保存lambda对象，事件触发时，依次遍历调用，类似于QT中的信号和槽，日志、监控、业务1、业务2，互相之间完全解耦。\n代码 Counter: 1000000 Time: 3966us Counter: 1000000 Time: 5316us #include \u0026lt;iostream\u0026gt; #include \u0026lt;chrono\u0026gt; #include \u0026lt;memory\u0026gt; #include \u0026lt;functional\u0026gt; #include \u0026lt;atomic\u0026gt; #include \u0026lt;string\u0026gt; std::atomic_int64_t counter = 0; // 定义回调接口 class UserInterface { public: virtual void name() = 0; virtual void full_name() = 0; }; class User : public UserInterface { public: void name() {} void full_name() { counter++; } }; void to_string(UserInterface* user) { user-\u0026gt;name(); user-\u0026gt;full_name(); } using name_handler = std::function\u0026lt;void()\u0026gt;; using full_name_handler = std::function\u0026lt;void()\u0026gt;; class Test { name_handler name_; full_name_handler full_name_; public: void set_name_handler(name_handler name) { name_ = name; } void set_full_name_handler(full_name_handler full_name) { full_name_ = full_name; } void to_string() { name_(); full_name_(); } }; int main() { User user; auto start = std::chrono::high_resolution_clock::now(); for (int i = 0; i \u0026lt; 1000000; i++) { to_string(\u0026amp;user); } auto end = std::chrono::high_resolution_clock::now(); std::cout \u0026lt;\u0026lt; \u0026quot;Counter: \u0026quot; \u0026lt;\u0026lt; counter \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026quot;Time: \u0026quot; \u0026lt;\u0026lt; std::chrono::duration_cast\u0026lt;std::chrono::microseconds\u0026gt;(end - start).count() \u0026lt;\u0026lt; \u0026quot;us\u0026quot; \u0026lt;\u0026lt; std::endl; counter = 0; auto name = []() {}; auto full_name = []() { counter++; }; Test test; test.set_name_handler(name); test.set_full_name_handler(full_name); start = std::chrono::high_resolution_clock::now(); for (int i = 0; i \u0026lt; 1000000; i++) { test.to_string(); } end = std::chrono::high_resolution_clock::now(); std::cout \u0026lt;\u0026lt; \u0026quot;Counter: \u0026quot; \u0026lt;\u0026lt; counter \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026quot;Time: \u0026quot; \u0026lt;\u0026lt; std::chrono::duration_cast\u0026lt;std::chrono::microseconds\u0026gt;(end - start).count() \u0026lt;\u0026lt; \u0026quot;us\u0026quot; \u0026lt;\u0026lt; std::endl; return 0; } 后记 查找资料的时候，翻到类似的代码片段 functionperformance.cpp\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;chrono\u0026gt; #include \u0026lt;memory\u0026gt; #include \u0026lt;functional\u0026gt; using namespace std; using namespace std::chrono; class Base { public: Base(){} virtual ~Base(){} virtual int func(int i) = 0; }; class Derived : public Base { public: Derived(int base = 10) : base{base} { } ~Derived(){} virtual int func(int i) { return i*base; } private: int base; }; struct Func { int base; int operator()(int i) { return i*base; } Func(int base) : base {base} { } }; const int base = 10; int calculate(int i) { return base*i; } int main() { const int num = 10000; Base *p = new Derived{10}; int total = 0; auto start = high_resolution_clock::now(); for (int i = 0; i \u0026lt; num; ++i) { total += p-\u0026gt;func(i); } auto end = high_resolution_clock::now(); std::cout\u0026lt;\u0026lt;\u0026quot;result: \u0026quot;\u0026lt;\u0026lt;total\u0026lt;\u0026lt;\u0026quot;\\nvirtual call elapsed: \\t\u0026quot;\u0026lt;\u0026lt;duration_cast\u0026lt;nanoseconds\u0026gt;(end-start).count()\u0026lt;\u0026lt;\u0026quot; nanoseconds.\\n\u0026quot;\u0026lt;\u0026lt;std::endl; total = 0; start = high_resolution_clock::now(); for (int i = 0; i \u0026lt; num; ++i) { total += calculate(i); } end = high_resolution_clock::now(); std::cout\u0026lt;\u0026lt;\u0026quot;result: \u0026quot;\u0026lt;\u0026lt;total\u0026lt;\u0026lt;\u0026quot;\\ndirect function call elapsed: \\t\u0026quot;\u0026lt;\u0026lt;duration_cast\u0026lt;nanoseconds\u0026gt;(end-start).count()\u0026lt;\u0026lt;\u0026quot; nanoseconds.\\n\u0026quot;\u0026lt;\u0026lt;std::endl; Func functor{10}; total = 0; start = high_resolution_clock::now(); for (int i = 0; i \u0026lt; num; ++i) { total += functor(i); } end = high_resolution_clock::now(); std::cout\u0026lt;\u0026lt;\u0026quot;result: \u0026quot;\u0026lt;\u0026lt;total\u0026lt;\u0026lt;\u0026quot;\\nfunctor call elapsed: \\t\u0026quot;\u0026lt;\u0026lt;duration_cast\u0026lt;nanoseconds\u0026gt;(end-start).count()\u0026lt;\u0026lt;\u0026quot; nanoseconds.\\n\u0026quot;\u0026lt;\u0026lt;std::endl; int base = 10; function\u0026lt;int(int)\u0026gt; lambda = [base](int i) { return i*base; }; total = 0; start = high_resolution_clock::now(); for (int i = 0; i \u0026lt; num; ++i) { total += lambda(i); } end = high_resolution_clock::now(); std::cout\u0026lt;\u0026lt;\u0026quot;result: \u0026quot;\u0026lt;\u0026lt;total\u0026lt;\u0026lt;\u0026quot;\\nlambda call elapsed: \\t\u0026quot;\u0026lt;\u0026lt;duration_cast\u0026lt;nanoseconds\u0026gt;(end-start).count()\u0026lt;\u0026lt;\u0026quot; nanoseconds.\\n\u0026quot;\u0026lt;\u0026lt;std::endl; return 0; } /* test on mac mini i7 2.7GHz clang++ -std=c++11 chronotest.cpp -O0 output: result: 499950000 virtual call elapsed: 43171 nanoseconds. result: 499950000 direct function call elapsed: 31379 nanoseconds. result: 499950000 functor call elapsed: 41497 nanoseconds. result: 499950000 lambda call elapsed: 207416 nanoseconds. =================================================== clang++ -std=c++11 chronotest.cpp -O1 output: result: 499950000 virtual call elapsed: 26144 nanoseconds. result: 499950000 direct function call elapsed: 22384 nanoseconds. result: 499950000 functor call elapsed: 33477 nanoseconds. result: 499950000 lambda call elapsed: 55799 nanoseconds. =================================================== clang++ -std=c++11 chronotest.cpp -O2 result: 499950000 virtual call elapsed: 22284 nanoseconds. result: 499950000 direct function call elapsed: 36 nanoseconds. result: 499950000 functor call elapsed: 30 nanoseconds. result: 499950000 lambda call elapsed: 28292 nanoseconds. =================================================== clang++ -std=c++11 chronotest.cpp -O3 result: 499950000 virtual call elapsed: 18975 nanoseconds. result: 499950000 direct function call elapsed: 29 nanoseconds. result: 499950000 functor call elapsed: 30 nanoseconds. result: 499950000 lambda call elapsed: 22542 nanoseconds. =================================================== clang++ -std=c++11 chronotest.cpp -O4 result: 499950000 virtual call elapsed: 22141 nanoseconds. result: 499950000 direct function call elapsed: 30 nanoseconds. result: 499950000 functor call elapsed: 30 nanoseconds. result: 499950000 lambda call elapsed: 22584 nanoseconds. */ 这里多了两种模式，普通函数和仿函数，提供接口回调的方式和直接调用比较，性能损耗是数量级的差异，仿函数性能和函数接近，有时候仿函数的性能更优，编译原理这块算是知识盲区，猜测是由于访问的变量地址和函数挨着，有利于CPU处理\n附上 wandbox 运行结果\nresult: 499950000 virtual call elapsed: 6143 nanoseconds. result: 499950000 direct function call elapsed: 30 nanoseconds. result: 499950000 functor call elapsed: 31 nanoseconds. result: 499950000 lambda call elapsed: 15134 nanoseconds. ","date":"2023-02-15T13:59:25+08:00","permalink":"https://ttf248.github.io/p/%E7%BC%96%E8%AF%91%E5%99%A8%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/","title":"编译器、回调函数、性能测试"},{"content":"在计算机的发展历史中，如何存储数据并没有统一的标准。\n字节的排列方式有两个通用规则。例如，将一个多位数的低位放在较小的地址处，高位放在较大的地址处，则称小端序；反之则称大端序。在网络应用中，字节序是一个必须被考虑的因素，因为不同机器类型可能采用不同标准的字节序，所以均按照网络标准转化。\n按照阅读习惯，大端字节序更符合从左到右的阅读顺序。\n处理器体系 x86、MOS Technology 6502、Z80、VAX、PDP-11 等处理器为小端序 Motorola 6800、Motorola 68000、PowerPC 970 等处理器为大端序 ARM、PowerPC（除PowerPC 970外）、DEC Alpha、SPARC V9、MIPS、PA-RISC及IA64的字节序是可配置的 网络序 网络传输一般采用大端序，也被称之为网络字节序，或网络序。IP协议中定义大端序为网络字节序。 Berkeley套接字定义了一组转换函数，用于16和32bit整数在网络序和本机字节序之间的转换。\n#include \u0026lt;arpa/inet.h\u0026gt; uint32_t htonl(uint32_t hostlong); //把uint32_t类型从主机序转换到网络序 uint16_t htons(uint16_t hostshort); //把uint16_t类型从主机序转换到网络序 uint32_t ntohl(uint32_t netlong); //把uint32_t类型从网络序转换到主机序 uint16_t ntohs(uint16_t netshort); //把uint16_t类型从网络序转换到主机序 如果选用asio作为网络库，内置的命名空间中有跨平台适配的函数名\nboost::asio::detail::socket_ops::network_to_host_long boost::asio::detail::socket_ops::network_to_host_short boost::asio::detail::socket_ops::host_to_network_long boost::asio::detail::socket_ops::host_to_network_short visual studio 调试器 调试模式下，选中调试菜单，窗口，勾选内存窗口\n在visual studio中，可以直接在调试器中查看内存中的数据，如下图所示\n查看内存的方式 窗口直接输出 \u0026amp;变量名，跳转到对应变量地址 如果变量原本就是指针，双击选中变量，拖动到内存窗口，展示对应地址的内容 如果变量不是指针，添加到计算窗口，获取地址，然后手工复制到内存窗口 举个栗子 收到一段数据，存储到buffer对象中，将网络序转成主机序，得到body_length等于 30，服务端划分了四个字节用于传出此数据。\nbool NetworkMessage::decode_header() { // 网络序转成主机序 body_length_ = boost::asio::detail::socket_ops::network_to_host_long(*(int *)buffer_.data()); return auto_reserve(body_length_); } 大端字节序：在内存窗口中，观察 buffer_ 的内容\n小端字节序：在内存窗口中，观察 body_length_ 的内容\n","date":"2023-01-10T14:18:12+08:00","permalink":"https://ttf248.github.io/p/%E4%B8%BB%E6%9C%BA%E5%BA%8F%E7%BD%91%E7%BB%9C%E5%BA%8F%E9%80%9A%E8%BF%87%E8%B0%83%E8%AF%95%E5%99%A8%E7%9B%B4%E6%8E%A5%E8%A7%82%E5%AF%9F/","title":"主机序、网络序，通过调试器，直接观察"},{"content":"工作的第七个年头，写代码获取的正反馈不是那么多了，回顾下怎么走上 coding 这条道路 人的各种选择，越是小时候，越遵从正反馈这个事情，主动的避害趋利\n一、小时候 搬家到市区，接触计算机书籍？黑客的资料？认识了 windows 系统？这些都算是后话\n时间应该定位到小时候和堂弟偷摸用家里的电脑玩游戏，堂弟舅舅在电脑城，经营了一个店铺 从小我俩接触计算机的时间就比较早，基本的认知也就建立了，后续在学校，上微机课程，也比较有兴趣 初中听说了计算机竞赛，感觉就很酷，转学后，这事情也就搁置了 我上初中那个年代，熟悉电脑的基本操作，在微机课的时候，比较容易出风头 如果你还熟悉，对，你没看错，不是熟练，熟悉 office 办公软件，那就更厉害了\n二、搬家 回到搬家这事，到了市区，由于邻居的原因，接触到了图书馆，虽说看了挺多的小说，但是也看了很多杂志 《电脑报》《大众软件》 愈发的对计算机这个产物产生了兴趣，小时候心理对于黑客的崇拜，非常积极的去学校相关的知识 认知了操作系统基本的：控制面板、CMD命令、VBS脚本\n《电脑报》小白人群挺适合的，每次都是用案例的形式，科普系统的操作 《大众软件》推荐各种软件，行业新闻，当然还有游戏新闻，最初的动力嘛，也埋下了游戏的种子\n三、高中 高二的时候，博哥转校进入我们班，前两年计算机竞赛保送了好几位前辈，校领导也比较重视这个竞赛 还有个前置的硬件基础，美国有位校友，给学校捐了一栋楼，新的图书馆、新的微机教室，一切都是那么巧合 加上博哥的科普，那会算是班级里面的计算机的大佬\n学霸 + 计算机高手，知道怎么黑别人电脑、杀教室的监控软件\n竞赛磕磕绊绊也是走到了决赛，学的不是很懂，题目都是些一些基础的算法，但是也是有点收获\n不过半桶水终究是半桶水，相当于是去旅游了一趟\n四、大学 等到了大学专业选择，听家里的选了自动化，其实想走的是强电专业，回家进入供电局，专业课程没学多少 自我驱动的学习能力在专业课程基本没有，大课程里面的计算机课程，学起来就很得心应手\n专业课逃课、计算机课程认真学，自己日常泡在论坛：《精易论坛》《吾爱破解》 结合专业学那点汇编、C++知识，从论坛接单赚钱，获取了更多的正反馈，越走越远了，拉不回来 到最后，小专业的选择，选择给芯片写代码，家里也没管那么多，让我自己选了\n这时，第三个关键人物：堂哥，高学历，进入百度 老姐也懂我，知道我那会就没心思考研，让我找堂哥聊聊 确定下后面的发展路线，暑假不回家，跟着导师，做项目，混经历 靠着自己还能看的成绩单，进入了恒生电子\n五、毕业 这里有个关键，我知道翻墙、选修了：计算机信息检索，知道如何快速的查找的和定位资料、问题 工作里面的贵人出现了，硕哥，给了时间让我自己学习，排查问题刨根问题，带着我去认识研发中心的大佬 这些也铺垫了，深圳分公司，对外都认为我很厉害，成功负责了交易通道组\n这里就有个问题，我对于计算机操作系统、算法等基础知识，软件工程设计 没有系统的学习，都是靠自己的历史经验 容易出现，前后否定自己的代码设计，没有准则进行模块设计，到了第七个年头，开始乏力了\n","date":"2023-01-09T13:45:09+08:00","permalink":"https://ttf248.github.io/p/%E9%82%A3%E6%97%B6%E5%B0%91%E5%B9%B4%E5%A4%A9%E5%88%86%E4%B9%9F%E8%AE%B8%E6%9C%89%E4%BD%86%E6%98%AF%E5%B9%B6%E4%B8%8D%E5%A4%9A/","title":"那时少年，天分也许有，但是并不多"},{"content":"政策公布的很突然，执行的很迅速，行程码下线、公共场所不再检查绿码。\n浏览纽约时报中文网，整个版面都在讨论中国解封。\n不评价政策，记录周围的情况。\n北京原本就没有清零，政策打开限制，迅速扩散，成片的感染，认识的朋友中，没有重症。\n深圳挨着广州，也开始迅速发展；人在上海带着，由于公司靠近郊区，写这篇稿子时，还没出现大面积感染。\n老家防护措施不多，紧随其后，大面积扩散。\n大部分应该和的感受差不多，突然就放开了，一周一个政策，直到全面放开。\n不能否认三年清零的效果，随遇而安。\n","date":"2022-12-22T19:22:04+08:00","permalink":"https://ttf248.github.io/p/%E4%B8%AD%E5%9B%BD%E6%96%B0%E5%86%A0%E8%82%BA%E7%82%8E%E8%A7%A3%E5%B0%81/","title":"中国新冠肺炎解封"},{"content":"翻看代码的时候，std::this_thread::yield() 猛的引入眼帘，C11里面的语法糖，用了不少，yield还是第一次看到，以前都没注意。\n没查手册，首先想到的是不是和异步变成相关，yieldboost库的协程实现里面用到了这个单词，这里肯定和协程没关系，控制逻辑和普通线程相关。\n文档 yield 此函数的准确性为依赖于实现，特别是使用中的 OS 调度器机制和系统状态。例如，先进先出实时调度器（ Linux 的 SCHED_FIFO ）将悬挂当前线程并将它放到准备运行的同优先级线程的队列尾（而若无其他线程在同优先级，则 yield 无效果）\nsleep_for 阻塞当前线程执行，至少经过指定的 sleep_duration 此函数可能阻塞长于 sleep_duration ，因为调度或资源争议延迟 标准库建议用稳定时钟度量时长。若实现用系统时间代替，则等待时间亦可能对时钟调节敏感\n分析 两个函数都是让当前线程不再占用线程，执行的效果按照平台情况而定？看到这里依旧有点云里雾里的，运行代码看看执行效果\nThinkPad 笔记本（visual studio 社区版2022）、腾讯云S2标准服务器（gcc8.5）\n运行平台 函数 第一次/us 第二次/us 第三次/us Windows sleep_for 9872 1884 11302 Windows yield 119 100 100 Linux sleep_for 171 168 167 Linux yield 101 102 101 从运行结果不难理解，由于操作系统实现的不同，高精度的休眠时，sleep_for稳定性差异巨大，如果想要高精度的休眠，使用yield更加合适\n时间精度提升到ms时，两者差异并不明显\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;chrono\u0026gt; #include \u0026lt;thread\u0026gt; // 建议其他线程运行一小段时间的“忙睡眠” void little_sleep(std::chrono::microseconds us) { auto start = std::chrono::high_resolution_clock::now(); auto end = start + us; do { std::this_thread::yield(); } while (std::chrono::high_resolution_clock::now() \u0026lt; end); } int main() { auto start = std::chrono::high_resolution_clock::now(); little_sleep(std::chrono::microseconds(100)); std::this_thread::sleep_for(std::chrono::microseconds(100)); auto elapsed = std::chrono::high_resolution_clock::now() - start; std::cout \u0026lt;\u0026lt; \u0026quot;waited for \u0026quot; \u0026lt;\u0026lt; std::chrono::duration_cast\u0026lt;std::chrono::microseconds\u0026gt;(elapsed).count() \u0026lt;\u0026lt; \u0026quot; microseconds\\n\u0026quot;; } 参考 https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html ","date":"2022-09-20T20:54:51+08:00","permalink":"https://ttf248.github.io/p/c11-sleep-for-vs-yield/","title":"C11: sleep for vs yield"},{"content":"有台闲置的腾讯云服务器，年底到期，也没想着续费，部署个MYSQL当作开发用的数据库。重装系统的时候，图省事，直接选择了腾讯云提供的三方镜像，已经安装好了MYSQL数据库。原以为系统里面应该自带个Readme之类的文件，说明下密码是什么，部署路径是什么。\n腾讯云重装系统很快，一分钟左右通知已经重装好了，登录进去，systemctl status mysql 服务已经启动了，找找密码在哪里，找了一圈，没找到，逐渐开始自闭。\n这时想着，都已经摸到了服务器，拿着root权限，总归是有法子重置下密码。翻翻资料，阿里云论坛有个帖子，继续折腾。\n重置密码 编辑配置文件 vim /etc/my.cnf，mysqld节点增加配置：skip-grant-tables，执行命令重启数据：systemctl restart mysql\n再使用mysql直接登录数据，接来下就是正常操作了，重置root用户密码，顺带开启下允许远程登录\nUSE mysql; UPDATE user SET authentication_string = password ('pass') WHERE User = 'root'; grant all privileges on *.* to 'root'@'%' identified by 'pass' with grant option; flush privileges; 回退修改的配置文件，重启下数据库，搞定。\n参考资料 https://help.aliyun.com/document_detail/42520.html ","date":"2022-09-20T14:27:35+08:00","permalink":"https://ttf248.github.io/p/linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%87%8D%E7%BD%AEmysql%E5%AF%86%E7%A0%81/","title":"Linux服务器，重置Mysql密码"},{"content":" 命这个字在中华汉字里面从来没有过同音字，或许这本身就暗示着，命只有一条。\n翻翻起点的排行榜，《夜的命名术》 月票高居榜首，第二名车尾灯都看不到了，这么多年看的都是西红柿、耳根，尝试下新作者的。\n截止到八月初，两百万 vs 八万。\n不评论文笔，也没这个本事，看了十几章，情节紧凑对得起这个月票。\n死也是找不到同音字。\n","date":"2022-08-11T22:10:14+08:00","permalink":"https://ttf248.github.io/p/%E5%A4%9C%E7%9A%84%E5%91%BD%E5%90%8D%E6%9C%AF/","title":"夜的命名术"},{"content":"金融交易系统在测试上的投入，远超其他系统，繁琐的测试步骤重复进行，ROI 太低。随着项目和人员的更替，不可避免引入更多的不可控因素，常见的情况，修改的是A接口输出的某个字段，却影响了B接口的结果，每次版本发布，风险也在积累。\n理论知识 如何衡量自动化的价值？ 一个自动化测试案例ROI = （手工运行时间）*（运行次数）/ (开发成本 + 维护成本)\n哪些功能需要做自动化测试？ 用户常用的功能，不会经常改变的功能。针对此类型的接口编写自动化测试代码，收益最高。\n为什么选择这个时间点推动自动化测试？ 临近项目上线，肯定不合适，远水解不了近渴，自动化属于长期收益模型。项目已经在生产环境上线，进入稳定发布周期，此时最为合适。\n框架的选择 缺乏相关实践经验的情况下，拿到自动化测试这么一个任务，常规开局：打开搜索引擎，寻找当前系统技术栈能用上的工具和框架，过一遍使用手册，开工大吉。能立马找个合适的工具，恭喜你，完美开局。\n先说一声我错了，翻查了相关的资料，不是说没有，而是框架本身太复杂了，部署占用的资源也过多。小白入门需要的是小巧的，精简的，咨询测试组的同事，提到了 Python 自建框架，简单来说就是用现有的单元测试框架，封装成自动测试框架。\n参考此项目的设计思路：https://github.com/wintests/pytestDemo\n为什么需要框架？ 服务有多个不同的部署环境，开发环境、测试环境、线上测试环境，框架的作用在于做一层剥离，测试案例和数据进行分离，按照不同的环境配置不同的案例数据，当然也支持公用的数据。\n核心的逻辑都是为了提高自动化的利用率。场景再复杂一些，不同环境之间的数据就是不通的，完全没有任何关系，配置案例数据的时候，增加 label 标签即可，指定当前数据支持的环境。\n参考资料 做性价比最高的自动化测试\n","date":"2022-08-04T11:39:18+08:00","permalink":"https://ttf248.github.io/p/%E6%B5%85%E8%B0%88%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/","title":"浅谈自动化测试"},{"content":"从上学时期开始算，接触 C++ 已经十多年了，为什么需要学习其他的编程语言？\n工作经历：缺乏优雅的模块设计经验，C++ 语法是自由的，学习了其他的语言，也能引导写出更优雅的设计\n编写一些工具的时候，时常会用到\n底层库的设计也好、业务模块实现也好，设计的准则都是想通的\n","date":"2022-08-04T11:27:30+08:00","permalink":"https://ttf248.github.io/p/%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%AD%A6%E4%B9%A0%E4%B8%80%E9%97%A8%E6%96%B0%E8%AF%AD%E8%A8%80/","title":"为什么需要学习一门新语言"},{"content":"C++跨平台开发，中文操作系统经常能碰到：error C2001常量中有换行符\nvisual studio cmake组织项目编译脚本，windows系统下面开发时，临时生成一份解决方案，跨平台的原因，文件编码选择utf-8。\n引用资料从原理出发详细的解释了问题的的成因\n针对编码，MSVC有专门的编译选项/source-charset和/execution-charset，前者表示文件本身的编码，后者表示编译以后的字符数组内的字节是什么编码，编码问题基本可以用这两个选项解决。\n比如，windows的cmd控制台默认只能显示GBK编码，但是代码文件本身是UTF-8，因为跨平台的缘故，又不方便直接修改成GBK，当然这里就不包括为不同平台写编码转换代码这种办法。在Win10上，可以设置这两个编译选项为/source-charset:utf-8 /execution-charset:gbk，表示让编译器以UTF-8编码读入，然后转为GBK保存在数组里面，这样直接printf就能在cmd控制台上正常显示汉字。\nCMake 针对 Visual studio 设置 if( WIN32 ) message( STATUS \u0026quot;Configuring trade on WIN32\u0026quot;) set( CMAKE_CXX_FLAGS \u0026quot;${CMAKE_CXX_FLAGS} /source-charset:utf-8 /execution-charset:gbk\u0026quot;) endif() 参考资料 https://zhuanlan.zhihu.com/p/146543940 ","date":"2022-08-04T10:51:43+08:00","permalink":"https://ttf248.github.io/p/visual-studio-%E7%BC%96%E8%AF%91%E5%AD%97%E7%AC%A6%E9%9B%86%E8%BD%AC/","title":"Visual Studio 编译字符集[转]"},{"content":"不懂政治、不做评论，记录下这场互联网上的“狂欢”\n随笔 前段时间的唐山打人事件、人教小学教材文化入侵事件，不知道还有多少人记得。新闻上的这种热点，已经麻木了，并没有太多感触，下班了照常看剧，这事就看个热闹。经济形势已经这样了，爆发战争，日子并不会变的更好。不懂政治、不做评论，记录下这场互联网上的“狂欢”。\nWiki 概述 2022年南希·佩洛西访问台湾，又称佩洛西访台，是指美国第52任众议院议长南希·佩洛西于2022年访问亚洲国家之旅其间，访问台湾的行程。\n由于美国众议院议长被视为美国第三号人物，并计划访问台湾，日期短期内接近8月1日的中国人民解放军建军纪念日，长期内接近中国共产党第二十次全国代表大会、2022年美国选举及2022年中华民国地方公职人员选举。中华人民共和国方面，其政府提出强烈抗议，派遣海军驱逐舰部队到达台海东北海域，动员山东舰与辽宁舰两个航空母舰战斗群，东部战区与南部战区分别在东海与南海开展大规模实兵实弹演习。美国方面，派遣罗纳德·里根号航空母舰战斗群抵达台海周边护卫佩洛西可能的访台行程，并调遣多批次侦察机与空中加油机至驻日美军嘉手纳空军基地待命。\n中国国家主席习近平与美国总统乔·拜登在访问前曾进行视频会晤，内容涉及台湾问题。台湾与国际媒体透露佩洛西议长及众院访问团将于2日抵达台北松山机场，过夜后将在3日会见中华民国总统蔡英文等政府高层。有观点认为此次佩洛西访问台湾有可能造成自1996年台湾海峡导弹危机，26年来新一次的台湾海峡危机。\n08-11 到今天基本算是尘埃落地，这段时间的头条，基本都是各种沿海军演，知乎也是煞费苦心，每天换着法子更新热榜，说的呢都是这个事情，小编辛苦了。\n","date":"2022-08-02T22:57:54+08:00","permalink":"https://ttf248.github.io/p/%E4%BD%A9%E6%B4%9B%E8%A5%BF%E8%AE%BF%E9%97%AE%E5%8F%B0%E6%B9%BE/","title":"佩洛西访问台湾"},{"content":"Linux 平台很简单 du -sh * 一行代码就搞定了。Windows 怎么办呢？磁盘很多，想清理一波，文件很多的情况下，系统自带的资源管理器，统计文件夹大小，速度慢的让你想放弃\nEverything windows 平台下做开发的朋友，没有亲手用过 everything，也应该听朋友提过。搜索速度远超系统自带的资源管理器。既然系统层面支持快速索引文件，肯定就能找到类似的工具，建立文件索引的同时，统计下文件的大小。\nWizTree 官网：https://www.diskanalyzer.com/\n普通的安装模式或者绿色版本解压运行\n速度快，数据展示类型丰富，左侧是树状图模式，右边是文件类型，当然也有图形化展示，在软件底栏。\nSpaceSniffer(update 2023 不再维护更新了) 软件官网：http://www.uderzo.it/main_products/space_sniffer/\n操作很简单，选择对应的盘符，软件会用图形化的方式，展示文件夹体积，体积越大，图像中对应的矩阵也就越大，其余操作，自己点点就明白了，支持输入条件过滤文件：\n文件体积过滤 文件日期过滤 参考资料 https://moe.best/software/spacesniffer.html\n","date":"2022-08-01T19:54:18+08:00","permalink":"https://ttf248.github.io/p/windows%E5%B9%B3%E5%8F%B0%E5%BF%AB%E9%80%9F%E7%BB%9F%E8%AE%A1%E6%96%87%E4%BB%B6%E5%A4%B9%E5%A4%A7%E5%B0%8F/","title":"Windows平台快速统计文件夹大小"},{"content":"静态博客的主题，主流是基于国外的模板，进行修改调整，没有过多考虑中文内容的排版\n正文 半个月前，调整了一下博客的样式表，工作多年都是做的后端服务开发，前端纯纯的小白一枚。前后折腾了半天，设计上都不太合理。灵光闪现，想到了常看的技术博客：infoq、开源中国，这些站点的排版看着就很不错，能不能借来用用？看了一会源码文件，定位相关的元素弄的一头雾水。\n做前端的朋友看到这里可能要笑了。。定位指定的元素都不懂。不懂没事，周末时间多，停下来思考下，以前写 python 爬虫的时候，好像用到了类似的东西。\n元素审查 没错，就是浏览器自带的元素审查工具，复制样式表、定位指定元素，都是分分钟的事情；selector 定位元素、hugo 新建 user define css\n复制元素 复制 outerHTML 复制 selector 复制 JS 路径 复制样式 复制 XPath 复制完整的 XPath ","date":"2022-07-31T23:36:48+08:00","permalink":"https://ttf248.github.io/p/%E5%A6%82%E4%BD%95copy%E7%BD%91%E9%A1%B5%E6%A0%B7%E5%BC%8F%E8%A1%A8css%E5%85%83%E7%B4%A0%E5%AE%A1%E6%9F%A5/","title":"如何Copy网页样式表（CSS）：元素审查"},{"content":"上海国安数据库事件，黑产圈子里面闹的沸沸扬扬，也不知道真假，过两年如果还记得，再回头看看。根据以往的经验，更新了一波本地的社工数据库资料，看到一个巨型SQL文件：17.9G，一般的文本编辑器，预览都是个问题，更别说打开了，和网友闲聊，提到了：EmEditor。\n正文 官网：https://www.emeditor.com/\n周末抽空试了一下，挺方便的，设计上就支持编辑大型文件，内存足够的情况下，整个文件都载入到内存中，搜索、编辑速度都挺快，也支持分割文件。\n","date":"2022-07-31T23:21:24+08:00","permalink":"https://ttf248.github.io/p/windows%E5%B9%B3%E5%8F%B0%E7%BC%96%E8%BE%91%E8%B6%85%E5%A4%A7%E5%9E%8B%E6%96%87%E4%BB%B6emeditor-text-editor/","title":"Windows平台编辑超大型文件：EmEditor (Text Editor)"},{"content":"领导班子在前两天还死要面子的说上海不会封城，上海很重要。结果呢，迫于现状或者说为了保住自己的乌纱帽来了一个隔江相望。先把黄浦江对面封一段时间，然后再封江这边。\n封城 小时候经历过非典，已经没有太多印象，后来看到相关资料，由于潜伏周期比较短，还没出现全国性的扩散就已经结束了。记得那会还在上小学，每天下学都很早，教室里每天都飘着一股消毒液的味道。\n19年底到现在，新冠肺炎疫情也都快三年了。在外打工的人，也都习惯了，该戴口罩的时候戴着口罩。上海这一波疫情反复呢，源头最初是香港，然后通过跨境关口扩散到了深圳，上海这边呢也是由于香港一波输入型病例导致的。官方最后给出通告，由于隔离酒店防护措施不到位导致了疫情扩散，变种后的病毒，毒性是减弱了，但是传播速度变快了，通过酒店的通风系统产生的扩散。最初那会儿其实不严重，还能管控住。\n人总是很自信。上海的领导们也是这样。他们会选择我们能做网格化的风控，精准防控。\n现在的结果大家也看到了，新增已经累计突破了2万，被逼无奈选择了封城，关键对外呢没有用“封城”这个字眼，因为在早前的新闻发布会上，对外宣称，上海不需要封城，算是给自己保留最后的颜面。\n买菜 外卖这个行业呢，是互联网做出来的新兴产业。核心点呢，就是需要有人给你配送对吧，但是由于疫情的大片区域被封锁了，就导致商家能做，关键没有人给你送，整个链路就少了最后一环。在外面的人可能不太理解，上海作为一个国际化的大都市，怎么会大家去一窝蜂的买菜。其实想一想也能明白，大部分的人呢也都是外地过来打工住的呢，是出租房，日常呢是公司食堂，或者在外面的店里吃，很少会在家里自己做。当外面这条路走不通的时候，有条件的就都会开始买菜。由于这种封城的公告并没有提前通知，大家也都没有日常储备那么多粮食或者说蔬菜。也就有了视频里面的一窝蜂的去买菜，在那种情况下聚集直接导致了，疫情的再次扩散。\n行业 从事的都是it行业，疫情对我的影响，体会了一下居家办公，19年那会，在家待了快一个月，前后改签车票十几次，完全没法确定什么时候能返回深圳。餐饮旅游或者很多服务行业，无法想象那些人这几年是怎么过的。\n","date":"2022-03-30T23:03:27+08:00","permalink":"https://ttf248.github.io/p/%E4%B8%8A%E6%B5%B7%E9%B8%B3%E9%B8%AF%E9%94%85%E5%B0%81%E5%9F%8E/","title":"上海鸳鸯锅封城"},{"content":" ouuan 弄了四个小时，看到这句话的时候，我还觉得搞笑了，怎么可能这么久？最后一看时间：三个小时。\n算是二零二二年开年的第一篇稿子，要搞的东西不复杂，就和标题说的一模一样（此时的我还很年轻），以为照抄 作业 就行，放到收藏夹里面，拖拖拉拉等了一个多月，终于想起来这个事情。\n迁移到hugo的时候一直觉得插件太少了，不能复制代码，导致很多笔记从印象笔记迁移到博客，复制代码的代码的操作就变得繁琐了，严重耽误我水博客的动力。\n序章 先仔细看看原作者的稿子，通读一遍然后翻翻作者介绍，我靠，碰到个大佬了，清华在读本科生，很早就接触到了计算机，诶，就是皮，先翻翻这个博客再说，完全不记得自己要做什么事情。顺带翻翻作者的Github仓库，这个修改后的even主题比现在的好看多了，新功能也多，搞起来，先把相关代码合并到过来。\n新功能：查看文章历史、关联递交记录 效果还是不错的，拖到文章末尾就能体验。\n动手前也没太细看作者原仓库的历史记录，以为简单的合并下就好了，最后合并了一堆代码，中间还冲突和N次，无脑覆盖，都是前端和渲染的模板代码，以我要的为准。\n仓库地址：https://github.com/TianlongXiang/hugo-theme-even\n中文的一个坑，git不调整这个参数，会导致生成的获取不到当前文章的commit hash，导致历史链接生成失败；生成文章完整历史的时候也需要改改自动集成脚本，记得拉取当前仓库全部的历史记录。\nfeat: 尝试拉取完整 github 仓库，用于动态更新文章最后一次改动记录 chore: 路径存在中文，hugo GitInfo 需要启用此设置 name: Build Github run: git config --global core.quotePath false \u0026amp;\u0026amp; hugo -b \u0026quot;https://www.xiangtianlong.com/\u0026quot; -d \u0026quot;github_public\u0026quot; \u0026amp;\u0026amp; ls 样式调整 调整站点内容宽度，之前的设计适合移动端和电脑端，实际上也没人手机上看，我自己都是电脑上看 目录栏支持自动伸缩 正文 参考ouuan的代码记录看了半个多小时，愣是没太看懂怎么增加的复制按钮。\n时光穿梭，一月之后，又想到这事\n既然这个作业没看懂，换个作业抄，总归能抄明白。搜索出来的结果，还挺让人意外，hugo官方的论坛里面就有个帖子提到了如何增加复制按钮，跑过去一看，逻辑清晰。懵逼的事情来了，回到的站点一看even渲染生成的代码块样式和资料中的描述不同，这块就比较啰嗦了，简单记录下。\n由于基本不懂前端开发，不懂的地方就开着浏览器审查元素，对着代码分析、靠着右边的样式器信息，慢慢也分析懂了逻辑；JavaScript没看懂，控制台来点日志。不懂的时候很多，静下心，慢慢梳理拆分逻辑，总归能找到思路。\npre节点有多个，这里指的是单个代码块，主题自己渲染了一行号出来，导致复制按钮出来两个 想要关点主题自带的代码高亮渲染，奈何这个主题设置不熟悉 hugo官网看资料，看了个半懂，知道有markup设置能控制代码高亮 调整配置文件，一直不对劲，渲染出来和预期不同 发现这堆设置pygmentsOptions，又继续翻资料，调整设置，先去掉行号 配置自定义的css样式表，配置自定义的js脚本 既然都搞了这么多事情，脑子突然想到最近看到一个配色图不错，改改按钮的样式：中国风天青色走起 ouuan 弄了四个小时，看到这句话的时候，我还觉得搞笑了，怎么可能这么久？最后一看时间：三个小时。\n参考链接 https://ouuan.github.io/post/from-hexo-to-hugo/ https://gohugobrasil.netlify.app/content-management/syntax-highlighting/ https://gohugo.io/getting-started/configuration-markup#highlight https://www.dannyguo.com/blog/how-to-add-copy-to-clipboard-buttons-to-code-blocks-in-hugo/ ","date":"2022-02-25T01:23:39+08:00","permalink":"https://ttf248.github.io/p/%E4%BB%A5%E4%B8%BA%E5%BE%88%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%8B%E6%83%85%E5%A2%9E%E5%8A%A0%E4%B8%80%E4%B8%AA%E4%BB%A3%E7%A0%81%E5%A4%8D%E5%88%B6%E6%8C%89%E9%92%AE/","title":"以为很简单的事情，增加一个代码复制按钮"},{"content":" 王羲之说：夫人之相与，俯仰一世，或取诸怀抱，悟言一室之内；或因寄所托，放浪形骸之外。\n人这一生，如昙花一现。如草木春绿枯荣，如曦月东升西落。\n偏偏这一生欲望却有很多。\n小时候溪头卧剥莲蓬，忙趁东风放纸鸢，急走追黄蝶，\n也傍桑影学种瓜，归来饭饱黄昏后，不脱蓑衣卧月明。\n长大后希望金榜题名，希望有佳人相伴，希望钱财不断，希望节节高升，希望高朋满座，希望夜夜笙歌。\n老了又想要健康长寿，童仆欢迎，稚子候门，有一盘棋，一知己，一壶酒，一庭院，安享天伦。\n你看世人慌慌张张，不过图碎银几两。偏偏这碎银几两，能解世间万种惆怅。\n有一大半的人还在为生活挣扎，哪里有时间去追寻意义？\n其实人这一生，不过是一场体验，就和草木，日月一样，体验这欲望的轮回。\n活不明白就会觉得，寄蜉蝣于天地，渺沧海之一粟。哀吾生之须臾，羡长江之无穷。活明白了就会欣于所遇，暂得于己，快然自足，不知老之将至。\n你可以追求这金钱名利，你也可以追求诗酒花茶，你可以追求江上之清风，也可以追求山间之明月。\n但是不用过分在意追求的结果，结果终将逝去。\n穷极一生，来到人间，尽可能体验世间的喜怒哀乐，生老病死。\n很喜欢大鱼海棠的这句话。\n我们这一生很短，我们终将会失去它，所以不妨大胆一点，爱一个人，攀一座山，追一次梦，不妨大胆一点，有很多事情没有答案。\n很喜欢《兰亭集序》和《赤壁赋》。\n每揽昔人兴感之由，若合一契，未甞不临文嗟悼，不能喻之于怀。固知一生死为虚诞，齐彭殇为妄作。后之视今，亦犹今之视昔。悲夫！\n","date":"2021-08-31T21:09:58+08:00","permalink":"https://ttf248.github.io/p/%E6%88%91%E4%BB%AC%E7%A9%B7%E6%9E%81%E4%B8%80%E7%94%9F%E8%BF%BD%E5%AF%BB%E7%9A%84%E6%98%AF%E4%BB%80%E4%B9%88/","title":"我们穷极一生追寻的是什么"},{"content":"不常见，时间长了肯定能碰到，关联股票代码：伯克希尔\n正文 部分股票代码的名称中包含 . 或者其他特殊字符，通过 Fix 报送给盈透（IB）时，需要针对股票代码名称进行一定的转换\nBRK/B -\u0026gt; BRK B\n针对盈透证券的情况，能分析出来，转换的规则是固定的，编码实现即可。当规则不固定的时候，一般系统内部需要存储对应的映射关系，业务操作人员定时更新。\n参考链接 How do I enter the symbol for Berkshire Hathaway Class B shares onto TWS?\n","date":"2021-08-30T17:35:59+08:00","permalink":"https://ttf248.github.io/p/%E7%9B%88%E9%80%8F%E8%AF%81%E5%88%B8%E8%82%A1%E7%A5%A8%E4%BB%A3%E7%A0%81%E7%89%B9%E6%AE%8A%E6%A0%BC%E5%BC%8F%E8%AF%B4%E6%98%8E/","title":"盈透证券股票代码特殊格式说明"},{"content":"随着金融市场不断演变，投资者已开始寻求更有效的投资工具以增加其投资回报。为了迎合投资者的需求，香港交易及结算所有限公司（香港交易所）推出了一系列股票期货合约，这些合约所代表的股票均在香港交易所全资附属公司香港联合交易所有限公司（联交所）上市，不但流通量高，交投也很活跃。透过投资于股票期货，投资者可参与个别上市公司表现之余，亦可享受衍生品市场提供的沽空及杠杆效应等方便。\n由于股票期货所代表的股票均为所属行业的表表者，投资者如认为某一行业的表现会优于或逊于整个股票市场的表现，可以相应选择投资该行业的股票期货。\n基本定义 股票期货合约是一个买卖协定，注明于将来既定日期以既定价格(立约成价)买入或卖出相等于某一既定股票数量(合约成数)的金融价值。\n所有股票期货合约都以现金结算，合约到期时不会有股票交收。\n合约到期 合约到期时，相等于立约成价和最后结算价两者之差乘以合约乘数的赚蚀金额，会在合约持有人的按金户口中扣存。\n最后结算价是相关股票于最后交易日当天的联交所报的正式收市价。\n如果股票期货的投资者希望在合约到期前平仓的话，原先沽空的投资者只须买回一张期货合约，而买入合约的投资者则卖出一张期货合约。\n保证金 在进行期货交易时，买卖双方均需要先缴付一笔基本按金，作为履行合约的保证。结算所在每日收市后会将所有未平仓的合约按市价计算盈亏，作为在投资者按金户口中扣存的依据。如果市况不利使投资者蒙受亏损，令按金下降到低于所规定的水平，期交所会要求投资者在指定时限内补款，使按金维持在原来的基本按金水平(即补仓)。\n优点 交易费用低廉：每张股票期货合约相等于数千股股票的价值，而买卖合约的佣金则视乎张数而定，所以交易成本相对合约价值而言极低。 沽空股票更便捷：由于投资者可以便捷地沽空股票期货，所以在跌市时，投资者可藉着沽空股票期货而获利。 庄家制度：为确保市场的流通充裕，香港交易所规定市场庄家在一个指定的差价范围内同时提供买入价及卖出价，使股票期货市场保持流通。 杠杆效应：投资者买卖股票期货合约只需缴付占合约面值一小部份的按金，令对冲及交易更合乎成本效益。 减低海外投资者的外汇风险：股票期货合约为海外投资者提供投资本地优质股票的途径，因为买卖股票期货只需要缴付按金，而非全部的合约价值，故大大减低了海外投资者所要承受的外汇风险。 透过电子交易系统进行买卖：股票期货合约采用期交所的电子交易系统进行买卖。所有买卖盘会按价格及时间的先后次序执行对盘，并能即时显示买入价，卖出价及成交价，令市场透明度达到最高水平。 结算公司提供履约保证：股票期货合约将由期交所全资拥有的香港期货结算有限公司(结算公司)登记、结算及提供履约保证。由于结算公司为所有未平仓合约的对手，因此，结算所参与者之间将无须承受对手风险。但是，保证的范围并不包括结算所参与者对其客户的财务责任；而投资者选用经纪进行买卖时必须小心慎重。 庄家制度 市场参与者或于个别股票期货注册成为市场庄家，并在指定的最大差价范围内同时提供买入价和卖出价。交易所参与者及其客户须注意个别股票期货可能没有市场庄家登记提供买卖差价而其买卖将以市场买卖单位为基础。投资者应留意买卖没有市场庄家登记的股票期货可能涉及流通性风险，入市前应谨慎考虑。\n买卖股票期货的风险 股票期货涉及高风险，买卖股票期货所招致的损失有可能超过开仓时缴付的按金，令阁下或须在短时间内缴付额外按金。若未能缴付，阁下的持仓或须平仓，任何亏损概要自行承担。因此，阁下务须清楚明白买卖股票期货的风险，并衡量是否适合自己。阁下进行交易前，宜根据本身财务状况及投资目标，向经纪或财务顾问查询是否适合买卖期货及期权合约。\n调整注释 倘正股公司以供股或派发红股等形式更改其股本结构，将会导致股价在除净权益时或生效日期时出现改变，而未平仓合约亦可以因而受到影响。\n如果其他情况不变，股东持有的组合价值并不会再除净日改变，但对股票期货的买家或者持有人来说，情况则有所不同，除非期货合约中作出适当的调整。如果没有改变立约成价，而股票期货的合约乘数又保持不变，股价的调整将会对股票期货持仓的价值造成无理及不公平的影响。\n结算所决定调整比率时，以维持期货合约的公平价值为原则，并只会在出现重大改变时作出调整。香港交易所会公布调整的详情，而交易所参与者需告知客户有关变化。\n股票期货合约概要 资讯供应商代码 参考资料 香港交易所 - 衍生产品/个股/股票期货\nHKEX_Stock_Futures_SC.pdf\n","date":"2021-08-18T10:54:50+08:00","permalink":"https://ttf248.github.io/p/%E6%B8%AF%E8%82%A1%E6%9C%9F%E8%B4%A7%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/","title":"港股期货基本概念"},{"content":"最近两个交易日股市大跌，新入场的韭菜们见识到了市场的风险。我国即将进入老龄化阶段，生育率的数据也是惨兮兮，降低的幅度大幅超出了相关专家的估计，阻挡生育率的绊脚石行业，我党都将重拳出击。\n学生减负 九十年代出生的我们，没有那么多的兴趣班，科目辅导班，放学了撒了疯的玩，首先是家里的条件不允许、其次是当时的辅导班尚未产生品牌效应，让家长信服他。转眼二十年过去，19年开始的K12教育资本化，猿辅导等作为代码的线上辅导班横空出世，资本的加持下，集中优秀的资源打造出来各种名牌辅导班，天价的费用也挡不住家长的热情。\n城市化的进程中，很多家长都是通过读书这条路，脱离寒门，完成了阶级的跃迁，自己作为社畜的工作，没有太多的时间照顾孩子，不仅自己很卷，也不希望孩子落后同辈；寒门难出贵子，没有合适的学历，普通的家庭在中国，其他的路径维持当前的阶级或者再次阶级跃迁很难，如果进入职业高中，在当前的社会环境中，以为这阶级的滑落，这是大部分家长无法接受的。\n我们回头看看为什么会有课外辅导，家长为什么需要课外辅导？课本的知识和例题都是一看就懂，很多科目涉及面很广，不过都是粗浅的概念，并没有太过深入。人才的选拔机制需要有一定的区分度，这就导致了一个矛盾点，试题单单从课本知识出发，无法达到筛选的作用，需要横向拓展、纵向拓展。这些内容都是老师无法在课堂上覆盖的方面，这个空间的存在，培育了养活课外辅导的土壤。\n文件内容很多，三十条细则规范了多个方面，指导文件大纲摘要：\n全面压减作业总量和时长，减轻学生过重作业负担 提升学校课后服务水平，满足学生多样化需求 坚持从严治理，全面规范校外培训行为 大力提升教育教学质量，确保学生在校内学足学好 强化配套治理，提升支撑保障能力 精心组织实施，务求取得实效 精英教育 在教育行业，其实还有一个现象，厉害的民办中学越来越多，公立学校的优质资源不够用了（衍生学区房）。各种规模化的教育集团，通过高薪待遇，拉拢优质的老师，建立优质的教学环境，逐步树立各自的品牌，最为出名的：衡水模式。老家平均公司三千多，厉害的民办小学，一个学年的费用九千到一万。教育集团形成一个良性的循环，我学费贵，但是老师厉害，学生成绩好，我提高学费，家长还是会把孩子送过来。公办的资源（老师）也会逐步被民办的学校吸引过去，最终沦为劣质教育的代名词。\n算法压榨 有数据表示，美团签约的骑手接近四百万，活跃的骑手四五十万，很多人依赖这份工作养家糊口，无止境的算法压榨配送时间，将人换算为可计量的单位，投入到算法中计算，不断的探索配送员的崩溃边界。自己以为很聪明，违背人性，服务资本。市场在这里放着，大家好好玩，可持续发展的玩，而不是搞垄断、搞特权，资本主义的玩法，肆意的野蛮的生长终将落幕。\n股市波动 二零二一年七月二十四号，新东方为代表的教育股表演花式跳水，美股盘前好未来紧接其后，股价腰斩。\n我国已经逐步进入老龄化，各种影响计划生育的社会现象，必然要被整治；垄断、加班的互联网公司被罚款了，资本聚集的教育行业也被整治了\n不允许教育行业被资本化，一票直接否定相关行业进行上市融资，哀嚎一片。\n腰斩的新东方 暴跌的美团 参考链接 监管密集出拳，在线教育急“刹车”\n国务院办公厅印发《关于进一步减轻义务教育阶段学生作业负担和校外培训负担的意见》\n","date":"2021-07-28T14:59:08+08:00","permalink":"https://ttf248.github.io/p/%E8%B5%84%E6%9C%AC%E5%9E%84%E6%96%AD%E5%92%8C%E5%9C%A8%E7%BA%BF%E6%95%99%E8%82%B2%E8%A1%8C%E4%B8%9A%E7%9A%84%E8%90%BD%E5%B9%95/","title":"资本垄断和在线教育行业的落幕"},{"content":"一种破坏系统的模式，进行系统稳定性测试\n正文 国内的互联网行业总是喜欢折腾点新东西出来，有时候听到个名词，一般人都想不到它是什么东西？\n看了部分文章，还是这段针对混沌工程初期的定义，较为容易接受\n混沌工程的早期探索，其实在行业内一直有，曾经是以故障测试、容灾演练等身份存在。而随着微服务架构的不断发展，以及分布式系统的不断庞大，混沌工程开始崭露头角，越来越被重视。当 Netflix 正式提出混沌工程概念后，相关理论也开始飞快丰富。Netflix 的实践也证明了混沌工程在稳定性领域所带来的巨大意义。\n参考链接 字节跳动混沌工程实践总结\n","date":"2021-07-28T14:35:07+08:00","permalink":"https://ttf248.github.io/p/%E6%B7%B7%E6%B2%8C%E5%B7%A5%E7%A8%8B/","title":"混沌工程"},{"content":"Deployment控制器实现了Kubernetes集群中一个很重要的功能，Pod的水平拓展和收缩功能。这个功能是传统云时代平台所必备的能力。\n碰到一个业务场景，需要修改数据库中的数据，调整后重启Pod节点。但是在Pod运行过程中，一直在修改表字段，需要临时性的暂停应用对表的更新，调整数据后恢复Pod。\n除了暴力的删除Deployment，有没有其他的方式，实现类似暂停的效果？\nkubectl scale --replicas=0 deployment/\u0026lt;your-deployment\u0026gt; 在看到答案之前，很多人可能都没想到，看到答案后，会心一笑，脑子没有转弯，思路还停留在直接操作进程的时代，想着直接操作业务进程。\n参考链接 how to stop/pause a pod in kubernetes\n","date":"2021-07-12T11:23:09+08:00","permalink":"https://ttf248.github.io/p/kubernetes%E6%9A%82%E5%81%9Cpod/","title":"kubernetes暂停pod"},{"content":"90年代出生的我们这辈人，08年的金融危机，大部分都没太多的感觉，毕竟那会还年轻，也没到理财的年纪。2015年的牛市来的轰轰烈烈，走的时候动静也不小，最后还是国家出手救市。与此同时，也让基金这个概念，走入了普通人的视野中。\n蚂蚁金服和支付宝 支付宝作为蚂蚁旗下天然的流量入口，出生就是定位支付工具，支付宝购买基金和微信购买基金，大部分人都选择了支付宝。支付宝也成功的把基金销售变成了普通的购物，2019年开始的小牛市，基金经理的报团取暖，归根结底还是疫情引导的货币大放水。入场的人都赚到了，没入场的看到了也眼红，赶着入场。新基金规模突破百亿的速度越来越快，在大妈都开始买基金的场景中，千亿基金也不远了。\n在以蚂蚁为代码的互联网基金销售平台火爆前，平明百姓接触基金销售多是在银行存钱的时候，大堂经理会热情的来介绍各种理财。互联网的包装、推销页面信息的引导，基金销售机构给的天价广告费，让支付宝给出的基金广告完全脱离理性。\n正常银行定期理财收益 4%，前些年玩的很疯的P2P理财 8%，信用卡还款利息 12%。我们的主角，支付宝推广的基金 150%、250%，市场上行，场内的人都开心，市场下行？支付宝是在玩火诶。给出的涨幅数据中，台面上只写了最近三年的收益图，老牌基金只写了年化的平均收益，为什么不敢单独写出来每年的平均收益？是因为很难计算？答案是否定的，因为数据不好看，不容易引导客户购买基金。\n固收理财 中国还没步入负利率时代，银行存款、国债是最为稳妥的固收产品；纯债的基金也是不错的，中国的平均工资多少，各位自行查阅各地统计局公布的数据即可。笔者写个简单的场景，资产规模 200万，年化收益 4%折算，每年的收益都超过了大部分城市的平均工资。\n后记 更多的是从我个人的经历出发，能写的很多，想了解更多的，推荐自行多去看看经济类的书籍，不要盲从。普通的家庭，理财的核心是保值、不是去玩火梦想暴富。\n大伯常说的一句话：\n合适的时间做合适的事情，价值是最大的；读书的时候认真读书，拿到好的学历比你发传单赚零用钱更好；刚毕业的时候认真工作，工资的涨幅能带你丰厚的回报；成家的时候，要学会照顾家里。\n有兴趣的可以去看看这篇演讲稿：关于光阴，你要读很多书才能找到答案，本站有文字稿。\n","date":"2021-07-09T11:27:06+08:00","permalink":"https://ttf248.github.io/p/%E5%9F%BA%E9%87%91%E5%92%8C%E5%9B%BA%E6%94%B6%E7%90%86%E8%B4%A2/","title":"基金和固收理财"},{"content":"中断交易是指当一个交易执行已经发生，并且IB收到来自交易所的执行信息。然后交易所意识到出现了某种错误（比如，定价、电子处理过程、明显的错误，等等），并决定中断（取消）该交易。这个过程完全由交易所来决定和控制。\nA busted traderefers to a situation where an execution occurs and IB receives the execution messagefrom the exchange. The exchange then realizes some type of error (Pricing,electronic, obvious error, etc) and rules to bust (cancel) the trade. Theexchange makes these rulings entirely on their own.\n从交易的角度出发，相当于港交所的成交取消和成交修正。\n","date":"2021-06-22T10:51:59+08:00","permalink":"https://ttf248.github.io/p/%E7%9B%88%E9%80%8F%E8%AF%81%E5%88%B8%E4%B8%AD%E6%96%AD%E4%BA%A4%E6%98%93/","title":"盈透证券：中断交易"},{"content":"金融软件开发的第五个年头，打交道最多的就是各种交易所的接口文档，熟悉的也是港交所的文档，近期处理中华通业务，涉及到了部分中华通业务，顺手查阅了深交所和上交所的资料\n港交所 官网链接\n常用 交易時間，交易和結算日曆 交易机制 中港金融詞彙對照表 滬港通及深港通交易日曆 PDF 滬港通及深港通交易日曆 CSV 中港金融詞彙對照表 PDF 市调机制冷静期触发记录 证券名单：基本信息、证券分类 收市竞价交易时段证券 市场波动调节机制（市调机制）证券 可进行卖空的指定证券 证券名单：基本信息、证券分类 XLSX 行情接口文档：港股 + 中华通 行情接口文档汇总链接\n常见问题答疑、指引开发手册、历史行情接口文档可以通过搜索栏获取下载地址，搜索历史版本号\n港股证券行情接口文档 中华通行情接口文档 HKEX_OMDC_Binary_Interface_Specifications_v_1,-d-,32c.pdf HKEX_OMDC_Developers_Guide_1_11.pdf OMDC_Connectivity_Guide_Securities_Market-Index_datafeed(v2_2).pdf OMD_Interface_Specification_China_Connect_Securities-(v1-3).pdf OMD_Connectivity_Guide_China_Connect_Securities.pdf OMD_Developers_Guide_China_Connect_Securities.pdf 报盘接口文档：港股 + 中华通 报盘接口文档汇总链接\n港股FIX协议接口文档 PDF 港股二级制协议接口文档 PDF 港股交易所错误代码清单 XLSX 中华通Fix协议接口文档 PDF 中华通二进制接口文档 PDF 上交所 行情报盘接口文档\n报错接口文档在其他菜单中获取\n报盘报错接口文档 XLSX\n深交所 行情报盘接口文档\n深交所没有提供单独的报错信息说明，在报盘接口文档的第六章有附加说明\n深圳证券交易所Binary交易数据接口规范（Ver1.18）PDF\n纳斯达克 假期安排 新股上市信息 收市价 全球市场收市价\n","date":"2021-01-27T14:35:21+08:00","permalink":"https://ttf248.github.io/p/%E4%BA%A4%E6%98%93%E6%89%80%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3%E6%B1%87%E6%80%BB/","title":"交易所接口文档汇总"},{"content":"工作多年接触到的都是centos操作系统，如果是mac用户或者Ubuntu用户，部分内容无法适用。\n安装部分可以参考清华大学的手册：https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/\n安装 由于不可知的神秘力量，国内安装docker推荐设置云厂商提供的仓库地址，这里推荐使用阿里云\n设置仓库源地址 yum install yum-utils device-mapper-persistent-data lvm2 \u0026amp;\u0026amp; \\\rsudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\r部署最新版本 docker作为常用的后台服务，推荐设置为开机启动，当前命令适用于centos7\nsudo yum install -y docker-ce docker-ce-cli containerd.io \u0026amp;\u0026amp; systemctl enable --now docker\r部署指定版本 kubernetes和docker的发布并没与完全同步，如果接下来需要部署kubernetes，请参考kubernetes部署说明，安装指定版本的docker\nyum list docker-ce --showduplicates | sort -r\rsudo yum install -y docker-ce-18.09.2-3.el7 docker-ce-cli-18.09.2-3.el7 containerd.io-18.09.2-3.el7 \u0026amp;\u0026amp; systemctl enable --now docker\r普通用户添加docker权限 sudo usermod -aG docker ${USER}\r卸载 sudo yum erase -y docker-ce docker-ce-cli containerd.io\r日常使用 镜像加速 依旧存在不可知的神秘力量，导致拉取镜像的时候速度不给力，此时国内的云厂商站出来了，提供了很多加速服务，依旧推荐一波阿里云\n加速的地址各位看管自己注册阿里云账号获取，此服务免费，阿里云也提供免费的镜像构建服务\ncat \u0026gt; /etc/docker/daemon.json \u0026lt;\u0026lt;EOF\r{\r\u0026quot;registry-mirrors\u0026quot;: [\r\u0026quot;https://docker.nju.edu.cn\u0026quot;,\r\u0026quot;https://mirror.baidubce.com\u0026quot;,\r\u0026quot;https://docker.m.daocloud.io\u0026quot;,\r\u0026quot;https://docker.mirrors.sjtug.sjtu.edu.cn\u0026quot;\r]\r}\rEOF\rsystemctl daemon-reload \u0026amp;\u0026amp; \\\rsystemctl restart docker\r强烈推荐的控制面板 docker volume create portainer_data \u0026amp;\u0026amp; \\\rdocker run -d --name=portainer --restart=always -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:2.20.3-alpine\r常用镜像拉取合集 docker pull rancher/rancher:stable \u0026amp;\u0026amp; docker pull portainer/portainer-ce:2.0.1 \u0026amp;\u0026amp; \\\rdocker pull centos:7 \u0026amp;\u0026amp; docker pull ubuntu:20.04 \u0026amp;\u0026amp; docker pull ubuntu:18.04 \u0026amp;\u0026amp; \\\rdocker pull redis:5 \u0026amp;\u0026amp; docker pull redis:6 \u0026amp;\u0026amp; \\\rdocker pull alpine:3.11 \u0026amp;\u0026amp; docker pull busybox:1.32 \u0026amp;\u0026amp; \\\rdocker pull rabbitmq:3.7-management \u0026amp;\u0026amp; \\\rdocker pull mariadb:10.2 \u0026amp;\u0026amp; \\\rdocker pull nginx:1.18 \u0026amp;\u0026amp; docker pull nginx:1.19 \u0026amp;\u0026amp; \\\rdocker pull mysql:5.6 \u0026amp;\u0026amp; docker pull mysql:8 \u0026amp;\u0026amp; \\\rdocker pull elasticsearch:6.8.11 \u0026amp;\u0026amp; docker pull logstash:6.8.11 \u0026amp;\u0026amp; docker pull kibana:6.8.11 \u0026amp;\u0026amp; \\\rdocker pull zookeeper:3.4 \u0026amp;\u0026amp; \\\rdocker pull influxdb:1.7 \u0026amp;\u0026amp; docker pull grafana/grafana:7.3.1 \u0026amp;\u0026amp; \\\rdocker pull percona:8 \u0026amp;\u0026amp; docker pull percona:5.6 \u0026amp;\u0026amp; \\\rdocker pull cloverzrg/frps-docker:0.34.3 \u0026amp;\u0026amp; docker pull cloverzrg/frpc-docker:0.34.3\r常用组合命令 https://docs.docker.com/engine/reference/commandline/docker/\n查看容器运行状态，附加format参数，查看详细的容器信息，此时不关注镜像信息\ndocker ps --format \u0026quot;{{.Names}}: {{.Ports}}: {{.Size}}\u0026quot;\r#portainer: 0.0.0.0:8000-\u0026gt;8000/tcp, 0.0.0.0:9000-\u0026gt;9000/tcp: 0B (virtual 172MB)\r#influxdb: 0.0.0.0:8086-\u0026gt;8086/tcp: 183B (virtual 311MB)\r一键停止所有容器\ndocker stop $(docker ps -a -q)\r一键删除所有镜像\ndokcer rmi $(docker images -a -q)\r导出镜像\ndocker save \u0026lt;IMAGE NAME\u0026gt;:\u0026lt;IMAGE TAG\u0026gt; \u0026gt; -o XXX.tar\r导出镜像并压缩\ndocker save \u0026lt;IMAGE NAME\u0026gt;:\u0026lt;IMAGE TAG\u0026gt; | gzip \u0026gt; XXX.tar\r导入镜像\ndocker load -i XXX.tar\r","date":"2021-01-21T09:26:07+08:00","permalink":"https://ttf248.github.io/p/docker%E4%BA%8C%E4%B8%89%E4%BA%8B/","title":"docker二三事"},{"content":"作者对硬件有浓厚兴趣，使用Jmeter进行压力测试，记录了在CentOS 7上部署Jmeter、InfluxDB和Grafana的过程。分享了Jmeter的安装和命令使用，InfluxDB的特点和Docker安装方法，以及Grafana的简单部署和配置。总结了高性能程序模式的经验和参考资料。\n背景 众所周知本人对硬件有很浓厚的兴趣，凑巧测试组在用Jmeter做压力测试，发现性能上不去，作为好奇宝宝的我果断出击，试试公司的压测是怎么玩的。此处还有个小故事，在某个久远的时间点，在开源中国看过一篇帖子，如何绘制看上去更加高大上的性能压测图，在测试围观过windows版本执行测试，已经做到了可视化的TPS数据展示，另外配置一份web面板能有什么用？\n脑子想的都是想当然的东西，你要去试试才明白 Don\u0026rsquo;t use GUI mode for load testing! only for Test creation and Test debuggin.\n官方推荐的是通过命令行的方式获取压测报告，绘制GUI的方式展示，存在数据上的误差？对于Jmeter了解的不是很深入，至少找到一个理由去折腾一下Linux版本的控制台面板\n开源中国的帖子，核心组件的部署方式并不友好，安装所需的文件也需要关注公众号才能下载，作为新生代的好青年，当然是用Docker替代了。说白了还是自己服务器在境内，跨境的源地址访问速度都很慢，至少镜像服务，阿里云有个免费的加速。\n关于docker的安装部署，此处不再赘述，推荐参考以前的稿子。\n接下来的内容氛围两大块：基本测试环境组件的搭建、各个组件的简单认知讲解\nJmeter Apache JMeter是Apache组织开发的基于Java的压力测试工具。用于对软件做压力测试，它最初被设计用于Web应用测试，但后来扩展到其他测试领域。 它可以用于测试静态和动态资源，例如静态文件、Java 小服务程序、CGI 脚本、Java 对象、数据库、FTP 服务器， 等等。JMeter 可以用于对服务器、网络或对象模拟巨大的负载，来自不同压力类别下测试它们的强度和分析整体性能。另外，JMeter能够对应用程序做功能/回归测试，通过创建带有断言的脚本来验证你的程序返回了你期望的结果。为了最大限度的灵活性，JMeter允许使用正则表达式创建断言。\nApache jmeter 可以用于对静态的和动态的资源（文件，Servlet，Perl脚本，java 对象，数据库和查询，FTP服务器等等）的性能进行测试。它可以用于对服务器、网络或对象模拟繁重的负载来测试它们的强度或分析不同压力类型下的整体性能。你可以使用它做性能的图形分析或在大并发负载测试你的服务器/脚本/对象。\nJmeter 部署 centos7 安装JDK运行环境、下载Jmeter安装包\nyum install java-1.8.0-openjdk -y \u0026amp;\u0026amp; \\ wget https://mirrors.bfsu.edu.cn/apache//jmeter/binaries/apache-jmeter-5.4.tgz \u0026amp;\u0026amp; tar -xf apache-jmeter-5.4.tgz 配置环境变量\nexport JMETER_HOME=$HOME/jmeter/apache-jmeter-5.4 export PATH=$JMETER_HOME/bin:$PATH Jmeter 命令 最后会对接Grafana控制面板，可以不输入-l参数，在web控制台观察数据\njmeter -n -t /tmp/order-500-10s.jmx -l /tmp/jmeter-order-report-20200109/order-500-10s.jtl # 一般不用测试结果和测试报告，简化命令 jmeter -n -t /tmp/order-500-10s.jmx InfluxDB InfluxDB是一款用Go语言编写的开源分布式时序、事件和指标数据库，无需外部依赖。该数据库现在主要用于存储涉及大量的时间戳数据，如DevOps监控数据，APP metrics, loT传感器数据和实时分析数据。\nInfluxDB 特点 InfluxDB的特点可以归纳为以下9个方面：\n无结构(无模式)：可以是任意数量的列; 可以设置metric的保存时间; 支持与时间有关的相关函数(如min、max、sum、count、mean、median等)，方便统计; 支持存储策略:可以用于数据的删改。(influxDB没有提供数据的删除与修改方法); 支持连续查询:是数据库中自动定时启动的一组语句，和存储策略搭配可以降低InfluxDB的系统占用量; 原生的HTTP支持，内置HTTP API; 支持类似sql语法; 支持设置数据在集群中的副本数; 支持定期采样数据，写入另外的measurement，方便分粒度存储数据。 InfluxDB docker 安装 mkdir influxdb \u0026amp;\u0026amp; cd influxdb \u0026amp;\u0026amp; \\ docker run -p 8086:8086 -d --name influxdb -v $PWD:/var/lib/influxdb influxdb:1.7 docker exec -it influxdb /bin/bash 进入容器，执行命令，人工创建数据库\nroot@bce0a55bbc72:/# influx Connected to http://localhost:8086 version 1.7.10 InfluxDB shell version: 1.7.10 \u0026gt; 交互面板执行命令 InfluxDB 创建数据库和用户 创建数据库：create database jmeter_t2 查看数据库：show databases 切换数据库：use jmeter_t2 创建用户：create user \u0026ldquo;admin\u0026rdquo; with password \u0026lsquo;admin\u0026rsquo; with all privileges 查看用户：show users\n\u0026gt; show users user admin ---- ----- admin true 如果显示用户权限admin为true，数据库的准备工作就完成了\nGrafana 编写测试案例的时候发现，图表展示的效果其实没太多必要，接口的tps数据在命令行执行的时候已经能观测到，更多是想知道程序内部的耗时\n简单部署grafana控制台面板，导入配置文件对接InfluxDB\n控制台支持通过标签过滤测试结果，一般只需要配置一个InfluxDB数据库即可：\n应用名称 测试案例名称 docker run -d --name=grafana -p 3000:3000 grafana/grafana:7.3.1 网页版由于采样器间隔会导致计算的TPS和相关数值与Jmeter聚合报告不相符，参考链接：https://www.vinsguru.com/jmeter-real-time-results-influxdb-grafana/\n资料中也描述了如何自定义监听器\n后记 高性能的程序模式必然是 one loop thread，任何的锁、入队列和出队列，都会造成不必要的性能损失 核心业务逻辑的耗时大于引入其他代码的耗时，并发才能有效提高效率，核心耗时如果足够小谨慎引入其他代码 参考资料 Jmeter系列之Jmeter+Grafana+InfluxDB实时监控 influxdb官方镜像 grafane官方镜像 Jmeter官网 To install Apache JMeter in CentOS7 ","date":"2020-12-22T10:12:50+08:00","permalink":"https://ttf248.github.io/p/linux%E6%90%AD%E5%BB%BAjmeter%E5%8E%8B%E6%B5%8B%E7%8E%AF%E5%A2%83/","title":"Linux搭建Jmeter压测环境"},{"content":"线上生产环境操作系统，Red Hat和CentOS为主流选择。记录了两个系统生命周期的官网链接，并分享了从CentOS 8升级到CentOS 8 Stream的经验。\n前言 线上生产环境操作系统，目前国内的环境来说，Red Hat和CentOS为主流选择。前两年经历了Red Hat 6的退役，特此记录两个系统生命周期官网链接。\n正文 Red Hat Enterprise Linux Life Cycle CentOS 产品规范 Red Hat Enterprise Linux（RHEL）和CentOS是企业级服务器操作系统的主流选择。RHEL提供了稳定的支持和更新周期，适合企业级应用。CentOS作为RHEL的社区版，提供了相似的功能和稳定性，但没有官方支持。\n追更 发布这篇稿子的时候，我也想不到自己会在两年后来更新，前两天刚把日常用的虚拟机，从CentOS 8升级到了CentOS 8 Stream。生产上怎么选择，我不好多说，本地环境还是追求最新的版本。\nCentOS 8 Stream是一个滚动发布的版本，提供了比传统CentOS更快的更新和新特性，适合开发和测试环境使用。\n","date":"2020-07-21T20:02:35+08:00","permalink":"https://ttf248.github.io/p/redhat-%E5%92%8C-centos-%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/","title":"Redhat 和 Centos 生命周期"},{"content":"先谈点题外话，中国特色社会主义和资本主义的不同。从老一辈的口中，都听过要想富，先修路。中国的基础设置建设，这些东西都是国家在出钱，放到资本主义社会，这些都会承包出去，偏远地区，完全没有利益可言，也就不会有公司乐意承接。说太多呢，有点偏离当前文章的主题，普通人可能觉得贸易战对生活没太多影响，实际上，我国的高端制造业一直相对薄弱。本人从事的IT行业，内存、硬盘、CPU、显卡，组装一台电脑的核心配置，都是来自于国外的工厂，这些配件的费用也占用了整机价格的50%，高端制造势在必行。中国和美国的碰撞也是不可避免的。\n参考资料 始于2018的中美贸易战 中国制造2025 维基百科 2018－2020年中美贸易战，简称中美贸易战（英语：China–United States trade war），又简称中美贸易争端、中美贸易摩擦、中美贸易纠纷或美中贸易战，是中华人民共和国与美利坚合众国之间的一场贸易战。\n贸易争端源起于美国总统唐纳德·特朗普于2018年3月22日签署备忘录时，宣称“中国偷窃美国知识产权和商业秘密”，并根据1974年贸易法第301条要求美国贸易代表对从中国进口的商品征收关税，涉及商品总计估达600亿美元。2018年7月6日，美国对价值340亿美元的中国输美商品征收25%的额外关税。中国商务部同日作出反制措施，对价值340亿美元的美国输华商品征收25%的额外关税，其中包括美国向中国出口最多的货品大豆。\n中美双方曾一度于2018年5月达成暂停贸易战的共识，并发表联合声明寻求和解。但美国贸易代表办公室其后于6月16日公布了第一批针对500亿美元中国输美商品的征税清单，将原有10%税率提高到25%。中国国务院关税税则委员会随后作出对等报复，中国商务部亦重启对美输华多项产品的反倾销调查。7月6日，特朗普政府正式对第一批征税清单中价值340亿美元的中国输美商品加征25%关税，标志着特朗普对华关税政策正式实施（剩余的160亿商品随后于8月23日加征25%关税）。中国商务部其后在声明中指出，“美国违反世贸规则，发动了迄今为止经济史上规模最大的贸易战”。中国海关总署指，中方的反击措施已在美方加征关税措施生效后即行实施。\n12月1日，G20布宜诺斯艾利斯峰会上，两国领导人习近平与唐纳德·特朗普达成共识，同意举行为期90日的谈判，并在谈判期内暂停新增贸易措施。2019年3月1日最后期限到期后，美国方面宣布已有重大进展，并延长暂停新增贸易措施的期限。\n2019年5月5日，美国总统唐纳德·特朗普宣布对另外价值约2000亿美元，合共2500亿美元的中国输美商品征收25%的关税，该措施于6月1日起正式对到达美国港口的中国商品生效。5月13日，中国国务院关税税则委员会宣布自6月1日起对原产于美国价值600亿美元的部分进口商品提高到加征5%至25%的关税。6月1日，美贸易代表办公室宣布将美方加征25%关税时间推迟至6月15日，中国国务院关税税则委员会则表示中方加征关税举措于6月1日如期生效。\n6月29日，两国领导人习近平与特朗普在G20大阪峰会上举行会谈，同意重启经贸磋商，美国不再对中国产品加征新的关税。\n8月1日，因特朗普政府不满中国政府对美国农产品的购买进程，特朗普在推特宣布将在2019年9月1日起，对余下价值3000亿美元的所有中国输美商品征收10%的关税。8月5日，人民币兑美元汇率跌破7关口。同日，美国财政部宣布将中国列为汇率操纵国。其后，中国政府宣布暂停购买美国农产品，并于8月24日宣布对约750亿美元美国商品加征10%或5%关税、对美国汽车及其零部件恢复加征关税；而美国在次日也增加之前加征的3000亿美元中国货品的税率至15%，以及目前的2500亿中国货品加征的25%关税至30%作为反制，但其后被搁置。\n2020年1月16日，中美两国签署第一阶段贸易协议。\n","date":"2020-07-21T19:52:41+08:00","permalink":"https://ttf248.github.io/p/%E4%B8%AD%E7%BE%8E%E8%B4%B8%E6%98%93%E6%88%98/","title":"中美贸易战"},{"content":"作者从小对组装电脑充满兴趣，大学后开始接触硬件组装。推荐了硬件性能对比网站和选购建议，包括CPU、固态硬盘、机械硬盘和内存频率等。分享了硬件选购经验和注意事项\n缘·妙不可言 打小呢就想着组装一台自己的电脑，奈何经济条件不允许。好不容易熬到了大学，为了便于携带，配置的也是笔记本。如果非要有个具体的时间点，我是什么时候开始有组装电脑这个念想的，就要说到老家的图书馆。毕竟也是个市区级别的图书馆，不仅有电子阅览室（其实从没去过，据说是按时计费），还有个杂志阅览室，也就是在这里，翻阅到了《大众软件》、《电脑报》这类杂志，对接触电脑不多的我来说，堪称神级科普资料。看到打副本的章节，就想着自己弄个电脑，也去拉怪，当主力输出；看到黑科技呢，幻想自己照着书上的做，也能达到描述的效果（论黑客工具的使用）。虽说高中课业重，就我那会的认知，书要读，玩也要玩，过的也算是“天真烂漫”，打着去图书馆看书的由头，没事就拎着个小包溜达过去，市区不大，一般都是徒步走去图书馆。到了地，吹着空调，看着小说、漫画、游戏杂志，偶尔也看点正经的书籍。\n年纪大了就容易忘事，图书馆引发的还不算是初次萌芽。初中的时候，亲戚家组装过一台电脑，也不知道当初组装那台机器是干嘛用的。操作系统还是 windows 2003，游戏有系统自带的纸牌 + 帝国时代。各种“斗智斗勇”想着偷到钥匙，带着堂弟一起玩游戏。\n刚入初中，学校就有就计算机的初级培训，后来转学，也接触到了一点计算机竞赛的概念。等到了高中，NOIP混过一次。说道这里，就不得不提，校友的力量，高中的计算机大楼是校友捐赠的，包含计算机教学室+图书馆。其实那会也是国内互联网浪潮的初浪。校领导也支持参与计算机竞赛，毕竟前面两届的学长，好几位前辈通过计算机保送了重点大学。\n从未这样回顾过我和电脑这些事。也难怪我毕业后硬是从自动化专业义无反顾的转到了计算机行业，种子早已种下，局中人不自知而已。从小接触的多了，以为自己很厉害，其实也就懂个皮毛，最大的优势也就是最初的那份热情。\n硬件组装 多逛逛卡吧、chiphell、知乎电脑组装的板块，萌新能较为简单的给出一份自己需要的机器清单。2019年后选购CPU，经济条件不充裕的情况下，想要更高的性能，首选AMD。\n推荐一个常用的硬件性能对比网站：https://cpu.userbenchmark.com/，价格这块基本可以和咸鱼的美版做个对比。真大佬可以去咸鱼淘二手的，能便宜很多。如果不是很精通，不推荐去咸鱼，本人就购买了假内存，虽说目前使用没发现问题，不太确定太多了，型号和参数完全对不上。\nSN550 VS SN750 SN550 1TB容量和SN750 1TB容量差别就是，两者持续读写差一倍，一个850MB，一个1.6GB，但日常使用没区别，因为两者4K都一样。当然这里说的是1TB容量的SN550，500G和250G速度顺序读写更慢。其实我觉得只要不是不差钱的，日常使用买SN550就行，我没买这个最大原因不是因为它的顺序读写速度，而是它最大只有1TB容量，而SN750有2TB容量。对我来说，在不额外扩展的情况下，主板的M.2 Nvme接口比这些固态的差价更值钱\n综合网友的结论，入手一块转接板，B150 主板也能支持 M2 接口的固态。\n机械硬盘选购 机械硬盘目前价格趋于稳定，对于有大量存储需求的用户，需要选购一款合适的机械硬盘，频繁下载资源的用户推荐企业级硬盘，常见的有：\n西数金盘 希捷exos 大容量的机械硬盘推荐进行分区，频繁的下载操作固定在某个分区进行，日后出现坏道，可以集中在某个分区，废弃当前分区即可，能有效延长机械硬盘寿命。\n希捷系列官网介绍\n内存频率 日常工作的角度出发，频率不会对性能产生太大的影响。\n内存时序（英语：Memory timings或RAM timings）是描述同步动态随机存取存储器（SDRAM）性能的四个参数：CL、TRCD、TRP和TRAS，单位为时钟周期。它们通常被写为四个用破折号分隔开的数字，例如7-8-8-24。第四个参数（RAS）经常被省略，而有时还会加入第五个参数：Command rate（命令速率），通常为2T或1T，也写作2N、1N。这些参数指定了影响随机存取存储器速度的潜伏时间（延迟时间）。较低的数字通常意味着更快的性能。决定系统性能的最终元素是实际的延迟时间，通常以纳秒为单位。\n当将内存时序转换为实际的延迟时，最重要的是注意它是以时钟周期为单位。如果不知道时钟周期的时间，就不可能了解一组数字是否比另一组数字更快。\n举例来说，DDR3-2000内存的时钟频率是1000 MHz，其时钟周期为1 ns。基于这个1 ns的时钟，CL=7给出的绝对延迟为7 ns。而更快的DDR3-2666（时钟1333 MHz，每个周期0.75 ns）则可能用更大的CL=9，但产生的绝对延迟6.75 ns更短。\n现代DIMM包括一个串行存在检测（SPD）ROM芯片，其中包含为自动配置推荐的内存时序。PC上的BIOS可能允许用户调整时序以提高性能（存在降低稳定性的风险），或在某些情况下增加稳定性（如使用建议的时序）。\n注意：内存带宽是测量内存的吞吐量，并通常受到传输速率而非潜伏时间的限制。通过交错访问SDRAM的多个内部bank，有可能以峰值速率连续传输。可能以增加潜伏时间为代价来增加带宽。具体来说，每个新一代的DDR内存都有着较高的传输速率，但绝对延迟没有显著变化，尤其是市场上的第一批新一代产品，通常有着较上一代更长的延迟。\n即便增加了内存延迟，增加内存带宽也可以改善多处理器或多个执行线程的计算机系统的性能。更高的带宽也将提升没有专用显存的集成显卡的性能。\n参考资料 内存时序参数说明 ","date":"2020-07-18T14:33:46+08:00","permalink":"https://ttf248.github.io/p/%E7%94%B5%E8%84%91%E7%BB%84%E8%A3%85%E9%82%A3%E4%BA%9B%E4%BA%8B/","title":"电脑组装那些事"},{"content":"由于境内访问GitHub Pages较慢，作者申请了个人域名并购买了国内云主机供应商的CDN加速服务。配置过程中，作者遇到了www子域名无法访问的问题，最终通过删除泛域名解析并单独设置二级域名解决。作者还分享了CDN加速的原理和配置经验，以及使用Nginx反向代理的尝试和教训。\n背景 网站托管在GitHub Pages，某些众所周知的原因，境内访问GitHub Pages有点慢。故而申请了个人域名，购买了国内云主机供应商的CDN加速服务。在设置加速服务的时候，想到了自己还有开发机器，上面部署了docker、frp、k8s等服务，这些服务都有配套的dashboard，本着不浪费的原则，配置了几个反向代理，全部挂上了二级域名。\n当我美滋滋用着二级域名的时候，突发现www子域名无法访问了，阿里云上命名配置了DNS同时解析到www.xiangtianlong.com和xiangtianlong.com，尚未启用CDN加速的时候，两个域名都能正常使用。\n在配置CDN加速的时候，由于二级域名太多，启用了泛域名规则，统一路由到了开发机器，结果导致www这个二级域名也挂了，是的，你没看错，www前缀是个二级域名。实际网站部署在GitHub Pages，开发机器没有任何网站的缓存信息。\n至于为什么开发机器上没有部署站点，因为静态博客，配着GitHub提供的action，自动集成发布，真香。\n域名 非专业的web开发，对于域名的理解不涉及SEO和跨域问题。作为博客站点，裸域容易突出博客主的站点，说的就是我这种用汉字拼音当做域名的小朋友，加之当前移动访问居多，能少输入几个字符。\n电脑端能使用快捷键免去输入www和com\nCDN 阿里云和腾讯云的都用过，新人上手不难，腾讯云还有个视频单独讲解相关的概念。CDN加速的原理和京东仓库是一个道理，发售新商品，提前统一配送到全国各地的仓库，触发配送请求的时候，就近分发。\n回源地址：网站资源原始存放的地址\n缓存文件设置，浏览器F12，管理控制台，简单分析静态资源和动态资源\n全部0天有效期 .php;.jsp;.asp;.aspx 0天有效期 .jpg;.png;.js;.css;.woff2 1天有效期 腾讯云配置规则：\n缓存过期规则最多可配置10条 多条缓存过期规则之间的优先级为底部优先 缓存过期时间最多可设置365天 悲惨自述 以前也没用过Nginx，以为网站随便搜索就能明白反向代理的配置，结果有点混乱，折腾半天连个302跳转也没弄明白，结果屁用没有。就想着笨办法解决一下，DNS解析删除*模式的泛域名解析，单个二级域名进行独立设置。此时突然注意到了阿里云DNS解析有一个叫做显示URL跳转的模式，尝试了一下，这不就是我想要的302跳转。\n设置了第一个二级域名正常访问，等我设置第二个的时候，发现没用，都快怀疑人生了，等了一会突然就能用了，看来阿里云的DNS扩散偶尔也是会抽风的\n参考资料 为什么越来越多的网站域名不加「www」前缀？ 带www和不带www域名有什么区别呢? Docker nginx 反向代理设置 ","date":"2020-06-20T10:36:27+08:00","permalink":"https://ttf248.github.io/p/%E7%BD%91%E7%AB%99%E5%8A%A0%E9%80%9F%E5%92%8C%E5%9F%9F%E5%90%8D%E8%AE%BE%E7%BD%AE/","title":"网站加速和域名设置"},{"content":"本文介绍了Markdown的基本概念及其在各种软件中的应用，推荐了使用VSCode作为IDE，并列出了推荐的插件。作者分享了从Hexo切换到Hugo的经验，强调了Hugo的灵活性和自定义能力。最后，提供了一些快速上手新技术的建议，并分享了一个解决Hugo主题样式不更新的小技巧。\n前言 Markdown 一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档\n详细的Markdown语法本文不做额外赘述，推荐一本电子书，点击此处\n市面上很多软件都已经支持md作为书写方式。csdn博文系统推出了支持md语法的在线编辑器，在首次使用时，默认会有一篇关于md语法的介绍文章，笔者觉得还不错；印象笔记在2018年增加了对于md笔记的支持，快捷栏中有各种md标记的选项，用起来和编辑普通的文章差不多，整体的交互流程属于新手友好\nIDE推荐 编写本文的时候，已经是2020年，vscode你必然是听说过的，毕竟能想到使用git page来搭建博文系统的都是业内人士。早些年的时候，sublime、atom也是不错的选择，经过两年开源社区的推动，vscode发展迅速，已经逐渐成为新手入场的首选。\n微软巨头和开源社区的关系从割裂的状态，成功跨入蜜月期：拥抱开源；笔者所在的公司在最近两年也积极的引入Java体系，换言之在业务开发上，如今的Java生态在国内属实真香\nvscode插件推荐 插件都有自带的Readme，介绍基本用法，核心功能，部分插件作者还提供动态效果展示图\nPaste Image，配合hugo的图片插件方式，很便捷的就能引入图片\n快捷键没记住，打开vscode快捷键管理菜单，搜索md，多看几遍；重看一遍插件使用说明\nhugo 笔者从hexo切换到了hugo，爱折腾是我的天性，终归是耐不住性子安安静静写文章\nhugo支持在单独的文件夹放置图片和md文档 academic主题在设计上支持多种各式的文章样式 各种便捷的自定义拓展 academic 官网默认exampleSite，menu引入采用#组件的方式，推荐使用url\nurl的模式，点击导航栏能实现单页的跳转，而非在首页进行滚动，这点纯属个人喜好\n样式上：随笔、演讲、电子书 灵活性：自定义整体风格、自定义css样式 这款主题对于中文的支持还不是很完善，主要是从视觉的角度来说，字体大小不太符合中文阅读习惯，hexo的开发人员大部分为国人，在这点优于hugo\n但是呢，自己动手丰衣足食，浏览器审核元素。定位了到了元素，想要知道需要修改的css样式名称，侧栏点击Insert Style Rule Below，即使嵌套多层的css，也能轻松拿到节点名称。\n引入custom.css 引入custom_js 主题内置的语法高亮设置，官方链接 结尾 小朋友又要吐槽了，你怎么从头到尾都说的模模糊糊，细节什么的都不提\n我想说的是，有下面这些东西，足够你用了：\n官方手册 插件说明 快速上手新技术，推荐先阅读官网文档，粗读不求一遍看懂，至少心里有个数，搜索引擎出来的结果，不一定和当前最新的版本保持一致，也许会产生误导。翻阅新书也是如此，先看目录，搞清楚作者准备讲什么，有时候读书先读序，部分国外的著作翻译成中文，译者的序其实涵盖了书籍和核心内容。\n彩蛋 切换hugo academic内置风格样式，发布到站点，访问时，风格没有发生变换。聪明的小伙伴已经想到了，清空本地浏览器缓存，能解决问题。机智的我：F12开发者模式，切换到network，勾选disable cache，刷新，搞定！\n","date":"2020-03-31T13:54:27+08:00","permalink":"https://ttf248.github.io/p/%E5%8D%9A%E5%AE%A2ide%E7%8E%AF%E5%A2%83%E5%92%8C%E7%A2%8E%E7%A2%8E%E5%BF%B5/","title":"博客IDE环境和碎碎念"},{"content":"使用 GitHub Actions 自动部署 Hugo 博客到 GitHub Pages 和 Gitee。\n背景介绍 昨天更新博客时发现travis服务不可用，查看travis网页，发现进度卡在拉取源码的时候，灵光闪现想到了github之前推出的action服务\n由于那会比较忙，同时也需要申请才能使用action，现在已经开始正式上线，周末闲来无事，尝试一个新玩具？\n官方资料大家自行进入网站查阅即可，本文就不做更多的转载了，如果之前用过kubernetes会觉得，action的yaml文件配置和kubernetes很像。\n关于的入门的教程，或者说是中文的介绍资料，推荐搜索阮一峰的博客，有两篇文章，第一篇是基础的语法介绍，第二篇是一个实际的案例。\n正文 需要的知识点\ngithub secrets action 语法 核心的job使用现有的组件完成，推送到国内gitee使用command实现，command这部分比较粗暴，都是强制推送，沿用了使用travis的逻辑。\nname: github pages and gitee pages on: push: branches: - hugo jobs: deploy: runs-on: ubuntu-18.04 steps: - uses: actions/checkout@v2 with: submodules: true - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: 'latest' extended: true - name: Build Github and Gitee ## 单个step只能写一个run命令 run: hugo -b \u0026quot;https://www.xiangtianlong.com/\u0026quot; -d \u0026quot;github_public\u0026quot; \u0026amp;\u0026amp; hugo -b \u0026quot;https://www.xiangtianlong.com/\u0026quot; -d \u0026quot;gitee_public\u0026quot; \u0026amp;\u0026amp; ls - name: Deploy Github uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.BLOG_TOKEN }} publish_dir: ./github_public publish_branch: master cname: xiangtianlong.com - name: Deploy Gitee run: cd ./gitee_public \u0026amp;\u0026amp; git init \u0026amp;\u0026amp; git config user.name \u0026quot;TianlongXiang\u0026quot; \u0026amp;\u0026amp; git config user.email \u0026quot;tianlongxiang51@gmail.com\u0026quot; \u0026amp;\u0026amp; git add . \u0026amp;\u0026amp; git commit -m \u0026quot;Update TianlongXiang's Blog\u0026quot; \u0026amp;\u0026amp; git push --force \u0026quot;https://xiangtianlong:${{ secrets.GITEE_PASSWORD }}@gitee.com/xiangtianlong/xiangtianlong.git\u0026quot; master:master 后记 从官方市场提供的action来看，目前支持的玩法挺多，构建docker镜像以后也能不再依赖dockerhub提供的服务\n查阅hugo的issue，发现使用github action自动部署git pages，最终发布的网页需要在master分支，如果是部署在其他分支，在setting界面，github会提示部署的网页存在语法问题\n实际上只是由于hugo的源文件放在了master分支，github当作jelly博客的源码进行检测，无法检查无法通过导致的报错\n解决方案也简单，hugo源码文件放到其他分支，静态文件发布在master分支\n","date":"2020-03-29T02:11:33+08:00","permalink":"https://ttf248.github.io/p/%E8%87%AA%E5%8A%A8%E9%9B%86%E6%88%90%E7%B3%BB%E7%BB%9F%E5%88%87%E6%8D%A2/","title":"自动集成系统切换"},{"content":"我希望到了二十年后，我是个可爱的老头，陪着一个可爱的老太太。不求大富大贵，身体硬朗，能到处去走走。\n视频原稿 优酷搜索即可，后续不再提供链接\n文字稿 我说10年后可爱的老头是我，我要努力的去做一个可爱的老头，未来的好，中国一定是要有好老头好老太太的中国。我即便10年后60岁了，也是这个世界第三国度里头最年轻的那一个。\n坦白的说，大家看我50岁的中国的男人要都这样的体型的话相当不错，但是在这个体型的背后是我信奉的一句话，越自律越自由！停了雨那会我都想去跑步去，明天下午我就会踢球。50岁了，依然可以打大场，不是开玩笑，而且经常是跟专业的一起踢。可是背后是什么？背后是自律，我剩下的那些天在跑步，而且跑步有人会觉得是非常枯燥的事情，越自律越自由，我因为自律，所以我可以自由的奔跑，从不听音乐，因为我觉得听自己的呼吸是跑步中最美的音乐。\n另外我基本不跑跑步机，然后有很多人北京雾霾那么严重，我一周跑5天，有两天我已经留给雾霾了，然后跟别人不一样的地方开个玩笑说，可能就是我从来不间断。我每个月都会在日记上，就是在我的阅历上跑了一天就画一天，每个月从不会少于18天，跑步的时候都是嗖一下就过去了，跑步的时候我又我又不戴眼镜，但是更重要的是我每周还在踢球，我带我的研究生最后一堂课一定是到我们家那一天的课，就一个主题叫趣味，我觉得趣味太重要了，我从来不跟没有任何乐趣和爱好的人打交道。\n敬而远之，这样的人太可怕了，没乐趣你就觉得您有什么乐趣，我还真没什么了，您喜欢什么工作？我天今年年初的时候，我的一个学生研究生分在中国新闻周刊，我们有一个专题叫致，10年后我的研究生每年毕业的时候，最后一篇作业都是让他给10年后写一篇文章，然后我给留下来，10年后我在给他们陆续展开，我也写一下50岁写给60岁，60岁是一个过去我从来没有想到过的远方远的在地图之外，但转眼就是我的下一站20岁写给30岁我的学生们，那是春天写给夏天的情书，但是我50岁写给60岁，可就是夏末写给秋天的喃喃自语了，我现在写给10年后是从整个世界慢慢的写给自己的一张床，一顿饭，自己的家人的身边，这很正常。\n但是60岁做一个什么样的人，我的题目很明确，在舒心的序里头这篇文章很长，我说10年后可爱的老头是我，我要努力的去做一个可爱的老头，中国想要可爱不仅取决于将来有更多像公民一定要做成公民，不再是小老百姓的年轻人，有朝气的年轻人，懂规矩的年轻人，未来的好中国一定是要有好老头好老太太的中国。目前中国超过60岁的人已经超过了2.3亿，10年后肯定过三个亿，也就是说仅仅从60岁以上的人口来说，中国人口如果单独是一个国家世界前5，甚至有可能世界第三，想想看多么可怕吗？\n我倒不觉得。我不知道大家今天有没有看网上的一个表，中国各个省市直辖市的平均寿命，上海和北京都超过了80岁，平均寿命男女全算上。平均寿命肯定是男的占了女的很大便宜。那也就意味着我即便10年后60岁了，也是这个世界第三国度里头最年轻的那一个。未来。女性如果55岁退休到平均年龄80岁，退休后还25年，男性60岁退休，到平均年龄80，退休后还20年！您不干点什么光跳广场舞。而且我可以说今天跳广场舞的大姐和大哥们是时代带给他们的文化习惯和娱乐方式。\n再隔20年，下一代人可能还会有很多跳广场舞的，但是会大量减少。因为下一代人不再是集体活动的积极参与者，就像岁数大的愿意旅游跟团走，现在年轻人越来越自由行、自助游，将来还会有广场舞，但是一定范围也在缩小，这没有好和不好，只有时代在洗牌，在不断的去变。我60岁的时候是作为最年轻的团队当中的一员，我该去做一个怎样的人？中国画说60耳顺，我相信我那个时候绝对不会听，什么都高兴，依然听到不该提，高兴的还会不高兴，更重要的是要为年轻人去做什么！\n要为好的事情去做什么？不懒惰，不轻易的妥协，该反对的反对，年轻人有可能伤他利益，你能不能挡在年轻人的面前？我现在经常要前后去照这面镜子。我的一个好朋友已经离世了，陶伟那时候经常聚会，在我们家聚会，有给我讲过一次真事儿，我们就集体痛，陈老一代那帮人什么东西都在家里头攒着，你说破盒子，你弄30多个塞床底下干嘛，你要告诉他，这件衣服500多买的，完了，供起来了，每天点香。因此我们这代人都习惯了跟自己的父母斗智斗勇，700多买回来得多少钱？\n220。但是容易出事儿。陶伟有一次花400多给他爸买了一个T恤衫。这T恤衫真不错，多少钱？99那行我穿上了。第2天惨了，晚上回来夸拍给陶伟400块钱，替我再买4件，今天我穿出去之后，你张数李大爷全觉得好，后来说这种撒谎的风险是很大的，将来你别做这样的老人，我不说具体的哪一个具体的人在医院骨科，老年人摔骨折了，最后发现很重要的原因是穿的地摊上买的鞋，当然这我谈的还仅仅是物质层面，老了依然要有精神生活藕，依然要有好奇心，依然愿意为年轻人挡风遮雨，活一天开心一天。\n我觉得我很好奇和兴奋的等着自己60岁到来的时刻，我觉得那是一个美好的时光的开始。\n谢谢各位。\n","date":"2020-02-15T11:28:28+08:00","permalink":"https://ttf248.github.io/p/%E6%9C%AA%E6%9D%A5%E7%9A%84%E5%A5%BD%E4%B8%AD%E5%9B%BD%E4%B8%80%E5%AE%9A%E6%98%AF%E6%9C%89%E5%A5%BD%E8%80%81%E5%A4%B4%E5%A5%BD%E8%80%81%E5%A4%AA%E5%A4%AA%E7%9A%84%E4%B8%AD%E5%9B%BD/","title":"未来的好中国一定是有好老头好老太太的中国"},{"content":"很常见的词语信息碎片化，自从高中毕业，抛开看小说的时间，我已经很长时间没有认真安静下来读一本书了，有时候回头看看，工作这么长时间，我还记得自己每年做了什么？很多时候，到了下半年，我已经忘记上半年的很多事情。写博客是个好习惯，纵然我写的很多东西不上台面，并没有什么关系，原本就是写给自己看的。\n最忠实的的读者是我自己\n视频原稿 优酷搜索即可，后续不再提供链接\n文字稿 每一个自己的18岁都像是一个期待和追问的目光，每一个人偶尔要拿自己的18岁来问问自己，你是当初自己要活的那个样子吗！我很怕现在每个人都有无数的朋友圈，没朋友，天天在聊天，没人谈心，知识获取无限，离智慧很远，每个人都应该用你的18岁问问自己，骗别人太容易了，骗自己太难！\n你我觉得每一个自己的18岁都像是一个期待和追问的目光。你骗得了别人，你骗不了自己的18岁，你的今天是你18岁要的样子吗？我觉得还好。在今天物质名气等等很多东西比我18岁想得多得多得多的，得到了，但是另一方面永远在路上，18岁的我在广播学院读新闻系，我希望成为法拉奇成为最好的记者，我今天依然在路上，但是这也就是好多人说白老师，你怎么还在CCTV因为我想成为好记者。新闻还在。这是我18岁的目光，所以我觉得每一个人偶尔要拿自己的18岁来问问自己，你是当初自己要活的那个样子吗？\n这是真骗不了别人的。这是我18岁时候的样子，一转眼就过去了32年，每一个到北京来上大学的人都会有这样的一张合影，在那个时代，天门广场皱巴巴的西装，然后校徽别在胸前，因为那个时候大学生少，别校徽，觉得特骄傲，那个时候的头发很长，但是还是很喜欢18岁时候的样子。很多年过去，我突然发现我庆幸于18岁所面对的那些东西，因为悄无声息的它塑造了我。1986年那一年5月8号，我在王府井书店买了朦胧诗选，那一年在工体听了崔健的一无所有，结果今天我突然发现我的文字风格受到最大的影响，包括我的性格就是朦胧诗、摇滚乐和古龙的武侠小说的影响。\n18岁你遭遇了什么？你就可能携带什么上路。我特别想知道今天的18岁都在遭遇什么？是不是如刀劈斧凿一样的在雕刻你。但是他用了什么工具？它打磨了你什么样的样子。我很怕现在每个人都有无数的朋友圈，没朋友，天天在聊天，没人谈心，知识获取无限，离智慧很远，知道什么都不知道，看似人人都在说个性。可是以我作为一个旁观者，我发现现在的年轻人非常一样，这怎么办？18岁你该让他遭遇什么？我非常喜欢1986年，因为1986年才是解决1966年的最好方式。\n1966年文化大革命靠76年打倒四人帮来结束，有偶然性，只有靠1986年的这种启蒙和人性的苏醒和每一个人的成长，才可能真正的把让你担心的基础去刨掉，我觉得我们还要经历启蒙，我们还要更要经历对人性的充分了解。中国社会不管经济发生多大的这种进步、变化储备，如果没有真正补上对人性了解的这一刻，然后顺应人性管制人性中恶的那一面，激活人性中善的那一面，未来依然会有很多让我们担心的东西。所以我的18岁也是这个时代的18岁，走的太远，别忘了当初为什么出发，现在已经被浓缩成不放初心这4个大字。\n所以我觉得不管走多远，每个人都应该用你的18岁问问自己，所以18岁留张照片是很好，经常拿出来问问自己，别人说什么没有用？骗别人太容易了。骗自己太难了，我刚才说我18的时候对今天20岁的人说说，你永远要让自己的18岁成为观看你的一双眼睛。另外20多岁刚才我也说过，多去尝试开很多扇门，你不知道哪个更适合你自己的，在哪扇门的后面，现在的中国很诧异，经常有20多岁的老人，然后有很多70多岁的年轻人。\n谢谢各位。\n","date":"2020-02-15T11:19:33+08:00","permalink":"https://ttf248.github.io/p/%E6%88%91%E7%9A%8418%E5%B2%81%E5%8F%AF%E8%83%BD%E8%B7%9F%E4%BD%A0%E4%BB%AC%E4%B8%8D%E5%A4%AA%E4%B8%80%E6%A0%B7/","title":"我的18岁，可能跟你们不太一样"},{"content":"讲述了作者对记者职业的看法，强调记者应具备社会良心、知识储备和长跑精神。作者还分享了自己在50岁时的感悟，包括对好奇心的保持、物质与精神的平衡以及对未来的思考。\n视频原稿 优酷搜索即可，后续不再提供链接\n文字稿 一个最好的记者就是首先有社会良心，第2个有知识储备，第3个长跑。不能我跑100米不过瘾了，跑了。我觉得这三者结合，人们期待的是疫苗安全的隐患彻底给我解决掉，这就像当初的奶粉事件一样，实在总是在出了问题、解决问题，彻底解决问题的这样逻辑循环当中前进。否则要记者干嘛？\n我觉得一个最好的记者首先有社会良心，第2个有知识储备，第3个长跑不能我跑100米不过瘾了，跑了。我觉得这三者结合我今年50整，你就明白我好像适合干新闻。我天然跟中国的改革40年紧密的捆绑在一起，我30岁生日，站在了松花江的岸边那一天，40岁的时候，2008我的生日是在奥运的直播当中进去的，又在奥运我的直播当中出去的。今年50岁，全国在纪念改革开放40周年，所以的确有一个对应，如果说大时代40岁，中国的改革40岁到底是不惑还是困惑？\n我觉得走过了40年的道路的中国，在物质方面已经给予了大家足够多的东西，给予了国家足够多的东西，但是焦虑和困惑增加了，并没有减少，我们以为强大了富裕了就一切OK了，结果发现物质不过是打了一个底，原来在物质上脱贫是最容易的，但是在精神上富裕起来，并且成为大国真的很难。美国都开始打你高科技了，咱要打人农产品了。这个世界上一直存在着一种叫老二不容易当！在美国这修理了多少个2了？因此我们必然要经过一个漫长的岁月，把这种二不是一变成超越自己，我不可能什么都得到。\n我很幸运的是25岁开始做电视的时候，首先是从人物采访开始，我接触了大量的几百上千的带着各种光环的人物，那个时候年轻都觉得这种光环一定让她们都很幸福，结果靠近她们的时候发现no，光环和他们的幸福没那么大关系，甚至有的时候成反比。这两天我刚看完郭沫若的最后29年，郭沫若几乎没挨过整，贵为国务院副副总理、什么政协副主席、副委员长等等。但是，自己的两个儿子一个自杀，另一个可能是被从楼上扔下来死，他会幸福？\n你拿什么去衡量幸福？在自己六七十岁的时候，接连两个儿子在几年之间离开自己，副总理就能够让她幸福。有很多名人字画就能够让人幸福，自己安全的度过了很多岁月，就能够幸福。要什么？所以我觉得看人读书最好的镜子。说句稍微重点的话，我觉得我们现在很多人的焦虑就来自于想的太多，书读得太少。这是杨绛老人给一个年轻人的回复，不读书都指望快餐，拿个手机就打算找到大力丸。怎么可能？我是在一本书笨笨的过程当中学会聪明的，减法是在书越来越多读的情况下做的减法。\n所以我希望我不能指望所有的人，但我希望比例在增加，越来越多的中国人能够去在读书中读出更好的自己，这才是最重要的。没有谁坐在地上凭空仰望星空，把所有事都想明白了，我做不到。但是我可以去照镜子，几年前BBC的新闻主播来北京，号称BBC最牛的新闻主播，然后有好事者在国际饭店组织了一个中国新闻主播和他的对话，我们俩对话。这哥们在对话过程中问了我一个问题，他说你觉得BBC应该跟CCTV学什么？我先开了个玩笑，我说当然首先要学中文了。\n接下来我开完玩笑说，我说BBC最该跟CCTV学的是对这个世界的好奇。我说我们这几年快速的去到世界去不？各种记者站，我们现在已经超过了70个记者站，我们觉得自己一个学生每当看到国外新鲜的东西，都觉得非常好奇，我们带着巨大的好奇之心在观察这个世界，而BBC已经把英国本身当成了世界了，你们不再好奇了。老哥一拍桌子，你说的太好了，我们缺乏的就是这个东西。2007年我去日本采访他的一个作家作家跟我说了这样一句话，他说日本这个国度除了没有希望，剩下什么都有，后来明白了，这句话说得真深，换个角度来说，10多年前我觉得中国是除了希望好像剩下什么都缺，但是就不缺希望，每个人都觉得前面有奔头。\n但是会不会有一天我们也变成了一个除了希望什么都有的富裕国度。坦白的说，我非常担心中国走到一天是负的，什么都有的时候才觉得自己真穷，我50岁的时候就唯恐自己成为一个一切物质条件都可以得到满足，却成为一个非常贫穷的人。在我们的现实生活中，高学历的、没文化的人很多，存折上有无数个数字的穷人很多，这才是这个时代的问题。真穷是不可怕的，因为前面有奔头有希望。这就是我说道德赤字和人性亏损的原因所在，所以我觉得科学家之所以发明了很多的东西，不是说一开始就承载着伟大的什么使命等等，我觉得好奇。\n好奇我能弄出来他吗？所以我始终在50岁左右的时候就开始督促自己要更好奇，所以我都很开心，我现在很烦的一件事就是坚持，刚才聊天的时候在说您还在坚持，我说别我说一旦坚持离死不远了。过去我们都说坚持就是胜利，中国足球只要坚持黑色三分钟，坚持就咬牙了，没乐趣了，没方法了就靠坚持了，坚持有的时候很重要，但是相当多的时候这句话要有AB面。我很怕我在做一件某件事情的时候是坚持，比如说这会跟大家聊天的时候，我就坚持把剩下说完，其实到现在我的时间都到了，可是我觉得好奇，跟大家的交流，我会说成什么样？\n给自己一个很小的关键词，但是你自己跟大家的互动去聊天，我觉得在50岁的时候，只要你还能保有很大的好奇，没问题，我喜欢所有好玩的东西，但不一定跟现在最好玩的东西，今天的时髦有可能一转眼。每年都有流行词，您还记着几个？今天的互联网某个媒体可能10年后是传统媒体想过吗？所以好玩的东西永远有它好玩的内在的东西，我尊重每一个大家的喜欢，那一定有他的道理，但是长期下来看，最后发现中国人最喜欢的还是打麻将，当你也喜欢吃快餐的时候，做大菜的饭馆自然会慢慢的倒闭。\n很多东西不仅仅是发个感慨就过了。您每天让在手机碎片化的阅读是多少？您长一点的阅读有多少？但是这也是一个过程，手机正在成为我们的手铐。所以我觉得看越短的东西多，慢慢人也会变得短视，但这也是一个过程，我从不担心内容为王。还会回来，您会每天娱乐至死，一直到自己的40岁，就像我看见十几岁的孩子喝可乐，你劝他少喝一点，但你知道他一定会喝，但是另一方面我又乐观，40岁他一定会回到茶的世界里来，这就是中国人的一生。\n很正常，但是我希望接下来的转变会更快一点。我们就是发个感慨，现在的调查记者这么少了，您不看调查了。\n谢谢各位。\n","date":"2020-02-15T11:08:38+08:00","permalink":"https://ttf248.github.io/p/%E8%BF%99%E4%B8%AA%E7%A4%BE%E4%BC%9A%E9%9C%80%E8%A6%81%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84%E8%AE%B0%E8%80%85/","title":"这个社会需要什么样的记者？"},{"content":"补充的读后感基本都是2021年随手写进来的，白岩松老师的演讲稿转文字时间，那会还是疫情刚开始的时候。不要说二十年之后，一年后、两年后，世界的变化总是超出人们的预料。现在国内的疫情已经结束尾声了，国外的疫情依旧闹腾。关于足球，几年国足踢得不错了，教练也敢放手进攻，比起当年懵懂的时候，陪着老爷子看球有点意思了。一个国家队的比赛，让老人都懒得看想要换台，是什么样的体验？\n视频原稿 优酷搜索即可，后续不再提供链接\n文字稿 你对中国足球还保持好奇吗？好奇，非常好奇，还能差成什么样？所以你发现中国足球踢不好有很多原因，其中的一个原因就在于谁都怕把球丢自己这儿，传给别人，自己就算了，没有这种玩法。\n当然这只是其中很小的一个原因，说20年的足球，20年后中国足球仿佛特遥远，第1个扩军了变成48个了，中国有可能去，但是依然有可能不去，一个国家队的最佳年龄是2630，那20年后也就是今天6岁到10岁的孩子，20年让你觉得特乐观，20年后肯定行了，我一说到今天610岁，您马上表情凝重了。所以因和果种豆得豆，我们今天在种什么？我们今天差点种让国家队踢联赛的大豆，长出来的会是什么？谁出台这个动作，谁就要作下课的准备，这是违反规律，所以我没想那么多。\n但是真应该想想今天6~10岁的孩子，他们在踢球吗？您就知道20年后中国足球啥样？\n","date":"2020-02-15T10:59:32+08:00","permalink":"https://ttf248.github.io/p/20%E5%B9%B4%E5%90%8E%E7%9A%84%E4%B8%AD%E5%9B%BD%E8%B6%B3%E7%90%83%E4%BC%9A%E6%80%8E%E4%B9%88%E6%A0%B7/","title":"20年后的中国足球会怎么样？"},{"content":"人做事，首先需要的就是问心无愧，这样睡觉踏实，能有小毛病，大是大非的问题上，最好不要放错。如果真的做错了，应该是尽力去挽救，不是藏着掖着，想着让自己忘记，人时善忘的，也是记性很好的物种。心安是归处，能对得起自己的反问，活的轻松一些。\n视频原稿 视频原始链接点击此处，如有侵权，联系本人删除，此文仅做文字稿翻译\n文字稿 我有八个字说的比较重，我觉得我们现在是道德赤字，人性亏损，时代总是在出了问题解决问题，彻底解决问题的这样逻辑循环当中前进，你要有耐心去等待它的洗牌。对于中国这样一个国度来说，很多东西是一个缓慢的洗牌的过程，所以别悲观在变，在洗牌。\n这两天中国都在跟两个台风做斗争，一个台风是无形的，一个台风是有形的，无形的台风就是疫苗，它冲击的是我们内心安全的堤坝。另一个台风中国很少有从上海登陆，然后让北京和天津遭殃，三个直辖市共同面对的台风几十年没有过。这是题外话，接下来你就要去思考的是你独善其身，你发生了很大的变化，你拥有了很多的答案，周围的环境不变话，你会幸福吗？我有8个字说的比较重，我觉得我们现在是道德赤字、人性亏损，这才是目前最大的赤字和最大的亏损。\n但是人们期待的是疫苗安全的隐患彻底给我解决掉，这就像当初的奶粉事件一样，所以有的时候你要多看看历史，也明白你知道美国的食药监局的建立和形成一道完善的法律，也与当初的奶粉、乳制品不安全紧密相关。所以三鹿奶粉的事件在逼迫中国在乳制品方面发生了很大的变革，疫苗不敢说接二连三，但是这一次我希望它是一个中止。所以你要知道时代总是在出了问题、解决问题，彻底解决问题的这样逻辑循环当中前进，否则要记者干嘛？否则要公民干嘛？\n所以我觉得我们每一个人能做的事情就是关切。但问题是中国的人太容易遗忘了。就像我刚才说的，撞完人家车来，咱停路边撒腿就跑了，一车的人没有人阻拦。我们的邻居、我们的同事有很大的比例是这样的人。所以要慢慢改变。而我们作为一个普通的民众，能做的事情就是关注他，不忘记。我觉得不是缺乏什么是过程，在吃不饱穿不暖的时候，你天天跟人谈理想，我觉得没有说服力，但是你等他吃饱了穿暖了，都把自己吃成了世界糖尿病第一大国，高血压第一大国，等等很多个第一大国，你就发现中国人开始跑步了，中国人开始减肥了，你问在座的各位姑娘，有谁没有经历过，我不大吃一顿，我就没有劲儿减肥的残酷经历，这就是一个小转变。\n我们所谈到的精神层面一定也是这个道理，当你吃饱了穿暖了，要开始跑步，要开始减肥的时候，慢慢精神的需求也会随之增加。你比如说我以前抽烟，但是当我开始跑步之后，稀里糊涂的突然我就有一天发现我20多天没抽过烟了，我再没抽过烟。当然我也不会特意说，我就把它彻底戒了，我觉得太太仪式感了，不排除一年当中还会抽两三根烟。当你生活方式在改变的时候，有很多当时东西随之会改变，我觉得对于中国人来说，你要有耐心去等待它的洗牌。\n越来越多的人感觉自己不幸福，不会放纵自己不幸福的。虽然抑郁症在增多，但是另一方面不就有越来越多的人也在去寻找积极的活着的方式吗？这个时候精神层面的东西就会增长，所以别悲观，你看同样的一件事，看你怎么看。我在街上经常看到开车加塞的，我很沮丧，一转眼我就乐观了，因为另一边排队的比以前长多了，这就是这样的一个过程，在座的各位在这样一个下完雨后的晚上，居然愿意到这个地方来聊这么多没用的东西，这不也是很好玩的事情吗？\n这不也是一种转变，所以有很多东西需要换一种思维方式去想，当然我觉得将来慢慢要增长的东西很多，比如说你说在创业，谁一生都是创业，所有人的一生都是创业，我们现在赋予了创业太时代感的东西，其实创业从来都在。苏轼不是创业吗？李白不是创业吗？一生都会有很多的创，最后创出了自己的品牌，绝大多数没创出来没关系，只要你活得足够有味道，而且你觉得值。我现在觉得中国特别缺乏的是好的失败是另一种成功的价值观。中国人只接受成功的结局，但是另一种好的失败是一种成功，不接受。\n我觉得那就很难，所以你发现中国足球踢不好有很多原因，其中的一个原因就在于谁都怕把球丢自己这传给别人自己就算了，没有这种玩法，当然这只是其中很小的一个原因。所以我觉得到了我这个岁数过去30岁的时候，在序言里头写透明快乐里头写不着急，到现在50岁有一点急，因为时光太匆匆了，太快了，你期待得很多东西还没有变成现实。但可是另一方面还是明白，对于中国这样一个国度来说，很多东西是一个缓慢的洗牌的过程。你看着父辈，有的父辈是红绿灯为无物，但是偶尔就会看到孩子拽着他爸。在变，在洗牌，所以我觉得要有点耐心。\n","date":"2020-02-15T01:20:34+08:00","permalink":"https://ttf248.github.io/p/%E9%81%93%E5%BE%B7%E8%B5%A4%E5%AD%97%E4%BA%BA%E6%80%A7%E4%BA%8F%E6%8D%9F/","title":"道德赤字、人性亏损"},{"content":"国家总的来说是在变好，变富强，如果人的虚荣心没有这没强。回顾九十年代到到现在，在我接触的家庭中，大家的生活都是变得比以前好多了，与此同时富人也是更多了，市场化经济的发展过程中，不可避免的出现了贫富差距扩大。\n大家常说的阶级固化、上升通道被锁死，这些是当前世界的通病的，我党在人民的基本福利待遇、社会保障上做出的贡献，这些东西，大家也应当看在眼里。小日子会越来越好，你不想买房子，你可以租房子；孩子读书也存在教育资源分配不均的问题，有时候需要做出取舍，你是想要更好的工作机会、工作环境，还是更多的时间陪伴家人，不要把你自己的想法强加在他人身上，包括你的孩子、家人。坐下来，好好谈谈，生活总归是越来越好的。\n视频原稿 视频原始链接点击此处，如有侵权，联系本人删除，此文仅做文字稿翻译\n三十岁 今年我已经整整50岁了，过去没想过，我觉得这就是老头。现在才发现还真是老头，这是30岁时候的样子。30岁的时候不觉得自己很年轻，很好看，50岁的时候回头一看真不错，30岁最大的人生感受是什么？回头看。我觉得是减法，关键词就是减法。从某种角度来说，痛并快乐着也是一种减法，把很多东西经历的想过的写出去，然后留在那，去新的白纸上，去跑步了。但是对于我来说30岁我觉得的确无论是从自己还是对于各位的提醒来说，做减法都是非常重要的。\n我现在在带东西联大的学生，我经常提醒他们，在30岁之前要玩命的做加法，要去尝试，你不知道自己有多少种可能，你也不知道命运将会给你怎样的机缘。所以不是你怎么知道，但是有的人就在20多岁的时候拼命的事，各种加法，但是忘了收，忘了到一定的时候要做减法，我觉得30岁左右是人生非常重要的一个，要在做了一系列加法和四处乱跑之后，要做一次减法的重要时间，否则就晚了，为什么要做减法？你不是所有的都适合，也不是适合你的，所有的事，你都该去做。\n8条线拴着你，你能跑多远？可能会互相牵制。\n在30岁的时候，我已经被破格提升，也就是说，学术的话叫教授，记者的话，叫高级记者。我29岁就被破格了，到现在这样的事情已经很少了，但是在那个时候又开始感到了一种巨大的困惑。到2000年的时候做悉尼奥运会，掌声也很多，我突然觉得一切都不太对劲了。我要自己问自己，你究竟要做什么？哪些东西是要抛掉的？那一年我做了非常重要的一个减法，我停了自己的节目，停了一年，没有任何出境，当时有人劝我说主持人这行，您只要一个月不出镜还凑合，您半年不出镜就没人记得你了，我说我这张脸真够廉价的。\n那一年开始去研发新节目。这是在出完了痛并快乐着之后，01年我整整停了一年。今天所走的一切其实都感慨于那个时候的做减法。我那个时候要问我可以做很多东西，我去做体育，我可以去做E了，可以去做很多其他好玩的东西，做制片人等等。但是我说不，我发现我只能做新闻，我也最该做新闻，在，然后我当时是三个栏目的制片人，我在一夜之间都辞了，也才成了今天的我。我单纯了。前几天跟同事聊天，我还说我说30来岁的时候做的一个非常重要的决定，不仅仅是很多可做的，但是我觉得我就是打新闻，这口深井，很多的职位有可能要提拔你当副主任了，我给拒绝了，回到了一个普通百姓的基础上。\n到现在为止，我是中央电视台连股级干部，都不是绝对本科毕业的群众。你了解我们的体制，但是我拒绝了。我就想看看一个本科生能走多远，一个本科生的学历，为什么不可以不断的去学习，让自己去带研究生吗？对，我现在带研究生，每年要带11个，这都是一个减法的结果。我觉得这当然是回过头来的一个感慨了。另外在年轻的时候，特别容易在奔波之中，最后就产生了一种感受什么呢？一切我都该得到，只要有哪个没得到，只要有哪件事有点缺陷，我就心里特别不舒服。\n在座的各位千万别也要学会做减法，就是在那个时候快到30岁的时候，28岁的时候，1996年看奥运会，我编出了一句话，缺陷是完美的重要组成部分，这个世界上就没有完美。在曾国藩的那部长篇小说里头，其实写到了一个很重要的一句话，人生的最好的境界是什么？曾国藩想给自己的书房起名叫求阙厅，花还没有全开的时候是最好的。月亮还没有全圆的时候是最好的，但是对于常人来说，都会觉得这是缺陷，还不够完美，不够达到极致，毁一个人的最好的方式就是让他求完美和达到极致。\n这个世界不是这样的，花没有全开的时候才是最棒的，花一全开，离落花就很近了，月亮一旦开始全圆，离慢慢的变成残月就很近了，所以我觉得这是我的30岁给我的很重要的一个助推和启示；40岁没那个时候好看了。但是我觉得放松了。自由一些了，为什么不再是西装革履了，不再是黑白模样了，而是开始问幸福了吗？\n四十岁 中国人有一句话叫40不惑，30岁是减法，40岁是困惑，不是不惑，我觉得现今这个时代40岁恐怕困惑的是最多的，我的中年危机来的还偏偏很早，到三十六七岁的时候就开始纠结，我干的这一切有价值吗？\n有意义吗？我到底要什么幸福了吗？这本书就是在这个困惑的基础上诞生出来了，在30岁的时候你会发现你的很多幸福目标是与物质挂钩的，三十而立力指的是学历得立。你得有车有房，要不丈母娘都不打算把你媳妇许配给你，很物质，但是40不惑很难。我觉得古人可能是平均预期寿命比没现在长，因此它要浓缩40，他就不惑了，我觉得我40正困惑了，物质没有给我带来，我以为会带给我的幸福。同样在40岁的时候，之所以很多人问我，你幸福吗？\n我那书名是幸福浪吗？是问号，代表的是我内心的困惑。中年危机的诞生，40岁你要去回答自己很多的问号，40岁左右要多跟自己聊聊天，要去读很多的东西，给自己一些答案。我很庆幸在我三十六七的时候走进了道德经的世界，我在《白说》里头已经谈到，在40岁的时候还要去思考的时候，如果周边的环境不发生改变，尤其是软环境，您心情舒畅的走出家门，到处是乱闯红绿灯的，你买个东西都是假的，打个疫苗。\n我说这两天中国都在跟台风两个台风做斗争，一个台风是无形的，一个台风是有形的，无形的台风就是疫苗，它冲击的是我们内心安全的堤坝。 另一个台风，中国很少有从上海登陆的台风，这是题外话，接下来你就要去思考的是，你独善其身，你发生了很大的变化，你拥有了很多的答案，周围的环境不变化，你会幸福吗？我有八个字说得比较重，我觉得我们现在是道德赤字人性亏损，这才是目前最大的赤字和最大的亏损。前些天就在离这不远，我亲眼见到了两个车相撞，其实撞的没那么严重，该负责任的，因为他撞了另一个车，跟人家说咱停到路边，人家好也慢慢说准备停到路边了，前面的车撒丫子跑了，一车人也没有拦着他的。\n这会是一个负责任的父亲吗？这会是一个负责任的儿子吗？更不要说他怎么会是一个负责任的公民，而他可能是您的同事，这就是道德赤字和人性亏损也，必然会影响到你。你不管自己是多么一个大写的人，除非你足不出户，但问题是，足不出户也不妨碍您的孩子要打疫苗，您送外卖，那外卖也有可能有问题！\n所以中国人如何学会由一个小老百姓变成一个公民，这可能是在我40岁的时候，既问给自己这个人，也问给社会的一个重要的命题。\n如果说30岁是减法，40岁是困惑，我觉得50岁应该是我送给自己的词是好奇，50岁很尴尬，前不着村后不着店，进、可攻；退、要混，也可以。在自己取得的某种东西上躺10年，混到退休也似乎可以。\n最近看一本书，其中一本书上写得非常有意思，说在硅谷里真正成功的创业者，五六十岁的偏多，这跟我们的概念是不同的。中国如何什么时候能够不把创业全部当成年轻的事业，就跟中国不该把志愿者都当成青年志愿者一样。上一周我做了一期节目，是中国马上要招募退休的中小学教师，每年有二三万块钱的补助，然后去乡村当老师，而且必须是优秀的。我说这正是开启了退休后再就业的先河，当然不光是慈善了，但是回到50，离那块还有点距离，你怎么去向前走？\n五十岁 更重要的是对于50岁的人来说有两个挑战，第1个挑战是你自己，你是不是还对很多的事情好奇，你的人生观是如何的？我觉得我的50岁最大的收获，或者是我此时按照什么方式在活着，我善待每一个今天，20岁的时候容易活在明天里，一不注意50岁容易活在昨天里，但是我努力的克制自己，既不活在明天，也不活在昨天，我善待每一个今天，50岁的人就不该总是明天再说，或者昨天真好！\n我觉得今天最好那天看蔡琴的演唱会碟，蔡琴说的一句话是蛮好的，他说每次看照片我都觉得两年前的我真好看，但是两年前的那一天，我从来没觉得自己好看过。这句话挺有味道的。我30岁的时候没觉得，那个时候我挺帅的，觉得自己的毛病很多，可是今天当我隔了20年回头看的时候。\n原来我也年轻过，原来我头发那么多，所以善待你的每一个今天，两年后再看您的今天最好不过了。\n就像史铁生说的那番话，当我的腿刚不能走路的时候，我坐在轮椅上天天怀念我能奔跑打篮球的时光，每天在怀念中都非常痛苦。 又隔了几年，我在轮椅上生了褥疮，浑身难受，那个时候天天怀念，几年前我什么都不疼，安静的能坐在轮椅上的时光。 又隔了一些年，我得了尿毒症，我总要去透析，这个时候我就怀念当初仅仅有褥疮的轮椅时光，那50岁如果再活不到善待每一个今天的地步，前面的50年白过了。\n其实我觉得别等到50岁才明白这个道理，30、40就该明白，所有的东西都容易轻易的错过。旅行中的一顿饭，你只要没吃，再吃30年后了，还不一定是味道，所以我觉得善待每一个今天是我50岁时候的第一个感受。\n第二个就是好奇，我发现我随时可以不再对很多事情好奇了，因为见过了很多，体验了很多，但是我督促自己好奇。所以现在做很多事，我都带着好奇的心，手机可不可以竖着拍，也可以，你去做现场报道，去做看似很大得很庄严的什么峰会，你连线可不可以更轻松？更好玩，更让大家印象深刻，你可不可以然后又用新媒体去进行传播，都可以。我觉得好奇是督促人类进步的最重要的一种一个动力，为什么不能成为督促一个个体进步的最重要动力？一个民族只要不好奇了，这个民族吹了。另外一个大的层面，50岁是一个重要的考验。四五十岁的时候，在中国你做一个怎样的既得利益者？我非常担心我们身边的很多人年轻的时候，因为希望而要去实现很多的梦想，但是一旦自己实现了梦想，成为既得利益者了，变成为阻拦别人实现梦想的人，我说的没错吧？ 转眼就用他曾经最不喜欢的方式在对待年轻人和事儿。\n因此在几年前我自己就开始以志愿者的身份每年招11个研究生，一待待两年，现在已经毕业了5期，有55个纯研究生，已经毕业了。我觉得做这样的既得利益者是件很幸福的事，你拥有了某些感触，你也有能力去带他们，每上完一天课，晚上请他们吃饭，花不了多少。但是这是一个好的既得利益者应该做的，既得利益者有可能是两个方面，一方面是重新成为铺路石。我曾经说过一句话，我说我不想太多的对帮助过我的人说谢谢，因为我要以加倍的方式去对待新的年轻人，这就是我说谢谢的方式。\n如果天天在那说谢谢你，却成为阻拦者。接下来就是为别人铺路。我希望中国不管是物质的、经济的、思想的、文化的、各个领域的既得利益者，当你成了的时候，要考虑你该怎么做？昨天推火车的人今天成了拦火车的人，回头看中国的历史到处如此，今天也不会。不是这样，甚至有的时候会更多，所以呼吁所有的既得利益者能重新像你年轻的时候，希望碰到什么样的人那样去做，那样的人我也许做的不够好，但起码我在想、在做、在说。\n","date":"2020-02-14T07:27:21+08:00","permalink":"https://ttf248.github.io/p/%E5%85%B3%E4%BA%8E%E5%85%89%E9%98%B4%E4%BD%A0%E8%A6%81%E8%AF%BB%E5%BE%88%E5%A4%9A%E4%B9%A6%E6%89%8D%E8%83%BD%E6%89%BE%E5%88%B0%E7%AD%94%E6%A1%88/","title":"关于光阴，你要读很多书才能找到答案"},{"content":"自定义分配器可以提升性能、提高内存使用效率，并解决频繁少量内存分配的问题。\n前因 近期接触到了网络网络数据包的开发，需要频繁的申请和释放小块的内存，原本想着使用内存池，查看了几个现有的内存池，发现了这个\nhttps://github.com/cacay/MemoryPool\n看到接口的时候，就比较纳闷，这个内存池的实现怎么有点奇怪。MemoryPool的实现逻辑，是在申请固定大小的内存空间。看过boost的内存池接口，提供的是一个模板，用的时候进行实例化。正巧这个库已经有文章进行过介绍，提到了allocator这个概念。\nwiki 在C++编程中，分配器（英语：allocator）是C++标准库的重要组成部分。C++的库中定义了多种被统称为“容器”的数据结构（如链表、集合等），这些容器的共同特征之一，就是其大小可以在程序的运行时改变；为了实现这一点，进行动态内存分配就显得尤为必要，在此分配器就用于处理容器对内存的分配与释放请求。换句话说，分配器用于封装标准模板库（STL）容器在内存管理上的低层细节。默认情况下，C++标准库使用其自带的通用分配器，但根据具体需要，程序员也可自行定制分配器以替代之。\n分配器最早由亚历山大·斯特潘诺夫作为C++标准模板库（Standard Template Library，简称STL）的一部分发明，其初衷是创造一种能“使库更加灵活，并能独立于底层数据模型的方法”，并允许程序员在库中利用自定义的指针和引用类型；但在将标准模板库纳入C++标准时，C++标准委员会意识到对数据模型的完全抽象化处理会带来不可接受的性能损耗，为作折中，标准中对分配器的限制变得更加严格，而有鉴于此，与斯特潘诺夫原先的设想相比，现有标准所描述的分配器可定制程度已大大受限。\n虽然分配器的定制有所限制，但在许多情况下，仍需要用到自定义的分配器，而这一般是为封装对不同类型内存空间（如共享内存与已回收内存）的访问方式，或在使用内存池进行内存分配时提高性能而为。除此以外，从内存占用和运行时间的角度看，在频繁进行少量内存分配的程序中，若引入为之专门定制的分配器，也会获益良多。\n使用需求 定义自定义分配器的主要原因之一是提升性能。利用专用的自定义分配器可以提高程序的性能，又或提高内存使用效率，亦或两者兼而有之[4][8]。默认分配器使用new操作符分配存储空间[文 5]，而这常利用C语言堆分配函数（malloc()）实现[9]。由于堆分配函数常针对偶发的内存大量分配作优化，因此在为需要一次分配大量内存的容器（如向量、双端队列）分配内存时，默认分配器一般效率良好[8]。但是，对于关联容器与双向链表这类需要频繁分配少量内存的容器来说，若采用默认分配器分配内存，则通常效率很低[4][9]。除此之外，基于malloc()的默认分配器还存在许多问题，诸如较差的引用局部性[4]，以及可能造成内存碎片化[4][9]。\n简言之，此段（……）（如同）是这一标准针对分配器的一场《我有一个梦想》的演讲。在梦想成真之前，关心可移植性的程序员将把自己局限于（使用）无状态的自定义分配器上。 ——斯科特 梅耶斯，《Effective STL》 有鉴于此，在这一情况下，人们常使用基于内存池的分配器来解决频繁少量分配问题[8]。与默认的“按需分配”方式不同，在使用基于内存池的分配器时，程序会预先为之分配大块内存（即“内存池”），而后在需要分配内存时，自定义分配器只需向请求方返回一个指向池内内存的指针即可；而在对象析构时，并不需实际解除分配内存，而是延迟到内存池的生命周期完结时才真正解除分配[注 1][8]。\n在“自定义分配器”这一话题上，已有诸多C++专家与相关作者参与探讨，例如斯科特·梅耶斯的作品《Effective STL》与安德烈·亚历山德雷斯库的《Modern C++ Design》都有提及。梅耶斯洞察到，若要求针对某一类型T的分配器的所有实例都相等，则可移植的分配器的实例必须不包含状态。虽然C++标准鼓励库的实现者支持带状态的分配器[文 4]，但梅耶斯称，相关段落是“（看似）美妙的观点”，但也几乎是空话，并称分配器的限制“过于严苛”[4]。例如，STL的list允许splice方法，即一个list对象A的节点可以被直接移入另一个list对象B中，这就要求A的分配器申请到的内存，可被B的分配器释放掉，从而推导出A与B的分配器实例必须相等。梅耶斯的结论是，分配器最好定义为使用静态方法的类型。例如，根据C++标准，分配器必须提供一个实现了rebind方法的other类模板。\n另外，在《C++程序设计语言》中，比雅尼·斯特劳斯特鲁普则认为“‘严格限制分配器，以免各对象信息不同’，这点显然问题不大”（大意），并指出大部分分配器并不需要状态，甚至没有状态情形下性能反倒更佳。他提出了三个自定义分配器的用例：内存池型的分配器、共享内存型分配器与垃圾回收型分配器，并展示了一个分配器的实现，此间利用了一个内部内存池，以快速分配/解除分配少量内存。但他也提到，如此优化可能已经在他所提供的样例分配器中实现[3]。\n自定义分配器的另一用途是调试内存相关错误[10]。若要做到这一点，可以编写一个分配器，令之在分配时分配额外的内存，并借此存放调试信息。这类分配器不仅可以保证内存由同类分配器分配/解除分配内存，还可在一定程度上保护程序免受缓存溢出之害[11]。\n","date":"2019-12-30T13:26:19+08:00","permalink":"https://ttf248.github.io/p/%E6%A0%87%E5%87%86%E5%BA%93%E5%AE%B9%E5%99%A8%E7%9A%84%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%99%A8allocator/","title":"标准库容器的内存分配器：allocator"}]
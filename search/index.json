[{"content":"紧接上文，今天继续聊聊局域网的 IP 地址。上次为了同步代码，服务器配置了代理，服务器和家里的台式机打通了网络，在一个局域网里面，代理程序部署在台式机上，服务器通过代理访问外网。同步代码很慢，扔那边就没管了，隔了半个月，到服务器验证代码，发现Git代码同步失败，网络错误，也没太过脑子，细看报错信息。\n案发现场 fatal: unable to access \u0026lsquo;https://cnb.cool/ttf248/learn/cpp.git/': Failed to connect to 10.243.52.68 port 7897 after 7 ms: Couldn\u0026rsquo;t connect to server\n相当然的以为是不是阿里云服务和腾讯云原生开发平台有网络隔离，导致代码无法同步，报错信息扔到群里，群里有大聪明看到了端口信息，说这个是不是代理的ip，然后马上有人接着说，你这个是局域网，域名解析的都不对，这会脑子还在失忆阶段，完全不记得自己配过代理。\n看到局域网三个字，脑子正常了，马上想起来自己配置过代理的事情，报错的地址是家里台式机的局域网地址。\n惯性思维：192.168.x.x 是局域网地址。\n在计算机网络中，局域网（LAN）IP地址是指在本地网络中使用的私有IP地址，这类地址不会直接暴露在公网上，主要用于内部设备通信。你提到的 10.243.52.68 和 192.168.x.x 都属于私有IP地址段，但它们属于不同的地址范围，适用场景和规划逻辑也有所不同。以下是详细对比：\n私有IP地址的分类与范围 根据 RFC 1918 标准，私有IP地址分为三大段，分别适用于不同规模的局域网：\n地址段 子网掩码 可用IP数量 适用场景 10.0.0.0/8 255.0.0.0 约1600万个 大型企业、园区网络 172.16.0.0/12 255.240.0.0 约100万个 中型企业网络 192.168.0.0/16 255.255.0.0 约6.5万个 小型局域网（家庭、办公室） 你的问题中的IP地址解析： 10.243.52.68\n属于 10.0.0.0/8 段，是大型私有网络的典型地址，常用于企业级局域网或广域网（如跨多个分支机构的内部网络）。 192.168.x.x\n属于 192.168.0.0/16 段，是最常见的小型私有网络地址，广泛用于家庭路由器、小型办公室等场景。 两者的核心区别 地址空间大小 10.0.0.0/8：\n整个网段的地址范围是 10.0.0.0 ~ 10.255.255.255，包含 16,777,216 个可用IP地址，适合需要大量IP地址的大型网络（如企业、学校、数据中心）。 192.168.0.0/16：\n地址范围是 192.168.0.0 ~ 192.168.255.255，仅包含 65,536 个可用IP地址，适用于设备数量较少的小型网络（如家庭中通常只有几十台设备）。 子网划分灵活性 10.0.0.0/8：\n由于地址空间大，可通过子网掩码进一步划分为多个子网（如 10.1.0.0/16、10.2.0.0/16 等），便于大型网络的分层管理和流量隔离。 192.168.0.0/16：\n通常直接使用默认子网掩码 255.255.0.0，划分子网的需求较少，适合简单的扁平网络结构。 常见应用场景 10.xxx.xxx.xxx： 企业内部网络：如跨国公司的多个分支机构通过VPN连接，每个分支可分配独立的子网（如 10.1.1.0/24、10.1.2.0/24）。 云服务商内部网络：如AWS、阿里云等私有云环境常使用 10. 段地址。 工业控制网络：部分工业设备默认使用 10. 段地址。 192.168.xxx.xxx： 家庭/小型办公室：路由器默认分配的地址（如 192.168.1.1 或 192.168.0.1）。 小型局域网共享：如通过路由器组建的WiFi网络，设备数量通常不超过200台。 与公网的隔离性 两者均为私有地址，无法直接被公网访问，需通过 NAT（网络地址转换） 或 VPN 连接到公网。但在实际使用中：\n10. 段常用于需要更复杂网络架构的场景（如多子网、VLAN划分）。 192.168. 段因地址空间小，更适合即插即用的简单网络。 为什么你会看到 10. 段地址？ 如果你在本地网络中发现 10.243.52.68 这样的地址，可能原因包括：\n企业级网络环境：\n你所在的公司或机构使用 10. 段作为内部IP地址，用于区分不同部门或设备（如服务器、办公电脑）。 虚拟机或容器网络：\n云计算平台（如VMware、Docker）常默认使用 10. 段地址为虚拟机分配IP。 特殊设备默认配置：\n部分网络设备（如工业交换机、防火墙）出厂时可能预设 10. 段地址。 总结：如何选择使用？ 小型网络（家庭/办公室）：优先选择 192.168.x.x，配置简单且足够用。 中大型网络（企业/园区）：使用 10.x.x.x 或 172.16.x.x，便于划分子网和管理大量设备。 两者本质上都是局域网地址，区别仅在于地址空间和适用场景，并无技术上的优劣之分，具体取决于网络规划需求。\n","date":"2025-06-06T18:46:55+08:00","permalink":"https://ttf248.life/p/102435268-also-belongs-to-the-local-area-network/","title":"10.243.52.68 也属于局域网"},{"content":"国内访问 GitHub 速度较慢，可以通过配置代理来加速访问。还有个方式，找个国内的托管平台，比如码云、Coding 等。配置对应的构建流水线，将代码同步到 GitHub。\n用了很多年的coding，界面简洁，近期发布公告，免费版不能继续用了，需要迁移到腾讯的新平台cnb，顺带吐槽下，阿里的托管平台，整个界面设计，班味很重。\nhttps://cnb.cool/ttf248\n仓库迁移 cnb官网提供了迁移工具，可以批量将代码从github迁移到cnb。\nhttps://docs.cnb.cool/zh/guide/migration-tools.html\nGit 配置代理 不配置加速，工具同步很慢，代码会先同步到本地，然后上传到远程仓库。\nGit 可以通过以下命令单独配置 HTTP 代理，不影响系统全局设置：\n# 设置 HTTP 代理 git config --global http.proxy http://proxy.example.com:8080 # 设置 HTTPS 代理 git config --global https.proxy http://proxy.example.com:8080 # 可选：仅为特定域名设置代理 git config --global http.https://github.com.proxy http://proxy.example.com:8080 如果需要取消代理配置，可以使用：\ngit config --global --unset http.proxy git config --global --unset https.proxy 查看当前代理配置：\ngit config --global --get http.proxy git config --global --get https.proxy ","date":"2025-06-06T18:29:46+08:00","permalink":"https://ttf248.life/p/git-single-configuration-proxy/","title":"Git单独配置代理"},{"content":"业务系统设计了 Summary 类型的监控指标，计算平均耗时：request_duration_milliseconds_sum / request_duration_milliseconds_count。\n查看数据，发现某个接口平均耗时很高，翻看时序图，平均耗时是突然增加的，等于就是某次请求耗时很高，拉高了平均值，想查具体是什么时候发生的请求，由于时段内的请求太少，查出来的数据一直空。\n答疑 ✅ 为什么 _sum 和 _count 有数据 _sum 和 _count 是 Summary 类型的核心指标，Prometheus 始终会采集并记录这两个值； 它们是累积型的 counter，适合用 rate() 或 increase()； 无论请求延迟如何变化，只要有请求，就一定会有 _sum 和 _count 数据； ❌ 为什么 {quantile=\u0026quot;0.99\u0026quot;} 可能无法在时序图中展示 哪怕 Summary 配置了 quantile=\u0026ldquo;0.99\u0026rdquo;，这个时间序列也可能不存在或缺失：\n指标肯定是配置了，数据也没有过期，📉 请求量太小，quantile 无法计算，滑动窗口机制，过了这段时间，就不会再纳入统计范围。\n分位数（如 p99）是通过采样统计计算的：\n如果某段时间内请求数太少（如 1~2 个请求），p99 的计算是不稳定或没有代表意义； Prometheus 客户端 SDK 会选择不暴露该 quantile 时间序列，以避免误导； 所以你会看到 _sum、_count 正常累加，但 quantile=\u0026quot;0.99\u0026quot; 没数据。 Histogram 和 Summary 的区别 Histogram 工作原理:\nHistogram 会将数据分桶（buckets），记录每个桶中落入的样本数量。\n例如，定义的桶为 [10ms, 50ms, 100ms, 500ms, 1s]，每次请求的耗时会被归入对应的桶中。\n优点:\n可以在 Prometheus 中聚合多个实例的数据（例如多个服务节点的请求耗时分布）。 适合计算分位数（如 P50、P95、P99）和观察耗时分布。 提供了灵活的查询能力，支持通过 PromQL 动态计算分位数。 缺点:\n需要预定义桶的范围，选择不当可能导致数据分布不均（例如，所有请求都落在一个桶中）。 桶的数量越多，存储和计算的开销越大。 适用场景:\n需要聚合多个实例的数据。 需要动态调整分位数或分析耗时分布。 Summary 工作原理:\nSummary 会在客户端直接计算分位数（如 P50、P95、P99），并将结果上报到 Prometheus。\n它还会记录样本的总数和总和，用于计算平均值。\n优点:\n不需要预定义桶，直接提供分位数结果。 适合单实例的精确分位数计算。 缺点:\n分位数的计算是在客户端完成的，无法在 Prometheus 中聚合多个实例的数据。 如果需要调整分位数（如从 P95 改为 P99），需要修改代码并重新部署。 适用场景:\n单实例监控，且对分位数的精确性要求较高。 不需要聚合多个实例的数据。 主要区别对比 特性 Histogram Summary 分位数计算 在 Prometheus 中动态计算 在客户端直接计算 多实例聚合 支持 不支持 桶的定义 需要预定义 不需要 存储开销 取决于桶的数量 固定开销 灵活性 高（可动态调整分位数） 低（需修改代码调整分位数） 总结 如果需要聚合多个实例的数据，或者需要灵活调整分位数，选择 Histogram。 如果只需要单实例的精确分位数，且分位数固定，选择 Summary。 在你的场景中，由于服务是分布式的，建议优先使用 Histogram，这样可以在 Prometheus 中聚合所有实例的数据，并动态计算分位数和耗时分布。\n滑动窗口的概念及其与 Histogram 和 Summary 的关系 滑动窗口的概念 滑动窗口是一种时间窗口机制，用于统计一段时间内的数据变化。它通过不断移动的时间范围，动态反映系统的实时状态。滑动窗口的特点是：\n固定时间范围：窗口的长度是固定的，例如最近 1 分钟、5 分钟。 实时更新：随着时间的推移，窗口会滑动，旧的数据被移出窗口，新数据被加入窗口。 常见用途：用于计算实时指标（如请求速率、平均值、分位数等）。 在 Prometheus 中，滑动窗口通常通过查询函数（如 rate()、avg_over_time()）实现。\n滑动窗口与 Histogram 的关系 Histogram 的数据结构：\nHistogram 会将样本数据分桶，并记录每个桶的计数。Prometheus 会周期性地抓取这些计数值。\n滑动窗口的实现：\n在 Prometheus 中，可以通过查询语句对 Histogram 的数据应用滑动窗口。例如：\nrate(http_request_duration_seconds_bucket[5m])：计算过去 5 分钟内每个桶的请求速率。 histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))：计算过去 5 分钟内的 P95 分位数。 优点：\n滑动窗口可以动态反映最近一段时间的请求耗时分布。 Histogram 的分桶机制与滑动窗口结合，可以高效计算分位数和分布。 滑动窗口与 Summary 的关系 Summary 的数据结构：\nSummary 会在客户端直接计算分位数，并上报到 Prometheus。它还会记录样本总数和总和。\n滑动窗口的实现：\n在 Prometheus 中，可以通过查询语句对 Summary 的数据应用滑动窗口。例如：\nrate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m])：计算过去 5 分钟内的平均请求耗时。 限制：\nSummary 的分位数是客户端计算的，无法在 Prometheus 中重新计算分位数，因此滑动窗口对分位数的支持有限。 如果需要聚合多个实例的数据，滑动窗口无法直接作用于 Summary 的分位数。 滑动窗口的适用场景 实时监控：滑动窗口适合用于监控系统的实时状态，例如最近 1 分钟的请求速率、耗时分布等。 异常检测：通过滑动窗口，可以快速发现短时间内的异常情况（如请求耗时突然增加）。 动态分析：滑动窗口可以动态反映系统的变化趋势，而不是静态的全局统计。 总结 Histogram 与滑动窗口结合，可以动态计算分位数（如 P95、P99）和请求耗时分布，适合分布式系统的监控。 Summary 与滑动窗口结合，可以计算平均值等简单指标，但分位数的灵活性较差，且不支持多实例聚合。 在你的场景中，由于需要监控极端请求耗时（如 P99）和大部分请求的平均值，建议使用 Histogram，并结合滑动窗口查询来动态分析系统的性能表现。\n","date":"2025-06-04T19:00:28+08:00","permalink":"https://ttf248.life/p/prometheus-monitoring-system-histogram-and-summary/","title":"Prometheus监控系统Histogram和Summary"},{"content":"文化传播：意识形态上的影响，潜移默化。 AI编程：不做软件设计，返工很多\n文化传播 起初项目仅仅支持了英语、日语、韩语三种语言，后面想着反正都是AI翻译，何不多支持几种语言呢？于是又增加了法语、俄罗斯语、印度语。此时还没发现问题，程序执行翻译的时候，由于历史的代码存在问题，翻译出来的格式不对，存档的文章需要重新翻译。\n统计耗时提醒，全部翻译完成需要将近20小时，毕竟是本地部署的大模型，那会还是用 12b 参数的大模型。想着干掉几个不常用的语言，减少翻译时间。于是删除了法语、俄罗斯语、印度语。这时候感觉到了不对劲，为什么开始的语言里面，我会选择韩语、日语。\n按照全球人口的分布，这两个语言的受众人群并不多，尤其是韩语，全球使用人数大概只有8000万左右。日语稍微多一点，大概1.2亿人。相比之下，法语、俄罗斯语、印度语的使用人数都在1亿以上。\n这时候才意识到，韩语、日语的受众人群并不是因为语言使用人数多，而是因为文化传播的影响。韩国和日本的文化在全球范围内有着广泛的影响力，尤其是在亚洲地区。K-pop、动漫、影视剧等文化产品吸引了大量粉丝，这些粉丝自然也会对相关语言产生兴趣。\n回顾成长的历程，小时经常看日本的动漫、漫画，长大了看了很多韩国的电影、电视剧。导致我在项目设置初始语言的时候，下意识的选择了这两个熟悉的语言。\n软件设计与AI编程 翻译助手最初只是一个简单的小工具，但在体验了 Claude4 的编码能力后，逐渐扩展了功能，增加了文章翻译、标签翻译等模块。随着功能的增加，代码复杂度也随之提升。虽然 AI 重构代码后目录结构显得更清晰，但在扩展新功能或修复缺陷时，AI生成的代码常常存在重复问题。\nAI在生成代码时，缺乏对整体结构和设计理念的理解。它通常基于已有代码进行修改和扩展，却未能有效复用已有模块，导致代码冗余。每次都需要手动清理重复代码，这无形中增加了开发成本。\n此外，AI生成的代码虽然语法正确，但在逻辑和设计上往往存在问题。例如，在另一个项目中稍微调整提示词后，生成的网页结构完全不同，缺乏一致性。这反映了项目初期缺乏合理设计，功能的增加更多是随意堆砌，导致代码结构混乱。\n这也提醒我们，软件工程的核心经验仍然不可忽视。合理的设计不仅能减少返工，还能提升代码的可维护性和扩展性。AI虽然是强大的工具，但它无法替代人类对系统设计的深刻理解和规划。\n","date":"2025-06-02T21:41:00+08:00","permalink":"https://ttf248.life/p/blog-translation-project-musings-cultural-transmission-ai-programming/","title":"博客翻译项目碎碎念：文化传播、AI编程"},{"content":"博客翻译项目最初设计过于复杂——先解析 Markdown 格式，再用占位符保护内容，最后送给大模型翻译。其实这完全是多此一举，大模型本身就具备识别 Markdown 语法的能力，可以直接处理原始内容并在翻译时保持格式完整。\n我们的工作就从调试代码，切换到调试大模型的提示词。\n模型：google/gemma-3-4b 硬件：Nvdia 3060 12GB\n没错，选的非思考模型，思考模型在执行翻译任务时，效率不够高，对比了 4b 参数和 12b 参数的效果，针对翻译任务来说 gemma3 的 4b 参数已经足够了，12b 的参数在翻译任务上并没有明显的优势。\n12b 参数的速度：11.32 tok/sec，4b 参数的速度：75.21 tok/sec。\n背景介绍 尽管在system里面加上了各种条件限制，输出的翻译结果，还是会出现一些问题，比如：格式没有保护，多出来了一些解释的内容。角色定义的时候，已经声明过，记得保护 Markdown 格式、仅输出翻译结果，最终的翻译还是不太稳定。\n此时想起来，以前接触过一个漫画翻译的项目，也用到了大模型的能力，它的翻译效果好像比我的效果更好一些，翻看代码，对比请求的数据，漫画翻译的项目，每次请求都会带上一组上下文，除了当前的翻译内容，还会带上之前的翻译内容。\n好处是什么，不仅能提升前后翻译的连贯性，还剩确保输出格式的稳定性。\n历史会话的重要性 随着 AI 大模型（如 GPT 系列、Claude、Gemini 等）的普及，越来越多企业和开发者通过 API 接入这些模型，构建智能客服、内容生成、代码助手等应用。然而，许多人在接入初期会遇到一个常见问题：模型输出不连贯、缺乏上下文理解，甚至答非所问。\n造成这种现象的一个关键原因是——没有在 API 请求中包含历史对话内容。\n什么是历史对话？ 历史对话是指在一次对话会话中，模型和用户之间之前的交流记录。在大多数大模型 API（如 OpenAI 的 Chat Completions API）中，开发者需要自己在请求中构建完整的 messages 数组，将历史对话以轮流的 user 和 assistant 消息形式传入。\n示例 { \u0026quot;model\u0026quot;: \u0026quot;gpt-4\u0026quot;, \u0026quot;messages\u0026quot;: [ {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: \u0026quot;帮我写一封辞职信\u0026quot;}, {\u0026quot;role\u0026quot;: \u0026quot;assistant\u0026quot;, \u0026quot;content\u0026quot;: \u0026quot;好的，你希望辞职的原因写些什么？\u0026quot;}, {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: \u0026quot;说我想追求个人职业发展\u0026quot;} ] } 如果你只发送最后一句话：\n{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: \u0026quot;说我想追求个人职业发展\u0026quot;} 模型根本不知道你在说辞职信，它可能完全无法理解上下文，输出质量自然很差。\n为什么历史对话如此重要？ 1. 构建上下文，提升连贯性 AI 模型本质上是“上下文驱动”的。它无法记住“之前”发生的任何事情，除非你显式告诉它。通过传入对话历史，模型可以更好地理解你的意图和话题背景，输出更符合预期。\n2. 降低误解率 如果你希望模型完成一个多轮指令，如写作、总结、调试代码，历史记录能让模型逐步积累理解，避免在中途“跑题”或丢失重点。\n3. 模拟真实人类对话行为 在实际应用中，如客服系统、教育助手、健康咨询等，用户的问题往往是逐步展开的，而不是一次性表达清楚。保留对话历史，可以让 AI 更像一个“有记忆力的助理”。\n如何在 API 中正确添加历史对话？ 以 OpenAI 的 API 为例，建议遵循以下结构：\nmessages = [ {\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;: \u0026quot;你是一个专业的法律助手\u0026quot;}, {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: \u0026quot;什么是合同的有效条件？\u0026quot;}, {\u0026quot;role\u0026quot;: \u0026quot;assistant\u0026quot;, \u0026quot;content\u0026quot;: \u0026quot;合同有效需要满足以下几个条件：……\u0026quot;}, {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: \u0026quot;那口头协议算吗？\u0026quot;} ] response = openai.ChatCompletion.create( model=\u0026quot;gpt-4\u0026quot;, messages=messages ) 注意：\n使用 system 消息设定模型行为和身份。 保留最近几轮关键对话即可，不需要每次传入全部历史（避免超过 token 限制）。 在长会话中，可通过截断早期内容，保留核心信息摘要，控制 token 消耗。 实践建议 对话状态管理：后端需设计缓存机制，记录每个用户的会话历史（如 Redis、数据库）。 限制长度：OpenAI GPT-4 的上下文长度为 128k tokens，Claude 3 可达 200k~1M，需合理裁剪。 动态摘要历史：当历史内容过长时，使用模型先对旧对话做摘要，再添加进对话上下文。 总结 AI 大模型的能力强大，但也需要开发者“喂”给它足够的上下文信息。通过在 API 请求中添加历史对话，不仅能显著提升模型输出的质量和连贯性，也能让用户体验更自然、更贴近真实对话。\n无论你是在构建 AI 客服、写作助手、编程帮手，还是教育类应用，这都是一个不可忽视的优化技巧。\n","date":"2025-06-02T21:16:24+08:00","permalink":"https://ttf248.life/p/blog-translation-project-musings-historical-conversations/","title":"博客翻译项目碎碎念：历史会话"},{"content":"在 Go 语言项目中，使用 staticcheck 查找未引用的函数是一种高效的静态分析方法。\n1. 安装 staticcheck 确保已安装 Go（版本 1.16+），然后执行以下命令安装 staticcheck：\ngo install honnef.co/go/tools/cmd/staticcheck@latest 2. 基本用法：查找未引用的函数 在项目根目录下执行：\nstaticcheck ./... 关键检查规则：\nU1000：检测未使用的函数、方法、变量或类型。 U1001：检测未使用的参数。 3. 过滤特定检查规则 若只需检查未使用的函数，可指定规则：\nstaticcheck -checks=U1000 ./... 4. 输出格式 默认输出格式为 {path}:{line}:{column}: {message}，例如：\nmain.go:10:2: func UnusedFunction is unused (U1000) 5. 配置文件（可选） 在项目根目录创建 .staticcheck.conf 文件，自定义检查规则：\n{ \u0026quot;checks\u0026quot;: [\u0026quot;U1000\u0026quot;, \u0026quot;-ST1000\u0026quot;] // 启用 U1000，禁用 ST1000（字符串格式化规则） } 6. 集成到 VS Code 安装 Go 扩展。\n在 settings.json 中添加：\n{ \u0026quot;go.lintTool\u0026quot;: \u0026quot;staticcheck\u0026quot;, \u0026quot;go.lintFlags\u0026quot;: [\u0026quot;-checks=U1000\u0026quot;] } 7. 忽略特定代码 在函数上方添加注释 //lint:ignore U1000 reason 可忽略检查：\n//lint:ignore U1000 Used by generated code func UnusedButNeeded() {} 常见问题解答 Q：如何处理测试文件中的未使用函数？\nA：staticcheck 默认会检查测试文件。若需排除，可使用 -tests=false 标志。\nQ：如何在 CI/CD 中集成？\nA：在 GitHub Actions 中添加：\n- name: Run staticcheck run: staticcheck -checks=U1000 ./... 示例输出 $ staticcheck -checks=U1000 ./... internal/utils/helper.go:15:2: func privateHelper is unused (U1000) cmd/server/main.go:23:2: func initConfig is unused (U1000) 通过 staticcheck 的 U1000 规则，你可以快速定位并清理未引用的函数，提高代码质量。\n","date":"2025-06-02T21:10:47+08:00","permalink":"https://ttf248.life/p/find-all-functions-not-referenced-in-the-go-project/","title":"Go 项目查找所有没有引用的函数"},{"content":"抖音刷到个浙江金融圈反腐的报道，很早以前写过一次关于金融反腐的序幕，后续没有再去追踪相关报道。\n每天都会看看财经新闻，以前是看不到什么金融反腐的报道，最近两年开始有很多金融反腐的报道，银行、券商等金融机构的高管被查的新闻越来越多。\n金融反腐的序幕\n浙江金融圈近期爆发的系统性反腐风暴，是近年来中国金融领域最具标志性的事件之一。这场始于2023年的反腐行动，以四大国有银行浙江省分行原行长集体落马为核心，揭开了地方金融系统长期存在的权力寻租、政商勾结等深层问题。以下从事件脉络、核心问题、深层原因及后续影响四个维度进行梳理：\n一、事件脉络：从朱从玖案到四大行“掌门人”全军覆没 导火索：朱从玖案牵出金融系统窝案\n2023年5月，时任浙江省副省长朱从玖落马，其“靠金融吃金融”的腐败模式成为突破口。朱从玖在任期间通过干预企业上市、融资贷款等获取巨额利益，并与金融机构高管形成利益同盟。2023年11月，朱从玖被开除党籍和公职，调查中供出的多条线索直接引发后续金融系统地震。\n反腐风暴升级：四大行浙江分行原行长相继落马\n2024年4月：中国银行浙江省分行原行长郭心刚被查，其退休后通过低价购房、股权溢价等方式敛财，滥用矿产贷款审批权导致国有资产重大损失。 2025年4月：建设银行浙江省分行原行长高强被查，其在任期间违规审批贷款导致多个项目烂尾，收受“顾问费”超千万元。 2025年5月：农业银行浙江省分行原行长冯建龙主动投案，其任内将农行浙江分行变为“家族产业”，亲属违规任职、生活作风问题严重。 2025年5月30日：工商银行浙江省分行原行长沈荣勤被查，其退休后通过“政商旋转门”掌控钱塘江金研院等机构，与八家民企形成利益输送网络。至此，四大行浙江分行原“一把手”在15个月内全部落马，形成反腐闭环。 监管系统同步震荡\n2025年1月，浙江省委金融办原副主任潘广恩主动投案，其利用职务便利为企业股改上市、引入投资等谋利，非法收受巨额财物。这标志着反腐行动从金融机构延伸至监管部门，揭示了“监管-金融机构-民企”三方利益链的深度绑定。\n二、核心问题：信贷腐败与旋转门利益链 信贷审批权异化：腐败的核心工具\n四大行原行长均利用信贷审批权进行利益输送：郭心刚违规发放矿产贷款，高强通过“顾问费”操控信贷，冯建龙家族式放贷导致烂尾项目，沈荣勤通过金研院平台为关联企业输送资金。数据显示，2024年银行系统被查人员中，68%涉及违规批贷或放贷，信贷权力失控问题触目惊心。\n旋转门腐败：退休不是保险箱\n四人均在退休后通过“身份转换”延续权力：郭心刚担任行业协会会长干预信贷，高强转任券商独董操控资本，沈荣勤搭建“金融产学研”平台连接民企。这种“退而不休”的模式，使退休高管得以规避监管，形成隐蔽的利益链条。2024年金融反腐白皮书显示，68%的案件涉及退休高管，浙江案例成为典型样本。\n政商边界模糊：从银行到民企的利益输送\n沈荣勤执掌的钱塘江金研院由正泰、传化等八家民企注资成立，表面为学术机构，实为政商勾兑枢纽。通过该平台，沈荣勤将银行资源导向关联企业，形成“金融机构-民企智库”绑定模式。类似模式在郭心刚、高强案件中亦有体现，暴露出地方金融生态中政商关系的深度扭曲。\n三、深层原因：制度漏洞与监管失灵 地方金融监管长期缺位\n浙江省作为民营经济大省，金融创新活跃，但监管体系未能同步跟进。朱从玖、潘广恩等官员长期主导地方金融政策，既当“运动员”又当“裁判员”，导致监管形同虚设。例如，潘广恩在金融办任职期间，违规干预企业融资、股改，却未受到有效制约。\n金融机构内控失效\n四大行浙江分行内部监督机制形同虚设。冯建龙任农行浙江分行行长时，亲属在系统内快速晋升，信贷审批“一言堂”现象突出。沈荣勤推行的“员工关爱计划”表面为福利，实则通过控制基层员工巩固权力，掩盖腐败行为。\n外部监督机制薄弱\n跨省监察模式的启用（如沈荣勤案由辽宁省监委办理）表明，地方保护主义曾严重阻碍反腐进程。此外，金融机构与民企的复杂股权关系（如浙商银行前十大贷款客户中半数为房企）导致风险传导隐蔽，传统监管手段难以穿透。\n四、后续影响：监管升级与行业重塑 反腐常态化与制度堵漏\n跨省监察与穿透式监管：中央纪委采用异地办案切断地方保护网，并将审查范围从在职行为延伸至退休后利益链。 技术反腐落地：浙江试点信贷审批AI风控模型，自动识别“人情贷”“政商贷”，从源头遏制权力寻租。 离职从业限制：浙江省拟出台《金融高管离职从业清单》，规定银行行长退休三年内不得任职关联企业，切断权力期权化链条。 金融生态重塑\n银行系统风险出清：浙商银行、杭州银行等机构因高管落马启动内部整顿，房地产贷款占比高的问题（如浙商银行房地产不良率达2.48%）倒逼业务转型。 民企融资环境优化：反腐行动后，浙江省推出“浙科贷”等政策，2024年为3.2万家科技型中小企业提供4500亿元贷款，推动金融回归服务实体经济本源。 社会警示效应\n四大行浙江分行原行长的集体覆灭，打破了“退休即安全”的幻想，传递出金融反腐“零容忍、无盲区”的信号。这一事件也为全国金融系统提供镜鉴：唯有强化权力制约、完善监管体系，才能守护金融安全。\n结语 浙江金融圈塌方事件，本质上是地方金融权力长期失控的集中爆发。这场风暴不仅清除了一批“金融蛀虫”，更推动了监管模式、制度设计和行业生态的深刻变革。未来，如何平衡金融创新与风险防控、如何构建“亲清”政商关系，将是浙江乃至全国金融领域持续探索的课题。\n","date":"2025-06-02T20:57:07+08:00","permalink":"https://ttf248.life/p/the-zhejiang-financial-circle-collapsed-and-the-anti-corruption-efforts-over-the-past-two-years-have-not-been-limited-to-government-departments/","title":"浙江金融圈塌方，最近两年的反腐不再局限于政府部门"},{"content":"本地有一个 Git 仓库，其中的子模块在拉取时处于一个临时分支。我在该临时分支上提交了一些代码，随后将子模块切换回了 main 分支。然而，这些提交的代码似乎丢失了，无法在 main 分支中找到。我也找不到那个临时分支的记录。\n解决方案 在Git子模块中提交到了临时分支，切换回main分支后找不到这些提交。这种情况可以通过以下步骤解决：\n确认提交记录：进入子模块目录，查看reflog找到丢失的提交 创建新分支保存提交：基于丢失的提交创建新分支 合并或 cherry-pick 提交到 main：将代码整合到主分支 下面是具体的操作步骤：\n# 进入子模块目录 cd path/to/your/submodule # 查看reflog记录所有HEAD变更（包括未关联分支的提交） git reflog PS F:\\dev\\notebook\\scripts\\hugo-content-suite\u0026gt; git reflog de05175 (HEAD -\u0026gt; main, origin/main, origin/HEAD) HEAD@{0}: checkout: moving from c8d070651310e90d283cb64d98da088c5fe05e73 to main c8d0706 HEAD@{1}: commit: feat: 添加Markdown标记符用法文档，提供详细语法示例与效果展示 48250f5 HEAD@{2}: commit: feat: 移除文章翻译预览功能，简化翻译流程 b8280b6 HEAD@{3}: commit: feat: 添加获取绝对路径功能，支持将相对路径转换为绝对路径 92c354b HEAD@{4}: commit: fix: 修复文章扫描逻辑，确保使用绝对路径进行扫描 de05175 (HEAD -\u0026gt; main, origin/main, origin/HEAD) HEAD@{5}: checkout: moving from main to de05175d4ec0828e3ae95d726b09dfff18f67a23 de05175 (HEAD -\u0026gt; main, origin/main, origin/HEAD) HEAD@{6}: clone: from https://cnb.cool/ttf248/hugo-content-suite.git # 基于丢失的提交创建新分支（例如使用456def提交） git checkout -b saved-work 456def # 切换回main分支 git checkout main # 将保存的工作合并到main（或使用cherry-pick选择特定提交） git merge saved-work # 或 git cherry-pick 456def # 返回主项目目录并提交子模块更新 cd .. git add path/to/your/submodule git commit -m \u0026quot;Update submodule to include new changes\u0026quot; 关键操作说明 git reflog：显示HEAD的所有历史记录，包括未关联到分支的提交 git checkout -b：从任意提交创建新分支，保存你的工作 git merge/cherry-pick：将保存的提交整合到目标分支 如果reflog中找不到记录，可能需要尝试使用git fsck --lost-found查找 orphaned commits，但这种情况比较少见。\n","date":"2025-06-02T16:44:58+08:00","permalink":"https://ttf248.life/p/git-submodule-merge-history-lost/","title":"Git子模块递交记录丢失"},{"content":"最近生物钟有点错乱，凌晨两点多还在折腾 Github Pages 的部署。\n加完班才去吃饭，鄙人刚好吃完就想睡，吃完回来八点半左右，犯困了，想着眯会，直接就睡着了，醒来已经凌晨两点多了。\n还没启动就消亡的分类：AI 研习社\n打脸 昨天才说的不折腾前端，好的今天我们折腾的不是前端，而是 UI UX 的体验。\n项目 有请我们的老朋友，https://github.com/ttf248/ai-coding-demo\n没错，就是原来自选股那个项目，重构项目的整体结构，后续 AI 编程相关的内容都会放在这个项目下。\n部署多个 Pages 项目国内托管在 https://cnb.cool/ttf248/ai-coding-demo，由于众所周知的原因，国内是不支持发布 pages 的，所以我们需要在国外的 Github 上发布。\n博客就是发布在国外的 Github 上。没试过，多个项目发布 pages，还有就是，当前处理的项目，并不是一个传统的博客站点，里面只是有很多文档，叠加几个静态的 html 设计稿。\n没错，这个页面，是我第一次点击，然后就发现了，多个项目部署 pages，并不会影响博客的发布，而是在博客的域名下，增加了一个新的路径。\nhttps://ttf248.life/ai-coding-demo/\n看到这里的时候，我直呼完美。\nAI 研习社 昨天新建的分类，想着通过 AI 来学习很多计算机的课程，比如说：算法、LeetCode 刷题。\n每次的学习记录，发布到博客上，形成一个知识库。新建了分类：AI 研习社\n现在看来，不同的课程，新建不同项目就行，学习笔记都写到项目的 Readme.md 中。\n","date":"2025-05-28T02:55:54+08:00","permalink":"https://ttf248.life/p/github-pages-easter-egg-deploy-multiple-sites/","title":"Github Pages 彩蛋：部署多个 Pages"},{"content":"多年来一直专注于后端开发，最近开始尝试探索 AI 编程，并涉足了一些前端相关的内容。然而，在这段折腾的过程中，我逐渐意识到自己又陷入了一个老毛病——繁花迷人眼。总想着用 AI 来实现一个前端界面，但实际上，这样的尝试对于当前的工作并没有太大的实际帮助，反而分散了精力。\nAI 的适用场景 在小型项目中，AI 工具的确能够发挥巨大的作用，尤其是在编写那些独立性强、与系统耦合度低、业务逻辑简单的函数时更显得得心应手。这类任务通常有明确的输入输出，且上下文依赖较少，非常适合当前 AI 辅助编程的能力范围。\n然而，当面对复杂的系统架构或深度的业务逻辑时，AI 的局限性就会逐渐显现。它可能会生成看似合理但实际上脱离项目真实需求的代码，甚至引入一些难以排查的潜在问题。在这些场景下，AI 更适合作为辅助工具，而非完全依赖的代码生成器。我们需要对生成的代码进行严格的审查和测试，确保其符合实际需求。\n错误与学习的代价 在尝试用 AI 生成前端代码的过程中，我发现自己面临了许多挑战。由于前端并不是我熟悉的领域，排查问题的过程往往耗时耗力。即使通过调整提示词让 AI 重写代码，也难以避免一些低级错误的出现。这种反复尝试不仅浪费了时间，还让我意识到，当前的精力更应该集中在后端的业务逻辑上，而不是在不熟悉的领域中摸索。\n回想起周末完成的那个项目，我更加确信，专注于后端开发和用户交互逻辑，通过控制台来实现功能，才是当前最有效率的选择。等到有更多的时间和精力时，再系统地学习前端知识，或许会是更好的策略。\n前端学习的计划 前端技术栈繁杂多样，想要快速上手并不现实。我计划先选择一个框架，比如 Vue.js 或 React.js，深入学习其核心概念和使用方法。只有在熟悉了基础知识之后，再尝试用 AI 辅助生成前端代码，才能有效避免因不熟悉而导致的错误和时间浪费。\n总之，当前阶段的重点还是要放在后端开发上，稳扎稳打地提升自己的核心技能。等到时机成熟，再去探索前端和 AI 的结合，或许会有更大的收获。\n","date":"2025-05-26T23:54:12+08:00","permalink":"https://ttf248.life/p/old-ailment-stunning-flowers/","title":"老毛病，繁花迷人眼"},{"content":"本站点基于 hugo 开发，但是笔者一直用的都是中文标题，导致生成的文章超链接不太友好，说人话就是，发出去的时候，看起来不太友好，中文的字符在超链接中会被转义成 %E4%BD%A0%E5%A5%BD 这种形式，虽然可以通过设置 slug 来解决，但是每次都要手动设置，太麻烦了。\n所以，今天尝试用 Claude4 来开发一个翻译助手，自动将中文标题转换为英文 slug，并且在文章中添加超链接。这样就可以避免手动设置了。\nclaude4 真香，上下文的能力大幅提升，复杂任务的处理效率也大幅提升。\n项目地址 国内项目地址：https://cnb.cool/ttf248/hugo-content-suite 国外项目地址：https://github.com/ttf248/hugo-content-suite\n代码实现 先说一下实现思路：我们需要扫描所有文章，提取标签信息和文章标题，然后调用本地的大模型（如 gemma-3-12b-it）进行翻译。\n在实际开发中，与前代大模型相比，Claude4 展现了几个显著的亮点。由于功能需求较多，Claude4 自动设计了交互式菜单，全面考虑了各种使用场景。例如，在标签处理方面，Claude4 不仅支持标签的统计与分析，还包括分类统计，甚至能够检测无标签文章。此外，它还提供了预览和生成标签页面的功能。\n无论是对接本地大模型、新增翻译缓存，还是进行大范围的代码重构，Claude4 都一次性完成，几乎没有出现任何问题。尽管项目规模不大，但包含了许多小功能。以往在开发过程中，大模型经常会遗忘前面的内容，而这次的 Claude4 表现非常出色，几乎没有出现遗忘上下文的情况。\n简而言之，智能程度提高了，后续准备切换到 Claude4 进行更多的开发工作，作为日常编码的主力模型。\n翻译缓存 这个点单说，除了减少大模型调用次数，实际本地跑 12b 模型，效率挺高，不耽误事，但是如果每次都要调用大模型，还是会有点慢的。其次就是，为了固定文章的连接，如果执行全量更新操作，文章的标题很长，偶尔就会出现，两次翻译出来的结果不一样的情况，导致文章的链接变了，这个就很尴尬了。\n功能优化 整个项目扔给 Claude4，分析优化的空间，拿到如下的建议：\n配置外置化 - 提高可维护性和灵活性 结构化日志 - 便于问题排查和监控 性能监控 - 了解系统运行状况 用户体验 - 进度条等视觉反馈 错误处理 - 更完善的异常处理机制 代码组织 - 更清晰的模块划分 审核了代码，全部都没什么毛病，比如配置文件，知道自己将原来代码中的配置，转换成默认配置，读取配置文件的时候，如果没有对应的配置文件，就会自动生成一个默认的配置文件，避免了用户的操作失误。\n需求：翻译正文的时候，动态计算当前翻译的效率，预估剩余的时间，相关信息输出到控制台：现在获取了文章的字符数量，每行进行翻译的时候，当前翻译的字符数量，时间，拟合计算每100字符的翻译时间，同时计算文章剩余的翻译预估时间\n代码搞定了，效果不是很满意，我就让AI提供新的设计方案：\n提供多种效率计算方式：实时效率、平均效率、滑动窗口效率 改进显示方式：进度条、分段统计、动态刷新 增加更多有用的指标：API调用次数、成功率等 代码完成以后，发现了新的惊喜，翻译效率的统计信息实时刷屏，但是没有无脑向下滚动。\n翻译正文到 English (总计 7163 字符)... 检测到 53 行需要翻译 [1/53] Stage1/6 [░░░░░░░░░░░░░░░░░░░░░░░░░] 1.9% 翻译 354 字符... ✅ 完成 (3.1s) | API调用 #1 ✅ 完成 (1.5s) | API调用 #2 ✅ 完成 (0.9s) | API调用 #3 ✅ 完成 (0.2s) | API调用 #4 ✅ 完成 (1.0s) | API调用 #5 ✅ 完成 (1.0s) | API调用 #6 ✅ 完成 (0.2s) | API调用 #7 📊 进度: 行 13.2% (7/53) | 字符 12.9% (925/7163) 114.6 字符/秒 📊 ⚡ 效率: 实时76.4 | 平均117.9 | 最近109.0 | 阶段113.6 字符/秒 📊 🎯 成功率: 100.0% (7/7) | 剩余: 46行7 7s] 9.4% 翻译 110 字符... ⏱️ 预估剩余: 55s | 预计完成: 00:10:19 8s] 11.3% 翻译 114 字符... 💾 处理速度: 3211.3 行/分钟 | 总用时: 8s] 13.2% 翻译 16 字符... [8/53] Stage1/6 [███░░░░░░░░░░░░░░░░░░░░░░] 15.1% 翻译 166 字符... 以前控制程序写的也不是很多，好奇如何实现的，翻看代码\n// 清屏并重新显示 (动态刷新效果) if translationCount \u0026gt; 1 { fmt.Print(\u0026quot;\\033[6A\\033[K\u0026quot;) // 上移6行并清除 } 性能统计菜单 新增的性能统计菜单，让我自己设计，都不一定能设计的这么完善\n📊 性能统计: 🔄 翻译次数: 360 ⚡ 缓存命中率: 1.4% (5/365) ⏱️ 平均翻译时间: 315.927234ms 📁 文件操作: 73 ❌ 错误次数: 0\n进度条显示 新增的进度条显示，详细的进度、已用时间、剩余时间预估\n请选择功能 (0-13): 10 🔍 正在收集翻译目标\u0026hellip; 📄 已加载缓存文件，包含 0 个翻译记录\n📊 翻译缓存统计: 🏷️ 标签总数: 229 个 📝 文章总数: 131 篇 ✅ 已缓存: 0 个 🔄 需翻译: 360 个\n确认生成全量翻译缓存？(y/n): y 🚀 正在生成全量翻译缓存\u0026hellip; 📄 已加载缓存文件，包含 0 个翻译记录 🔍 检查缓存中的翻译\u0026hellip; 🔄 需要翻译 360 个新标签 [░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 5/360 (1.4%) - 用时: 3s - 预计剩余: 3m8s💾 已保存缓存文件，包含 5 个翻译记录 [█░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 10/360 (2.8%) - 用时: 6s - 预计剩余: 3m28s💾 已保存缓存文件，包含 10 个翻译记录 [██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 15/360 (4.2%) - 用时: 9s - 预计剩余: 3m30s💾 已保存缓存文件，包含 15 个翻译记录 [██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 20/360 (5.6%) - 用时: 13s - 预计剩余: 3m36s💾 已保存缓存文件，包含 20 个翻译记录 [███░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 25/360 (6.9%) - 用时: 16s - 预计剩余: 3m33s💾 已保存缓存文件，包含 25 个翻译记录 [████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 30/360 (8.3%) - 用时: 19s - 预计剩余: 3m30s💾 已保存缓存文件，包含 30 个翻译记录 [████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 35/360 (9.7%) - 用时: 22s - 预计剩余: 3m25s💾 已保存缓存文件，包含 35 个翻译记录\n=== Hugo 博客管理工具 === 🚀 核心功能 1. 一键处理全部 (完整博客处理流程) 📝 内容管理 2. 生成标签页面 3. 生成文章Slug 4. 翻译文章为多语言版本 💾 缓存管理 5. 查看缓存状态 6. 生成全量翻译缓存 7. 清空翻译缓存 0. 退出程序 ","date":"2025-05-24T03:05:31+08:00","permalink":"https://ttf248.life/p/claude-4-release-hugo-tags-hyperlink-translation-assistant/","title":"Claude4发布，尝试开发：hugo标签、超链接翻译助手"},{"content":"中国计划生育政策在限制人口增长同时，遏制家族式发展，冲击传统社会结构，抑制家族企业扩张与政坛家族势力，对比韩国财阀、印度家族垄断可见其独特性。如今放开生育限制，虽面临低生育率等挑战，却也需警惕新垄断风险，需在多方寻求平衡。\n一、人口控制与家族式发展的消长 计划生育政策作为中国持续近四十年的基本国策，其直接成效显著。数据显示，1978年至2007年，中国人口自然增长率从12‰下降至5.2‰，少生4亿余人，人口占世界比重从22.2%降至20.1%。这种人口增速的骤减，深刻重塑了中国社会的家庭结构。以家族企业为例，计划生育政策实施后，企业主生育子女数量显著下降：政策前生育三孩及以上的比例达40.63%，政策后骤降至18.46%，独生子女生育比例从6.25%升至32.31%。这种结构性变化直接导致家族企业可选择的内部接班人范围大幅缩小，客观上抑制了家族企业的代际扩张能力。\n对比韩国和印度的情况，差异显著。韩国虽未实施严格的计划生育，但生育率长期低迷（2023年为0.7），然而其财阀集团通过交叉持股、遗产税规避等手段，仍牢牢掌控国家经济命脉。五大财阀总营收占韩国GDP超50%，三星集团一家便占全国GDP的20%。印度则呈现另一番景象：79%的经济产出由家族企业贡献，六大财团控制电信、钢铁等关键领域，20家顶尖企业赚取全国企业利润的80%。这种差异的核心在于，中国计划生育政策通过限制家庭规模，从源头削弱了家族企业扩张的人力基础，而韩印两国因政策环境不同，家族势力得以持续渗透经济领域。\n二、垄断遏制与社会结构转型 计划生育政策对经济领域的影响，突出表现在对垄断现象的抑制。中国家族企业因子女数量减少，难以形成韩印式的财阀集团。以韩国为例，财阀通过“循环出资”维持家族控制权，三星家族仅持有集团2%的股份，却通过复杂股权结构掌控全局。而在中国，计划生育后家族企业普遍面临“子承父业”的困境，不得不引入职业经理人或进行股权多元化改革。澎湃新闻的研究显示，计划生育后家族企业女性接班人比例从13.85%提升至34.21%，且接班人学历显著提高，本科及以上学历占比从43.75%升至98.46%。这种转型虽未完全消除家族控制，但显著降低了单一家族垄断市场的可能性。\n在社会结构层面，计划生育政策加速了传统家族核心模式的解体。中国家庭规模从1982年的4.41人/户降至2020年的2.62人/户，小型化家庭削弱了家族在经济、教育、社会支持等方面的功能。与之形成对比的是印度，其家庭规模仍保持在4人左右，种姓制度与家族势力深度绑定，导致社会流动性低下。中国的家庭结构转型为个体主义的发展创造了空间，2023年中国单身成年人口达2.4亿，消费市场呈现“一人经济”崛起的趋势，这种转变进一步稀释了家族经济的影响力。\n三、政治领域的权力分散化 计划生育政策对政治生态的影响同样深远。传统上，家族势力通过血缘和姻亲关系渗透基层政治。例如，河南新野县161个政治家族几乎把持所有政府部门，副科级以上干部中20%属于“官二代”。但计划生育政策实施后，家庭规模缩小使得家族网络扩张受限。北京大学的研究显示，计划生育后官员子女数量减少，家族政治网络的复杂度显著下降。此外，政策推动的教育普及（人均受教育年限从1982年的5.2年提升至2023年的10.9年），促进了社会流动，削弱了家族势力对政治资源的垄断。\n对比韩国和印度，韩国财阀与政治的深度勾结（如三星集团高管与政府的权钱交易）和印度种姓制度下的家族政治世袭，凸显了中国政策的独特性。中国通过计划生育政策，客观上减少了权力世袭的可能性。尽管县域政治中仍存在家族现象，但整体趋势是权力结构的分散化。2025年全国两会期间，有政协委员提议将“人口与计划生育法”更名为“人口与生育法”，全面放开生育，这一举措可能进一步影响未来政治生态的演变。\n四、政策调整后的挑战与机遇 2016年全面二孩政策、2021年三孩政策的实施，标志着中国生育政策的重大转向。然而，政策效果有限：2022年生育率仅为1.18，远低于世代更替水平（2.1）。放开生育对家族企业的影响呈现双重性：一方面，部分企业家可能通过多生育增强家族传承能力，如浙江娃哈哈集团宗庆后之女宗馥莉作为独生女接班；另一方面，高育儿成本（一线城市养育一个孩子至18岁平均成本达100万元）和职业女性生育意愿下降，使得家庭规模扩张受限。\n在经济领域，放开生育可能催生新的垄断形态。三孩政策推动母婴、托育等行业集中度提升，2025年婴幼儿托育市场规模预计达1621.3亿元，头部企业通过并购整合中小厂商，市场集中度CR5超55%。这种集中度提升可能带来效率，但也需警惕新的垄断风险。政府需在鼓励生育与防止市场集中之间寻求平衡，如通过反垄断法加强监管，同时提供育儿补贴（如杭州三孩家庭每月可领3000元奶粉补贴）降低家庭负担。\n在政治领域，放开生育可能对家族势力产生微妙影响。尽管短期内难以恢复传统家族政治网络，但长期看，多子女家庭可能在基层政治中形成新的影响力。因此，完善干部选拔机制、加强监督（如建立干部亲属任职回避制度）仍是防范权力世袭的关键。\n五、国际镜鉴与未来展望 韩国和印度的经验表明，家族势力的消长与政策导向密切相关。韩国通过扶持财阀实现经济腾飞，但也付出了社会公平受损的代价；印度因缺乏有效政策遏制家族垄断，导致贫富分化加剧。中国的计划生育政策在控制人口的同时，客观上抑制了家族势力扩张，但也带来老龄化加剧、劳动力短缺等问题。\n未来，中国需在人口政策与社会经济发展之间寻求新平衡。一方面，通过生育支持政策（如延长产假、建设普惠托育机构）提升生育率；另一方面，加强反垄断执法，防止家族企业通过资本运作形成新的垄断。在政治领域，需进一步推进基层民主建设，完善监督机制，确保权力运行透明化。\n总之，计划生育政策作为中国社会变革的重要推手，其影响远超人口领域。它重塑了家庭结构、经济模式和政治生态，为中国避免陷入韩印式的家族垄断陷阱提供了路径。随着政策调整，如何在新的人口格局下平衡效率与公平、自由与秩序，将是中国面临的长期挑战。\n","date":"2025-05-24T02:36:49+08:00","permalink":"https://ttf248.life/p/china-family-planning-policy-impacts/","title":"计划生育政策的多维影响：从社会结构到经济政治的深层变革"},{"content":"自从新建了AI 灵感碰撞坊，很多有的没的东西，都在试着用AI记录，发布出来，静下来自己思考的东西，反而越来越少了，以后需要稍微控制下此栏目的产出，整合为月刊的形式不错，每月发布一篇就行。\n这就像是某种后遗症，或者说是副作用，效率是提高了，但是思考的深度和广度却下降了。\n效率提升：不可否认 鱼的七秒钟见闻以前这个栏目维护的不多，有些热点事件，由于懒并没与去互联网搜索资料、整理记录下来，现在有了各种AI工具，整理好大纲就行，AI能做到自动联网搜索记录相关的事件，生成我需要的文章，简单的整理下格式，发布出来就行。\n这就像是一个懒人福音，效率提高了不少，甚至可以说是事半功倍。\n抛开写稿子，写代码的时候，效率提升是实打实的，很多代码的编写，以前是需要详细阅读API接口文档说明，现在直接跳过，这种跳过相当的有必要，熟悉API属于体力劳动，而不是脑力劳动，AI来搞定这部分内容，刚刚好。\n垃圾内容 很多稿子，内容质量不高，不能说没有东西，读起来怎么说，没有烟火气息，是我以前不喜欢的风格，味同嚼蜡。\n换个角度来说，AI生成的内容，确实是有点像是流水线生产出来的东西，缺乏灵魂。\n新时代的互联网垃圾\n遗忘性 此类型的稿子，都是AI生成的，读者的情况不清楚，但是时间长了，我自己的印象也会模糊，甚至是忘记了。\n类似的问题，写代码的时候也会发生，不翻看代码提交记录，根本不知道自己当时是怎么想的，为什么要这么写。特别是代码通过和AI反复沟通，最后生成的代码，和最初的想法差别很大，甚至是完全不一样。\n搜索 最近打开谷歌、百度的次数明显减少了，很多问题用AI来搜索，交互也好、搜索的结果也好，都比传统的搜索引擎要好很多。\n现在让我们祭奠下不知道是否还活着的bing ai，属于大厂里面最早发布的，能联网搜索的AI工具。\n谷歌用的少了，访问stackoverflow的次数也少了，很多问题直接问AI就行了，这网站也逐渐要被时代所淘汰。\n结尾 笔者还在维护的博客，原本也没多少访问量，现在就更不指望了，更多是个记录的地方，写给自己看的。\n","date":"2025-05-14T19:39:50+08:00","permalink":"https://ttf248.life/p/ai-overuse-side-effects/","title":"AI用多了，有点后遗症"},{"content":"2020-2025年江西省教师招聘呈现大幅缩减趋势：特岗教师招聘量由6,617人锐减至32人（降幅99.5%），国编教师由11,324人降至2,146人（降幅81.1%）。主科（语数英）占比稳定但总量收缩，音体美等学科虽比例上升但绝对数量有限（如2025年各仅招2人）。政策端推行\u0026quot;退一补一\u0026quot;编制紧缩，教师资源向职教及偏远地区倾斜，传统中小学岗位大幅缩减，2025年部分学科计划数为零\n江西省历年特岗教师招聘数量，统计最近五年的数据，按照学科分别统计，整理为表格\n——————\n根据江西省教育厅、人力资源和社会保障厅等官方发布的招聘公告及公开数据，整理2020-2025年特岗教师与国编教师招聘情况如下。需说明的是，2025年数据为计划招聘数，且部分年份学科细分信息未完全公开，表格中“未细分”标注的学科为总量统计或数据缺失。\n一、2020-2025年江西省特岗教师招聘数据 年份 总招聘人数 语文 数学 英语 物理 化学 生物 政治/道德与法治 历史 地理 音乐 体育 美术 信息技术 未细分 2020 6,617 1,200 1,100 900 400 300 300 500 400 400 300 300 300 200 317 2021 6,020 1,100 1,000 800 350 280 280 450 350 350 280 280 280 180 280 2022 3,835 800 750 600 250 200 200 350 250 250 200 200 200 150 180 2023 3,146 650 600 500 200 150 150 300 200 200 150 150 150 100 146 2024 2,008 400 380 300 150 120 120 250 150 150 120 120 120 80 86 2025 32 8 6 4 2 2 2 2 2 2 2 2 2 0 0 二、2020-2025年江西省国编教师招聘数据 年份 总招聘人数 语文 数学 英语 物理 化学 生物 政治/道德与法治 历史 地理 音乐 体育 美术 信息技术 未细分 2020 11,324 2,200 2,000 1,800 600 500 500 700 600 600 500 500 500 300 524 2021 13,324 2,500 2,300 2,000 700 600 600 800 700 700 600 600 600 400 624 2022 10,200 2,000 1,800 1,500 500 400 400 600 500 500 500 500 500 300 500 2023 7,821 1,500 1,400 1,200 400 300 300 500 400 400 400 400 400 200 421 2024 3,957 800 750 600 250 200 200 350 250 250 200 200 200 150 257 2025 2,146 400 380 300 150 120 120 250 150 150 120 120 120 80 86 三、数据说明 数据来源：江西省教育厅、人力资源和社会保障厅历年招聘公告及官方统计（2020-2024年为实际招聘数，2025年为计划数）。 学科分类： 特岗教师以农村义务教育阶段学科为主，2025年仅保留少量主科岗位。 国编教师覆盖全学段，学科设置更全面，包含学前教育、特殊教育等（因数据未细分，未单独列出）。 趋势分析： 总量锐减：2025年特岗教师招聘量较2020年下降99.5%，国编教师下降81.1%，反映人口结构变化和教育资源调整。 学科冷热： 主科（语文、数学、英语）占比稳定，但招聘量逐年收缩。 音体美、信息技术等学科占比上升，但绝对数量有限（如2025年音体美各仅招2人）。 部分学科（如英语）因学生数量减少出现停招。 政策背景： 编制收紧：推行“退一补一”政策，严控新增编制，2024年编制外岗位占比达68.6%。 结构性调整：教师资源向职业教育、偏远地区倾斜，传统中小学招聘大幅缩减。 四、获取完整数据建议 官方渠道： 江西省教育厅官网（http://jyt.jiangxi.gov.cn） 江西省人力资源和社会保障厅官网（http://rst.jiangxi.gov.cn） 工具推荐： 江西人事考试网（http://www.jxpta.com）：历年岗位表下载。 江西智慧教育平台（http://www.jxedu.gov.cn）：特岗教师专项数据。 注意事项： 2025年部分学科（如信息技术）计划数为0，实际招聘可能通过调剂补充。 学科分类可能存在年度差异（如“道德与法治”与“思想政治”合并），以当年公告为准。 如需更详细的学科岗位分布或地区细分数据，建议直接联系当地教育局或通过官方招聘系统查询。\n","date":"2025-05-12T18:59:51+08:00","permalink":"https://ttf248.life/p/jiangxi-specialist-and-national-teacher-recruitment-trends-2020-2025/","title":"特岗教师招聘，突然就变少了"},{"content":"github-readme-stats 是一个 GitHub 个人资料的统计信息生成器，允许用户在其 GitHub 个人资料中显示各种统计信息和图表。它提供了多种自定义选项，可以根据用户的需求进行调整。\n笔者管理仓库习惯按照项目分组，github 不支持仓库分组，只能通过拆分不同的组织来实现。github-readme-stats 最新分支无法支持跨越不同组织的仓库统计，笔者 fork 了一个分支，合并了对应的代码。\n最终效果 Pull Request 原始地址 Adds the ability to include data from organization repositories\n合并 PullRequest 到 Fork 的仓库 要将某个 Pull Request (PR) 合并到你 fork 的仓库，有几种方式可以做到，取决于你是想：\n从上游（upstream）仓库合并 PR 到你的 fork，还是 从其他人的 fork 中合并 PR 到你的 fork，或者 合并一个开在你 fork 上的 PR（比如别人给你 fork 提了个 PR） 我先给你一个最常见的场景：你 fork 了一个仓库，想把上游的某个 PR 合并到你的 fork。操作流程如下👇：\n✅ 方法一：命令行方式（最通用） 步骤 1：克隆你自己的 fork git clone https://github.com/你的用户名/仓库名.git cd 仓库名 步骤 2：添加 upstream（原仓库地址） git remote add upstream https://github.com/原作者用户名/仓库名.git 步骤 3：抓取 upstream 的 PR 分支 找到你想合并的 PR 编号，例如 PR #123。\n你可以这样拉取该 PR 的代码：\ngit fetch upstream pull/123/head:pr-123 步骤 4：切换并合并分支 git checkout main # 或者你自己的目标分支 git merge pr-123 如果一切正常，你可以推送到你 fork 上的 GitHub 仓库：\ngit push origin main ✅ 方法二：GitHub 网页界面（简单但有限） 如果你在 GitHub 网页上看到某个 PR 是对上游仓库的，你可以：\n进入该 PR 页面。 点击右上角 “Commits” 或 “Files changed”，看这个 PR 是基于哪个分支。 在你的 fork 页面，新建一个分支，然后手动 cherry-pick PR 的 commit（需要点 Git 技术）。 或者点“Open in GitHub Desktop”，用 GUI 工具来合并。 🚀 如果别人是对你的 fork 提了 PR 你就直接进入 PR 页面，点击 “Merge pull request” 按钮即可。\n需要我根据你现在的具体场景（比如 PR 链接、你是用网页还是命令行）来手把手演示吗？也可以给我具体链接，我帮你分析最简单的做法。\n","date":"2025-05-07T18:44:03+08:00","permalink":"https://ttf248.life/p/merge-pullrequest-to-forked-repo/","title":"合并 PullRequest 到 Fork 的仓库"},{"content":"脚本用于批量修改 Git 历史提交的作者信息，通过 git filter-branch 重写历史提交记录。\n您提供的脚本用于批量修改 Git 仓库历史提交中的作者信息，整体思路是正确的，但在 git filter-branch 的 --env-filter 中使用数组（如 OLD_EMAILS=(\u0026quot;...\u0026quot;)）可能会导致兼容性问题，因为某些 shell 环境（如 /bin/sh）并不支持数组语法。\n为提高兼容性，建议将数组替换为以空格分隔的字符串，并使用 for 循环遍历每个旧邮箱地址。以下是修改后的脚本示例：\n#!/bin/sh git filter-branch --env-filter ' OLD_EMAILS=\u0026quot;TianlongXiang51@gmail.com nick@qq.com tianlongxiang51@gmail.com\u0026quot; CORRECT_NAME=\u0026quot;tianlong.xiang\u0026quot; CORRECT_EMAIL=\u0026quot;tianlong.xiang@foxmail.com\u0026quot; for OLD_EMAIL in $OLD_EMAILS do if [ \u0026quot;$GIT_COMMITTER_EMAIL\u0026quot; = \u0026quot;$OLD_EMAIL\u0026quot; ] then export GIT_COMMITTER_NAME=\u0026quot;$CORRECT_NAME\u0026quot; export GIT_COMMITTER_EMAIL=\u0026quot;$CORRECT_EMAIL\u0026quot; fi if [ \u0026quot;$GIT_AUTHOR_EMAIL\u0026quot; = \u0026quot;$OLD_EMAIL\u0026quot; ] then export GIT_AUTHOR_NAME=\u0026quot;$CORRECT_NAME\u0026quot; export GIT_AUTHOR_EMAIL=\u0026quot;$CORRECT_EMAIL\u0026quot; fi done ' --tag-name-filter cat -- --branches --tags 注意事项：\n在执行此脚本之前，建议备份您的仓库，以防止意外情况发生。\n此操作会重写 Git 历史，修改提交的作者信息，可能会导致提交哈希值发生变化。\n如果您已经将更改推送到远程仓库，需要使用强制推送：\ngit push --force --tags origin 'refs/heads/*' 请谨慎使用强制推送，尤其是在多人协作的项目中，以避免对他人造成影响。\n统计仓库所有的不重复作者邮箱\ngit log --format='%an \u0026lt;%ae\u0026gt;' | sort -u ","date":"2025-05-07T18:38:31+08:00","permalink":"https://ttf248.life/p/git-modify-commit-message/","title":"Git修改历史记录中的递交信息"},{"content":"北京协和 “4+4” 项目（4 年非医学本科 + 4 年医学博士）主打跨学科精英培养，2025 年董袭莹事件曝光其借家庭背景（医学 / 科研世家）进入项目，学历存模糊性、论文涉抄袭，暴露该模式精英化招生与公平性矛盾，学制压缩及规培争议待解。\n提示语 编写博客：协和 4+4 来龙去脉，核心：天宫的一角、被凡人看见了，董小姐的家庭背景，正常医学博士不可能八年毕业，董小姐家庭背景、学历背景\n协和4+4：被拆解的医学教育\u0026quot;天宫\u0026quot; 北京协和医学院的\u0026quot;4+4\u0026quot;项目，自2018年启动以来便被视作中国医学教育的\u0026quot;天宫\u0026quot;。这个仿照美国医学教育体系设计的项目，以\u0026quot;纳多学科背景者、纳爱医者、纳天下贤才\u0026quot;为理念，试图在传统医学教育体系中撕开一道裂缝。其核心逻辑在于：用4年非医学本科教育+4年医学博士培养，替代传统的5+3+3（本科5年+硕士3年+博士3年）模式，培养跨学科医学领军人才。\n这一模式的\u0026quot;天宫\u0026quot;属性体现在三个维度：\n招生门槛的精英化：早期要求申请者来自QS/Times/US News排名前50的大学或US News文理学院前10（如巴纳德学院），后期虽放宽至前100名，但仍需GPA 3.6以上或年级前30%。 培养路径的国际化：采用美国式的器官-系统整合课程、PBL教学法，学生需在4年内完成人体解剖学、病理学等核心课程，并参与临床实习。 出口质量的争议性：尽管执业医师考试通过率（95.2%）略低于传统八年制（98.5%），但毕业生多进入协和系医院，职业发展与传统路径无显著差异。 董袭莹事件：凡人窥见的\u0026quot;天宫\u0026quot;裂痕 2025年4月，中日友好医院胸外科医生肖飞被举报婚内出轨事件，意外揭开了协和4+4项目的\u0026quot;神秘面纱\u0026quot;。涉事者董袭莹的履历引发三重质疑：\n学历背景的模糊性：\n本科院校争议：董袭莹自称毕业于哥伦比亚大学，但实际就读的是其独立学院巴纳德学院（2025年US News文理学院排名第14位）。尽管该校符合协和\u0026quot;文理学院前20\u0026quot;的要求，但其毕业证上同时标注\u0026quot;巴纳德学院\u0026quot;与\u0026quot;哥伦比亚大学\u0026quot;，在国内招聘市场易被误认为哥大本部。 专业跨度争议：经济学本科+临床医学博士的路径，虽符合4+4项目\u0026quot;多学科背景\u0026quot;的定位，但被质疑缺乏医学预科课程基础。其博士论文《跨模态图像融合技术在医疗影像分析中的研究》被指与北科大发明专利高度雷同，涉嫌学术不端。 家庭背景的特殊性：\n学术资源垄断：父亲为中冶建研院书记，母亲为北科大工程技术研究院副院长，祖父为协和影像领域院士，外公为材料领域外籍院士，姑姑姑父为北科大博导。这种\u0026quot;医学+科研+高校\u0026quot;的复合家庭背景，为其提供了推荐信（需2名生物医学副教授推荐）、科研合作（如北科大专利）等隐性资源。 职业路径跳跃：规培阶段从胸外科转至泌尿外科，研究方向横跨骨科、消化内科、影像学等多领域，被质疑\u0026quot;资源铺路\u0026quot;。 学制争议的放大：\n时间压缩的合理性：传统医学博士需11年（5+3+3），而4+4项目将时间压缩至8年。尽管协和强调\u0026quot;课程整合\u0026quot;与\u0026quot;早期临床\u0026quot;，但部分医生指出，其临床实习时间（12个月）仍少于传统八年制（18个月），可能影响技能积累。 规培减免的争议：部分规培基地允许4+4毕业生减免1年规培，被质疑破坏行业公平性。 争议背后的医学教育困局 董袭莹事件折射出中国医学教育的深层矛盾：\n精英化与公平性的冲突：\n4+4项目的\u0026quot;申请-审核制\u0026quot;本质上是对美国医学院模式的移植，但中国缺乏类似MCAT的标准化考试，推荐信、科研经历等主观评价易受家庭背景影响。 数据显示，2023届4+4毕业生中，30%来自清北复交，25%来自海外名校，家庭背景对申请的影响显著。 学制改革的现实困境：\n时间压缩的代价：4+4学生科研产出（如论文数量）显著低于传统八年制，被指\u0026quot;重临床轻科研\u0026quot;。 行业认可度分化：三甲医院更看重协和招牌，而基层医院对4+4毕业生的临床能力持谨慎态度。 医学教育的国际接轨之惑：\n美国4+4模式需通过MCAT考试，并接受3-7年规培，而中国4+4项目简化了准入与规培环节，导致\u0026quot;形似神不似\u0026quot;。 教育部数据显示，2024年全国医学博士招生中，4+4项目占比不足5%，其规模化推广仍面临阻力。 结语：重构医学教育的\u0026quot;天宫\u0026quot;秩序 协和4+4项目的争议，本质上是精英教育与公众期待之间的碰撞。当\u0026quot;天宫\u0026quot;的一角被凡人窥见，暴露的不仅是个别案例的瑕疵，更是整个医学教育体系的深层矛盾。未来的改革需在三个层面发力：\n透明化选拔机制：引入标准化考试（如中国版MCAT），减少推荐信等主观因素的影响。 延长规培周期：将4+4毕业生的规培时间恢复至3年，确保临床能力达标。 强化过程监管：建立学术诚信审查机制，对跨学科研究进行严格的原创性验证。 医学教育的\u0026quot;天宫\u0026quot;不应是少数人的特权，而应成为真正培育医学精英的摇篮。只有当选拔机制的公平性、培养过程的严谨性、职业发展的规范性得到全面保障，这场医学教育的\u0026quot;天宫实验\u0026quot;才能真正落地生根。\n","date":"2025-05-07T01:08:27+08:00","permalink":"https://ttf248.life/p/medical-education-and-the-butterfly-effect-of-dong-xiying-incident/","title":"医学教育的天宫与董袭莹事件的蝴蝶效应"},{"content":"上个月我们试用了 cursor，但是由于免费额度的限制，并没有做太复杂的功能开发，只是简单的测试了一下。那会就发现，字节也发布了类似的产品，两者底层调用的大模型一样，都是 Claude-3.5。\n字节产品叫做 Trae，先发布的 mac 版本，今年二月份，终于发布了 windows 版本。大厂的东西就是好，能免费白嫖，不用掏钱，无限量使用 Claude-3.5，这个模型的效果还是很不错的。\n最终卡在了K线图的开发上，由于本人基本不懂 react，所以只能放弃了。想要继续开发，需要笔者补充一些前端的基础知识，将任务拆分的更细，而不是直接给一个大任务：开发K线图。\n发现的问题 由于使用国外的 AI 模型，Vue3 + Element-Plus 的训练数据不足，因此选择了 React 作为前端框架 可能存在偶发的语法错误，需要人工修复 部分复杂问题的解决方案需要人工指引 代码结构优化需要人工指导 其中耗时最多的地方，打包前端代码到容器中，由于笔者零基础 .env.production tsconfig.json，完全是没有概念的，这些还是中途求助豆包，才捋顺对应的逻辑。前端开发 dev 模式和 build 模式，对于代码的检查，差异很大。后端数据库和服务的容器脚本，合计五分钟就搞定了。\nAI 目前更多的提高开发的效率，你有基础是最好的，并不是 AI 会帮你解决所有的问题。\n仓库地址 正如标题说的，我们这次是能不写就不动手，和AI硬聊，设计开发自选股模块。看最终能做出来什么效果。\n仓库地址：https://github.com/ttf248/trae-demo\n详细的使用方法，可以看仓库的 README.md 文件。\n仓库包含很多递交记录，大部分都是我和 Trae 的对话记录，以及我对 Trae 的一些功能的测试，备注了是否人工干预来实现对应的功能。\nPrompt 项目是从零开始创建，下面是项目的 Prompt：\n基于项目原型图，开发功能：自选股，需要支持合约的新增、删除、修改、查询。自选股界面需要展示基础的行情数据。支持多个不同的市场切换。 前端：react 后端：golang gin gorm 数据库：PostgreSQL 服务端需要支持跨域请求，同时需要考虑数据的校验和错误处理，如果后端服务不可用，前端需要告警提示。 后端需要展示请求和应答的日志；前端也打印通讯的日志，方便排查问题。 UI和交互优化 前端界面的设计完全依赖的 Grok，我们首先在 Trae 里面做出来产物的雏形，但是没有审美，由于使用的模型，代码能力很强，但是其他能力比较弱，所以我们需要使用 Grok 来优化前端的 UI。\n通过将当前的界面截图，上传到 Grok 里面，然后让它帮我们优化 UI，可能一次性拿到很多的优化建议，我们人工评估，然后拷贝到 Trae 中执行，观察优化的效果。\n技术栈 前端：React + TypeScript 后端：Golang + Gin + GORM 数据库：PostgreSQL 17 系统架构 后端架构 后端采用 Golang 的 Gin 框架实现 RESTful API，主要模块包括：\n数据库模块\n使用 GORM 作为 ORM 框架 支持环境变量配置数据库连接 自动进行数据库表迁移 路由模块\nRESTful API 设计 统一的错误处理机制 内置请求日志记录 跨域处理\n支持本地开发环境跨域 可配置的 CORS 策略 支持 Cookie 跨域 前端架构 前端使用 React + TypeScript 构建，实现了：\n股票列表展示 自选股管理 行情数据展示 错误提示机制 ","date":"2025-02-27T23:20:39+08:00","permalink":"https://ttf248.life/p/design-develop-custom-stock-module-no-code/","title":"不写代码，设计开发自选股模块"},{"content":"人工智能（AI）近年来无疑是技术领域最为热议的话题之一，尤其是在过去的两年里，AI技术得到了飞速的进展。无论是深度学习、自然语言处理，还是计算机视觉、自动化决策系统，AI的应用场景层出不穷。然而，尽管技术不断取得突破，AI仍然面临着一个类似于Docker发布前的瓶颈——缺乏一个杀手级的应用来真正引爆市场。\nPrompt: 编写文章：AI发展两年，有点类似 docker 发布前的状态，缺乏一个杀手级应用，基于现有的技术，弄出来一个完美的落地场景，docker 是没用到太多新技术，但是整套方案很合理，改变了运维、开发的工作流程\nAI发展现状：技术已经成熟，但应用尚需突破 从技术层面来看，AI在过去的两年里已经取得了相当大的进展。无论是OpenAI推出的GPT系列模型，还是Google的BERT、DeepMind的Alpha系列，AI的处理能力已经远超之前的预期。尤其是自然语言处理领域，GPT-4等模型不仅具备了强大的生成能力，还在理解和推理上展现了令人惊叹的表现。\n然而，尽管技术日新月异，AI在实际应用上的落地却面临一定的挑战。与Docker发布前的状态类似，虽然AI的潜力巨大，但目前尚未出现一个真正能够广泛普及、改变产业的杀手级应用。大家都在谈论AI的前景，却未必能够找到一个可以直接带来革命性改变的应用场景。很多AI应用仍然停留在初步的尝试阶段，且大部分需要进一步的整合与优化。\nDocker与AI的相似性：技术不一定是创新，方案才是关键 如果回顾Docker发布前的历史，我们不难发现，当时的技术环境和AI的发展现状有诸多相似之处。Docker发布之前，容器技术并不是新鲜事物，早期的LXC（Linux Containers）和虚拟化技术都具备了容器化的基本能力。但Docker通过对现有技术的巧妙整合和优化，提出了一种更简单、直观且高效的方案。这套方案并没有引入颠覆性的技术，但却解决了许多运维和开发过程中的痛点，极大地简化了软件的部署、扩展和管理流程。\n同样，AI领域也面临类似的情形。目前的AI技术虽然已不再是“新鲜事物”，但要想真正实现大规模的应用，仍然需要一个完美的落地场景，像Docker一样，将现有技术融合并优化，形成一个合理的应用方案。AI的杀手级应用，可能并不依赖于全新的技术突破，而是如何通过整合现有的技术，解决实际业务中的痛点和需求。\n如何找到AI的“Docker时刻”？ 要让AI技术真正得到广泛应用，需要从几个方面着手：\n实际场景的深度挖掘\n目前，许多AI的应用场景仍然偏向于实验性质，缺乏大规模的实际落地。例如，AI客服、智能推荐等领域虽然应用广泛，但其功能仍有许多局限，尚未能突破行业的瓶颈。真正的突破，可能来自于那些被传统方法困扰已久的行业，比如医疗、制造业、物流等领域，AI可以通过更高效的数据处理、预测分析，帮助企业在这些复杂的场景中提升效率和降低成本。\n产品化与易用性\n类似于Docker通过简化容器化流程来提升运维的效率，AI产品的易用性同样至关重要。AI的普及不仅仅是技术的普及，更是其产品化的普及。将AI集成到日常工作流中，让用户在不需要深入理解技术的前提下，能够轻松使用这些工具，这是AI落地的重要一步。\n生态建设与标准化\n任何一项新技术的广泛应用，都离不开生态的建设。Docker之所以能快速崛起，正是因为它的开放性和兼容性，使得开发者能够轻松地与各种云平台、工具和服务对接。同样，AI的未来也依赖于生态系统的建设。AI的标准化、模型的共享、数据的开放，以及技术的可集成性，都将影响AI是否能够形成广泛的行业应用。\n结语：AI的未来充满可能性，但仍需更完善的落地方案 尽管AI的技术在过去两年里取得了长足的进步，但目前它依然处于“没有杀手级应用”的阶段。与Docker发布前的容器化技术相似，AI需要一个合理的应用场景，将现有的技术与业务需求深度融合，才能真正实现大规模的应用和普及。技术创新固然重要，但能够简化流程、提高效率的解决方案，更能推动技术的普及与发展。\n未来，AI可能会像Docker一样，不是通过颠覆性的技术突破，而是通过整合现有的技术，打造出一个完美的应用场景，最终改变我们工作和生活的方式。\n","date":"2025-02-20T18:16:37+08:00","permalink":"https://ttf248.life/p/ai-development-two-years-like-docker-pre-release/","title":"AI发展两年：有点类似Docker发布前的状态"},{"content":"美股有三个交易时段，分别是：盘前、盘中、盘后；接口推送数据还是数值增量的逻辑（尽可能的节约带宽），仅在第一次发送全量，第二次开始所有字段都是增量推送逻辑。\n为什么不用最优方案？牵扯到不同项目组，有些都已经上线多年。我方属于新对接，所以只能尽量兼容。\n一系列问题 单从摘要上看，可能还觉得没什么问题，问题带入组内的系统架构，带出来一系列问题。刚处理上一个问题，又遇到了新的问题，这个问题是由于之前的问题引起的。\n无法识别交易时段 已知盘中阶段定义为在 protobuf 中定义为 0，但是在收到数据的时候由于是增量推送，业务方无法有效识别这个零是默认值，还是真实的业务值。\n通俗理解：每次收到 0，无法判断这个 0 是新行情设置的值，还是 protobuf 的默认值\n引入 optional Since protobuf release 3.15, proto3 supports using the optional keyword (just as in proto2) to give a scalar field presence information\n组内的通讯协议是基于 protobuf 的，但是由于历史原因，选择的版本比较老，并没支持 optional 关键字。懂的都理解，由于从底层开始引入 protobuf，项目底层通过静态库的方式发布，导致整个编译链路都需要升级，这个成本是非常高的。\ngcc 版本问题 好不容易想了方案，底层发布两个不同的版本，尽可能的控制 protobuf 新版本的编译依赖传播。但是在编译的时候，发现 gcc 版本太低，不支持 protobuf 的新特性。\n组内常用的服务器类型：centos7、centos8。centos7 默认的 gcc 版本是 4.8，centos8 默认的 gcc 版本是 8.3。由于 protobuf 的新特性需要 gcc 版本在 7.4 以上，所以 centos7 无法支持。\nBug 82461 - [7 Regression] Temporary required for brace-initializing (non-literal-type) member variable。\n最后折腾一圈，相关服务的部署、编译服务器都挪到 centos8 上，解决了这个问题。\n合理的枚举 回顾整个问题，其实有一个更简单、高效的解决方案：调整枚举的定义，从 1 开始编号，而不是从 0 开始。这样就能有效区分默认值和业务值，避免上述一系列麻烦。\n为什么从 1 开始更合理？ 在 protobuf 中，枚举类型的默认值固定为 0。如果我们将有意义的业务值定义为 0（比如“盘中”），在增量推送时，业务方无法判断收到的 0 是业务值还是未设置的默认值。而如果将枚举从 1 开始定义，0 可以保留为一个无意义的默认值或“未知”状态，问题迎刃而解。\n建议的实践：\n在设计 protobuf 枚举时，始终将 0 定义为无意义的默认值（如 UNKNOWN 或 RESERVED）。 将实际业务值从 1 开始分配，确保与默认值 0 区分开。\n通过这一小调整，我们不仅解决了交易时段识别的问题，还为未来的协议设计提供了一个宝贵的经验教训。\n","date":"2025-02-20T15:26:51+08:00","permalink":"https://ttf248.life/p/protobuf-zero-value-trap/","title":"Protobuf零值陷阱：当默认值成为业务逻辑的隐形杀手"},{"content":"在2024年的国庆前夕，中国股市经历了一场令人瞩目的暴涨行情，然而假期过后，市场却迎来了戏剧性的暴跌转折。这场股市的“冰火两重天”，不仅让投资者们经历了过山车般的心跳，也引发了市场对政策、经济和市场规律的深刻思考。\nPrompt: 以去年国庆前股市暴涨为主题，编写博客，最后记得带上国庆后的股市暴跌，文章风格：新闻记事\n国庆前的股市暴涨：政策驱动的狂欢 2024年国庆前的五个交易日，中国股市从低迷瞬间跃升至“沸腾模式”。9月30日，A股市场全线放量大涨，主要指数涨幅均创历史新高。上证指数大涨8.06%，深证成指上涨10.67%，创业板指飙升15.36%，北证50指数更是创下史上最大单日涨幅，暴涨22.84%。市场情绪极度亢奋，沪深北三市当日成交额达到26115亿元，较上一交易日大幅放量11559亿元，大盘中超5300只个股集体上涨，呈现“一片红”的局面。\n这波行情的核心推动力，源于政府一系列超预期政策的集中发布及由此引发的市场预期变化。9月24日，中国人民银行宣布降准、降息，降低存量房贷利率，并统一房贷的最低首付比例。9月26日的中央政治局会议强调，要加大财政货币政策逆周期调节力度，努力提振资本市场，大力引导中长期资金入市。9月30日，四项房地产支持政策密集出台。这些政策措施向市场传递了政府全力稳市场、稳增长的决心。\n国庆后的股市暴跌：狂欢后的冷静与调整 然而，国庆假期过后，市场情绪急转直下。10月8日，A股以近乎涨停的幅度强势开盘，然而大幅高开之后，市场迎来剧烈震荡，最终高开低走报收。自此之后，市场重心不断下移，截至10月16日，沪指振幅超过15%，累计下跌470多点。10月8日至10日，A股核心指数全线走低，其中创业板指下跌6.21%。 这波暴跌的原因，一方面是对前期快速上涨累积风险的消化，另一方面也与市场对政策预期的调整有关。部分投资者认为，政策的短期效应已经显现，但长期效果仍需观察。此外，外围市场的波动也对A股产生了影响。10月9日，恒生指数暴跌9.41%，A50期货暴跌10.4%，进一步加剧了市场的下跌。\n市场的反思与展望 国庆前后股市的剧烈波动，引发了市场对政策、经济和市场规律的深刻反思。一方面，政策的短期刺激效应显著，但长期效果仍需观察。另一方面，市场的快速上涨和下跌，也提醒投资者要保持理性，避免情绪化投资。\n未来，A股市场能否走出真正的“长牛”行情，仍取决于政策能否有效传导至实体经济，最终带动经济基本面的实质性改善。投资者应密切关注政策的具体落实情况，以及经济数据的变化，合理调整投资策略。\n国庆前后股市的暴涨与暴跌，是一场政策与市场的博弈，也是一次对投资者心态的考验。在这场“冰火两重天”的行情中，我们看到了市场的力量，也看到了政策的影响力。未来，市场将如何演绎，让我们拭目以待。\n","date":"2025-02-15T03:42:26+08:00","permalink":"https://ttf248.life/p/long-time-no-see-bull-market-in-stocks/","title":"好久不见的股票牛市"},{"content":"咱中国人啊，每逢春节，阖家团圆，看电影成了必不可少的娱乐项目。今年春节档，《哪吒》那叫一个火爆出圈，大街小巷都在议论，这架势，有点像当年的《战狼》，都透着股子爱国主题的劲儿，莫名就让人涌起民族自豪感。\nPrompt: 编写文章，主题：春节档哪吒的火爆出圈，莫名的民族自豪感，类似以前的电影：战狼，爱国主题。不能否认进步很多，但是也没好到这个程度，作为游戏党，很多面看起来就很油腻，打斗的场面网游风比较重。已经刷到不少为了哪吒的票房，买了电影票但是不去看的人。\n打斗场面质感不够 我一游戏党，平日里沉浸在各种网游世界，对电影本没抱多大期望。可架不住这《哪吒》热度高啊，身边人都在说，我心想，那就去瞅瞅呗。走进影院，画面一出来，我这心里就 “咯噔” 一下。虽说画面制作比以前进步不少，但有些画面看起来真有点油腻，那打斗场面，咋说呢，网游风太重了。我玩了那么多年游戏，这画面风格和游戏里有些场景太像了，少了电影该有的质感。\n疯狂的影迷 电影看完，出来一瞧，好家伙，网上不少人说为了《哪吒》的票房，买了票却不看电影。这操作我也是服了，看来大家对这部电影的支持热情那是相当高涨，都愿意为它做点什么。\n故事情节 咱回想一下，《战狼》那时候，吴京喊出 “犯我中华者，虽远必诛”，多少人热血沸腾，觉得咱中国军人太厉害了，咱国家太强大了。这《哪吒》虽说没那么直白的爱国口号，但它把中国传统文化展现得淋漓尽致。哪吒、敖丙这些神话人物，咱们从小就听着他们的故事长大，电影里把他们的恩怨情仇、成长历程演绎得有血有肉，这不就是咱中国文化的魅力所在吗？\n就说哪吒吧，从小被误解，受尽白眼，可他偏不服输，喊出 “我命由我不由天”，这精神头和咱中国人骨子里的那股韧劲多像啊。不管遇到多大困难，咱都不低头，靠着自己的努力去改变命运。敖丙也一样，背负着家族使命，看似冷酷，实则内心善良，为了朋友不惜牺牲自己。这种友情、这种担当，在现实生活中，咱们不也常常能见到吗？\n动画电影的进步 虽说《哪吒》有些地方没那么完美，但它把中国传统文化和现代电影技术结合得挺好，让咱看到了中国动画电影的进步。就像当年《战狼》让大家看到中国电影在动作片领域的突破一样。这种进步，让咱觉得咱中国电影也能在国际舞台上崭露头角，也能让外国人看到咱中国文化的精彩。\n咱中国人，不管走到哪儿，心里都装着自己的国家和文化。《哪吒》和《战狼》这样的电影，就像一把把钥匙，打开了咱内心深处民族自豪感的那扇门。让咱在欢声笑语中，感受着国家的强大、文化的魅力，也激励着咱在各自的岗位上努力奋斗，为国家的繁荣昌盛贡献自己的一份力量。这大概就是这些电影火爆出圈，能引发咱民族自豪感的原因吧。以后啊，也希望有更多这样的电影出现，让咱这份民族自豪感一直满满当当的。\n","date":"2025-02-15T03:40:07+08:00","permalink":"https://ttf248.life/p/ne-zha-breaks-through-during-spring-festival/","title":"春节档哪吒出圈"},{"content":"业务模型：后台服务借助 TCP 与集团的行情网关建立连接。每次连接时，需先行发送一个授权请求，随后持续发送心跳包以维持连接状态。 然而，某一天，收到了服务断开连接的告警信息。通过仔细排查日志后发现，后台服务一直在持续发送心跳包，但对方却毫无回应，可连接却始终未断开。\n现场简述 原本正在公司加班推进项目进度，工作群里突然弹出告警信息。乍一看，我还以为是老毛病，大概率是网络超时致使心跳发送失败，进而导致服务断开连接。可在仔细排查日志后，却发现实际情况并非如此。后台已发送了授权登录消息，然而一直未收到应答，与此同时，心跳包仍在持续不断地发送，对方却始终未回复任何心跳数据。经过对日志的深入分析，暴露出了以下几个关键问题：\n授权消息无应答：极有可能是对方系统正在重启，使得授权消息未能得到及时处理。 未成功授权却发送心跳数据：经排查，发现这是程序逻辑上的漏洞。心跳发送函数的判断逻辑存在缺陷，仅仅校验了连接状态，却遗漏了对授权状态的校验。 服务未断开连接：若服务能够断开连接，便可以触发重连机制，从而重新发送授权消息。 目前，还剩下最后一个亟待解决的问题——为何服务没有断开连接。这一问题的解决需要开展更为深入细致的排查工作。\n分析网络数据包 tcpdump 是一个非常强大的网络抓包工具，可以用来捕获网络数据包。通过分析网络数据包，我们可以更加直观地了解网络通信的细节。在这里，我们可以使用 tcpdump 来捕获网络数据包，以便进一步分析。\n分析图中的数据，我可以看到心跳一直在正常发送，对方服务器并没有回复任何数据，但是给了 ACK，这就导致连接不会主动断开了。\n常见标志位说明 在 TCP 协议中，PSH（Push）和 ACK（Acknowledgment）是两个重要的标志位，分别用于控制数据传输和流量确认。它们的作用如下：\n1. PSH（Push Flag） 功能：\nPSH 标志位的作用是请求接收方立即将缓冲区中的数据推送给上层应用（而不是等待缓冲区填满）。这意味着一旦收到带有 PSH 标志的数据段，接收方会尽可能快地处理并传递给应用程序，而非暂存于操作系统缓冲区中。\n典型场景：\nHTTP/HTTPS 请求：客户端发送请求时（如 GET /index.html）会设置 PSH，希望服务器立即响应。 SSH 协议：每次键盘输入都会触发 PSH，确保输入字符实时传输。 实时通信：视频流、在线游戏等低延迟场景可能使用 PSH 减少延迟。 注意：\nPSH 并非强制要求，接收方可以选择忽略该标志位（但仍需正常处理数据）。 发送方可能不设置 PSH，此时接收方会根据自身缓冲策略决定何时推送数据。 2. ACK（Acknowledgment Flag） 功能：\nACK 标志位表示确认已正确接收前序数据段。每个 ACK 包含一个确认号（Acknowledgment Number），表示期望接收的下一个字节序号。它是 TCP 可靠传输的核心机制。\n工作原理：\n发送方发送数据段时，会携带期望接收方的 ACK 值（例如 ACK = 序列号 + 数据长度）。 接收方收到数据后，会生成一个 ACK 报文段，确认已接收的数据序号。 发送方只有在收到对应的 ACK 后，才会重传未被确认的数据。 示例：\n若发送方发送了序号为 100~199 的数据段，则期望接收方的 ACK 应为 200。 若接收方未收到 100~199 中的某些数据，会通过 ACK=150 告知发送方重传。 3. PSH 和 ACK 的组合 在 TCP 报文中，PSH 和 ACK 可以同时出现，常见于以下场景：\nHTTP 请求响应：\n客户端发送 POST 请求时（含数据），会设置 PSH 和 ACK（确认之前的响应）。\nClient → Server: SYN, ACK=1 → 建立连接 Client → Server: PSH, ACK=1, 数据 → 发送请求数据 Server → Client: PSH, ACK=数据长度+1 → 返回响应 SSH 握手后传输命令：\n客户端输入命令后，发送带有 PSH 和 ACK 的数据段，确保命令立即传输并被服务器处理。\n4. 其他标志位的关联 标志位 名称 简要说明 SYN 同步 初始化连接（三次握手） FIN 结束 优雅关闭连接 RST 复位 强制终止连接（异常情况） URG 紧急 标记紧急指针（极少使用） 总结 PSH 关注的是数据尽快到达应用层，降低延迟。 ACK 关注的是数据的可靠传输，避免丢包或乱序。 两者协同工作，平衡了 TCP 协议的效率和可靠性。\n","date":"2025-02-14T22:54:13+08:00","permalink":"https://ttf248.life/p/backend-service-tcp-communication-troubleshooting/","title":"后台服务TCP通讯异常排查"},{"content":"回顾多年的炒股经历，虽然没有赚到大钱，但也没有亏太多。最大的问题在于资金流规划不合理，心态不稳定。目前阶段，主要收入来源是工作，每天打工赚取固定工资，对于金钱波动的承受能力还停留在债券和银行存款的层面。然而，人都是贪心的，买少了，涨了也赚不到钱；买多了，跌了就会亏钱。这时候，心态的稳定就显得尤为重要，它能帮助我们稳住财富之舟。\n历史亏损案例 除开刚入市的时候，碰过小盘股、次新股，后来接触的票，基本都是蓝筹大盘股：工商银行、中国联通、恒生电子、中兴通讯、各种大盘指数基金。\n买蓝筹，就是和老钱靠齐：\n恒大出问题的时候，银行股跟着暴跌，成功把握洗出盘，那会对于经济大盘的认知存在缺陷，房地产在国家经济里面占比太重，牵扯的东西，不能硬着陆，后面持续的股市下行，工商银行之类的红利股，持续涨了两年左右。 贸易战刚开始的阶段，中兴收到重创，股价也是大幅下跌，后续也都慢慢修复了。 恒生电子属于老东家，蚂蚁金服下去以后，股价也是大幅下跌，但是这个股票有庄家操盘，每年都能冲上去几次，合理的控制仓位，亏不了多少。 债券投资 怎么说呢，也算是蒙对了利率下行的周期。在杭州的工作有变动，放弃了买房的想法，手上那会已经配置过银行的定期，就看中了以前投资的债券，加大了债券的投资比例。刚好利率这几年下行，吃到了债券的牛市。\n回去的杭州半年的工作，很多东西倒是停下来想明白了。房子不是一定要买的，也不是一定要留在外面工作的，自己的抗压能力也就这样，如果碰到失业，房贷是座山。\n投资收益预期 预期年化口头上喊着对标银行三年定期，实际上，还是贪心想要更多，从开始加仓着急，到后面现金流枯竭。购置保险、买房、结婚，都是资金流的大头，整体的规划上，没有留出足够的资金流，导致后期的资金流不足。\n后续计划是长期持有券商ETF和恒生科技指数，整体资产的配置上，还是保险为底仓、中长期的债券、然后就是股票基金。\n","date":"2025-02-14T20:30:24+08:00","permalink":"https://ttf248.life/p/investing-takes-time/","title":"投资赚钱这事，急不来，着急了也没用"},{"content":"随着最早的网文读者步入中年，针对他们的爽文也发生了变化。主角多以父亲、师傅或老年人身份出现，迎合了中年读者对生活和情感的不同需求。这类作品不再仅仅追求升级和逆袭，而是更注重情感共鸣和生活感悟。\n目标用户：岁月流转中的读者群体变迁 曾经的网文读者，如今大多已步入中年。他们经历了生活的磨砺，心态和价值观发生了变化。对于他们来说，年轻时追捧的热血、冒险等元素已不再是唯一的追求。他们更渴望在阅读中找到与自己当下生活状态相契合的情感共鸣，以及对过去岁月的回忆和对未来生活的期许。中年爽文正是基于这样的心理需求而产生，它以更贴近中年人生活和心态的情节设定，吸引了这一特定群体的读者。\n角色转变：从少年英雄到中年担当 我的徒弟都是大反派：主角陆州在成为师傅后，面对的是一群性格各异、实力强大的徒弟。他们在正邪之间徘徊，而陆州则需要引导他们走向正道。这部小说通过主角与徒弟之间的互动，展现了中年人在教导下一代时所面临的挑战和困惑。同时，徒弟们的成长和转变也让读者看到了希望和未来，仿佛看到了自己对子女或年轻一代的期望。\n情感共鸣：生活感悟与家庭责任 六十大寿来系统：主角在六十大寿时获得了系统，开始了新的生活旅程。这个设定让中年读者能够感受到一种“为时未晚”的希望和激励。尽管已经到了晚年，但主角依然可以通过系统实现自己的价值和梦想。这种情节让读者联想到自己在生活中可能错失的机会和未完成的梦想，同时也传递了一种积极向上的生活态度，鼓励他们在任何年龄都不要放弃追求。\n情节设计：贴合中年生活的节奏与趣味 中年爽文的情节设计往往更加注重生活的细节和情感的细腻表达。不再像年轻时的爽文那样追求快节奏的升级和冒险，而是更加注重人物之间的关系和情感纠葛。例如，在《史上最强师傅》中，主角与徒弟之间的师徒情谊、与同门之间的兄弟情谊等都得到了细致的描绘。这种情节设计让中年读者能够感受到一种温暖和亲切，仿佛看到了自己生活中的亲情、友情和爱情。\n","date":"2025-02-13T22:12:57+08:00","permalink":"https://ttf248.life/p/years-of-settling-alternative-fantasy-and-emotional-attachment/","title":"岁月沉淀下的另类幻想与情感寄托"},{"content":"春节期间，一家人（七八个人）想去看电影，本想着在淘票票和猫眼上把票买了，一看价格 60 元。刚好手里有一张影院的充值卡，需要人到影院前台才能购票，想着问问前台有没有什么优惠，没想到同样的场次在前台买只要 35 元，这价格差着实让人惊讶。\n平台服务费的“隐形加成” 线上购票平台虽然方便，但平台服务费不可忽视。它们为用户打造便捷的购票体验，比如精准选座、随时查看购票记录等，这些都需要投入资金维护。而这些成本就通过平台服务费的形式，加到了票价里，导致线上票价升高。\n影院差异化运营策略 春节档观影需求爆棚，影院为了收益最大化，采用差异化定价。线上平台流量大，很多人习惯提前在网上购票，影院就把线上票价定得高些；而前台直接面对的是现场购票的散客，为了吸引这部分人群，给出较低价格。\n合作分成背后的价格逻辑 线上平台和影院的合作分成模式影响着票价。线上平台要从票房里分一杯羹，为保证盈利，就会把票价抬高。而影院前台售票没有中间环节，成本降低，票价自然亲民。\n消费者购票小窍门 消费者以后购票别只盯着线上平台，打电话问问影院前台价格，或者直接去前台咨询说不定有惊喜。要是常看电影，办个影院会员卡，享受会员优惠也能省不少钱。\n","date":"2025-02-11T00:02:02+08:00","permalink":"https://ttf248.life/p/chinese-new-year-movie-ticket-price-mystery/","title":"春节档电影票价之谜：线上与线下的价格差异"},{"content":"好久没去春节档凑热闹，这次去看了两部电影，感觉有点不一样。\n本文探讨2025年春节档电影的新变化，聚焦《唐人街探案1900》和《哪吒之魔童闹海》。前者借1900年美国旧金山唐人街背景，展现华人受种族歧视与压迫，映射社会政治环境；后者作为动画电影，以丰富隐喻元素暗讽现实国际政治格局，如玉虚宫类似五角大楼影射美国政治体系、天元鼎上美元符号象征美元霸权、仙人玉牌像美国绿卡暗示身份等级、灭魂丹似生化武器暗指恶意行径等。两部电影带来全新观影体验，引发对电影艺术与政治表达关系的思考。\n春节档电影风格的革新 以往春节档电影多是轻松娱乐、阖家欢的风格，旨在让观众在节日中放松身心，很少触碰敏感政治话题。但2025年春节档打破常规，《唐人街探案1900》和《哪吒之魔童闹海》融入丰富政治元素，引发观众广泛讨论，为春节档电影带来全新气象。\n《唐人街探案1900》：时代政治的生动写照 《唐人街探案1900》将故事设定在1900年美国旧金山唐人街，彼时华人在海外遭受严重种族歧视与压迫。主角们探案时，不仅要解开案件谜团，还要应对来自社会各方的歧视与不公平对待。影片对种族歧视和权力斗争的展现，真实映射出当时的社会政治环境，让我们看到那个动荡时代华人移民为生存和尊严进行的艰难抗争，背后的政治问题值得深入思考。\n这样的历史背景，不禁让人联想到当下海外华人在商业领域所面临的困境，如 TikTok 与周受资事件。\n当地时间 2024 年 12 月 6 日，美国哥伦比亚特区联邦巡回上诉法院驳回 TikTok 的请求，认定国会以国家安全名义颁布的强制出售法律经受住了宪法审查。TikTok CEO 周受资在发给员工的备忘录中写道，下一步将是 “寻求禁令，等待美国最高法院的审查” 。这一事件的源头是美国出台的《保护美国人免受外国敌对控制的应用程序侵害》法律，按照规定，字节跳动必须在法案通过后 270 天内剥离出售美国 TikTok 业务，强制出售的最后期限为 2025 年 1 月 19 日。\n此前在各种听证会上，周受资也遭受了诸多刁难。当地时间 2024 年 1 月 31 日，美国国会参议院司法委员会举行 “大型科技公司与网络儿童性剥削危机” 听证会 ，知名反华议员汤姆・科顿面对周受资，一连抛出 8 个关于国籍的问题，包括询问他是哪国人，有没有申请过中国国籍、美国国籍，甚至连他妻子和孩子的国籍都不放过。明明听证会主题是 “网络儿童性剥削”，但议员却将话题转移到 TikTok 由中国公司字节跳动所有这一点上，让周受资回答与主题无关的问题。就像《唐人街探案 1900》里华人在海外遭受无端歧视一样，周受资在商业领域也因 TikTok 的背景，遭受着不公正的对待与质疑。这一系列事件反映出在不同时代，海外华人在追求自身发展与权益维护时，都面临着来自外部的重重阻碍，无论是百年前的种族歧视，还是如今商业上的政治操弄，都值得我们深刻反思。\n《哪吒之魔童闹海》：神话背后的政治隐喻剖析 《哪吒之魔童闹海》看似是一部普通动画电影，但其中诸多设定和情节饱含政治隐喻。\n权力体系的映射：玉虚宫被塑造成仙界至高权力中心，建筑风格与美国五角大楼相似，内部以白色为主调，象征西方以“普世价值”为幌子推行霸权主义。无量仙翁统领的“除妖队”，其手下鹿男鹤女被认为对应美国盟友体系中的日韩。玉虚宫的“在线会议”场景，十二金仙围坐讨论“封神大战”，就像美国主导的北约会议，打着“维护秩序”的旗号打压他国。 经济霸权的暗示：玉虚宫炼丹用的天元鼎，入口处有美元符号，隐喻美国通过经济霸权“炼化”他国资源。影片中无量仙翁以“替天行道”之名把龙族投入鼎中炼化，如同某些国家借“国际规则”谋取利益。 身份与等级的隐喻：哪吒获得的仙人身份玉牌，颜色和纹样设计与美国绿卡高度相似，象征仙界对“异族”的排斥和等级划分，暗示现实中不同国家、群体之间的身份差异与不平等对待。 恶意行径的暗指：无量仙翁逼迫哪吒服下的灭魂丹，外形酷似生化武器，暗讽某些国家以“救世”之名，行破坏、毁灭他国之实。 资源与发展的象征：七色宝莲作为重塑哪吒与敖丙肉身的关键，象征被大国垄断的能源与技术命脉。其“琼浆玉液”需通过玉虚宫的“成仙考试”获取，映射现实中发展中国家对核心资源的依赖以及在霸权体系下遭受的“规则性掠夺”，宝莲的短暂失效与恢复条件，暗喻能源危机下小国的生存困境 。 电影艺术与政治表达的深度思考 这两部电影在春节档全民观影热潮中融入政治元素，给观众带来全新观影体验，不再只是单纯的娱乐作品，更像一面镜子，映照出历史与现实中的政治问题。这引发了我们对电影艺术与政治表达关系的深入思考。未来电影创作中，导演是否会更多地通过电影传达对社会政治的看法？电影作为强大的文化传播媒介，在艺术表达的同时，能否承担起更多对社会现实的关注和思考？这些问题值得我们在欣赏电影时深入探讨，也期待电影行业在艺术与现实表达融合方面带来更多精彩。\n彩蛋 豆包大模型，今天不是很给力，卡顿了好几次，文章出来一半就卡住了，还无法继续，只能重开个会话。\n","date":"2025-02-10T23:49:42+08:00","permalink":"https://ttf248.life/p/political-elements-in-chinese-films-spring-festival-2025/","title":"2025 春节档电影中的政治元素剖析"},{"content":"民主党和共和党，在政治理念、政策主张和社会价值观等方面存在显著差异。\n政治理念与政策主张 民主党：倾向于自由派，主张政府在经济和社会事务中发挥积极作用，支持社会福利、环境保护和多元文化。在税务政策上，民主党支持为中低收入群体减税，同时提高高收入者和企业的税率。在社会问题上，民主党支持堕胎权、同性婚姻，并倡导严格的枪支管制。在外交政策上，民主党强调多边主义和外交手段，倾向于通过国际合作解决全球问题。\n共和党：倾向于保守派，主张限制政府干预，强调个人自由和市场经济。在税务政策上，共和党支持减税，认为减税应适用于所有人，无论收入高低。在社会问题上，共和党反对堕胎和同性婚姻，支持持枪权。在外交政策上，共和党倾向于采取强硬立场，支持通过军事手段维护国家利益。\n特朗普上台的意义 唐纳德·特朗普在2024年再次当选美国总统，标志着共和党在美国政治中的主导地位。特朗普的政策主张包括：\n经济政策：特朗普主张通过减税和放松监管来刺激经济增长，特别是支持传统制造业和能源产业的发展。他还倾向于采取保护主义贸易政策，重新谈判或退出现有贸易协议，以保护美国的经济利益。\n移民政策：特朗普计划加强边境安全，限制非法移民，并对合法移民实施更严格的审查和限制。他还支持限制难民和庇护申请，以维护国家安全。\n外交政策：特朗普倾向于采取单边主义，强调“美国优先”，减少对国际组织的依赖，重新评估与盟友的关系，并在必要时采取更强硬的外交手段。他还计划扩大对化石燃料的生产和使用，放松对环境保护的限制。\n特朗普的再次当选可能导致美国国内政策的重大调整，并对全球政治和经济产生深远影响。他的政策可能引发国际社会的关注和反应，特别是在贸易、环境和人权等领域。\n","date":"2025-02-10T23:40:04+08:00","permalink":"https://ttf248.life/p/us-two-major-parties-democrats-republicans/","title":"美国的两大主要政党——民主党和共和党"},{"content":"Ollama 是一个开源的 AI 工具，旨在使用户能够本地运行和部署大型语言模型（LLM）。它的目标是提供一个方便且高效的方式，让开发者可以在本地机器上使用像 GPT 这样的模型，而不需要依赖云端服务。Ollama 支持多种模型，并且专注于优化性能，使得即使是资源有限的设备也能顺畅运行这些模型。\n通过 Ollama，用户可以使用基于文本的 AI 应用程序，并能够与本地部署的模型进行交互，而无需担心数据隐私或是高昂的 API 使用费用。你可以通过命令行界面（CLI）调用不同的模型，进行自然语言处理、问答等任务。\nollama 适合不同模型尝鲜，windows 版本测试下来，无法充分发挥硬件的性能，可能是因为 windows 版本的原因，linux 版本可能会更好。部署32b参数的模型，内存、显卡负载都有不高的情况下，回复速度很慢。\n硬件概述 操作系统：win11 CPU：i7-10700K 内存：40GB 显卡：RTX 3060 12GB 环境准备 新增系统环境变量，方便后续使用：\nset OLLAMA_MODELS=E:\\ollama\n这个变量指定了 Ollama 模型的存放路径。E:\\ollama 是一个文件夹路径，表示所有本地模型文件都存储在该目录下。Ollama 会根据这个路径加载和使用你下载或部署的语言模型。你可以将模型文件存放在其他位置，只需要更改这个路径。\nset OLLAMA_HOST=127.0.0.1:8000\n这个环境变量设置了 Ollama 服务的主机和端口。\n127.0.0.1 是本地地址（localhost），意味着 Ollama 服务会只监听来自本机的请求。 8000 是指定的端口号，表示 Ollama 服务将在 8000 端口上等待和处理请求。你可以根据需要更改端口号，但需要确保该端口没有被其他应用占用。 set OLLAMA_ORIGINS=*\n这个环境变量控制允许哪些来源的请求访问 Ollama 服务。\n* 表示允许任何来源（即所有域名和 IP 地址）都可以访问 Ollama 服务。这通常用于开发和调试环境，在生产环境中，通常会指定更严格的来源控制，限制只有特定的域或 IP 才能访问你的服务，以提高安全性。 deepseek-R1 模型部署 ollama 安装属于傻瓜式，此处不在赘述。\n安装后的校验：\nC:\\Users\\core\u0026gt;ollama -v ollama version is 0.5.11 模型部署，参考官网模型页面，选择对应参数的模型：ollama run deepseek-r1:14b\n14b 参数能有效的记住会话上下文，更小的参数版本，无法记住会话上下文。32b 参数版本，本机部署很卡顿，没有再深入进行测试。\n参考资料 https://www.ollama.com/library/deepseek-r1 https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw https://blog.csdn.net/x18990027/article/details/145368094 ","date":"2025-02-07T22:41:02+08:00","permalink":"https://ttf248.life/p/ollama-local-deployment-deepseek-r1/","title":"ollama 本地部署 deepseek-R1"},{"content":"用习惯了 Linux 上面的 zsh，前两天写博客的时候，突然发现 PowerShell 7 也支持持久化设置命令行预测视图，于是就试了一下，发现还是挺好用的。\n也不知道是做了什么操作，开启了这个功能，反正就是有了。\n在当今多样化的操作系统环境下，系统管理员和开发者们一直在寻找一款能够跨平台、高效且功能强大的工具，以满足他们在系统管理和自动化任务方面的需求。PowerShell 7正是这样一款备受瞩目的工具，它不仅提供了强大的脚本编写能力，还实现了跨Windows、Linux和macOS等操作系统的运行，为用户带来了前所未有的便利。\nPowerShell 7：跨平台的强大工具 跨平台特性 PowerShell 7打破了平台的限制，无论是在Windows系统上进行企业级的服务器管理，还是在Linux环境下进行系统运维，亦或是在macOS上进行日常开发任务，用户都可以使用统一的PowerShell 7工具。这极大地提高了工作效率，减少了因平台差异而带来的学习成本和操作复杂性。\n强大的功能 它具备强大的脚本编写能力，支持面向对象编程、函数、模块等高级编程特性。通过PowerShell 7，用户可以轻松地操作文件系统，对文件和文件夹进行创建、删除、复制、移动等操作；可以访问和修改注册表，对系统的配置进行深度调整；能够管理进程和服务，实现对系统运行状态的有效监控和控制。此外，PowerShell 7还能与各种Windows和非Windows技术进行交互，例如在Active Directory中进行用户和权限管理，在Azure云平台上进行资源调配和管理等。\n开源生态 PowerShell 7是开源的，这一特性使得全球的开发者和爱好者能够积极参与到它的开发和改进中来。大量的开源模块和工具不断涌现，丰富了PowerShell 7的功能和应用场景。用户可以根据自己的需求，在开源社区中找到合适的模块来扩展PowerShell 7的功能，或者贡献自己的代码，推动整个社区的发展。\n兼容性与稳定性 PowerShell 7在保持对旧版本PowerShell一定兼容性的同时，引入了许多新的功能和改进。这些改进不仅提升了性能，还增强了稳定性，使得用户在使用过程中能够更加流畅地完成各种任务，减少了因软件故障而导致的工作中断。\n开启命令行预测视图 在PowerShell 7的众多实用功能中，Set-PSReadLineOption -PredictionViewStyle ListView 命令是一个能够提升用户命令行输入体验的实用工具。\n不开启命令，也能实现自动补全，但是仅仅是行内的补全，开启后，可以实现预测视图，以列表的形式展示所有可能的补全选项，用户可以通过上下键选择需要的选项，从而提高了命令输入的准确性和效率。\n让命令持久生效的方法 为了让 Set-PSReadLineOption -PredictionViewStyle ListView 命令在每次启动PowerShell时都能生效，我们可以将其添加到PowerShell的配置文件中。PowerShell的配置文件是一个特殊的脚本，在PowerShell启动时会自动执行其中的命令。\n确定配置文件路径 在PowerShell中，我们可以使用 $PROFILE 变量来查看配置文件的路径。如果该路径下的文件不存在，用户可以手动创建一个。\necho $PROFILE 打开配置文件 使用文本编辑器，如功能强大的Notepad++或者轻量级的Visual Studio Code，打开通过 $PROFILE 变量获取到的配置文件路径对应的文件。\n添加命令 在打开的配置文件中，添加 Set-PSReadLineOption -PredictionViewStyle ListView 命令。确保命令的书写准确无误，以保证配置文件在执行时能够正确生效。\n保存配置文件 完成命令添加后，保存配置文件并关闭文本编辑器。此时，配置文件已经包含了我们希望在每次PowerShell启动时执行的命令。\n验证设置 关闭当前的PowerShell窗口，重新启动PowerShell。在新启动的PowerShell中，输入命令时，命令行输入预测视图样式应该已经按照我们的设置，以列表视图的形式展示，这表明我们的设置已经成功生效。\n通过以上步骤，我们不仅深入了解了PowerShell 7的强大功能和特性，还掌握了如何通过设置命令行输入预测视图样式来提升操作体验，并且学会了如何让这些设置持久生效。希望这些知识能够帮助你在使用PowerShell 7的过程中更加得心应手，高效地完成各种系统管理和自动化任务。\n参考资料 https://github.com/PowerShell/PowerShell/releases https://www.v2ex.com/t/911909 ","date":"2025-02-07T22:19:12+08:00","permalink":"https://ttf248.life/p/powershell-7-persisting-settings-commandline-prediction-view/","title":"PowerShell 7 与持久化设置命令行预测视图"},{"content":"春节前夕，DeepSeek 一度成为热议话题，短短几天内便在社交媒体上引起了广泛关注。这种突然的爆火，不仅让人惊讶，还带动了市场的连锁反应。与此同时，英伟达的股票却迎来了暴跌，许多投资者对其前景产生了疑虑，部分机构在此期间进行了大规模的做空操作，似乎一切都指向了一个“精心策划”的局面。\nDeepSeek 的爆火：短时间内迅速成为焦点 DeepSeek 是一个基于 AI 的工具，专注于对深度学习模型的优化，尤其是在自然语言处理（NLP）和图像生成领域的应用。春节前的几天，这个项目突然间受到大量投资者和技术从业者的关注。其背后团队的表现以及所展示的技术成果，让许多人对这个项目产生了强烈的兴趣。无论是在开发者社区，还是社交媒体平台上，关于 DeepSeek 的讨论几乎占据了技术圈的所有话题。\n然而，DeepSeek 的突然爆火并非偶然。经过分析，很多人开始怀疑这背后可能涉及到了某些机构的操作。尤其是在其爆火之后，英伟达股价出现了明显的下跌，显然有一些因素在推动着这一变化。\n英伟达股票暴跌：做空操作的幕后推手 英伟达，这家全球领先的图形处理单元（GPU）制造商，一直以来是许多大模型和 AI 计算的关键硬件提供商。随着 AI 市场的快速发展，英伟达的股票长期以来表现强劲，甚至成为了许多投资者青睐的对象。然而，随着 DeepSeek 的爆火和市场对其技术的高度关注，英伟达股票却迎来了暴跌。\n这一现象的背后，或许涉及到了机构投资者的做空策略。在过去几年中，随着 AI 技术的普及，英伟达的股价已被高度推高，很多投资者开始认为其股价存在过度炒作的风险。尤其是在 DeepSeek 这样的技术爆火之后，一些机构可能通过做空英伟达的股票，获得了可观的利润。通过精确的市场时机把握和对 DeepSeek 影响力的预判，这些机构成功地从中获利。\n大模型思维链的接触：从“结果”到“过程” 在传统的人工智能应用中，许多从业者和投资者更多关注的是 AI 模型的“结果”——例如生成的图片、文本等直接的产出。而在与 DeepSeek 相关的讨论中，越来越多的人开始意识到，大模型背后所隐藏的思维链才是更值得关注的核心内容。过去，我们只能看到模型输出的结果，但现在，我们更需要去理解其背后的逻辑、算法以及如何通过调整这些因素来优化模型的表现。\n这种思维方式的转变，实际上是对 AI 研究和应用的一种深入思考。从简单的黑箱操作，到真正理解模型内部运作机制的转变，让许多技术人员和投资者都开始重新审视人工智能的未来发展方向。DeepSeek 的火爆，恰恰是这一思维链的突破性应用，它让人们开始关注整个模型的构建和优化过程，而不仅仅是最终的输出结果。\n总结 DeepSeek 的突然爆火，英伟达股票的暴跌，以及市场背后机构的做空操作，这一切背后似乎都是一个精心设计的局。通过对大模型思维链的深入理解，我们可以看到，AI 技术的应用不仅仅是表面现象的堆砌，更是对模型内部逻辑的深入挖掘和优化。随着技术的进步，未来我们或许将看到更多类似 DeepSeek 这样的创新工具，推动 AI 研究和应用向更高层次发展。\n这种现象不仅让我们看到了 AI 技术的巨大潜力，也促使我们开始思考技术背后的商业博弈和资本运作。接下来的市场走势如何，将会是技术与资本博弈的持续焦点。\n","date":"2025-02-07T20:36:05+08:00","permalink":"https://ttf248.life/p/deepseek-explodes-before-chinese-new-year-nvidia-stock-plummets-behind-the-scenes-and-large-language-model-reasoning/","title":"DeepSeek 春节前突然爆火，英伟达股票暴跌：背后的机构操作与大模型思维链"},{"content":"美股市场持续的牛市，抛开美国本身的“硬实力”，更多的是美元的大水漫灌。\n现代货币体系在2008年金融危机之后，就逐渐成为全球多个经济体默契参考的重要理论支撑，主要特点是更加强调大政府在干预市场时的主观能动性，利用政府财政赤字为主要工具，实现市场的充分就业同时稳定通胀。\n大政府大家更熟悉的是凯恩斯主义，强调政府在大周期中的削峰填谷作用，比如过热时抑制和收缩时刺激，非常注重政府支出的乘数放大效应，也就是同样一块钱的货币能刺激多少消费乘数的增加，政府支出1开钱，企业和个人增加1块钱的收入，企业扩大生产增加就业，个人扩大消费从而抵御经济收缩。同时，对财政赤字上限和可持续性相对保守，消费乘数会带动市场的回暖，从而增加政府的收入，尤其是在经济过热周期的抑制，是可以积累下个周期的刺激筹码，比如政府负债潜力和利率水平。\n而现代货币体系更像是极致凯恩斯主义的延伸，但又有不同，最大的特点就是政府负债的限制问题，央行就不该具有独立性，主要目标是通胀和充分就业，资源和生产力有限的通胀，也就是说，政府通过无限制的财政赤字，随着科技发展生产效率提升，不断地向市场增加购买力，直至达到理想的充分就业和生产瓶颈，那么继续增加货币就会带来通胀，这时才选择控制财政赤字的上限，只要市场还存在闲置的生产资料，政府加大赤字就不会引发通胀。\n金融危机之后 当然现实毕竟不是理想世界，各个环节的执行都是人参与的，凯恩斯主义也是选择性的应用，导致的结果是经济下行刺激的多，经济过热抑制的少，经济差刺激带来政绩，经济过热也是政绩，根本很难抑制，带来的诸多经济问题，新的金融危机甚至不亚于传统的产能过剩带来的经济冲击。2008年全球金融危机其实就是极致凯恩斯主义下的市场自我强化导致的泡沫，出现了大量的旁氏结构金融投资品，比如房地产和以房地产为底层资产衍生的金融投资品，甚至在危机爆发之前，包括学界、政界、市场层面都对风险认识不足，把债务支撑的繁荣当做政绩，更多的还是因此获利，比如巨大的金融体系，亏了是你们的，分红是我们的，就是破产，早就赚的盆满钵满，钱是不可能吐出来的，最终导致大量参与者的投入，承担了前面人各个环节的收益。\n这时现代货币体系的影子进入金融危机之后，典型的特征就是快速的财政赤字货币化和央行的无限量化宽松，以及所谓的应急央行贷款政策，央行作为最终贷款人无限供给子弹，政府也可以不断负债，央行与财政政策协调配合，央行通过购买国债等方式支持政府财政赤字支出，确保政策目标的一致性，这也是为什么现代的货币政策和财政政策界限越发模糊的原因，基础货币投放上，非常依赖央行直接参与国债的购买，左手印钞右手花。\n欧元区与美国都有相似的表现，2008年欧盟的政府债务约为 6.7 万亿欧元，政府杠杆率大概在66%，略高于普遍认为的警戒线60%，截止2014年，也就是救市的5年时间，债务规模9.5 万亿欧，杠杆就来到了93%。美国则更夸张，2008 年美国政府债务约为 10 万亿美元，2014年大概到18万亿左右，最近又一次打开政府债务上限，当然每次的闹剧都是以政府停摆为噱头，但每次都会打破政府债务限额，至今突破36万亿，相比2008年金融危机增长26万亿，考虑到GDP增长因素，政府杠杆也从60%，增长到120%以上，美联储作为最终贷款人，在多次的救市中扮演重要角色，也是政府债务的主要购买方之一。\n现代货币体系的弊端与限制 这种政府主导的经济刺激方案，虽然不能说是计划经济，但面临的问题是一致的，你怎么保证市场的全知全能和所有环节参与者的无私无畏，举一个最简单的例子，假设政府部门增加了某个方向的预算100万，是给领导的小舅子呢，还是给性价比更高的市场竞价呢？当然现实中会以更复杂的方式形成利益的输送，导致的结果是，政府虽然扩大了负债和开支，但流向完全不可控，最近美国闹得沸沸扬扬的成立政府效率部门，其实也是此类问题的延伸。当然这些在不同的腐败指数经济体内，表现参差不齐，我们更多的讨论普遍的问题。\n1.通胀问题 随着现代信息网络的发展，政府对于市场信息的掌握程度已经远高于过去，但依据不是全知全能，市场本身存在变数，且市场总是会因为预期做出改变，进入套娃结构，我预判了你的预判。就以实际表现为例，虽然在2008年2020年之间，现代货币理论的实践表现不错，真正的实现了短期内的经济复苏和通胀稳定，欧元区甚至还出现了阶段性的通缩问题，而美国的通胀也基本维持在预期的13%之间，让人们就像过去相信凯恩斯主义一样相信着更极致的工具。\n其实我们回头来看，主要是因为发展中国家的制造业在2008年以后依旧呈现高增长趋势，比如在此期间逐步坐稳全球生产地位的我国，以及后发的东南亚和印度等经济体，都维持了较高的制造业增加值，恰好对冲了现代货币理论中的最大限制，资源供给限制，让欧美即便在去产业化和过度金融化下，同时出现了政府债务和货币供给激增下，维系了较为稳定的通胀。\n然而到了2020年以后，随着更大规模的刺激政策使用，欧元区和美国都出现了较为显著的通胀，高位时均在10%左右，即便到了今天，加息至今已经快3年，美国的就业市场依旧表现出异常的过热，金融市场在货币支撑下出现背离经济增长的过度繁荣，随着基数效应消失，美国的通胀又奔着3%去了，这种加息中的过热表现，与财政赤字密切相关，加息是货币政策上的收缩，而财政政策上确实扩张，叠加2020年的超大规模货币投放，让美国的通胀异常的顽固，现代货币理论的最大限制就是通胀高企。\n2.政府债务问题 原则上政府可以无上限的通过以债养债来实现债务偿付，但前提一定是央行彻底沦为傀儡，也就是现代货币体系中的财政政策和货币政策的目标一致性，显然美联储并不准备向政府完全放开权限，结合十几年积累的政府债务余额，尤其是利息支出，高息加高负债，逐渐成为财政的巨大负担。\n2023 财年：美国 2023 财年的财政收入为 44390 亿美元，当年的债务利息支出占财政收入的比重约为 15%，2024年延续了高息的状态，据美国财政部公布的数据 2024 财年: 美国联邦政府的财政赤字达到 1.833 万亿美元，债务净利息支出为 8820 亿美元，占美国联邦收入的约 18%，甚至要超过社保开支。\n这就是财政的可持续问题，如果长期维系低息，低通胀，高负债（比如日本），确实可以在长期内形成这种准现代货币理论的应用，根据72规则，只要利息足够低，财政以债养债下的增量是非常缓慢的，如果资金成本1%，纯以债养债可以达到72年债务翻一倍，假设通胀打破了这种微妙的平衡，债务的利息偿付积累过程中，复利会导致未来的债务走势失控，利滚利本金反而成为次要因素。央行如果再出现与执政党的目标不一致，这类问题将会更加尖锐。而特朗普政府的政治主张恰恰与现阶段美联储鹰派形成鲜明的差异，这也是这个任期内美国政府与美联储关系激化的重要来源，大家最关注的大概就是现任主席能否顺利的到任期结束。\n3.金融泡沫与货币信用问题 你理想情况下，政府扩大的开支进入居民和企业部门，大家都会扩大开支，从而带动有效需求的增加，但大家都是2000年以来诸多金融泡沫的亲身经历者，显然人们在投资和消费之间的选择上，会出现巨大的投资增值倾向，尤其是存在一个或者多个增值预期极强的产品出现时，大家会一窝蜂的去金融市场寻求更高的增值，甚至不惜压缩生活质量和加杠杆上车，这在不管日本、美国还是我国的房地产高增长时期都是类似的表现，结合政策刺激、从业者根据自己利益最大化的追求，次级贷款之类的问题非常多，很多所谓的救市政策其实就是鼓励举债。\n所以历史的表现出奇的一致，当货币政策和财政政策大规模发力的时候，往往是资产泡沫和财富再分配的狂欢，资产泡沫在前，财富再分配在后，这导致了另一个问题，就是极致凯恩斯主义，或者现代货币理论长期使用都会出现的经济庞氏化问题（明斯基时刻），只要还有热钱，则资产价格继续上涨，只要继续上涨，就能吸引后来者持币前来，而衡量基本生活开支变化的cpi，反而变化并不显著，钱流入特定领域空转，后来者钱无以为继，狂欢之后就是崩溃，也就是明斯基时刻的审判，屡试不爽。\n此外，货币本身也有供需关系，当市场供给过多时，传统的投资品容纳不了的时候，或者收割太多次无法吸金的时候，比如屡次崩盘的房地产泡沫（日本人几十年不敢再碰房地产投资），税收等政策的抑制，增加房地产持有税来降低投机需求，都会增加金融投机的成本，那么在货币供给过剩的情况土壤下，市场急需吸金且免税的投资品，各类虚拟投资品应运而生，就连美国总统和总统夫人都进来分一杯羹，一种说法是挖美元墙角，实际上更像是全球货币滥发和金融空转下的法币信用受损的必然结果，现代货币理论最仰赖的国家垄断权利下的信用货币地位，甚至都要受到挑战，什么样的土壤，衍生什么样的金融游戏。\n总结起来，现代货币理论与凯恩斯主义更像是递进和替代关系，更加注重政府大手干预市场，且对财政赤字和央行的独立性的态度更加激进，凯恩斯主义过度使用带来了滞胀和金融危机，应对这种人造经济过热的出清，现代货币理论又在2008年之后悄悄的接盘，在经济全球化下生产力继续提升，确实在短期内既快速恢复了增长，又维持使用国的通胀水平，但也积累了大量的政府负债和金融泡沫，当通胀反弹，央行与政府目标不一致，高息和高杠杆并存，极大的加剧了政府结息带来的财政负担，财政可持续性大幅减弱，同时因为过多的政府参与的基础货币投放，带来了金融泡沫，同时无限印钞削弱了货币本身的信用，看起来美元很强，实际上都是同行的衬托，同时巨大的投资需求土壤，衍生了各类新型的金融投资投机工具，甚至逃脱了传统金融投资品的税收限制，这都是全球经济的缩影。现代货币理论可能不是未来，而更是2008就开始使用的过去式，叠加逆经济全球化，过去金融泡沫吹得越大，政府债务积累越高，金融投机工具越疯狂，实现财富畸形分配的效率越高，则未来硬着陆的风险越大，包括经济和社会风险，不管凯恩斯主义也好，现代货币理论也罢，货币供给再多，都无法真正解决财富结构问题，反而在资产泡沫和旁氏化中激化风险，人们总是在同一个坑里以不同的姿势反复的跌到，但从来不会从中学到东西。\n","date":"2025-02-06T23:16:34+08:00","permalink":"https://ttf248.life/p/modern-monetary-theory-future-global-economy/","title":"现代货币理论是全球经济体的未来吗?"},{"content":"在外汇市场上，尤其是在银行或货币兑换点，我们常常会看到“买入汇率”和“卖出汇率”这样的术语。很多人对这两个概念可能不太清楚，甚至有些混淆。今天，我们就通过一个简单的例子，帮助大家理解这两个汇率的含义以及它们的作用。\n1. 什么是“买入汇率”和“卖出汇率”？ 买入汇率：银行或货币兑换机构愿意按这个汇率购买外币，也就是说，当你将外币（如美元）卖给银行时，银行会按照买入汇率支付给你人民币。\n卖出汇率：银行或货币兑换机构愿意按这个汇率出售外币，也就是说，当你用人民币购买外币时，银行会按照卖出汇率卖给你外币。\n简单来说：\n买入汇率：银行从你手中买外币的价格。 卖出汇率：银行卖外币给你的价格。 需要注意的是，银行买入和卖出的汇率通常是不一样的，卖出汇率一般要高于买入汇率。这个差价就是银行的盈利来源。\n2. 具体案例分析 为了让大家更清楚理解这两个汇率的实际应用，我们来做个具体的例子：\n假设你去银行兑换美元，银行给出的汇率如下：\n买入汇率：1美元 = 7.0人民币 卖出汇率：1美元 = 7.2人民币 情境一：你把美元卖给银行 假设你手里有1000美元，想把这些美元卖给银行，银行会按照买入汇率来计算：\n\\[ 1000 \\, \\text{美元} \\times 7.0 \\, \\text{人民币/美元} = 7000 \\, \\text{人民币} \\] 也就是说，银行会给你7000人民币。这里的汇率是买入汇率，因为你是把美元卖给银行。\n情境二：你用人民币买美元 假设你手里有7000人民币，想要换成美元。银行会按照卖出汇率来计算：\n\\[ 7000 \\, \\text{人民币} \\div 7.2 \\, \\text{人民币/美元} = 972.22 \\, \\text{美元} \\] 在这个情况下，你用7000人民币可以换取大约972.22美元。这里的汇率是卖出汇率，因为你是从银行购买美元。\n3. 为什么买入汇率和卖出汇率不同？ 你可能已经注意到，银行的买入汇率（7.0人民币/美元）比卖出汇率（7.2人民币/美元）要低。这是因为银行在进行外汇交易时，通常会通过这种汇率差来获利。换句话说，银行通过收取更高的卖出汇率和支付更低的买入汇率之间的差价来赚取利润。\n例如，在上面的案例中，银行的差价是：\n\\[ \\text{卖出汇率}（7.2） - \\text{买入汇率}（7.0） = 0.2 \\, \\text{人民币} \\] 这部分差价就是银行的利润来源。\n4. 总结 买入汇率：银行按此汇率从你手中买外币（你卖外币时的汇率）。 卖出汇率：银行按此汇率把外币卖给你（你买外币时的汇率）。 汇率差：买入和卖出汇率之间的差额是银行的盈利点。 了解了这两个汇率的概念后，我们在进行外汇兑换时就能更清楚地知道自己会得到多少外币，或者需要花费多少人民币才能买到外币。希望这个简单的例子能帮助大家更好地理解外汇汇率的基本原理！\n","date":"2025-02-06T22:32:10+08:00","permalink":"https://ttf248.life/p/understanding-buy-and-sell-exchange-rates/","title":"理解汇率中的“买入汇率”和“卖出汇率”"},{"content":"windows 下，使用 visual studio 调试程序时，如果 pdb 文件与可执行文件不匹配，visual studio 会提示“无法加载符号文件”。程序运行发生崩溃，落地 dump 文件，如果是不匹配的 pdb 文件，visual studio 也无法顺利的进入崩溃现场。\n什么是 pdb 文件 PDB 文件是微软的一种调试信息文件，用于调试程序。PDB 文件包含了程序的符号表、源代码文件名、行号等信息。在程序编译时，可以生成 PDB 文件，用于调试程序。\nWinDbg 调试 WinDbg 是微软的一款调试工具，可以用于调试 windows 程序。WinDbg 可以加载不匹配的 pdb 文件，但是需要手动加载。.reload /f /i 命令可以强制加载不匹配的 pdb 文件。\n但是 WinDbg 使用起来不如 visual studio 方便，所以我们希望 visual studio 也能加载不匹配的 pdb 文件。\nvisual studio 加载不匹配的 pdb 文件 源码现在一般都是通过 git 管理，完全能找到对应版本的代码，重新编译，生成对应的 pdb 文件。为什么无法加载呢？主要是一些元数据无法匹配。\n有个小工具，可以修改元数据，基于 exe 文件信息，生成一个新的 pdb 文件，使得 visual studio 能够加载。\nchkmatch 下载地址：https://www.debuginfo.com/tools/chkmatch.html\n站点缓存地址：chkmatch.zip\nChkMatch utility can be used to check whether an executable and debug information file match. It can also be used to enforce matching between an executable and debug information file, if they are compatible. For more information about debug information matching and related issues, see this article. Supported debug information formats: DBG, PDB 2.0, PDB 7.0. chkmatch [-c ExeFile DebugInfoFile ] | [-m ExeFile DebugInfoFile] -c Check matching between the executable and the debug information file. -m Make the executable and the debug information file match. ExeFile The name of the executable file. DebugInfoFile The name of the debug information file. 使用 chkmatch 先执行检查操作，分析不匹配的原因，提示签名不匹配。\nC:\\Users\\tianlong.xiang\\Downloads\\chkmatch\u0026gt;ChkMatch.exe -c \u0026quot;D:\\Program Files\\Rolan\\trade\\UAT_YinStrade\\YinTrade.Main.exe\u0026quot; E:\\YinTech\\ykcz_securities_trading_client\\Sec_Trade\\YinTrade.Main\\bin\\Release\\YinTrade.Main.pdb ChkMatch - version 1.0 Copyright (C) 2004 Oleg Starodumov http://www.debuginfo.com/ Executable: D:\\Program Files\\Rolan\\trade\\UAT_YinStrade\\YinTrade.Main.exe Debug info file: E:\\YinTech\\ykcz_securities_trading_client\\Sec_Trade\\YinTrade.Main\\bin\\Release\\YinTrade.Main.pdb Executable: TimeDateStamp: c26d9be3 Debug info: 2 ( CodeView ) TimeStamp: f86b0a4f Characteristics: 0 MajorVer: 0 MinorVer: 0 Size: 122 RVA: 001cdc44 FileOffset: 001cbe44 CodeView format: RSDS Signature: {428c9b95-39a3-4a8d-a8e5-7be453684757} Age: 1 PdbFile: D:\\stock_UAT\\ykcz_securities_trading_client\\Sec_Trade\\YinTrade.Main\\obj\\Release\\YinTrade.Main.pdb Debug info: 16 ( Unknown ) TimeStamp: 00000000 Characteristics: 0 MajorVer: 0 MinorVer: 0 Size: 0 RVA: 00000000 FileOffset: 00000000 Debug information file: Format: PDB 7.00 Signature: {06fae08e-c0a2-4f3d-9c7c-dfc684445dd1} Age: 1 Result: Unmatched (reason: Signature mismatch) 然后执行修改操作，使得 pdb 文件与 exe 文件匹配。\nC:\\Users\\tianlong.xiang\\Downloads\\chkmatch\u0026gt;ChkMatch.exe -m \u0026quot;D:\\Program Files\\Rolan\\trade\\UAT_YinStrade\\YinTrade.Main.exe\u0026quot; E:\\YinTech\\ykcz_securities_trading_client\\Sec_Trade\\YinTrade.Main\\bin\\Release\\YinTrade.Main.pdb ChkMatch - version 1.0 Copyright (C) 2004 Oleg Starodumov http://www.debuginfo.com/ Executable: D:\\Program Files\\Rolan\\trade\\UAT_YinStrade\\YinTrade.Main.exe Debug info file: E:\\YinTech\\ykcz_securities_trading_client\\Sec_Trade\\YinTrade.Main\\bin\\Release\\YinTrade.Main.pdb Executable: TimeDateStamp: c26d9be3 Debug info: 2 ( CodeView ) TimeStamp: f86b0a4f Characteristics: 0 MajorVer: 0 MinorVer: 0 Size: 122 RVA: 001cdc44 FileOffset: 001cbe44 CodeView format: RSDS Signature: {428c9b95-39a3-4a8d-a8e5-7be453684757} Age: 1 PdbFile: D:\\stock_UAT\\ykcz_securities_trading_client\\Sec_Trade\\YinTrade.Main\\obj\\Release\\YinTrade.Main.pdb Debug info: 16 ( Unknown ) TimeStamp: 00000000 Characteristics: 0 MajorVer: 0 MinorVer: 0 Size: 0 RVA: 00000000 FileOffset: 00000000 Debug information file: Format: PDB 7.00 Signature: {06fae08e-c0a2-4f3d-9c7c-dfc684445dd1} Age: 1 Writing to the debug information file... Result: Success. 参考资料 forcing-to-load-unmatched-symbols-in-visual-studio-2015-debugger ","date":"2025-01-23T20:04:33+08:00","permalink":"https://ttf248.life/p/visual-studio-load-unmatched-pdb/","title":"visual studio 加载“不配套”的 pdb 文件"},{"content":"转眼又是一年过去了，工作上的最大的变动，还是AI参与度明显提高了，相当以往来说，不同的开发语言之间切换，需要开发者熟悉的各种语言不同的 api 接口，现在这些基础代码都可以通过 AI 生成代码了，对于开发者来说，就是一个很大的福音。\nChatGPT 早在 23 年的时候，整过两篇简单的入门介绍，转眼已经到了 25 年，怎么说呢，并没有感知到显著的进步，还是需要开发有自己的认知，能合理的拆分任务，当然，最重要的是识别 AI 生成的代码是否存在 bug。\nGithub copilot 忘记是是哪天了，看到资料说新加坡部署了服务器，国内使用，再也不用长期挂梯子，当然，登录的时候，还是需要挂个梯子，不过这个梯子只需要登录的时候用一下，之后就可以关闭了。\n日常用的更多的也是 Github copilot，这个插件，可以直接在 vscode、visual studio 中直接使用。不用两个软件之间切换。相对于 ChatGPT，Github copilot 对于项目的支持更好，交互上更友好，能你能选择部分本地的文件投喂，“训练”AI，这样生成的代码更符合你的项目。\nCursor AI 最近看到了一个新的 AI 编程 IDE，Cursor AI，这个 IDE 也是基于 Github copilot 的，不过这个 IDE 更加的智能，可以帮你直接创建文件。\n简单的用了一下，感觉还是不错的，不过对于现有项目的理解还是不够，本地项目文件多的时候，大的重构优化调整，还是需要开发者拆分任务。\n附上一个例子：切换到 curso 的工程模式，输入内容：新建个人简历网页，支持多个不同风格切换，记得填充一些个人信息用于数据展示。\n经过几次来回的拉扯，你就能拿到如下的网页，当然，这个网页还是比较简单的，不过对于新手来说，还是很不错的。\n目前注册用户能免费试用 150 次高级 api，付费用户限制 5000 次高级 api\n个人简历\n","date":"2025-01-23T19:30:13+08:00","permalink":"https://ttf248.life/p/cursor-ai-programming-ide-trial/","title":"Cursor AI 编程 IDE 试用"},{"content":"在实际的C++开发中，位操作是常见的技术，尤其在处理系统状态、标志位或控制位时，位操作可以提供非常高效的解决方案。本文将通过一个例子，讲解如何使用位操作来获取和设置特定的标志位。\n位操作基础概念 在计算机中，数据是以二进制位（0和1）存储的。位操作就是对二进制位进行操作。C++中有几种常用的位操作符：\n按位与（\u0026amp;）：用于检查某一位是否为1。 按位或（|）：用于设置某一位为1。 按位异或（^）：用于反转某一位。 按位取反（~）：将所有位反转。 左移（\u0026laquo;）：将所有位左移若干位。 右移（\u0026raquo;）：将所有位右移若干位。 在本例中，我们需要对一个 unsigned short 类型的变量 wInfo 进行一系列的位操作，通过不同的标志位来表示不同的状态。\nflowchart LR A[原始数值: 00010000] --\u0026gt; B[左移: 00010000 \u0026lt;\u0026lt; 1] B --\u0026gt; C[结果: 00100000] C --\u0026gt; D[右移: 00100000 \u0026gt;\u0026gt; 1] D --\u0026gt; E[结果: 00010000] subgraph 左移操作 direction LR A --\u0026gt; B --\u0026gt; C end subgraph 右移操作 direction LR C --\u0026gt; D --\u0026gt; E end 需求解析 根据题目中的描述，我们有一个 16 位的标志位，用来表示不同的状态。这些状态通过各个不同的二进制位来表示，每个二进制位对应一种特定的含义。例如：\nbit0 是否失败 bit1 是否压缩 bit2 是否增量 bit3 是否有后续包 bit5 正常请求或注销 使用位操作实现 我们将通过位操作来设置和获取这些标志位。具体来说：\n按位取值：获取某一位的值（0或1）。 按位设置：设置某一位为1。 按位清除：设置某一位为0。 我们首先定义一个 unsigned short 类型的变量 wInfo 来保存这些标志位。然后，我们通过位操作来检查和设置相应的标志。\nC++ 示例代码 #include \u0026lt;iostream\u0026gt; #include \u0026lt;bitset\u0026gt; // 定义标志位常量 const unsigned short BIT_0_FAIL = 1 \u0026lt;\u0026lt; 0; // bit0 是否失败 const unsigned short BIT_1_COMPRESSED = 1 \u0026lt;\u0026lt; 1; // bit1 是否压缩 const unsigned short BIT_2_INCREMENT = 1 \u0026lt;\u0026lt; 2; // bit2 是否增量 const unsigned short BIT_3_HAS_MORE = 1 \u0026lt;\u0026lt; 3; // bit3 是否有后续包 const unsigned short BIT_5_CANCEL = 1 \u0026lt;\u0026lt; 5; // bit5 正常请求(0)或注销(1) // 检查某一位是否为1 bool isBitSet(unsigned short wInfo, unsigned short bitMask) { return (wInfo \u0026amp; bitMask) != 0; } // 设置某一位为1 void setBit(unsigned short\u0026amp; wInfo, unsigned short bitMask) { wInfo |= bitMask; } // 清除某一位（设置为0） void clearBit(unsigned short\u0026amp; wInfo, unsigned short bitMask) { wInfo \u0026amp;= ~bitMask; } int main() { // 假设wInfo的初始值为0 unsigned short wInfo = 0; // 设置bit0（失败标志） setBit(wInfo, BIT_0_FAIL); // 设置bit1（压缩标志） setBit(wInfo, BIT_1_COMPRESSED); // 打印wInfo的二进制值 std::cout \u0026lt;\u0026lt; \u0026quot;wInfo (in binary): \u0026quot; \u0026lt;\u0026lt; std::bitset\u0026lt;16\u0026gt;(wInfo) \u0026lt;\u0026lt; std::endl; // 检查各个标志位 std::cout \u0026lt;\u0026lt; \u0026quot;bit0 (是否失败): \u0026quot; \u0026lt;\u0026lt; (isBitSet(wInfo, BIT_0_FAIL) ? \u0026quot;是\u0026quot; : \u0026quot;否\u0026quot;) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026quot;bit1 (是否压缩): \u0026quot; \u0026lt;\u0026lt; (isBitSet(wInfo, BIT_1_COMPRESSED) ? \u0026quot;是\u0026quot; : \u0026quot;否\u0026quot;) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026quot;bit2 (是否增量): \u0026quot; \u0026lt;\u0026lt; (isBitSet(wInfo, BIT_2_INCREMENT) ? \u0026quot;是\u0026quot; : \u0026quot;否\u0026quot;) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026quot;bit3 (是否有后续包): \u0026quot; \u0026lt;\u0026lt; (isBitSet(wInfo, BIT_3_HAS_MORE) ? \u0026quot;是\u0026quot; : \u0026quot;否\u0026quot;) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026quot;bit5 (是否注销): \u0026quot; \u0026lt;\u0026lt; (isBitSet(wInfo, BIT_5_CANCEL) ? \u0026quot;是\u0026quot; : \u0026quot;否\u0026quot;) \u0026lt;\u0026lt; std::endl; // 清除bit1（压缩标志） clearBit(wInfo, BIT_1_COMPRESSED); // 打印更新后的wInfo std::cout \u0026lt;\u0026lt; \u0026quot;Updated wInfo (in binary): \u0026quot; \u0026lt;\u0026lt; std::bitset\u0026lt;16\u0026gt;(wInfo) \u0026lt;\u0026lt; std::endl; return 0; } 执行代码，推荐老朋友：https://wandbox.org/\nwInfo (in binary): 0000000000000011 bit0 (是否失败): 是 bit1 (是否压缩): 是 bit2 (是否增量): 否 bit3 (是否有后续包): 否 bit5 (是否注销): 否 Updated wInfo (in binary): 0000000000000001 代码解释 标志位定义：使用位移操作（1 \u0026lt;\u0026lt; n）来定义各个标志位。例如，1 \u0026lt;\u0026lt; 0 对应 bit0，1 \u0026lt;\u0026lt; 1 对应 bit1，依此类推。这样，我们就为每个标志位分配了唯一的二进制位置。\n检查某一位：isBitSet 函数通过与运算 wInfo \u0026amp; bitMask 来检查特定的标志位是否为1。如果该位为1，函数返回true，否则返回false。\n设置某一位：setBit 函数通过按位或操作 wInfo |= bitMask 来将特定的标志位置为1。\n清除某一位：clearBit 函数通过按位与操作 wInfo \u0026amp;= ~bitMask 来将特定的标志位置为0。\n总结 通过位操作，我们能够高效地处理多个状态标志位。在实际开发中，这种技术尤其有用。例如，在嵌入式开发、网络协议、系统状态管理等场景中，常常使用位标志来表示多个二进制状态，既节省空间又提高效率。\n希望这篇博客能够帮助你理解如何在 C++ 中使用位操作来实现按位取值和设置，掌握这些技能对编写高效且易于维护的代码非常有帮助！\n","date":"2025-01-17T02:23:56+08:00","permalink":"https://ttf248.life/p/cpp-bitwise-operations-flags/","title":"C++ 位操作基础：按位取值与标志位设置"},{"content":"台式机硬件三连发，前文我们提到了固态硬盘 PCIE 转接器，老的固态哪里去了呢？当然没有浪费，有没有坏掉，拆下来安装到了新买的机械师创物者Mini-3765H上（一年前）。\n新机器，硬件规格还是给力的，2.5G 双网口、PCIE4.0、WiFi6。\n最近搬家了房间没有单独的路由器组网，机器都是走无线网络连接，华硕主板台式机的无线网卡性能不太行，也可能是路由器无线接入，局域网之间上传速度不行，导致机器之间的网速不太行。新购买 2.5G 网卡，安装到台式机上。\n至此，主板的插槽用完了：显卡、无线网卡、2.5G 网卡、固态硬盘 PCIE 转接器。\n网络说明 两台机器上网还是靠原本的无线网卡，但是两台之间走网线直连，两端都是 2.5G 网卡。怎么网线直连两台机器，这里就不多说明了，网上有很多教程，记得放开防火墙。任选一台作为网关即可。\ngraph TD; A[机器1\u0026lt;br\u0026gt;IP: 192.168.4.1\u0026lt;br\u0026gt;子网掩码: 255.255.255.0\u0026lt;br\u0026gt;默认网关: - \u0026lt;br\u0026gt;自动获取DNS] --\u0026gt;|网线直连（2.5G）| B[机器2\u0026lt;br\u0026gt;IP: 192.168.4.2\u0026lt;br\u0026gt;子网掩码: 255.255.255.0\u0026lt;br\u0026gt;默认网关: 192.168.4.1\u0026lt;br\u0026gt;自动获取DNS]; A --\u0026gt;|无线网卡| Internet; B --\u0026gt;|无线网卡| Internet; 两个网段测速 路由器局域网 C:\\Users\\core\\Desktop\\iperf-3.1.3-win32\u0026gt;iperf3.exe -c 192.168.3.237 Connecting to host 192.168.3.237, port 5201 [ 4] local 192.168.3.122 port 1656 connected to 192.168.3.237 port 5201 [ ID] Interval Transfer Bandwidth [ 4] 0.00-1.00 sec 9.17 MBytes 76.7 Mbits/sec [ 4] 1.00-2.00 sec 9.91 MBytes 83.2 Mbits/sec [ 4] 2.00-3.00 sec 8.74 MBytes 73.3 Mbits/sec [ 4] 3.00-4.00 sec 10.2 MBytes 85.2 Mbits/sec [ 4] 4.00-5.00 sec 9.23 MBytes 77.1 Mbits/sec [ 4] 5.00-6.00 sec 8.80 MBytes 73.9 Mbits/sec [ 4] 6.00-7.01 sec 8.00 MBytes 66.8 Mbits/sec [ 4] 7.01-8.00 sec 7.69 MBytes 64.9 Mbits/sec [ 4] 8.00-9.01 sec 9.72 MBytes 81.1 Mbits/sec [ 4] 9.01-10.01 sec 7.63 MBytes 63.6 Mbits/sec - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bandwidth [ 4] 0.00-10.01 sec 89.0 MBytes 74.6 Mbits/sec sender [ 4] 0.00-10.01 sec 89.0 MBytes 74.6 Mbits/sec receiver iperf Done. 直连局域网 C:\\Users\\core\\Desktop\\iperf-3.1.3-win32\u0026gt;iperf3.exe -c 192.168.4.1 Connecting to host 192.168.4.1, port 5201 [ 4] local 192.168.4.2 port 1524 connected to 192.168.4.1 port 5201 [ ID] Interval Transfer Bandwidth [ 4] 0.00-1.01 sec 178 MBytes 1.48 Gbits/sec [ 4] 1.01-2.00 sec 204 MBytes 1.72 Gbits/sec [ 4] 2.00-3.00 sec 214 MBytes 1.80 Gbits/sec [ 4] 3.00-4.00 sec 229 MBytes 1.92 Gbits/sec [ 4] 4.00-5.00 sec 202 MBytes 1.69 Gbits/sec [ 4] 5.00-6.00 sec 213 MBytes 1.79 Gbits/sec [ 4] 6.00-7.00 sec 230 MBytes 1.93 Gbits/sec [ 4] 7.00-8.00 sec 192 MBytes 1.61 Gbits/sec [ 4] 8.00-9.00 sec 220 MBytes 1.84 Gbits/sec [ 4] 9.00-10.00 sec 230 MBytes 1.93 Gbits/sec - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bandwidth [ 4] 0.00-10.00 sec 2.06 GBytes 1.77 Gbits/sec sender [ 4] 0.00-10.00 sec 2.06 GBytes 1.77 Gbits/sec receiver iperf Done. 参考资料 给hugo添加mermaid支持 ","date":"2025-01-10T00:37:52+08:00","permalink":"https://ttf248.life/p/desktop-upgrade-to-2-5g-network-card-accelerates-local-area-network-interconnection/","title":"台式升级到2.5G网卡，加速局域网互联"},{"content":"紧接上文，莫名出现无线网卡无法识别的问题，在重建分区之前，网上也查到了其他方案，比如说：主板电池卸载，断电十五分钟；升级最新版本的 BOIS 驱动，但是都有问题。\n想着还有事情要处理，切换到有限网络，从客厅拉网线的到房间，这个时候，问题又来了，有线网络也无法识别。上大招重装系统，出现引导分区丢失。如果是一直出现问题，也不会折腾这么久，华硕这个磁盘冲突，是偶发性的，系统重启不稳定触发。\n上周台式机添置了新的磁盘，长江存储的 2T 固态硬盘，M2 接口，然后机器就一直没重启，直到昨天关机了一次。\n重装系统 算算时间也都两年没有重装系统，C盘已经不够用了，windows 老问题，日常各种软件都喜欢在 C盘 存点东西。于是，决定重装系统。系统重装以后，网卡问题都正常了，隔天恢复了日常的开发环境，准备做个系统备份，这个时候新的问题来了，系统重启以后，引导分区丢失。\n按照上一篇文章的步骤，重建了引导分区，但是不太稳定，重启以后，引导分区随时可能加载不到，开始怀疑折腾机箱的时候，硬盘线松动了，但是检查了几次，都没有问题。\n记忆复苏 很多年前，这台机器加装过一次固态硬盘，那会是新买了一个 PCIE 转换器（插在显卡接口上），没有直接将硬盘安装到主板上。这次，直接安装到主板上，可能是主板的问题。\n主板说明书 主板说明书，存在问题，标注的 SATA 接口的位置和实际的位置不同，由于磁盘太多，接口上都安装了硬盘，老的固态都是 SATA 接口，按照主板说明书，接口之间是存在冲突的，经过实际的测试，发现这个冲突是不稳定触发，触发的时候，就会导致对应的磁盘无法加载，刚好这个是系统磁盘，引导也在对应的磁盘上，系统启动就会出现引导加载失败。\n解决方案 重新安装固态硬盘到 PCIE 转换器上，这个时候，主板上的 SATA 接口就不会有冲突了，系统启动正常。\n","date":"2025-01-10T00:08:51+08:00","permalink":"https://ttf248.life/p/asus-z490-motherboard-disk-recognition-issues/","title":"华硕主板 Z490 安装磁盘太多，偶发性磁盘无法识别"},{"content":"从什么版本开始的我也不清楚，但是在Windows 11中，磁盘清理工具已经有了很大的改进，变得更加智能了。\n重点它是官方的工具，不会误删文件，不会有广告，不会有弹窗，不会有后台进程，不会有任何不必要的东西。\n在Windows 11中，可以通过设置-系统-存储-临时文件来打开磁盘清理工具。\n普通用户选择清理建议即可，系统会根据你的使用情况，给出一些建议。\n笔者作为一个开发者，磁盘上有很多临时文件，所以选择临时文件，里面包含了很多临时文件，比如Visual Studio的临时文件，Windows Update的临时文件等等。\n","date":"2025-01-06T19:29:45+08:00","permalink":"https://ttf248.life/p/windows-disk-cleanup-storage/","title":"Windows自带的磁盘清理工具：存储"},{"content":"国内服务器部署docker，部署以后，如果公司没有提供镜像中心，开发首先要做的就是配置一个国内的镜像加速地址。巧了今天有台服务器，配置了镜像加速地址，但是发现拉取镜像的时候，一直拉取不到。\n报错信息：Error response from daemon: Get \u0026quot;https://registry-1.docker.io/v2/\u0026quot;: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\n20250106 时隔两天，所有的服务器都恢复了，这事居然不上热搜，国内所有的镜像代理都挂了\n故障排查与修复尝试 起初，尝试切换至其他镜像加速地址，期望借此解决问题，然而事与愿违，问题依旧。\n紧接着，着手修改本地 DNS 配置，试图从网络解析层面找到突破口，遗憾的是，经过一番调试，故障依然存在。\n此时，本地网络的稳定性已备受质疑，于是果断切换至手机热点，试图绕过可能存在的本地网络故障点，可结果还是令人沮丧，问题毫无改善迹象。\n问题蔓延 手头尚有几台部署于国内的服务器，且均安装了 Docker 环境。尝试在这些服务器上拉取镜像，本以为能另辟蹊径，结果发现无一例外，均无法成功拉取，所反馈的报错信息如出一辙，这表明问题并非局限于某一台设备。\n进一步探究发现，镜像代理似乎瞬间失灵，在这紧急关头，迅速切换至境外机器进行尝试，令人稍感欣慰的是，镜像拉取在此处恢复正常，这意味着问题大概率出在国内的网络链路或相关配置上。\n策略调整：迂回解决 鉴于国内直接拉取镜像的途径已被重重阻碍，而国外镜像却能正常访问，为尽快推进项目，决定采取迂回战术。首先切换至国外服务器，顺利拉取所需镜像，随后将其推送至国内镜像仓库，以此搭建起一座“数据桥梁”。\n与此同时，同步对 Dockerfile 文件进行修改，将镜像地址替换为适配国内环境的地址，再重新构建镜像，最终成功部署。\n","date":"2025-01-04T18:29:25+08:00","permalink":"https://ttf248.life/p/docker-domestic-image-proxy-failure/","title":"Docker 国内镜像代理失效"},{"content":"电竞产业，在过去十余年中经历了迅猛的发展，成为了全球范围内不可忽视的文化现象。特别是以《英雄联盟》（League of Legends，简称LOL）为代表的MOBA类游戏，它不仅为玩家提供了竞技的乐趣，也为资本注入了强大的动力，推动着一系列电竞平台和赛事的蓬勃发展。然而，这一切随着资本的涌入和泛娱乐产业的崛起，也进入了一个逐渐衰退的阶段。熊猫TV的兴起与陨落、斗鱼与虎牙的竞争，标志着“野蛮资本时代”的落幕，电竞行业的天时地利人和似乎也都开始发生变化。\n第一章：电竞的崛起与资本注入 1.1 初期的电子竞技：从草根到职业化\n早期的电竞产业起步相对草根，尤其是中国市场。许多玩家凭借对游戏的热爱，参与到《星际争霸》、Dota等游戏的竞技中。然而，电竞的真正崛起始于《英雄联盟》的发布与推广。自2011年《英雄联盟》正式进入中国市场后，电竞逐渐从一个小众圈子发展为大众文化的一部分。特别是在2013年起，LPL（中国职业联赛）逐步形成，英雄联盟成为了中国电竞产业的顶梁柱。\n1.2 资本疯狂涌入：熊猫TV与电竞直播平台的兴起\n2015年，是中国电竞行业的一个分水岭。资本的涌入让电竞从单纯的竞技赛事，转向了更为庞大的产业链。熊猫TV作为代表之一，成为了资本过剩的产物。由王思聪（熊猫直播的创始人之一）投资的熊猫TV迅速崛起，以其创新的内容与庞大的投资吸引了大量观众和用户。然而，这也正是资本“野蛮”流入的典型例子——资本对市场的疯狂追逐往往缺乏耐性和长远眼光。熊猫TV的资金和人力投入虽然短期内取得了一定成绩，但因为管理问题和过度依赖资本的高烧，最终在2019年宣告破产。\n1.3 直播平台竞争：斗鱼与虎牙的“资本大战”\n熊猫TV的陨落并未导致电竞直播行业的衰退，反而推动了斗鱼和虎牙等平台的崛起。斗鱼和虎牙两大直播平台迅速成为电竞行业的领军者，彼此竞争也愈发激烈。斗鱼早期凭借《英雄联盟》职业赛事的直播，以及对顶级主播的签约，成为了电竞直播的标杆。而虎牙则通过加大对电竞赛事的投入以及自身平台的多元化布局，逐渐缩小了与斗鱼的差距。\n在这一过程中，资本再次发挥了巨大的作用。斗鱼于2018年成功上市，虎牙则于同年也进行了IPO。资本的快速流动带来了行业的高度集中，也导致了平台之间在主播、版权等方面的激烈竞争，形成了“资本大战”。\n第二章：泛娱乐化与电竞的融合 2.1 泛娱乐化浪潮：资金流向多元化娱乐项目\n随着资本对电竞行业的重注，电竞平台的内容逐渐泛娱乐化。电竞主播不仅局限于比赛解说和赛事直播，他们开始拓展到唱歌、跳舞、直播互动等多种娱乐形式。平台上的内容更加丰富，逐步形成了以电竞为核心，但又包含多种娱乐元素的内容生态。\n然而，泛娱乐化也带来了问题——电竞原本专注的游戏文化逐渐被边缘化，取而代之的是娱乐至上的趋势。这种趋势让一些原本深爱电竞文化的观众产生了离场的情绪，而资本也开始将更多的目光转向其他娱乐领域。资本的过度涌入与逐利性让电竞产业的本质逐渐变得模糊，原本以竞技为核心的价值理念开始弱化。\n2.2 泛娱乐行业的崛起：资本的撤退与转型\n随着短视频平台、直播平台以及娱乐圈等其他泛娱乐产业的崛起，资本逐渐将资金从电竞转向了更为广泛的娱乐内容。在这个过程中，腾讯、阿里巴巴、字节跳动等巨头也不再单纯依靠电竞项目作为盈利来源，而是加大了在电影、音乐、短视频等领域的投资。特别是字节跳动的崛起，通过抖音等短视频平台的爆发式增长，使得电竞的风头被其他娱乐内容所掩盖。\n第三章：英雄联盟的“青黄不接”：时代红利消退 自2011年《英雄联盟》进入中国市场以来，它几乎是中国电竞行业的代名词，成就了无数职业选手、战队和赛事，也催生了一个庞大的电竞产业链。然而，十多年过去了，《英雄联盟》作为中国电竞的领军项目，已经进入了“青黄不接”的阶段。尤其是在最近几年，《英雄联盟》的影响力正在逐渐下滑，甚至出现了明显的衰退迹象。\n3.1 玩家群体的“断层”\n最为明显的变化便是玩家群体的断层。最初，电竞的快速发展依靠的是大量青少年玩家的支持，他们中的许多人因为《英雄联盟》而成为了职业玩家或观众。那一代网瘾少年，几乎是在“时代红利”下成长起来的，他们沉浸于LOL带来的竞技魅力之中，也因此推动了整个行业的快速扩张。然而，随着时间的推移，这些玩家逐渐长大，进入了社会，开始转向其他生活和职业方向。与此同时，新一代的年轻玩家对《英雄联盟》的兴趣并不如当年的热烈，电竞的受众群体已经出现了明显的年龄偏差和兴趣下降。\n3.2 游戏内容的“疲软”\n《英雄联盟》经过多次更新和改版，虽然依然保持着一定的竞技魅力，但游戏本身的内容创新已经显得有些力不从心。每年发布的版本更新、英雄平衡调整以及新玩法的引入，似乎都未能从根本上解决玩家对新鲜感的需求。与此同时，MOBA类游戏的市场逐渐饱和，其他类型的游戏（如《王者荣耀》、《和平精英》）迅速崛起，分流了大量原本属于《英雄联盟》的玩家。这种竞争态势，让《英雄联盟》始终无法摆脱“追赶者”的角色。\n结语：电竞产业的未来何去何从？ 电竞产业更像是凭空而起的高楼，过多的资金在互联网行业中游荡，他们在寻找着下一个风口，而电竞产业也成为了他们的目标之一。依托着国内的人口红利，电竞产业在短时间内取得了巨大的成功，但这种成功并不是建立在稳固的基础之上。资本的过度涌入、人才的短缺、游戏内容的疲软，这些问题都在阻碍着电竞产业的健康发展。\n大学时代以前，游戏玩的并不是很多，可以说联盟算是伴随了一代人的成长，总决赛看了那么多，作为一个局外人，对比中韩的选手，特别是 Faker，国内的选手，在大赛期间，总是有一种畏首畏尾的感觉，我也知道选手的心理压力很大，但是这个行业也发展了十多年，选手的心理问题，理应被团队重视，但是并没有，国内的玩法还是依靠选手自身的天赋。\n","date":"2024-12-31T07:19:39+08:00","permalink":"https://ttf248.life/p/end-of-league-of-legends-era/","title":"野蛮资本时代的落幕：英雄联盟电竞时代终结"},{"content":"懂王再次当选美国总统，也将虚拟货币带回大众的视野中。港交所也一直在积极部署相关的业务，这里简单记录一下港交所的虚拟货币发展史。\n翻看相关合约清单的详情资料，发现最初引入的并不是现货而是期货，这也是合理的，因为期货市场的流动性更好，更容易引入机构投资者。而后引入的现货ETF，也是合理的，因为ETF是一种更容易接受的投资工具。\n虚拟货币清单 港交所的行情数据中并没有提供标识，区分合约是否为虚拟货币，但是可以通过合约的名称来判断。官网的交易清单中，倒是提供了对应的子类别virtualasset。\nhttps://www.hkex.com.hk/Market-Data/Securities-Prices/Exchange-Traded-Products?sc_lang=en\u0026amp;asset=virtualasset\n2022年12月16日 香港交易所歡迎亞洲首批加密資產ETF上市 香港交易及結算所有限公司（香港交易所）今天（星期五）歡迎亞洲首批加密資產ETF上市，進一步擴大其產品生態圈，為香港及國際投資者提供更多選擇。\n今天上市的兩隻新ETF — 南方東英比特幣期貨ETF（股份代號：3066）及南方東英以太幣期貨ETF（股份代號：3068）由南方東英資產管理有限公司管理，分別追蹤在芝加哥商品交易所（芝商所）交易的標準化、現金結算的比特幣期貨合約及以太幣期貨合約。\n香港交易所首席營運總監及市場聯席主管姚嘉仁表示：「今天上市的兩隻加密資產ETF，為香港日益豐富多元的交易所買賣產品生態圈錦上添花。這些新産品將首次在亞洲為投資者提供參與數碼資產投資的機會，亦反映了我們對數碼經濟的關注和市場的需求。我們期待在未來幾個月將迎來更多主題式 ETF 和數碼資產新產品。」\nETF是香港交易所旗下市場發展最快的業務之一，產品種類於2022年亦不斷拓展，愈趨多元化，包括於年內推出了首隻元宇宙ETF、首隻碳期貨ETF及首隻區塊鏈ETF，更首次將ETF納入滬深港通。\n此外，香港交易所買賣產品（ETP，包括ETF和槓桿及反向產品）今年首十一個月的平均每日成交金額為118億元，較去年同期的78億元大增50%，反映ETP愈來愈受投資者歡迎。截至2022年11月，於香港交易所上市的ETP共有168隻，市值達3,735億元。\n2024年4月30日 香港交易所歡迎首批虛擬資產現貨ETF上市 香港交易結算所有限公司（香港交易所）今天（星期二）歡迎亞洲首批虛擬資產現貨ETF 上市，增加香港市場的產品種類及為投資者提供更豐富的選擇，鞏固香港作為亞洲領先ETF 市場的地位。\n香港交易所證券產品發展主管羅博仁說：「今天新上市的虛擬資產現貨 ETF 將豐富香港交易所多元及活躍的ETF市場生態圈，為投資者提供新資產類別的投資機會。繼一年前成功推出虛擬資產期貨ETF後，亞洲首批虛擬資產現貨 ETF將進一步提升香港交易所買賣產品的產品種類及流動性。我們期待繼續與市場持份者緊密合作，在我們國際化的市場引入更多新產品。」\n首批虛擬資產期貨ETF在2022年上市後備受投資者青睞，交投暢旺。在香港上市的三隻虛擬資產期貨ETF的日均成交量由2023年的890萬元增加至2024年第一季的5,130萬元，同時亦吸引了 5.29 億元的資金流入。\n交易所買賣產品（包括ETF、槓桿及反向產品）是香港交易所增長最快的市場之一，產品種類在過去一年亦不斷增加。2023年及2024首季新增的16隻ETF產品包括亞太區首隻沙特阿拉伯ETF、香港首批備兌認購期權ETF，目前在香港上市的ETF共有179隻。\n2024年10月28日 香港交易所將推出虛擬資產指數系列 香港交易及結算所有限公司（香港交易所）今日（星期一）宣布，將於2024年11月15日推出香港交易所虛擬資產指數系列（指數系列），為虛擬資產這個快速興起的資產類別提供可靠的基準價格，支持香港發展成為亞洲領先的數字資產中心。\n該指數系列將為比特幣和以太幣在亞洲時區的定價提供透明且可靠的基準，致力於為虛擬資產提供統一參考價格，解決該類資產在全球交易所之間價格差異。\n香港交易所集團行政總裁陳翊庭表示：「我們很高興推出香港交易所虛擬資產指數系列，以滿足區域內對這一快速興起的資產類別的需求。通過提供透明可靠的實時基準，我們希望能夠幫助投資者做出明智的投資決策，從而支持虛擬資產生態圈的健康發展，鞏固香港作為國際金融中心的地位。」\n該指數系列的推出是香港交易所致力探索新興領域的一部分，一方面支持香港金融科技的發展，同時亦為投資者在不斷變化的市場環境中提供重要的基準工具和解決方案。\n指數系列將包括比特幣和以太幣的參考指數以及參考匯率。\n參考指數以比特幣或以太幣的24小時交易量加權的基準現貨價格為基礎，並依據多家主要虛擬資產交易所的匯總市場價格計算，且即時以美元計價。而參考匯率是為金融產品結算而設計，於香港時間每日下午4:00計算。\n該指數系列將會是香港開發的第一個符合歐盟基準法規（BMR）的虛擬資產指數系列，由位於英國注冊的基準管理機構與虛擬資產資料及指數提供商 CCData 共同管理和計算。\n香港特別行政區政府於2022年發布了關於虛擬資產發展的政策聲明，希望在香港培育一個充滿活力的虛擬資產產業和生態圈。香港交易所虛擬資產指數系列的推出將通過提供實時數據和亞洲時區的每日參考價格，幫助公眾增加對虛擬資產投資趨勢的理解。\n有關指數系列的設計和計算方法的更多細節將適時公布。\n参考资料 https://www.hkex.com.hk/news/news-release/2022/221216news?sc_lang=zh-hk https://www.hkex.com.hk/News/News-Release/2024/240430news?sc_lang=zh-HK https://www.hkex.com.hk/News/News-Release/2024/241028news?sc_lang=zh-HK ","date":"2024-12-31T07:00:28+08:00","permalink":"https://ttf248.life/p/hong-kong-exchange-virtual-currency-history/","title":"香港交易所，虚拟货币发展史"},{"content":"刚刚研究了Hugo的模块化功能，发现真的很强大。不像传统的插件系统，Hugo的模块更注重目录结构的一致性。通过 hugo mod init 就能轻松管理主题和依赖。\n突然想到，这种设计理念和微服务有点像，都是通过标准化的接口来实现模块间的解耦。\n","date":"2024-12-19T14:30:00+08:00","permalink":"https://ttf248.life/notes/2024-12-19-hugo-modules-thoughts/","title":"今天折腾了一下Hugo的模块化功能"},{"content":"今天第三杯咖啡了，突然意识到程序员和咖啡的关系就像是代码和编译器的关系：\n没有咖啡的程序员 = 没有编译器的代码 过量的咖啡 = 过度优化的代码，反而容易出bug 好的咖啡 = 优雅的代码，让人愉悦 看来需要找到咖啡的最佳实践了 😄\n","date":"2024-12-19T10:15:00+08:00","permalink":"https://ttf248.life/notes/2024-12-19-coffee-philosophy/","title":"程序员的咖啡哲学"},{"content":"早上6点起床，窗外还是一片黑暗。但是这种安静的感觉很棒，整个世界仿佛只属于我一个人。\n泡了一杯咖啡，开始今天的第一个番茄钟。发现早起真的能让一整天都更有效率。\n准备把这个习惯坚持下去 💪\n","date":"2024-12-19T08:30:00+08:00","permalink":"https://ttf248.life/notes/2024-12-19-0830-morning-routine/","title":""},{"content":"今天看到一段代码，注释写得特别棒：\n// 这里使用 setTimeout 而不是 setInterval // 因为我们需要等待上一次操作完成后再执行下一次 // 避免在慢网络环境下的并发问题 好的注释不是解释代码在做什么，而是解释为什么要这样做。\n这就是经验的价值所在。\n","date":"2024-12-18T22:15:00+08:00","permalink":"https://ttf248.life/notes/2024-12-18-code-comments-art/","title":"代码注释的艺术"},{"content":"最近在研究区块链在金融领域的应用，发现技术本身不是最大的障碍，监管和合规才是。\n想起之前做银行系统的经历，每一行代码都可能涉及资金安全，责任重大。相比之下，互联网产品的试错成本要低很多。\n也许这就是为什么金融科技的创新总是相对保守的原因吧。\n","date":"2024-12-18T16:45:00+08:00","permalink":"https://ttf248.life/notes/2024-12-18-fintech-thoughts/","title":"金融科技的一些思考"},{"content":"午餐时间到了，但是还想再写几行代码\u0026hellip;\n程序员的通病：一旦进入flow状态就忘记吃饭。\n不过健康更重要，马上去吃饭！\n身体是革命的本钱 🏃‍♂️\n","date":"2024-12-18T12:00:00+08:00","permalink":"https://ttf248.life/notes/2024-12-18-lunch-reminder/","title":""},{"content":"华泰柏瑞沪深300ETF等公告下调综合费率至同类最低一档。\n11月19日，华泰柏瑞基金公告，为更好地满足广大投资者的投资理财需求，自11月22日起，调低华泰柏瑞沪深300ETF及其联接基金的管理费率、托管费率，并修订相应基金合同中的有关内容。\n调整后，华泰柏瑞沪深300ETF及其联接基金的年管理费率降至0.15%，年托管费率降至0.05%，全部调至指数基金的最低一档费率。\n几乎同时，业内规模前列的华夏沪深300ETF、华夏上证50ETF、南方中证500ETF、嘉实沪深300ETF、易方达创业板ETF等亦公告调低管理费和托管费，费率全部降至0.15%和0.05%。\n与以往多数ETF降费不同的是，这一次降费由市场中具备规模优势品种的主动出击，对行业后续影响会较大。交易所数据显示，截至11月18日，华泰柏瑞沪深300ETF规模超过3700亿元，是当前市场上规模居首的ETF。\n规模最大的一批超级ETF率先降费，显示了其让利给投资者的主动意愿，也让投资者能以更高的性价比投资人气和流动性良好的基金产品。\n业内观点认为，具有规模优势的ETF降费，一方面，有利于发挥公募基金普惠金融的服务功能，更大面积地帮助投资者降低持有成本，提升收益空间和投资获得感；\n另一方面，低费率也有利于进一步提升产品本身的竞争力，在流动性虹吸效应和成本运营优势的加持下，产品有望吸引更多中长期增量资金入市，助建“长钱长投”的良好生态。\n近年来，凭借着交易灵活、透明度高、流动性强、投资门槛低等独特优势，宽基ETF已经成为资金低位入市、“长钱长投”的主要通道。\n本次降费，可能成为某种程度的“加速器”，让A股市场的长钱入场更加通畅。\n后记 笔者定投的天弘基金还没发公告，不过也应该会跟进。如果不更新，就要考虑换基金了。\n原管理费：0.5%，托管费：0.1%。新管理费：0.15%，托管费：0.05%。这个降幅还是很大的。\n","date":"2024-11-21T03:08:48+08:00","permalink":"https://ttf248.life/p/etf-fees-cut-china/","title":"降费了，降费了，国内超大型ETF批量降费了"},{"content":"大锤正在落下。\n投顾服务搭上短视频的东风后，或正在驶入快车道。\n今年9月下旬，A股行情呈现一片火热后，抖音荐股受到了各方的关注。\n先后有“大蓝”等多位财经主播在抖音走红，间接对资本市场造成了一定的波动。\n但一众迅速走红的财经主播背后力量也不容忽视，那就是第三方投顾服务公司。\n据了解，不少第三方投顾服务公司在短视频运营多个账号，通过投流吸引用户观看投教视频，提升用户购买相应投顾产品的热情。\n更有传言称，某第三方投顾公司仅仅今年10月便斩获10亿元收入，超过今年上半年的收入。\n但“好日子”正在面临更多变数。\n11月以来，多部门先后发文，要求证券服务机构加强自媒体账号的合规管理。\n11月15日晚，同花顺（300033.SZ）公告称子公司由于直播业务涉及暗示推荐个股等行为而被证监局处罚。 这或许都在向市场释放监管从严的信号。 九方智投（9636.HK）等一众第三方投顾服务机构的展业或许也将面临更多压力。\n监管严密盯梢 抖音等短视频平台的兴起，放大了情绪声音，也间接对交易行为造成影响。\n据巨量算数监测，在成交额创新高的9月27日至10月8日，抖音A股关键词搜索指数从423.84万飞升至1277.86万，膨胀了两倍多。\n如此境况下，第三方投顾机构“推波助澜”的行为，正在引起监管部门的关注。\n投顾机构人员在直播中通过各种方式推荐个股，是高频违规行为。\n11月8日，广东证监局对某公司直播中存在“暗示推荐个股”等情形做出了暂停新增客户的监管措施。\n11月14日晚，广东证券期货业协会发文《直播管控不到位，机构被暂停业务》，直指部分具有证券咨询资格的机构在直播展业过程中存在管控不到位等情况，且直播过程中存在推荐个股的行为。\n“杜绝直播荐股行为。直播属于公众媒体传播，直播人员无论是否登记为证券投资顾问，均不得在直播过程中推荐个股。”广东证券期货业协会指出。\n这不是孤例。\n此前的11月7日，上海证监局披露的罚单中，也有一例涉及在社交媒体平台非法荐股。\n经监管调查发现，海顺证券投资咨询有限公司上海分公司投顾人员王永，通过微信视频号公开发布具有误导性的视频内容，这违背了从业规范。\n上海证监局就此对王永采取出具警示函的监督管理措施。\n据信风（ID:TradeWind01）了解，还有部分不具备资格的投顾机构采取挂靠券商的方式在抖音推荐股票，现已被停播。\n“行业有人在抖音直播，实际上是挂靠在券商下面的，这样就有投资顾问资格了，然后线上直播引流，线下卖投顾组合产品。”华南一位投顾从业人士向信风（ID:TradeWind01）表示，“但是后来因为直播中推荐股票，被发现了，所以就被停播了。正规的券商一般就是投教直播会说板块情况，但不会涉及到个股。”\n目前监管正在对社交媒体非法荐股保持高度关注。\n例如深圳证监局通知近期，行业内出现个别机构或个人利用自媒体违规荐股等违规行为，为进一步规范辖区证券投资咨询机构自媒体运营管理，各机构要进一步加强公司自媒体运营管理。\n这或许给一众第三方投顾服务机构的展业带来更多挑战。\n“流量生意”是非 被短视频吸引入市的股民是否赚到钱不得而知，但作为“卖水人”的第三方投顾服务公司在二级市场的身价已经水涨船高。\n作为“在线投教第一股”，九方智投的市值从今年9月初的28.78亿元飙升至11月13日收盘的124.64亿元，49个交易日内涨幅已经高达333.08%。\n半年报显示，今年上半年九方智投在抖音、小红书等社交媒体平台进行品牌曝光，截止今年6月末已经有488个账户和0.46亿关注者。\n例如作为九方智投的首席投资顾问，“洪帮主”在抖音上的粉丝数达226万。\n“我们深耕MCN运营，以用户为中心，协同推动流量、品牌与产品的全面发展。”九方智投指出，“通过深度融合直播、短视频等新媒体工具，借助AI技术，构建起粉丝网路，并积极探索电商模式，有效实现流量的高效转化。”\n九方智投的投顾课程包覆盖了几十元到十余万元的不同价格带。其中最贵的课程包系超级投资家，定价为13.96万元/半年，内含独家观点、投顾私享服务等。\n不过九方智投的投顾产品退款率在10%以上。\n2024年上半年，九方智投旗舰系列、九方智投擒龙系列的退款率分别达到14.7%、18.5%。\n但在监管风暴下，九方智投的展业是否会受到影响，仍待进一步关注。\n近期有媒体报道称近期九方智投等第三方投顾公司旗下的账号受到了影响。\n11月7日，有媒体报道称“洪帮主”被暂停直播。\n不过11月15日下午信风（ID:TradeWind01）搜索该账号发现，在“洪帮主”的直播界面仍然可以预约11月18日的直播。\n同时还有市场消息称，有关部门已经进场九方智投检查。\n但接近九方智投人士告诉信风（ID:TradeWind01），相关检查属于常规检查，已经结束。\n这不是近期被卷入此轮监管风暴传闻的唯一一家公司。\n有消息称，同花顺涉非法荐股被立案，或将暂停展业。 对此，同花顺11月15日回应称“不存在非法荐股情况，不存在被立案调查。” 不过当天晚上，同花顺就宣布子公司浙江同花顺云软件有限公司由于直播业务推广过程中合规管控不到位, 且存在暗示推荐个股等情形而被浙江证监局处以暂停新增客户3个月等处罚。 这背后，或许也意味着监管部门对于抖音直播等社交媒体平台上的荐股内容的关注正在进一步升级。\n事实上，短视频的蛋糕也吸引着不少券商，但受限于合规要求，目前券商对此仍较为谨慎。\n某券商人士告诉信风（ID:TradeWind01），公司在探索短视频运营、引流的方法，还组织人员前往短视频平台公司进行学习，但受限于合规要求，目前仍处于探索阶段。\n事实上，监管的种种合规要求背后，是因为短视频平台的内容具有明显的情绪化色彩，但投资更多需要市场参与者保持理性来对待，二者存在天然的冲突。\n若放纵情绪的力量影响资本市场，容易引发市场的剧烈波动，有悖于资本市场的长期健康发展。\n证券持牌机构究竟应以何种方式拥抱短视频时代的到来，才能避免“踩红线”，对各方显然是一道难解的题。\n","date":"2024-11-21T02:59:18+08:00","permalink":"https://ttf248.life/p/third-party-wealth-managers-scrutiny-tiktok-stock-winners-crackdown/","title":"三方投顾监管升温，“抖音炒股”幕后赢家迎来整肃？"},{"content":"CentOS Stream是红帽企业Linux发行之前的上游开源开发平台‌。 首次关注到开源操作系统生命周期 redhat and centos life cycle\n到期了，有什么问题呢？除了安全问题，dnf 不能用了，我也是最近安装工具的时候，发现 dnf 失败，检查镜像源，发现是 CentOS 8 Stream 到期了。\nCentOS Stream简介 定位与角色‌ CentOS Stream位于Fedora Linux（上游开发）和RHEL（Red Hat Enterprise Linux，下游开发）之间，充当着桥梁的角色。\n它可以被视为是用来体验最新红帽系Linux特性的一个版本，适合尝鲜使用。‌\n诞生与背景‌ 随着时间的推移，Red Hat公司开始寻求更加有效的方式来发展其企业级Linux平台，于是推出了CentOS Stream。\n‌CentOS 8在2021年年底结束维护后，CentOS Stream作为其继承者继续更新，并成为CentOS项目的未来发展方向。‌\n特点与优势‌ CentOS Stream是一个滚动发布的Linux发行版，提供更快捷的更新。它为社区、合作伙伴和客户的参与提供了更高的透明度和更多机会，使得用户可以更快、更直接地为红帽企业Linux做贡献。‌\nCentOS Stream的内容是Red Hat有意收录于下个稳定版RHEL的软件，因此它能为社群成员提供一个稳定的ABI/API进行开发及测试之用。\n使用场景与目标用户‌ CentOS Stream适合那些希望继续获得最新Linux特性更新的CentOS用户，以及希望参与红帽企业Linux开发的开发人员和合作伙伴。‌\n它也旨在协助社群中的成员、Red Hat伙伴及其他人在一个较稳定及可预测的Linux生态环境下充分利用创新的开源程序。\n到期时间 Release Released Active Support Security Support Latest 9 3 years ago (15 Sep 2021) Ends in 2 years and 6 months (31 May 2027) Ends in 2 years and 6 months (31 May 2027) 9 8 5 years ago (24 Sep 2019) Ended 5 months and 3 weeks ago (31 May 2024) Ended 5 months and 3 weeks ago (31 May 2024) 8 解决方案 懒得折腾升级的问题，选用了ubuntu24.04长期支持版本。\n","date":"2024-11-16T23:24:50+08:00","permalink":"https://ttf248.life/p/centos-8-stream-eol/","title":"CentOS 8 Stream EOL"},{"content":"翻看历史提交记录，站点切换过很多次主题，每次切换主题都会有一些自定义的修改，这里记录一下自定义修改主题的思路。笔者的Github也有个仓库，短暂的维护过even主题，后来由于强迫症，非想要升级hugo编译器到最新版本，导致even主题不兼容，所以又切换到了stack主题。\nHugo的模块化 提到模块化，大家可能会想到的是Nginx模块，IDEA插件等等。 通常是我可以通过上传一些模块，来满足我的差异化需求。 之所以大家都喜欢这种模块，主要是因为足够灵活，不用费太大的劲就可以满足自身的需求。 因为很多时候，虽然大体上差不多，但总有一些细节上的差异。 这也正说明软件的复杂度，除了技术上的复杂度，还有业务上的复杂度。 大多数情况下，我们面对的主要是业务复杂度。 这也正是在软件领域，对”隔行如隔山”这句俗语最好的阐述。 如今，不仅互联网行业，金融行业，就算传统的制造业，都已经使用上了信息化系统，来帮助企业的生产和管理。 同样是请假系统，哪怕在同样的行业，不同的公司，都会有所差异。\n而Hugo的模块和大家印象中的模块有点不一样，并不是以功能为单位，来满足差异化需求。 而是以目录结构为主，来识别相同的结构。\n资料链接：07. Hugo架构 — Hugo的模块\n[[imports]] path = \u0026quot;github.com/CaiJimmy/hugo-theme-stack/v3\u0026quot; git submodule 方式依旧能用，本文不建议使用，如果引入主题的发生了更新，维护起来会比较麻烦，要单独的 git 仓库管理主题。\n主题的修改逻辑 有了前面模块化的基础概念理解，再来理解自定义主题，就简单那很多了，hugo现在的主题，也是多个不同的模块组装起来的，我们想要修改其中一个模块，找到对应的模板文件，修改即可。\n摘取自stack官方文档：\nUsing this method, there won\u0026rsquo;t be any file under themes directory. In order to modify the theme, you will have to copy the file you want to modify to the same directory under layouts directory.\nFor example, in order to modify the themes/hugo-theme-stack/layouts/partials/head/custom.html file, you will have to copy it to layouts/partials/head/custom.html and modify it there (copy the code from theme\u0026rsquo;s repository). The same applies to assets and static directories。\n如何找到模板文件 正统思路 翻阅主题的源码文件，理解主题的设计思路，找到对应的模板文件，修改即可。\n粗暴思路 笔者并不是很懂前端代码，所以有时候会采用粗暴的方式，比如直接在浏览器中打开对应的页面，找到想要修改的地方，通过审查元素的方式，定位到css name，主题源码中搜索，找到对应的文件，复制一份到站点目录，修改即可。\n小技巧 官方默认就提供了一个文件，用于自定义样式，我们需要改造的地方地方，可以通过拆分多个文件，custom.scss 文件引入我们其他的文件，这样可以更好的管理样式文件。\n汇总修改内容(6h) 现在已经是AI编码的元年，详细的内容，这里就不详细贴出来了，只是简单的列举一下，本站点的一些修改内容，比如调整复制按钮的样式，重新设置代码的块的样式，ChatGPT都是能轻松搞定的。\n整体：全局文字样式，沿用以前 even 融合 info cn 的显示风格，中文友好 首页：右侧导航增加鼠标交互动画 首页：文章新增摘要预览（耗时颇多，用了取巧的办法实现） 滚动栏：美化了一下滚动栏的样式 代码块：引入了 highlight.js 代码高亮插件，美化代码块样式 文章详情：部分内容属于转载，新增原作者信息展示，原链接展示 归档页面：顶部的分类图片，移除主题自带的颜色蒙版，显示原图 归档页面：新增了按照年份的分类的统计展示面板 归档页面：两栏显示布局 stack 主题的组件复用率很高，也导致首页文章新增摘要预览耗时颇多，改了对应的组件，文章的详情页面也随之发生了变动，导致正文重复展示内容，golang 模板的语法也不是很熟悉，所以花费了不少时间，组件之间的参数传递一直没搞定，最后通过取巧的办法，主页单独引入JavaScript脚本，通过自定义特殊变量，来实现摘要预览。\n有时候代码复用率太高也是个问题，会导致修改一个地方，其他地方也会受到影响，所以在修改主题的时候，一定要注意，不要破坏原有的逻辑。\n评论区 这哥们的修改更加完善：https://blog.reincarnatey.net/2024/0719-better-waline/\n本站点简单的启用了 Waline 评论系统，stack 主题默认支持 Waline，只需要在 config.toml 中配置即可。\n推荐首页邮箱联系、本站点不开放评论区\n","date":"2024-11-15T22:01:17+08:00","permalink":"https://ttf248.life/p/hugo-module-customizing-themes-ideas/","title":"Hugo Module自定义修改主题：思路讲解"},{"content":"最近抖音上的大冰老师很火，经常能刷到视频的切片账号，都是直播的里面的一些内容。有位连麦的听众问道：“大冰老师，我想把西安的房子卖了，回到老家躺平？”大冰老师回答：“你现在年龄，三十出头，你没法子躺平，你的父母在变老的路上，你的孩子还没成家立业，回到老家你还需要应付小县城里面的婆罗门”。\n先不说观点是非对错，婆罗门这个词是什么意思呢？\n县城婆罗门：小地方的“大人物” 在许多小县城里，大家总会说起一些“县城婆罗门”——这些人的存在，仿佛是地方社会的一种象征。他们往往不是什么真正的宗教人物，也没有拥有“高大上”的头衔，而是一些看似普通但又举足轻重的人物。他们代表的是小地方里的“权力、地位与话语权”，是那个县城里某个阶层的象征。\n什么是“县城婆罗门”？ 首先，我们得弄明白，“婆罗门”原本是印度社会中的最高阶层，代表着智慧、权威和精神上的至高无上。而在中国的县城中，“县城婆罗门”这个词，并没有那么复杂的宗教背景，它更多地是一种社会现象的比喻。\n简单来说，“县城婆罗门”可以理解为县城中的一些“文化权威”，比如那些老师、医生、当地的知名商人、官员等等。虽然他们的职位看似平凡，但在县城这种较为封闭的环境中，他们拥有的是相对较高的社会地位，或者说，他们的意见和行为在当地有着不容忽视的影响力。\n谁是“县城婆罗门”？ 在县城里，几乎每个行业都有这样的“婆罗门”。他们可能是：\n教育工作者：尤其是一些在地方上有着几十年教龄的老师，可能并不是什么名校毕业生，但他们深知如何通过知识建立威信，受到了广泛的尊敬。 地方政府官员：县城的副县长、科级干部等，他们掌控着一定的资源与权力，哪怕他们的职位不高，但因其权力范围局限，也能成为地方的“婆罗门”。 本地的“企业家”：一些县城里的老板，虽然规模并不大，但他们手中握有一定的财富，拥有了地方话语权。他们或许经营着一两家本地知名的小企业，在县城中有着不小的影响力。 这些人，虽然与大城市里的名流或高官相比，地位不算显赫，但在县城这个小社会里，他们的地位几乎等同于“文化长者”或“权力中心”。\n“县城婆罗门”的地位，如何影响社会？ 要理解“县城婆罗门”的真正意义，我们必须从县城的特殊环境来考量。在这个地方，信息流通不如大城市那么快，社会阶层的流动也较为固定。这里的“婆罗门”们，往往是因为长期深耕当地，积累了声望、知识和人脉。他们影响着地方的政治、经济、文化等各个方面。\n文化影响力：在小地方，尤其是教育系统可能没那么发达，普通人也没有太多的选择空间。当地的文化“婆罗门”通过课堂上的知识传递、媒体的讲解、乃至社交场合的言传身教，悄然塑造了地方的文化氛围。\n社会资源的集中：由于县城的人口和资源有限，这些“婆罗门”往往是地方资源的主要掌控者之一。无论是社会福利、政策落实，还是某些项目的审批，都少不了他们的影响。他们的话语权和决定权，使得他们在地方社会中占据了一席之地。\n人际关系的网状结构：在一个相对封闭的小社会里，人际关系往往至关重要。这些“县城婆罗门”通过建立强大的社交网络，控制了信息流通和资源分配，因此能在关键时刻起到决定性的作用。\n“县城婆罗门”背后的隐喻 虽然“县城婆罗门”常常是受到尊敬和崇拜的，但这种“高高在上”的地位也并非没有问题。在现代社会里，我们不难发现，许多县城的“婆罗门”可能并没有真正的能力和创新精神，而是通过世袭关系、资源垄断等方式，保持着自己的位置。随着信息化的发展，这些“婆罗门”的权力逐渐被打破，新的社会流动性开始影响着小县城的面貌。\n总的来说，“县城婆罗门”是一个很有趣的社会现象，体现了地方社会中的权力和文化结构。尽管他们的“权力”可能并不直接威胁到国家的治理，但在地方范围内，他们无疑是举足轻重的人物。在这个信息流通迅速、社会变革加速的时代，县城里的这些“婆罗门”们也许正在面临着前所未有的挑战。\n结语 本来都不会有这篇稿子，就是好奇婆罗门是什么，然后扔给了kimi，结果还挺搞笑的，我能看到网页端已经搜索出来了结果，但是瞬间就变成了相关内容无法展示，然后我就想，这个词是不是有什么特殊的意义，然后我就扔给了ChatGPT,就有了这篇文章。\n","date":"2024-11-13T23:02:25+08:00","permalink":"https://ttf248.life/p/county-brahmins-big-shots-in-small-towns/","title":"县城婆罗门：小地方的“大人物”"},{"content":"在C++开发的历史项目中，我们使用自定义协议进行通信，协议采用了二维数组的模式。在处理大量数据时，协议内部需要遍历数组并进行序列化操作以生成日志，由于效率较低，导致了系统在高负载下出现明显的卡顿，业务部门反馈系统卡顿。\n问题定位 在排查问题时，我们首先对系统进行了性能分析，发现系统在处理大量数据时，CPU 占用率明显增加，且系统响应时间变长。通过分析系统的日志，我们发现了大量的序列化操作，这些操作在处理二维数组时效率较低，导致了系统性能下降。\npstack工具截取服务的线程信息，定位到日志线程大部分时间都在处理字符串的拼接。\n这里是今天的重点，不同的累加方式，效率差别巨大。历史代码中使用的是 + 运算符，这种方式会频繁的创建临时对象，效率很低。你知道它效率很差，但你不知道它效率有多差的那种。\ndemo 验证 基于项目代码，我们抽离业务逻辑，编写了一个简单的 demo，用于验证字符串拼接的效率问题。windows 下的 vs2022 编译器，linux 下的 gcc8.5 编译器，Release模式下编译运行，对比效率。\n关键点说明 项目使用的是方法四，在尚未拿到测试数据的时候，读者可以先思考一下，哪种方式效率最高？哪种方式效率最低？看到结果的时候，我还是很惊讶的。\n方法 1 (+= 拼接)：直接通过 += 将每个字段拼接到字符串中。 方法 2 (std::ostringstream 拼接)：使用流（std::ostringstream）来拼接每个字段，这种方法更高效，特别是对于大量数据拼接时。 方法 3（预分配内存的 += 拼接）：通过 reserve 提前为字符串分配足够的内存，减少了内存重新分配的开销，从而提升了性能。 方法 4 (bodys = bodys + body + \u0026quot;\\n\u0026quot;)：每次拼接都创建一个新的临时字符串对象，这会导致性能下降，尤其是在大规模拼接时，因为每次拼接都会涉及一次新的内存分配和复制。 参考结果，我们可以看到，项目刚好选中了效率最差的方式。\n再进一步，我们来分析不同平台编译器的优化效率，微软的 visual studio 一如既往的优秀，针对字符串的优化效率很高，而 gcc 编译器在这方面的优化效率就差了一些。\n代码在不同的机器执行，两份数据没有直接的对比意义，可以分别对比不同拼接方法之间的差值。\nwindows 平台下的 vs2022 编译器 ---------------------------------------- Data Generation Time: 0.054 seconds. ---------------------------------------- ---------------------------------------- Data Merging Performance: ---------------------------------------- + Data merging (+=) took: 0.053 seconds. + ostringstream Data merging took: 0.054 seconds. + Pre-reserved Data merging took: 0.045 seconds. + Data merging (bodys = bodys + body + \u0026quot;\\n\u0026quot;) took: 16.108 seconds. ---------------------------------------- Data Merging Complete. ---------------------------------------- Program finished. linux 平台下的 gcc8.5 编译器 ---------------------------------------- Data Generation Time: 0.108 seconds. ---------------------------------------- ---------------------------------------- Data Merging Performance: ---------------------------------------- + Data merging (+=) took: 0.100 seconds. + ostringstream Data merging took: 0.083 seconds. + Pre-reserved Data merging took: 0.057 seconds. + Data merging (bodys = bodys + body + \u0026quot;\\n\u0026quot;) took: 29.298 seconds. ---------------------------------------- Data Merging Complete. ---------------------------------------- Program finished. 完整代码 #include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;random\u0026gt; #include \u0026lt;chrono\u0026gt; #include \u0026lt;sstream\u0026gt; #include \u0026lt;iomanip\u0026gt; typedef std::vector\u0026lt;std::string\u0026gt; DataRow; typedef std::vector\u0026lt;DataRow\u0026gt; DataGroup; struct ResponsePackage { std::string ErrorInfo; DataRow Head; std::string ClientId; std::string UUID; std::string MsgID; std::string SessionID; std::string ExtraInfo1; std::string ExtraInfo2; DataGroup DataBody; }; // Generate specified length of random string std::string generateRandomString(size_t length) { const char charset[] = \u0026quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\u0026quot;; const size_t max_index = sizeof(charset) - 1; std::string random_string; random_string.reserve(length); std::random_device rd; std::mt19937 generator(rd()); std::uniform_int_distribution\u0026lt;\u0026gt; distribution(0, max_index); for (size_t i = 0; i \u0026lt; length; ++i) { random_string += charset[distribution(generator)]; } return random_string; } void create_large_string() { // Example request package with 50 fields ResponsePackage requestPackage; requestPackage.Head = { \u0026quot;Field1\u0026quot;, \u0026quot;Field2\u0026quot;, \u0026quot;Field3\u0026quot;, \u0026quot;Field4\u0026quot;, \u0026quot;Field5\u0026quot;, \u0026quot;Field6\u0026quot;, \u0026quot;Field7\u0026quot;, \u0026quot;Field8\u0026quot;, \u0026quot;Field9\u0026quot;, \u0026quot;Field10\u0026quot;, \u0026quot;Field11\u0026quot;, \u0026quot;Field12\u0026quot;, \u0026quot;Field13\u0026quot;, \u0026quot;Field14\u0026quot;, \u0026quot;Field15\u0026quot;, \u0026quot;Field16\u0026quot;, \u0026quot;Field17\u0026quot;, \u0026quot;Field18\u0026quot;, \u0026quot;Field19\u0026quot;, \u0026quot;Field20\u0026quot;, \u0026quot;Field21\u0026quot;, \u0026quot;Field22\u0026quot;, \u0026quot;Field23\u0026quot;, \u0026quot;Field24\u0026quot;, \u0026quot;Field25\u0026quot;, \u0026quot;Field26\u0026quot;, \u0026quot;Field27\u0026quot;, \u0026quot;Field28\u0026quot;, \u0026quot;Field29\u0026quot;, \u0026quot;Field30\u0026quot;, \u0026quot;Field31\u0026quot;, \u0026quot;Field32\u0026quot;, \u0026quot;Field33\u0026quot;, \u0026quot;Field34\u0026quot;, \u0026quot;Field35\u0026quot;, \u0026quot;Field36\u0026quot;, \u0026quot;Field37\u0026quot;, \u0026quot;Field38\u0026quot;, \u0026quot;Field39\u0026quot;, \u0026quot;Field40\u0026quot;, \u0026quot;Field41\u0026quot;, \u0026quot;Field42\u0026quot;, \u0026quot;Field43\u0026quot;, \u0026quot;Field44\u0026quot;, \u0026quot;Field45\u0026quot;, \u0026quot;Field46\u0026quot;, \u0026quot;Field47\u0026quot;, \u0026quot;Field48\u0026quot;, \u0026quot;Field49\u0026quot;, \u0026quot;Field50\u0026quot; }; requestPackage.ClientId = \u0026quot;ClientID\u0026quot;; requestPackage.UUID = \u0026quot;UUID\u0026quot;; requestPackage.MsgID = \u0026quot;MsgID\u0026quot;; requestPackage.SessionID = \u0026quot;SessionID\u0026quot;; requestPackage.ExtraInfo1 = \u0026quot;ExtraInfo1\u0026quot;; requestPackage.ExtraInfo2 = \u0026quot;ExtraInfo2\u0026quot;; // Start timing for data generation auto start_gen = std::chrono::high_resolution_clock::now(); // Generate 10,000 rows of data, each with 50 fields for (size_t i = 0; i \u0026lt; 10000; ++i) { DataRow dataRow(50, \u0026quot;This is a test string\u0026quot;); requestPackage.DataBody.push_back(dataRow); } // End timing for data generation auto end_gen = std::chrono::high_resolution_clock::now(); std::chrono::duration\u0026lt;double\u0026gt; duration_gen = end_gen - start_gen; // Display result generation time std::cout \u0026lt;\u0026lt; \u0026quot;\\n----------------------------------------\\n\u0026quot;; std::cout \u0026lt;\u0026lt; \u0026quot;Data Generation Time: \u0026quot; \u0026lt;\u0026lt; std::fixed \u0026lt;\u0026lt; std::setprecision(3) \u0026lt;\u0026lt; duration_gen.count() \u0026lt;\u0026lt; \u0026quot; seconds.\\n\u0026quot;; std::cout \u0026lt;\u0026lt; \u0026quot;----------------------------------------\\n\u0026quot;; // Data merging using different methods std::cout \u0026lt;\u0026lt; \u0026quot;\\n----------------------------------------\\n\u0026quot;; std::cout \u0026lt;\u0026lt; \u0026quot;Data Merging Performance:\\n\u0026quot;; std::cout \u0026lt;\u0026lt; \u0026quot;----------------------------------------\\n\u0026quot;; { // Method 1: Using '+=' string concatenation auto start_merge = std::chrono::high_resolution_clock::now(); std::string bodys(\u0026quot;\u0026quot;); for (auto\u0026amp; vec : requestPackage.DataBody) { std::string body(\u0026quot;This is a test string\u0026quot;); for (auto\u0026amp; item : vec) { body += item + \u0026quot; \u0026quot;; } bodys += body + \u0026quot;\\n\u0026quot;; } auto end_merge = std::chrono::high_resolution_clock::now(); std::chrono::duration\u0026lt;double\u0026gt; duration_merge = end_merge - start_merge; std::cout \u0026lt;\u0026lt; \u0026quot;+ Data merging (+=) took: \u0026quot; \u0026lt;\u0026lt; std::fixed \u0026lt;\u0026lt; std::setprecision(3) \u0026lt;\u0026lt; duration_merge.count() \u0026lt;\u0026lt; \u0026quot; seconds.\\n\u0026quot;; } { // Method 2: Using ostringstream auto start_merge = std::chrono::high_resolution_clock::now(); std::ostringstream bodys; for (auto\u0026amp; vec : requestPackage.DataBody) { std::ostringstream body; body \u0026lt;\u0026lt; \u0026quot;This is a test string\u0026quot;; for (auto\u0026amp; item : vec) { body \u0026lt;\u0026lt; item \u0026lt;\u0026lt; \u0026quot; \u0026quot;; } bodys \u0026lt;\u0026lt; body.str() \u0026lt;\u0026lt; \u0026quot;\\n\u0026quot;; } auto end_merge = std::chrono::high_resolution_clock::now(); std::chrono::duration\u0026lt;double\u0026gt; duration_merge = end_merge - start_merge; std::cout \u0026lt;\u0026lt; \u0026quot;+ ostringstream Data merging took: \u0026quot; \u0026lt;\u0026lt; std::fixed \u0026lt;\u0026lt; std::setprecision(3) \u0026lt;\u0026lt; duration_merge.count() \u0026lt;\u0026lt; \u0026quot; seconds.\\n\u0026quot;; } { // Method 3: Pre-allocated memory auto start_merge = std::chrono::high_resolution_clock::now(); std::string bodys; bodys.reserve(1000 * 50 * 20); // Pre-allocate enough memory for (auto\u0026amp; vec : requestPackage.DataBody) { std::string body(\u0026quot;This is a test string\u0026quot;); body.reserve(50 * 20); // Pre-allocate memory for each row for (auto\u0026amp; item : vec) { body += item + \u0026quot; \u0026quot;; } bodys += body + \u0026quot;\\n\u0026quot;; } auto end_merge = std::chrono::high_resolution_clock::now(); std::chrono::duration\u0026lt;double\u0026gt; duration_merge = end_merge - start_merge; std::cout \u0026lt;\u0026lt; \u0026quot;+ Pre-reserved Data merging took: \u0026quot; \u0026lt;\u0026lt; std::fixed \u0026lt;\u0026lt; std::setprecision(3) \u0026lt;\u0026lt; duration_merge.count() \u0026lt;\u0026lt; \u0026quot; seconds.\\n\u0026quot;; } { // Method 4: Using 'bodys = bodys + body + \u0026quot;\\n\u0026quot;' auto start_merge = std::chrono::high_resolution_clock::now(); std::string bodys(\u0026quot;\u0026quot;); for (auto\u0026amp; vec : requestPackage.DataBody) { std::string body(\u0026quot;This is a test string\u0026quot;); for (auto\u0026amp; item : vec) { body = body + item + \u0026quot; \u0026quot;; // Note the use of 'body = body + item' } bodys = bodys + body + \u0026quot;\\n\u0026quot;; // Again, using 'bodys = bodys + body' } auto end_merge = std::chrono::high_resolution_clock::now(); std::chrono::duration\u0026lt;double\u0026gt; duration_merge = end_merge - start_merge; std::cout \u0026lt;\u0026lt; \u0026quot;+ Data merging (bodys = bodys + body + \\\u0026quot;\\\\n\\\u0026quot;) took: \u0026quot; \u0026lt;\u0026lt; std::fixed \u0026lt;\u0026lt; std::setprecision(3) \u0026lt;\u0026lt; duration_merge.count() \u0026lt;\u0026lt; \u0026quot; seconds.\\n\u0026quot;; } std::cout \u0026lt;\u0026lt; \u0026quot;\\n----------------------------------------\\n\u0026quot;; std::cout \u0026lt;\u0026lt; \u0026quot;Data Merging Complete.\\n\u0026quot;; std::cout \u0026lt;\u0026lt; \u0026quot;----------------------------------------\\n\u0026quot;; } int main() { try { create_large_string(); } catch (const std::exception\u0026amp; e) { std::cerr \u0026lt;\u0026lt; \u0026quot;Caught exception: \u0026quot; \u0026lt;\u0026lt; e.what() \u0026lt;\u0026lt; std::endl; } std::cout \u0026lt;\u0026lt; \u0026quot;\\nProgram finished.\\n\u0026quot;; return 0; } ","date":"2024-11-13T19:42:59+08:00","permalink":"https://ttf248.life/p/linux-backend-slow-string-processing/","title":"linux后端服务处理大量字符串数据-效率很慢"},{"content":"在C++中，lambda表达式是一种方便的匿名函数，可以捕获外部变量并在其体内使用。这使得lambda成为一种灵活的编程工具。不过，lambda表达式的参数生命周期是一个需要特别关注的方面，尤其是在捕获和传递参数时\n1. Lambda表达式的参数生命周期 Lambda表达式的参数生命周期通常与其他C++函数一样。函数的参数在函数调用时存在，函数调用结束时，参数生命周期结束。然而，由于lambda表达式可能会捕获外部变量，因此参数的生命周期也受到捕获方式的影响。\n2. 捕获与参数生命周期的关系 2.1 捕获外部变量 C++的lambda表达式允许通过两种方式捕获外部变量：\n按值捕获：通过值捕获，外部变量的值被复制到lambda内部，lambda内的副本生命周期由lambda的生命周期控制。 按引用捕获：通过引用捕获，外部变量的引用会保留，lambda内的引用指向原始外部变量，生命周期取决于外部变量。 int x = 10; auto lambda_by_value = [x]() { std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; std::endl; }; // 捕获x的副本 auto lambda_by_reference = [\u0026amp;x]() { std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; std::endl; }; // 捕获x的引用 lambda_by_value(); // 打印10 lambda_by_reference(); // 打印10 对于捕获的变量，生命周期如下：\n按值捕获：捕获时外部变量的值被复制到lambda，lambda生命周期结束时，复制的副本被销毁。 按引用捕获：lambda持有外部变量的引用，外部变量必须在lambda使用之前有效，否则会导致未定义行为。 2.2 Lambda参数 Lambda的参数与常规函数参数类似，它们的生命周期仅限于lambda函数体内。也就是说，lambda参数会在lambda调用时被创建，并且在lambda调用结束后，参数的生命周期也结束。\nauto lambda = [](int a, int b) { std::cout \u0026lt;\u0026lt; a + b \u0026lt;\u0026lt; std::endl; }; lambda(5, 10); // a和b在这里是lambda的参数 在这个例子中，a 和 b 是lambda表达式的参数，它们在lambda调用时创建，并在lambda执行结束后销毁。\n3. 捕获外部变量时的生命周期问题 3.1 捕获的变量是否能在lambda外部有效 按值捕获：即使外部变量在lambda调用后销毁，lambda内部依然持有外部变量的副本。因此，lambda内部的副本可以安全使用，即使外部变量已经不再存在。 int x = 10; auto lambda = [x]() { std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; std::endl; }; x = 20; // x 在lambda调用后修改 lambda(); // 打印10，捕获的是x的副本 按引用捕获：如果捕获的是外部变量的引用，lambda内部对该引用的访问依赖于外部变量的生命周期。如果外部变量在lambda执行之前就销毁了，那么会出现悬空引用的问题，导致未定义行为。 int x = 10; auto lambda = [\u0026amp;x]() { std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; std::endl; }; x = 20; // x 在lambda调用前修改 lambda(); // 打印20，捕获的是x的引用 如果lambda的执行顺序不确定，确保捕获的外部变量在lambda执行时仍然有效非常重要。\n","date":"2024-11-13T19:23:02+08:00","permalink":"https://ttf248.life/p/cpp-lambda-parameter-lifetime/","title":"C++中lambd表达式参数生命周期"},{"content":"书接上回，回来发现 Ghub 有更新，有点小开心，客服说的问题驱动无法正常加载的问题能搞定了，结果折腾一圈，重装卸载，还是不能正常使用。\n背景 继续联系客服咨询处理处理方案，结果被告知，能有工程师远程协助，但是工程师的上班时间和我自己的上班时间一模一样，无奈下只能放弃，翻看上次排查问题留下的资料，准备尝试手动安装驱动。\n获取驱动安装包 罗技官方并没有单独提供设备的驱动安装包，我如何才能拿到驱动文件呢？\n配合上次重装系统留下的系统镜像安装包，我们可以在本地虚拟机中重装一次系统，再纯净的系统中，我们单独部署一份Ghub，将耳机设备介入到虚拟机中，找到驱动的路径，拷贝出来即可。\n相关的路径：\nC:\\ProgramData\\LGHUB C:\\Windows\\System32\\DriverStore\\FileRepository\\logi_audio.inf_amd64_010b035044e24be4 设备管理器 重点是第二个路径怎么找到的，我们先简单梳理一波 Win11 系统如何手动管理驱动文件。这块内容，通过控制变量法来识别的，通过不断的插拔设备，在虚拟机里面分析设备管理器中的设备信息，识别到耳机合计有三个驱动需要处理。其中有两个驱动是系统自带的，只有一个是罗技提供的。\n上图中的第二个驱动，是由罗技提供的，我们分析设备现在的驱动程序，再虚拟机里面翻找所有的驱动路径，当然你首先需要找到 logi 开头的文件，然后进行文件的对比，你就能定位到驱动的文件件，拷贝整个文件夹，你就拿到了驱动安装包\n安装驱动 还在在设备管理器的界面，点击：更新驱动，点击：浏览我的电脑查找驱动，进入到如下界面：\n当然你打开的时候，只能看到一个驱动，那就是普通的USB驱动，选择从磁盘安装，路径就是我们前面拷贝出来的文件夹，安装以后，选择的下拉清单中，就能多出来罗技特有的驱动，将设备驱动切换到新安装的驱动即可。\n人体学设备驱动 这块的驱动文件都是系统提供的，你只需要检查设备的驱动前面是否存在感叹号，如果存在感叹号，进入驱动选择界面，随意切换一个其他类型的驱动，然后再改回来即可恢复正常\n完工 耳机麦克风的音量恢复正常，熟悉的耳返功能也回来了。\n","date":"2024-06-05T07:20:17+08:00","permalink":"https://ttf248.life/p/win11-logitech-g431-headphone-driver-installation/","title":"Win11 Logitech G431 耳机驱动安装"},{"content":"如果完全不懂这些东西，第一时间联系官方的客服也就不会折腾好几个小时。\n正文 最近，我家里用于开发的台式电脑C盘空间不够用了，特意拿出了一块256GB的半退役固态硬盘单独给C盘使用，奈何经常瞎折腾。自从搬到上海后一直忙于各种事务，终于在上周抽空重装了系统。\n重装系统过程很顺利，日常软件的安装和开发环境的部署也都没有出现问题。几天后，我打算放松一下，玩几局游戏，这时才想起鼠标和耳机的驱动还没有安装。这两个设备都是罗技的，所以我下载了GHUB软件，它可以自动识别硬件并安装驱动。\n然而，意外发生了。鼠标的驱动安装顺利，但耳机的驱动一直显示“加载中”。我怀疑可能是最新版的Windows 11系统与罗技的驱动不兼容，导致安装失败。于是，我开始查找资料，尝试手动安装驱动，但问题依旧没有解决。\n简单科普一下，这两个设备的驱动分别起什么作用。\n鼠标的驱动主要用于调节鼠标的移动速度等功能。宏功能我很少用，只需恢复以前记得的参数即可。 耳机的驱动则主要用于耳返功能，这在团队语音时非常有用，可以让我听到自己讲话的声音。虽然系统的麦克风设置里有类似的侦听功能，但效果不如驱动实现得好。 尽管我反复尝试，耳机的驱动始终无法正常加载。今天，我终于想到可以找客服问问情况，看看是否有解决方案。客服告诉我，最近他们的服务器出了问题，导致驱动下载异常。他们正在处理这个问题，让我不要着急，等下次更新后问题就能解决了。\n虽然还没能解决耳机驱动的问题，但至少知道了原因，希望问题能尽快得到解决。\n鼠标驱动设置 ","date":"2024-05-31T21:46:12+08:00","permalink":"https://ttf248.life/p/logitech-headphone-driver-installation-failure/","title":"罗技耳机驱动安装失败"},{"content":" 取消商品房利率下限 明日起下调公积金利率0.25% 首套首付比例降至15% 3000亿元保障性住房再贷款 取消全国层面首套住房和二套住房商业性个人住房贷款利率政策下限 中国人民银行上海总部，各省、自治区、直辖市及计划单列市分行；各国有商业银行，中国邮政储蓄银行，各股份制商业银行：\n为落实党中央、国务院决策部署，适应我国房地产市场供求关系的新变化、人民群众对优质住房的新期待，促进房地产市场平稳健康发展，现就调整商业性个人住房贷款利率政策有关事项通知如下：\n一、取消全国层面首套住房和二套住房商业性个人住房贷款利率政策下限。\n二、中国人民银行各省级分行按照因城施策原则，指导各省级市场利率定价自律机制，根据辖区内各城市房地产市场形势及当地政府调控要求，自主确定是否设定辖区内各城市商业性个人住房贷款利率下限及下限水平（如有）。\n三、银行业金融机构应根据各省级市场利率定价自律机制确定的利率下限（如有），结合本机构经营状况、客户风险状况等因素，合理确定每笔贷款的具体利率水平。\n下调个人住房公积金贷款利率0.25个百分点 中国人民银行上海总部，各省、自治区、直辖市及计划单列市分行；各政策性银行、国有商业银行，中国邮政储蓄银行，各股份制商业银行：\n中国人民银行决定，自2024年5月18日起，下调个人住房公积金贷款利率0.25个百分点，5年以下（含5年）和5年以上首套个人住房公积金贷款利率分别调整为2.35%和2.85%，5年以下（含5年）和5年以上第二套个人住房公积金贷款利率分别调整为不低于2.775%和3.325%。\n首付款比例调整为不低于15% 中国人民银行上海总部，各省、自治区、直辖市及计划单列市分行；国家金融监督管理总局各监管局；各国有商业银行，中国邮政储蓄银行，各股份制商业银行：\n为落实党中央、国务院决策部署，适应我国房地产市场供求关系的新变化、人民群众对优质住房的新期待，促进房地产市场平稳健康发展，现就个人住房贷款政策有关事项通知如下：\n对于贷款购买商品住房的居民家庭，首套住房商业性个人住房贷款最低首付款比例调整为不低于15%，二套住房商业性个人住房贷款最低首付款比例调整为不低于25%。\n在此基础上，中国人民银行各省级分行、国家金融监督管理总局各派出机构根据城市政府调控要求，按照因城施策原则，自主确定辖区各城市首套和二套住房商业性个人住房贷款最低首付款比例下限。\n央行将设立3000亿保障性住房再贷款 下午4点，住房城乡建设部、自然资源部、中国人民银行、国家金融监督管理总局四部门齐聚国务院政策例行吹风会，介绍切实做好保交房工作配套政策有关情况。\n会上，中国人民银行副行长陶玲宣布，央行将设立3000亿保障性住房再贷款，支持地方国有企业以合理价格收购已建成未出售商品房，用作配售型或配租型保障性住房，预计将带动银行贷款5000亿元。\n据央行介绍，保障性住房再贷款期限一年可展期4次，利率1.75%，面向21家全国性银行，激励银行向城市政府选定的地方国有企业发放贷款，收购已建成未出售商品房用作保障性住房。所收购的商品房严格限定在房地产企业已建成未出售的商品房。\n关于此政策，近期央行将出台《关于设立保障性住房再贷款有关事宜的通知》。\n","date":"2024-05-17T20:42:25+08:00","permalink":"https://ttf248.life/p/promoting-real-estate-and-central-bank-four-measures/","title":"促进房地产、央行连发四招"},{"content":"最近，家中的装修项目让日常开销激增。平常也都在用信用卡，账单周期内还钱，虽然手头上有足够的现金，但更倾向于将这些现金存放在货币基金中，以获得一些额外的利息收入。同时，为了确保财务的稳定性，设置了自动还款功能，以便到期时能够及时偿还信用卡账单。\n银行现状：存款增加，贷款减少 在经济不确定性增加的情况下，人们更倾向于储蓄而不是消费或投资。这导致银行的存款量增加，但同时也意味着银行需要支付更多的利息给存款人。另一方面，由于消费和投资活动的减少，贷款需求降低，银行难以通过发放贷款来获取利息收入。\n为了吸引和留住客户，银行不得不提供更有竞争力的存款利率，这进一步压缩了银行的利差空间。同时，为了刺激经济增长和消费，中央银行可能会采取降低基准利率的政策，这也会影响到银行的贷款利率，进而影响银行的盈利能力。\n银行营销策略：培养用户习惯 最近快到了还款的日子。首先，交通银行联系我，提供了一年期的免费分期服务，不收取任何利息。紧接着，招商银行也提供了分期利息打2.5折的优惠，折算成年化利率仅为1.9%。面对这样的优惠，我选择了接受两家银行的分期服务。\n我意识到银行为了培养用户习惯，真的不惜下血本。按照银行流水的定义，我应该属于银行的优质客户。在当前银行资金放贷难的背景下，通过培养我的分期意识，银行实际上是在为未来我可能出现的资金周转困难做准备，届时他们就能从我这里赚取更多的利息收入。毕竟，众所周知，信用卡账单分析的利息并不低。\n银行通过提供免费分期服务和低利率分期优惠，不仅增加了信用卡的使用频率和额度，还在用户心中树立了积极的形象。这种策略的转变体现了银行对市场变化的快速响应和对客户需求的深入理解。通过这种方式，银行不仅解决了资金放贷难的问题，还为未来的盈利做好铺垫，赚钱不是只看当下，放眼未来才能长长久久。\n个人财务管理的重要性 尽管银行的分期优惠听起来很诱人，但作为用户，用户应当认识到过度依赖信用卡分期可能会带来的风险。我们应该充分考虑自身的还款能力和未来的资金需求，避免因短期的财务便利而陷入长期的债务困境。个人财务管理的关键在于平衡当前的需求与未来的规划。\n","date":"2024-03-31T01:33:48+08:00","permalink":"https://ttf248.life/p/bank-marketing-personal-finance-balance/","title":"银行营销策略与个人财务管理的平衡艺术"},{"content":"在当今数字时代，游戏已经不仅仅是一种简单的娱乐方式，而是成为了人们日常生活中不可或缺的一部分。从心理学的角度来看，游戏在不同年龄段的人们心理发展中扮演着不同的角色，同时也与社交娱乐紧密相连。\n心理状态 年轻人处于探索自我和建立身份的阶段，游戏为他们提供了一个低成本的尝试和探索环境。通过游戏，他们可以尝试不同的角色和生活，满足好奇心和探索欲。而随着年龄的增长，个人的兴趣和价值观逐渐稳定，游戏可能不再符合他们的生活目标和兴趣点。\n社交属性 同时，游戏也成为了社交活动的一部分，特别是对年轻人而言。他们通过游戏结交朋友和建立社交网络，游戏成为了社交的桥梁。然而，随着年龄的增长，人们的社交圈逐渐稳定，社交需求可能通过其他更成熟的方式得到满足，游戏在社交中的作用相对减弱。\n社交属性：带妹 在国内，由于恋爱教育的不足，小时候父母只会让你好好学习，毕业了立马就让你恋爱，这个现象很常见。\n因为学业、工作繁忙或缺乏交往技巧，在现实生活中未能建立起稳定的情感关系，从而感到孤独和渴望被关注。游戏中的“带妹”行为为他们提供了一个释放这种渴望的出口，通过帮助和保护女性玩家，他们能体验到被需要和被重视的感觉，获得情感上的满足。\n同时，游戏中的互动规则明确、环境可控，相比现实生活的复杂性和不确定性，游戏提供了一种确定性和安全感，减少了对现实交往中不确定性的恐惧。然而，长期依赖游戏中的虚拟满足感可能会影响他们在现实生活中建立和维护健康情感关系的能力\n现实压力 游戏提供了一个虚拟的世界，让玩家可以暂时逃避现实中的压力、挑战或不愉快的情绪。特别是对于那些面临学业压力、家庭问题或人际关系挑战的年轻人来说，游戏可能成为他们寻求安慰和放松的一种途径。\n游戏通常设计得让玩家在完成任务、提升等级或击败对手时获得成就感和认可。年轻人可能会沉迷于游戏中，因为他们在游戏中能够获得一种被赞赏和认可的感觉，这种感觉在他们现实生活中可能较为缺乏\n年龄增加以后不喜欢玩了 年轻时，个人面临的社会责任和压力相对较小，有更多时间和精力投入到游戏中。随着步入职场、成立家庭等社会责任的增加，时间和精力变得更加宝贵，游戏可能被视为一种时间消耗，而不是优先选择的休闲方式。\n随着年龄的增长，人们的认知能力和兴趣点也会发生变化。年轻时可能对动作快速、画面华丽的游戏感兴趣，而随着阅历的增加，可能更偏好策略性、故事性强或者有深度的游戏。如果市场上的游戏不能满足这些变化的需求，兴趣自然会减少。\n","date":"2024-03-30T15:07:45+08:00","permalink":"https://ttf248.life/p/games-multidimensionality-psychological-development-social-entertainment/","title":"游戏的多维：心理发展与社交娱乐的交汇点"},{"content":"人民币汇率的异动和大盘下跌可能与全球央行的动态、瑞士央行的意外降息、美国经济数据的表现以及市场对通胀和降息预期的调整有关。这些因素共同作用于外汇市场和股市，导致了人民币汇率的波动和A股市场的下跌。\n根据您提供的链接内容，2024年3月22日，人民币汇率出现了显著的波动。以下是详细情况：\n美元兑离岸人民币汇率突破：当日开盘时，人民币走弱，美元兑离岸人民币盘中升破7.24至7.24926，美元兑在岸人民币盘中升破7.22至7.22360，双双突破2023年11月17日以来的新高。截至财联社记者发稿时，美元兑离岸人民币突破了7.26关口，最低报7.2639，且趋势未止。\n央行中间价调整：3月22日，央行公布人民币对美元中间价报7.1004，调贬62个基点，调整幅度有所扩大。\nA股市场反应：受多种因素影响，当日A股三大指数低开低走，跌幅均超过1%。\n外汇市场波动原因：香港一投资机构资深外汇交易员表示，外汇市场波动主要是因为瑞士央行意外降息提振了美元，加上美国经济强劲、通胀粘性可能推迟降息，导致美元指数上涨。\n全球央行动态：本周是全球市场的“超级央行周”，美国、日本、英国、澳大利亚等多国央行都将在本周公布利率决议。瑞士央行意外宣布降息，成为G10货币央行自疫情爆发以来的首个降息行动，这打破了市场平衡。\n人民币走势预测：光大银行金融市场部研究员周茂华表示，尽管近期人民币有所波动，但整体幅度明显小于美元等主要货币，短期波动不会改变年内人民币稳中趋升的走势。\n","date":"2024-03-23T00:31:13+08:00","permalink":"https://ttf248.life/p/renminbi-exchange-rate-volatility/","title":"人民币汇率出现了显著的波动，突破7.26"},{"content":"在 Python 编程中，字典是一种非常强大的数据结构，它允许我们将键值对关联起来，并以高效的方式查找和操作这些数据。当我们尝试在字典中存储自定义对象时，通常会遇到一个关键概念：Python 中的对象赋值实际上是引用赋值，而非对象本身的深拷贝。这意味着将自定义对象放入字典时，字典中存储的是对该对象的引用，而非对象的一个全新副本。\n存储自定义对象的基本示例 假设我们有一个简单的 Person 类：\nclass Person: def __init__(self, name, age): self.name = name self.age = age # 创建一个 Person 对象 p1 = Person(\u0026quot;Alice\u0026quot;, 30) # 将对象存储到字典中 people_dict = {} people_dict[\u0026quot;alice\u0026quot;] = p1 在这个例子中，people_dict 字典现在包含一个键为 \u0026quot;alice\u0026quot; 的项，其值是对 Person 类型的 p1 对象的引用。如果我们修改 p1 的属性：\np1.age = 31 那么通过字典访问这个对象时，我们会发现其年龄也被更新了：\nprint(people_dict[\u0026quot;alice\u0026quot;].age) # 输出：31 这是因为字典中存储的并不是 Person 对象的独立副本，而是指向同一内存地址的引用。\n深拷贝与浅拷贝的区别 在涉及嵌套数据结构或自定义对象时，这种引用行为可能会导致意外的结果。例如，如果自定义对象中包含可变类型的属性（如列表或另一个自定义对象），直接将这样的对象存入字典并对其进行修改，会影响到通过字典获取的对象。\nclass Address: def __init__(self, street, city): self.street = street self.city = city class Person: def __init__(self, name, age, address): self.name = name self.age = age self.address = address address = Address(\u0026quot;Main St.\u0026quot;, \u0026quot;Springfield\u0026quot;) p1 = Person(\u0026quot;Bob\u0026quot;, 40, address) people_dict[\u0026quot;bob\u0026quot;] = p1 # 修改原始地址对象 address.city = \u0026quot;Shelbyville\u0026quot; # 字典中的人的地址也变了 print(people_dict[\u0026quot;bob\u0026quot;].address.city) # 输出：Shelbyville 解决办法：深拷贝\n为了避免这种共享状态带来的问题，有时我们需要确保字典存储的是对象的一个完整副本，而不是引用。Python 提供了 copy 模块中的 deepcopy 函数来实现这一目标：\nimport copy # 使用深拷贝存储对象 people_dict[\u0026quot;bob_deepcopy\u0026quot;] = copy.deepcopy(p1) # 此时即使修改原始地址对象，深拷贝的对象不会受影响 address.city = \u0026quot;Capital City\u0026quot; print(people_dict[\u0026quot;bob\u0026quot;].address.city) # 输出：Capital City print(people_dict[\u0026quot;bob_deepcopy\u0026quot;].address.city) # 输出：Shelbyville 总之，在 Python 中利用字典存储自定义对象时，务必注意默认情况下存储的是对象引用。对于那些需要保持独立状态的情况，请使用 deepcopy 进行深拷贝，以避免因共享引用而导致的意料之外的数据变化。\n","date":"2024-03-22T01:08:05+08:00","permalink":"https://ttf248.life/p/python-dictionary-custom-objects-reference-vs-deepcopy/","title":"Python 字典存储自定义对象：引用与深拷贝的重要性"},{"content":"315 实际上没有报道鸡骨泥，这个问题本身在混淆央视 3·15 晚会的官方曝光和同期发生的其他食品安全热点事件。\n知乎回答：新闻学 315晚会一共提了九个厂家，里面并没有淀粉肠，而现在搞得那些被提名的大品牌完全没热度，倒是把淀粉肠这种国民级（全国各地小吃街基本都会有并且摊位量应该也是第一）的小吃拉出来说事感觉淀粉肠完全就是被拉出来背锅的，我找了网上的新闻来源就是一个央广网在3.15那天发了个调查火腿肠的新闻，但也只是列出了几家厂家的成分，并且几个厂家也并不是主要生产淀粉肠的厂家，成分上并看不出什么毛病，然后这个b记者通过一个工厂员工说有时候用的是鸡骨泥替代鸡肉也就是听说，然后她就去淘宝问宠物食品店卖鸡骨泥的商家，人能不能吃？，这不是sb问题吗？人家一个宠物食品敢说让你人吃？然后后面就传谣传成淀粉肠里含的都有鸡骨泥，鸡骨泥人不能吃。\n现在搞得估计很多工厂都要关门，全国几十万的小摊贩都面临货砸手里没生意干的地步。\n人间真实 据潇湘晨报17日报道，3月16日，河南三门峡，“淀粉肠塌房”的第二天，有大娘出摊卖淀粉肠，但2小时过去后仍无人问津，最后自己默默把淀粉肠吃了。拍摄者称，他自己平时吃淀粉肠一次能吃四五根，但是得知淀粉肠里面有鸡骨泥后坚决不吃了。当天他好奇被曝光后还会不会有人买淀粉肠，结果看到摊贩2小时没卖出一根。\n阿姨哪里知道什么淀粉肠事件，她只知道今天突然没人买她的烤肠了。 大娘没错，她只是为了养家糊口，大娘甚至都不知道产品有没有问题、是不是合格，也不知道什么是骨泥，她们不知道网络，只是作为底层的人想办法活着。 淀粉肠是塌方了，但是为此买单的是一个个底层营业者。这是一个痛苦的过程。 知乎回答：监管不利 几年前的一个下午，我和一位北漂同事去吃午饭，路过一个卖烤肠、铁板里脊的小摊。\n我随口说了句：“现在这样的黑科技淀粉肠、里脊肉还有会吃吗？”因为在我的观念里，上一次吃淀粉火腿肠已经是大概十几年前了。\n同事犹豫了下，然后委婉的说：“可能因为你生活在大城市吧。其实在我们家乡那种小地方，榨菜、方便面、火腿肠，就是每天的日常生活。\n“我上学时候，只有考了满分，我爸才会路上让我吃一次烤肠。不是因为不卫生，而是的烤肠毕竟要1.5元，能买2斤青菜了。\n“像是称呼方便面、碳酸饮料、辣条为“垃圾食品”的说法，我是到了北京上学后才听说的。”\n我意识到了自己刚才无心话语中的傲慢，默默不再说话。但这件事给我印象很深。\n实际上，这才是中国大部分百姓的日常。\n他们的生活里，没有高大上的“地中海饮食”、“绿色有机蔬菜”、“非转基因大豆”。他们只关心能否买到一些便宜又好吃的蔬菜、肉类、零食，全家人享受下不多的幸福时刻。\n至于货架上的东西，是什么成分构成的、是不是会毒害他们的健康、有没有什么奇特的化学成分。\n本来就不是他们应该关心和懂的。\n他们就是朴素的相信，如果有问题的东西，应该有人管不会出现在货架上的。\n但看了一场315，大家才发现并不是。\n市场里的电子秤、加油站的汽油泵，会藏着高科技改装主板，需要UP主冒着挨打的风险拍下视频，监管人员才能“恍然大悟”的去查处；\n直播间的梅菜肉、小摊上的淀粉肠，原来用的是烂肉、骨粉，需要央视的记者卧底调查拍下录像，才会有人去核实，调查货源去向；\n电视频道、机场广告里面大肆宣传的“保健酒”，需要有人拍摄了视频揭了所有老底，才会一夜间紧急撤下，消失在市民面前。\n一年一次的315，每次抽奖一样的弄掉五六个卖了许久的产品，足够么？\n那些已经吃过、买过的消费者，又去找谁呢。\n","date":"2024-03-18T00:31:58+08:00","permalink":"https://ttf248.life/p/sausages-and-street-vendors-capital-news-influence/","title":"淀粉肠和路边小摊: 资本的新闻影响力"},{"content":"想要家里的网络快如闪电？关键在于了解网线的选择、光猫和路由器的配置，还有那些不起眼的小细节。这篇博客将带你轻松了解如何用六类网线打造千兆网络，以及如何通过简单的设备检查和配置，确保你的网络速度不受束缚。让我们一起探索，让家里的网速飞起来！\n第一章：深入剖析网络传输介质 当我们谈论实现千兆网络接入时，承载信息高速传输的载体——网线起着至关重要的作用。下面将对五类、六类和七类网线进行详细的解读：\n1. 五类网线（CAT5） 五类网线，也称为CAT5，是较早普及的一种双绞线类型，每对线芯通过精密的螺旋结构设计来减少串扰。它主要适用于10/100Mbps的快速以太网，最大传输频率约100MHz，虽然在过去曾广泛应用，但对于当前追求千兆乃至更高速度的需求而言，五类网线由于物理限制无法满足要求。\n2. 六类网线（CAT6） 随着技术发展，六类网线应运而生。相比五类网线，六类线材采用了更严格的制造标准和更先进的结构设计，显著提高了抗干扰能力和传输效率，可支持高达1Gbps的传输速率，并且在理想条件下，传输距离可以达到100米，这恰好符合千兆网络的接入需求。\n3. 七类网线（CAT7） 七类网线则代表着当前双绞线技术的尖端水准。它不仅在传输速率上有飞跃式提升，理论上可支持最高10Gbps的超高速率，而且在设计上加入了完整的屏蔽系统，包括每个线对之间的屏蔽以及整体外层的屏蔽，从而极大地降低了外部电磁干扰和近端串扰，保障了数据传输的稳定性与准确性。不过，七类网线主要用于未来的万兆以太网或者特定的高要求场景。\n在搭建千兆家庭网络环境中，为了充分释放千兆光纤的潜力，选用六类网线是最为经济且高效的选择。同时，确保所有连接线材的质量合格，并严格按照标准接线方式操作，也是确保网络性能的重要环节。\n第二章：深挖网络中枢设备——光猫、路由器LAN口带宽的影响 光猫及其LAN口带宽的重要性 光猫，全称光纤调制解调器，是家庭宽带接入的核心设备，它的功能在于将光纤中的光信号转化为数字信号，供家庭网络设备使用。对于千兆光纤用户来说，光猫是否支持千兆传输显得尤为重要。如果光猫的WAN口只支持百兆，那么即使入户光纤速率再高，也会因为这个瓶颈而被限制在百兆以内。同样地，光猫的LAN口也需要具备千兆输出能力，否则连接在其上的路由器或其他设备，无法获取到真正的千兆速率。\n路由器LAN口带宽的作用 路由器的LAN口负责将接收到的数据分发到各个终端设备。当路由器的LAN口仅为百兆时，即便其他设备配置再好，也只能实现百兆速率的局域网通信。因此，在构建千兆家庭网络时，确保路由器的WAN口能够接收千兆数据，并且LAN口也能提供千兆级别的数据输出能力，这样才能使家中所有的智能设备享受到高速网络带来的流畅体验。\n此外，需要注意的是，部分老旧或低端路由器可能存在LAN口速率自动协商机制，这意味着即使路由器本身支持千兆，也可能因线路、设备兼容性等原因降级为百兆模式。因此，正确配置路由器参数，启用强制千兆模式，并配合千兆交换机或直连设备，是实现全千兆网络的关键步骤之一。\n在升级为千兆光纤后，务必检查并更换为千兆光猫和千兆路由器，确保所有设备接口均达到千兆级别。\n第三章：潜藏之谜——一根断裂的子线如何影响千兆网络速度 子线故障与网络性能下降 在测速期间网络始终保持连接，没有出现明显的断网状况。由于是新入户部署的宽带，弱电箱里面很杂乱，时不时还在调整光猫的走线，电源接口插排的位置，偶发性出现过测速达到千兆。\n依据前面的资料，我们已经分析排查了网线型号、光猫 lan 口速度，最终发现罪魁祸首竟是网线内部的一根棕色子线断裂。\n断裂的原因：师傅来安装水晶头的时候，这根网线用力稍微猛了一点，导致一根子线断了一半，没有彻底断开，后续重新调整光猫位置的时候，不断的移动位置，导致彻底断裂。\n六类网线八根线的功能解析 六类网线遵循TIA/EIA-568-B标准，包含八根双绞线，颜色编码如下：\n白橙 / 橙 白绿 / 绿 白蓝 / 蓝 白棕 / 棕 在千兆以太网（1000BASE-T）的标准下，这八根线中有四对线同时工作，具体分工如下：\n白橙与橙这对线（1\u0026amp;2），用于发送数据（Tx+/-）； 白绿与绿这对线（3\u0026amp;6），用于接收数据（Rx+/-）； 白蓝与蓝这对线（4\u0026amp;5）以及白棕与棕这对线（7\u0026amp;8），在千兆以太网中原本并非主用，但在某些高级应用（例如，部分PoE供电或未来的技术扩展）中可能会启用。而在传统的百兆网络中，确实只需要使用1、2、3、6这四根线即可。 断裂子线对网络速度的影响 在上述情况下，倘若一根褐色的子线（即棕线或棕白线）断裂，理论上在千兆网络环境下确实会造成速度下降，因为千兆网络需要所有四对线同时进行双向传输以实现满速。但是，由于家庭网络设备往往存在自动协商功能，当检测到线缆出现问题时，会退回到能够正常工作的较低速率模式，也就是百兆模式，这就解释了为何即使有一根子线断裂，网络还能保持连接并工作在百兆速度上。\n简言之，尽管一根棕色子线断裂不影响百兆网络的基本运行，但在千兆网络环境下，它却足以成为限制网络速度的关键因素。直至进行深入诊断和修复，才能真正发挥千兆光纤的全部潜能。这也提醒我们在遇到类似情况时，不应忽视任何潜在的网络基础设施问题，即使是看似不影响基本连接的小故障，也可能成为高速网络体验的隐形障碍。\n","date":"2024-03-18T00:29:02+08:00","permalink":"https://ttf248.life/p/gigabit-fiber-slow-speed/","title":"新安装的千兆入户光纤，为何测速仅达百兆？"},{"content":"在开发桌面应用程序时，特别是在使用Windows Presentation Foundation (WPF)框架构建富客户端应用时，正确处理用户界面（UI）线程对于保证应用的流畅性和响应性至关重要。UI线程，又称为主线程，是负责处理窗口和控件事件、布局计算以及绘制界面的核心线程。任何与UI元素交互的操作都应当在UI线程上执行，这是WPF以及其他大多数GUI框架遵循的基本原则。\n什么是UI线程？ UI线程在WPF应用启动时由操作系统创建，并初始化应用程序主窗口。它是应用程序中唯一能够直接访问和修改UI组件的状态的线程。这意味着诸如按钮点击、文本框输入、窗口尺寸变化等所有用户交互产生的事件都在这个线程上下文中处理。同时，WPF的依赖属性系统、数据绑定机制以及布局逻辑也都在UI线程上同步执行。\n卡顿现象及其原因 当UI线程被长时间占用或阻塞时，例如执行耗时的计算、大量数据加载、数据库查询或其他I/O密集型任务时，会导致UI线程无法及时响应用户的交互请求，进而表现为界面无响应（Freeze），也就是我们常说的“卡顿”。这种情况下，用户会明显感觉到应用的延迟和不流畅，严重时甚至会出现“Application Not Responding”（ANR）警告。\nUI线程的两条基本规则 为了避免上述情况的发生，WPF开发者应遵循以下两条关键规则：\n不要在UI线程上执行耗时操作：任何可能导致UI线程挂起的操作都应尽可能地移至后台线程执行，以确保UI线程能及时响应用户的输入和渲染屏幕的变化。 不要在非UI线程直接更新UI元素：由于WPF的安全机制设计，只有UI线程有权对UI元素进行修改。试图从其他线程直接更改UI状态将会抛出异常。因此，即使在后台线程完成了计算或数据准备，也需要通过适当的跨线程通信机制将结果显示到UI上。 解决方案：异步编程与线程安全更新 为了在保持UI流畅的同时又能执行耗时任务，WPF提供了多种异步编程模型和工具来协助开发者实现这一目标：\nDispatcher对象：WPF的Dispatcher类允许你将工作项安排到UI线程的任务队列中执行。你可以使用Dispatcher.Invoke或Dispatcher.BeginInvoke方法从后台线程安全地更新UI。 async/await关键字：利用C#语言的异步特性，可以编写异步方法并在其中使用await关键字等待后台任务完成，完成后自动回到UI线程执行后续的UI更新代码。 案例 使用Dispatcher.Invoke方法更新UI private void Button_Click(object sender, RoutedEventArgs e) { // 假设这是一个耗时操作 Task.Run(() =\u0026gt; { var result = LongRunningOperation(); // 这里是模拟一个耗时计算的方法 // 当耗时操作完成后，在UI线程上更新UI Application.Current.Dispatcher.Invoke(() =\u0026gt; { LabelStatus.Text = $\u0026quot;计算结果: {result}\u0026quot;; }); }); } private string LongRunningOperation() { // 模拟耗时操作 Thread.Sleep(5000); return \u0026quot;已完成\u0026quot;; } 使用async/await关键字配合Task.Run private async void Button_ClickAsync(object sender, RoutedEventArgs e) { Button button = sender as Button; button.IsEnabled = false; // 防止用户重复点击 try { // 开启后台任务 var result = await Task.Run(() =\u0026gt; LongRunningOperation()); // 在后台任务完成后，自动切换回UI线程更新UI LabelStatus.Text = $\u0026quot;计算结果: {result}\u0026quot;; } catch (Exception ex) { MessageBox.Show($\u0026quot;发生错误: {ex.Message}\u0026quot;); } finally { button.IsEnabled = true; // 重新启用按钮 } } ","date":"2024-03-12T07:12:21+08:00","permalink":"https://ttf248.life/p/wpf-ui-thread-and-freezing-solutions/","title":"WPF中的UI线程与卡顿问题及其解决方案"},{"content":"在同一段业务代码的情况下，程序在 CentOS 7 环境下编译并运行正常，但当切换到 CentOS 8 并使用更新版的 GCC 进行编译时，程序却发生了崩溃。值得注意的是，问题只在 Release 模式下出现，Debug 模式则完全没有问题。这是我们第一次遇到类似的情况，经过三天的排查，最终找到了问题的根源。\n问题定位 通过一番排查，问题的症结在于 函数缺少返回值。在 Release 模式下，GCC 新版本会进行更多的优化，这导致了原本没有显式返回值的函数在执行过程中出现了未知的逻辑，从而引发了崩溃。我们的结论是，编译器的警告不容忽视，尤其是在老项目中，部分警告可能被无视，但也应当避免屏蔽所有警告。\n环境说明 CentOS 7 GCC版本：\ngcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39) Copyright © 2015 Free Software Foundation, Inc. CentOS 8 GCC版本：\ngcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-21) Copyright (C) 2018 Free Software Foundation, Inc. 崩溃现象 我们在分析程序崩溃的堆栈时，看到的堆栈信息如下：\n[New LWP 1385902] [Thread debugging using libthread_db enabled] Using host libthread_db library \u0026quot;/lib64/libthread_db.so.1\u0026quot;. Core was generated by `./pstack_main`. Program terminated with signal SIGSEGV, Segmentation fault. #0 0x00007ffe894b4420 in ?? () (gdb) bt #0 0x00007ffe894b4420 in ?? () #1 0x00000000004008e9 in main () 这个堆栈看上去并不直观，崩溃函数的栈信息居然显示为一个 ??，这让问题的排查变得更加复杂。\n代码示例 为了更好地理解问题，下面是重现崩溃的最小代码示例：\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;map\u0026gt; int test() { std::cout \u0026lt;\u0026lt; \u0026quot;1\u0026quot; \u0026lt;\u0026lt; std::endl; } int main() { test(); return 0; } 该代码中的 test() 函数显然没有显式返回一个值，而它的返回类型是 int。根据 C++ 规范，当一个函数声明为 int 类型时，必须有一个返回值，否则就可能导致未定义行为。\n编译警告 在我们的项目中，CMake 脚本屏蔽了许多编译时警告，其中就包括了以下警告信息：\n/root/pstack/main.cpp: In function ‘int test()’: /root/pstack/main.cpp:7:1: warning: no return statement in function returning non-void [-Wreturn-type] 这一警告表明 test() 函数没有返回值，而这正是问题的根源。高版本的 GCC（如 8.5.0）在优化代码时可能会对这种未定义的行为做出不稳定的优化，从而导致程序崩溃。\n汇编代码差异 为了解释 GCC 编译器优化行为的差异，我们对比了不同版本 GCC 生成的汇编代码：\nGCC 4.8.5 生成的汇编代码：\n汇编代码较为冗长，且包含了对标准输出流（如 std::cout）的处理逻辑。这表明编译器进行了更保守的优化，未对 test() 函数中缺失返回值的问题做过多优化，可能因此避免了崩溃。\nGCC 8.5.0 生成的汇编代码：\n新版本的 GCC 进行了更多的优化，减少了代码量。然而，这种优化可能使得缺少返回值的函数执行时行为不确定，从而导致程序崩溃。\n结论 通过这次问题排查，我们深刻认识到，在 C++ 中，函数返回值必须明确，特别是在函数声明为 int 时，必须提供一个返回值。对于使用较旧版本编译器的项目，升级到新版本的 GCC 时，可能会遇到更多的优化和更严格的警告机制。因此，我们建议在编译时 不要屏蔽所有警告，而是应该有选择性地处理它们，尤其是函数返回值、类型匹配等常见问题。\n最终，通过为 test() 函数添加一个返回值，问题得以解决，程序恢复了正常的运行。\n","date":"2024-03-10T23:19:06+08:00","permalink":"https://ttf248.life/p/gcc-upgrade-causes-program-crash-code-irregularities/","title":"升级GCC版本导致程序崩溃：代码不规范的隐患"},{"content":"背景：本地机器部署 windows 版本的业务系统，cpu 资源占用 5% 左右。vmware安装的 centos8 中部署 linux 版本业务系统，资源占用异常。\n问题描述 宿主机：win10 企业版 vmware：17.5 虚拟机：centos8 虚拟机资源分配为4C8GB，启动业务系统。业务系统部署在虚拟机Linux系统中，虚拟机内部 top 命令观察系统资源占用，cpu 占用并不高，外层 windows 系统，任务管理器观察到的CPU资源占用很高，查看进程发现，vmware 进程占用CPU资源很高。\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;+ | Windows | | | | +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+ | | | VMware | | | | Program | | | +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+ | | | +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;+\n知识点 此问题的排查，并不顺利，由于导火索并不是业务系统本身，而是虚拟机本身的问题。如何将思路从常规的业务代码转移到系统负载，再从负载数据的异常，定位到软中断，最后来到关键点，什么东西会影响 Vmware 软中断的工作效率？本文将先科普各个知识点，最后给出解决方案。\nhyper-v Windows操作系统的虚拟化技术经历了一次重大变革。在微软首次发布WSL时，启用Hyper-V服务会导致无法同时使用VMware虚拟机。直到后续版本，VMware才能与Hyper-V服务兼容。\n系统负载 在Linux系统中，\u0026ldquo;负载\u0026rdquo;（load）是指系统中正在运行或等待执行的进程的数量。负载通常由三个数字表示，分别是1分钟、5分钟和15分钟内运行队列中的平均进程数量。这些数字可以通过运行\u0026quot;uptime\u0026quot;命令或\u0026quot;top\u0026quot;命令来查看。\n具体来说，这三个数字分别代表：\n1分钟负载：系统在过去1分钟内运行队列中的平均进程数量。 5分钟负载：系统在过去5分钟内运行队列中的平均进程数量。 15分钟负载：系统在过去15分钟内运行队列中的平均进程数量。 负载的含义是在系统中等待运行的进程数。如果这个数字高于系统的逻辑CPU数量，表明系统负载很高，意味着有许多进程正在等待处理器资源。这可能会导致系统变得缓慢或不响应，具体取决于负载的高低程度以及系统的配置和性能。\n在理想情况下，负载应该保持在系统的逻辑CPU数量范围内，这样系统的性能就能够得到最优化。如果负载持续高于CPU数量，可能需要进一步分析系统中的进程，找出导致负载高的原因，并采取相应的措施来调整系统资源分配或优化进程的运行方式。\n分析负载 mpstat mpstat 命令用于报告单个或多个处理器的多个信息，包括平均负载、CPU利用率、中断和上下文切换等。在 sysstat 包中，mpstat 是非常有用的工具，可以用来分析系统的负载情况。下面是使用 mpstat 进行负载分析的步骤：\n安装 sysstat： 如果您的系统上没有安装 sysstat，可以使用适合您系统的包管理工具进行安装。\n运行 mpstat： 使用 mpstat 命令查看 CPU 的使用情况和负载。默认情况下，mpstat 每秒钟显示一次 CPU 使用情况的平均值。您可以通过指定时间间隔来调整输出频率。例如，要以每秒钟一次的频率运行 mpstat，可以使用以下命令：mpstat -P ALL 2，irq 表示占用资源占用\n01:32:33 PM CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 01:32:35 PM all 0.00 0.00 0.26 0.00 3.73 0.26 0.00 0.00 0.00 95.76 01:32:35 PM 0 0.00 0.00 0.51 0.00 3.57 0.00 0.00 0.00 0.00 95.92 01:32:35 PM 1 0.00 0.00 0.00 0.00 3.59 0.51 0.00 0.00 0.00 95.90 01:32:35 PM 2 0.00 0.00 0.00 0.00 4.15 0.00 0.00 0.00 0.00 95.85 01:32:35 PM 3 0.00 0.00 0.52 0.00 3.61 0.52 0.00 0.00 0.00 95.36 分析输出： mpstat 的输出包括了每个 CPU 的利用率，以及系统的平均负载。特别关注平均负载以及每个 CPU 的利用率，可以帮助您了解系统的负载情况。如果负载较高，可以进一步分析是哪些进程导致的，以及是否存在性能瓶颈。\n结合其他工具： 除了 mpstat，还可以使用 sar、pidstat、iostat 等工具来综合分析系统性能。通过结合多种工具的输出，可以更全面地了解系统的负载情况，并找出性能问题的根源。\n中断 此处不展开讲解内容太多， 推荐: 《面向应用开发者的系统指南》CPU篇之软中断\n频繁的触发软中断，也会体现在系统负载中。\n问题排查 考虑到仅从CPU角度分析无法定位问题，我们是否应该开始怀疑系统是否出现了异常？可能是Linux操作系统的负载过高，导致VMware占用了过多的CPU资源。通过使用mpstat分析本地虚拟机，我们发现irq占用异常，单核接近25%，而在正常情况下，启动业务进程空跑时，irq占比应该约为5%。\n在组内同事的开发环境中，他的CentOS 7部署在VMware上，资源占用显示正常。另一方面，在上海的开发环境中，虽然也是VMware，但我们无法直接观察宿主机的CPU资源情况。这时，我们面临着多个变量：VMware虚拟机、Linux操作系统和GCC版本。\n转而分析测试环境，深圳的测试环境部署在物理机上，运行着低版本GCC编译的服务，而且在CentOS 8上运行。有趣的是，在深圳环境中，irq占用都是正常的。\n为了排查GCC版本引入的问题，我们将使用高版本GCC编译的程序部署到深圳环境进行测试，结果显示也都是正常的。\n问题似乎变得更加明朗，我们开始怀疑操作系统是否存在问题。毕竟，CentOS 8已经不再受到官方支持。但即便重新部署了纯净的CentOS 7和CentOS 8，问题依然存在。\n此时，我们开始怀疑唯一的不确定因素，即VMware虚拟机软件。突然间，灵光一现，我们想到了Hyper-V技术。是否之前启用了Hyper-V，但没有彻底关闭，从而导致了这个问题？毕竟，软中断也是通过虚拟机软件来实现的。不同的虚拟机虚拟技术是否存在BUG？这些问题值得深入思考和调查。\n结论 根据微软官方的手册，我们完全关闭了本机的Hyper-V服务后，发现VMware在宿主机上恢复了正常。至此，问题终于迎刃而解。正如一开始所述，这段经历曲折而艰辛，需要综合性的分析和判断。这也是我们首次排查问题，定位到了虚拟机这一层面。\nDisable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V-Hypervisor bcdedit /set hypervisorlaunchtype off https://learn.microsoft.com/zh-cn/troubleshoot/windows-client/application-management/virtualization-apps-not-work-with-hyper-v ","date":"2024-03-10T22:14:59+08:00","permalink":"https://ttf248.life/p/vmware-virtual-machine-cpu-usage-anomaly/","title":"vmware虚拟机cpu资源占用异常"},{"content":"本文旨在揭示在C++编程中不正确使用std::map容器可能导致程序崩溃，通过中括号操作符尝试访问不存在的键时，会自动添加一个空元素。我们将深入剖析这一误解，并通过实例代码展示其潜在风险。\n存储简单值不会有什么问题，但如果存储的是指针，那么就会有问题。因为指针是一个地址，如果没有初始化，那么这个地址是不确定的，这样就会导致程序崩溃。\n正文 在C++标准库中，std::map是一种关联容器，它按照键（key）的升序存储元素，并提供了高效的关键字查找功能。然而，新手开发者有时会因为对std::map中括号操作符 [] 的行为理解有误而陷入困境。实际上，当使用 [] 访问一个不存在的键时，std::map 会插入一个新的键值对，且默认构造函数将会用来初始化该键对应的值类型。\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;map\u0026gt; int main() { std::map\u0026lt;std::string, int\u0026gt; myMap; // 错误的用法：假设这里试图访问一个不存在的键并认为会得到0 std::cout \u0026lt;\u0026lt; \u0026quot;Value for 'nonexistent_key': \u0026quot; \u0026lt;\u0026lt; myMap[\u0026quot;nonexistent_key\u0026quot;] \u0026lt;\u0026lt; std::endl; // 实际上，上述行代码创建了一个新的键值对，其中值被默认初始化为int的默认值（通常是0） return 0; } 以上代码虽然没有直接导致程序崩溃，但这种隐式的插入行为在某些情况下可能导致意料之外的副作用，例如资源泄漏或不符合预期的状态变更。更糟糕的是，在多线程环境下并发访问未初始化的内存区域，甚至可能导致程序崩溃。\n为了防止此类问题，推荐使用 std::map::find() 或 std::map::count() 方法来检查键是否存在，或者利用 std::map::insert() 明确地插入元素：\nstd::map\u0026lt;std::string, int\u0026gt; safeMap; if (safeMap.count(\u0026quot;nonexistent_key\u0026quot;) == 0) { std::cout \u0026lt;\u0026lt; \u0026quot;Key does not exist.\u0026quot; \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026quot;Value for existing key: \u0026quot; \u0026lt;\u0026lt; safeMap[\u0026quot;nonexistent_key\u0026quot;] \u0026lt;\u0026lt; std::endl; } // 或者明确插入一个键值对，指定初始值 safeMap.insert({ \u0026quot;new_key\u0026quot;, 0 }); 如果 map 容器内部保存的对象为指针类型，自动插入元素的行为将保存一个未初始化的指针，调用到此指针的任何操作都将导致程序崩溃。\n","date":"2024-03-10T22:03:06+08:00","permalink":"https://ttf248.life/p/cpp-programming-traps-std-map-crash-details/","title":"C++编程中的陷阱：错误使用`std::map`导致程序崩溃详解"},{"content":"在软件开发和运维中，经常会遇到进程假死的情况，这种情况会导致系统性能下降或者服务不可用。本文介绍如何使用 pstack 工具来排查进程假死问题，通过分析进程的堆栈信息，找出问题的原因并解决。\n背景：风控系统子服务出现假死，导致风控服务不可用。由于缺乏服务可用性监控，无法及时发现进程假死的情况，导致系统不可用。\n正文 进程假死是指进程停止响应，但并没有退出的状态。这种情况可能由于多种原因引起，比如死锁、资源耗尽、异常等。为了解决这类问题，我们可以使用 pstack 工具来分析进程的堆栈信息，找出问题的根源。\n步骤 pstack 是一个常用的工具，通常随着 gdb（GNU 调试器）一起提供。你可以通过以下命令安装它：\nsudo apt-get install gdb 获取进程ID：首先，我们需要获取假死进程的进程ID（PID）。可以使用 ps 命令来列出所有进程，并找到需要排查的进程ID。 使用 pstack 工具分析进程堆栈，一旦获取到进程ID，就可以使用 pstack 工具来获取该进程的堆栈信息。运行以下命令：\npstack \u0026lt;PID\u0026gt; 这将输出该进程的堆栈信息，显示出当前正在执行的函数调用序列。通过分析这些信息，可以发现进程停滞的位置，进而定位问题。\n分析堆栈信息，通过查看堆栈信息，可以找到导致进程假死的原因。可能会发现一些死锁情况、无限循环或者其他异常情况。根据具体情况采取相应的措施，比如释放锁、修复代码逻辑等。\n案例 简单 demo，main 函数启动以后，新建子线程，实际执行函数进入死循环，导致程序无法正常结束，陷入假死的状态。\ncmake_minimum_required(VERSION 3.0.0) project(pstack_main VERSION 0.1.0 LANGUAGES C CXX) include(CTest) enable_testing() # 查找线程库 find_package(Threads REQUIRED) add_executable(pstack_main main.cpp) # 链接线程库 target_link_libraries(pstack_main PRIVATE Threads::Threads) set(CPACK_PROJECT_NAME ${PROJECT_NAME}) set(CPACK_PROJECT_VERSION ${PROJECT_VERSION}) include(CPack) #include \u0026lt;iostream\u0026gt; #include \u0026lt;thread\u0026gt; #include \u0026lt;chrono\u0026gt; void infiniteLoop() { while (true) { // 主线程进入死循环 } } int main() { std::thread thread(infiniteLoop); // 创建一个线程，执行死循环函数 thread.join(); // 等待线程结束 return 0; } 启动程序，执行 pstack 结果：\nThread 2 (Thread 0x7eff3619b700 (LWP 1315017)): #0 infiniteLoop () at /root/pstack/main.cpp:6 #1 0x0000000000402ca9 in std::__invoke_impl\u0026lt;void, void (*)()\u0026gt; (__f=@0x2260eb8: 0x4029a6 \u0026lt;infiniteLoop()\u0026gt;) at /usr/include/c++/8/bits/invoke.h:60 #2 0x0000000000402b02 in std::__invoke\u0026lt;void (*)()\u0026gt; (__fn=@0x2260eb8: 0x4029a6 \u0026lt;infiniteLoop()\u0026gt;) at /usr/include/c++/8/bits/invoke.h:95 #3 0x0000000000403150 in std::thread::_Invoker\u0026lt;std::tuple\u0026lt;void (*)()\u0026gt; \u0026gt;::_M_invoke\u0026lt;0ul\u0026gt; (this=0x2260eb8) at /usr/include/c++/8/thread:244 #4 0x0000000000403126 in std::thread::_Invoker\u0026lt;std::tuple\u0026lt;void (*)()\u0026gt; \u0026gt;::operator() (this=0x2260eb8) at /usr/include/c++/8/thread:253 #5 0x000000000040310a in std::thread::_State_impl\u0026lt;std::thread::_Invoker\u0026lt;std::tuple\u0026lt;void (*)()\u0026gt; \u0026gt; \u0026gt;::_M_run (this=0x2260eb0) at /usr/include/c++/8/thread:196 #6 0x00007eff36bceb23 in execute_native_thread_routine () from /lib64/libstdc++.so.6 #7 0x00007eff36ea91ca in start_thread () from /lib64/libpthread.so.0 #8 0x00007eff361d58d3 in clone () from /lib64/libc.so.6 Thread 1 (Thread 0x7eff372e1740 (LWP 1315016)): #0 0x00007eff36eaa6cd in __pthread_timedjoin_ex () from /lib64/libpthread.so.0 #1 0x00007eff36bceda7 in std::thread::join() () from /lib64/libstdc++.so.6 #2 0x00000000004029d2 in main () at /root/pstack/main.cpp:13 可以看到，进程假死的原因是死循环，主线程进入死循环，子线程无法退出，导致进程假死。\n","date":"2024-02-24T23:55:59+08:00","permalink":"https://ttf248.life/p/pstack-troubleshooting-process-hangs/","title":"pstack排查进程假死"},{"content":"如果说当年按照家里的规划，老老实实读电网，没有出来写代码，我可能会是一个标准的乖乖男。\n扫去记忆里的灰尘，起因还是临近春节，和室友的一次聊天，顺带梳理了一波这些年的历程。\n章节一 高考的成绩不能说好，也不能说差，混了一个211毕业了，按照老爸最初的规划，我应该好好读电网，然后回到老家市区的供电局工作。前面也有稿子提到过，怎么一步步走上IT这条路，有一点里面忘记提了：金钱观、自控力。\n初一还在村镇的学校，初二家里就安排转学到了市区，如同刘姥姥到了大观园，多少有些没有适应市区的繁华，小时候没有去过几次电影院，确切的说，没有和爸妈一起去过几次电影院，倒是家里的亲戚带我去过。上天总会给你留下幸运，那会认识了几个臭味相投哥们，虽说后面联系少了，那段少年的时光现在来看也是美好的。在周末补习以后，一起收拾教室里面的塑料瓶，能够熟练的一脚踩扁然后装进书包，带回去找我妈存着，积攒的差不多了，找个收废品的处理掉。一起下象棋、打羽毛球、玩斗地主，输了的惩罚做几个俯卧撑，那会还有点小庆幸，老爸从小就带着我做各种运动。从这会开始，，金钱观稍微有点不对，稍微有点自卑，但是这些小不幸都是一闪而过，家里也不是说揭不开锅，确实没有多少零花钱，和周围的同学有时候玩不到一起，特别是周末，父母的努力是肉眼能看到的，我们从村里搬出来，到了市区。此时种子已经埋下，静待发芽。\n头脑简单的我，读书期间总体是非常快乐的，就如很多人毕业后才能体会到的，读书其实不算一件难事，投入和产出转化起来比较容易。\n叠加小时候帝国时代的记忆，到了大学期间，触碰到了笔记本电脑，如同潘多拉的魔盒打开，接触到了游戏，也和游戏商人这个角色产生了联系。最初的时候，我就是一个底层的销售人员，从上游进货，然后靠着自己社群的渠道，慢慢销售手里的货物，赚点小钱，到了后面，逐步明白整个链路的运转逻辑。我们销售的货物，不过是上游程序批量孵化的，他们的成本趋近于零。此时，路已经开始有点歪了，专业里面还有细分的专业，左边是电网，右边是自动化（很杂、芯片编程、工厂电气自动化），我明白程序能赚钱，还不是小钱，渠道上游确实赚了很多，加上以前有着编程的底子，开始东搞、西搞，弄了点小钱，在分专业的时候，自然而然我选择的是自动化。打了大三的专业课，很多我都没去，天天脑子里面就想着写代码搞钱。\n去年的文章里面提过，带着对黑客的美好憧憬接触的编程，非科班的IT凭着仁爱，搞了汇编、渗透、游戏外挂、dll劫持和盗号，熟悉和了解各种黑产、灰产；父母教会了做人，法律还是规劝住了我，路没有彻底走歪。\n前文链接：那时少年\n大学期间也谈过一次恋爱，回过头来看，更多是对于电视剧里面爱情的向往，心智不成熟的我，那会尚且无法明白如何爱一个人，更无法做到：成家立业。\n章节二 时代的洪流中，我是也是幸运的，大学的一通折腾，我当然不可能去考研，毕业就参加了工作，趁着IT的东风，工作也是顺顺当当的。已经是工作的第八个年头，行业的热钱消失，终归开始了落幕，有时候也会怀疑，当初的选择是不是错了，当初听老爸的进入电网也许是个更好的选择。如果是在工作的前面五年，可能还有这样的想法，后面就也就慢慢消失了。校招入了恒生，五年没有更换公司，不论是技术的认知、行业的认识，亦或是自己的能力的认知，都存在一定的缺陷。听从杭州总部的安排，去了深圳分公司，经历了一次职场斗争（事后才梳理清楚脉络，两边都输了，最后的赢家是董事会），抱着对技术的热爱，回到了杭州，带着点年少一点不自知，从杭州撤了，跑到了上海。\n原本计划回杭州安家、落户、买房，利率最高点、房价最高峰，入场就要被套住，家底薄折腾不起，真让我扛着房贷结婚的压力，叠加行业下行，情绪上容易不稳定。\n章节三 出来那么多年，见识了那么多事，自己也蠢过，也浪过，目前尚且安好。经历一些事，经历一些人，总归是慢慢长大了，如果一直在家待着，性格里面的缺陷不知会以何种形式爆发出来。\n","date":"2024-02-08T10:30:43+08:00","permalink":"https://ttf248.life/p/come-out-for-a-walk-is-good/","title":"出来走走总归是好的"},{"content":"设计行情 SDK，针对不同的回调函数实现方式，进行了一次耗时的测试。近期在看 C++ 函数编程，当函数变成了一等公民，在程序内部流转，耗时有什么不同？\n前文链接：编译器、回调函数、性能测试\nleimao 大佬刚好也做了类似的测试，借代码一用。\n正文 执行平台依旧是我们的老朋友，https://wandbox.org/\n#include \u0026lt;cassert\u0026gt; #include \u0026lt;chrono\u0026gt; #include \u0026lt;functional\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; int add_one(int input) { return input + 1; } bool validate_vector_add_one(std::vector\u0026lt;int\u0026gt; const\u0026amp; input_vector, std::vector\u0026lt;int\u0026gt; const\u0026amp; output_vector) { bool is_valid{true}; for (size_t i{0}; i \u0026lt; input_vector.size(); ++i) { if (output_vector.at(i) != input_vector.at(i) + 1) { is_valid = false; break; } } return is_valid; } void reset_vector(std::vector\u0026lt;int\u0026gt;\u0026amp; input_vector) { for (size_t i{0}; i \u0026lt; input_vector.size(); ++i) { input_vector.at(i) = 0; } } template \u0026lt;typename T, typename Func\u0026gt; void unitary_function_pass_by_lambda_function(T\u0026amp; output, T const\u0026amp; input, Func const func) { output = func(input); } template \u0026lt;typename T\u0026gt; void unitary_function_pass_by_std_function_value(T\u0026amp; output, T const\u0026amp; input, std::function\u0026lt;T(T)\u0026gt; const func) { output = func(input); } template \u0026lt;typename T\u0026gt; void unitary_function_pass_by_std_function_reference( T\u0026amp; output, T const\u0026amp; input, std::function\u0026lt;T(T)\u0026gt; const\u0026amp; func) { output = func(input); } template \u0026lt;typename T\u0026gt; void unitary_function_pass_by_function_pointer(T\u0026amp; output, T const\u0026amp; input, T (*func)(T)) { output = func(input); } int main() { // Set floating point format std::cout with 3 decimal places. std::cout.precision(3); size_t const num_elements{10000000}; std::vector\u0026lt;int\u0026gt; input_vector(num_elements, 0); std::vector\u0026lt;int\u0026gt; output_vector(num_elements, 0); auto const lambda_function_add_one{[](int const\u0026amp; input) -\u0026gt; int { return input + 1; }}; std::function\u0026lt;int(int)\u0026gt; const std_function_add_one{lambda_function_add_one}; std::cout \u0026lt;\u0026lt; \u0026quot;The size of a function pointer: \u0026quot; \u0026lt;\u0026lt; sizeof(\u0026amp;add_one) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026quot;The size of a std::function pointer: \u0026quot; \u0026lt;\u0026lt; sizeof(\u0026amp;std_function_add_one) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026quot;The size of a std::function: \u0026quot; \u0026lt;\u0026lt; sizeof(std_function_add_one) \u0026lt;\u0026lt; std::endl; // Call function frequently in a vanilla way. // The compiler knows what function to call at compile time and can optimize // the code. // This is the best performance we could get. std::chrono::steady_clock::time_point const time_start_vanilla{ std::chrono::steady_clock::now()}; for (size_t i{0}; i \u0026lt; num_elements; ++i) { output_vector.at(i) = add_one(input_vector.at(i)); } std::chrono::steady_clock::time_point const time_end_vanilla{ std::chrono::steady_clock::now()}; auto const time_elapsed_vanilla{ std::chrono::duration_cast\u0026lt;std::chrono::nanoseconds\u0026gt;(time_end_vanilla - time_start_vanilla) .count()}; float const latency_vanilla{time_elapsed_vanilla / static_cast\u0026lt;float\u0026gt;(num_elements)}; std::cout \u0026lt;\u0026lt; \u0026quot;Latency Pass Vanilla: \u0026quot; \u0026lt;\u0026lt; latency_vanilla \u0026lt;\u0026lt; \u0026quot; ns\u0026quot; \u0026lt;\u0026lt; std::endl; assert(validate_vector_add_one(input_vector, output_vector)); reset_vector(output_vector); // Sometimes, we don't know what function to call at compile time. // We can use std::function to pass a function as an argument. // In this case, we pass the std::function by value. // Because the size of a std::function is 32 bytes, passing by value // results in a lot of copying and bad performance. std::chrono::steady_clock::time_point const time_start_pass_by_std_function_value{std::chrono::steady_clock::now()}; for (size_t i{0}; i \u0026lt; num_elements; ++i) { unitary_function_pass_by_std_function_value( output_vector.at(i), input_vector.at(i), std_function_add_one); } std::chrono::steady_clock::time_point const time_end_pass_by_std_function_value{std::chrono::steady_clock::now()}; auto const time_elapsed_pass_by_std_function_value{ std::chrono::duration_cast\u0026lt;std::chrono::nanoseconds\u0026gt;( time_end_pass_by_std_function_value - time_start_pass_by_std_function_value) .count()}; float const latency_pass_by_std_function_value{ time_elapsed_pass_by_std_function_value / static_cast\u0026lt;float\u0026gt;(num_elements)}; std::cout \u0026lt;\u0026lt; \u0026quot;Latency Pass By Std Function Value: \u0026quot; \u0026lt;\u0026lt; latency_pass_by_std_function_value \u0026lt;\u0026lt; \u0026quot; ns\u0026quot; \u0026lt;\u0026lt; std::endl; assert(validate_vector_add_one(input_vector, output_vector)); reset_vector(output_vector); // Instead of passing the std::function by value, we can pass it by // reference (pointer). In this case, object copying is eliminated. The // performance is better than passing the std::function by value. However, // the performance is still not as good as the vanilla way. std::chrono::steady_clock::time_point const time_start_pass_by_std_function_reference{ std::chrono::steady_clock::now()}; for (size_t i{0}; i \u0026lt; num_elements; ++i) { unitary_function_pass_by_std_function_reference( output_vector.at(i), input_vector.at(i), std_function_add_one); } std::chrono::steady_clock::time_point const time_end_pass_by_std_function_reference{ std::chrono::steady_clock::now()}; auto const time_elapsed_pass_by_std_function_reference{ std::chrono::duration_cast\u0026lt;std::chrono::nanoseconds\u0026gt;( time_end_pass_by_std_function_reference - time_start_pass_by_std_function_reference) .count()}; float const latency_pass_by_std_function_reference{ time_elapsed_pass_by_std_function_reference / static_cast\u0026lt;float\u0026gt;(num_elements)}; std::cout \u0026lt;\u0026lt; \u0026quot;Latency Pass By Std Function Reference: \u0026quot; \u0026lt;\u0026lt; latency_pass_by_std_function_reference \u0026lt;\u0026lt; \u0026quot; ns\u0026quot; \u0026lt;\u0026lt; std::endl; assert(validate_vector_add_one(input_vector, output_vector)); reset_vector(output_vector); // std::function is a general purpose wrapper for function pointers, // callable objects, and lambda functions. Because it's general purpose, // it's not as efficient as a function pointer. In this case, we pass a // function pointer to a function. The performance is better than passing // the std::function by reference. std::chrono::steady_clock::time_point const time_start_pass_by_function_pointer{std::chrono::steady_clock::now()}; for (size_t i{0}; i \u0026lt; num_elements; ++i) { unitary_function_pass_by_function_pointer(output_vector.at(i), input_vector.at(i), \u0026amp;add_one); } std::chrono::steady_clock::time_point const time_end_pass_by_function_pointer{std::chrono::steady_clock::now()}; auto const time_elapsed_pass_by_function_pointer{ std::chrono::duration_cast\u0026lt;std::chrono::nanoseconds\u0026gt;( time_end_pass_by_function_pointer - time_start_pass_by_function_pointer) .count()}; float const latency_pass_by_function_pointer{ time_elapsed_pass_by_function_pointer / static_cast\u0026lt;float\u0026gt;(num_elements)}; std::cout \u0026lt;\u0026lt; \u0026quot;Latency Pass By Function Pointer: \u0026quot; \u0026lt;\u0026lt; latency_pass_by_function_pointer \u0026lt;\u0026lt; \u0026quot; ns\u0026quot; \u0026lt;\u0026lt; std::endl; assert(validate_vector_add_one(input_vector, output_vector)); reset_vector(output_vector); // We can also pass a lambda function to a function. // The compiler knows what function to call at compile time and can optimize // the code. The performance is also better than passing the std::function // by reference. std::chrono::steady_clock::time_point const time_start_pass_by_lambda_function{std::chrono::steady_clock::now()}; for (size_t i{0}; i \u0026lt; num_elements; ++i) { unitary_function_pass_by_lambda_function( output_vector.at(i), input_vector.at(i), lambda_function_add_one); } std::chrono::steady_clock::time_point const time_end_pass_by_lambda_function{std::chrono::steady_clock::now()}; auto const time_elapsed_pass_by_lambda_function{ std::chrono::duration_cast\u0026lt;std::chrono::nanoseconds\u0026gt;( time_end_pass_by_lambda_function - time_start_pass_by_lambda_function) .count()}; float const latency_pass_by_lambda_function{ time_elapsed_pass_by_lambda_function / static_cast\u0026lt;float\u0026gt;(num_elements)}; std::cout \u0026lt;\u0026lt; \u0026quot;Latency Pass By Lambda Function: \u0026quot; \u0026lt;\u0026lt; latency_pass_by_lambda_function \u0026lt;\u0026lt; \u0026quot; ns\u0026quot; \u0026lt;\u0026lt; std::endl; assert(validate_vector_add_one(input_vector, output_vector)); reset_vector(output_vector); } # 组里常规也就开启 O2 优化，编译选用了 gcc13，不同版本的 gcc 性能耗时略有不同，版本越高 lambda 效果越好 The size of a function pointer: 8 The size of a std::function pointer: 8 The size of a std::function: 32 Latency Pass Vanilla: 0.418 ns Latency Pass By Std Function Value: 3.47 ns Latency Pass By Std Function Reference: 1.36 ns Latency Pass By Function Pointer: 0.396 ns Latency Pass By Lambda Function: 0.44 ns 参考资料 https://leimao.github.io/blog/CPP-Function-Call-Performance/\n","date":"2024-01-24T14:11:33+08:00","permalink":"https://ttf248.life/p/cpp-function-call-timing/","title":"C++函数调用耗时"},{"content":"关于字节序的科普 主机序、网络序，通过调试器，直接观察\n计算机领域历史原因形成的某些设计习惯，跟马屁股宽度决定火箭推进器宽度的道理是一样的，没必要硬去分析里面的“优势”“劣势”，纯粹只是历史习惯。\n原文链接 作者：北极 链接：https://www.zhihu.com/question/637413724/answer/3346032134 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n正文转载 现如今的大小端状况，是历史习惯+商业化的结果，跟技术本身关系不大。ARM 可以设置成大端也可以设置成小端。TCP/IP 头至今仍然是大端（网络字节序）。存储领域也有很多存储协议/规范以大端方式保存数据。\n所以题主的三个问题，在今天看来：\n计算机为什么普遍采用小端存储？\u0026ndash;\u0026gt; 不正确。 为什么低字节存储在低地址的小端方式比大端方式效率更高? \u0026ndash;\u0026gt; 效率并不会更高。 任何以当前技术来论证这三个问题的，都属于先射箭后画靶子的行为。\n但是如果说大端或者小端的选择，在计算机发展历史上，确实是有一定客观因素的：主机字节序（小端）的优势：小端的加法器比较好做，如果做一个8位*4的加法器，只需要一个8位加法器，然后依次从低到高循环加上所有字节就可以了，进位的电路非常简单，而如果是大端，则需要一次加载32位，否则无法进行计算。现在来看，一次加载8位还是32位，区别不大，但是在几十年前，存储器的价格昂贵，自然是越简单越好，所以主机字节序选择小端是基于成本的考虑。网络字节序（大端）的优势：早年设备的缓存很小，先接收高字节能快速的判断报文信息：包长度（需要准备多大缓存）、地址范围（IP地址是从前到后匹配的）。早年的网络设备的缓存都是以字节为单位的，先取高字节确实是会更快一些。所以网络设备使用大端，也是基于成本的考虑。\n所以，字节序的选择，在历史上，大多数是应用场景和成本的考虑更多（比如：PPC/MIPS更适合做网络设备），而后来的技术发展过程中，由于兼容性的原因，大小端的配置沿用至今。\n在今天看来，这些优势已经完全不存在了，仅仅只是历史习惯。\n","date":"2024-01-24T10:43:05+08:00","permalink":"https://ttf248.life/p/little-endian-storage-why/","title":"计算机为什么普遍采用小端存储"},{"content":"心血来潮，琢磨找找新壁纸，习惯黑色系列，部分区域彩色即可，桌面需要放置图标，其他色系作壁纸，图标就不清晰了。\n盯着上面的汇编代码思考一波，没看懂，尝试扔给AI，解释了指令，没有解释场景，必然是某个特殊场景用到的指令，常规代码不是这样的。\nAI此时不如搜索引擎了，汇编的知识储备不足。\n壁纸 汇编代码 PUSHFD MOV DWORD PTR [ESP],0X100 POPFD 实际应用场景\nbool IsDebugged() { __try { __asm { pushfd mov dword ptr [esp], 0x100 popfd nop } return true; } __except(GetExceptionCode() == EXCEPTION_SINGLE_STEP ? EXCEPTION_EXECUTE_HANDLER : EXCEPTION_CONTINUE_EXECUTION) { return false; } } 解释说明 TrapFlag是标志寄存器中的一个标志位，当这个标志位被设置时，会抛出异常SINGLE_STEP，因为如果我们跟踪代码，这个标志位会被调试器清零，所以我们看不到这个异常。\n实际测试时发现，如果直接步过检测调试的函数，那么调试不会被检测到，只有步入检测函数执行时才会检测到(资料查询，尚未实际验证)\n参考资料 中文的相关资料，都是基于网站的英文稿子翻译，站点科普了很多种反调试的技术。\nhttps://anti-debug.checkpoint.com/ https://song-10.gitee.io/2021/08/08/Reverse-2021-08-08-anti-debug/ ","date":"2024-01-23T19:46:36+08:00","permalink":"https://ttf248.life/p/program-anti-debug/","title":"程序如何反调试"},{"content":"最近有人咨询，如何下载焦点访谈的视频，脑子里面想着十有八九又是 m3u8 方式加密，洒洒水了，简单处理下。\n下载器 https://github.com/nilaoda/N_m3u8DL-CLI\nm3u8 downloader 开源的命令行m3u8/HLS/dash下载器，支持普通AES-128-CBC解密，多线程，自定义请求头等. 支持简体中文,繁体中文和英文. English Supported.\n浏览器插件 Live Stream Downloader\n蜜汁自信 拿到地址，以为搞定了，结果啥也不是，无法正常解析分段内容，查询资料，发现官方处理了下载地址，需要人工进行一定的替换，将插件解析到的 key 人工复制替换到下面的链接中\nhttps://newcntv.qcloudcdn.com/asp/hls/2000/0303000a/3/default/***********************/2000.m3u8 截止 2024年1月，地址测试有效，后续如有变动，自行分析网页。\n历史地址备份：https://hlswx.cntv.kcdnvip.com/asp/hls/main/0303000a/3/default/一串字符/main.m3u8?maxbr=2000\n参考资料 http://jln.cn/post/517.html\n","date":"2024-01-23T19:23:35+08:00","permalink":"https://ttf248.life/p/how-to-download-focus-interview-cctv-videos/","title":"如何下载焦点访谈/CCTV视频文件"},{"content":"公司安全策略调整，机械师 mini最终还是搬迁回家作为备用服务器，顺带重装机器系统，ubuntu 切换到了windows server，由于激活的手段不正规，自己家里用，好像不激活也没事\n非常规方式激活，触发了微软的检测（正常运行了半个月），服务器开机一小时，自动关机，翻了一圈系统日志，才发现是盗版导致的。\n没辙，再次重装系统，SqlServer也面临重装，每次弄都比较蛋疼，文件权限管控严格，导致无法正常附加数据库。\n报错信息 系统重装以后，SqlServer在附加数据库中可能会出现5120，操作系统错误拒绝访问。\n处理脚本 前文链接：批量更新本地Git仓库，没错又是这个熟悉的脚本，改造一下，我们遍历文件夹的同时修改文件的权限，当前用于拥有完全编辑的权限。\n网上的教程大部分都是让你手动修改，他们每次只需要修改几个文件吗？我每次都需要处理一批文件，全部手动处理，人会自闭的。\n$currentUserName = [System.Security.Principal.WindowsIdentity]::GetCurrent().Name [Console]::OutputEncoding = [System.Text.Encoding]::UTF8 $rootDirectory = \u0026quot;D:\\data\\2013_RujiaInfo\u0026quot; Get-ChildItem -Path $rootDirectory -Recurse | ForEach-Object { $itemPath = $_.FullName if ($_ -is [System.IO.DirectoryInfo]) { $icaclsResult = icacls $itemPath /setowner \u0026quot;$currentUserName\u0026quot; 2\u0026gt;\u0026amp;1 if ($LASTEXITCODE -eq 0) { Write-Host \u0026quot;已更改文件夹 $itemPath 的所有者为 $currentUserName\u0026quot; # 授予当前用户写入权限 Invoke-Expression \u0026quot;icacls `\u0026quot;$itemPath`\u0026quot; /grant `\u0026quot;$($currentUserName):(OI)(CI)F`\u0026quot;\u0026quot; Write-Host \u0026quot;已授予 $currentUserName 编辑文件夹的权限\u0026quot; } else { Write-Host \u0026quot;无法更改文件夹 $itemPath 的所有者。错误信息: $icaclsResult\u0026quot; } } else { $takeownResult = icacls $itemPath /setowner \u0026quot;$currentUserName\u0026quot; 2\u0026gt;\u0026amp;1 if ($LASTEXITCODE -eq 0) { # 授予当前用户写入权限 Invoke-Expression \u0026quot;icacls `\u0026quot;$itemPath`\u0026quot; /grant `\u0026quot;$($currentUserName):(F)`\u0026quot;\u0026quot; Write-Host \u0026quot;已授予 $currentUserName 编辑文件的权限\u0026quot; } else { Write-Host \u0026quot;无法更改文件 $itemPath 的所有者。错误信息: $takeownResult\u0026quot; } } } ","date":"2024-01-23T19:06:36+08:00","permalink":"https://ttf248.life/p/bulk-modify-sqlserver-database-disk-permissions/","title":"批量修改SqlServer数据库磁盘文件权限"},{"content":"Windows 平台有个鲁大师（娱乐大师），不能说数据很准，单总归有个参考，当然也有其他的专业跑分软件，到了 Linux 系统，好像一直没遇到特别合适的跑分软件。\nSysbench 是一款多功能的基准测试工具，可用于测试CPU、内存、文件I/O、线程性能等。您可以使用 sysbench 来执行各种性能测试任务。\n手头上刚好有三台机器用于测试：机械师 mini 本地小主机、阿里云 dev 开发云服务器、华为云开发服务器。\n安装Sysbench 在大多数Linux发行版中，您可以使用包管理工具来安装Sysbench。例如，在CentOS 8上，可以使用以下命令进行安装\nsudo dnf install sysbench Sysbench的使用示例 测试CPU性能：sysbench --test=cpu run 测试内存读取性能：sysbench --test=memory run 测试文件I/O性能： sysbench --test=fileio --file-test-mode=rndrw prepare sysbench --test=fileio --file-test-mode=rndrw run sysbench --test=fileio --file-test-mode=rndrw cleanup 测试多线程性能: sysbench --test=threads --num-threads=4 run 测试MySQL数据库性能（需调整数据库最大连接数）： sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword --oltp-table-size=1000000 prepare sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword --max-time=60 --oltp-read-only=off --oltp-test-mode=complex --max-requests=0 run sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword cleanup 跑分数据报告 ABCD1本地机械师阿里云华为云2系统配置System Information\nOperating System Ubuntu 23.04\nKernel Linux 6.2.0-36-generic x86_64\nModel Machenike Machenike DT Computer\nMotherboard Machenike Machenike DT Computer\nBIOS American Megatrends International, LLC.\nDB19V012\nCPU Information\nName Intel Core i7-12650H\nTopology 1 Processor, 10 Cores, 16 Threads\nIdentifier GenuineIntel Family 6 Model 154 Stepping 3\nBase Frequency 4.60 GHz\nL1 Instruction Cache 32.0 KB x 8\nL1 Data Cache 48.0 KB x 8\nL2 Cache 1.25 MB x 2\nL3 Cache 24.0 MB\nMemory Information\nSize 62.6 GBSystem Information\nOperating System CentOS Stream 8\nKernel Linux 4.18.0-513.el8.x86_64 x86_64\nModel Alibaba Cloud Alibaba Cloud ECS\nMotherboard N/A\nBIOS SeaBIOS 449e491\nCPU Information\nName Intel(R) Xeon(R) Platinum\nTopology 1 Processor, 1 Core, 2 Threads\nIdentifier GenuineIntel Family 6 Model 85 Stepping 4\nBase Frequency 2.50 GHz\nL1 Instruction Cache 32.0 KB\nL1 Data Cache 32.0 KB\nL2 Cache 1.00 MB\nL3 Cache 33.0 MB\nMemory Information\nSize 1.65 GBSystem Information\nOperating System Ubuntu 22.04.1 LTS\nKernel Linux 5.15.0-60-generic x86_64\nModel OpenStack Foundation OpenStack Nova\nMotherboard N/A\nBIOS SeaBIOS\nrel-1.10.2-0-g5f4c7b1-20181220_000000-szxrtosci10000\nCPU Information\nName Intel(R) Xeon(R) Gold 6278C CPU @ 2.60GHz\nTopology 1 Processor, 1 Core, 2 Threads\nIdentifier GenuineIntel Family 6 Model 85 Stepping 7\nBase Frequency 2.60 GHz\nL1 Instruction Cache 32.0 KB\nL1 Data Cache 32.0 KB\nL2 Cache 1.00 MB\nL3 Cache 35.8 MB\nMemory Information\nSize 3.64 GB3CPUsysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)\nRunning the test with following options:\nNumber of threads: 1\nInitializing random number generator from current time\nPrime numbers limit: 10000\nInitializing worker threads...\nThreads started!\nCPU speed:\nevents per second: 4032.48\nGeneral statistics:\ntotal time: 10.0004s\ntotal number of events: 40330\nLatency (ms):\nmin: 0.25\navg: 0.25\nmax: 0.73\n95th percentile: 0.25\nsum: 9997.55\nThreads fairness:\nevents (avg/stddev): 40330.0000/0.00\nexecution time (avg/stddev): 9.9975/0.00sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)\nRunning the test with following options:\nNumber of threads: 1\nInitializing random number generator from current time\nPrime numbers limit: 10000\nInitializing worker threads...\nThreads started!\nCPU speed:\nevents per second: 1062.51\nGeneral statistics:\ntotal time: 10.0008s\ntotal number of events: 10628\nLatency (ms):\nmin: 0.91\navg: 0.94\nmax: 22.84\n95th percentile: 1.06\nsum: 9993.46\nThreads fairness:\nevents (avg/stddev): 10628.0000/0.00\nexecution time (avg/stddev): 9.9935/0.00sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)\nRunning the test with following options:\nNumber of threads: 1\nInitializing random number generator from current time\nPrime numbers limit: 10000\nInitializing worker threads...\nThreads started!\nCPU speed:\nevents per second: 1125.56\nGeneral statistics:\ntotal time: 10.0005s\ntotal number of events: 11258\nLatency (ms):\nmin: 0.86\navg: 0.89\nmax: 1.70\n95th percentile: 0.99\nsum: 9995.40\nThreads fairness:\nevents (avg/stddev): 11258.0000/0.00\nexecution time (avg/stddev): 9.9954/0.004内存Running the test with following options:\nNumber of threads: 1\nInitializing random number generator from current time\nRunning memory speed test with the following options:\nblock size: 1KiB\ntotal size: 102400MiB\noperation: write\nscope: global\nInitializing worker threads...\nThreads started!\nTotal operations: 101993199 (10198146.52 per second)\n99602.73 MiB transferred (9959.13 MiB/sec)\nGeneral statistics:\ntotal time: 10.0001s\ntotal number of events: 101993199\nLatency (ms):\nmin: 0.00\navg: 0.00\nmax: 0.03\n95th percentile: 0.00\nsum: 4059.50\nThreads fairness:\nevents (avg/stddev): 101993199.0000/0.00\nexecution time (avg/stddev): 4.0595/0.00Running the test with following options:\nNumber of threads: 1\nInitializing random number generator from current time\nRunning memory speed test with the following options:\nblock size: 1KiB\ntotal size: 102400MiB\noperation: write\nscope: global\nInitializing worker threads...\nThreads started!\nTotal operations: 48418803 (4841004.79 per second)\n47283.99 MiB transferred (4727.54 MiB/sec)\nGeneral statistics:\ntotal time: 10.0001s\ntotal number of events: 48418803\nLatency (ms):\nmin: 0.00\navg: 0.00\nmax: 25.26\n95th percentile: 0.00\nsum: 4578.95\nThreads fairness:\nevents (avg/stddev): 48418803.0000/0.00\nexecution time (avg/stddev): 4.5789/0.00Running the test with following options:\nNumber of threads: 1\nInitializing random number generator from current time\nRunning memory speed test with the following options:\nblock size: 1KiB\ntotal size: 102400MiB\noperation: write\nscope: global\nInitializing worker threads...\nThreads started!\nTotal operations: 57056904 (5704765.11 per second)\n55719.63 MiB transferred (5571.06 MiB/sec)\nGeneral statistics:\ntotal time: 10.0001s\ntotal number of events: 57056904\nLatency (ms):\nmin: 0.00\navg: 0.00\nmax: 0.06\n95th percentile: 0.00\nsum: 4556.06\nThreads fairness:\nevents (avg/stddev): 57056904.0000/0.00\nexecution time (avg/stddev): 4.5561/0.005硬盘2147483648 bytes written in 1.81 seconds (1129.59 MiB/sec).\nRunning the test with following options:\nNumber of threads: 1\nInitializing random number generator from current time\nExtra file open flags: (none)\n128 files, 16MiB each\n2GiB total file size\nBlock size 16KiB\nNumber of IO requests: 0\nRead/Write ratio for combined random IO test: 1.50\nPeriodic FSYNC enabled, calling fsync() each 100 requests.\nCalling fsync() at the end of test, Enabled.\nUsing synchronous I/O mode\nDoing random r/w test\nInitializing worker threads...\nThreads started!\nFile operations:\nreads/s: 3373.41\nwrites/s: 2248.94\nfsyncs/s: 7201.80\nThroughput:\nread, MiB/s: 52.71\nwritten, MiB/s: 35.14\nGeneral statistics:\ntotal time: 10.0127s\ntotal number of events: 128288\nLatency (ms):\nmin: 0.00\navg: 0.08\nmax: 5.14\n95th percentile: 0.34\nsum: 9977.78\nThreads fairness:\nevents (avg/stddev): 128288.0000/0.00\nexecution time (avg/stddev): 9.9778/0.002147483648 bytes written in 19.29 seconds (106.16 MiB/sec).\nRunning the test with following options:\nNumber of threads: 1\nInitializing random number generator from current time\nExtra file open flags: (none)\n128 files, 16MiB each\n2GiB total file size\nBlock size 16KiB\nNumber of IO requests: 0\nRead/Write ratio for combined random IO test: 1.50\nPeriodic FSYNC enabled, calling fsync() each 100 requests.\nCalling fsync() at the end of test, Enabled.\nUsing synchronous I/O mode\nDoing random r/w test\nInitializing worker threads...\nThreads started!\nFile operations:\nreads/s: 1593.12\nwrites/s: 1062.08\nfsyncs/s: 3406.64\nThroughput:\nread, MiB/s: 24.89\nwritten, MiB/s: 16.60\nGeneral statistics:\ntotal time: 10.0164s\ntotal number of events: 60600\nLatency (ms):\nmin: 0.00\navg: 0.16\nmax: 31.32\n95th percentile: 0.54\nsum: 9956.30\nThreads fairness:\nevents (avg/stddev): 60600.0000/0.00\nexecution time (avg/stddev): 9.9563/0.002147483648 bytes written in 18.29 seconds (111.98 MiB/sec).\nRunning the test with following options:\nNumber of threads: 1\nInitializing random number generator from current time\nExtra file open flags: (none)\n128 files, 16MiB each\n2GiB total file size\nBlock size 16KiB\nNumber of IO requests: 0\nRead/Write ratio for combined random IO test: 1.50\nPeriodic FSYNC enabled, calling fsync() each 100 requests.\nCalling fsync() at the end of test, Enabled.\nUsing synchronous I/O mode\nDoing random r/w test\nInitializing worker threads...\nThreads started!\nFile operations:\nreads/s: 1665.88\nwrites/s: 1110.59\nfsyncs/s: 3563.77\nThroughput:\nread, MiB/s: 26.03\nwritten, MiB/s: 17.35\nGeneral statistics:\ntotal time: 10.0112s\ntotal number of events: 63355\nLatency (ms):\nmin: 0.00\navg: 0.16\nmax: 205.01\n95th percentile: 0.78\nsum: 9972.64\nThreads fairness:\nevents (avg/stddev): 63355.0000/0.00\nexecution time (avg/stddev): 9.9726/0.006多线程Running the test with following options:\nNumber of threads: 4\nInitializing random number generator from current time\nInitializing worker threads...\nThreads started!\nGeneral statistics:\ntotal time: 10.0002s\ntotal number of events: 197956\nLatency (ms):\nmin: 0.16\navg: 0.20\nmax: 0.34\n95th percentile: 0.21\nsum: 39970.47\nThreads fairness:\nevents (avg/stddev): 49489.0000/5.70\nexecution time (avg/stddev): 9.9926/0.00Running the test with following options:\nNumber of threads: 4\nInitializing random number generator from current time\nInitializing worker threads...\nThreads started!\nGeneral statistics:\ntotal time: 10.0174s\ntotal number of events: 18360\nLatency (ms):\nmin: 0.57\navg: 2.18\nmax: 32.77\n95th percentile: 2.61\nsum: 40050.41\nThreads fairness:\nevents (avg/stddev): 4590.0000/94.36\nexecution time (avg/stddev): 10.0126/0.00Running the test with following options:\nNumber of threads: 4\nInitializing random number generator from current time\nInitializing worker threads...\nThreads started!\nGeneral statistics:\ntotal time: 10.0004s\ntotal number of events: 28536\nLatency (ms):\nmin: 0.23\navg: 1.40\nmax: 3.56\n95th percentile: 1.47\nsum: 39975.16\nThreads fairness:\nevents (avg/stddev): 7134.0000/39.87\nexecution time (avg/stddev): 9.9938/0.01 后记 ChatGPT 还是个好东西，上面的表格，按照以前掌握的Markdown完全无法编排，不做成表格，展示的效果就会很差，自定义主题限制了页面最大宽度，同步调整了一波页面的配置，宽度改为百分比限制。\n简单的方法，使用TablesGenerator等在线工具生成HTML表格（内容复杂不合适） 或者使用谷歌在线文档编写，然后下载保存为HTML文档，直接复制到博客（简单直接，最终采用） 确保 config 配置开启了 unsafe 配置项，单独给页面配置宽度\n在 Hugo 中，你可以为页面单独设置宽度。这可以通过在页面的 Front Matter 中添加自定义参数来实现。以下是一个示例：\n在你的 Markdown 页面的 Front Matter 部分（通常在文件的开头部分）添加一个自定义参数，例如 custom_width： --- title: \u0026quot;我的页面\u0026quot; date: 2024-01-09 custom_width: \u0026quot;800px\u0026quot; # 设置宽度为 800 像素 --- 正文内容... 在你的 Hugo 主题中，找到或创建对应的单页面模板文件（例如，layouts/_default/single.html）。\n在单页面模板中，检查页面的 Front Matter 中是否有 custom_width 参数，并将其应用到相应的 HTML 元素上，例如 div：\n{{ define \u0026quot;main\u0026quot; }} \u0026lt;div style=\u0026quot;max-width: {{ with .Params.custom_width }}{{ . }}{{ else }}100%{{ end }}; margin: 0 auto;\u0026quot;\u0026gt; {{ .Content }} \u0026lt;/div\u0026gt; {{ end }} 这个示例中，我们使用了内联样式（style属性）为 div 元素设置了 max-width 属性，使其在没有指定 custom_width 参数时，宽度默认为100%。margin: 0 auto; 用于将 div 元素居中。\n请注意，实际应用中，你可能需要根据你的主题结构和CSS样式的细节来调整上述示例。确保在调整样式时保持主题的一致性和可读性。\n由于启用的主题稍微有些不同，最后调整了站点自定义的CSS配置。\n","date":"2024-01-09T10:56:23+08:00","permalink":"https://ttf248.life/p/linux-system-benchmark-test/","title":"Linux系统跑分测试"},{"content":"习惯更新软件版本，不知道从哪个版本的Git开始，禁止从Http仓库拉取代码\nfatal: Unencrypted HTTP is not supported for GitLab. Ensure the repository remote URL is using HTTPS 背景介绍 环境：Windows 平台，一直用的都是小乌龟来操作git，配置秘钥也是通过小乌龟来处理的，之前弄过一次脚本，批量更新本地的仓库\n前文链接：批量更新本地Git仓库\n今天回家执行代码更新的时候，出现了前面的报错，仓库无法正常更新了，本想着Git应该提供了配置，让我继续使用http的协议更新仓库，找了一圈，也没翻到对应的配置项。\n最简单的解决方案当然是切换成ssh协议来更新仓库，公司配置的gitlab短期内不会提供https协议。\n遗留问题 前面编写批量更新本地仓库脚本的是时候，本来想着使用ssh的方式拉取仓库，也没细查是因为什么，通过小乌龟配置的git配置信息并没有同步到 config 中，导致通过命令行执行\ngit pull #提示没有权限，无法正常更新仓库 通过命令检查秘钥配置也是正确的：ssh -T git@gitlab.yintech.net\n如果你使用Git小乌龟（TortoiseGit）能够正常拉取代码，但在命令行中使用 git pull 命令时提示秘钥不对，这可能是因为Git小乌龟使用的是PuTTY的SSH密钥，而命令行使用的是OpenSSH的SSH密钥。\n小乌龟的秘钥配置，不会从系统 .ssh 文件夹读取秘钥文件信息，而是通过界面仓库配置的时候，单独配置秘钥文件的路径，有用的小技巧：拉取的第一个仓库配置了秘钥即可让其余仓库都复用这个秘钥文件，PuTTY 加载秘钥以后，不会立即退出，而是启动了一个代理服务。\n通过调整全局配置，不使用系统默认的ssh配置，这样配置后，Git Bash 将使用 TortoisePlink 进行 SSH 操作。这种配置适用于使用 TortoiseGit 自带的 PuTTY 工具的情况。\ngit config --global core.sshCommand \u0026quot;'C:/Program Files/TortoiseGit/bin/TortoisePlink.exe' -batch -ssh\u0026quot; 上面配置的执行文件文件路径自行修改到对应的小乌龟路径，由于配置的完整路径，无需添加路径到系统环境变量中。\n","date":"2024-01-08T21:22:04+08:00","permalink":"https://ttf248.life/p/git-disable-http-repositories/","title":"Git禁用http仓库"},{"content":"两年前给站点添加代码区域的拷贝功能，前后折腾了小半天，最终渲染效果有点不如意，作为半吊子前端开发，也没想着改进，能用就行，今年用AI开发了小程序，对于前端的开发也更加熟悉了，重构一波（AI重新设计）。\n悟道：任务拆解开，很多小任务，AI开发起来还是顺手的。已经倒闭的小程序，75%代码由AI提供，拆解了多个任务交付，人工进行项目代码的组装。\n前文 以为很简单的事情，增加一个代码复制按钮\n正文 promot: 设计 css 和 JavaScript 代码，定位网页元素 class=\u0026ldquo;highlight\u0026rdquo;，这个元素的容器内，添加一个 复制按钮，实现复制代码的功能\n给的第一稿代码一眼看上去就有问题，重新生成一稿，基本可用，复制的内容不对，有冗余的文字，再次引导优化，人工指定核心的颜色设计，包含哪些特效\n了解到您对按钮的尺寸和颜色有特定的要求，我们可以重新设计按钮的样式以适应这些要求。以下是一个调整后的 CSS 样式，其中包括了您提供的颜色方案，并对按钮的尺寸进行了优化：\n.copy-btn { position: absolute; top: 2px; /* 调整位置 */ right: 2px; padding: 3px 6px; /* 缩小尺寸 */ font-size: 12px; /* 减小字体大小 */ background-color: #8FD1E1; /* 按钮背景色 */ color: #272822; /* 文字颜色 */ border: 1px solid #272822; /* 边框颜色 */ border-radius: 3px; /* 圆角 */ cursor: pointer; opacity: 0.7; /* 默认半透明 */ transition: opacity 0.3s ease, background-color 0.3s ease; /* 平滑过渡效果 */ } .copy-btn:hover { opacity: 1; /* 鼠标悬停时不透明 */ background-color: #A3D4E5; /* 鼠标悬停时的背景色 */ } .highlight { position: relative; } 在这个样式中，我减小了按钮的尺寸和字体大小，使其更加精致。同时，按钮的默认状态是半透明的，当鼠标悬停在按钮上时，它会变为不透明，并且背景色会变得稍微亮一些，以提供视觉反馈。这样的设计既符合您的颜色要求，又保持了现代化和用户友好的特点。\n对应的提供了一份更简单的 JavaScript：\ndocument.addEventListener('DOMContentLoaded', function() { // 查找所有 .highlight 元素 const highlights = document.querySelectorAll('.highlight'); highlights.forEach(function(highlight) { // 创建复制按钮 const copyBtn = document.createElement('button'); copyBtn.textContent = '复制'; copyBtn.classList.add('copy-btn'); // 将按钮添加到每个 .highlight 元素中 highlight.appendChild(copyBtn); // 添加点击事件监听器 copyBtn.addEventListener('click', function() { // 假设 .highlight 下的第一个 \u0026lt;code\u0026gt; 元素包含要复制的代码 const code = highlight.querySelector('code') ? highlight.querySelector('code').textContent : ''; navigator.clipboard.writeText(code).then(() =\u0026gt; { // 显示复制成功信息 copyBtn.textContent = '已复制!'; setTimeout(() =\u0026gt; { copyBtn.textContent = '复制'; }, 2000); }).catch(err =\u0026gt; { console.error('复制失败: ', err); }); }); }); }); 后记 虽说我更期望在代码区域的右上角，顶部区域新增复制按钮，由于对前端不够了解，无法基于关键词准确描述功能，和AI来回折腾几个回合也没有达到预期。\n就是不知道随着时间的发展，AI对于程序开发会有多大的影响。\n","date":"2023-12-22T08:44:26+08:00","permalink":"https://ttf248.life/p/ai-programming-and-task-decomposition/","title":"AI编程和任务拆解"},{"content":"东方甄选小作文事件是一起由于东方甄选官方账号否认主播董宇辉是所有小作文的作者而引发的网络风波。到底真相如何，已经无从考证，公司权谋的斗争将这个事情推上了风口浪尖。\n鱼的七秒钟记忆，以后都交付给AI撰写，尝试了Bing AI和ChatGPT plus，前者给的资料更加完整，搜索引擎的获取的资料还是更多一些，输出的博文内容不够完整，格式比较僵硬；后者通过关键词获取内容，生成的内容不是那么完整，但是能获取完整的博文内容，如果给出参考资料的网址，能优化生成的稿子。\n正文 东方甄选小作文事件是一场围绕版权和创作归属的争议，从2023年12月5日开始，涉及主播董宇辉与东方甄选的一系列互动。这场风波不仅揭示了商业运作的复杂性，也引发了对当代商业文化和网络社会的深刻反思\n2023年12月5日：事件起点 东方甄选发布了一段预热视频，主播董宇辉朗诵的“小作文”迅速走红。 东方甄选在视频评论中声明，这些小作文多数由文案团队创作，并非全部出自董宇辉之手。 2023年12月13日：董宇辉的回应 董宇辉发表长文，反对以“饭圈”名义污名化任何人，表明自己对事件的立场。 2023年12月14日：管理层的回应 东方甄选CEO孙东旭发布道歉视频，承认公司管理上的漏洞。 东方甄选董事长俞敏洪也对事件进行回应，向董宇辉表达歉意。 2023年12月16日：重大决策 东方甄选官方宣布免去孙东旭的CEO职务，俞敏洪兼任。 同日，俞敏洪发表致歉信，表示将解除直播间拉黑的网友。 2023年12月18日：董宇辉的新角色 新东方教育科技集团任命董宇辉为新东方教育科技集团董事长文化助理，兼任新东方文旅集团副总裁。 俞敏洪透露，将与董宇辉成立工作室，开辟新的直播账号和直播间。 结论与反思 这场风波不仅是一场关于版权和创作归属的争议，更深层次地反映了文化与商业的碰撞。在数字化、碎片化的时代背景下，内容创作的版权归属成为了一个值得深思的话题。东方甄选小作文事件，不仅是一场媒体风波，更是对当代商业文化和网络社会的一次深刻反思。\n作为观察者，我们应该如何看待这种文化与商业的碰撞？在追求商业利益的同时，我们又该如何保护和尊重创作者的劳动成果？这些问题，值得我们每一个人深思。\n","date":"2023-12-20T18:57:25+08:00","permalink":"https://ttf248.life/p/dongfang-zhenxuan-essay-controversy-culture-vs-commerce/","title":"东方甄选小作文风波：一场文化与商业的碰撞"},{"content":"氪金类型的游戏，这里不做讨论，游戏圈子里面，这种统称：人民币战士，不需要对游戏设定的理解，需要你有个殷实的钱包。他们享受的乐趣在于周围小弟的前呼后拥，屠城的快感。\n有着广大受众的竞技游戏，比如：英雄联盟、DOTA、王者荣耀、绝地求生，这类型的游戏，世界观设定完整、游戏赛事已经进入良性循环的状态。\n在游戏设计中，心理学确实是一个关键领域，而社交心理学尤为重要。理解人们的行为、需求和动机可以帮助设计更吸引人的游戏体验。关于\u0026quot;装逼\u0026quot;和社交心理学之间的关系，我们可以从以下几个角度来看：\n社交认同感： 人们往往寻求在社交群体中建立认同感。在游戏中，如果设计能够让玩家感到自己在某方面很出色，能够引起其他玩家的注意，这可能会提高他们的社交认同感。这可能表现为炫耀技能、展示获得的奖励等。\n社交竞争： 一些游戏采用了社交竞争的元素，鼓励玩家在社交网络中展示他们的成就。这可以通过排行榜、成就系统或多人对战等方式来实现。这样的设计激发了玩家间的竞争心理，可能会导致一些玩家表现得更为出色以获得社交认可。\n自我展示： 有些游戏允许玩家通过自定义角色、虚拟物品等方式进行自我展示。这种自我展示不仅仅是为了炫耀，还可以是一种表达个性和社交交流的方式。\n团队合作： 一些游戏注重团队合作，通过社交互动来达到游戏目标。在这样的情境中，装逼的行为可能并不被鼓励，而是强调团队协作和相互支持。\n心理奖励系统： 游戏设计可以采用心理奖励系统，激发玩家积极的社交行为。例如，给予玩家奖励或特权，以鼓励他们积极参与社交互动。\n总体而言，游戏设计中的社交心理学可以被用来塑造玩家之间的互动和社交体验。装逼行为在一些情境下可能存在，但游戏设计师通常会努力平衡这种行为，以确保游戏体验对所有玩家都是积极和有趣的。\n想到哪里写到哪里，没有完整的大纲，稍微有点乱。\n作者常玩的英雄联盟，算是我们这代人的青春记忆，大部分的家长都不喜欢孩子玩游戏，因为他们没有深入的了解体会过这类型的游戏，当然也和游戏设定有关系，每局游戏都是新的开始、对于很多孩子来说，玩的时候，并没有带入太多的思考，属于自行探索的玩法，这种模式下，游戏的输赢，更多取决于孩子本身的游戏天赋。依据笔者的实际体验，相当多一部分的玩家属于此类型，对于他们来说。\n最大的成本不是金钱，而是时间。\n游戏里面也有娱乐模式，用以满足娱乐玩家的需求。\n英雄联盟这种竞技游戏对于笔者来说，更多的是圆了一个三国梦。开局你兜里两手空空，靠着自己的理解，补刀、发育，花费经济，布控视野，设局埋伏对面，更多的是用脑子玩游戏，没有那种绝佳的游戏天赋，也能玩的很开心。统领全局的掌控感，逆风翻盘的愉悦感。还有很多弹幕常说的云玩家，他们已经不玩游戏了，但是每次到世界赛期间，他们还是会观看比赛。\n这里就不得不提，游戏时间。指的不是单局游戏的时间，而是你上号的时间，周末的下午、每天工作日的晚上七点到晚上十点之间，你会发现和队友大部分情况都能正常沟通，你发出去的信号，队友能理解，能收到回应。换到其他时间，比如说通宵游戏，你碰到的更多就是网瘾少年，顺风的情况，无事发生，逆风的情况下，他们能问候你的全家，隔着屏幕你都能感受到那股子戾气。\n本身就是从事IT行业，游戏这些东西接触的很多，玩的也多，各种类型的玩过，对于竞技游戏，一直习惯用脑子玩，而是不是拼反应速度，天赋摆在这里，和职业的对比，或者小年轻对比，反应还是慢一些，习惯的是开黑，然后接管队伍的指挥权。最初玩的时候，就是读书那会，YY工会的老大哥们带着玩的。\n现在游戏的环境怎么说呢，都比较浮躁，没有之前那种纯粹\n上了年级以后，高分段的对局，玩下来真的很累，全程都是高度集中，思考对面谋划，如何化解对面的设局，属于那种，你打完都不想继续的状态。\n真说你玩的很厉害，如果不打职业比赛，对于人生轨迹来说，并没有什么作用，能作为社交的手段，但是无法谋生，立足于社会。\n单机游戏和网络游戏是两种不同类型的游戏，它们在玩法、体验和技术上存在显著差异。以下是理解单机游戏和网络游戏之间区别的一些关键方面：\n连接方式：\n单机游戏（Offline/Single-player）： 这种游戏是在本地设备上独自玩的，不需要互联网连接。玩家可以在没有网络连接的情况下享受游戏体验。 网络游戏（Online/Multiplayer）： 这类游戏通常需要互联网连接，因为玩家要与其他玩家进行实时互动。网络游戏可以是多人合作或对抗性的，涉及到在线社交和竞技。 玩家互动：\n单机游戏： 玩家主要与游戏内的人工智能、预设的任务或敌对元素互动。游戏体验通常更加个人化，受到游戏内设计和故事情节的影响。 网络游戏： 玩家可以与来自世界各地的其他真实玩家互动。这可能包括合作完成任务、对抗或竞技比赛，以及社交元素如聊天、公会系统等。 游戏设计和内容：\n单机游戏： 游戏设计更侧重于提供一个完整的、独立的故事情节和游戏体验。游戏内容通常是预先设计好的，玩家在游戏中探索、解谜或战斗。 网络游戏： 游戏设计需要考虑到实时互动和玩家之间的竞争或协作。游戏的内容可能更动态，包括定期更新、在线事件和社交互动。 技术要求：\n单机游戏： 通常可以在离线状态下运行，对设备性能和互联网连接的要求相对较低。 网络游戏： 需要较强的互联网连接，而且对服务器和网络性能有较高的要求，以确保实时互动的顺畅进行。 商业模式：\n单机游戏： 通常采用一次性购买或下载的商业模式，玩家购买游戏后即可在本地设备上完整地玩游戏。 网络游戏： 可能采用免费游玩、广告、道具购买或订阅等多种商业模式，以维持服务器运营和不断更新游戏内容。 理解这些区别有助于玩家在选择游戏时明确自己的偏好，并使游戏设计者更好地满足玩家的期望。\n","date":"2023-12-11T10:26:22+08:00","permalink":"https://ttf248.life/p/game-psychology-competitive-gaming/","title":"游戏心理学：竞技游戏"},{"content":"趁着双十一搞活动，阿里云新入手了一台服务器：经济适用版本，99一年，配置不高，作为跳板机代理家里的服务也是不错的，活动持续到2026年。\n特意选了上海地区的服务器，低延迟代理家里的机器，win11 和 windows server 2022，server 版本是后面部署的，使用的时候，突然收到拒绝访问的消息，本来以为是服务器更新，等会就能恢复正常。隔了五分钟，再去尝试，依旧拒绝登录，检索相关的报错，提示有人正在尝试登录，并且由于密码错误次数太多，现在无法登录。\n以前也是接触过安防攻击的脚本，立马就想到了，这些登录大概率不是正常的行为，是有人在攻击服务，尝试暴力破解登录服务器。服务器防火墙设置图省事，没有设置白名单，代理了两台机器的 3389 端口，在公网里面暴露出来，就和鱼塘里面的鱼饵差不多。既然知道了是脚本小子在攻击，接下来的事情就简单了，设置防火墙白名单，仅允许公司的IP地址和家里的IP地址访问代理服务。\nfrps代理服务端以前也没配置运行日志，开启日志后，给我看乐了，全国各地的代理IP，都在尝试登录家里的服务器，还好有一台是 server 版本，让我意识到了问题，不然 win11 那台机器，迟早别攻破，密码设置的比较简单。\n2023/11/17 16:51:14 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [101.43.98.211:50486] 2023/11/17 16:51:14 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [218.93.202.63:56970] 2023/11/17 16:51:14 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [222.179.106.174:60812] 2023/11/17 16:51:15 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [58.16.204.238:2839] 2023/11/17 16:51:15 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [124.223.47.24:50274] 2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [43.248.128.22:55883] 2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [43.143.53.138:56955] 2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [43.228.7.250:61550] 2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [125.76.228.9:55842] 2023/11/17 16:51:17 [I] [proxy.go:204] [4dfcc2259937dcb9] [winserver-remote] get a user connection [91.240.118.187:49326] 2023/11/17 16:51:17 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [91.240.118.187:49324] 2023/11/17 16:51:17 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [89.248.163.79:51712] 2023/11/17 16:51:18 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [218.63.75.24:62387] 2023/11/17 16:51:19 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [103.186.109.227:51396] 2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [116.233.234.104:51567] 2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [222.187.193.202:51585] 2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [59.48.98.42:57489] 2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [146.56.241.134:53558] 2023/11/17 16:51:21 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [222.179.106.174:30620] 2023/11/17 16:51:23 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [183.14.214.51:62128] 捎带手，查了下linux服务的登录日志，除开阿里云这台机器，还有朋友一台华为云的机器\nsudo grep \u0026quot;Failed password\u0026quot; /var/log/secure centos系列 sudo grep \u0026quot;Failed password\u0026quot; /var/log/auth.log ubuntu系列 Nov 16 04:46:34 aliyun-sh sshd[156625]: Failed password for root from 120.55.164.64 port 53410 ssh2 Nov 16 04:46:34 aliyun-sh sshd[156623]: Failed password for root from 111.16.215.122 port 36548 ssh2 Nov 16 04:46:58 aliyun-sh sshd[156630]: Failed password for invalid user share from 139.9.233.78 port 53872 ssh2 Nov 16 04:47:23 aliyun-sh sshd[156634]: Failed password for invalid user spark from 139.9.233.78 port 36134 ssh2 Nov 16 04:47:26 aliyun-sh sshd[156636]: Failed password for root from 120.55.164.64 port 46142 ssh2 Nov 16 04:47:47 aliyun-sh sshd[156640]: Failed password for root from 111.16.215.122 port 42962 ssh2 Nov 16 04:48:24 aliyun-sh sshd[156652]: Failed password for root from 120.55.164.64 port 38868 ssh2 Nov 16 04:48:25 aliyun-sh sshd[156654]: Failed password for root from 111.16.215.122 port 46164 ssh2 Nov 16 04:48:39 aliyun-sh sshd[156657]: Failed password for invalid user test from 139.9.233.78 port 39386 ssh2 Nov 16 04:48:50 aliyun-sh sshd[156659]: Failed password for root from 111.16.215.122 port 38892 ssh2 Nov 16 04:48:53 aliyun-sh sshd[156662]: Failed password for root from 120.55.164.64 port 49348 ssh2 Nov 16 04:48:53 aliyun-sh sshd[156664]: Failed password for invalid user test from 139.9.233.78 port 49864 ssh2 Nov 16 04:50:02 aliyun-sh sshd[156672]: Failed password for root from 111.16.215.122 port 45294 ssh2 Nov 16 04:50:30 aliyun-sh sshd[156680]: Failed password for invalid user zabbix from 139.9.233.78 port 52206 ssh2 Nov 16 04:50:50 aliyun-sh sshd[156683]: Failed password for root from 120.55.164.64 port 34820 ssh2 Nov 16 04:50:51 aliyun-sh sshd[156685]: Failed password for root from 111.16.215.122 port 58978 ssh2 Nov 16 04:51:18 aliyun-sh sshd[156689]: Failed password for root from 120.55.164.64 port 45306 ssh2 Nov 16 04:51:25 aliyun-sh sshd[156692]: Failed password for root from 111.16.215.122 port 33938 ssh2 华为云这台机器开启的时间比较长，已经开始进入字典爆破的中期，各种奇怪的用户都开始出现。\nNov 16 20:30:35 hecs-411458 sshd[182965]: Failed password for invalid user oeh from 39.129.9.180 port 26459 ssh2 Nov 16 20:32:17 hecs-411458 sshd[182967]: Failed password for invalid user dnu from 39.129.9.180 port 27079 ssh2 Nov 16 20:34:12 hecs-411458 sshd[182971]: Failed password for invalid user rq from 39.129.9.180 port 27742 ssh2 Nov 16 20:36:07 hecs-411458 sshd[182979]: Failed password for invalid user zw from 39.129.9.180 port 28415 ssh2 Nov 16 20:37:59 hecs-411458 sshd[182981]: Failed password for invalid user egi from 39.129.9.180 port 29068 ssh2 Nov 16 20:39:52 hecs-411458 sshd[182984]: Failed password for invalid user bjb from 39.129.9.180 port 29723 ssh2 Nov 16 20:41:53 hecs-411458 sshd[182988]: Failed password for invalid user hna from 39.129.9.180 port 30375 ssh2 Nov 16 20:43:46 hecs-411458 sshd[182994]: Failed password for invalid user gar from 39.129.9.180 port 31036 ssh2 Nov 16 20:45:40 hecs-411458 sshd[183003]: Failed password for invalid user mze from 39.129.9.180 port 31703 ssh2 Nov 16 20:47:35 hecs-411458 sshd[183007]: Failed password for invalid user tmh from 39.129.9.180 port 32381 ssh2 Nov 16 21:23:01 hecs-411458 sshd[183047]: Failed password for invalid user amax from 112.4.65.118 port 41188 ssh2 Nov 16 22:31:20 hecs-411458 sshd[183116]: Failed password for root from 211.228.203.123 port 60213 ssh2 Nov 16 22:53:44 hecs-411458 sshd[183162]: Failed password for root from 112.132.249.164 port 39272 ssh2 Nov 17 11:44:26 hecs-411458 sshd[184811]: Failed password for invalid user jsh from 43.157.103.27 port 54608 ssh2 Nov 17 11:47:23 hecs-411458 sshd[184818]: Failed password for invalid user mrunal from 43.157.103.27 port 50448 ssh2 Nov 17 11:48:46 hecs-411458 sshd[184820]: Failed password for invalid user robertsheen from 43.157.103.27 port 50560 ssh2 后记 开发自用的服务器，windows 公网访问需要设置白名单，linux 建议禁止密码登录，开启秘钥文件登录。\n","date":"2023-11-20T15:08:53+08:00","permalink":"https://ttf248.life/p/cloud-servers-and-script-kids/","title":"云服务器和脚本小子"},{"content":"组里的项目之间存在依赖关系，由于历史原因，并未使用submodule维护项目的依赖，日常开发需要手动依次更新仓库代码，否则可能碰到各种奇怪的问题。\n参考网上的资料，结构基本都类似，本地手动维护一份仓库目录：git_list.txt，编写脚本遍历目录，一次执行更新，以后开工前先执行下脚本\nlinux create new file: batch_pull.sh\n#!/bin/bash echo \u0026quot;============ 更新仓库 ===================\u0026quot; # 检查 git_list.txt 是否存在 if [ ! -f \u0026quot;git_list.txt\u0026quot; ]; then echo \u0026quot;git_list.txt 文件不存在！请创建并添加要拉取的 git 仓库 URL。\u0026quot; exit 1 else echo \u0026quot;============ 检测到了 git 仓库清单文件 ====\u0026quot; fi # 逐行读取 git_list.txt 中的 URL，并执行拉取操作 while read -r url; do if [ -d \u0026quot;$url\u0026quot; ]; then cd \u0026quot;$url\u0026quot; || continue git pull cd .. echo \u0026quot;Pull $url 完成！\u0026quot; echo \u0026quot;========================================\u0026quot; else echo \u0026quot;目录 $url 不存在，跳过拉取。\u0026quot; fi done \u0026lt; \u0026quot;git_list.txt\u0026quot; windows create a new file: batch_pull.bat\n@echo off chcp 65001 \u0026gt; nul rem 进入脚本所在目录 cd /d \u0026quot;%~dp0\u0026quot; rem 检查 git_list.txt 是否存在 if not exist \u0026quot;git_list.txt\u0026quot; ( echo git_list.txt 文件不存在！请创建并添加要拉取的 git 仓库 URL。 exit /b 1 ) else ( echo ============ 检测到了 git 仓库清单文件 ==== ) rem 逐行读取 git_list.txt 中的 URL，并执行拉取操作 for /f %%i in (git_list.txt) do ( if exist \u0026quot;%%i\u0026quot; ( pushd \u0026quot;%%i\u0026quot; git pull popd echo Pull %%i 完成！ echo ======================================== ) else ( echo 目录 %%i 不存在，跳过拉取。 ) ) 历史遗留问题 顺带处理重装系统以后碰到的git文件夹权限文件：Fatal error \u0026ldquo;unsafe repository (\u0026rsquo;/home/repon\u0026rsquo; is owned by someone else)\u0026rdquo;\n网上建议的做法大多来源自stack overflow:\n仓库目录添加信任: git config --global --add safe.directory /home/repon 手动修改配置文件.gitconfig，指定目录添加信任 [safe] directory = /home/repon 上面的方式处理以后，仓库更新是正常了，每次执行git pull控制台都有很多警告信息，提示用户所有者错误\n台式机重装系统 开发的机器，太久没有重装系统，系统盘垃圾文件爆炸，没辙，抽空重装了一波系统，再次碰到这个权限的问题，以前的脚本跑不通，修改的权限不完整\n用上新的方案，直接添加*，这样git会自动信任所有目录\ngit config --global --add safe.directory \u0026quot;*\u0026quot; 不知道是用户权限的问题，还是大家没习惯windows平台其实也有类似chown的命令，修改文件夹所有者，当然如果你的目录不多，手动修改所有者也行，但是这台工作电脑添加了域信息，不知道是公司部署的域存在异常，还是本地系统设置存在异常，用户清单中，找不到登录所用的用户，最后还是通过命令行处理的。\n管理员权限，执行powershell脚本change_ower.ps1，记得调整脚本文件编码为gbk，中文操作系统，这样才不会乱码\n# 获取当前用户的用户名 $currentUserName = [System.Security.Principal.WindowsIdentity]::GetCurrent().Name # 设置 PowerShell 的字符编码为 UTF-8 [Console]::OutputEncoding = [System.Text.Encoding]::UTF8 # 要更改所有者的根目录路径 $rootDirectory = \u0026quot;G:\\workspace\u0026quot; # 替换为实际的目录路径 # 递归遍历目录并更改文件和文件夹的所有者 Get-ChildItem -Path $rootDirectory -Recurse | ForEach-Object { $itemPath = $_.FullName # 检查是文件还是文件夹 if ($_ -is [System.IO.DirectoryInfo]) { # 如果是文件夹，使用 icacls 更改所有者权限 $icaclsResult = icacls $itemPath /setowner \u0026quot;$currentUserName\u0026quot; 2\u0026gt;\u0026amp;1 if ($LASTEXITCODE -eq 0) { Write-Host \u0026quot;已更改文件夹 $itemPath 的所有者为 $currentUserName\u0026quot; } else { Write-Host \u0026quot;无法更改文件夹 $itemPath 的所有者。错误信息: $icaclsResult\u0026quot; } } else { # 如果是文件，使用 icacls 更改所有者权限 $takeownResult = icacls $itemPath /setowner \u0026quot;$currentUserName\u0026quot; 2\u0026gt;\u0026amp;1 if ($LASTEXITCODE -eq 0) { # Write-Host \u0026quot;已更改文件 $itemPath 的所有者为 $currentUserName\u0026quot; } else { Write-Host \u0026quot;无法更改文件 $itemPath 的所有者。错误信息: $takeownResult\u0026quot; } } } 不出意外的还是出现了预料之外的情况，脚本执行输出的中文信息乱，尝试设置控制台的字符编码，调整脚本编码，输出的都是乱码，脑子那会大概率不清醒了，试着启用 控制面板-区域-语言设置的 beta 功能，全局开启 Unicode 编码，脚本执行是正常了，好几个开发软件都无法正常工作，回头梳理资料才想起来，调整脚本文件的编码，设置为 gbk\n资料 https://ganzhixiong.com/p/f1b9f4fc/ https://stackoverflow.com/questions/71901632/fatal-error-unsafe-repository-home-repon-is-owned-by-someone-else ","date":"2023-10-19T14:16:22+08:00","permalink":"https://ttf248.life/p/bulk-update-local-git-and-legacy-permissions/","title":"批量更新本地Git仓库和历史遗留的权限问题"},{"content":"小程序开发设计的坑还没填上，新挖一个WPF，最近公司也动荡了一波，异地协同办公沟通总归效率总归有点不如意，索性承接了客户端界面的开发。\nWPF 推荐 WPF 微软官网学习资料 WPF 基础总结(学习建议) WPF 中文网 WPF 个人总结和学习推荐 WPF 界面设计用到的很多概念，类似于网页前端设计，尽可能的剥离UI设计和业务逻辑，让UI的设计能独立出来，也是互联网公司期望的分工方式。今年刚好折腾过小程序，很多概念上的东西都是通用的，上手也就比较轻松，这些算是现代UI设计中的道，掌握了基础的框架概念，后面的路不容易走歪。\n以前有Winform开发经验的读者，推荐阅读：WPF 基础总结(学习建议)，篇幅不长，适合有经验的读者规划学习路线\n零基础的读者推荐阅读：WPF 中文网，从零开始介绍基础的概念、发展的历史、底层类的认知逻辑。这个网站说来也是巧了，今年八月份作者刚发布的，用来吸引读者购买课程，和我这边的时间刚好对上了，如果再晚一点，和我大概率也就没有缘分了。\n想要最正统的学习资料，当然是微软官网的资料，有些枯燥，新读者需要有耐心。\n经典的电子书籍也有很多，不是很推荐，日常工作的事情也多，静下来看书的时间并不是很多，很难一下子就进入看书的状态，带着项目练习更合适一些。\nC# 和.net 发布历史 想对于以前学习的语言，最近几年，发布的新特性稍微有点多，语法的版本每年都在迭代。\nhttps://en.wikipedia.org/wiki/C_Sharp_(programming_language)\n官方学习资料：\nhttps://learn.microsoft.com/zh-cn/dotnet/csharp/ https://learn.microsoft.com/zh-cn/dotnet/core/tutorials/with-visual-studio?pivots=dotnet-7-0 ","date":"2023-10-17T10:49:24+08:00","permalink":"https://ttf248.life/p/wpf-learning-resources/","title":"WPF学习资料"},{"content":"中共中央政治局：要加大国有企业、金融领域反腐败力度，深入纠治“四风”\n中共中央政治局 中共中央政治局9月27日召开会议，审议《关于二十届中央第一轮巡视情况的综合报告》。中共中央总书记习近平主持会议。会议强调，要以巡视整改为契机，进一步加强党的全面领导，督促被巡视党组织提高政治站位，认真履行党中央赋予的职责使命，不断增强国有企业核心功能和核心竞争力，夯实中国特色社会主义的重要物质基础和政治基础，加大金融企业服务实体经济和国家战略力度，推动高质量发展。要统筹发展和安全，树牢底线思维、极限思维，采取有力措施防范化解重大风险，牢牢守住安全底线。要推动全面从严治党向纵深发展，压紧压实党委（党组）书记第一责任人责任、领导班子成员“一岗双责”、纪检监察机构监督责任，突出加强对各级“一把手”的监督，加大国有企业、金融领域反腐败力度，深入纠治“四风”，深化以案促改、以案促治，一体推进不敢腐、不能腐、不想腐。要认真贯彻新时代党的组织路线，加强领导班子建设、干部人才队伍建设和基层党组织建设。要综合用好巡视成果，深化改革、完善制度，推进源头治理，促进标本兼治。（新华社）\n造成重大金融风险！中国银行原党委书记、董事长刘连舸被开除党籍 据中央纪委国家监委网站，经中共中央批准，中央纪委国家监委对中国银行股份有限公司原党委书记、董事长刘连舸严重违纪违法问题进行了立案审查调查。 经查，刘连舸丧失理想信念，背弃初心使命，落实党中央决策部署不坚决、打折扣，弃守金融风险防控职责，大肆违规插手信贷项目，违法发放贷款，造成重大金融风险，履行全面从严治党主体责任不力，严重破坏所在单位政治生态，私自携带违禁书刊入境，处心积虑对抗组织审查；无视中央八项规定精神，违规收受礼品礼金、出入私人会所、接受滑雪和旅游安排，长期借用管理对象车辆；不按规定报告个人有关事项，在组织函询时不如实说明问题，徇私录用调整提拔干部；违规经商办企业；违规干预资金借贷，私自留存涉密资料；道德败坏，家风不正，对亲属失管失教；毫无纪法底线，擅权妄为，“靠金融吃金融”，利用职务便利为他人在贷款融资、项目合作等方面谋利，并非法收受巨额财物。\n刘连舸严重违反党的政治纪律、组织纪律、廉洁纪律、工作纪律和生活纪律，构成严重职务违法并涉嫌受贿、违法发放贷款犯罪，且在党的十八大后不收敛、不收手，性质严重，影响恶劣，应予严肃处理。依据《中国共产党纪律处分条例》《中华人民共和国监察法》《中华人民共和国公职人员政务处分法》等有关规定，经中央纪委常委会会议研究并报中共中央批准，决定给予刘连舸开除党籍处分；按规定取消其享受的待遇；终止其党的二十大代表资格；收缴其违纪违法所得；将其涉嫌犯罪问题移送检察机关依法审查起诉，所涉财物一并移送。\n中国光大集团原党委书记、董事长李晓鹏严重违纪违法被开除党籍和公职。（央视新闻） 中央纪委国家监委网站通报，据贵州省纪委监委消息：贵州银行原党委书记、董事长李志明涉嫌严重违纪违法，目前正接受贵州省纪委监委纪律审查和监察调查。 时隔八年，汇金增持四大行 10月11日，工商银行、农业银行、中国银行、建设银行四大国有商业银行分别发布公告，获汇金公司增持，分别为2761万股、3727万股、2489万股、1838万股；汇金公司拟在未来6个月内继续在二级市场增持四大行。\n","date":"2023-10-09T14:53:35+08:00","permalink":"https://ttf248.life/p/financial-anti-corruption-curtain-rise/","title":"金融反腐的序幕"},{"content":"主播送 IPhone？小程序排名奖励？各种直播平台的礼物抽奖？\n上面三个看着没有太多关联的东西，实质上都是免费流量变现的不同模式，有点金融游戏的意思。\n平台抽奖获取礼物 常规的场景中，用户重置获取平台货币，购买礼物送给心怡的主播，各家平台还有另外一种玩法，用户获取了平台货币以后，不再直接送礼，可以花费一定量的货币，参与抽奖活动，获取限定的高价礼物。\n此时已经出现问题了，线上抽奖简单理解就是平台开赌场，参与人数足够多，肯定是不会亏本的。屌丝用户机带着搏一搏的心态，想着中个大奖，再去送礼，有面子、当大哥！\n主播送礼（实物） 前文提到的平台抽奖针对的是用户自身的行文，主播每个月都有流水任务、人气任务；开启送礼抽奖的玩法，粉丝送指定的礼物、或者送指定金额的礼物，就有机会参与抽奖，礼物可能是高端手机、或者现金红包。\n对于人气高的大主播而言，这个活动很赚钱，等于就是临时发起的零元购，参与的人数足够多，主播也是赚钱的。这里就考验了主播的运营能力。\n当然还有一种玩法，给的奖励很高（现金价值），很多户外主播就是这种玩法，变相的线上赌博了。直播的内容没人在乎，用户只关心自己是不是能中奖。\n除开秀场类型的主播，通过PK模式，诱导粉丝消费充值，普通的游戏主播，很难带动玩家的消费情绪，打游戏和看直播都是消遣的方式，并不想产生额外的金钱支出，特别是竞技类游戏，抽奖的方式，可以培养用户的充值习惯、消费习惯、偶尔还能冲动消费（送很多，想中奖）。\n小程序排名奖励 设计一个小程序，弄一些没什么用的流程，或者提供部分游戏相关的辅助服务。前面这些都是掩护，为了通过腾讯的审核，小程序里面的玩法带上排名机制。用户通过浏览激励广告，完成任务，赢取积分，后台依据积分设置排名，排名较高的用户获取指定的奖励。\n核心逻辑：广告收入 \u0026gt; 运营成本 + 奖励费用\n小程序也有正常运行的方式，提供合理的服务，通过适当的广告赚取收入，赚的可能不多，但是涓涓细流，也是可以的。\n","date":"2023-09-19T07:04:35+08:00","permalink":"https://ttf248.life/p/traffic-monetization-business-model-raffle/","title":"流量变现的商业模式：抽奖"},{"content":"办公室新入手一台mini主机，想着配置配置环境方便，在家偶尔也有访问的需求，临时部署内网穿透。按照以往的经验，部署frp服务，指定端口转发，需要一台公网的服务器，连接的质量取决于公网服务器的宽带质量。折腾一点新鲜的Zerotier虚拟机局域网，类似于VPN，本地新建虚拟网卡，所有的机器都加入到一个虚拟网络中。\n什么是 Zerotier ZeroTier是一种软件定义的广域网络（SD-WAN）解决方案，它允许用户在不同地理位置的设备之间创建安全的虚拟网络。通过ZeroTier，您可以轻松地将多台计算机、服务器和设备连接到一个虚拟的、加密的网络中，就好像它们在同一局域网中一样。这可以帮助程序员和IT专业人员在不同地点之间安全地共享数据和资源，而无需复杂的网络设置和VPN配置。\nZerotier网络：Zerotier网络是一个虚拟的、全球性的局域网络，允许不同设备通过互联网连接在一起，就好像它们在同一个物理网络上一样。这个网络可以包含多个子网，所有设备都通过Zerotier的技术连接在一起。\n行星服务器：行星服务器是Zerotier网络的关键组件之一。它是全球性的，负责维护和管理整个Zerotier网络的拓扑结构、路由信息和网络状态。行星服务器起到全局的网络控制中心作用，但不直接传输数据。用户的设备需要连接至少一个行星服务器来参与Zerotier网络。\n中转服务器：中转服务器是Zerotier网络中的辅助节点，用于帮助设备之间建立直接通信通道。当设备之间无法直接连接时，它们可以通过中转服务器来传输数据。这有助于提高网络的可达性和性能。中转服务器通常位于全球各地，充当数据传输的中转点。\n总的来说，Zerotier通过行星服务器和中转服务器的协助，使设备能够在全球范围内创建虚拟的局域网络，实现安全、快速的设备之间通信。行星服务器负责全局网络管理，而中转服务器则帮助设备在需要时建立通信连接。\n安装部署 访问 ZeroTier 官方网站（https://www.zerotier.com/）以获取安装文件和文档。 根据您的操作系统下载和安装ZeroTier One客户端。支持Windows、macOS、Linux和许多其他平台。 安装完成后，启动ZeroTier One客户端。 注册一个ZeroTier账户，如果您还没有账户的话。您可以在客户端中创建一个账户。 登录您的ZeroTier账户并创建一个新的网络。网络将会有一个唯一的16位ID，您需要记住它。 在您的设备上加入这个网络。您可以在客户端中输入网络ID或使用QR码扫描功能。 安装并配置ZeroTier客户端的设备将会被添加到同一虚拟网络中。这些设备之间现在可以直接通信，就好像它们在同一局域网中一样。 您可以在ZeroTier的控制面板中管理网络设置、添加设备和监视网络流量等。 安装部署 moon 国内运营商很多都禁止了UDP打洞，frp服务稳定，由于走的tcp协议，Zerotier部署中转服务器也能实现类似的效果，防火墙需要开放udp 9993。\ncurl -s https://install.zerotier.com/ | sudo bash 检查安装是否成功\nzerotier-cli info 加入到局域网\nzerotier-cli join network-id 创建 moon\ncd /var/lib/zerotier-one \u0026amp;\u0026amp; sudo zerotier-idtool initmoon identity.public \u0026gt; moon.json 编辑配置文件，调整stableEndpoints节点，\u0026ldquo;服务器公网ip/9993\u0026rdquo;\n生成签名配置，创建moons.d文件夹，前面文件文件移动到此，重启服务\nsudo zerotier-idtool genmoon moon.json mkdir moons.d \u0026amp;\u0026amp; mv 000000eb444ec0d8.moon moons.d/ systemctl restart zerotier-one.service 客户端节点加入 moon 服务器, id 取自前面 json 配置文件中的 id 字段\nzerotier-cli.bat orbit ztaddr ztaddr # 观察是否出现新的 mooon 节点，id 和信息为服务器配置的相同 [root@idv-36f9d5 ~]# zerotier-cli listpeers 200 listpeers \u0026lt;ztaddr\u0026gt; \u0026lt;path\u0026gt; \u0026lt;latency\u0026gt; \u0026lt;version\u0026gt; \u0026lt;role\u0026gt; 200 listpeers 0cccb***** 35.236.*.*/64393;110;10726 327 1.6.3 LEAF 200 listpeers 3a46f***** 185.180.*.*/9993;110;757 -1 - PLANET 200 listpeers 3ed7c***** 39.97.*.*/9993;172;79 32 1.6.3 MOON 200 listpeers 4f838***** - -1 - LEAF 200 listpeers 62f86***** 50.7.*.*/9993;110;4796 351 - PLANET 200 listpeers 778cd***** 103.195.*.*/9993;5148;4887 253 - PLANET 200 listpeers 992fc***** 195.181.*.*/9993;10161;4921 226 - PLANET 200 listpeers 9d2b5***** - -1 - LEAF windows 平台通过管理员权限启动终端，通过 zerotier-cli.bat 命令行操作，Linux 平台通过 zerotier-cli 操作；peers 子命令查看连接、listpeers查看所有节点，能正常展示 moon 节点表示加入成功\n如何卸载 Windows平台如何卸载不再赘述，常规操作，通过控制面板卸载即可，我们重点说下ubuntu。\n通过dpkg删除zerotier-one服务 sudo dpkg -P zerotier-one 删除zerotier-one文件夹，该文件夹存储了address地址，删除后再次安装会获得新的address地址 sudo rm -rf /var/lib/zerotier-one/ 后记 原本都是已经卸载了，服务器到了，没有合适的服务作为代理节点，阿里云搞业绩，提供了开发特供服务器，配置不高，99一年，价格实惠，弄了两年。看中的就是服务器提供的带宽。\n参考资料 https://www.wnark.com/archives/152.html https://www.cnblogs.com/Yogile/p/12642423.html ","date":"2023-09-19T04:58:03+08:00","permalink":"https://ttf248.life/p/zero-tier-remote-lan/","title":"异地局域网ZeroTier"},{"content":"vmware虚拟机安装开发系统的时候，一般都会多预留点磁盘空间，用的时间长了，本地占用的磁盘空间远超虚拟机实际文件的内容。\n场景描述 df -h命令，查看当前机器的磁盘信息，实际用了 60G，删掉所有的快照和克隆镜像，本地虚拟机占用的磁盘空间依旧远大于 60G，让本就不富裕的硬盘，雪上加霜。\n前置条件 虚拟机安装的时候，没有勾选预分配磁盘 本地存放虚拟机的硬盘，剩余的磁盘空间大于当前虚拟机所占用的空间 剩余的空间不足，可以考虑临时移动虚拟机到移动硬盘，优化了磁盘以后再迁移回来。\n工具 官方提供了open-vm-tools包，可以通过 yum 安装或者 vmware-tools 镜像包安装\n命令 vmware-toolbox-cmd disk shrink / 执行了以后，虚拟机会自动关机，vmware 宿主程序会执行磁盘压缩，执行时间取决于虚拟机的体积和磁盘的访问速度。\n执行效果还是很不错的，虚拟机的磁盘空间占用基本等于df -h的磁盘信息。\n","date":"2023-06-21T18:35:41+08:00","permalink":"https://ttf248.life/p/vmware-virtual-machine-disk-space-optimization/","title":"VMware 虚拟机磁盘空间优化"},{"content":"国内的资料，基本都在推荐秋叶大佬的一键部署包，想着都是基于Python的开源项目，部署也不会很复杂，试试从零开始。\n折腾AI生成图，特意更换了显卡，3060 12g入门版本；服役七年的960光荣下线\n核心的pytorch cuda安装，以前编写pyhton游戏辅助脚本时，本地安装过，没想到还是碰到坑，cuda加密一直无法激活。\n待处理 1.重新规划文章结构，先介绍 pytorch，版本的对应关系，如何查看版本 2.本地如何从零开始新建虚拟环境，部署 Pytorch 3.翻译稿子，从零开始 stable diffusion https://stable-diffusion-art.com/install-windows/ 4.整理参考资料\n步骤 用中文搜索可能找不到相关一步一步安装的教程。在Google里面你用英文去搜索，有很多类似的教程，就是从零开始。介绍了一下，我们需要安装git，然后又说明了一下，我们需要安装python。然后就是你去把仓库下载过来，直接双击脚本搞定了。\nhttps://github.com/AUTOMATIC1111/stable-diffusion-webui\n详细的使用和答疑，翻看issues，https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki\n我也不知道为什么就没人解释这个仓库是干嘛的。其实从名字也不难看出来，它是一个界面控制台，让我们用起来更方便。实际上在安装的时候，他会去下载官方的仓库内容，获取实际的SD代码。\n仓库呢同时也做了一个安装启动脚本。会自动识别当前文件夹，是否有Python虚拟环境。如果有的话默认使用当前路径的的python。\n如果是纯小白用户，建议看一下：https://stable-diffusion-art.com/install-windows/\npytorch https://pytorch.org/get-started/locally/\n这里才是我今天想说的，首先你不要听他们的步骤直接启动脚本。Python通过requirement文件去安装依赖库，这个都是小问题。核心就是你的显卡版本驱动的版本，需要和pytorch对应。这个呢，也有很多人介绍相应的关系，网上找一找就有了。\n参考：https://blog.csdn.net/weixin_40660408/article/details/129896700\n创建一个虚拟环境对，就是一个空的虚拟环境，你在里面直接先去官网执行脚本，把pytorch安装好了。\npython -c \u0026quot;import torch; print(torch.version.cuda)\u0026quot; python -c \u0026quot;import torch; print(torch.__version__, torch.cuda.is_available())\u0026quot; 上面两个脚本可以检查一下你需要安装的cuda版本，也能检查一下你安装是否成功了。\n这里不建议花里胡哨的操作，你先按照官方页面的逻辑复制过来，直接安装就好了，直接pip去安装，你的pytorch很有可能失败，或者没有激活cuda。\npip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 重点：文件夹的路径不要有乱七八糟的东西，不然很有可能导致pytorch无法使用。\n中间来来回回安装了很多次，也尝试了把官方的安装文件下载下来手动去安装。就是想着升级一下2.0的版本，因为官方的文档说2.0速度会快一些。但是之前用的不多，也不知道Python的版本和这个是不是有影响。中间呢也查看了官方的手册，说的是建议用3.8的版本。这里就产生了一个小冲突，之前用过一键安装部署包，它里面是3.10的版本。最后就是从零开始先新建文件夹，创建虚拟环境，确保torch已经安装成功了。\n然后把这个安装好的虚拟环境移动到web UI的文件夹里面。这个时候再去启动脚本安装，其他的依赖问题就不大了。\n移动后，需要执行：python -m pip install \u0026ndash;upgrade \u0026ndash;force-reinstall pip，修复一下 pip\n可能看起来挺莫名其妙的，但是这个地方折腾了挺久的。因为它一直无法正确的识别我torch。为了排除所有的干扰因素，才想到先安装它，再去安装其他的依赖库。\nXformers 建议开启，能加速图像生成和减少现存占用，副作用，同一组参数，生成的图像相对不是那么稳定\nstable-diffusion-webui:Xformers\nhuggingface optimization\nOptimization Ratio Time taken Torch active/reserved Sys VRAM 100.00% 2m 57.03s 7440/10058 MiB 12288/12288 MiB (100.0%) 51.02% 1m 29.21s 4547/7164 MiB 9298/12288 MiB (75.67%) ((masterpiece)),((best quality)),((high detial)),((realistic,)) Industrial age city, deep canyons in the middle,chinese architectural streets,bazaars, Bridges, (rainy days:1.2), (steampunk:0.8), chinese architecture Negative prompt: nsfw,((cowboy)),(((pubic))), ((((pubic_hair))))sketch, duplicate, ugly, huge eyes, text, logo, monochrome, worst face, (bad and mutated hands:1.3), (worst quality:2.0), (low quality:2.0), (blurry:2.0), horror, geometry, bad_prompt, (bad hands), (missing fingers), multiple limbs, bad anatomy, (interlocked fingers:1.2), Ugly Fingers, (extra digit and hands and fingers and legs and arms:1.4), crown braid, ((2girl)), (deformed fingers:1.2), (long fingers:1.2),succubus wings,horn,succubus horn,succubus hairstyle, (bad-artist-anime), bad-artist, bad hand, borrowed character, text focus, watermark, sample watermark, character watermark, lofter username, photo date watermark, movie poster, magazine cover, journal, cover, cover page, doujin cover, album cover, manga cover, brand name imitation, EasyNegative,Tights, silk stockings,shorts Steps: 35, Sampler: DPM adaptive, CFG scale: 5.5, Seed: 2223996555, Size: 1088x1088, Model hash: 543bcbc212, Model: base_Anything-V3.0-pruned, Clip skip: 2, ENSD: 31337 后记 为什么不是推荐那个一键部署包，因为他那个包里面，有部分设置是作者私人定制过的，和官方原模原样的是不一样的。如果你是初学者，你可能不知道为什么要设置那些参数最好的逻辑还是先用官方给的。随着你用的时间越来越长，多去看看官方的手册，你就知道哪些参数需要调整了。\n显卡的选择 数据货币矿难之后, 显卡的价格相对来说不是那么高了，普通的入门玩家，3060和3060ti之间抉择，一般都会推荐大显存12G版本的3060，毕竟能生成更大分辨率的图，为什么需要更大的分辨率，因为你可以在生成的时候，把分辨率调大，这样生成的图像就会更加清晰，更加细腻。如果你是想要生成一些小图，那么8G的显存也是够用的。\n还有一点，高清放大选项，具化细节，让画面细节更加丰富，也需要更多的显存。\n以下是NVIDIA GeForce GTX 970、GeForce RTX 3060 Ti、GeForce RTX 3060、GeForce RTX 3080和GeForce RTX 3080 Ti的单精度（FP32）、半精度（FP16）和双精度（FP64）浮点数计算能力的规格汇总表：\n显卡型号 发布年份 单精度浮点数计算能力（TFLOPS） 半精度浮点数计算能力（TFLOPS） 双精度浮点数计算能力（TFLOPS） GeForce GTX 970 2014 3.49 87.2 0.109 GeForce RTX 3060 Ti 2020 16.2 32.4 0.51 GeForce RTX 3060 2021 12.7 25.4 0.39 GeForce RTX 3080 2020 29.8 58.9 0.93 GeForce RTX 3080 Ti 2021 34.8 68.7 1.36 摘录来的，各种显卡性能测试数据\n更新 间隔半年，本来还想再梳理一下安装步骤，科普更多的基础概念，结果发现，普通人玩AI画图，真就是基于大佬给的图片参数，进行参数调整，或者基于已有的图片，进行格式化的重新渲染。\n中间有过项目，尝试用AI来绘制小程序的UI素材，结果折腾半天，效果都不如意，不如我直接从官方的小程序拉资源图片。\n","date":"2023-04-13T00:23:54+08:00","permalink":"https://ttf248.life/p/stable-diffusion-zero-install-story/","title":"Stable-diffusion-从零安装的恩怨情仇"},{"content":"one loop thread，耗时已经在微秒层面，更换服务器，从最多积压六万数据包，到几乎没有积压\n在单线程循环处理数据的场景中，CPU的性能取决于主频、缓存大小、指令集架构等因素。一般来说，主频越高、缓存越大、指令集架构越先进的CPU在单线程处理数据时性能越好\n单线程 性能提升，增加线程不是分必要的，梳理项目流程，确定耗时的点，单线程是否能满足需求，单线程考虑的东西更少，也不容易出问题。\n上来就和就说加线程，多少有点毛病\n事件 处理的都是行情数据，延迟敏感\n吭哧吭哧加班一晚上，发布新的优化版本，本地剥离接口进行测试，速度也还行，tps：4.2万\n部署到服务器，tps骤降：2.1万，回家尝试台式机，tps：7.9万，开始怀疑组内服务虚拟机多少有点问题，首先怀疑主频导致的，家用台式机和服务器CPU，差异最大的地方就是主频\n测试服务器A\nprocessor\t: 7 vendor_id\t: GenuineIntel cpu family\t: 6 model\t: 47 model name\t: Intel(R) Xeon(R) CPU E7- 4807 @ 1.87GHz stepping\t: 2 microcode\t: 0x34 cpu MHz\t: 1866.733 cache size\t: 18432 KB physical id\t: 1 siblings\t: 4 core id\t: 3 cpu cores\t: 4 apicid\t: 7 initial apicid\t: 7 fpu\t: yes fpu_exception\t: yes cpuid level\t: 11 wp\t: yes flags\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss ht syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 cx16 sse4_1 sse4_2 popcnt aes hypervisor lahf_lm pti dtherm arat bugs\t: clflush_monitor cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit bogomips\t: 3733.46 clflush size\t: 64 cache_alignment\t: 64 address sizes\t: 40 bits physical, 48 bits virtual power management: 测试服务器B\nprocessor\t: 7 vendor_id\t: GenuineIntel cpu family\t: 6 model\t: 63 model name\t: Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz stepping\t: 2 microcode\t: 0x3c cpu MHz\t: 2599.998 cache size\t: 20480 KB physical id\t: 14 siblings\t: 1 core id\t: 0 cpu cores\t: 1 apicid\t: 14 initial apicid\t: 14 fpu\t: yes fpu_exception\t: yes cpuid level\t: 15 wp\t: yes flags\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cpuid_fault epb pti fsgsbase smep xsaveopt cqm_llc cqm_occup_llc dtherm ida arat pln pts bugs\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit bogomips\t: 5199.99 clflush size\t: 64 cache_alignment\t: 64 address sizes\t: 40 bits physical, 48 bits virtual power management: 咨询 OpenAI 首先是核心数和主频方面，Intel(R) Xeon(R) CPU E7- 4807 @ 1.87GHz拥有6个物理核心和12个逻辑核心，主频为1.87GHz；而Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz拥有8个物理核心和16个逻辑核心，主频为2.60GHz。因此，从核心数和主频方面来看，E5-2640 v3在单线程处理数据时应该比E7- 4807更具优势。\n其次是缓存大小方面，E7- 4807的缓存大小为12MB，而E5-2640 v3的缓存大小为20MB。因此，E5-2640 v3拥有更大的缓存空间，可以提高数据的访问速度和缓存命中率。\n最后是架构方面，E5-2640 v3采用了更先进的Haswell架构，而E7- 4807采用的是旧的Nehalem架构。Haswell架构相对于Nehalem架构在性能方面有所提升，这也可能对E5-2640 v3在单线程处理数据时的性能提升产生影响。\n因此，综合考虑，在单线程循环处理数据的场景中，E5-2640 v3应该比E7- 4807具有更好的性能。但是，具体的性能差异会受到多种因素的影响，包括数据处理的算法、内存带宽、系统负载等等，需要具体问题具体分析。\n硬件资料 https://www.cpubenchmark.net/compare/3786.2vs2365.2/%5BDual-CPU%5D-Intel-Xeon-E7–4807-vs-%5BDual-CPU%5D-Intel-Xeon-E5-2640-v3\nSpecification Xeon E7-4807 (LGA1567) Xeon E5-2640 v3 (LGA2011-v3) Price Search Online $78 - BUY Socket Type LGA1567 LGA2011-v3 CPU Class Server Server Clockspeed 1.9 GHz 2.6 GHz Turbo Speed Not Supported Up to 3.4 GHz # of Physical Cores 6 (Threads: 12) 8 (Threads: 16) Cache NA2 NA2 Max TDP 95W x 2 90W x 2 Yearly Running Cost $34.68 $32.85 Other First Seen on Chart Q3 2020 Q3 2014 # of Samples 1 46 CPU Value 69.1 225.6 Single Thread Rating 721 (-59.2%) 1767 (0.0%) CPU Mark 6223 (-64.6%) 17600 (0.0%) ","date":"2023-04-07T16:30:15+08:00","permalink":"https://ttf248.life/p/program-optimization-dont-fight-hardware/","title":"程序优化不要试图对抗硬件"},{"content":"就如当年学习搜索引擎的技巧，我们也需要学习一些和AI沟通的技巧，给出合理且充分的限定条件，高效的获取需要的答案。\n如果你换个角度呢，当前的AI属于一个记忆力很好的小孩子，它拥有过目不忘的能力，有抄作业的能力。我们需要做的是学会如何正确、有效的和AI沟通，精准的描述需求，帮助AI生成预期的结果。\n科普 火出天际的AI确切的说Generative Pre-Training，直译过来就是生成式的预训练。它是一种基于互联网可用数据训练的文本生成深度学习模型，用于问答、文本摘要生成、机器翻译、分类、代码生成和对话 AI 等任务。目前已经有 GPT-1、GPT-2、GPT-3 和 GPT-4 等不同版本的模型，每个版本都比前一个版本更大、更强大。\n到底有没有智能 相似度足够高，准确率也就越高 基础的、重复性的工作，进过特定训练，不再需要人工的介入 生成式AI是一种利用现有的文本、音频、图像等数据来创建新内容的技术。它可以用于文本生成、语音合成、图像生成、对话系统等多种任务。生成式AI的逻辑性取决于它的训练数据和模型结构。一般来说，生成式AI可以在一定程度上遵循语法、逻辑和常识，但也可能出现错误、偏差或不真实的内容。因此，生成式AI的输出需要人类的判断和验证，不能盲目相信或使用。\nPrompt 工程师 时间河流不会逆流，人需要学会适应潮流。你可以认为AI不智能，没有逻辑性，它经常写出来不能用的代码。\n如果你换个角度呢，当前的AI属于一个记忆力很好的小孩子，它拥有过目不忘的能力，有抄作业的能力。我们需要做的是学会如何正确、有效的和AI沟通，精准的描述需求，帮助AI生成预期的结果。\n对话模式 两年前Github Copilot发布，谁也想不到两年后，OpenAI横空出世，让人类认知到了大语言模型的能力。\n基于基于注释的编程和基于对话的编程，交互逻辑上完全不同，对话的模式，小白用户的交互体验友好，此处必须提到NewBing在每个问题之后，给出的追问提示，微软在尝试引导用户，获取AI知识库里面，更多的内容。\n举个栗子 场景：高铁旅途时间漫漫，编码是个不错的选择。流量有限的情况下，处理几个图片，获取了图片素材，下载软件处理图片稍微有点奢侈，网络条件也不允许。\n需求：有一批图片素材，带透明背景图，用来作为小程序的导航栏，选中的状态是彩色的，没选中的状态是黑白的，素材都是彩色的，需要预处理一下。\nPrompt：编写一段 python 代码，从一个文件夹中读取所有的图片，将图片转换成黑白，维持透明背景，保存图片的时候，优化图片的质量，减少文件体积，同时在控制台展示，优化前后的文件体积大小对比\n# 导入必要的库 import os import PIL from PIL import Image # 定义一个函数，将图片转换成黑白，维持透明背景，保存图片，并返回文件体积 def convert_and_save(image_file): # 打开图片 image = Image.open(image_file) # 获取图片的模式，如果是 RGBA 模式，说明有透明背景 mode = image.mode if mode == \u0026quot;RGBA\u0026quot;: # 创建一个和图片大小一致的白色背景图片 background = Image.new(\u0026quot;RGB\u0026quot;, image.size, (255, 255, 255)) # 将原图片粘贴到白色背景上，忽略透明像素 background.paste(image, mask=image.split()[3]) # 将合成的图片转换成灰度模式 gray_image = background.convert(\u0026quot;L\u0026quot;) # 将灰度图片再转换成 RGBA 模式，以便保留透明背景 final_image = gray_image.convert(\u0026quot;RGBA\u0026quot;) else: # 如果不是 RGBA 模式，直接将图片转换成灰度模式 final_image = image.convert(\u0026quot;L\u0026quot;) # 获取原图片的文件名和扩展名 file_name, file_ext = os.path.splitext(image_file) # 定义新图片的文件名，添加 _bw 后缀表示黑白 new_file_name = file_name + \u0026quot;_bw\u0026quot; + file_ext # 保存新图片，并优化质量，减少文件体积 final_image.save(new_file_name, optimize=True) # 获取原图片和新图片的文件体积，并返回 old_size = os.path.getsize(image_file) new_size = os.path.getsize(new_file_name) return old_size, new_size # 定义一个文件夹路径，存放所有的图片 folder_path = \u0026quot;images\u0026quot; # 遍历文件夹中的所有文件 for file in os.listdir(folder_path): # 拼接完整的文件路径 file_path = os.path.join(folder_path, file) # 判断是否是图片文件，根据扩展名判断，可以根据需要添加或修改扩展名 if file_path.endswith((\u0026quot;.png\u0026quot;, \u0026quot;.jpg\u0026quot;, \u0026quot;.jpeg\u0026quot;, \u0026quot;.gif\u0026quot;)): # 调用函数，转换并保存图片，并获取文件体积 old_size, new_size = convert_and_save(file_path) # 在控制台展示优化前后的文件体积大小对比 print(f\u0026quot;{file}: {old_size} bytes -\u0026gt; {new_size} bytes\u0026quot;) AI迅速给出了答案，看着很漂亮，用起来也没问题，经验丰富的程序源，会觉得下面的代码不够通用，也没法上生产环境：\n参数固定了 没有日志文件，信息都打印在控制台 图片处理的任务，适合多线程模型 NewBing登场，依据提示，选择了一个问题：这段代码有什么可以改进的地方吗\n这次给的答案，实话，完全超出了预期，一般程序员能想到的优化措施，AI都给出对应的建议\n这段代码可能还有一些可以改进的地方，比如： 可以使用 argparse 库，让用户可以通过命令行参数指定文件夹路径和扩展名，而不是写死在代码里。 可以使用 logging 库，记录程序的运行情况，而不是直接打印到控制台。 可以使用 try-except 语句，捕获可能出现的异常，比如文件打开失败，图片转换失败等，并做相应的处理。 可以使用 multiprocessing 库，利用多核处理器，加速图片的转换和保存过程。 很友好的应答，考虑到部署的环境存在差异，允许不支持多进程\n当然，我很乐意帮你修改一下代码。我尝试添加了 argparse, logging 和 try-except 语句，但没有添加 multiprocessing 库，因为我不确定你的电脑是否支持多核处理。修改后的代码如下： # 导入必要的库 import argparse import logging import multiprocessing import os from PIL import Image # 定义一个函数，将图片转换成黑白，维持透明背景，保存图片，并返回文件体积 def convert_and_save(image_file): # 打开图片 try: image = Image.open(image_file) except Exception as e: logging.error(f\u0026quot;Failed to open {image_file}: {e}\u0026quot;) return None, None # 获取图片的模式，如果是 RGBA 模式，说明有透明背景 mode = image.mode if mode == \u0026quot;RGBA\u0026quot;: # 创建一个和图片大小一致的白色背景图片 background = Image.new(\u0026quot;RGB\u0026quot;, image.size, (255, 255, 255)) # 将原图片粘贴到白色背景上，忽略透明像素 background.paste(image, mask=image.split()[3]) # 将合成的图片转换成灰度模式 gray_image = background.convert(\u0026quot;L\u0026quot;) # 将灰度图片再转换成 RGBA 模式，以便保留透明背景 final_image = gray_image.convert(\u0026quot;RGBA\u0026quot;) else: # 如果不是 RGBA 模式，直接将图片转换成灰度模式 final_image = image.convert(\u0026quot;L\u0026quot;) # 获取原图片的文件名和扩展名 file_name, file_ext = os.path.splitext(image_file) # 定义新图片的文件名，添加 _bw 后缀表示黑白 new_file_name = file_name + \u0026quot;_bw\u0026quot; + file_ext # 保存新图片，并优化质量，减少文件体积 try: final_image.save(new_file_name, optimize=True) except Exception as e: logging.error(f\u0026quot;Failed to save {new_file_name}: {e}\u0026quot;) return None, None # 获取原图片和新图片的文件体积，并返回 old_size = os.path.getsize(image_file) new_size = os.path.getsize(new_file_name) return file_name, old_size, new_size # 定义一个函数，解析命令行参数，并返回文件夹路径和扩展名列表 def parse_args(): # 创建一个解析器对象 parser = argparse.ArgumentParser(description=\u0026quot;Convert images to black and white and optimize quality.\u0026quot;) # 添加一个必选的位置参数，表示文件夹路径 parser.add_argument(\u0026quot;folder_path\u0026quot;, help=\u0026quot;The path of the folder that contains the images.\u0026quot;) # 添加一个可选的参数，表示扩展名列表，默认为 png, jpg, jpeg 和 gif parser.add_argument(\u0026quot;-e\u0026quot;, \u0026quot;--extensions\u0026quot;, nargs=\u0026quot;+\u0026quot;, default=[\u0026quot;.png\u0026quot;, \u0026quot;.jpg\u0026quot;, \u0026quot;.jpeg\u0026quot;, \u0026quot;.gif\u0026quot;], help=\u0026quot;The extensions of the image files.\u0026quot;) # 解析命令行参数，并返回结果对象 args = parser.parse_args() return args.folder_path, args.extensions # 定义一个函数，打印优化前后的文件体积大小对比 def print_result(result): # 如果结果不为空，说明转换和保存成功 if result: # 解包结果为文件名和文件体积元组 if len(result) == 3: file, old_size, new_size = result # 在控制台展示优化前后的文件体积大小对比 logging.info(f\u0026quot;{file}: {old_size} bytes -\u0026gt; {new_size} bytes\u0026quot;) else: logging.info(f\u0026quot;{result}\u0026quot;) # 配置日志记录器，将日志输出到控制台和文件中，设置日志等级为 INFO logging.basicConfig(level=logging.INFO, format=\u0026quot;%(asctime)s %(levelname)s %(message)s\u0026quot;, handlers=[logging.StreamHandler(), logging.FileHandler(\u0026quot;log.txt\u0026quot;)]) # 调用函数，获取文件夹路径和扩展名列表 folder_path, extensions = parse_args() if __name__ == \u0026quot;__main__\u0026quot;: # Windows 需要这个函数的原因是 Windows 缺乏 fork() 函数（这不完全正确）。 # 因此，在 Windows 上，fork() 是通过创建一个新的进程来模拟的，这个新的进程中运行的代码，在 Linux 上是在子进程中运行的。 # 由于这些代码要在技术上无关的进程中运行，所以它必须在运行之前被传递到那里。 # 传递的方式是先将它们序列化，然后通过管道从原始进程发送到新的进程。 # 另外，这个新的进程被通知它必须运行通过管道传递的代码，通过向它传递 --multiprocessing-fork 命令行参数。 # 如果你看一下 freeze_support() 函数的实现，它的任务是检查它运行在哪个进程中，是否应该运行通过管道传递的代码 multiprocessing.freeze_support() # 创建一个进程池，根据电脑的核心数自动分配进程 pool = multiprocessing.Pool() # 创建一个空列表，用于存放异步任务的结果对象 results = [] # 遍历文件夹中的所有文件 for file in os.listdir(folder_path): # 拼接完整的文件路径 file_path = os.path.join(folder_path, file) # 判断是否是图片文件，根据扩展名判断，可以根据需要修改扩展名列表 if any(file_path.endswith(ext) for ext in extensions): # 调用函数，转换并保存图片，并获取文件体积，使用异步方式，不阻塞主进程 result = pool.apply_async(convert_and_save, args=(file_path,), callback=print_result) # 将结果对象添加到列表中 results.append((file, result)) # 关闭进程池，不再接受新的任务 pool.close() # 等待所有的任务完成 pool.join() 后记 由于本地开发是windows系统，AI第一次给出的答案，并没有加上main函数，也没有multiprocessing.freeze_support。通过追问发生的报错，修复了代码。\n就如当年学习搜索引擎的技巧，我们也需要学习一些和AI沟通的技巧，给出合理且充分的限定条件，高效的获取需要的答案。\n注意：如果你是个编程新手，基于给出的注释，还有看不懂的地方，可以继续追问相关代码\n","date":"2023-03-26T20:46:53+08:00","permalink":"https://ttf248.life/p/prompt-engineer/","title":"Prompt 工程师"},{"content":"微信小程序介绍与开发准备\n为什么会有小程序 更好的体验：内嵌网页加载缓慢、白屏；原生应用的体验，更快速的加载 规范与管理：对于微信来说，接入和管理 在小程序发布之前，微信发布过一个SDK叫做JSSDK，开放部分的微信原生能力：微信支付、卡券。但是开发者基于网页开发语言的逻辑来进行开发，能绕过微信的一些监管。小程序有一套自己的描述语言。\n什么是小程序 小程序是一种不需要下载安装即可使用的应用，它实现了应用触手可及的梦想\n用户扫一扫或者搜一下即可打开应用，也体现了用完即走的理念\n用户不用关系是否安装太多应用的问题。应用将无处不在，随时可用，但又无需安装卸载\n小程序和移动应用的区别 无需安装、不占内存、易传播：扫码、小程序卡片、搜一搜\n小程序能做什么 内容工具：知乎热榜、微博热门、摩拜单车、今日头条、腾讯地图、腾讯翻译 零售：拼多多、京东购物、蘑菇街、每日优鲜、小米商城、屈臣氏 游戏：跳一跳、欢乐斗地主、欢乐麻将、斗鱼直播、YY直播 课程内容2018年的，到了现在，部分应用厂商已经倒闭了\n开发准备 注册小程序账号：正常填写信息即可注册，邮箱点击激活链接 信息登记 登录小程序管理后台 完善小程序信息 绑定开发者：个人开发者，登录的微信号为管理员账号，无需额外的绑定操作 邮箱有一定的限制，需要一个新的邮箱，但是QQ邮箱能申请别名，微信后台并不会校验。尝试过后，小程序的名字比较麻烦，但凡涉及到了商标，就容易审核失败。\n服务类目可以选择，也能自定义添加，一个小程序能添加五个类目。\n设置里面能查看小程序的ID信息，也能开启消息推送，启用了消息推送就能使用消息模板功能。\n开发者工具（笔者自述） 正常下载安装，没什么特殊注意事项，简单了解，直接游客模式进入，如果想启用手机调试，也就是手机查看小程序的开发版本，需要登录小程序的开发者账号，然后点击设置，在项目详情里面切换到指定的小程序ID\n代码结构 js: 交互逻辑 json：数据配置 wxml：界面的元素 wxss：界面的样式 ","date":"2023-03-24T21:59:11+08:00","permalink":"https://ttf248.life/p/wechat-mini-program-background-and-development-environment/","title":"微信小程序背景和开发环境"},{"content":"行政通知，办公位变动，从原本的二楼，迁移到十五楼，普普通通的一次工位迁移\n设计感 迁徙 收市打包、轻车熟路，新的工位，调整电脑布线，舒服的姿势开始工作\n(ÒωÓױ)！，接上网线，组里常用的服务器，不能访问了，试着切换无线网络，访问又正常了\n起初呢以为是服务器网段设置问题，新的工位的有线网络，不在防火墙配置的名单里面，联系IT同事调整下就好了；这个网段呢，不止一台服务器，试着访问其他服务器，都是正常的，逐渐产生疑惑？专业的事情交给专业的人来处理，最后运维部门的同事定位到，由于这台服务器部署了docker，服务的默认网络docker0和办公室有线网络配置的网段冲突了，导致发过去的数据包，都收不到应答，被路由给了docker服务。\n其他服务器都没部署docker服务，也就这台，我比较常用，偶尔用容器部署一些测试服务，没想到还能碰到这个场景。后来细想想，由于整个集团都在一个办公大楼里面，IT部门的同事划分网段，用到了172打头的地址也不奇怪。\ndocker0 # vim /etc/docker/daemon.json { \u0026quot;bip\u0026quot;:\u0026quot;172.200.0.1/24\u0026quot; } 重启下服务，切换到新的网络，服务器恢复正常访问。\n参考资料 Docker从入门到实践-docker0\n","date":"2023-03-11T01:42:05+08:00","permalink":"https://ttf248.life/p/office-move-server-inaccessible/","title":"办公室迁移，服务器无法访问了"},{"content":"提到嵌入式，脑海里还是当年学校实验室的51单片机和飞思卡尔。\nLPA3399Pro 是一款基于瑞芯微RK3399Pro平台开发的视觉主机，针对需要大量视觉运算场景的便携式运算主机。它内置NPU计算单元，具有3.0TOPS算力，支持多种算法模型。\nRV1109 是瑞芯微人工智能下机器视觉分支的SoC，内置独立NPU。 RV1109可提供1TOPS算力。\nSystem on Chip SoC 是 System on a Chip 的缩写，意为“片上系统”。它是一种将多个电子系统集成到一个芯片上的技术。这种技术可以大大减小电子产品的体积和重量，同时提高性能和降低功耗。\nSoC（System on a Chip）和 CPU（Central Processing Unit）都是计算机系统中的重要组成部分，但它们之间有一些区别。\nCPU 是计算机系统中的核心处理器，负责执行程序指令。它通常只包含运算单元、控制单元和寄存器等基本部件。\nSoC 则是将多个电子系统集成到一个芯片上，除了包含 CPU 外，还可以集成其他组件，如内存、图形处理器、输入/输出接口等。这样可以大大减小电子产品的体积和重量，同时提高性能和降低功耗。\n总之，CPU 是 SoC 的一个组成部分，而 SoC 则是一个更为复杂、集成度更高的电子系统。\nMicrocontroller Unit SoC（System on a Chip）和 MCU（Microcontroller Unit）都是将多个电子系统集成到一个芯片上的技术，但它们之间也有一些区别。\nMCU 是一种微控制器，通常包含一个 CPU、内存、输入/输出接口等基本部件。它通常用于控制其他电子设备，如家用电器、汽车电子系统等。\nSoC 则是将更多的电子系统集成到一个芯片上，除了包含 MCU 的基本部件外，还可以集成其他组件，如图形处理器、无线通信模块等。这样可以大大减小电子产品的体积和重量，同时提高性能和降低功耗。\n总之，MCU 是一种简单的微控制器，而 SoC 则是一个更为复杂、集成度更高的电子系统。\n","date":"2023-03-07T13:42:36+08:00","permalink":"https://ttf248.life/p/embedded-entry-professional-terms/","title":"嵌入式入门篇1-专业名词"},{"content":"GitHub Copilot 发布也不到两年时间，ChatGPT 问世了，不是很懂背后的原理，都用了一段时间。两个工具的辅助层面完全不同，但是都做到了大幅提高生产力。\n太复杂的事情，AI还做不到，毕竟他们没有逻辑，有套路的或者说范式固定的事情，训练的语料足够，AI的效果能打个九分。\ngithub copilot 发布的时候，看着官网的介绍demo，不是很智能，试用了一下，不是很好用，放弃了。\n2022年前，闲来无事，切换到新版本体验一下，效果已经不错了，就是国内的速度有点慢，大概率是网络的原因。Python之类的语言，依据注释写出来的代码都还不错，比我自己查资料然后编写的速度快了很多。\nChatGPT Github Copilot还停留在程序员，也就是开发的角度来设计产品，你需要懂的如何编程，慢慢的通过注释来引导AI辅助编程。\nChatGPT 走到了下一个层面，让外行人也能迅速上手。对话聊天交互式的设计，你完全可以提出问题，描述需求，不懂的地方，继续提问。\n简单来个例子，知道分词的概念，但是不知道如何编码，想要计算字符串的相似度：\nPython 分词计算 維天運通 LOGORY 和 合肥維天運通信息科技股份有限公司 两个字符串的相似度； 比较前，统一处理字符串，英文转换为小写； 第二个字符中如果能找到第一个字符的首字符，将第二个字符串截位，截位的长度为第一个字符串的长度 你好，这是Bing。😊\n根据网上的信息123，Python 分词计算可以使用 jieba 库来实现。jieba 库支持三种分词模式：精确模式、全模式和搜索引擎模式。你可以根据你的需求选择合适的模式。\n为了比较两个字符串的相似度，你需要先对它们进行分词，然后计算它们的词向量或者编辑距离等指标。你可以使用 numpy 或者 scipy 等库来进行数学运算。\n为了统一处理字符串，英文转换为小写，你可以使用 Python 的内置函数 lower() 来实现。\n为了截取第二个字符串，你可以使用 Python 的切片操作符 [ ] 来实现。\n以下是一个可能的代码示例：\nimport jieba import numpy as np from scipy.spatial.distance import cosine # 定义两个字符串 str1 = \u0026quot;維天運通 LOGORY\u0026quot; str2 = \u0026quot;合肥維天運通信息科技股份有限公司\u0026quot; # 统一处理字符串，英文转换为小写 str1 = str1.lower() str2 = str2.lower() # 找到第二个字符串中第一个字符的位置 index = str2.find(str1[0]) # 如果找到了，截取第二个字符串 if index != -1: str2 = str2[index:index+len(str1)] # 使用 jieba 库进行分词 words1 = list(jieba.cut(str1)) words2 = list(jieba.cut(str2)) # 计算两个字符串的词向量（以词频作为权重） vector1 = np.zeros(len(words1)) vector2 = np.zeros(len(words1)) for i, word in enumerate(words1): vector1[i] += 1 # 统计第一个字符串中每个词出现的次数 if word in words2: vector2[i] += 1 # 统计第二个字符串中每个词出现的次数 # 计算两个字符串的相似度（以余弦距离作为指标） similarity = 1 - cosine(vector1, vector2) print(\u0026quot;两个字符串的相似度是：\u0026quot;, similarity) 更进一步，咨询运行的结果，恭喜你，发现问题了，结果是瞎编的，它并没有实际运行代码，但是会给你一个不错的结果\n栗子 提问：sql 语句，查出产品代码表中，产品代码在这个区间 80000-89999 的记录\n你好，这是 Bing。😊 根据搜索结果12，你可以使用 SQL BETWEEN 运算符来选择给定区间内的值。BETWEEN 运算符包含了开始和结束的值。 你需要先指定要查询的表名和列名，然后在 WHERE 子句中使用 BETWEEN 运算符和区间值。 例如，如果你要查询产品代码表中，产品代码在 80000 到 89999 之间的记录，你可以使用以下语句： SELECT * FROM product_code WHERE code BETWEEN 80000 AND 89999; 这里，* 表示选择所有列3。如果你只想选择特定的列，比如产品名称和价格，你可以用逗号分隔它们，如下： SELECT name, price FROM product_code WHERE code BETWEEN 80000 AND 89999; 希望这能帮助到你。 继续提问，否定它：产品代码是字符串，你的代码错了\n抱歉，我没有注意到产品代码是字符串。如果是这样的话，你需要在区间值两边加上单引号，如下： SELECT * FROM product_code WHERE code BETWEEN '80000' AND '89999'; 请原谅我的错误。🙏 恭喜你，它会认错的。\n","date":"2023-02-28T17:05:17+08:00","permalink":"https://ttf248.life/p/ai-assisted-programming-productivity-evolution/","title":"AI辅助编程，生产力的进化"},{"content":"不常用，但是很有用的git命令\n重装系统导致windows上文件夹所有者信息变更 新版本git增加了安全性校验，提示不安全，导致无法继续操作\ngit config --global --add safe.directory git config --global --add safe.directory \u0026quot;*\u0026quot; 新电脑保存账号密码信息 git config --global credential.helper store 如果保存的信息需要更新，先清理老的凭证\ngit config --system --unset credential.helper ","date":"2023-02-17T10:08:57+08:00","permalink":"https://ttf248.life/p/less-common-git-commands-summary/","title":"几个不常用GIT命令汇总"},{"content":"港交所12月13日宣布，旗下证券市场即将推出“港币-人民币双柜台模式”(以下称“双柜台模式”)及双柜台庄家机制，进一步支持人民币柜台在香港上市、交易及结算。\n双柜台模式及双柜台庄家机制 港交所称，待监管机构批准及市场准备就绪后，各项新措施的登记程序预计可于2023年上半年开始推行。在双柜台模式下，港交所将优化相关交易及结算安排，让投资者可以互换同一个发行人发行的港币柜台及人民币柜台证券。\n为提升人民币柜台的流动性及收窄两个柜台之间的价差，香港交易所将引入双柜台庄家机制，待相关法例经立法会通过后，从事流通量供应活动的市场庄家在进行特定交易时可以豁免印花税。与此同时，各项新措施也将为后续内地投资者通过港股通交易以人民币定价的证券做好前期准备工作。\n“推出港币-人民币双柜台模式及双柜台庄家机制是我们市场发展的重要举措。配合我们的其他市场举措，这一安排将有助吸引更多双柜台证券在香港上市，与港交所现有的内地产品发挥良好的协同效应。港交所致力于积极推动人民币国际化进程和不断提升香港作为全球领先离岸人民币中心的地位。”香港交易所首席营运总监及市场联席主管姚嘉仁表示。\n据悉，港股现行的上市、交易、结算及交收安排亦将大致适用于双柜台模式下的人民币柜台证券。港交所将适时公布双柜台模式的实施日期以及符合纳入庄家机制的合资格双柜台证券名单。\n如何识别港币-人民币交易柜台 港交所文件显示，港币-人民币双柜台交易安排将大致遵循现有股票代码分配计划，即港币柜台的股票代码以“0”开始的5位数字，而人民币柜台的股票代码以“8”开始的5位数字。港币及人民币柜台股票代码的最后四位数将相同。人民币柜台的股票简称将后缀“-R”。\n交易安排方面，在人民币及港币柜台的证券为相同类别且可互相转换的基础上，若其中一个柜台（如港币柜台）是可以进行卖空的指定证券，另一个柜台（如人民币柜台）也可以按照交易所规则被纳入为可进行卖空的指定证券，相应地，两个柜台均会在交易所公布的可进行卖空的指定证券名单中。\n鉴于两个柜台的股票属于同一类别，且可相互转换，购买或以港币持有该股票，以人民币卖出都将被视为持货沽售，反之亦然。两个柜台之间的结算时间是T+2。\n对于符合卖空资格的指定股票，比如以港币借入股票，随后在人民币柜台卖出，将被视为有担保的卖空，反之亦然。\n值得一提的是，在双柜台模式下，由于人民币柜台仅供交易及结算，故不会向人民币柜台提供实物股票存入或提取服务，实物股票只可存入港币柜台之后再转换至人民币柜台。同样，人民币柜台需转换至港币柜台之后才可以提取实物股票。\n相关交易结算及交收的费用，所有香港结算费用，除代收股息服务费及代收利息服务费之外，都以港元计算及收取。代收股息服务费及代收利息服务费是以有关证券所采用的合资格货币计算。\n参考资料 HKD-RMB-Dual-Counter-Model 来源：香港交易所脈搏/HKEx Pulse、券商中国\n","date":"2023-02-16T20:25:47+08:00","permalink":"https://ttf248.life/p/hk-rmb-dual-counter/","title":"港币、人民币双柜台模式"},{"content":"去年设计了一个SDK，负责处理封装一些事件，对外提供一个类接口，服务初始化的时候，调用方实现对应的类，并将对象指针传给模块。 接触过C11，好奇心害死猫，就想着这些接口都用lambda函数对象回调来实现会是什么结果，和纯虚函数的接口定义方法比较，更加灵活。 疑问就出现了，两种不同的语法，从性能角度来说，哪个更快一些？不懂编译原理，弄段代码试试看。\n前言 在线网址，能选择不同编译器，编译参数，在linux平台运行代码，亦或者查看对应的汇编代码。\nhttps://wandbox.org/：有时候做些技术验证，网页执行小片段的代码很省事 https://godbolt.org/：用不同的颜色，区分不同的汇编对应的代码，比本地的调试器看起来更加省事。 正文 标准委员会制定了语法的规则，在编译层面，如何实现，取决于各家的编译器，这里不得不说一声，微软的编译器，挺厉害的。语法糖不是万能的，回调接口不多，使用lambda更加便捷，也无需定义空回调函数接口；回调接口种类繁多的时候，传统的虚函数更有利于业务接口定义的统一。\nwindows平台，两者性能接近，没有太多的差异 linux平台，虚函数和lambda比较，单次多了1.35ns 常规的业务系统开发中，此级别的性能损耗可以忽略，引入lambda，在设计的上，能带来更多的便捷。在设计多信号处理时，尤为明显，底层有事件触发，如果需要落地日志，出入日志对象的的处理函数。当需要更多的业务处理接口时，底层用vector保存lambda对象，事件触发时，依次遍历调用，类似于QT中的信号和槽，日志、监控、业务1、业务2，互相之间完全解耦。\n代码 Counter: 1000000 Time: 3966us Counter: 1000000 Time: 5316us #include \u0026lt;iostream\u0026gt; #include \u0026lt;chrono\u0026gt; #include \u0026lt;memory\u0026gt; #include \u0026lt;functional\u0026gt; #include \u0026lt;atomic\u0026gt; #include \u0026lt;string\u0026gt; std::atomic_int64_t counter = 0; // 定义回调接口 class UserInterface { public: virtual void name() = 0; virtual void full_name() = 0; }; class User : public UserInterface { public: void name() {} void full_name() { counter++; } }; void to_string(UserInterface* user) { user-\u0026gt;name(); user-\u0026gt;full_name(); } using name_handler = std::function\u0026lt;void()\u0026gt;; using full_name_handler = std::function\u0026lt;void()\u0026gt;; class Test { name_handler name_; full_name_handler full_name_; public: void set_name_handler(name_handler name) { name_ = name; } void set_full_name_handler(full_name_handler full_name) { full_name_ = full_name; } void to_string() { name_(); full_name_(); } }; int main() { User user; auto start = std::chrono::high_resolution_clock::now(); for (int i = 0; i \u0026lt; 1000000; i++) { to_string(\u0026amp;user); } auto end = std::chrono::high_resolution_clock::now(); std::cout \u0026lt;\u0026lt; \u0026quot;Counter: \u0026quot; \u0026lt;\u0026lt; counter \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026quot;Time: \u0026quot; \u0026lt;\u0026lt; std::chrono::duration_cast\u0026lt;std::chrono::microseconds\u0026gt;(end - start).count() \u0026lt;\u0026lt; \u0026quot;us\u0026quot; \u0026lt;\u0026lt; std::endl; counter = 0; auto name = []() {}; auto full_name = []() { counter++; }; Test test; test.set_name_handler(name); test.set_full_name_handler(full_name); start = std::chrono::high_resolution_clock::now(); for (int i = 0; i \u0026lt; 1000000; i++) { test.to_string(); } end = std::chrono::high_resolution_clock::now(); std::cout \u0026lt;\u0026lt; \u0026quot;Counter: \u0026quot; \u0026lt;\u0026lt; counter \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026quot;Time: \u0026quot; \u0026lt;\u0026lt; std::chrono::duration_cast\u0026lt;std::chrono::microseconds\u0026gt;(end - start).count() \u0026lt;\u0026lt; \u0026quot;us\u0026quot; \u0026lt;\u0026lt; std::endl; return 0; } 后记 查找资料的时候，翻到类似的代码片段 functionperformance.cpp\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;chrono\u0026gt; #include \u0026lt;memory\u0026gt; #include \u0026lt;functional\u0026gt; using namespace std; using namespace std::chrono; class Base { public: Base(){} virtual ~Base(){} virtual int func(int i) = 0; }; class Derived : public Base { public: Derived(int base = 10) : base{base} { } ~Derived(){} virtual int func(int i) { return i*base; } private: int base; }; struct Func { int base; int operator()(int i) { return i*base; } Func(int base) : base {base} { } }; const int base = 10; int calculate(int i) { return base*i; } int main() { const int num = 10000; Base *p = new Derived{10}; int total = 0; auto start = high_resolution_clock::now(); for (int i = 0; i \u0026lt; num; ++i) { total += p-\u0026gt;func(i); } auto end = high_resolution_clock::now(); std::cout\u0026lt;\u0026lt;\u0026quot;result: \u0026quot;\u0026lt;\u0026lt;total\u0026lt;\u0026lt;\u0026quot;\\nvirtual call elapsed: \\t\u0026quot;\u0026lt;\u0026lt;duration_cast\u0026lt;nanoseconds\u0026gt;(end-start).count()\u0026lt;\u0026lt;\u0026quot; nanoseconds.\\n\u0026quot;\u0026lt;\u0026lt;std::endl; total = 0; start = high_resolution_clock::now(); for (int i = 0; i \u0026lt; num; ++i) { total += calculate(i); } end = high_resolution_clock::now(); std::cout\u0026lt;\u0026lt;\u0026quot;result: \u0026quot;\u0026lt;\u0026lt;total\u0026lt;\u0026lt;\u0026quot;\\ndirect function call elapsed: \\t\u0026quot;\u0026lt;\u0026lt;duration_cast\u0026lt;nanoseconds\u0026gt;(end-start).count()\u0026lt;\u0026lt;\u0026quot; nanoseconds.\\n\u0026quot;\u0026lt;\u0026lt;std::endl; Func functor{10}; total = 0; start = high_resolution_clock::now(); for (int i = 0; i \u0026lt; num; ++i) { total += functor(i); } end = high_resolution_clock::now(); std::cout\u0026lt;\u0026lt;\u0026quot;result: \u0026quot;\u0026lt;\u0026lt;total\u0026lt;\u0026lt;\u0026quot;\\nfunctor call elapsed: \\t\u0026quot;\u0026lt;\u0026lt;duration_cast\u0026lt;nanoseconds\u0026gt;(end-start).count()\u0026lt;\u0026lt;\u0026quot; nanoseconds.\\n\u0026quot;\u0026lt;\u0026lt;std::endl; int base = 10; function\u0026lt;int(int)\u0026gt; lambda = [base](int i) { return i*base; }; total = 0; start = high_resolution_clock::now(); for (int i = 0; i \u0026lt; num; ++i) { total += lambda(i); } end = high_resolution_clock::now(); std::cout\u0026lt;\u0026lt;\u0026quot;result: \u0026quot;\u0026lt;\u0026lt;total\u0026lt;\u0026lt;\u0026quot;\\nlambda call elapsed: \\t\u0026quot;\u0026lt;\u0026lt;duration_cast\u0026lt;nanoseconds\u0026gt;(end-start).count()\u0026lt;\u0026lt;\u0026quot; nanoseconds.\\n\u0026quot;\u0026lt;\u0026lt;std::endl; return 0; } /* test on mac mini i7 2.7GHz clang++ -std=c++11 chronotest.cpp -O0 output: result: 499950000 virtual call elapsed: 43171 nanoseconds. result: 499950000 direct function call elapsed: 31379 nanoseconds. result: 499950000 functor call elapsed: 41497 nanoseconds. result: 499950000 lambda call elapsed: 207416 nanoseconds. =================================================== clang++ -std=c++11 chronotest.cpp -O1 output: result: 499950000 virtual call elapsed: 26144 nanoseconds. result: 499950000 direct function call elapsed: 22384 nanoseconds. result: 499950000 functor call elapsed: 33477 nanoseconds. result: 499950000 lambda call elapsed: 55799 nanoseconds. =================================================== clang++ -std=c++11 chronotest.cpp -O2 result: 499950000 virtual call elapsed: 22284 nanoseconds. result: 499950000 direct function call elapsed: 36 nanoseconds. result: 499950000 functor call elapsed: 30 nanoseconds. result: 499950000 lambda call elapsed: 28292 nanoseconds. =================================================== clang++ -std=c++11 chronotest.cpp -O3 result: 499950000 virtual call elapsed: 18975 nanoseconds. result: 499950000 direct function call elapsed: 29 nanoseconds. result: 499950000 functor call elapsed: 30 nanoseconds. result: 499950000 lambda call elapsed: 22542 nanoseconds. =================================================== clang++ -std=c++11 chronotest.cpp -O4 result: 499950000 virtual call elapsed: 22141 nanoseconds. result: 499950000 direct function call elapsed: 30 nanoseconds. result: 499950000 functor call elapsed: 30 nanoseconds. result: 499950000 lambda call elapsed: 22584 nanoseconds. */ 这里多了两种模式，普通函数和仿函数，提供接口回调的方式和直接调用比较，性能损耗是数量级的差异，仿函数性能和函数接近，有时候仿函数的性能更优，编译原理这块算是知识盲区，猜测是由于访问的变量地址和函数挨着，有利于CPU处理\n附上 wandbox 运行结果\nresult: 499950000 virtual call elapsed: 6143 nanoseconds. result: 499950000 direct function call elapsed: 30 nanoseconds. result: 499950000 functor call elapsed: 31 nanoseconds. result: 499950000 lambda call elapsed: 15134 nanoseconds. ","date":"2023-02-15T13:59:25+08:00","permalink":"https://ttf248.life/p/compiler-callback-performance-testing/","title":"编译器、回调函数、性能测试"},{"content":"在计算机的发展历史中，如何存储数据并没有统一的标准。\n字节的排列方式有两个通用规则。例如，将一个多位数的低位放在较小的地址处，高位放在较大的地址处，则称小端序；反之则称大端序。在网络应用中，字节序是一个必须被考虑的因素，因为不同机器类型可能采用不同标准的字节序，所以均按照网络标准转化。\n按照阅读习惯，大端字节序更符合从左到右的阅读顺序。\n处理器体系 x86、MOS Technology 6502、Z80、VAX、PDP-11 等处理器为小端序 Motorola 6800、Motorola 68000、PowerPC 970 等处理器为大端序 ARM、PowerPC（除PowerPC 970外）、DEC Alpha、SPARC V9、MIPS、PA-RISC及IA64的字节序是可配置的 网络序 网络传输一般采用大端序，也被称之为网络字节序，或网络序。IP协议中定义大端序为网络字节序。 Berkeley套接字定义了一组转换函数，用于16和32bit整数在网络序和本机字节序之间的转换。\n#include \u0026lt;arpa/inet.h\u0026gt; uint32_t htonl(uint32_t hostlong); //把uint32_t类型从主机序转换到网络序 uint16_t htons(uint16_t hostshort); //把uint16_t类型从主机序转换到网络序 uint32_t ntohl(uint32_t netlong); //把uint32_t类型从网络序转换到主机序 uint16_t ntohs(uint16_t netshort); //把uint16_t类型从网络序转换到主机序 如果选用asio作为网络库，内置的命名空间中有跨平台适配的函数名\nboost::asio::detail::socket_ops::network_to_host_long boost::asio::detail::socket_ops::network_to_host_short boost::asio::detail::socket_ops::host_to_network_long boost::asio::detail::socket_ops::host_to_network_short visual studio 调试器 调试模式下，选中调试菜单，窗口，勾选内存窗口\n在visual studio中，可以直接在调试器中查看内存中的数据，如下图所示\n查看内存的方式 窗口直接输出 \u0026amp;变量名，跳转到对应变量地址 如果变量原本就是指针，双击选中变量，拖动到内存窗口，展示对应地址的内容 如果变量不是指针，添加到计算窗口，获取地址，然后手工复制到内存窗口 举个栗子 收到一段数据，存储到buffer对象中，将网络序转成主机序，得到body_length等于 30，服务端划分了四个字节用于传出此数据。\nbool NetworkMessage::decode_header() { // 网络序转成主机序 body_length_ = boost::asio::detail::socket_ops::network_to_host_long(*(int *)buffer_.data()); return auto_reserve(body_length_); } 大端字节序：在内存窗口中，观察 buffer_ 的内容\n小端字节序：在内存窗口中，观察 body_length_ 的内容\n","date":"2023-01-10T14:18:12+08:00","permalink":"https://ttf248.life/p/host-network-byte-order-debugger/","title":"主机序、网络序，通过调试器，直接观察"},{"content":"工作的第七个年头，写代码获取的正反馈不是那么多了，回顾下怎么走上 coding 这条道路 人的各种选择，越是小时候，越遵从正反馈这个事情，主动的避害趋利\n一、小时候 搬家到市区，接触计算机书籍？黑客的资料？认识了 windows 系统？这些都算是后话\n时间应该定位到小时候和堂弟偷摸用家里的电脑玩游戏，堂弟舅舅在电脑城，经营了一个店铺 从小我俩接触计算机的时间就比较早，基本的认知也就建立了，后续在学校，上微机课程，也比较有兴趣 初中听说了计算机竞赛，感觉就很酷，转学后，这事情也就搁置了 我上初中那个年代，熟悉电脑的基本操作，在微机课的时候，比较容易出风头 如果你还熟悉，对，你没看错，不是熟练，熟悉 office 办公软件，那就更厉害了\n二、搬家 回到搬家这事，到了市区，由于邻居的原因，接触到了图书馆，虽说看了挺多的小说，但是也看了很多杂志 《电脑报》《大众软件》 愈发的对计算机这个产物产生了兴趣，小时候心理对于黑客的崇拜，非常积极的去学校相关的知识 认知了操作系统基本的：控制面板、CMD命令、VBS脚本\n《电脑报》小白人群挺适合的，每次都是用案例的形式，科普系统的操作 《大众软件》推荐各种软件，行业新闻，当然还有游戏新闻，最初的动力嘛，也埋下了游戏的种子\n三、高中 高二的时候，博哥转校进入我们班，前两年计算机竞赛保送了好几位前辈，校领导也比较重视这个竞赛 还有个前置的硬件基础，美国有位校友，给学校捐了一栋楼，新的图书馆、新的微机教室，一切都是那么巧合 加上博哥的科普，那会算是班级里面的计算机的大佬\n学霸 + 计算机高手，知道怎么黑别人电脑、杀教室的监控软件\n竞赛磕磕绊绊也是走到了决赛，学的不是很懂，题目都是些一些基础的算法，但是也是有点收获\n不过半桶水终究是半桶水，相当于是去旅游了一趟\n四、大学 等到了大学专业选择，听家里的选了自动化，其实想走的是强电专业，回家进入供电局，专业课程没学多少 自我驱动的学习能力在专业课程基本没有，大课程里面的计算机课程，学起来就很得心应手\n专业课逃课、计算机课程认真学，自己日常泡在论坛：《精易论坛》《吾爱破解》 结合专业学那点汇编、C++知识，从论坛接单赚钱，获取了更多的正反馈，越走越远了，拉不回来 到最后，小专业的选择，选择给芯片写代码，家里也没管那么多，让我自己选了\n这时，第三个关键人物：堂哥，高学历，进入百度 老姐也懂我，知道我那会就没心思考研，让我找堂哥聊聊 确定下后面的发展路线，暑假不回家，跟着导师，做项目，混经历 靠着自己还能看的成绩单，进入了恒生电子\n五、毕业 这里有个关键，我知道翻墙、选修了：计算机信息检索，知道如何快速的查找的和定位资料、问题 工作里面的贵人出现了，硕哥，给了时间让我自己学习，排查问题刨根问题，带着我去认识研发中心的大佬 这些也铺垫了，深圳分公司，对外都认为我很厉害，成功负责了交易通道组\n这里就有个问题，我对于计算机操作系统、算法等基础知识，软件工程设计 没有系统的学习，都是靠自己的历史经验 容易出现，前后否定自己的代码设计，没有准则进行模块设计，到了第七个年头，开始乏力了\n","date":"2023-01-09T13:45:09+08:00","permalink":"https://ttf248.life/p/that-boy-talent-maybe-but-not-much/","title":"那时少年，天分也许有，但是并不多"},{"content":"政策公布的很突然，执行的很迅速，行程码下线、公共场所不再检查绿码。\n浏览纽约时报中文网，整个版面都在讨论中国解封。\n不评价政策，记录周围的情况。\n北京原本就没有清零，政策打开限制，迅速扩散，成片的感染，认识的朋友中，没有重症。\n深圳挨着广州，也开始迅速发展；人在上海带着，由于公司靠近郊区，写这篇稿子时，还没出现大面积感染。\n老家防护措施不多，紧随其后，大面积扩散。\n大部分应该和的感受差不多，突然就放开了，一周一个政策，直到全面放开。\n不能否认三年清零的效果，随遇而安。\n","date":"2022-12-22T19:22:04+08:00","permalink":"https://ttf248.life/p/china-coronavirus-end-lockdown/","title":"中国新冠肺炎解封"},{"content":"翻看代码的时候，std::this_thread::yield() 猛的引入眼帘，C11里面的语法糖，用了不少，yield还是第一次看到，以前都没注意。\n没查手册，首先想到的是不是和异步变成相关，yieldboost库的协程实现里面用到了这个单词，这里肯定和协程没关系，控制逻辑和普通线程相关。\n文档 yield 此函数的准确性为依赖于实现，特别是使用中的 OS 调度器机制和系统状态。例如，先进先出实时调度器（ Linux 的 SCHED_FIFO ）将悬挂当前线程并将它放到准备运行的同优先级线程的队列尾（而若无其他线程在同优先级，则 yield 无效果）\nsleep_for 阻塞当前线程执行，至少经过指定的 sleep_duration 此函数可能阻塞长于 sleep_duration ，因为调度或资源争议延迟 标准库建议用稳定时钟度量时长。若实现用系统时间代替，则等待时间亦可能对时钟调节敏感\n分析 两个函数都是让当前线程不再占用线程，执行的效果按照平台情况而定？看到这里依旧有点云里雾里的，运行代码看看执行效果\nThinkPad 笔记本（visual studio 社区版2022）、腾讯云S2标准服务器（gcc8.5）\n运行平台 函数 第一次/us 第二次/us 第三次/us Windows sleep_for 9872 1884 11302 Windows yield 119 100 100 Linux sleep_for 171 168 167 Linux yield 101 102 101 从运行结果不难理解，由于操作系统实现的不同，高精度的休眠时，sleep_for稳定性差异巨大，如果想要高精度的休眠，使用yield更加合适\n时间精度提升到ms时，两者差异并不明显\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;chrono\u0026gt; #include \u0026lt;thread\u0026gt; // 建议其他线程运行一小段时间的“忙睡眠” void little_sleep(std::chrono::microseconds us) { auto start = std::chrono::high_resolution_clock::now(); auto end = start + us; do { std::this_thread::yield(); } while (std::chrono::high_resolution_clock::now() \u0026lt; end); } int main() { auto start = std::chrono::high_resolution_clock::now(); little_sleep(std::chrono::microseconds(100)); std::this_thread::sleep_for(std::chrono::microseconds(100)); auto elapsed = std::chrono::high_resolution_clock::now() - start; std::cout \u0026lt;\u0026lt; \u0026quot;waited for \u0026quot; \u0026lt;\u0026lt; std::chrono::duration_cast\u0026lt;std::chrono::microseconds\u0026gt;(elapsed).count() \u0026lt;\u0026lt; \u0026quot; microseconds\\n\u0026quot;; } 参考 https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html ","date":"2022-09-20T20:54:51+08:00","permalink":"https://ttf248.life/p/c11-sleep-for-vs-yield/","title":"C11: sleep for vs yield"},{"content":"有台闲置的腾讯云服务器，年底到期，也没想着续费，部署个MYSQL当作开发用的数据库。重装系统的时候，图省事，直接选择了腾讯云提供的三方镜像，已经安装好了MYSQL数据库。原以为系统里面应该自带个Readme之类的文件，说明下密码是什么，部署路径是什么。\n腾讯云重装系统很快，一分钟左右通知已经重装好了，登录进去，systemctl status mysql 服务已经启动了，找找密码在哪里，找了一圈，没找到，逐渐开始自闭。\n这时想着，都已经摸到了服务器，拿着root权限，总归是有法子重置下密码。翻翻资料，阿里云论坛有个帖子，继续折腾。\n重置密码 编辑配置文件 vim /etc/my.cnf，mysqld节点增加配置：skip-grant-tables，执行命令重启数据：systemctl restart mysql\n再使用mysql直接登录数据，接来下就是正常操作了，重置root用户密码，顺带开启下允许远程登录\nUSE mysql; UPDATE user SET authentication_string = password ('pass') WHERE User = 'root'; grant all privileges on *.* to 'root'@'%' identified by 'pass' with grant option; flush privileges; 回退修改的配置文件，重启下数据库，搞定。\n参考资料 https://help.aliyun.com/document_detail/42520.html ","date":"2022-09-20T14:27:35+08:00","permalink":"https://ttf248.life/p/linux-server-reset-mysql-password/","title":"Linux服务器，重置Mysql密码"},{"content":"在中华汉字的庞大体系中，“命”字独一无二，连一个同音字都没有。或许，这冥冥之中暗示着，每个人的生命仅有一次，无可复制，无法重来。\n闲暇时翻翻起点中文网的排行榜，《夜的命名术》的月票数量一骑绝尘，稳居榜首，与第二名拉开了极大的差距，简直望尘莫及。以往多年，我看的多是像唐家三少、耳根这些知名作家的作品，这次决定尝试一下新作者的作品，体验不一样的阅读感受。\n截至八月初，《夜的命名术》的月票数高达两百万，而第二名仅有八万，悬殊的差距令人咋舌。\n我自知才疏学浅，没什么能力去评价这本书的文笔。但通读十几章下来，书中情节紧凑，环环相扣，引人入胜，能收获如此高的月票，确实是实至名归。\n有意思的是，和“命”字一样，“死”字在汉字里也找不到同音字，这是否也蕴含着生命的终结同样独一无二、不可替代的深意呢？\n","date":"2022-08-11T22:10:14+08:00","permalink":"https://ttf248.life/p/nights-naming-art/","title":"夜的命名术"},{"content":"金融交易系统在测试上的投入，远超其他系统，繁琐的测试步骤重复进行，ROI 太低。随着项目和人员的更替，不可避免引入更多的不可控因素，常见的情况，修改的是A接口输出的某个字段，却影响了B接口的结果，每次版本发布，风险也在积累。\n理论知识 如何衡量自动化的价值？ 一个自动化测试案例ROI = （手工运行时间）*（运行次数）/ (开发成本 + 维护成本)\n哪些功能需要做自动化测试？ 用户常用的功能，不会经常改变的功能。针对此类型的接口编写自动化测试代码，收益最高。\n为什么选择这个时间点推动自动化测试？ 临近项目上线，肯定不合适，远水解不了近渴，自动化属于长期收益模型。项目已经在生产环境上线，进入稳定发布周期，此时最为合适。\n框架的选择 缺乏相关实践经验的情况下，拿到自动化测试这么一个任务，常规开局：打开搜索引擎，寻找当前系统技术栈能用上的工具和框架，过一遍使用手册，开工大吉。能立马找个合适的工具，恭喜你，完美开局。\n先说一声我错了，翻查了相关的资料，不是说没有，而是框架本身太复杂了，部署占用的资源也过多。小白入门需要的是小巧的，精简的，咨询测试组的同事，提到了 Python 自建框架，简单来说就是用现有的单元测试框架，封装成自动测试框架。\n参考此项目的设计思路：https://github.com/wintests/pytestDemo\n为什么需要框架？ 服务有多个不同的部署环境，开发环境、测试环境、线上测试环境，框架的作用在于做一层剥离，测试案例和数据进行分离，按照不同的环境配置不同的案例数据，当然也支持公用的数据。\n核心的逻辑都是为了提高自动化的利用率。场景再复杂一些，不同环境之间的数据就是不通的，完全没有任何关系，配置案例数据的时候，增加 label 标签即可，指定当前数据支持的环境。\n参考资料 做性价比最高的自动化测试\n","date":"2022-08-04T11:39:18+08:00","permalink":"https://ttf248.life/p/automated-testing-overview/","title":"浅谈自动化测试"},{"content":"从上学时期开始算，接触 C++ 已经十多年了，为什么需要学习其他的编程语言？\n工作经历：缺乏优雅的模块设计经验，C++ 语法是自由的，学习了其他的语言，也能引导写出更优雅的设计\n编写一些工具的时候，时常会用到\n底层库的设计也好、业务模块实现也好，设计的准则都是想通的\n","date":"2022-08-04T11:27:30+08:00","permalink":"https://ttf248.life/p/why-learn-a-new-language/","title":"为什么需要学习一门新语言"},{"content":"C++跨平台开发，中文操作系统经常能碰到：error C2001常量中有换行符\nvisual studio cmake组织项目编译脚本，windows系统下面开发时，临时生成一份解决方案，跨平台的原因，文件编码选择utf-8。\n引用资料从原理出发详细的解释了问题的的成因\n针对编码，MSVC有专门的编译选项/source-charset和/execution-charset，前者表示文件本身的编码，后者表示编译以后的字符数组内的字节是什么编码，编码问题基本可以用这两个选项解决。\n比如，windows的cmd控制台默认只能显示GBK编码，但是代码文件本身是UTF-8，因为跨平台的缘故，又不方便直接修改成GBK，当然这里就不包括为不同平台写编码转换代码这种办法。在Win10上，可以设置这两个编译选项为/source-charset:utf-8 /execution-charset:gbk，表示让编译器以UTF-8编码读入，然后转为GBK保存在数组里面，这样直接printf就能在cmd控制台上正常显示汉字。\nCMake 针对 Visual studio 设置 if( WIN32 ) message( STATUS \u0026quot;Configuring trade on WIN32\u0026quot;) set( CMAKE_CXX_FLAGS \u0026quot;${CMAKE_CXX_FLAGS} /source-charset:utf-8 /execution-charset:gbk\u0026quot;) endif() 参考资料 https://zhuanlan.zhihu.com/p/146543940 ","date":"2022-08-04T10:51:43+08:00","permalink":"https://ttf248.life/p/visual-studio-character-set/","title":"Visual Studio 编译字符集[转]"},{"content":"不懂政治、不做评论，记录下这场互联网上的“狂欢”\n随笔 前段时间的唐山打人事件、人教小学教材文化入侵事件，不知道还有多少人记得。新闻上的这种热点，已经麻木了，并没有太多感触，下班了照常看剧，这事就看个热闹。经济形势已经这样了，爆发战争，日子并不会变的更好。不懂政治、不做评论，记录下这场互联网上的“狂欢”。\nWiki 概述 2022年南希·佩洛西访问台湾，又称佩洛西访台，是指美国第52任众议院议长南希·佩洛西于2022年访问亚洲国家之旅其间，访问台湾的行程。\n由于美国众议院议长被视为美国第三号人物，并计划访问台湾，日期短期内接近8月1日的中国人民解放军建军纪念日，长期内接近中国共产党第二十次全国代表大会、2022年美国选举及2022年中华民国地方公职人员选举。中华人民共和国方面，其政府提出强烈抗议，派遣海军驱逐舰部队到达台海东北海域，动员山东舰与辽宁舰两个航空母舰战斗群，东部战区与南部战区分别在东海与南海开展大规模实兵实弹演习。美国方面，派遣罗纳德·里根号航空母舰战斗群抵达台海周边护卫佩洛西可能的访台行程，并调遣多批次侦察机与空中加油机至驻日美军嘉手纳空军基地待命。\n中国国家主席习近平与美国总统乔·拜登在访问前曾进行视频会晤，内容涉及台湾问题。台湾与国际媒体透露佩洛西议长及众院访问团将于2日抵达台北松山机场，过夜后将在3日会见中华民国总统蔡英文等政府高层。有观点认为此次佩洛西访问台湾有可能造成自1996年台湾海峡导弹危机，26年来新一次的台湾海峡危机。\n08-11 到今天基本算是尘埃落地，这段时间的头条，基本都是各种沿海军演，知乎也是煞费苦心，每天换着法子更新热榜，说的呢都是这个事情，小编辛苦了。\n","date":"2022-08-02T22:57:54+08:00","permalink":"https://ttf248.life/p/pelosi-visits-taiwan/","title":"佩洛西访问台湾"},{"content":"Linux 平台很简单 du -sh * 一行代码就搞定了。Windows 怎么办呢？磁盘很多，想清理一波，文件很多的情况下，系统自带的资源管理器，统计文件夹大小，速度慢的让你想放弃\nEverything windows 平台下做开发的朋友，没有亲手用过 everything，也应该听朋友提过。搜索速度远超系统自带的资源管理器。既然系统层面支持快速索引文件，肯定就能找到类似的工具，建立文件索引的同时，统计下文件的大小。\nWizTree 官网：https://www.diskanalyzer.com/\n普通的安装模式或者绿色版本解压运行\n速度快，数据展示类型丰富，左侧是树状图模式，右边是文件类型，当然也有图形化展示，在软件底栏。\nSpaceSniffer(update 2023 不再维护更新了) 软件官网：http://www.uderzo.it/main_products/space_sniffer/\n操作很简单，选择对应的盘符，软件会用图形化的方式，展示文件夹体积，体积越大，图像中对应的矩阵也就越大，其余操作，自己点点就明白了，支持输入条件过滤文件：\n文件体积过滤 文件日期过滤 参考资料 https://moe.best/software/spacesniffer.html\n","date":"2022-08-01T19:54:18+08:00","permalink":"https://ttf248.life/p/windows-platform-quick-folder-size-statistics/","title":"Windows平台快速统计文件夹大小"},{"content":"静态博客的主题，主流是基于国外的模板，进行修改调整，没有过多考虑中文内容的排版\n正文 半个月前，调整了一下博客的样式表，工作多年都是做的后端服务开发，前端纯纯的小白一枚。前后折腾了半天，设计上都不太合理。灵光闪现，想到了常看的技术博客：infoq、开源中国，这些站点的排版看着就很不错，能不能借来用用？看了一会源码文件，定位相关的元素弄的一头雾水。\n做前端的朋友看到这里可能要笑了。。定位指定的元素都不懂。不懂没事，周末时间多，停下来思考下，以前写 python 爬虫的时候，好像用到了类似的东西。\n元素审查 没错，就是浏览器自带的元素审查工具，复制样式表、定位指定元素，都是分分钟的事情；selector 定位元素、hugo 新建 user define css\n复制元素 复制 outerHTML 复制 selector 复制 JS 路径 复制样式 复制 XPath 复制完整的 XPath ","date":"2022-07-31T23:36:48+08:00","permalink":"https://ttf248.life/p/how-to-copy-webpage-css-element-inspect/","title":"如何Copy网页样式表（CSS）：元素审查"},{"content":"上海国安数据库事件，黑产圈子里面闹的沸沸扬扬，也不知道真假，过两年如果还记得，再回头看看。根据以往的经验，更新了一波本地的社工数据库资料，看到一个巨型SQL文件：17.9G，一般的文本编辑器，预览都是个问题，更别说打开了，和网友闲聊，提到了：EmEditor。\n正文 官网：https://www.emeditor.com/\n周末抽空试了一下，挺方便的，设计上就支持编辑大型文件，内存足够的情况下，整个文件都载入到内存中，搜索、编辑速度都挺快，也支持分割文件。\n","date":"2022-07-31T23:21:24+08:00","permalink":"https://ttf248.life/p/windows-platform-edit-large-files-emeditor-text-editor/","title":"Windows平台编辑超大型文件：EmEditor (Text Editor)"},{"content":"领导班子在前两天还死要面子的说上海不会封城，上海很重要。结果呢，迫于现状或者说为了保住自己的乌纱帽来了一个隔江相望。先把黄浦江对面封一段时间，然后再封江这边。\n封城 小时候经历过非典，已经没有太多印象，后来看到相关资料，由于潜伏周期比较短，还没出现全国性的扩散就已经结束了。记得那会还在上小学，每天下学都很早，教室里每天都飘着一股消毒液的味道。\n19年底到现在，新冠肺炎疫情也都快三年了。在外打工的人，也都习惯了，该戴口罩的时候戴着口罩。上海这一波疫情反复呢，源头最初是香港，然后通过跨境关口扩散到了深圳，上海这边呢也是由于香港一波输入型病例导致的。官方最后给出通告，由于隔离酒店防护措施不到位导致了疫情扩散，变种后的病毒，毒性是减弱了，但是传播速度变快了，通过酒店的通风系统产生的扩散。最初那会儿其实不严重，还能管控住。\n人总是很自信。上海的领导们也是这样。他们会选择我们能做网格化的风控，精准防控。\n现在的结果大家也看到了，新增已经累计突破了2万，被逼无奈选择了封城，关键对外呢没有用“封城”这个字眼，因为在早前的新闻发布会上，对外宣称，上海不需要封城，算是给自己保留最后的颜面。\n买菜 外卖这个行业呢，是互联网做出来的新兴产业。核心点呢，就是需要有人给你配送对吧，但是由于疫情的大片区域被封锁了，就导致商家能做，关键没有人给你送，整个链路就少了最后一环。在外面的人可能不太理解，上海作为一个国际化的大都市，怎么会大家去一窝蜂的买菜。其实想一想也能明白，大部分的人呢也都是外地过来打工住的呢，是出租房，日常呢是公司食堂，或者在外面的店里吃，很少会在家里自己做。当外面这条路走不通的时候，有条件的就都会开始买菜。由于这种封城的公告并没有提前通知，大家也都没有日常储备那么多粮食或者说蔬菜。也就有了视频里面的一窝蜂的去买菜，在那种情况下聚集直接导致了，疫情的再次扩散。\n行业 从事的都是it行业，疫情对我的影响，体会了一下居家办公，19年那会，在家待了快一个月，前后改签车票十几次，完全没法确定什么时候能返回深圳。餐饮旅游或者很多服务行业，无法想象那些人这几年是怎么过的。\n","date":"2022-03-30T23:03:27+08:00","permalink":"https://ttf248.life/p/shanghai-yuanyang-pot-sealed/","title":"上海鸳鸯锅封城"},{"content":"普通人都是社交动物，没错，你是个人，也是个直立行走的动物，附带很强的社交属性；有自卑心、虚荣心，社会一直在变化，也在一直侵蚀你的平常心。我们不讨论那些伟人，那些甘愿为了社会、为了国家燃烧自己。\n现在的我 按照平均工资来看，或者按照老家的工资来看，我现在的收入已经超出了平均水平一大截，还能有什么不满足的？\n当你赚到了一万，就会想着赚一百万；当你赚到了一百万，就会想着赚一千万，这是常人的天性，人要面对自己的内心\n那眼红的是什么，是更加轻松的赚钱方式：短视频\n大家都懂行业入行不简单。你看到的这是短视频，你没有看到的是后面的拍摄文案编写。但每一个人呢都有一个自己是天才的梦，我适合那个行业，我天生就适合。\n开始接触 刷了那么多的视频。用自己的脑子稍微分析一下很多镜头，明显带着专业的剪辑手法，带着很强烈的电影色彩。等于就是说人家有些。都是科班出身。当然有草根爆红的逻辑，但那儿并不适用于一般人，对吧？\n抖音上呢，还会有很多教你如何去做视频的视频。这个时候人间清醒了，如果真的能赚钱，他为什么不自己做，而来教你做。\n反人类的推荐算法 之前抖音算法在给我推荐电影剪辑、动漫剪辑的时候，刷着刷着，你也会觉得比较有意思。而当我去看了一些关于抖音如何赚钱的时候，他给我推荐的都是各类教学视频，并且会不间断的给你推荐，充斥着我整个推荐流。我自己呢也是在it这个行业。这个时候就会觉得做算法的那群大哥们脑子是不是有那么点问题，你这样推荐，是觉得你傻呢还是我傻呢？关键呢，你还能变着法子给我推荐如何用抖音赚钱的视频，从不同的角度从各种类型你都能来一下。这稿子呢，是我凌晨3点在这写的，本来也不想写。我就觉得这种商业模式能持续多长时间？你能侵吞大家的时间多久？\n活明白 教人做事的时候一套一套的，自己做事的时候控制不了自己，这就是个笑话。不是个纯粹的技术博客编写者，所以有些东西我也没有往国内去发，这里呢我随意的吐槽，如果有一天被封了，那只能说换个地方吧。我不能说抖音什么都没做吧，至少现在实时新闻的传播，国家一些政策的宣传，他也都在积极配合，毕竟在我国呢，你不能违背我党，对吧？\n这时候想想以前读书的时候。当你真的找不到人生的意义，安安静静看一本书就够了。在现在这个时代，还能有多少人静下心来安安静静的看书。\n后记 这里呢也要感谢一手科学技术的进步。如果你能看到这一行，你就会发现整篇稿子非常的口语化。而我呢，真的就是念着念着把它给写完了。本来常用的输入法是搜狗输入法，用了也七八年了。但是语音输入这一块呢，不得不说专业的还是讯飞。\n2022年文章的序号改成了002。为什么会多了两个零呢？有个梦想，今年的文章数量能够破百，对这就是个梦想。也不能说是文章吧，只能说是一些记录。吾日三省吾身，你总归能想到一些东西，对吧？\n","date":"2022-03-27T03:23:53+08:00","permalink":"https://ttf248.life/p/when-you-want-to-make-money/","title":"当你想搞钱的时候"},{"content":" ouuan 弄了四个小时，看到这句话的时候，我还觉得搞笑了，怎么可能这么久？最后一看时间：三个小时。\n算是二零二二年开年的第一篇稿子，要搞的东西不复杂，就和标题说的一模一样（此时的我还很年轻），以为照抄 作业 就行，放到收藏夹里面，拖拖拉拉等了一个多月，终于想起来这个事情。\n迁移到hugo的时候一直觉得插件太少了，不能复制代码，导致很多笔记从印象笔记迁移到博客，复制代码的代码的操作就变得繁琐了，严重耽误我水博客的动力。\n序章 先仔细看看原作者的稿子，通读一遍然后翻翻作者介绍，我靠，碰到个大佬了，清华在读本科生，很早就接触到了计算机，诶，就是皮，先翻翻这个博客再说，完全不记得自己要做什么事情。顺带翻翻作者的Github仓库，这个修改后的even主题比现在的好看多了，新功能也多，搞起来，先把相关代码合并到过来。\n新功能：查看文章历史、关联递交记录 效果还是不错的，拖到文章末尾就能体验。\n动手前也没太细看作者原仓库的历史记录，以为简单的合并下就好了，最后合并了一堆代码，中间还冲突和N次，无脑覆盖，都是前端和渲染的模板代码，以我要的为准。\n仓库地址：https://github.com/TianlongXiang/hugo-theme-even\n中文的一个坑，git不调整这个参数，会导致生成的获取不到当前文章的commit hash，导致历史链接生成失败；生成文章完整历史的时候也需要改改自动集成脚本，记得拉取当前仓库全部的历史记录。\nfeat: 尝试拉取完整 github 仓库，用于动态更新文章最后一次改动记录 chore: 路径存在中文，hugo GitInfo 需要启用此设置 name: Build Github run: git config --global core.quotePath false \u0026amp;\u0026amp; hugo -b \u0026quot;https://www.xiangtianlong.com/\u0026quot; -d \u0026quot;github_public\u0026quot; \u0026amp;\u0026amp; ls 样式调整 调整站点内容宽度，之前的设计适合移动端和电脑端，实际上也没人手机上看，我自己都是电脑上看 目录栏支持自动伸缩 正文 参考ouuan的代码记录看了半个多小时，愣是没太看懂怎么增加的复制按钮。\n时光穿梭，一月之后，又想到这事\n既然这个作业没看懂，换个作业抄，总归能抄明白。搜索出来的结果，还挺让人意外，hugo官方的论坛里面就有个帖子提到了如何增加复制按钮，跑过去一看，逻辑清晰。懵逼的事情来了，回到的站点一看even渲染生成的代码块样式和资料中的描述不同，这块就比较啰嗦了，简单记录下。\n由于基本不懂前端开发，不懂的地方就开着浏览器审查元素，对着代码分析、靠着右边的样式器信息，慢慢也分析懂了逻辑；JavaScript没看懂，控制台来点日志。不懂的时候很多，静下心，慢慢梳理拆分逻辑，总归能找到思路。\npre节点有多个，这里指的是单个代码块，主题自己渲染了一行号出来，导致复制按钮出来两个 想要关点主题自带的代码高亮渲染，奈何这个主题设置不熟悉 hugo官网看资料，看了个半懂，知道有markup设置能控制代码高亮 调整配置文件，一直不对劲，渲染出来和预期不同 发现这堆设置pygmentsOptions，又继续翻资料，调整设置，先去掉行号 配置自定义的css样式表，配置自定义的js脚本 既然都搞了这么多事情，脑子突然想到最近看到一个配色图不错，改改按钮的样式：中国风天青色走起 ouuan 弄了四个小时，看到这句话的时候，我还觉得搞笑了，怎么可能这么久？最后一看时间：三个小时。\n参考链接 https://ouuan.github.io/post/from-hexo-to-hugo/ https://gohugobrasil.netlify.app/content-management/syntax-highlighting/ https://gohugo.io/getting-started/configuration-markup#highlight https://www.dannyguo.com/blog/how-to-add-copy-to-clipboard-buttons-to-code-blocks-in-hugo/ ","date":"2022-02-25T01:23:39+08:00","permalink":"https://ttf248.life/p/add-copy-button-for-simple-task/","title":"以为很简单的事情，增加一个代码复制按钮"},{"content":" 王羲之说：夫人之相与，俯仰一世，或取诸怀抱，悟言一室之内；或因寄所托，放浪形骸之外。\n人这一生，如昙花一现。如草木春绿枯荣，如曦月东升西落。\n偏偏这一生欲望却有很多。\n小时候溪头卧剥莲蓬，忙趁东风放纸鸢，急走追黄蝶，\n也傍桑影学种瓜，归来饭饱黄昏后，不脱蓑衣卧月明。\n长大后希望金榜题名，希望有佳人相伴，希望钱财不断，希望节节高升，希望高朋满座，希望夜夜笙歌。\n老了又想要健康长寿，童仆欢迎，稚子候门，有一盘棋，一知己，一壶酒，一庭院，安享天伦。\n你看世人慌慌张张，不过图碎银几两。偏偏这碎银几两，能解世间万种惆怅。\n有一大半的人还在为生活挣扎，哪里有时间去追寻意义？\n其实人这一生，不过是一场体验，就和草木，日月一样，体验这欲望的轮回。\n活不明白就会觉得，寄蜉蝣于天地，渺沧海之一粟。哀吾生之须臾，羡长江之无穷。活明白了就会欣于所遇，暂得于己，快然自足，不知老之将至。\n你可以追求这金钱名利，你也可以追求诗酒花茶，你可以追求江上之清风，也可以追求山间之明月。\n但是不用过分在意追求的结果，结果终将逝去。\n穷极一生，来到人间，尽可能体验世间的喜怒哀乐，生老病死。\n很喜欢大鱼海棠的这句话。\n我们这一生很短，我们终将会失去它，所以不妨大胆一点，爱一个人，攀一座山，追一次梦，不妨大胆一点，有很多事情没有答案。\n很喜欢《兰亭集序》和《赤壁赋》。\n每揽昔人兴感之由，若合一契，未甞不临文嗟悼，不能喻之于怀。固知一生死为虚诞，齐彭殇为妄作。后之视今，亦犹今之视昔。悲夫！\n","date":"2021-08-31T21:09:58+08:00","permalink":"https://ttf248.life/p/what-we-seek-throughout-life/","title":"我们穷极一生追寻的是什么"},{"content":"不常见，时间长了肯定能碰到，关联股票代码：伯克希尔\n正文 部分股票代码的名称中包含 . 或者其他特殊字符，通过 Fix 报送给盈透（IB）时，需要针对股票代码名称进行一定的转换\nBRK/B -\u0026gt; BRK B\n针对盈透证券的情况，能分析出来，转换的规则是固定的，编码实现即可。当规则不固定的时候，一般系统内部需要存储对应的映射关系，业务操作人员定时更新。\n参考链接 How do I enter the symbol for Berkshire Hathaway Class B shares onto TWS?\n","date":"2021-08-30T17:35:59+08:00","permalink":"https://ttf248.life/p/interactive-brokers-stock-code-format-explanation/","title":"盈透证券股票代码特殊格式说明"},{"content":"常常在人生的某个阶段，人会陷入一种迷茫，不知道自己究竟想要什么，在工作的琐碎日常里，渐渐迷失了对工作意义的追寻。回想起刚毕业时，内心满是炽热的憧憬，那时的我会毫不犹豫地说，我渴望写代码，写出能让人眼前一亮的、超厉害的代码。可工作至今，更多接触到的是业务层面的事务，这其中更多得益于行业发展带来的红利。\n在生活观念上，我还没有把结婚生子、成家立业这些事纳入自己的思考范围，脑子里几乎什么都没想，只想着享受当下。每到周末，我就喜欢安安静静地打游戏，常常能一整天都宅在家里，沉浸在自己的小世界里。\n人这一辈子，总归需要有点自己热爱并全心投入的事情。\n买房 前两年，我还满心想着要努力存钱买一套属于自己的房子，每天都在为这个目标精打细算。然而，看着房价一路飙升，我从最初的焦虑、不甘，到最后变得麻木，渐渐觉得即便买了房，也不过是给自己套上了一个沉重的包袱，最后便放弃了这个想法。\n存钱 起初，存钱是为了实现一些小目标，比如配一台性能强劲的台式机，购置一台心仪已久的相机，或是来一场说走就走的旅行。但现在，我以一种更佛系的态度对待存钱这件事，在日常开销上不再有太多顾虑，看到想吃的东西就去吃，对新奇的事物也能大胆去尝试。\n回家 到最后，我发现自己内心深处最渴望的，不过是回家看看。不需要做什么特别的事，仅仅是回到那个熟悉的地方，感受家的温暖与宁静 。\n","date":"2021-08-26T18:01:06+08:00","permalink":"https://ttf248.life/p/lost-and-confused/","title":"迷茫了"},{"content":"随着金融市场不断演变，投资者已开始寻求更有效的投资工具以增加其投资回报。为了迎合投资者的需求，香港交易及结算所有限公司（香港交易所）推出了一系列股票期货合约，这些合约所代表的股票均在香港交易所全资附属公司香港联合交易所有限公司（联交所）上市，不但流通量高，交投也很活跃。透过投资于股票期货，投资者可参与个别上市公司表现之余，亦可享受衍生品市场提供的沽空及杠杆效应等方便。\n由于股票期货所代表的股票均为所属行业的表表者，投资者如认为某一行业的表现会优于或逊于整个股票市场的表现，可以相应选择投资该行业的股票期货。\n基本定义 股票期货合约是一个买卖协定，注明于将来既定日期以既定价格(立约成价)买入或卖出相等于某一既定股票数量(合约成数)的金融价值。\n所有股票期货合约都以现金结算，合约到期时不会有股票交收。\n合约到期 合约到期时，相等于立约成价和最后结算价两者之差乘以合约乘数的赚蚀金额，会在合约持有人的按金户口中扣存。\n最后结算价是相关股票于最后交易日当天的联交所报的正式收市价。\n如果股票期货的投资者希望在合约到期前平仓的话，原先沽空的投资者只须买回一张期货合约，而买入合约的投资者则卖出一张期货合约。\n保证金 在进行期货交易时，买卖双方均需要先缴付一笔基本按金，作为履行合约的保证。结算所在每日收市后会将所有未平仓的合约按市价计算盈亏，作为在投资者按金户口中扣存的依据。如果市况不利使投资者蒙受亏损，令按金下降到低于所规定的水平，期交所会要求投资者在指定时限内补款，使按金维持在原来的基本按金水平(即补仓)。\n优点 交易费用低廉：每张股票期货合约相等于数千股股票的价值，而买卖合约的佣金则视乎张数而定，所以交易成本相对合约价值而言极低。 沽空股票更便捷：由于投资者可以便捷地沽空股票期货，所以在跌市时，投资者可藉着沽空股票期货而获利。 庄家制度：为确保市场的流通充裕，香港交易所规定市场庄家在一个指定的差价范围内同时提供买入价及卖出价，使股票期货市场保持流通。 杠杆效应：投资者买卖股票期货合约只需缴付占合约面值一小部份的按金，令对冲及交易更合乎成本效益。 减低海外投资者的外汇风险：股票期货合约为海外投资者提供投资本地优质股票的途径，因为买卖股票期货只需要缴付按金，而非全部的合约价值，故大大减低了海外投资者所要承受的外汇风险。 透过电子交易系统进行买卖：股票期货合约采用期交所的电子交易系统进行买卖。所有买卖盘会按价格及时间的先后次序执行对盘，并能即时显示买入价，卖出价及成交价，令市场透明度达到最高水平。 结算公司提供履约保证：股票期货合约将由期交所全资拥有的香港期货结算有限公司(结算公司)登记、结算及提供履约保证。由于结算公司为所有未平仓合约的对手，因此，结算所参与者之间将无须承受对手风险。但是，保证的范围并不包括结算所参与者对其客户的财务责任；而投资者选用经纪进行买卖时必须小心慎重。 庄家制度 市场参与者或于个别股票期货注册成为市场庄家，并在指定的最大差价范围内同时提供买入价和卖出价。交易所参与者及其客户须注意个别股票期货可能没有市场庄家登记提供买卖差价而其买卖将以市场买卖单位为基础。投资者应留意买卖没有市场庄家登记的股票期货可能涉及流通性风险，入市前应谨慎考虑。\n买卖股票期货的风险 股票期货涉及高风险，买卖股票期货所招致的损失有可能超过开仓时缴付的按金，令阁下或须在短时间内缴付额外按金。若未能缴付，阁下的持仓或须平仓，任何亏损概要自行承担。因此，阁下务须清楚明白买卖股票期货的风险，并衡量是否适合自己。阁下进行交易前，宜根据本身财务状况及投资目标，向经纪或财务顾问查询是否适合买卖期货及期权合约。\n调整注释 倘正股公司以供股或派发红股等形式更改其股本结构，将会导致股价在除净权益时或生效日期时出现改变，而未平仓合约亦可以因而受到影响。\n如果其他情况不变，股东持有的组合价值并不会再除净日改变，但对股票期货的买家或者持有人来说，情况则有所不同，除非期货合约中作出适当的调整。如果没有改变立约成价，而股票期货的合约乘数又保持不变，股价的调整将会对股票期货持仓的价值造成无理及不公平的影响。\n结算所决定调整比率时，以维持期货合约的公平价值为原则，并只会在出现重大改变时作出调整。香港交易所会公布调整的详情，而交易所参与者需告知客户有关变化。\n股票期货合约概要 资讯供应商代码 参考资料 香港交易所 - 衍生产品/个股/股票期货\nHKEX_Stock_Futures_SC.pdf\n","date":"2021-08-18T10:54:50+08:00","permalink":"https://ttf248.life/p/hong-kong-futures-basics/","title":"港股期货基本概念"},{"content":"最近两个交易日股市大跌，新入场的韭菜们见识到了市场的风险。我国即将进入老龄化阶段，生育率的数据也是惨兮兮，降低的幅度大幅超出了相关专家的估计，阻挡生育率的绊脚石行业，我党都将重拳出击。\n学生减负 九十年代出生的我们，没有那么多的兴趣班，科目辅导班，放学了撒了疯的玩，首先是家里的条件不允许、其次是当时的辅导班尚未产生品牌效应，让家长信服他。转眼二十年过去，19年开始的K12教育资本化，猿辅导等作为代码的线上辅导班横空出世，资本的加持下，集中优秀的资源打造出来各种名牌辅导班，天价的费用也挡不住家长的热情。\n城市化的进程中，很多家长都是通过读书这条路，脱离寒门，完成了阶级的跃迁，自己作为社畜的工作，没有太多的时间照顾孩子，不仅自己很卷，也不希望孩子落后同辈；寒门难出贵子，没有合适的学历，普通的家庭在中国，其他的路径维持当前的阶级或者再次阶级跃迁很难，如果进入职业高中，在当前的社会环境中，以为这阶级的滑落，这是大部分家长无法接受的。\n我们回头看看为什么会有课外辅导，家长为什么需要课外辅导？课本的知识和例题都是一看就懂，很多科目涉及面很广，不过都是粗浅的概念，并没有太过深入。人才的选拔机制需要有一定的区分度，这就导致了一个矛盾点，试题单单从课本知识出发，无法达到筛选的作用，需要横向拓展、纵向拓展。这些内容都是老师无法在课堂上覆盖的方面，这个空间的存在，培育了养活课外辅导的土壤。\n文件内容很多，三十条细则规范了多个方面，指导文件大纲摘要：\n全面压减作业总量和时长，减轻学生过重作业负担 提升学校课后服务水平，满足学生多样化需求 坚持从严治理，全面规范校外培训行为 大力提升教育教学质量，确保学生在校内学足学好 强化配套治理，提升支撑保障能力 精心组织实施，务求取得实效 精英教育 在教育行业，其实还有一个现象，厉害的民办中学越来越多，公立学校的优质资源不够用了（衍生学区房）。各种规模化的教育集团，通过高薪待遇，拉拢优质的老师，建立优质的教学环境，逐步树立各自的品牌，最为出名的：衡水模式。老家平均公司三千多，厉害的民办小学，一个学年的费用九千到一万。教育集团形成一个良性的循环，我学费贵，但是老师厉害，学生成绩好，我提高学费，家长还是会把孩子送过来。公办的资源（老师）也会逐步被民办的学校吸引过去，最终沦为劣质教育的代名词。\n算法压榨 有数据表示，美团签约的骑手接近四百万，活跃的骑手四五十万，很多人依赖这份工作养家糊口，无止境的算法压榨配送时间，将人换算为可计量的单位，投入到算法中计算，不断的探索配送员的崩溃边界。自己以为很聪明，违背人性，服务资本。市场在这里放着，大家好好玩，可持续发展的玩，而不是搞垄断、搞特权，资本主义的玩法，肆意的野蛮的生长终将落幕。\n股市波动 二零二一年七月二十四号，新东方为代表的教育股表演花式跳水，美股盘前好未来紧接其后，股价腰斩。\n我国已经逐步进入老龄化，各种影响计划生育的社会现象，必然要被整治；垄断、加班的互联网公司被罚款了，资本聚集的教育行业也被整治了\n不允许教育行业被资本化，一票直接否定相关行业进行上市融资，哀嚎一片。\n腰斩的新东方 暴跌的美团 参考链接 监管密集出拳，在线教育急“刹车”\n国务院办公厅印发《关于进一步减轻义务教育阶段学生作业负担和校外培训负担的意见》\n","date":"2021-07-28T14:59:08+08:00","permalink":"https://ttf248.life/p/capital-monopoly-and-the-fall-of-online-education/","title":"资本垄断和在线教育行业的落幕"},{"content":"一种破坏系统的模式，进行系统稳定性测试\n正文 国内的互联网行业总是喜欢折腾点新东西出来，有时候听到个名词，一般人都想不到它是什么东西？\n看了部分文章，还是这段针对混沌工程初期的定义，较为容易接受\n混沌工程的早期探索，其实在行业内一直有，曾经是以故障测试、容灾演练等身份存在。而随着微服务架构的不断发展，以及分布式系统的不断庞大，混沌工程开始崭露头角，越来越被重视。当 Netflix 正式提出混沌工程概念后，相关理论也开始飞快丰富。Netflix 的实践也证明了混沌工程在稳定性领域所带来的巨大意义。\n参考链接 字节跳动混沌工程实践总结\n","date":"2021-07-28T14:35:07+08:00","permalink":"https://ttf248.life/p/chaos-engineering/","title":"混沌工程"},{"content":"Deployment控制器实现了Kubernetes集群中一个很重要的功能，Pod的水平拓展和收缩功能。这个功能是传统云时代平台所必备的能力。\n碰到一个业务场景，需要修改数据库中的数据，调整后重启Pod节点。但是在Pod运行过程中，一直在修改表字段，需要临时性的暂停应用对表的更新，调整数据后恢复Pod。\n除了暴力的删除Deployment，有没有其他的方式，实现类似暂停的效果？\nkubectl scale --replicas=0 deployment/\u0026lt;your-deployment\u0026gt; 在看到答案之前，很多人可能都没想到，看到答案后，会心一笑，脑子没有转弯，思路还停留在直接操作进程的时代，想着直接操作业务进程。\n参考链接 how to stop/pause a pod in kubernetes\n","date":"2021-07-12T11:23:09+08:00","permalink":"https://ttf248.life/p/kubernetes-pause-pod/","title":"kubernetes暂停pod"},{"content":"90年代出生的我们这辈人，08年的金融危机，大部分都没太多的感觉，毕竟那会还年轻，也没到理财的年纪。2015年的牛市来的轰轰烈烈，走的时候动静也不小，最后还是国家出手救市。与此同时，也让基金这个概念，走入了普通人的视野中。\n蚂蚁金服和支付宝 支付宝作为蚂蚁旗下天然的流量入口，出生就是定位支付工具，支付宝购买基金和微信购买基金，大部分人都选择了支付宝。支付宝也成功的把基金销售变成了普通的购物，2019年开始的小牛市，基金经理的报团取暖，归根结底还是疫情引导的货币大放水。入场的人都赚到了，没入场的看到了也眼红，赶着入场。新基金规模突破百亿的速度越来越快，在大妈都开始买基金的场景中，千亿基金也不远了。\n在以蚂蚁为代码的互联网基金销售平台火爆前，平明百姓接触基金销售多是在银行存钱的时候，大堂经理会热情的来介绍各种理财。互联网的包装、推销页面信息的引导，基金销售机构给的天价广告费，让支付宝给出的基金广告完全脱离理性。\n正常银行定期理财收益 4%，前些年玩的很疯的P2P理财 8%，信用卡还款利息 12%。我们的主角，支付宝推广的基金 150%、250%，市场上行，场内的人都开心，市场下行？支付宝是在玩火诶。给出的涨幅数据中，台面上只写了最近三年的收益图，老牌基金只写了年化的平均收益，为什么不敢单独写出来每年的平均收益？是因为很难计算？答案是否定的，因为数据不好看，不容易引导客户购买基金。\n固收理财 中国还没步入负利率时代，银行存款、国债是最为稳妥的固收产品；纯债的基金也是不错的，中国的平均工资多少，各位自行查阅各地统计局公布的数据即可。笔者写个简单的场景，资产规模 200万，年化收益 4%折算，每年的收益都超过了大部分城市的平均工资。\n后记 更多的是从我个人的经历出发，能写的很多，想了解更多的，推荐自行多去看看经济类的书籍，不要盲从。普通的家庭，理财的核心是保值、不是去玩火梦想暴富。\n大伯常说的一句话：\n合适的时间做合适的事情，价值是最大的；读书的时候认真读书，拿到好的学历比你发传单赚零用钱更好；刚毕业的时候认真工作，工资的涨幅能带你丰厚的回报；成家的时候，要学会照顾家里。\n有兴趣的可以去看看这篇演讲稿：关于光阴，你要读很多书才能找到答案，本站有文字稿。\n","date":"2021-07-09T11:27:06+08:00","permalink":"https://ttf248.life/p/funds-and-fixed-income-wealth-management/","title":"基金和固收理财"},{"content":"中断交易是指当一个交易执行已经发生，并且IB收到来自交易所的执行信息。然后交易所意识到出现了某种错误（比如，定价、电子处理过程、明显的错误，等等），并决定中断（取消）该交易。这个过程完全由交易所来决定和控制。\nA busted traderefers to a situation where an execution occurs and IB receives the execution messagefrom the exchange. The exchange then realizes some type of error (Pricing,electronic, obvious error, etc) and rules to bust (cancel) the trade. Theexchange makes these rulings entirely on their own.\n从交易的角度出发，相当于港交所的成交取消和成交修正。\n","date":"2021-06-22T10:51:59+08:00","permalink":"https://ttf248.life/p/interactive-brokers-trading-interruption/","title":"盈透证券：中断交易"},{"content":"金融软件开发的第五个年头，打交道最多的就是各种交易所的接口文档，熟悉的也是港交所的文档，近期处理中华通业务，涉及到了部分中华通业务，顺手查阅了深交所和上交所的资料\n港交所 官网链接\n常用 交易時間，交易和結算日曆 交易机制 中港金融詞彙對照表 滬港通及深港通交易日曆 PDF 滬港通及深港通交易日曆 CSV 中港金融詞彙對照表 PDF 市调机制冷静期触发记录 证券名单：基本信息、证券分类 收市竞价交易时段证券 市场波动调节机制（市调机制）证券 可进行卖空的指定证券 证券名单：基本信息、证券分类 XLSX 行情接口文档：港股 + 中华通 行情接口文档汇总链接\n常见问题答疑、指引开发手册、历史行情接口文档可以通过搜索栏获取下载地址，搜索历史版本号\n港股证券行情接口文档 中华通行情接口文档 HKEX_OMDC_Binary_Interface_Specifications_v_1,-d-,32c.pdf HKEX_OMDC_Developers_Guide_1_11.pdf OMDC_Connectivity_Guide_Securities_Market-Index_datafeed(v2_2).pdf OMD_Interface_Specification_China_Connect_Securities-(v1-3).pdf OMD_Connectivity_Guide_China_Connect_Securities.pdf OMD_Developers_Guide_China_Connect_Securities.pdf 报盘接口文档：港股 + 中华通 报盘接口文档汇总链接\n港股FIX协议接口文档 PDF 港股二级制协议接口文档 PDF 港股交易所错误代码清单 XLSX 中华通Fix协议接口文档 PDF 中华通二进制接口文档 PDF 上交所 行情报盘接口文档\n报错接口文档在其他菜单中获取\n报盘报错接口文档 XLSX\n深交所 行情报盘接口文档\n深交所没有提供单独的报错信息说明，在报盘接口文档的第六章有附加说明\n深圳证券交易所Binary交易数据接口规范（Ver1.18）PDF\n纳斯达克 假期安排 新股上市信息 收市价 全球市场收市价\n","date":"2021-01-27T14:35:21+08:00","permalink":"https://ttf248.life/p/exchange-interface-documentation/","title":"交易所接口文档汇总"},{"content":"工作多年接触到的都是centos操作系统，如果是mac用户或者Ubuntu用户，部分内容无法适用。\n安装部分可以参考清华大学的手册：https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/\n安装 由于不可知的神秘力量，国内安装docker推荐设置云厂商提供的仓库地址，这里推荐使用阿里云\n设置仓库源地址 yum install yum-utils device-mapper-persistent-data lvm2 \u0026amp;\u0026amp; \\\rsudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\r部署最新版本 docker作为常用的后台服务，推荐设置为开机启动，当前命令适用于centos7\nsudo yum install -y docker-ce docker-ce-cli containerd.io \u0026amp;\u0026amp; systemctl enable --now docker\r部署指定版本 kubernetes和docker的发布并没与完全同步，如果接下来需要部署kubernetes，请参考kubernetes部署说明，安装指定版本的docker\nyum list docker-ce --showduplicates | sort -r\rsudo yum install -y docker-ce-18.09.2-3.el7 docker-ce-cli-18.09.2-3.el7 containerd.io-18.09.2-3.el7 \u0026amp;\u0026amp; systemctl enable --now docker\r普通用户添加docker权限 sudo usermod -aG docker ${USER}\r卸载 sudo yum erase -y docker-ce docker-ce-cli containerd.io\r日常使用 镜像加速 依旧存在不可知的神秘力量，导致拉取镜像的时候速度不给力，此时国内的云厂商站出来了，提供了很多加速服务，依旧推荐一波阿里云\n加速的地址各位看管自己注册阿里云账号获取，此服务免费，阿里云也提供免费的镜像构建服务\ncat \u0026gt; /etc/docker/daemon.json \u0026lt;\u0026lt;EOF\r{\r\u0026quot;registry-mirrors\u0026quot;: [\r\u0026quot;https://docker.nju.edu.cn\u0026quot;,\r\u0026quot;https://mirror.baidubce.com\u0026quot;,\r\u0026quot;https://docker.m.daocloud.io\u0026quot;,\r\u0026quot;https://docker.mirrors.sjtug.sjtu.edu.cn\u0026quot;\r]\r}\rEOF\rsystemctl daemon-reload \u0026amp;\u0026amp; \\\rsystemctl restart docker\r强烈推荐的控制面板 docker volume create portainer_data \u0026amp;\u0026amp; \\\rdocker run -d --name=portainer --restart=always -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:2.20.3-alpine\r常用镜像拉取合集 docker pull rancher/rancher:stable \u0026amp;\u0026amp; docker pull portainer/portainer-ce:2.0.1 \u0026amp;\u0026amp; \\\rdocker pull centos:7 \u0026amp;\u0026amp; docker pull ubuntu:20.04 \u0026amp;\u0026amp; docker pull ubuntu:18.04 \u0026amp;\u0026amp; \\\rdocker pull redis:5 \u0026amp;\u0026amp; docker pull redis:6 \u0026amp;\u0026amp; \\\rdocker pull alpine:3.11 \u0026amp;\u0026amp; docker pull busybox:1.32 \u0026amp;\u0026amp; \\\rdocker pull rabbitmq:3.7-management \u0026amp;\u0026amp; \\\rdocker pull mariadb:10.2 \u0026amp;\u0026amp; \\\rdocker pull nginx:1.18 \u0026amp;\u0026amp; docker pull nginx:1.19 \u0026amp;\u0026amp; \\\rdocker pull mysql:5.6 \u0026amp;\u0026amp; docker pull mysql:8 \u0026amp;\u0026amp; \\\rdocker pull elasticsearch:6.8.11 \u0026amp;\u0026amp; docker pull logstash:6.8.11 \u0026amp;\u0026amp; docker pull kibana:6.8.11 \u0026amp;\u0026amp; \\\rdocker pull zookeeper:3.4 \u0026amp;\u0026amp; \\\rdocker pull influxdb:1.7 \u0026amp;\u0026amp; docker pull grafana/grafana:7.3.1 \u0026amp;\u0026amp; \\\rdocker pull percona:8 \u0026amp;\u0026amp; docker pull percona:5.6 \u0026amp;\u0026amp; \\\rdocker pull cloverzrg/frps-docker:0.34.3 \u0026amp;\u0026amp; docker pull cloverzrg/frpc-docker:0.34.3\r常用组合命令 https://docs.docker.com/engine/reference/commandline/docker/\n查看容器运行状态，附加format参数，查看详细的容器信息，此时不关注镜像信息\ndocker ps --format \u0026quot;{{.Names}}: {{.Ports}}: {{.Size}}\u0026quot;\r#portainer: 0.0.0.0:8000-\u0026gt;8000/tcp, 0.0.0.0:9000-\u0026gt;9000/tcp: 0B (virtual 172MB)\r#influxdb: 0.0.0.0:8086-\u0026gt;8086/tcp: 183B (virtual 311MB)\r一键停止所有容器\ndocker stop $(docker ps -a -q)\r一键删除所有镜像\ndokcer rmi $(docker images -a -q)\r导出镜像\ndocker save \u0026lt;IMAGE NAME\u0026gt;:\u0026lt;IMAGE TAG\u0026gt; \u0026gt; -o XXX.tar\r导出镜像并压缩\ndocker save \u0026lt;IMAGE NAME\u0026gt;:\u0026lt;IMAGE TAG\u0026gt; | gzip \u0026gt; XXX.tar\r导入镜像\ndocker load -i XXX.tar\r","date":"2021-01-21T09:26:07+08:00","permalink":"https://ttf248.life/p/docker-two-three-things/","title":"docker二三事"},{"content":"作者对硬件有浓厚兴趣，使用Jmeter进行压力测试，记录了在CentOS 7上部署Jmeter、InfluxDB和Grafana的过程。分享了Jmeter的安装和命令使用，InfluxDB的特点和Docker安装方法，以及Grafana的简单部署和配置。总结了高性能程序模式的经验和参考资料。\n背景 众所周知本人对硬件有很浓厚的兴趣，凑巧测试组在用Jmeter做压力测试，发现性能上不去，作为好奇宝宝的我果断出击，试试公司的压测是怎么玩的。此处还有个小故事，在某个久远的时间点，在开源中国看过一篇帖子，如何绘制看上去更加高大上的性能压测图，在测试围观过windows版本执行测试，已经做到了可视化的TPS数据展示，另外配置一份web面板能有什么用？\n脑子想的都是想当然的东西，你要去试试才明白 Don\u0026rsquo;t use GUI mode for load testing! only for Test creation and Test debuggin.\n官方推荐的是通过命令行的方式获取压测报告，绘制GUI的方式展示，存在数据上的误差？对于Jmeter了解的不是很深入，至少找到一个理由去折腾一下Linux版本的控制台面板\n开源中国的帖子，核心组件的部署方式并不友好，安装所需的文件也需要关注公众号才能下载，作为新生代的好青年，当然是用Docker替代了。说白了还是自己服务器在境内，跨境的源地址访问速度都很慢，至少镜像服务，阿里云有个免费的加速。\n关于docker的安装部署，此处不再赘述，推荐参考以前的稿子。\n接下来的内容氛围两大块：基本测试环境组件的搭建、各个组件的简单认知讲解\nJmeter Apache JMeter是Apache组织开发的基于Java的压力测试工具。用于对软件做压力测试，它最初被设计用于Web应用测试，但后来扩展到其他测试领域。 它可以用于测试静态和动态资源，例如静态文件、Java 小服务程序、CGI 脚本、Java 对象、数据库、FTP 服务器， 等等。JMeter 可以用于对服务器、网络或对象模拟巨大的负载，来自不同压力类别下测试它们的强度和分析整体性能。另外，JMeter能够对应用程序做功能/回归测试，通过创建带有断言的脚本来验证你的程序返回了你期望的结果。为了最大限度的灵活性，JMeter允许使用正则表达式创建断言。\nApache jmeter 可以用于对静态的和动态的资源（文件，Servlet，Perl脚本，java 对象，数据库和查询，FTP服务器等等）的性能进行测试。它可以用于对服务器、网络或对象模拟繁重的负载来测试它们的强度或分析不同压力类型下的整体性能。你可以使用它做性能的图形分析或在大并发负载测试你的服务器/脚本/对象。\nJmeter 部署 centos7 安装JDK运行环境、下载Jmeter安装包\nyum install java-1.8.0-openjdk -y \u0026amp;\u0026amp; \\ wget https://mirrors.bfsu.edu.cn/apache//jmeter/binaries/apache-jmeter-5.4.tgz \u0026amp;\u0026amp; tar -xf apache-jmeter-5.4.tgz 配置环境变量\nexport JMETER_HOME=$HOME/jmeter/apache-jmeter-5.4 export PATH=$JMETER_HOME/bin:$PATH Jmeter 命令 最后会对接Grafana控制面板，可以不输入-l参数，在web控制台观察数据\njmeter -n -t /tmp/order-500-10s.jmx -l /tmp/jmeter-order-report-20200109/order-500-10s.jtl # 一般不用测试结果和测试报告，简化命令 jmeter -n -t /tmp/order-500-10s.jmx InfluxDB InfluxDB是一款用Go语言编写的开源分布式时序、事件和指标数据库，无需外部依赖。该数据库现在主要用于存储涉及大量的时间戳数据，如DevOps监控数据，APP metrics, loT传感器数据和实时分析数据。\nInfluxDB 特点 InfluxDB的特点可以归纳为以下9个方面：\n无结构(无模式)：可以是任意数量的列; 可以设置metric的保存时间; 支持与时间有关的相关函数(如min、max、sum、count、mean、median等)，方便统计; 支持存储策略:可以用于数据的删改。(influxDB没有提供数据的删除与修改方法); 支持连续查询:是数据库中自动定时启动的一组语句，和存储策略搭配可以降低InfluxDB的系统占用量; 原生的HTTP支持，内置HTTP API; 支持类似sql语法; 支持设置数据在集群中的副本数; 支持定期采样数据，写入另外的measurement，方便分粒度存储数据。 InfluxDB docker 安装 mkdir influxdb \u0026amp;\u0026amp; cd influxdb \u0026amp;\u0026amp; \\ docker run -p 8086:8086 -d --name influxdb -v $PWD:/var/lib/influxdb influxdb:1.7 docker exec -it influxdb /bin/bash 进入容器，执行命令，人工创建数据库\nroot@bce0a55bbc72:/# influx Connected to http://localhost:8086 version 1.7.10 InfluxDB shell version: 1.7.10 \u0026gt; 交互面板执行命令 InfluxDB 创建数据库和用户 创建数据库：create database jmeter_t2 查看数据库：show databases 切换数据库：use jmeter_t2 创建用户：create user \u0026ldquo;admin\u0026rdquo; with password \u0026lsquo;admin\u0026rsquo; with all privileges 查看用户：show users\n\u0026gt; show users user admin ---- ----- admin true 如果显示用户权限admin为true，数据库的准备工作就完成了\nGrafana 编写测试案例的时候发现，图表展示的效果其实没太多必要，接口的tps数据在命令行执行的时候已经能观测到，更多是想知道程序内部的耗时\n简单部署grafana控制台面板，导入配置文件对接InfluxDB\n控制台支持通过标签过滤测试结果，一般只需要配置一个InfluxDB数据库即可：\n应用名称 测试案例名称 docker run -d --name=grafana -p 3000:3000 grafana/grafana:7.3.1 网页版由于采样器间隔会导致计算的TPS和相关数值与Jmeter聚合报告不相符，参考链接：https://www.vinsguru.com/jmeter-real-time-results-influxdb-grafana/\n资料中也描述了如何自定义监听器\n后记 高性能的程序模式必然是 one loop thread，任何的锁、入队列和出队列，都会造成不必要的性能损失 核心业务逻辑的耗时大于引入其他代码的耗时，并发才能有效提高效率，核心耗时如果足够小谨慎引入其他代码 参考资料 Jmeter系列之Jmeter+Grafana+InfluxDB实时监控 influxdb官方镜像 grafane官方镜像 Jmeter官网 To install Apache JMeter in CentOS7 ","date":"2020-12-22T10:12:50+08:00","permalink":"https://ttf248.life/p/linux-setup-jmeter-testing-environment/","title":"Linux搭建Jmeter压测环境"},{"content":"线上生产环境操作系统，Red Hat和CentOS为主流选择。记录了两个系统生命周期的官网链接，并分享了从CentOS 8升级到CentOS 8 Stream的经验。\n前言 线上生产环境操作系统，目前国内的环境来说，Red Hat和CentOS为主流选择。前两年经历了Red Hat 6的退役，特此记录两个系统生命周期官网链接。\n正文 Red Hat Enterprise Linux Life Cycle CentOS 产品规范 Red Hat Enterprise Linux（RHEL）和CentOS是企业级服务器操作系统的主流选择。RHEL提供了稳定的支持和更新周期，适合企业级应用。CentOS作为RHEL的社区版，提供了相似的功能和稳定性，但没有官方支持。\n追更 发布这篇稿子的时候，我也想不到自己会在两年后来更新，前两天刚把日常用的虚拟机，从CentOS 8升级到了CentOS 8 Stream。生产上怎么选择，我不好多说，本地环境还是追求最新的版本。\nCentOS 8 Stream是一个滚动发布的版本，提供了比传统CentOS更快的更新和新特性，适合开发和测试环境使用。\n","date":"2020-07-21T20:02:35+08:00","permalink":"https://ttf248.life/p/redhat-centos-lifecycle/","title":"Redhat 和 Centos 生命周期"},{"content":"先谈点题外话，中国特色社会主义和资本主义的不同。从老一辈的口中，都听过要想富，先修路。中国的基础设置建设，这些东西都是国家在出钱，放到资本主义社会，这些都会承包出去，偏远地区，完全没有利益可言，也就不会有公司乐意承接。说太多呢，有点偏离当前文章的主题，普通人可能觉得贸易战对生活没太多影响，实际上，我国的高端制造业一直相对薄弱。本人从事的IT行业，内存、硬盘、CPU、显卡，组装一台电脑的核心配置，都是来自于国外的工厂，这些配件的费用也占用了整机价格的50%，高端制造势在必行。中国和美国的碰撞也是不可避免的。\n参考资料 始于2018的中美贸易战 中国制造2025 维基百科 2018－2020年中美贸易战，简称中美贸易战（英语：China–United States trade war），又简称中美贸易争端、中美贸易摩擦、中美贸易纠纷或美中贸易战，是中华人民共和国与美利坚合众国之间的一场贸易战。\n贸易争端源起于美国总统唐纳德·特朗普于2018年3月22日签署备忘录时，宣称“中国偷窃美国知识产权和商业秘密”，并根据1974年贸易法第301条要求美国贸易代表对从中国进口的商品征收关税，涉及商品总计估达600亿美元。2018年7月6日，美国对价值340亿美元的中国输美商品征收25%的额外关税。中国商务部同日作出反制措施，对价值340亿美元的美国输华商品征收25%的额外关税，其中包括美国向中国出口最多的货品大豆。\n中美双方曾一度于2018年5月达成暂停贸易战的共识，并发表联合声明寻求和解。但美国贸易代表办公室其后于6月16日公布了第一批针对500亿美元中国输美商品的征税清单，将原有10%税率提高到25%。中国国务院关税税则委员会随后作出对等报复，中国商务部亦重启对美输华多项产品的反倾销调查。7月6日，特朗普政府正式对第一批征税清单中价值340亿美元的中国输美商品加征25%关税，标志着特朗普对华关税政策正式实施（剩余的160亿商品随后于8月23日加征25%关税）。中国商务部其后在声明中指出，“美国违反世贸规则，发动了迄今为止经济史上规模最大的贸易战”。中国海关总署指，中方的反击措施已在美方加征关税措施生效后即行实施。\n12月1日，G20布宜诺斯艾利斯峰会上，两国领导人习近平与唐纳德·特朗普达成共识，同意举行为期90日的谈判，并在谈判期内暂停新增贸易措施。2019年3月1日最后期限到期后，美国方面宣布已有重大进展，并延长暂停新增贸易措施的期限。\n2019年5月5日，美国总统唐纳德·特朗普宣布对另外价值约2000亿美元，合共2500亿美元的中国输美商品征收25%的关税，该措施于6月1日起正式对到达美国港口的中国商品生效。5月13日，中国国务院关税税则委员会宣布自6月1日起对原产于美国价值600亿美元的部分进口商品提高到加征5%至25%的关税。6月1日，美贸易代表办公室宣布将美方加征25%关税时间推迟至6月15日，中国国务院关税税则委员会则表示中方加征关税举措于6月1日如期生效。\n6月29日，两国领导人习近平与特朗普在G20大阪峰会上举行会谈，同意重启经贸磋商，美国不再对中国产品加征新的关税。\n8月1日，因特朗普政府不满中国政府对美国农产品的购买进程，特朗普在推特宣布将在2019年9月1日起，对余下价值3000亿美元的所有中国输美商品征收10%的关税。8月5日，人民币兑美元汇率跌破7关口。同日，美国财政部宣布将中国列为汇率操纵国。其后，中国政府宣布暂停购买美国农产品，并于8月24日宣布对约750亿美元美国商品加征10%或5%关税、对美国汽车及其零部件恢复加征关税；而美国在次日也增加之前加征的3000亿美元中国货品的税率至15%，以及目前的2500亿中国货品加征的25%关税至30%作为反制，但其后被搁置。\n2020年1月16日，中美两国签署第一阶段贸易协议。\n","date":"2020-07-21T19:52:41+08:00","permalink":"https://ttf248.life/p/us-china-trade-war/","title":"中美贸易战"},{"content":"作者从小对组装电脑充满兴趣，大学后开始接触硬件组装。推荐了硬件性能对比网站和选购建议，包括CPU、固态硬盘、机械硬盘和内存频率等。分享了硬件选购经验和注意事项\n缘·妙不可言 打小呢就想着组装一台自己的电脑，奈何经济条件不允许。好不容易熬到了大学，为了便于携带，配置的也是笔记本。如果非要有个具体的时间点，我是什么时候开始有组装电脑这个念想的，就要说到老家的图书馆。毕竟也是个市区级别的图书馆，不仅有电子阅览室（其实从没去过，据说是按时计费），还有个杂志阅览室，也就是在这里，翻阅到了《大众软件》、《电脑报》这类杂志，对接触电脑不多的我来说，堪称神级科普资料。看到打副本的章节，就想着自己弄个电脑，也去拉怪，当主力输出；看到黑科技呢，幻想自己照着书上的做，也能达到描述的效果（论黑客工具的使用）。虽说高中课业重，就我那会的认知，书要读，玩也要玩，过的也算是“天真烂漫”，打着去图书馆看书的由头，没事就拎着个小包溜达过去，市区不大，一般都是徒步走去图书馆。到了地，吹着空调，看着小说、漫画、游戏杂志，偶尔也看点正经的书籍。\n年纪大了就容易忘事，图书馆引发的还不算是初次萌芽。初中的时候，亲戚家组装过一台电脑，也不知道当初组装那台机器是干嘛用的。操作系统还是 windows 2003，游戏有系统自带的纸牌 + 帝国时代。各种“斗智斗勇”想着偷到钥匙，带着堂弟一起玩游戏。\n刚入初中，学校就有就计算机的初级培训，后来转学，也接触到了一点计算机竞赛的概念。等到了高中，NOIP混过一次。说道这里，就不得不提，校友的力量，高中的计算机大楼是校友捐赠的，包含计算机教学室+图书馆。其实那会也是国内互联网浪潮的初浪。校领导也支持参与计算机竞赛，毕竟前面两届的学长，好几位前辈通过计算机保送了重点大学。\n从未这样回顾过我和电脑这些事。也难怪我毕业后硬是从自动化专业义无反顾的转到了计算机行业，种子早已种下，局中人不自知而已。从小接触的多了，以为自己很厉害，其实也就懂个皮毛，最大的优势也就是最初的那份热情。\n硬件组装 多逛逛卡吧、chiphell、知乎电脑组装的板块，萌新能较为简单的给出一份自己需要的机器清单。2019年后选购CPU，经济条件不充裕的情况下，想要更高的性能，首选AMD。\n推荐一个常用的硬件性能对比网站：https://cpu.userbenchmark.com/，价格这块基本可以和咸鱼的美版做个对比。真大佬可以去咸鱼淘二手的，能便宜很多。如果不是很精通，不推荐去咸鱼，本人就购买了假内存，虽说目前使用没发现问题，不太确定太多了，型号和参数完全对不上。\nSN550 VS SN750 SN550 1TB容量和SN750 1TB容量差别就是，两者持续读写差一倍，一个850MB，一个1.6GB，但日常使用没区别，因为两者4K都一样。当然这里说的是1TB容量的SN550，500G和250G速度顺序读写更慢。其实我觉得只要不是不差钱的，日常使用买SN550就行，我没买这个最大原因不是因为它的顺序读写速度，而是它最大只有1TB容量，而SN750有2TB容量。对我来说，在不额外扩展的情况下，主板的M.2 Nvme接口比这些固态的差价更值钱\n综合网友的结论，入手一块转接板，B150 主板也能支持 M2 接口的固态。\n机械硬盘选购 机械硬盘目前价格趋于稳定，对于有大量存储需求的用户，需要选购一款合适的机械硬盘，频繁下载资源的用户推荐企业级硬盘，常见的有：\n西数金盘 希捷exos 大容量的机械硬盘推荐进行分区，频繁的下载操作固定在某个分区进行，日后出现坏道，可以集中在某个分区，废弃当前分区即可，能有效延长机械硬盘寿命。\n希捷系列官网介绍\n内存频率 日常工作的角度出发，频率不会对性能产生太大的影响。\n内存时序（英语：Memory timings或RAM timings）是描述同步动态随机存取存储器（SDRAM）性能的四个参数：CL、TRCD、TRP和TRAS，单位为时钟周期。它们通常被写为四个用破折号分隔开的数字，例如7-8-8-24。第四个参数（RAS）经常被省略，而有时还会加入第五个参数：Command rate（命令速率），通常为2T或1T，也写作2N、1N。这些参数指定了影响随机存取存储器速度的潜伏时间（延迟时间）。较低的数字通常意味着更快的性能。决定系统性能的最终元素是实际的延迟时间，通常以纳秒为单位。\n当将内存时序转换为实际的延迟时，最重要的是注意它是以时钟周期为单位。如果不知道时钟周期的时间，就不可能了解一组数字是否比另一组数字更快。\n举例来说，DDR3-2000内存的时钟频率是1000 MHz，其时钟周期为1 ns。基于这个1 ns的时钟，CL=7给出的绝对延迟为7 ns。而更快的DDR3-2666（时钟1333 MHz，每个周期0.75 ns）则可能用更大的CL=9，但产生的绝对延迟6.75 ns更短。\n现代DIMM包括一个串行存在检测（SPD）ROM芯片，其中包含为自动配置推荐的内存时序。PC上的BIOS可能允许用户调整时序以提高性能（存在降低稳定性的风险），或在某些情况下增加稳定性（如使用建议的时序）。\n注意：内存带宽是测量内存的吞吐量，并通常受到传输速率而非潜伏时间的限制。通过交错访问SDRAM的多个内部bank，有可能以峰值速率连续传输。可能以增加潜伏时间为代价来增加带宽。具体来说，每个新一代的DDR内存都有着较高的传输速率，但绝对延迟没有显著变化，尤其是市场上的第一批新一代产品，通常有着较上一代更长的延迟。\n即便增加了内存延迟，增加内存带宽也可以改善多处理器或多个执行线程的计算机系统的性能。更高的带宽也将提升没有专用显存的集成显卡的性能。\n参考资料 内存时序参数说明 ","date":"2020-07-18T14:33:46+08:00","permalink":"https://ttf248.life/p/computer-assembly/","title":"电脑组装那些事"},{"content":"由于境内访问GitHub Pages较慢，作者申请了个人域名并购买了国内云主机供应商的CDN加速服务。配置过程中，作者遇到了www子域名无法访问的问题，最终通过删除泛域名解析并单独设置二级域名解决。作者还分享了CDN加速的原理和配置经验，以及使用Nginx反向代理的尝试和教训。\n背景 网站托管在GitHub Pages，某些众所周知的原因，境内访问GitHub Pages有点慢。故而申请了个人域名，购买了国内云主机供应商的CDN加速服务。在设置加速服务的时候，想到了自己还有开发机器，上面部署了docker、frp、k8s等服务，这些服务都有配套的dashboard，本着不浪费的原则，配置了几个反向代理，全部挂上了二级域名。\n当我美滋滋用着二级域名的时候，突发现www子域名无法访问了，阿里云上命名配置了DNS同时解析到www.xiangtianlong.com和xiangtianlong.com，尚未启用CDN加速的时候，两个域名都能正常使用。\n在配置CDN加速的时候，由于二级域名太多，启用了泛域名规则，统一路由到了开发机器，结果导致www这个二级域名也挂了，是的，你没看错，www前缀是个二级域名。实际网站部署在GitHub Pages，开发机器没有任何网站的缓存信息。\n至于为什么开发机器上没有部署站点，因为静态博客，配着GitHub提供的action，自动集成发布，真香。\n域名 非专业的web开发，对于域名的理解不涉及SEO和跨域问题。作为博客站点，裸域容易突出博客主的站点，说的就是我这种用汉字拼音当做域名的小朋友，加之当前移动访问居多，能少输入几个字符。\n电脑端能使用快捷键免去输入www和com\nCDN 阿里云和腾讯云的都用过，新人上手不难，腾讯云还有个视频单独讲解相关的概念。CDN加速的原理和京东仓库是一个道理，发售新商品，提前统一配送到全国各地的仓库，触发配送请求的时候，就近分发。\n回源地址：网站资源原始存放的地址\n缓存文件设置，浏览器F12，管理控制台，简单分析静态资源和动态资源\n全部0天有效期 .php;.jsp;.asp;.aspx 0天有效期 .jpg;.png;.js;.css;.woff2 1天有效期 腾讯云配置规则：\n缓存过期规则最多可配置10条 多条缓存过期规则之间的优先级为底部优先 缓存过期时间最多可设置365天 悲惨自述 以前也没用过Nginx，以为网站随便搜索就能明白反向代理的配置，结果有点混乱，折腾半天连个302跳转也没弄明白，结果屁用没有。就想着笨办法解决一下，DNS解析删除*模式的泛域名解析，单个二级域名进行独立设置。此时突然注意到了阿里云DNS解析有一个叫做显示URL跳转的模式，尝试了一下，这不就是我想要的302跳转。\n设置了第一个二级域名正常访问，等我设置第二个的时候，发现没用，都快怀疑人生了，等了一会突然就能用了，看来阿里云的DNS扩散偶尔也是会抽风的\n参考资料 为什么越来越多的网站域名不加「www」前缀？ 带www和不带www域名有什么区别呢? Docker nginx 反向代理设置 ","date":"2020-06-20T10:36:27+08:00","permalink":"https://ttf248.life/p/website-acceleration-and-domain-setup/","title":"网站加速和域名设置"},{"content":"本文介绍了Markdown的基本概念及其在各种软件中的应用，推荐了使用VSCode作为IDE，并列出了推荐的插件。作者分享了从Hexo切换到Hugo的经验，强调了Hugo的灵活性和自定义能力。最后，提供了一些快速上手新技术的建议，并分享了一个解决Hugo主题样式不更新的小技巧。\n前言 Markdown 一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档\n详细的Markdown语法本文不做额外赘述，推荐一本电子书，点击此处\n市面上很多软件都已经支持md作为书写方式。csdn博文系统推出了支持md语法的在线编辑器，在首次使用时，默认会有一篇关于md语法的介绍文章，笔者觉得还不错；印象笔记在2018年增加了对于md笔记的支持，快捷栏中有各种md标记的选项，用起来和编辑普通的文章差不多，整体的交互流程属于新手友好\nIDE推荐 编写本文的时候，已经是2020年，vscode你必然是听说过的，毕竟能想到使用git page来搭建博文系统的都是业内人士。早些年的时候，sublime、atom也是不错的选择，经过两年开源社区的推动，vscode发展迅速，已经逐渐成为新手入场的首选。\n微软巨头和开源社区的关系从割裂的状态，成功跨入蜜月期：拥抱开源；笔者所在的公司在最近两年也积极的引入Java体系，换言之在业务开发上，如今的Java生态在国内属实真香\nvscode插件推荐 插件都有自带的Readme，介绍基本用法，核心功能，部分插件作者还提供动态效果展示图\nPaste Image，配合hugo的图片插件方式，很便捷的就能引入图片\n快捷键没记住，打开vscode快捷键管理菜单，搜索md，多看几遍；重看一遍插件使用说明\nhugo 笔者从hexo切换到了hugo，爱折腾是我的天性，终归是耐不住性子安安静静写文章\nhugo支持在单独的文件夹放置图片和md文档 academic主题在设计上支持多种各式的文章样式 各种便捷的自定义拓展 academic 官网默认exampleSite，menu引入采用#组件的方式，推荐使用url\nurl的模式，点击导航栏能实现单页的跳转，而非在首页进行滚动，这点纯属个人喜好\n样式上：随笔、演讲、电子书 灵活性：自定义整体风格、自定义css样式 这款主题对于中文的支持还不是很完善，主要是从视觉的角度来说，字体大小不太符合中文阅读习惯，hexo的开发人员大部分为国人，在这点优于hugo\n但是呢，自己动手丰衣足食，浏览器审核元素。定位了到了元素，想要知道需要修改的css样式名称，侧栏点击Insert Style Rule Below，即使嵌套多层的css，也能轻松拿到节点名称。\n引入custom.css 引入custom_js 主题内置的语法高亮设置，官方链接 结尾 小朋友又要吐槽了，你怎么从头到尾都说的模模糊糊，细节什么的都不提\n我想说的是，有下面这些东西，足够你用了：\n官方手册 插件说明 快速上手新技术，推荐先阅读官网文档，粗读不求一遍看懂，至少心里有个数，搜索引擎出来的结果，不一定和当前最新的版本保持一致，也许会产生误导。翻阅新书也是如此，先看目录，搞清楚作者准备讲什么，有时候读书先读序，部分国外的著作翻译成中文，译者的序其实涵盖了书籍和核心内容。\n彩蛋 切换hugo academic内置风格样式，发布到站点，访问时，风格没有发生变换。聪明的小伙伴已经想到了，清空本地浏览器缓存，能解决问题。机智的我：F12开发者模式，切换到network，勾选disable cache，刷新，搞定！\n","date":"2020-03-31T13:54:27+08:00","permalink":"https://ttf248.life/p/blog-ide-environment-and-ramblings/","title":"博客IDE环境和碎碎念"},{"content":"使用 GitHub Actions 自动部署 Hugo 博客到 GitHub Pages 和 Gitee。\n背景介绍 昨天更新博客时发现travis服务不可用，查看travis网页，发现进度卡在拉取源码的时候，灵光闪现想到了github之前推出的action服务\n由于那会比较忙，同时也需要申请才能使用action，现在已经开始正式上线，周末闲来无事，尝试一个新玩具？\n官方资料大家自行进入网站查阅即可，本文就不做更多的转载了，如果之前用过kubernetes会觉得，action的yaml文件配置和kubernetes很像。\n关于的入门的教程，或者说是中文的介绍资料，推荐搜索阮一峰的博客，有两篇文章，第一篇是基础的语法介绍，第二篇是一个实际的案例。\n正文 需要的知识点\ngithub secrets action 语法 核心的job使用现有的组件完成，推送到国内gitee使用command实现，command这部分比较粗暴，都是强制推送，沿用了使用travis的逻辑。\nname: github pages and gitee pages on: push: branches: - hugo jobs: deploy: runs-on: ubuntu-18.04 steps: - uses: actions/checkout@v2 with: submodules: true - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: 'latest' extended: true - name: Build Github and Gitee ## 单个step只能写一个run命令 run: hugo -b \u0026quot;https://www.xiangtianlong.com/\u0026quot; -d \u0026quot;github_public\u0026quot; \u0026amp;\u0026amp; hugo -b \u0026quot;https://www.xiangtianlong.com/\u0026quot; -d \u0026quot;gitee_public\u0026quot; \u0026amp;\u0026amp; ls - name: Deploy Github uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.BLOG_TOKEN }} publish_dir: ./github_public publish_branch: master cname: xiangtianlong.com - name: Deploy Gitee run: cd ./gitee_public \u0026amp;\u0026amp; git init \u0026amp;\u0026amp; git config user.name \u0026quot;TianlongXiang\u0026quot; \u0026amp;\u0026amp; git config user.email \u0026quot;tianlongxiang51@gmail.com\u0026quot; \u0026amp;\u0026amp; git add . \u0026amp;\u0026amp; git commit -m \u0026quot;Update TianlongXiang's Blog\u0026quot; \u0026amp;\u0026amp; git push --force \u0026quot;https://xiangtianlong:${{ secrets.GITEE_PASSWORD }}@gitee.com/xiangtianlong/xiangtianlong.git\u0026quot; master:master 后记 从官方市场提供的action来看，目前支持的玩法挺多，构建docker镜像以后也能不再依赖dockerhub提供的服务\n查阅hugo的issue，发现使用github action自动部署git pages，最终发布的网页需要在master分支，如果是部署在其他分支，在setting界面，github会提示部署的网页存在语法问题\n实际上只是由于hugo的源文件放在了master分支，github当作jelly博客的源码进行检测，无法检查无法通过导致的报错\n解决方案也简单，hugo源码文件放到其他分支，静态文件发布在master分支\n","date":"2020-03-29T02:11:33+08:00","permalink":"https://ttf248.life/p/auto-integration-system-switch/","title":"自动集成系统切换"},{"content":"我希望到了二十年后，我是个可爱的老头，陪着一个可爱的老太太。不求大富大贵，身体硬朗，能到处去走走。\n视频原稿 优酷搜索即可，后续不再提供链接\n文字稿 我说10年后可爱的老头是我，我要努力的去做一个可爱的老头，未来的好，中国一定是要有好老头好老太太的中国。我即便10年后60岁了，也是这个世界第三国度里头最年轻的那一个。\n坦白的说，大家看我50岁的中国的男人要都这样的体型的话相当不错，但是在这个体型的背后是我信奉的一句话，越自律越自由！停了雨那会我都想去跑步去，明天下午我就会踢球。50岁了，依然可以打大场，不是开玩笑，而且经常是跟专业的一起踢。可是背后是什么？背后是自律，我剩下的那些天在跑步，而且跑步有人会觉得是非常枯燥的事情，越自律越自由，我因为自律，所以我可以自由的奔跑，从不听音乐，因为我觉得听自己的呼吸是跑步中最美的音乐。\n另外我基本不跑跑步机，然后有很多人北京雾霾那么严重，我一周跑5天，有两天我已经留给雾霾了，然后跟别人不一样的地方开个玩笑说，可能就是我从来不间断。我每个月都会在日记上，就是在我的阅历上跑了一天就画一天，每个月从不会少于18天，跑步的时候都是嗖一下就过去了，跑步的时候我又我又不戴眼镜，但是更重要的是我每周还在踢球，我带我的研究生最后一堂课一定是到我们家那一天的课，就一个主题叫趣味，我觉得趣味太重要了，我从来不跟没有任何乐趣和爱好的人打交道。\n敬而远之，这样的人太可怕了，没乐趣你就觉得您有什么乐趣，我还真没什么了，您喜欢什么工作？我天今年年初的时候，我的一个学生研究生分在中国新闻周刊，我们有一个专题叫致，10年后我的研究生每年毕业的时候，最后一篇作业都是让他给10年后写一篇文章，然后我给留下来，10年后我在给他们陆续展开，我也写一下50岁写给60岁，60岁是一个过去我从来没有想到过的远方远的在地图之外，但转眼就是我的下一站20岁写给30岁我的学生们，那是春天写给夏天的情书，但是我50岁写给60岁，可就是夏末写给秋天的喃喃自语了，我现在写给10年后是从整个世界慢慢的写给自己的一张床，一顿饭，自己的家人的身边，这很正常。\n但是60岁做一个什么样的人，我的题目很明确，在舒心的序里头这篇文章很长，我说10年后可爱的老头是我，我要努力的去做一个可爱的老头，中国想要可爱不仅取决于将来有更多像公民一定要做成公民，不再是小老百姓的年轻人，有朝气的年轻人，懂规矩的年轻人，未来的好中国一定是要有好老头好老太太的中国。目前中国超过60岁的人已经超过了2.3亿，10年后肯定过三个亿，也就是说仅仅从60岁以上的人口来说，中国人口如果单独是一个国家世界前5，甚至有可能世界第三，想想看多么可怕吗？\n我倒不觉得。我不知道大家今天有没有看网上的一个表，中国各个省市直辖市的平均寿命，上海和北京都超过了80岁，平均寿命男女全算上。平均寿命肯定是男的占了女的很大便宜。那也就意味着我即便10年后60岁了，也是这个世界第三国度里头最年轻的那一个。未来。女性如果55岁退休到平均年龄80岁，退休后还25年，男性60岁退休，到平均年龄80，退休后还20年！您不干点什么光跳广场舞。而且我可以说今天跳广场舞的大姐和大哥们是时代带给他们的文化习惯和娱乐方式。\n再隔20年，下一代人可能还会有很多跳广场舞的，但是会大量减少。因为下一代人不再是集体活动的积极参与者，就像岁数大的愿意旅游跟团走，现在年轻人越来越自由行、自助游，将来还会有广场舞，但是一定范围也在缩小，这没有好和不好，只有时代在洗牌，在不断的去变。我60岁的时候是作为最年轻的团队当中的一员，我该去做一个怎样的人？中国画说60耳顺，我相信我那个时候绝对不会听，什么都高兴，依然听到不该提，高兴的还会不高兴，更重要的是要为年轻人去做什么！\n要为好的事情去做什么？不懒惰，不轻易的妥协，该反对的反对，年轻人有可能伤他利益，你能不能挡在年轻人的面前？我现在经常要前后去照这面镜子。我的一个好朋友已经离世了，陶伟那时候经常聚会，在我们家聚会，有给我讲过一次真事儿，我们就集体痛，陈老一代那帮人什么东西都在家里头攒着，你说破盒子，你弄30多个塞床底下干嘛，你要告诉他，这件衣服500多买的，完了，供起来了，每天点香。因此我们这代人都习惯了跟自己的父母斗智斗勇，700多买回来得多少钱？\n220。但是容易出事儿。陶伟有一次花400多给他爸买了一个T恤衫。这T恤衫真不错，多少钱？99那行我穿上了。第2天惨了，晚上回来夸拍给陶伟400块钱，替我再买4件，今天我穿出去之后，你张数李大爷全觉得好，后来说这种撒谎的风险是很大的，将来你别做这样的老人，我不说具体的哪一个具体的人在医院骨科，老年人摔骨折了，最后发现很重要的原因是穿的地摊上买的鞋，当然这我谈的还仅仅是物质层面，老了依然要有精神生活藕，依然要有好奇心，依然愿意为年轻人挡风遮雨，活一天开心一天。\n我觉得我很好奇和兴奋的等着自己60岁到来的时刻，我觉得那是一个美好的时光的开始。\n谢谢各位。\n","date":"2020-02-15T11:28:28+08:00","permalink":"https://ttf248.life/p/future-china-with-good-grandparents/","title":"未来的好中国一定是有好老头好老太太的中国"},{"content":"很常见的词语信息碎片化，自从高中毕业，抛开看小说的时间，我已经很长时间没有认真安静下来读一本书了，有时候回头看看，工作这么长时间，我还记得自己每年做了什么？很多时候，到了下半年，我已经忘记上半年的很多事情。写博客是个好习惯，纵然我写的很多东西不上台面，并没有什么关系，原本就是写给自己看的。\n最忠实的的读者是我自己\n视频原稿 优酷搜索即可，后续不再提供链接\n文字稿 每一个自己的18岁都像是一个期待和追问的目光，每一个人偶尔要拿自己的18岁来问问自己，你是当初自己要活的那个样子吗！我很怕现在每个人都有无数的朋友圈，没朋友，天天在聊天，没人谈心，知识获取无限，离智慧很远，每个人都应该用你的18岁问问自己，骗别人太容易了，骗自己太难！\n你我觉得每一个自己的18岁都像是一个期待和追问的目光。你骗得了别人，你骗不了自己的18岁，你的今天是你18岁要的样子吗？我觉得还好。在今天物质名气等等很多东西比我18岁想得多得多得多的，得到了，但是另一方面永远在路上，18岁的我在广播学院读新闻系，我希望成为法拉奇成为最好的记者，我今天依然在路上，但是这也就是好多人说白老师，你怎么还在CCTV因为我想成为好记者。新闻还在。这是我18岁的目光，所以我觉得每一个人偶尔要拿自己的18岁来问问自己，你是当初自己要活的那个样子吗？\n这是真骗不了别人的。这是我18岁时候的样子，一转眼就过去了32年，每一个到北京来上大学的人都会有这样的一张合影，在那个时代，天门广场皱巴巴的西装，然后校徽别在胸前，因为那个时候大学生少，别校徽，觉得特骄傲，那个时候的头发很长，但是还是很喜欢18岁时候的样子。很多年过去，我突然发现我庆幸于18岁所面对的那些东西，因为悄无声息的它塑造了我。1986年那一年5月8号，我在王府井书店买了朦胧诗选，那一年在工体听了崔健的一无所有，结果今天我突然发现我的文字风格受到最大的影响，包括我的性格就是朦胧诗、摇滚乐和古龙的武侠小说的影响。\n18岁你遭遇了什么？你就可能携带什么上路。我特别想知道今天的18岁都在遭遇什么？是不是如刀劈斧凿一样的在雕刻你。但是他用了什么工具？它打磨了你什么样的样子。我很怕现在每个人都有无数的朋友圈，没朋友，天天在聊天，没人谈心，知识获取无限，离智慧很远，知道什么都不知道，看似人人都在说个性。可是以我作为一个旁观者，我发现现在的年轻人非常一样，这怎么办？18岁你该让他遭遇什么？我非常喜欢1986年，因为1986年才是解决1966年的最好方式。\n1966年文化大革命靠76年打倒四人帮来结束，有偶然性，只有靠1986年的这种启蒙和人性的苏醒和每一个人的成长，才可能真正的把让你担心的基础去刨掉，我觉得我们还要经历启蒙，我们还要更要经历对人性的充分了解。中国社会不管经济发生多大的这种进步、变化储备，如果没有真正补上对人性了解的这一刻，然后顺应人性管制人性中恶的那一面，激活人性中善的那一面，未来依然会有很多让我们担心的东西。所以我的18岁也是这个时代的18岁，走的太远，别忘了当初为什么出发，现在已经被浓缩成不放初心这4个大字。\n所以我觉得不管走多远，每个人都应该用你的18岁问问自己，所以18岁留张照片是很好，经常拿出来问问自己，别人说什么没有用？骗别人太容易了。骗自己太难了，我刚才说我18的时候对今天20岁的人说说，你永远要让自己的18岁成为观看你的一双眼睛。另外20多岁刚才我也说过，多去尝试开很多扇门，你不知道哪个更适合你自己的，在哪扇门的后面，现在的中国很诧异，经常有20多岁的老人，然后有很多70多岁的年轻人。\n谢谢各位。\n","date":"2020-02-15T11:19:33+08:00","permalink":"https://ttf248.life/p/my-18th-might-be-different/","title":"我的18岁，可能跟你们不太一样"},{"content":"讲述了作者对记者职业的看法，强调记者应具备社会良心、知识储备和长跑精神。作者还分享了自己在50岁时的感悟，包括对好奇心的保持、物质与精神的平衡以及对未来的思考。\n视频原稿 优酷搜索即可，后续不再提供链接\n文字稿 一个最好的记者就是首先有社会良心，第2个有知识储备，第3个长跑。不能我跑100米不过瘾了，跑了。我觉得这三者结合，人们期待的是疫苗安全的隐患彻底给我解决掉，这就像当初的奶粉事件一样，实在总是在出了问题、解决问题，彻底解决问题的这样逻辑循环当中前进。否则要记者干嘛？\n我觉得一个最好的记者首先有社会良心，第2个有知识储备，第3个长跑不能我跑100米不过瘾了，跑了。我觉得这三者结合我今年50整，你就明白我好像适合干新闻。我天然跟中国的改革40年紧密的捆绑在一起，我30岁生日，站在了松花江的岸边那一天，40岁的时候，2008我的生日是在奥运的直播当中进去的，又在奥运我的直播当中出去的。今年50岁，全国在纪念改革开放40周年，所以的确有一个对应，如果说大时代40岁，中国的改革40岁到底是不惑还是困惑？\n我觉得走过了40年的道路的中国，在物质方面已经给予了大家足够多的东西，给予了国家足够多的东西，但是焦虑和困惑增加了，并没有减少，我们以为强大了富裕了就一切OK了，结果发现物质不过是打了一个底，原来在物质上脱贫是最容易的，但是在精神上富裕起来，并且成为大国真的很难。美国都开始打你高科技了，咱要打人农产品了。这个世界上一直存在着一种叫老二不容易当！在美国这修理了多少个2了？因此我们必然要经过一个漫长的岁月，把这种二不是一变成超越自己，我不可能什么都得到。\n我很幸运的是25岁开始做电视的时候，首先是从人物采访开始，我接触了大量的几百上千的带着各种光环的人物，那个时候年轻都觉得这种光环一定让她们都很幸福，结果靠近她们的时候发现no，光环和他们的幸福没那么大关系，甚至有的时候成反比。这两天我刚看完郭沫若的最后29年，郭沫若几乎没挨过整，贵为国务院副副总理、什么政协副主席、副委员长等等。但是，自己的两个儿子一个自杀，另一个可能是被从楼上扔下来死，他会幸福？\n你拿什么去衡量幸福？在自己六七十岁的时候，接连两个儿子在几年之间离开自己，副总理就能够让她幸福。有很多名人字画就能够让人幸福，自己安全的度过了很多岁月，就能够幸福。要什么？所以我觉得看人读书最好的镜子。说句稍微重点的话，我觉得我们现在很多人的焦虑就来自于想的太多，书读得太少。这是杨绛老人给一个年轻人的回复，不读书都指望快餐，拿个手机就打算找到大力丸。怎么可能？我是在一本书笨笨的过程当中学会聪明的，减法是在书越来越多读的情况下做的减法。\n所以我希望我不能指望所有的人，但我希望比例在增加，越来越多的中国人能够去在读书中读出更好的自己，这才是最重要的。没有谁坐在地上凭空仰望星空，把所有事都想明白了，我做不到。但是我可以去照镜子，几年前BBC的新闻主播来北京，号称BBC最牛的新闻主播，然后有好事者在国际饭店组织了一个中国新闻主播和他的对话，我们俩对话。这哥们在对话过程中问了我一个问题，他说你觉得BBC应该跟CCTV学什么？我先开了个玩笑，我说当然首先要学中文了。\n接下来我开完玩笑说，我说BBC最该跟CCTV学的是对这个世界的好奇。我说我们这几年快速的去到世界去不？各种记者站，我们现在已经超过了70个记者站，我们觉得自己一个学生每当看到国外新鲜的东西，都觉得非常好奇，我们带着巨大的好奇之心在观察这个世界，而BBC已经把英国本身当成了世界了，你们不再好奇了。老哥一拍桌子，你说的太好了，我们缺乏的就是这个东西。2007年我去日本采访他的一个作家作家跟我说了这样一句话，他说日本这个国度除了没有希望，剩下什么都有，后来明白了，这句话说得真深，换个角度来说，10多年前我觉得中国是除了希望好像剩下什么都缺，但是就不缺希望，每个人都觉得前面有奔头。\n但是会不会有一天我们也变成了一个除了希望什么都有的富裕国度。坦白的说，我非常担心中国走到一天是负的，什么都有的时候才觉得自己真穷，我50岁的时候就唯恐自己成为一个一切物质条件都可以得到满足，却成为一个非常贫穷的人。在我们的现实生活中，高学历的、没文化的人很多，存折上有无数个数字的穷人很多，这才是这个时代的问题。真穷是不可怕的，因为前面有奔头有希望。这就是我说道德赤字和人性亏损的原因所在，所以我觉得科学家之所以发明了很多的东西，不是说一开始就承载着伟大的什么使命等等，我觉得好奇。\n好奇我能弄出来他吗？所以我始终在50岁左右的时候就开始督促自己要更好奇，所以我都很开心，我现在很烦的一件事就是坚持，刚才聊天的时候在说您还在坚持，我说别我说一旦坚持离死不远了。过去我们都说坚持就是胜利，中国足球只要坚持黑色三分钟，坚持就咬牙了，没乐趣了，没方法了就靠坚持了，坚持有的时候很重要，但是相当多的时候这句话要有AB面。我很怕我在做一件某件事情的时候是坚持，比如说这会跟大家聊天的时候，我就坚持把剩下说完，其实到现在我的时间都到了，可是我觉得好奇，跟大家的交流，我会说成什么样？\n给自己一个很小的关键词，但是你自己跟大家的互动去聊天，我觉得在50岁的时候，只要你还能保有很大的好奇，没问题，我喜欢所有好玩的东西，但不一定跟现在最好玩的东西，今天的时髦有可能一转眼。每年都有流行词，您还记着几个？今天的互联网某个媒体可能10年后是传统媒体想过吗？所以好玩的东西永远有它好玩的内在的东西，我尊重每一个大家的喜欢，那一定有他的道理，但是长期下来看，最后发现中国人最喜欢的还是打麻将，当你也喜欢吃快餐的时候，做大菜的饭馆自然会慢慢的倒闭。\n很多东西不仅仅是发个感慨就过了。您每天让在手机碎片化的阅读是多少？您长一点的阅读有多少？但是这也是一个过程，手机正在成为我们的手铐。所以我觉得看越短的东西多，慢慢人也会变得短视，但这也是一个过程，我从不担心内容为王。还会回来，您会每天娱乐至死，一直到自己的40岁，就像我看见十几岁的孩子喝可乐，你劝他少喝一点，但你知道他一定会喝，但是另一方面我又乐观，40岁他一定会回到茶的世界里来，这就是中国人的一生。\n很正常，但是我希望接下来的转变会更快一点。我们就是发个感慨，现在的调查记者这么少了，您不看调查了。\n谢谢各位。\n","date":"2020-02-15T11:08:38+08:00","permalink":"https://ttf248.life/p/what-kind-of-journalists-does-society-need/","title":"这个社会需要什么样的记者？"},{"content":"补充的读后感基本都是2021年随手写进来的，白岩松老师的演讲稿转文字时间，那会还是疫情刚开始的时候。不要说二十年之后，一年后、两年后，世界的变化总是超出人们的预料。现在国内的疫情已经结束尾声了，国外的疫情依旧闹腾。关于足球，几年国足踢得不错了，教练也敢放手进攻，比起当年懵懂的时候，陪着老爷子看球有点意思了。一个国家队的比赛，让老人都懒得看想要换台，是什么样的体验？\n视频原稿 优酷搜索即可，后续不再提供链接\n文字稿 你对中国足球还保持好奇吗？好奇，非常好奇，还能差成什么样？所以你发现中国足球踢不好有很多原因，其中的一个原因就在于谁都怕把球丢自己这儿，传给别人，自己就算了，没有这种玩法。\n当然这只是其中很小的一个原因，说20年的足球，20年后中国足球仿佛特遥远，第1个扩军了变成48个了，中国有可能去，但是依然有可能不去，一个国家队的最佳年龄是2630，那20年后也就是今天6岁到10岁的孩子，20年让你觉得特乐观，20年后肯定行了，我一说到今天610岁，您马上表情凝重了。所以因和果种豆得豆，我们今天在种什么？我们今天差点种让国家队踢联赛的大豆，长出来的会是什么？谁出台这个动作，谁就要作下课的准备，这是违反规律，所以我没想那么多。\n但是真应该想想今天6~10岁的孩子，他们在踢球吗？您就知道20年后中国足球啥样？\n","date":"2020-02-15T10:59:32+08:00","permalink":"https://ttf248.life/p/china-football-in-20-years/","title":"20年后的中国足球会怎么样？"},{"content":"人做事，首先需要的就是问心无愧，这样睡觉踏实，能有小毛病，大是大非的问题上，最好不要放错。如果真的做错了，应该是尽力去挽救，不是藏着掖着，想着让自己忘记，人时善忘的，也是记性很好的物种。心安是归处，能对得起自己的反问，活的轻松一些。\n视频原稿 视频原始链接点击此处，如有侵权，联系本人删除，此文仅做文字稿翻译\n文字稿 我有八个字说的比较重，我觉得我们现在是道德赤字，人性亏损，时代总是在出了问题解决问题，彻底解决问题的这样逻辑循环当中前进，你要有耐心去等待它的洗牌。对于中国这样一个国度来说，很多东西是一个缓慢的洗牌的过程，所以别悲观在变，在洗牌。\n这两天中国都在跟两个台风做斗争，一个台风是无形的，一个台风是有形的，无形的台风就是疫苗，它冲击的是我们内心安全的堤坝。另一个台风中国很少有从上海登陆，然后让北京和天津遭殃，三个直辖市共同面对的台风几十年没有过。这是题外话，接下来你就要去思考的是你独善其身，你发生了很大的变化，你拥有了很多的答案，周围的环境不变话，你会幸福吗？我有8个字说的比较重，我觉得我们现在是道德赤字、人性亏损，这才是目前最大的赤字和最大的亏损。\n但是人们期待的是疫苗安全的隐患彻底给我解决掉，这就像当初的奶粉事件一样，所以有的时候你要多看看历史，也明白你知道美国的食药监局的建立和形成一道完善的法律，也与当初的奶粉、乳制品不安全紧密相关。所以三鹿奶粉的事件在逼迫中国在乳制品方面发生了很大的变革，疫苗不敢说接二连三，但是这一次我希望它是一个中止。所以你要知道时代总是在出了问题、解决问题，彻底解决问题的这样逻辑循环当中前进，否则要记者干嘛？否则要公民干嘛？\n所以我觉得我们每一个人能做的事情就是关切。但问题是中国的人太容易遗忘了。就像我刚才说的，撞完人家车来，咱停路边撒腿就跑了，一车的人没有人阻拦。我们的邻居、我们的同事有很大的比例是这样的人。所以要慢慢改变。而我们作为一个普通的民众，能做的事情就是关注他，不忘记。我觉得不是缺乏什么是过程，在吃不饱穿不暖的时候，你天天跟人谈理想，我觉得没有说服力，但是你等他吃饱了穿暖了，都把自己吃成了世界糖尿病第一大国，高血压第一大国，等等很多个第一大国，你就发现中国人开始跑步了，中国人开始减肥了，你问在座的各位姑娘，有谁没有经历过，我不大吃一顿，我就没有劲儿减肥的残酷经历，这就是一个小转变。\n我们所谈到的精神层面一定也是这个道理，当你吃饱了穿暖了，要开始跑步，要开始减肥的时候，慢慢精神的需求也会随之增加。你比如说我以前抽烟，但是当我开始跑步之后，稀里糊涂的突然我就有一天发现我20多天没抽过烟了，我再没抽过烟。当然我也不会特意说，我就把它彻底戒了，我觉得太太仪式感了，不排除一年当中还会抽两三根烟。当你生活方式在改变的时候，有很多当时东西随之会改变，我觉得对于中国人来说，你要有耐心去等待它的洗牌。\n越来越多的人感觉自己不幸福，不会放纵自己不幸福的。虽然抑郁症在增多，但是另一方面不就有越来越多的人也在去寻找积极的活着的方式吗？这个时候精神层面的东西就会增长，所以别悲观，你看同样的一件事，看你怎么看。我在街上经常看到开车加塞的，我很沮丧，一转眼我就乐观了，因为另一边排队的比以前长多了，这就是这样的一个过程，在座的各位在这样一个下完雨后的晚上，居然愿意到这个地方来聊这么多没用的东西，这不也是很好玩的事情吗？\n这不也是一种转变，所以有很多东西需要换一种思维方式去想，当然我觉得将来慢慢要增长的东西很多，比如说你说在创业，谁一生都是创业，所有人的一生都是创业，我们现在赋予了创业太时代感的东西，其实创业从来都在。苏轼不是创业吗？李白不是创业吗？一生都会有很多的创，最后创出了自己的品牌，绝大多数没创出来没关系，只要你活得足够有味道，而且你觉得值。我现在觉得中国特别缺乏的是好的失败是另一种成功的价值观。中国人只接受成功的结局，但是另一种好的失败是一种成功，不接受。\n我觉得那就很难，所以你发现中国足球踢不好有很多原因，其中的一个原因就在于谁都怕把球丢自己这传给别人自己就算了，没有这种玩法，当然这只是其中很小的一个原因。所以我觉得到了我这个岁数过去30岁的时候，在序言里头写透明快乐里头写不着急，到现在50岁有一点急，因为时光太匆匆了，太快了，你期待得很多东西还没有变成现实。但可是另一方面还是明白，对于中国这样一个国度来说，很多东西是一个缓慢的洗牌的过程。你看着父辈，有的父辈是红绿灯为无物，但是偶尔就会看到孩子拽着他爸。在变，在洗牌，所以我觉得要有点耐心。\n","date":"2020-02-15T01:20:34+08:00","permalink":"https://ttf248.life/p/moral-deficit-humanity-loss/","title":"道德赤字、人性亏损"},{"content":"国家总的来说是在变好，变富强，如果人的虚荣心没有这没强。回顾九十年代到到现在，在我接触的家庭中，大家的生活都是变得比以前好多了，与此同时富人也是更多了，市场化经济的发展过程中，不可避免的出现了贫富差距扩大。\n大家常说的阶级固化、上升通道被锁死，这些是当前世界的通病的，我党在人民的基本福利待遇、社会保障上做出的贡献，这些东西，大家也应当看在眼里。小日子会越来越好，你不想买房子，你可以租房子；孩子读书也存在教育资源分配不均的问题，有时候需要做出取舍，你是想要更好的工作机会、工作环境，还是更多的时间陪伴家人，不要把你自己的想法强加在他人身上，包括你的孩子、家人。坐下来，好好谈谈，生活总归是越来越好的。\n视频原稿 视频原始链接点击此处，如有侵权，联系本人删除，此文仅做文字稿翻译\n三十岁 今年我已经整整50岁了，过去没想过，我觉得这就是老头。现在才发现还真是老头，这是30岁时候的样子。30岁的时候不觉得自己很年轻，很好看，50岁的时候回头一看真不错，30岁最大的人生感受是什么？回头看。我觉得是减法，关键词就是减法。从某种角度来说，痛并快乐着也是一种减法，把很多东西经历的想过的写出去，然后留在那，去新的白纸上，去跑步了。但是对于我来说30岁我觉得的确无论是从自己还是对于各位的提醒来说，做减法都是非常重要的。\n我现在在带东西联大的学生，我经常提醒他们，在30岁之前要玩命的做加法，要去尝试，你不知道自己有多少种可能，你也不知道命运将会给你怎样的机缘。所以不是你怎么知道，但是有的人就在20多岁的时候拼命的事，各种加法，但是忘了收，忘了到一定的时候要做减法，我觉得30岁左右是人生非常重要的一个，要在做了一系列加法和四处乱跑之后，要做一次减法的重要时间，否则就晚了，为什么要做减法？你不是所有的都适合，也不是适合你的，所有的事，你都该去做。\n8条线拴着你，你能跑多远？可能会互相牵制。\n在30岁的时候，我已经被破格提升，也就是说，学术的话叫教授，记者的话，叫高级记者。我29岁就被破格了，到现在这样的事情已经很少了，但是在那个时候又开始感到了一种巨大的困惑。到2000年的时候做悉尼奥运会，掌声也很多，我突然觉得一切都不太对劲了。我要自己问自己，你究竟要做什么？哪些东西是要抛掉的？那一年我做了非常重要的一个减法，我停了自己的节目，停了一年，没有任何出境，当时有人劝我说主持人这行，您只要一个月不出镜还凑合，您半年不出镜就没人记得你了，我说我这张脸真够廉价的。\n那一年开始去研发新节目。这是在出完了痛并快乐着之后，01年我整整停了一年。今天所走的一切其实都感慨于那个时候的做减法。我那个时候要问我可以做很多东西，我去做体育，我可以去做E了，可以去做很多其他好玩的东西，做制片人等等。但是我说不，我发现我只能做新闻，我也最该做新闻，在，然后我当时是三个栏目的制片人，我在一夜之间都辞了，也才成了今天的我。我单纯了。前几天跟同事聊天，我还说我说30来岁的时候做的一个非常重要的决定，不仅仅是很多可做的，但是我觉得我就是打新闻，这口深井，很多的职位有可能要提拔你当副主任了，我给拒绝了，回到了一个普通百姓的基础上。\n到现在为止，我是中央电视台连股级干部，都不是绝对本科毕业的群众。你了解我们的体制，但是我拒绝了。我就想看看一个本科生能走多远，一个本科生的学历，为什么不可以不断的去学习，让自己去带研究生吗？对，我现在带研究生，每年要带11个，这都是一个减法的结果。我觉得这当然是回过头来的一个感慨了。另外在年轻的时候，特别容易在奔波之中，最后就产生了一种感受什么呢？一切我都该得到，只要有哪个没得到，只要有哪件事有点缺陷，我就心里特别不舒服。\n在座的各位千万别也要学会做减法，就是在那个时候快到30岁的时候，28岁的时候，1996年看奥运会，我编出了一句话，缺陷是完美的重要组成部分，这个世界上就没有完美。在曾国藩的那部长篇小说里头，其实写到了一个很重要的一句话，人生的最好的境界是什么？曾国藩想给自己的书房起名叫求阙厅，花还没有全开的时候是最好的。月亮还没有全圆的时候是最好的，但是对于常人来说，都会觉得这是缺陷，还不够完美，不够达到极致，毁一个人的最好的方式就是让他求完美和达到极致。\n这个世界不是这样的，花没有全开的时候才是最棒的，花一全开，离落花就很近了，月亮一旦开始全圆，离慢慢的变成残月就很近了，所以我觉得这是我的30岁给我的很重要的一个助推和启示；40岁没那个时候好看了。但是我觉得放松了。自由一些了，为什么不再是西装革履了，不再是黑白模样了，而是开始问幸福了吗？\n四十岁 中国人有一句话叫40不惑，30岁是减法，40岁是困惑，不是不惑，我觉得现今这个时代40岁恐怕困惑的是最多的，我的中年危机来的还偏偏很早，到三十六七岁的时候就开始纠结，我干的这一切有价值吗？\n有意义吗？我到底要什么幸福了吗？这本书就是在这个困惑的基础上诞生出来了，在30岁的时候你会发现你的很多幸福目标是与物质挂钩的，三十而立力指的是学历得立。你得有车有房，要不丈母娘都不打算把你媳妇许配给你，很物质，但是40不惑很难。我觉得古人可能是平均预期寿命比没现在长，因此它要浓缩40，他就不惑了，我觉得我40正困惑了，物质没有给我带来，我以为会带给我的幸福。同样在40岁的时候，之所以很多人问我，你幸福吗？\n我那书名是幸福浪吗？是问号，代表的是我内心的困惑。中年危机的诞生，40岁你要去回答自己很多的问号，40岁左右要多跟自己聊聊天，要去读很多的东西，给自己一些答案。我很庆幸在我三十六七的时候走进了道德经的世界，我在《白说》里头已经谈到，在40岁的时候还要去思考的时候，如果周边的环境不发生改变，尤其是软环境，您心情舒畅的走出家门，到处是乱闯红绿灯的，你买个东西都是假的，打个疫苗。\n我说这两天中国都在跟台风两个台风做斗争，一个台风是无形的，一个台风是有形的，无形的台风就是疫苗，它冲击的是我们内心安全的堤坝。 另一个台风，中国很少有从上海登陆的台风，这是题外话，接下来你就要去思考的是，你独善其身，你发生了很大的变化，你拥有了很多的答案，周围的环境不变化，你会幸福吗？我有八个字说得比较重，我觉得我们现在是道德赤字人性亏损，这才是目前最大的赤字和最大的亏损。前些天就在离这不远，我亲眼见到了两个车相撞，其实撞的没那么严重，该负责任的，因为他撞了另一个车，跟人家说咱停到路边，人家好也慢慢说准备停到路边了，前面的车撒丫子跑了，一车人也没有拦着他的。\n这会是一个负责任的父亲吗？这会是一个负责任的儿子吗？更不要说他怎么会是一个负责任的公民，而他可能是您的同事，这就是道德赤字和人性亏损也，必然会影响到你。你不管自己是多么一个大写的人，除非你足不出户，但问题是，足不出户也不妨碍您的孩子要打疫苗，您送外卖，那外卖也有可能有问题！\n所以中国人如何学会由一个小老百姓变成一个公民，这可能是在我40岁的时候，既问给自己这个人，也问给社会的一个重要的命题。\n如果说30岁是减法，40岁是困惑，我觉得50岁应该是我送给自己的词是好奇，50岁很尴尬，前不着村后不着店，进、可攻；退、要混，也可以。在自己取得的某种东西上躺10年，混到退休也似乎可以。\n最近看一本书，其中一本书上写得非常有意思，说在硅谷里真正成功的创业者，五六十岁的偏多，这跟我们的概念是不同的。中国如何什么时候能够不把创业全部当成年轻的事业，就跟中国不该把志愿者都当成青年志愿者一样。上一周我做了一期节目，是中国马上要招募退休的中小学教师，每年有二三万块钱的补助，然后去乡村当老师，而且必须是优秀的。我说这正是开启了退休后再就业的先河，当然不光是慈善了，但是回到50，离那块还有点距离，你怎么去向前走？\n五十岁 更重要的是对于50岁的人来说有两个挑战，第1个挑战是你自己，你是不是还对很多的事情好奇，你的人生观是如何的？我觉得我的50岁最大的收获，或者是我此时按照什么方式在活着，我善待每一个今天，20岁的时候容易活在明天里，一不注意50岁容易活在昨天里，但是我努力的克制自己，既不活在明天，也不活在昨天，我善待每一个今天，50岁的人就不该总是明天再说，或者昨天真好！\n我觉得今天最好那天看蔡琴的演唱会碟，蔡琴说的一句话是蛮好的，他说每次看照片我都觉得两年前的我真好看，但是两年前的那一天，我从来没觉得自己好看过。这句话挺有味道的。我30岁的时候没觉得，那个时候我挺帅的，觉得自己的毛病很多，可是今天当我隔了20年回头看的时候。\n原来我也年轻过，原来我头发那么多，所以善待你的每一个今天，两年后再看您的今天最好不过了。\n就像史铁生说的那番话，当我的腿刚不能走路的时候，我坐在轮椅上天天怀念我能奔跑打篮球的时光，每天在怀念中都非常痛苦。 又隔了几年，我在轮椅上生了褥疮，浑身难受，那个时候天天怀念，几年前我什么都不疼，安静的能坐在轮椅上的时光。 又隔了一些年，我得了尿毒症，我总要去透析，这个时候我就怀念当初仅仅有褥疮的轮椅时光，那50岁如果再活不到善待每一个今天的地步，前面的50年白过了。\n其实我觉得别等到50岁才明白这个道理，30、40就该明白，所有的东西都容易轻易的错过。旅行中的一顿饭，你只要没吃，再吃30年后了，还不一定是味道，所以我觉得善待每一个今天是我50岁时候的第一个感受。\n第二个就是好奇，我发现我随时可以不再对很多事情好奇了，因为见过了很多，体验了很多，但是我督促自己好奇。所以现在做很多事，我都带着好奇的心，手机可不可以竖着拍，也可以，你去做现场报道，去做看似很大得很庄严的什么峰会，你连线可不可以更轻松？更好玩，更让大家印象深刻，你可不可以然后又用新媒体去进行传播，都可以。我觉得好奇是督促人类进步的最重要的一种一个动力，为什么不能成为督促一个个体进步的最重要动力？一个民族只要不好奇了，这个民族吹了。另外一个大的层面，50岁是一个重要的考验。四五十岁的时候，在中国你做一个怎样的既得利益者？我非常担心我们身边的很多人年轻的时候，因为希望而要去实现很多的梦想，但是一旦自己实现了梦想，成为既得利益者了，变成为阻拦别人实现梦想的人，我说的没错吧？ 转眼就用他曾经最不喜欢的方式在对待年轻人和事儿。\n因此在几年前我自己就开始以志愿者的身份每年招11个研究生，一待待两年，现在已经毕业了5期，有55个纯研究生，已经毕业了。我觉得做这样的既得利益者是件很幸福的事，你拥有了某些感触，你也有能力去带他们，每上完一天课，晚上请他们吃饭，花不了多少。但是这是一个好的既得利益者应该做的，既得利益者有可能是两个方面，一方面是重新成为铺路石。我曾经说过一句话，我说我不想太多的对帮助过我的人说谢谢，因为我要以加倍的方式去对待新的年轻人，这就是我说谢谢的方式。\n如果天天在那说谢谢你，却成为阻拦者。接下来就是为别人铺路。我希望中国不管是物质的、经济的、思想的、文化的、各个领域的既得利益者，当你成了的时候，要考虑你该怎么做？昨天推火车的人今天成了拦火车的人，回头看中国的历史到处如此，今天也不会。不是这样，甚至有的时候会更多，所以呼吁所有的既得利益者能重新像你年轻的时候，希望碰到什么样的人那样去做，那样的人我也许做的不够好，但起码我在想、在做、在说。\n","date":"2020-02-14T07:27:21+08:00","permalink":"https://ttf248.life/p/about-time-and-books/","title":"关于光阴，你要读很多书才能找到答案"},{"content":"自定义分配器可以提升性能、提高内存使用效率，并解决频繁少量内存分配的问题。\n前因 近期接触到了网络网络数据包的开发，需要频繁的申请和释放小块的内存，原本想着使用内存池，查看了几个现有的内存池，发现了这个\nhttps://github.com/cacay/MemoryPool\n看到接口的时候，就比较纳闷，这个内存池的实现怎么有点奇怪。MemoryPool的实现逻辑，是在申请固定大小的内存空间。看过boost的内存池接口，提供的是一个模板，用的时候进行实例化。正巧这个库已经有文章进行过介绍，提到了allocator这个概念。\nwiki 在C++编程中，分配器（英语：allocator）是C++标准库的重要组成部分。C++的库中定义了多种被统称为“容器”的数据结构（如链表、集合等），这些容器的共同特征之一，就是其大小可以在程序的运行时改变；为了实现这一点，进行动态内存分配就显得尤为必要，在此分配器就用于处理容器对内存的分配与释放请求。换句话说，分配器用于封装标准模板库（STL）容器在内存管理上的低层细节。默认情况下，C++标准库使用其自带的通用分配器，但根据具体需要，程序员也可自行定制分配器以替代之。\n分配器最早由亚历山大·斯特潘诺夫作为C++标准模板库（Standard Template Library，简称STL）的一部分发明，其初衷是创造一种能“使库更加灵活，并能独立于底层数据模型的方法”，并允许程序员在库中利用自定义的指针和引用类型；但在将标准模板库纳入C++标准时，C++标准委员会意识到对数据模型的完全抽象化处理会带来不可接受的性能损耗，为作折中，标准中对分配器的限制变得更加严格，而有鉴于此，与斯特潘诺夫原先的设想相比，现有标准所描述的分配器可定制程度已大大受限。\n虽然分配器的定制有所限制，但在许多情况下，仍需要用到自定义的分配器，而这一般是为封装对不同类型内存空间（如共享内存与已回收内存）的访问方式，或在使用内存池进行内存分配时提高性能而为。除此以外，从内存占用和运行时间的角度看，在频繁进行少量内存分配的程序中，若引入为之专门定制的分配器，也会获益良多。\n使用需求 定义自定义分配器的主要原因之一是提升性能。利用专用的自定义分配器可以提高程序的性能，又或提高内存使用效率，亦或两者兼而有之[4][8]。默认分配器使用new操作符分配存储空间[文 5]，而这常利用C语言堆分配函数（malloc()）实现[9]。由于堆分配函数常针对偶发的内存大量分配作优化，因此在为需要一次分配大量内存的容器（如向量、双端队列）分配内存时，默认分配器一般效率良好[8]。但是，对于关联容器与双向链表这类需要频繁分配少量内存的容器来说，若采用默认分配器分配内存，则通常效率很低[4][9]。除此之外，基于malloc()的默认分配器还存在许多问题，诸如较差的引用局部性[4]，以及可能造成内存碎片化[4][9]。\n简言之，此段（……）（如同）是这一标准针对分配器的一场《我有一个梦想》的演讲。在梦想成真之前，关心可移植性的程序员将把自己局限于（使用）无状态的自定义分配器上。 ——斯科特 梅耶斯，《Effective STL》 有鉴于此，在这一情况下，人们常使用基于内存池的分配器来解决频繁少量分配问题[8]。与默认的“按需分配”方式不同，在使用基于内存池的分配器时，程序会预先为之分配大块内存（即“内存池”），而后在需要分配内存时，自定义分配器只需向请求方返回一个指向池内内存的指针即可；而在对象析构时，并不需实际解除分配内存，而是延迟到内存池的生命周期完结时才真正解除分配[注 1][8]。\n在“自定义分配器”这一话题上，已有诸多C++专家与相关作者参与探讨，例如斯科特·梅耶斯的作品《Effective STL》与安德烈·亚历山德雷斯库的《Modern C++ Design》都有提及。梅耶斯洞察到，若要求针对某一类型T的分配器的所有实例都相等，则可移植的分配器的实例必须不包含状态。虽然C++标准鼓励库的实现者支持带状态的分配器[文 4]，但梅耶斯称，相关段落是“（看似）美妙的观点”，但也几乎是空话，并称分配器的限制“过于严苛”[4]。例如，STL的list允许splice方法，即一个list对象A的节点可以被直接移入另一个list对象B中，这就要求A的分配器申请到的内存，可被B的分配器释放掉，从而推导出A与B的分配器实例必须相等。梅耶斯的结论是，分配器最好定义为使用静态方法的类型。例如，根据C++标准，分配器必须提供一个实现了rebind方法的other类模板。\n另外，在《C++程序设计语言》中，比雅尼·斯特劳斯特鲁普则认为“‘严格限制分配器，以免各对象信息不同’，这点显然问题不大”（大意），并指出大部分分配器并不需要状态，甚至没有状态情形下性能反倒更佳。他提出了三个自定义分配器的用例：内存池型的分配器、共享内存型分配器与垃圾回收型分配器，并展示了一个分配器的实现，此间利用了一个内部内存池，以快速分配/解除分配少量内存。但他也提到，如此优化可能已经在他所提供的样例分配器中实现[3]。\n自定义分配器的另一用途是调试内存相关错误[10]。若要做到这一点，可以编写一个分配器，令之在分配时分配额外的内存，并借此存放调试信息。这类分配器不仅可以保证内存由同类分配器分配/解除分配内存，还可在一定程度上保护程序免受缓存溢出之害[11]。\n","date":"2019-12-30T13:26:19+08:00","permalink":"https://ttf248.life/p/standard-library-container-memory-allocator/","title":"标准库容器的内存分配器：allocator"}]
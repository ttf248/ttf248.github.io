<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>コンピュータ on 向叔の手帳</title>
        <link>https://ttf248.life/ja/categories/%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF/</link>
        <description>Recent content in コンピュータ on 向叔の手帳</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>ja</language>
        <lastBuildDate>Wed, 28 May 2025 03:11:57 +0800</lastBuildDate><atom:link href="https://ttf248.life/ja/categories/%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>GitHub Pages ギミック：複数のPagesをデプロイする</title>
        <link>https://ttf248.life/ja/p/github-pages-easter-egg-deploy-multiple-sites/</link>
        <pubDate>Wed, 28 May 2025 02:55:54 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/github-pages-easter-egg-deploy-multiple-sites/</guid>
        <description>&lt;p&gt;最近、体内時計が少し狂っていて、深夜2時過ぎまでGitHub Pagesのデプロイに手を出していた。&lt;/p&gt;
&lt;p&gt;終わった後、やっとご飯を食べに行ったんだけど、食べた直後に眠くなり、食べて帰ってきて8時半くらいには、眠くて、少し仮眠ったらそのまま寝てしまい、起きたらもう午前2時過ぎだった。&lt;/p&gt;
&lt;p&gt;まだ始動もせず消滅したカテゴリー：AI 研習会&lt;/p&gt;
&lt;p&gt;ツッコミ&lt;/p&gt;
&lt;p&gt;昨日まで「フロントエンドをいじらない」と言っていたのに、今日はフロントエンドではなく、UI/UXの体験についていじっている。&lt;/p&gt;
&lt;p&gt;プロジェクト&lt;/p&gt;
&lt;p&gt;皆様、弊社の旧友である&lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/ai-coding-demo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/ai-coding-demo&lt;/a&gt;をご紹介させていただきます。&lt;/p&gt;
&lt;p&gt;その通り、元々選択した株のプロジェクトです。このプロジェクトで全体の構造を再構築し、今後のAIプログラミング関連の内容はこちらに統合していきます。&lt;/p&gt;
&lt;p&gt;複数のページを部署する。&lt;/p&gt;
&lt;p&gt;プロジェクトは[https://cnb.cool/ttf248/ai-coding-demo]でホストされています。周知の事情により、中国国内ではPagesを公開できないため、海外のGitHubに公開する必要があります。&lt;/p&gt;
&lt;p&gt;ブログは海外のGithubに公開されているものです。まだ試していませんが、複数のプロジェクトでpagesを公開したり、現在取り組んでいるプロジェクトが従来のブログサイトではなく、多くのドキュメントといくつかの静的なhtmlデザインが含まれているという状況です。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/github-pages-easter-egg-deploy-multiple-sites/20250528030230.png&#34;
	width=&#34;798&#34;
	height=&#34;530&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;pages&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;150&#34;
		data-flex-basis=&#34;361px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;はい、このページは私が最初にクリックして気づいたのですが、複数のプロジェクトをデプロイしたpagesはブログの公開に影響を与えず、ブログのドメイン下に新しいパスが追加されるだけです。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://ttf248.life/ai-coding-demo/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ttf248.life/ai-coding-demo/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ここを見て、まさに完璧だと思った。&lt;/p&gt;
&lt;p&gt;AI研究会&lt;/p&gt;
&lt;p&gt;昨日新設したカテゴリーで、AIを使って多くのコンピュータのコースを学習しようと考えた。例えば、アルゴリズムや LeetCode の問題演習など。&lt;/p&gt;
&lt;p&gt;毎回の学習記録をブログに投稿し、知識データベースを構築。新カテゴリー「AI 研習会」を作成しました。&lt;/p&gt;
&lt;p&gt;今のところ、異なるコースごとに新しいプロジェクトを作成し、学習ノートは各プロジェクトのReadme.mdにまとめて記述するのが良いようだ。&lt;/p&gt;</description>
        </item>
        <item>
        <title>古傷、華やかさに惑わされる瞳</title>
        <link>https://ttf248.life/ja/p/old-ailment-stunning-flowers/</link>
        <pubDate>Mon, 26 May 2025 23:54:12 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/old-ailment-stunning-flowers/</guid>
        <description>&lt;p&gt;長年バックエンド開発に注力していましたが、最近になりAIプログラミングの探求を始め、フロントエンド関連の内容にも触れました。しかし、この試行錯誤の中で、また昔からある癖——華やかさに目がくらむ——に陥っていることに気づきました。AIを使ってフロントエンドインターフェースを実現したいと考えがちですが、実際には現在の仕事に対する具体的な助けにはならず、むしろ気を散らすだけです。&lt;/p&gt;
&lt;p&gt;AIの適用場面&lt;/p&gt;
&lt;p&gt;小規模プロジェクトにおいて、AIツールは特に大きな効果を発揮します。独立性が高く、システムとの結合度が低く、ビジネスロジックが単純な関数を記述する際には、いっそうその手腕が光ります。これらのタスクは通常、明確な入力と出力があり、コンテキスト依存性が少ないため、現在のAIによるプログラミング支援の能力範囲に最適です。&lt;/p&gt;
&lt;p&gt;しかし、複雑なシステムアーキテクチャや高度なビジネスロジックに直面すると、AIの限界が徐々に明らかになる。一見妥当に見えるものの、実際にはプロジェクトの真の要求から逸脱したコードを生成したり、原因究明が困難な潜在的な問題を導入したりする可能性がある。このような状況では、AIは完全なコードジェネレーターとしてではなく、むしろ補助ツールとして活用すべきである。生成されたコードについては厳格なレビューとテストを行い、実際の要件を満たしていることを確認する必要がある。&lt;/p&gt;
&lt;p&gt;間違いと学習の代償&lt;/p&gt;
&lt;p&gt;AIによるフロントエンドコード生成を試みる中で、多くの課題に直面しました。フロントエンドは得意分野ではないため、問題の切り分けには時間と労力がかかります。プロンプトを調整してAIにコードを書き直しても、初歩的なエラーを避けることは難しいです。この繰り返しの試行錯誤は時間を浪費するばかりで、現在の自分の努力は、不慣れなフロントエンドではなく、バックエンドのビジネスロジックに集中すべきだと気づかされました。&lt;/p&gt;
&lt;p&gt;週末に完了したプロジェクトを振り返ると、バックエンド開発とユーザーインタラクションロジックに集中し、コンソールで機能を実装することが現時点で最も効率的な選択だと確信する。より多くの時間とエネルギーがある時に、フロントエンドの知識を体系的に学ぶ方が良い戦略かもしれない。&lt;/p&gt;
&lt;p&gt;フロントエンド学習計画&lt;/p&gt;
&lt;p&gt;フロントエンド技術のスタックは複雑で多様なため、すぐに習得するのは現実的ではありません。まずは Vue.js や React.js のようなフレームワークを一つ選び、そのコアコンセプトと使い方を深く学習する予定です。基礎知識に慣れてからこそ、AI を活用してフロントエンドコードを生成することで初めて、不慣れによるエラーや時間浪費を効果的に回避できます。&lt;/p&gt;
&lt;p&gt;結局、現段階ではバックエンド開発に重点を置き、着実にコアスキルを向上させることが重要だ。時機が整ったら、フロントエンドとAIの組み合わせを探求するのも良いかもしれないし、より大きな成果が得られるかもしれない。&lt;/p&gt;</description>
        </item>
        <item>
        <title>クロード4リリース、試作：Hugoタグ、ハイパーリンク翻訳アシスタント</title>
        <link>https://ttf248.life/ja/p/claude-4-release-and-experimentation-hugo-tags-hyperlink-translation-assistant/</link>
        <pubDate>Sat, 24 May 2025 03:05:31 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/claude-4-release-and-experimentation-hugo-tags-hyperlink-translation-assistant/</guid>
        <description>&lt;p&gt;このサイトはHugoで開発されているのですが、筆者はいつも中国語のタイトルを使っているため、生成される記事のハイパーリンクが親しみやすくありません。要するに、発信したときに見栄えが悪く、中国語の文字がハイパーリンク内で%E4%BD%A0%E5%A5%BDのような形式に変換されてしまうのです。Slugを設定すれば解決できるのですが、毎回手動で設定する必要があり、面倒です。&lt;/p&gt;
&lt;p&gt;そこで、今日はClaude4を使って翻訳アシスタントを開発してみようと思います。中国語のタイトルを自動的に英語のスラッグに変換し、記事中にハイパーリンクを追加することで、手動設定の手間を省きます。&lt;/p&gt;
&lt;p&gt;クロード4は素晴らしい、文脈理解能力と複雑なタスク処理の効率が大幅に向上している。&lt;/p&gt;
&lt;p&gt;プロジェクトアドレス&lt;/p&gt;
&lt;p&gt;国内プロジェクトアドレス：&lt;a class=&#34;link&#34; href=&#34;https://cnb.cool/ttf248/hugo-content-suite&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://cnb.cool/ttf248/hugo-content-suite&lt;/a&gt;
海外プロジェクトの場所：&lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/hugo-content-suite&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/hugo-content-suite&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;コード実装&lt;/p&gt;
&lt;p&gt;実装のアイデアですが、まず全ての記事をスキャンし、タグ情報と記事タイトルを抽出した後、ローカルの大規模言語モデル（gemma-3-12b-itなど）を用いて翻訳します。&lt;/p&gt;
&lt;p&gt;実際の開発において、以前のモデルと比較して、&lt;code&gt;Claude4&lt;/code&gt; はいくつかの顕著な特徴を示しています。多岐にわたる機能要件に対応するため、&lt;code&gt;Claude4&lt;/code&gt; は自動的にインタラクティブメニューを設計し、様々な使用シナリオを網羅的に考慮しています。例えば、タグ処理に関して、&lt;code&gt;Claude4&lt;/code&gt; はタグの統計と分析だけでなく、分類統計もサポートし、さらには&lt;strong&gt;未ラベルの記事&lt;/strong&gt;を検出することも可能です。また、&lt;strong&gt;プレビュー&lt;/strong&gt;機能やタグページ生成機能も提供されています。&lt;/p&gt;
&lt;p&gt;ローカルLLMとの連携、翻訳キャッシュの追加、広範囲にわたるコードのリファクタリングなど、あらゆることを&lt;code&gt;Claude4&lt;/code&gt;が一括で完了させ、ほとんど問題なく実行できた。プロジェクト規模は大きくないものの、多くの小機能が含まれていた。従来の大規模言語モデルでは開発中に内容を忘れてしまうことが多かったが、今回の&lt;code&gt;Claude4&lt;/code&gt;は非常に優れたパフォーマンスを発揮し、&lt;strong&gt;コンテキストの忘れがあまり見られなかった&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;要するに、知能が向上し、次はその後の開発作業を &lt;code&gt;Claude4&lt;/code&gt; に移行する予定です。日常のコーディングにおける主力モデルとして活用します。&lt;/p&gt;
&lt;p&gt;翻訳キャッシュ&lt;/p&gt;
&lt;p&gt;この点に関しては、大規模言語モデルの呼び出し回数を減らすだけでなく、実際にローカルで12Bモデルを実行すると、効率は高く、作業を妨げることはありません。しかし、毎回大規模言語モデルを呼び出すと少し遅くなることがあります。また、記事の関連性を固定するために全量更新を行う際、記事のタイトルが長い場合、稀に翻訳結果が異なり、記事のリンクが変わってしまうという事態が発生することがあり、これは非常に困ります。&lt;/p&gt;
&lt;p&gt;機能改善&lt;/p&gt;
&lt;p&gt;プロジェクト全体を &lt;code&gt;Claude4&lt;/code&gt; に投げ込み、最適化の余地を分析した結果、以下の提案が得られました。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;配置外置化 - 提高可维护性和灵活性
结构化日志 - 便于问题排查和监控
性能监控 - 了解系统运行状况
用户体验 - 进度条等视觉反馈
错误处理 - 更完善的异常处理机制
代码组织 - 更清晰的模块划分
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;コードを確認しました、全て問題ありません。例えば設定ファイルですが、元のコードの設定をデフォルト設定に変換し、設定ファイルを読み込む際に、対応する設定ファイルがない場合、自動的にデフォルトの設定ファイルが生成されるため、ユーザーの誤りを避けることができます。&lt;/p&gt;
&lt;h3 id=&#34;heading&#34;&gt;
&lt;/h3&gt;&lt;p&gt;要件：本文を翻訳する際、現在の翻訳効率を動的に計算し、残りの時間を予測し、関連情報をコンソールに出力すること。現在、記事の文字数を取得済み。各行を翻訳する際に、現在の翻訳文字数、時間、100字あたりの翻訳時間の推定値を算出し、同時に記事全体の翻訳にかかる残り時間を予測する。&lt;/p&gt;
&lt;p&gt;コードは終わったけど、あまり満足いかないので、AIに新しいデザイン案を提供してもらった。&lt;/p&gt;
&lt;p&gt;効率計算方法を複数提供：リアルタイム効率、平均効率、スライディングウィンドウ効率
表示方法を改善：プログレスバー、段階的統計、動的更新
より多くの有用な指標を追加する：API呼び出し回数、成功率など&lt;/p&gt;
&lt;p&gt;コードが完了した後、新たな驚きがありましたが、翻訳効率の統計情報がリアルタイムで表示され、無駄なスクロールは発生しませんでした。&lt;/p&gt;
&lt;p&gt;翻訳本文を英語に（合計7163文字）…
検出された翻訳が必要な行は53行です。
[1/53] ステージ1/6 [░░░░░░░░░░░░░░░░░░░░░░░░░] 1.9% 翻訳 354 文字…
完了 (3.1秒) | API呼び出し #1
完了 (1.5秒) | API呼び出し #2
完了 (0.9秒) | API呼び出し #3
完了 (0.2秒) | API呼び出し#4
完了 (1.0秒) | API呼び出し #5
完了 (1.0秒) | API呼び出し #6
完了 (0.2秒) | API呼び出し #7
進捗：行 13.2% (7/53) | 文字 12.9% (925/7163) 114.6 字/秒
⚡効率：リアルタイム76.4｜平均117.9｜最近109.0｜段階113.6文字/秒 📊
成功率：100.0%（7/7）| 残り：46行、7秒] 9.4% 翻訳 110文字…
残り時間: 55秒 | 推定完了: 00:10:19 8秒] 進捗 11.3% 翻訳 114 文字…
処理速度: 3211.3 行/分 | 合計時間: 8秒] 13.2% 翻訳 16 文字…
[8/53] ステージ1/6 [███░░░░░░░░░░░░░░░░░░░░░░] 15.1% 翻訳 166 文字…&lt;/p&gt;
&lt;p&gt;以前は制御プログラムをあまり書いていなかったので、どのように実現されているのか興味があり、コードを確認した。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;// 清屏并重新显示 (动态刷新效果)
if translationCount &amp;gt; 1 {
   fmt.Print(&amp;quot;\033[6A\033[K&amp;quot;) // 上移6行并清除
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;性能統計メニュー&lt;/p&gt;
&lt;p&gt;自分で設計したわけでもないのに、新機能の&lt;strong&gt;パフォーマンス統計メニュー&lt;/strong&gt;がこんなに完成されているとは。&lt;/p&gt;
&lt;p&gt;パフォーマンス統計：
翻訳回数: 360
キャッシュヒット率：1.4%（5/365）
平均翻訳時間: 315.927234ms
ファイル操作：73
試行回数：0&lt;/p&gt;
&lt;p&gt;進捗状況表示&lt;/p&gt;
&lt;p&gt;新たに追加された&lt;strong&gt;プログレスバー表示&lt;/strong&gt;。詳細な進捗状況、経過時間、および残り時間の推定値。&lt;/p&gt;
&lt;p&gt;機能を選択してください (0-13): 10
翻訳目標を収集中です。
キャッシュファイルが読み込まれました。翻訳記録は 0 件です。&lt;/p&gt;
&lt;p&gt;翻訳キャッシュ統計:
🏷️ ラベル総数：229個
記事総数：131件
キャッシュ済み: 0 個
360個&lt;/p&gt;
&lt;p&gt;確認しますか？ 全量翻訳キャッシュを生成します。(y/n): y
🚀 全量翻訳キャッシュを生成中…
キャッシュファイルが読み込まれました。翻訳記録は 0 件です。
翻訳をキャッシュから確認中…
🔄 360個の新しいタグを翻訳する必要があります。
[░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 5/360 (1.4%) - 時間: 3秒 - 残り時間: 3分8秒💾 キャッシュファイル保存済み、翻訳記録5件を含む
[█░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 10/360 (2.8%) - 時間: 6秒 - 残り時間: 3分28秒💾 キャッシュファイル保存済み、翻訳記録10件を含む
[██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 15/360 (4.2%) - 時間: 9秒 - 残り時間: 3分30秒💾 キャッシュファイル保存済み、翻訳記録15件を含む
[██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 20/360 (5.6%) - 時間: 13秒 - 残り時間: 3分36秒💾 キャッシュファイル保存済み、翻訳記録20件を含む
[███░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 25/360 (6.9%) - 時間: 16秒 - 残り時間: 3分33秒💾 キャッシュファイル保存済み、25件の翻訳記録を含む
[████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 30/360 (8.3%) - 時間: 19秒 - 残り時間: 3分30秒💾 キャッシュファイル保存済み、30件の翻訳記録を含む
[████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 35/360 (9.7%) - 時間: 22秒 - 残り時間: 3分25秒💾 キャッシュファイル保存済み、35件の翻訳記録を含む&lt;/p&gt;
&lt;hr&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;=== Hugo 博客管理工具 ===

🚀 核心功能
  1. 一键处理全部 (完整博客处理流程)

📝 内容管理
  2. 生成标签页面
  3. 生成文章Slug
  4. 翻译文章为多语言版本

💾 缓存管理
  5. 查看缓存状态
  6. 生成全量翻译缓存
  7. 清空翻译缓存

  0. 退出程序
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>ForkリポジトリへのPullRequestのマージ</title>
        <link>https://ttf248.life/ja/p/merge-pullrequest-to-fork-repository/</link>
        <pubDate>Wed, 07 May 2025 18:44:03 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/merge-pullrequest-to-fork-repository/</guid>
        <description>&lt;p&gt;&lt;code&gt;github-readme-stats&lt;/code&gt;は、GitHubプロフィール用の統計情報ジェネレーターであり、ユーザーが自身のGitHubプロフィールに様々な統計情報やグラフを表示することを可能にします。多様なカスタマイズオプションが用意されており、ユーザーのニーズに合わせて調整できます。&lt;/p&gt;
&lt;p&gt;筆者は倉庫の管理をプロジェクトごとに分けていますが、GitHubでは倉庫のグループ化がサポートされていないため、異なる組織に分割するという方法で対応しています。&lt;code&gt;github-readme-stats&lt;/code&gt; の最新ブランチは、異なる組織の倉庫を跨いだ統計に対応していないため、筆者がフォークしたブランチに該当するコードをマージしました。&lt;/p&gt;
&lt;h2 id=&#34;最終効果&#34;&gt;最終効果
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://github-readme-stats-chi-one-17.vercel.app/api?username=ttf248&amp;amp;hide_title=true&amp;amp;show_icons=true&amp;amp;hide=contribs&amp;amp;line_height=24&amp;amp;include_all_commits=true&amp;amp;count_private=true&amp;amp;bg_color=0000&amp;amp;text_color=8A919F&amp;amp;locale=cn&amp;amp;role=OWNER,COLLABORATOR,ORGANIZATION_MEMBER&amp;amp;timstamp=1746608356&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;GitHub Stats&#34;
	
	
&gt;
&lt;img src=&#34;https://github-readme-stats-chi-one-17.vercel.app/api/top-langs/?username=ttf248&amp;amp;hide_title=true&amp;amp;hide=html,javascript,css&amp;amp;layout=compact&amp;amp;bg_color=0000&amp;amp;text_color=8A919F&amp;amp;locale=cn&amp;amp;role=OWNER,COLLABORATOR,ORGANIZATION_MEMBER&amp;amp;timstamp=1746608356&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Top Languages&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;プルリクエストの元のurl&#34;&gt;プルリクエストの元のURL
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/anuraghazra/github-readme-stats/pull/2459&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Adds the ability to include data from organization repositories&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;pull-request-を-fork-のリポジトリにマージする&#34;&gt;Pull Request を Fork のリポジトリにマージする
&lt;/h2&gt;&lt;p&gt;プルリクエスト（PR）をあなたのフォークしたリポジトリにマージするには、いくつかの方法があり、それはあなたが何をしたいかによって異なります。&lt;/p&gt;
&lt;p&gt;アップストリームリポジトリからPRをあなたのフォークにマージしますか、それとも
他の人のフォークからPRをあなたのフォークにマージする、または
フォークされたリポジトリからのプルリクエストをマージする（例えば、誰かがあなたにフォークしてプルリクエストを提出した場合）。&lt;/p&gt;
&lt;p&gt;まず、最も一般的なシナリオを説明します。&lt;strong&gt;リポジトリをフォークし、上流のプルリクエストを自分のフォークにマージしたい場合&lt;/strong&gt;です。手順は以下の通りです。👇&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;方法一コマンドライン方式最も汎用的&#34;&gt;方法一：コマンドライン方式（最も汎用的）
&lt;/h3&gt;&lt;h4 id=&#34;ステップ1自分のフォークをクローンする&#34;&gt;ステップ1：自分のフォークをクローンする
&lt;/h4&gt;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/你的用户名/仓库名.git
cd 仓库名
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;ステップ-2upstreamオリジナルリポジトリのアドレスを追加する&#34;&gt;ステップ 2：upstream（オリジナルリポジトリのアドレス）を追加する
&lt;/h4&gt;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git remote add upstream https://github.com/原作者用户名/仓库名.git
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;ステップ3アップストリームのprブランチをリベースする&#34;&gt;ステップ3：アップストリームのPRブランチをリベースする
&lt;/h4&gt;&lt;p&gt;PR番号を見つけてください。例えば、PR#123です。&lt;/p&gt;
&lt;p&gt;PR のコードは、このようにプルできます。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git fetch upstream pull/123/head:pr-123
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;ステップ-4ブランチの切り替えとマージ&#34;&gt;ステップ 4：ブランチの切り替えとマージ
&lt;/h4&gt;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git checkout main    # 或者你自己的目标分支
git merge pr-123
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;もしすべてが正常であれば、あなたのフォークしたGitHubリポジトリにプッシュできます。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git push origin main
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h3 id=&#34;方法二github-网页界面简单但有限-第二の方法githubウェブインターフェース簡単だが機能は限られている&#34;&gt;方法二：GitHub 网页界面（简单但有限） 第二の方法：GitHubウェブインターフェース（簡単だが機能は限られている）
&lt;/h3&gt;&lt;p&gt;GitHubのウェブページでプルリクエストがアップストリームのリポジトリに対するものである場合、あなたは：&lt;/p&gt;
&lt;p&gt;そのPRページにアクセスしてください。
右上隅の「&lt;strong&gt;Commits&lt;/strong&gt;」または「&lt;strong&gt;Files changed&lt;/strong&gt;」をクリックして、このPRがどのブランチに基づいているか確認してください。
あなたのフォークページで新しいブランチを作成し、手動でPRのコミットをcherry-pickします。（Gitの知識が必要です。）
または「&lt;strong&gt;GitHub Desktopで開く&lt;/strong&gt;」をクリックして、GUIツールを使ってマージしてください。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-もし他の人があなたのフォークに対してprを提出したら&#34;&gt;🚀 もし他の人があなたのフォークに対してPRを提出したら
&lt;/h3&gt;&lt;p&gt;プルリクエストのマージページに直接アクセスして、「&lt;strong&gt;Merge pull request&lt;/strong&gt;」ボタンをクリックしてください。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;今の具体的な状況（例えばPRリンクや、ウェブページかコマンドラインのどちらを使っているか）に合わせて、私が手取り直して説明しましょうか？具体的なリンクを教えていただければ、一番簡単な方法を分析してお手伝いします。&lt;/p&gt;</description>
        </item>
        <item>
        <title>Git のコミット履歴のメッセージ変更</title>
        <link>https://ttf248.life/ja/p/git-modify-commit-message/</link>
        <pubDate>Wed, 07 May 2025 18:38:31 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/git-modify-commit-message/</guid>
        <description>&lt;p&gt;スクリプトは、git filter-branch を使用して、Git の履歴コミットの作成者情報を一括で変更するために使用されます。&lt;/p&gt;
&lt;p&gt;提供されたスクリプトは、Git リポジトリの過去のコミットの作成者情報を一括で変更するためのもので、全体的なコンセプトは正しいですが、&lt;code&gt;git filter-branch&lt;/code&gt; の &lt;code&gt;--env-filter&lt;/code&gt; で配列（例：&lt;code&gt;OLD_EMAILS=(&amp;quot;...&amp;quot;)&lt;/code&gt;）を使用すると、互換性の問題が生じる可能性があります。なぜなら、一部のシェル環境（&lt;code&gt;/bin/sh&lt;/code&gt; など）では配列構文がサポートされていないためです。&lt;/p&gt;
&lt;p&gt;互換性を高めるため、配列をスペースで区切られた文字列に置き換え、&lt;code&gt;for&lt;/code&gt;ループを使用して各古いメールアドレスを反復処理することをお勧めします。以下に変更後のスクリプトの例です。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/sh

git filter-branch --env-filter &#39;
OLD_EMAILS=&amp;quot;TianlongXiang51@gmail.com nick@qq.com tianlongxiang51@gmail.com&amp;quot;
CORRECT_NAME=&amp;quot;tianlong.xiang&amp;quot;
CORRECT_EMAIL=&amp;quot;tianlong.xiang@foxmail.com&amp;quot;

for OLD_EMAIL in $OLD_EMAILS
do
    if [ &amp;quot;$GIT_COMMITTER_EMAIL&amp;quot; = &amp;quot;$OLD_EMAIL&amp;quot; ]
    then
        export GIT_COMMITTER_NAME=&amp;quot;$CORRECT_NAME&amp;quot;
        export GIT_COMMITTER_EMAIL=&amp;quot;$CORRECT_EMAIL&amp;quot;
    fi
    if [ &amp;quot;$GIT_AUTHOR_EMAIL&amp;quot; = &amp;quot;$OLD_EMAIL&amp;quot; ]
    then
        export GIT_AUTHOR_NAME=&amp;quot;$CORRECT_NAME&amp;quot;
        export GIT_AUTHOR_EMAIL=&amp;quot;$CORRECT_EMAIL&amp;quot;
    fi
done
&#39; --tag-name-filter cat -- --branches --tags
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注意事項：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;スクリプトを実行する前に、予期せぬ事態を防ぐため、リポジトリのバックアップを取ることをお勧めします。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;この操作はGitの履歴を上書きし、コミットの作成者情報を変更するため、コミットハッシュ値が変化する可能性があります。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;変更をリモートリポジトリにプッシュしている場合は、強制プッシュを使用する必要があります。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git push --force --tags origin &#39;refs/heads/*&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;強制プッシュは慎重に行ってください。特に複数人で共同作業しているプロジェクトでは、他者に影響を与えないように注意してください。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;倉庫内の重複しない著者メールアドレスをすべて統計する。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git log --format=&#39;%an &amp;lt;%ae&amp;gt;&#39; | sort -u
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>暇つぶしに、中国の水墨画風のテーマをデザインしたい。</title>
        <link>https://ttf248.life/ja/p/chinese-ink-style-theme/</link>
        <pubDate>Tue, 08 Apr 2025 03:42:47 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/chinese-ink-style-theme/</guid>
        <description>&lt;p&gt;カラフルなホームページを見飽きて、急にシンプルなスタイルで、中国の水墨画風のテーマを作りたい気分だ。&lt;/p&gt;
&lt;p&gt;スタイルシートは現在、大幅に改造されており、異なる要素ごとに特定のスタイルが設定され、テーマのデフォルトスタイルを上書きするために使用されています。&lt;/p&gt;
&lt;p&gt;再構築なしで、AIに直接新しいテーマを生成させると、結果は非常に不安定です。&lt;/p&gt;
&lt;p&gt;偶然にもtrae claudeの大規模言語モデルの待ち行列に遭遇し、VS Codeエージェントモードに切り替えたところ、効果が非常に悪く、修正したものは全くデザイン性がない。&lt;/p&gt;
&lt;p&gt;結局、やはり自分はフロントエンドが理解できていないので、タスクをAIに効果的に分解して割り当てることができない。&lt;/p&gt;</description>
        </item>
        <item>
        <title>コードを書かずに、カスタム銘柄選択モジュールを設計・開発する。</title>
        <link>https://ttf248.life/ja/p/no-code-design-develop-custom-stock-module/</link>
        <pubDate>Thu, 27 Feb 2025 23:20:39 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/no-code-design-develop-custom-stock-module/</guid>
        <description>&lt;p&gt;先月、Cursor を試用しましたが、無料枠の制限により、複雑な機能開発は行わず、簡単なテストにとどまりました。その際、ByteDance も同様の商品をリリースしていることがわかり、両者とも基盤となる大規模言語モデルは Claude-3.5 でした。&lt;/p&gt;
&lt;p&gt;バイトのプロダクトTrae、まずMac版がリリースされ、今年の2月になってようやくWindows版もリリースされました。大手企業のものはやっぱり良いですね。無料で利用でき、お金を払わずにClaude-3.5を無制限に使えるので、このモデルの効果はなかなか良いです。&lt;/p&gt;
&lt;p&gt;最終、K線図の開発でつまずいてしまいました。私自身がreactの基礎をほとんど理解していないため、諦めざるを得ませんでした。開発を続けたいのであれば、筆者がフロントエンドの基礎知識を補強し、タスクをより細かく分割する必要があり、いきなり「K線図の開発」という大きなタスクを与えるべきではありません。&lt;/p&gt;
&lt;h2 id=&#34;発見された問題&#34;&gt;発見された問題
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;海外のAIモデルを使用するため、Vue3 + Element-Plus のトレーニングデータが不足しているため、React をフロントエンドフレームワークとして選択しました。&lt;/li&gt;
&lt;li&gt;文法的な誤りが偶発的に存在する可能性があり、手動での修正が必要です。&lt;/li&gt;
&lt;li&gt;複雑な問題の解決には、手動によるガイダンスが必要です。&lt;/li&gt;
&lt;li&gt;コード構造の最適化には人的指導が必要です。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最も時間がかかったのは、フロントエンドコードをコンテナにパッケージ化することです。筆者はゼロから始めたため、&lt;code&gt;.env.production&lt;/code&gt;や&lt;code&gt;tsconfig.json&lt;/code&gt;といった概念が全く理解できませんでした。途中で豆包（友人）に助けられたおかげで、ようやく対応するロジックを整理することができました。フロントエンドの開発におけるdevモードとbuildモードでは、コードのチェックに関して大きな違いがあります。バックエンドデータベースとサービスのコンテナスクリプトは、合わせて5分程度で終わりました。&lt;/p&gt;
&lt;p&gt;AIは現在、開発の効率を上げることに重点が置かれており、基礎があることが最も重要です。AIがすべての問題を解決するわけではありません。&lt;/p&gt;
&lt;h2 id=&#34;倉庫住所&#34;&gt;倉庫住所
&lt;/h2&gt;&lt;p&gt;タイトルが示すように、今回は書かずにAIと直接対話し、独自の株式モジュールを設計・開発します。最終的にどのような効果が得られるか見てみましょう。&lt;/p&gt;
&lt;p&gt;倉庫アドレス：&lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/trae-demo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/trae-demo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;詳細な使用方法は、倉庫のREADME.mdファイルを参照してください。&lt;/p&gt;
&lt;p&gt;倉庫には多くの提出記録が含まれており、そのほとんどが私とTraeとの会話記録、そして私がTraeのいくつかの機能に対して行ったテストです。それぞれの機能を達成するために手動介入を行ったかどうかを注記しています。&lt;/p&gt;
&lt;h2 id=&#34;prompt&#34;&gt;Prompt
&lt;/h2&gt;&lt;p&gt;プロジェクトはゼロから作成され、以下にプロンプトを示します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;基于项目原型图，开发功能：自选股，需要支持合约的新增、删除、修改、查询。自选股界面需要展示基础的行情数据。支持多个不同的市场切换。

前端：react
后端：golang gin gorm
数据库：PostgreSQL

服务端需要支持跨域请求，同时需要考虑数据的校验和错误处理，如果后端服务不可用，前端需要告警提示。

后端需要展示请求和应答的日志；前端也打印通讯的日志，方便排查问题。
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;ユーザーインターフェースとインタラクションの最適化&#34;&gt;ユーザーインターフェースとインタラクションの最適化
&lt;/h2&gt;&lt;p&gt;フロントエンドのインターフェースのデザインは完全にGrokに依存しており、まずTraeでプロダクトのプロトタイプを作成しましたが、美意識はありませんでした。使用しているモデルはコード生成能力は非常に高いですが、他の能力は弱いため、Grokを使ってフロントエンドUIを最適化する必要があります。&lt;/p&gt;
&lt;p&gt;現在のインターフェースのスクリーンショットを Grok にアップロードし、UI の最適化を依頼すると、一度に多くの改善提案が得られるかもしれない。私たちはそれらを評価し、Trae で実行して、最適化の効果を確認する。&lt;/p&gt;
&lt;h3 id=&#34;技術スタック&#34;&gt;技術スタック
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;フロントエンド：React + TypeScript&lt;/li&gt;
&lt;li&gt;バックエンド：Golang + Gin + GORM&lt;/li&gt;
&lt;li&gt;データベース：PostgreSQL 17&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;システムアーキテクチャ&#34;&gt;システムアーキテクチャ
&lt;/h2&gt;&lt;h2 id=&#34;バックエンドアーキテクチャ&#34;&gt;バックエンドアーキテクチャ
&lt;/h2&gt;&lt;p&gt;バックエンドはGolangのGinフレームワークでRESTful APIを実装しており、主なモジュールは以下の通りです。&lt;/p&gt;
&lt;p&gt;データベースモジュール&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GORM を ORM フレームワークとして使用する&lt;/li&gt;
&lt;li&gt;環境変数を設定してデータベース接続を構成する。&lt;/li&gt;
&lt;li&gt;自動的にデータベーステーブルを移行する&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ルーティングモジュール&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RESTful API 設計&lt;/li&gt;
&lt;li&gt;統一されたエラー処理メカニズム&lt;/li&gt;
&lt;li&gt;内蔵リクエストログ&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;越域処理&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ローカル開発環境でのクロスドメインをサポートする。&lt;/li&gt;
&lt;li&gt;設定可能なCORSポリシー&lt;/li&gt;
&lt;li&gt;Cookie のクロスドメインをサポート&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;フロントエンドアーキテクチャ&#34;&gt;フロントエンドアーキテクチャ
&lt;/h2&gt;&lt;p&gt;フロントエンドはReact + TypeScriptで構築されており、以下の機能を実装しています：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;株式リスト表示&lt;/li&gt;
&lt;li&gt;自主選択株式管理&lt;/li&gt;
&lt;li&gt;市場データ表示&lt;/li&gt;
&lt;li&gt;エラー通知メカニズム&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>プロトバッファのゼロ値トラップ：デフォルト値がビジネスロジックの隠れた殺人者となる場合</title>
        <link>https://ttf248.life/ja/p/protobuf-zero-value-traps/</link>
        <pubDate>Thu, 20 Feb 2025 15:26:51 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/protobuf-zero-value-traps/</guid>
        <description>&lt;p&gt;米国株には3つの取引時間帯があり、それぞれ盤前、盤中、盤後です。データインターフェースは、可能な限り帯域幅を節約するために、数値増分方式でデータをプッシュします。初回送信時はフルデータですが、2回目以降はすべてのフィールドが差分更新となります。&lt;/p&gt;
&lt;p&gt;なぜ最適な方法を使わないのか？いくつかのプロジェクトチームが関わっていて、すでに何年も稼働しているものもある。当方は新規の連携なので、できるだけ互換性を保つようにするしかない。&lt;/p&gt;
&lt;h2 id=&#34;一連の問題&#34;&gt;一連の問題
&lt;/h2&gt;&lt;p&gt;概要だけ見れば、まだ問題なさそうに見えるかもしれないが、システムアーキテクチャに問題を持ち込むと、一連の問題を引き起こす。先の問題を解決したと思ったら、また新しい問題が発生し、その問題は以前の問題が原因だ。&lt;/p&gt;
&lt;h3 id=&#34;取引期間を識別できません&#34;&gt;取引期間を識別できません。
&lt;/h3&gt;&lt;p&gt;既知ディスク上のフェーズ定義は、&lt;code&gt;protobuf&lt;/code&gt;で0と定義されていますが、データ受信時に増分プッシュであるため、ビジネス側はこの0がデフォルト値なのか、実際のビジネス値なのかを有効に識別できません。&lt;/p&gt;
&lt;p&gt;平たく言うと、0を受け取るたびに、その0が新しい相場設定の値なのか、それともprotobufのデフォルト値なのかを判断できないということです。&lt;/p&gt;
&lt;h3 id=&#34;オプション導入&#34;&gt;オプション導入
&lt;/h3&gt;&lt;p&gt;Since protobuf release 3.15, proto3 supports using the optional keyword (just as in proto2) to give a scalar field presence information&lt;/p&gt;
&lt;p&gt;グループ内の通信プロトコルは &lt;code&gt;protobuf&lt;/code&gt; をベースにしていますが、過去の経緯から古いバージョンが採用されており、&lt;code&gt;optional&lt;/code&gt; キーワードに対応していません。事情はよくわかっていると思いますが、&lt;code&gt;protobuf&lt;/code&gt;を基盤から導入しているため、プロジェクトは静的ライブラリとして配布され、そのためにはコンパイルチェーン全体をアップグレードする必要があります。このコストは非常に高いです。&lt;/p&gt;
&lt;h3 id=&#34;gccのバージョン問題&#34;&gt;GCCのバージョン問題
&lt;/h3&gt;&lt;p&gt;やっとの思いで計画を立てたものの、基盤に2つの異なるバージョンをリリースし、可能な限り&lt;code&gt;protobuf&lt;/code&gt;の新バージョンのコンパイル依存関係の伝播を制御しようとしたのですが、コンパイル時に&lt;code&gt;gcc&lt;/code&gt;のバージョンが低く、&lt;code&gt;protobuf&lt;/code&gt;の新機能に対応していないことがわかりました。&lt;/p&gt;
&lt;p&gt;チーム内でよく使用されるサーバーの種類：CentOS 7、CentOS 8。CentOS 7 のデフォルトの &lt;code&gt;gcc&lt;/code&gt; バージョンは 4.8 で、CentOS 8 のデフォルトの &lt;code&gt;gcc&lt;/code&gt; バージョンは 8.3 です。&lt;code&gt;protobuf&lt;/code&gt; の新機能には &lt;code&gt;gcc&lt;/code&gt; バージョンが 7.4 以上必要であるため、CentOS 7 ではサポートできません。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://gcc.gnu.org/bugzilla/show_bug.cgi?id=82461&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Bug 82461 - [7 Regression] Temporary required for brace-initializing (non-literal-type) member variable&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;最終、関連サービスのデプロイやコンパイルサーバーをCentOS 8に移行することで、この問題を解決しました。&lt;/p&gt;
&lt;h2 id=&#34;合理な列挙&#34;&gt;合理な列挙
&lt;/h2&gt;&lt;p&gt;問題全体を振り返ると、実はもっと簡単で効率的な解決策があります。それは、列挙の定義を調整し、0からではなく1から番号付けすることです。これにより、デフォルト値とビジネス値を効果的に区別でき、上記の様々な問題を回避できます。&lt;/p&gt;
&lt;h3 id=&#34;なぜ1から始めるのがもっと合理的だろうか&#34;&gt;なぜ1から始めるのがもっと合理的だろうか？
&lt;/h3&gt;&lt;p&gt;&lt;code&gt;protobuf&lt;/code&gt;において、列挙型のデフォルト値は常に0に固定されています。もしビジネス上の意味のある値を0として定義した場合（例えば「盤中」）、増分プッシュ時に受信した0がビジネスの値なのか、未設定のデフォルト値なのかをクライアント側で判断することができません。しかし、列挙型を1から開始して定義すれば、0を有意義でないデフォルト値や「未知」の状態として保持できるため、問題は容易に解決されます。&lt;/p&gt;
&lt;p&gt;推奨される実践：&lt;/p&gt;
&lt;p&gt;プロトバッファの列挙型を設計する際には、常に 0 を無意味なデフォルト値として定義してください（例：&lt;code&gt;UNKNOWN&lt;/code&gt; または &lt;code&gt;RESERVED&lt;/code&gt;）。
実際のビジネス値を1から割り当て、デフォルト値の0と区別するようにしてください。&lt;/p&gt;
&lt;p&gt;この小さな調整により、取引セッションの識別問題を解決するだけでなく、将来のプロトコル設計のための貴重な経験となりました。&lt;/p&gt;</description>
        </item>
        <item>
        <title>バックエンドサービスTCP通信異常調査</title>
        <link>https://ttf248.life/ja/p/backend-service-tcp-communication-troubleshooting/</link>
        <pubDate>Fri, 14 Feb 2025 22:54:13 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/backend-service-tcp-communication-troubleshooting/</guid>
        <description>&lt;p&gt;ビジネスモデル：バックエンドサービスはTCP経由でグループのマーケットデータゲートウェイと接続を確立します。各接続において、まず認証リクエストを送信し、その後、継続的にハートビートパケットを送信して接続状態を維持します。
しかし、ある日、サービス接続が切れているという警告メッセージを受け取りました。ログを詳細に調査した結果、バックグラウンドサービスは継続的にハートビートパケットを送信しているものの、相手からの応答はなく、それでも接続は切断されませんでした。&lt;/p&gt;
&lt;h2 id=&#34;現場概説&#34;&gt;現場概説
&lt;/h2&gt;&lt;p&gt;元々会社で残業してプロジェクトの進捗を詰めていたところ、仕事のグループチャットに突然警告メッセージが飛び込んできた。最初はよくあるトラブルかと思ったが、ネットワークのタイムアウトで心跳送信が失敗し、結果としてサービス接続が切れたのだろうと推測した。しかし、ログを詳しく調査したところ、実際はそうではなかった。バックエンドから認証ログインメッセージは送信されているものの、応答がないままで、その間も心跳パケットは途絶えず送られ続けている。ログの深掘り分析の結果、以下のいくつかの重要な問題点が明らかになった：&lt;/p&gt;
&lt;p&gt;認証メッセージに応答がない場合、相手のシステムが再起動中の可能性が非常に高く、その結果、認証メッセージがタイムリーに処理されなかったと考えられます。
未認証のままハートビートデータが送信される問題について調査した結果、プログラムのロジックに欠陥があることが判明しました。ハートビート送信関数の判定ロジックには問題があり、接続状態のみを検証しているものの、認証状態の検証は考慮されていませんでした。
サービスが接続を解除できれば、再接続メカニズムがトリガーされ、承認メッセージが再送信されます。&lt;/p&gt;
&lt;p&gt;現在、まだ最後の解決すべき問題が残っています—それはなぜサービスが接続を切断していないのかです。この問題を解決するには、より深く詳細な調査が必要です。&lt;/p&gt;
&lt;h2 id=&#34;ネットワークデータパケットを解析する&#34;&gt;ネットワークデータパケットを解析する
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;tcpdump&lt;/code&gt;は非常に強力なネットワークパケットキャプチャツールであり、ネットワークデータパケットをキャプチャするために使用できます。ネットワークパケットを分析することで、ネットワーク通信の詳細をより直感的に理解できます。ここでは、&lt;code&gt;tcpdump&lt;/code&gt;を使用してネットワークデータパケットをキャプチャし、さらに分析することができます。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/backend-service-tcp-communication-troubleshooting/20250220151952.png&#34;
	width=&#34;1126&#34;
	height=&#34;202&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;tcpdump&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;557&#34;
		data-flex-basis=&#34;1337px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;グラフ中のデータから、心拍が常に正常に送信されていることがわかりますが、相手側のサーバーからはデータが一切返信されておらず、ただ &lt;code&gt;ACK&lt;/code&gt; だけが送られてきました。これにより、接続は自動的に切断されません。&lt;/p&gt;
&lt;h2 id=&#34;一般的なフラグの説明&#34;&gt;一般的なフラグの説明
&lt;/h2&gt;&lt;p&gt;TCPプロトコルにおいて、&lt;code&gt;PSH&lt;/code&gt;(Push)と&lt;code&gt;ACK&lt;/code&gt;(Acknowledgment)は、データ転送とフロー制御の確認にそれぞれ使用される重要なフラグです。それらの役割は以下の通りです。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;1-pshpush-flag&#34;&gt;&lt;strong&gt;1. PSH（Push Flag）&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;機能：
PSH フラグの役割は、**受信側がバッファ内のデータを上層アプリケーションに直ちにプッシュする（バッファがいっぱいになるまで待つのではなく）**ことです。つまり、PSHフラグが付いたデータセグメントを受信すると、受信側は可能な限り速やかに処理してアプリケーションに渡すため、オペレーティングシステムのバッファに一時的に保存することはありません。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;典型的な状況：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HTTP/HTTPSリクエスト：クライアントがリクエストを送信する際（例：&lt;code&gt;GET /index.html&lt;/code&gt;）には、&lt;code&gt;PSH&lt;/code&gt;を設定し、サーバーに直ちにレスポンスすることを期待します。&lt;/li&gt;
&lt;li&gt;SSHプロトコル：キーボード入力ごとに&lt;code&gt;PSH&lt;/code&gt;がトリガーされ、入力文字のリアルタイム転送を保証します。&lt;/li&gt;
&lt;li&gt;リアルタイム通信：ビデオストリーミングやオンラインゲームなどの低遅延シナリオでは、&lt;code&gt;PSH&lt;/code&gt;を使用して遅延を削減することがあります。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PSHは必須ではなく、受信側はこのフラグを無視しても構いません（ただし、データは通常通り処理する必要があります）。&lt;/li&gt;
&lt;li&gt;送信元が&lt;code&gt;PSH&lt;/code&gt;を設定しない場合、受信側は自身のバッファポリシーに基づいてデータをいつプッシュするかを決定します。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;2-ackacknowledgment-flag&#34;&gt;&lt;strong&gt;2. ACK（Acknowledgment Flag）&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;機能：
ACK フラグは、&lt;strong&gt;先行するデータセグメントが正しく受信されたことを示す&lt;/strong&gt;ものです。各 ACK には、期待される次のバイトのシーケンス番号を含む確認番号（Acknowledgment Number）が含まれており、これは TCP の信頼性のある転送の中核となるメカニズムです。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;動作原理：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;送信元がデータセグメントを送信する際、受信者が期待する &lt;code&gt;ACK&lt;/code&gt; 値（例えば &lt;code&gt;ACK = シーケンス番号 + データ長&lt;/code&gt;）を一緒に持ちます。&lt;/li&gt;
&lt;li&gt;受信側はデータを受信後、&lt;code&gt;ACK&lt;/code&gt;セグメントを生成し、受信確認済みのデータシーケンス番号を示すものとする。&lt;/li&gt;
&lt;li&gt;送信者は、対応する&lt;code&gt;ACK&lt;/code&gt;を受け取るまで、未確認のデータを再送しません。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;例&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;送信元がシーケンス番号&lt;code&gt;100～199&lt;/code&gt;のデータセグメントを送信した場合、受信側の&lt;code&gt;ACK&lt;/code&gt;は&lt;code&gt;200&lt;/code&gt;であるべきです。&lt;/li&gt;
&lt;li&gt;受信側が&lt;code&gt;100～199&lt;/code&gt;のデータの一部を受信していない場合、&lt;code&gt;ACK=150&lt;/code&gt;を送信側に送信して再送を要求します。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;pshとackの組み合わせ&#34;&gt;PSHとACKの組み合わせ
&lt;/h3&gt;&lt;p&gt;TCP パケットにおいて、&lt;code&gt;PSH&lt;/code&gt; と &lt;code&gt;ACK&lt;/code&gt; が同時に出現することは、以下の状況でよく見られます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;HTTPリクエスト応答
クライアントが &lt;code&gt;POST&lt;/code&gt; リクエストを送信する際（データを含む場合）、&lt;code&gt;PSH&lt;/code&gt; と &lt;code&gt;ACK&lt;/code&gt;（以前の応答に対する確認）が設定されます。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-plaintext&#34;&gt;Client → Server: SYN, ACK=1 → 建立连接
Client → Server: PSH, ACK=1, 数据 → 发送请求数据
Server → Client: PSH, ACK=数据长度+1 → 返回响应
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SSHハンドシェイク後のコマンド送信
クライアントがコマンドを入力すると、&lt;code&gt;PSH&lt;/code&gt;と&lt;code&gt;ACK&lt;/code&gt;を含むデータセグメントを送信し、コマンドが直ちに転送され、サーバーによって処理されることを保証します。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;他のフラグとの関連&#34;&gt;他のフラグとの関連
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;フラグ&lt;/th&gt;
&lt;th&gt;名前&lt;/th&gt;
&lt;th&gt;簡単な説明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;SYN&lt;/td&gt;
&lt;td&gt;同期&lt;/td&gt;
&lt;td&gt;初期化接続（三次握手）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;FIN&lt;/td&gt;
&lt;td&gt;終了&lt;/td&gt;
&lt;td&gt;エレガントな接続のクローズ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;リセット&lt;/td&gt;
&lt;td&gt;強制終了 (異常時)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;URG&lt;/td&gt;
&lt;td&gt;緊急&lt;/td&gt;
&lt;td&gt;緊急ポインタをマークする（ほとんど使用しない）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id=&#34;まとめ&#34;&gt;まとめ
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;データがアプリケーション層にできるだけ早く到達することに注力し、遅延を低減することです。&lt;/li&gt;
&lt;li&gt;ACKは、&lt;strong&gt;データの信頼性のある転送&lt;/strong&gt;に焦点を当てており、パケットの消失や順不同を避けることを目的としています。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;両者は協調して働き、TCPプロトコルの効率と信頼性のバランスを取った。&lt;/p&gt;</description>
        </item>
        <item>
        <title>ローカルにdeepseek-R1をデプロイ</title>
        <link>https://ttf248.life/ja/p/ollama-local-deployment-deepseek-r1/</link>
        <pubDate>Fri, 07 Feb 2025 22:41:02 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ollama-local-deployment-deepseek-r1/</guid>
        <description>&lt;p&gt;Ollamaは、ユーザーがローカルで大規模言語モデル（LLM）を実行およびデプロイできるようにすることを目的としたオープンソースのAIツールです。開発者がクラウドサービスに依存することなく、GPTのようなモデルをローカルマシン上で利用できる、便利で効率的な方法を提供することを目指しています。Ollamaは複数のモデルをサポートしており、パフォーマンスの最適化に重点を置いており、リソースが限られたデバイスでもこれらのモデルをスムーズに実行できるようにします。&lt;/p&gt;
&lt;p&gt;Ollama を使用すれば、ユーザーはテキストベースの AI アプリケーションを利用でき、データプライバシーを気にすることなく、また高額な API 利用料金を心配することなく、ローカルにデプロイされたモデルと対話することができます。コマンドラインインターフェース（CLI）を通じて様々なモデルを呼び出し、自然言語処理や質問応答などのタスクを実行できます。&lt;/p&gt;
&lt;p&gt;Ollamaは様々なモデルを試すのに適していますが、Windows版をテストしたところ、ハードウェアの性能を十分に発揮できないようです。原因はWindows版にあるのかもしれません。Linux版の方が良いかもしれません。32bパラメータのモデルをデプロイした場合、メモリやGPUの負荷が低いにも関わらず、応答速度が非常に遅いです。&lt;/p&gt;
&lt;h2 id=&#34;ハードウェア概要&#34;&gt;ハードウェア概要
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;オペレーティングシステム：win11&lt;/li&gt;
&lt;li&gt;CPU：i7-10700K&lt;/li&gt;
&lt;li&gt;メモリ：40GB&lt;/li&gt;
&lt;li&gt;グラフィックボード：RTX 3060 12GB&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;環境準備&#34;&gt;環境準備
&lt;/h2&gt;&lt;p&gt;新たにシステム環境変数を追加し、今後の利用を容易にします。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_MODELS=E:\ollama&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
この変数は、Ollamaモデルの保存パスを指定します。&lt;code&gt;E:\ollama&lt;/code&gt; はフォルダパスで、すべてのローカルモデルファイルがそのディレクトリに格納されていることを示しています。Ollamaは、このパスに基づいてダウンロードまたはデプロイした言語モデルをロードして使用します。モデルファイルを別の場所に保存したい場合は、このパスを変更するだけです。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_HOST=127.0.0.1:8000&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
この環境変数は、Ollama サービスのホストとポートを設定します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;127.0.0.1&lt;/code&gt; はローカルアドレス（localhost）であり、Ollama サービスはローカルからのリクエストのみをリッスンします。&lt;/li&gt;
&lt;li&gt;8000は指定されたポート番号で、Ollamaサービスが8000ポートでリクエストを待機し処理することを示します。必要に応じてポート番号を変更できますが、そのポートが他のアプリケーションによって使用されていないことを確認してください。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_ORIGINS=*&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
この環境変数は、Ollama サービスにアクセスできるリクエストのソースを制御します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;*&lt;/code&gt; は、Ollama サービスへのアクセスを任意のソース（すべてのドメインと IP アドレス）から許可することを意味します。これは通常、開発およびデバッグ環境で使用されます。本番環境では、セキュリティを高めるために、特定のドメインまたは IP からのみアクセスできるように、より厳格なソースの制御を指定することが一般的です。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;deepseek-r1モデルのデプロイ&#34;&gt;DeepSeek-R1モデルのデプロイ
&lt;/h2&gt;&lt;p&gt;Ollamaのインストールは簡単で、ここでは詳細を説明しません。&lt;/p&gt;
&lt;p&gt;インストール後の検証：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core&amp;gt;ollama -v
ollama version is 0.5.11
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;モデルのデプロイについては、公式ウェブサイトのモデルページを参照し、対応するパラメータを持つモデルを選択してください。例：&lt;code&gt;ollama run deepseek-r1:14b&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;14bパラメータは会話のコンテキストを効果的に記憶できますが、より小さいパラメータバージョンではそれができません。32bパラメータバージョンについては、ローカルでのデプロイが非常に遅く、さらなるテストは行っていません。&lt;/p&gt;
&lt;h2 id=&#34;参照資料&#34;&gt;参照資料
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ollama.com/library/deepseek-r1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.ollama.com/library/deepseek-r1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/x18990027/article/details/145368094&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/x18990027/article/details/145368094&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>PowerShell 7 と永続化設定コマンドライン予測ビュー</title>
        <link>https://ttf248.life/ja/p/powershell-7-persisting-settings-command-line-prediction-view/</link>
        <pubDate>Fri, 07 Feb 2025 22:19:12 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/powershell-7-persisting-settings-command-line-prediction-view/</guid>
        <description>&lt;p&gt;Linuxのzshに慣れていて、先日ブログを書こうとしたときに、PowerShell 7も永続的な設定でコマンドライン予測ビューをサポートしていることに気づいたので、試してみたところ、なかなか便利だった。&lt;/p&gt;
&lt;p&gt;どういう操作をしたのかもわからないけど、この機能がオンになってしまったみたいだ。とにかく、そうなってしまった。&lt;/p&gt;
&lt;p&gt;現代の多様なオペレーティングシステム環境において、システム管理者や開発者は、プラットフォームを越えて効率的かつ強力なツールを探し求めています。それは、システム管理および自動化タスクのニーズを満たすためです。PowerShell 7はまさにそのような注目を集めているツールであり、強力なスクリプト作成機能を提供するだけでなく、Windows、Linux、macOSなどのオペレーティングシステムを跨いで実行され、ユーザーに前例のない利便性をもたらします。&lt;/p&gt;
&lt;h2 id=&#34;powershell-7クロスプラットフォームの強力なツール&#34;&gt;PowerShell 7：クロスプラットフォームの強力なツール
&lt;/h2&gt;&lt;h3 id=&#34;クロスプラットフォーム機能&#34;&gt;クロスプラットフォーム機能
&lt;/h3&gt;&lt;p&gt;PowerShell 7は、プラットフォームの制約を取り払い、Windowsシステムでのエンタープライズサーバー管理、Linux環境でのシステム運用、macOS上での日常的な開発タスクなど、あらゆる場所で統一されたPowerShell 7ツールを使用できます。これにより、作業効率が大幅に向上し、プラットフォームの違いによる学習コストや操作の複雑さが軽減されます。&lt;/p&gt;
&lt;h3 id=&#34;強力な機能&#34;&gt;強力な機能
&lt;/h3&gt;&lt;p&gt;強力なスクリプト作成機能を備えており、オブジェクト指向プログラミング、関数、モジュールなどの高度なプログラミング機能に対応しています。PowerShell 7を通じて、ユーザーはファイルシステムを簡単に操作し、ファイルの作成、削除、コピー、移動などの操作を実行できます。レジストリにアクセスして変更することで、システムの構成を深く調整することも可能です。プロセスやサービスを管理し、システム動作状態の有効な監視と制御を実現します。さらに、PowerShell 7は、Active Directoryでのユーザーおよび権限管理、Azureクラウドプラットフォーム上でのリソース割り当ておよび管理など、さまざまなWindowsおよび非Windowsテクノロジーとの連携が可能です。&lt;/p&gt;
&lt;h3 id=&#34;オープンソースエコシステム&#34;&gt;オープンソースエコシステム
&lt;/h3&gt;&lt;p&gt;PowerShell 7はオープンソースであり、この特徴により世界中の開発者や愛好家が積極的にその開発と改善に参加できます。多数のオープンソースモジュールやツールが次々と登場し、PowerShell 7 の機能と応用範囲を広げています。ユーザーは自分のニーズに合わせて、オープンソースコミュニティで適切なモジュールを見つけたり、自分のコードを寄稿してコミュニティ全体の発展に貢献したりすることができます。&lt;/p&gt;
&lt;h3 id=&#34;互換性と安定性&#34;&gt;互換性と安定性
&lt;/h3&gt;&lt;p&gt;PowerShell 7は、古いバージョンのPowerShellとの互換性を維持しながら、多くの新機能と改善を導入しています。これらの改善はパフォーマンスの向上だけでなく、安定性も強化し、ユーザーがさまざまなタスクをよりスムーズに完了できるようにするとともに、ソフトウェアの不具合による作業の中断を減らします。&lt;/p&gt;
&lt;h2 id=&#34;コマンドライン予測ビューを開く&#34;&gt;コマンドライン予測ビューを開く
&lt;/h2&gt;&lt;p&gt;PowerShell 7の多くの便利な機能の中でも、&lt;code&gt;Set-PSReadLineOption -PredictionViewStyle ListView&lt;/code&gt;コマンドは、ユーザーのコマンドライン入力体験を向上させる実用的なツールです。&lt;/p&gt;
&lt;p&gt;コマンドの実行を有効にしない状態でもオートコンプリート機能は利用できますが、それは行内の補完に限られます。有効にすると予測表示がされ、考えられるすべての補完候補をリスト形式で表示します。ユーザーは上下キーを使って必要な候補を選択できるため、コマンド入力の正確性と効率が向上します。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/powershell-7-persisting-settings-command-line-prediction-view/20250207222546.png&#34;
	width=&#34;814&#34;
	height=&#34;205&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;powershell7&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;397&#34;
		data-flex-basis=&#34;952px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;コマンドを永続的に有効にする方法&#34;&gt;コマンドを永続的に有効にする方法
&lt;/h2&gt;&lt;p&gt;PowerShellを起動するたびに&lt;code&gt;Set-PSReadLineOption -PredictionViewStyle ListView&lt;/code&gt;コマンドが有効になるようにするには、このコマンドをPowerShellのプロファイルに追加できます。PowerShellのプロファイルは特別なスクリプトで、PowerShellの起動時に自動的に実行されます。&lt;/p&gt;
&lt;h3 id=&#34;設定構成ファイルパス&#34;&gt;設定構成ファイルパス
&lt;/h3&gt;&lt;p&gt;PowerShellでは、&lt;code&gt;$PROFILE&lt;/code&gt;変数を使って設定ファイルのパスを確認できます。そのパスにファイルが存在しない場合は、ユーザーが手動で作成できます。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;echo $PROFILE
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;設定ファイルを開く&#34;&gt;設定ファイルを開く
&lt;/h3&gt;&lt;p&gt;強力なメモ帳++や軽量のVisual Studio Codeなどのテキストエディタを使用し、&lt;code&gt;$PROFILE&lt;/code&gt;変数から取得される構成ファイルパスに対応するファイルを開きます。&lt;/p&gt;
&lt;h3 id=&#34;追加命令&#34;&gt;追加命令
&lt;/h3&gt;&lt;p&gt;開いている設定ファイルに、&lt;code&gt;Set-PSReadLineOption -PredictionViewStyle ListView&lt;/code&gt; コマンドを追加してください。コマンドの記述ミスがないように注意し、設定ファイルが実行時に正しく有効になるようにしてください。&lt;/p&gt;
&lt;h3 id=&#34;設定ファイルを保存する&#34;&gt;設定ファイルを保存する
&lt;/h3&gt;&lt;p&gt;コマンドが完了したら、設定ファイルを保存し、テキストエディタを閉じます。これで、設定ファイルには、PowerShellの起動時に実行したいコマンドがすべて含まれています。&lt;/p&gt;
&lt;h3 id=&#34;検証設定&#34;&gt;検証設定
&lt;/h3&gt;&lt;p&gt;現在のPowerShellウィンドウを閉じ、PowerShellを再起動します。新しく起動したPowerShellでコマンドを入力する際、コマンドライン入力予測ビューのスタイルがリスト表示になっているはずです。これは、設定が正常に適用されたことを示しています。&lt;/p&gt;
&lt;p&gt;上記の手順を通して、私たちは PowerShell 7 の強力な機能と特徴を深く理解するだけでなく、コマンドライン入力による予測ビューのスタイル設定を通じて操作体験を向上させる方法を習得し、これらの設定を持続的に有効にする方法も学びました。これらの知識が、PowerShell 7 を使用する際に、よりスムーズに、そして効率的に様々なシステム管理および自動化タスクを実行できるようになることを願っています。&lt;/p&gt;
&lt;h2 id=&#34;参照資料&#34;&gt;参照資料
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/PowerShell/PowerShell/releases&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/PowerShell/PowerShell/releases&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.v2ex.com/t/911909&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.v2ex.com/t/911909&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>atopツールによるLinuxシステム指標の監視：インストール、設定と使用完全ガイド</title>
        <link>https://ttf248.life/ja/p/using-atop-to-monitor-linux-system-metrics-installation-configuration-and-usage-guide/</link>
        <pubDate>Thu, 06 Feb 2025 22:48:55 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/using-atop-to-monitor-linux-system-metrics-installation-configuration-and-usage-guide/</guid>
        <description>&lt;p&gt;Linuxシステム運用において、システムリソースとプロセス状態をリアルタイムかつ包括的に監視することは非常に重要です。atopツールは強力な監視ツールとして、この目標を容易に達成するのに役立ちます。本稿では、Linuxインスタンスにおけるatop監視ツールのインストール、設定、使用方法について詳細に説明します。&lt;/p&gt;
&lt;h2 id=&#34;一atopツール紹介&#34;&gt;一、atopツール紹介
&lt;/h2&gt;&lt;p&gt;atopは、Linuxシステムのリソースとプロセスを監視するために特別に設計されたツールです。システムおよびプロセスの活動を記録し、すべてのプロセスの実行状況を報告します。このツールが収集するデータには、CPU、メモリ、ディスク、ネットワークなどのリソース使用状況やプロセス状態が含まれ、データをログファイル形式でディスクに保存することもできます。各プロセスについて、CPU使用率、メモリ増加量、ディスク使用率、優先度、ユーザー名、状態、および終了コードなど、重要な情報を取得できます。さらに、atopの設定ファイルを介して、ログ収集頻度、ログファイルの保存パス、およびローテーションポリシーなどのパラメータをカスタマイズできます。&lt;/p&gt;
&lt;h2 id=&#34;二atopツールのインストール&#34;&gt;二、atopツールのインストール
&lt;/h2&gt;&lt;p&gt;さまざまなLinuxディストリビューションでのatopのインストール方法は若干異なります。以下では、一般的なオペレーティングシステムを例としてご紹介します。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Alibaba Cloud Linux 3/2、CentOS 7/8、Fedora、Rocky Linux 9&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;実行インストールコマンド：&lt;code&gt;sudo yum install -y atop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;atopサービスを開始します：&lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ubuntu / Debian&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ソフトウェアリポジトリの更新：&lt;code&gt;sudo apt update&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;実行インストールコマンド：&lt;code&gt;sudo apt install -y atop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;atopサービスを開始します：&lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;CentOS Stream 9&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ダウンロードしてインストール：&lt;code&gt;sudo wget https://www.atoptool.nl/download/atop-2.11.0-1.el9.x86_64.rpm &amp;amp;&amp;amp; sudo rpm -i atop-2.11.0-1.el9.x86_64.rpm&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;atopサービスを開始します：&lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;openSUSE&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;実行インストールコマンド：&lt;code&gt;sudo zypper install -y atop atop-daemon&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;atopサービスを開始します：&lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;上記に挙げられているオペレーティングシステムに、ご利用のディストリビューションが含まれていない場合は、atop公式サイトでインストール情報を入手してください。&lt;/p&gt;
&lt;h2 id=&#34;三監視期間とログ保持期間の設定&#34;&gt;三、監視期間とログ保持期間の設定
&lt;/h2&gt;&lt;p&gt;設定ファイルの位置: Alibaba Cloud Linux 3/2、CentOS 7/8およびFedoraシステムでは、atopの設定ファイルは&lt;code&gt;/etc/sysconfig/atop&lt;/code&gt;です。Ubuntu、DebianおよびopenSUSEシステムでは、設定ファイルは&lt;code&gt;/etc/default/atop&lt;/code&gt;です。
デフォルト設定パラメータ説明
- ログオプションは、ログファイル記録のオプションを制御するために使用され、デフォルトでは空です。
- ログ間隔：監視周期、デフォルト600秒。過去のログをトレースして問題解決する場合は、実際のニーズに合わせてこの頻度を調整することをお勧めします。
- ログ保持期間、デフォルトは28日。
- ログファイルが保存されるパスです。デフォルトは &lt;code&gt;/var/log/atop&lt;/code&gt; です。
設定手順
- コマンドを実行して設定ファイルを開きます。
- Alibaba Cloud Linux 3/2、CentOS 7/8、Fedoraシステムでは：&lt;code&gt;sudo vim /etc/sysconfig/atop&lt;/code&gt;
- Ubuntu、Debian、openSUSE、CentOS Stream 9、Rocky Linux 9システムにおいて：&lt;code&gt;sudo vim /etc/default/atop&lt;/code&gt;
- &lt;code&gt;i&lt;/code&gt;キーで編集モードに入り、必要に応じて設定パラメータを調整します。例えば、監視サイクルを30秒に修正し、ログ保持期間を7日に設定し、ログパスはデフォルトのままにします。
- &lt;code&gt;Esc&lt;/code&gt;キーを押し、&lt;code&gt;:wq&lt;/code&gt;と入力して、保存して編集を終了します。
- atopサービスの再起動により設定が有効になります：&lt;code&gt;sudo systemctl restart atop&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;LOGOPTS=&amp;quot;&amp;quot;
LOGINTERVAL=30
LOGGENERATIONS=7
LOGPATH=/var/log/atop 
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;四atopツールを使用する&#34;&gt;四、atopツールを使用する
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;よく使用されるコマンドの紹介:&lt;/strong&gt; インタラクティブなコマンドモードでは、以下のよく使用されるコマンドがあります。
- デフォルトの統合出力ビューに戻ります。
- プロセスの一覧の完全なコマンドラインを表示します。
- プロセスごとのメモリ使用率で降順にフィルタリングします。
- プロセスごとのディスク使用率で降順にフィルタリングします。
- プロセス資源の総合利用率に基づいて降順にフィルタリングする。
- プロセスネットワークの使用率で降順にフィルタリングする。
- 次の監視収集ポイントに移動します。
- 前の監視データ収集ポイントへ移動します。
- b：指定日時、形式は&lt;code&gt;YYYYMMDDhhmm&lt;/code&gt;です。&lt;/p&gt;
&lt;p&gt;リソース監視フィールドの説明
- ATOP：ホスト名、情報サンプリングの日付と時刻。
- プロセス全体の実行状況、カーネルモードとユーザーモードの実行時間、プロセスの総数、およびさまざまな状態のプロセス数を含む。
- CPU：CPU全体の利用状況を示し、各フィールドの数値の合計は&lt;code&gt;N*100%&lt;/code&gt;(NはCPUコア数)として表示されます。カーネルモード、ユーザーモード、割り込み、アイドル、ディスクI/O待ちなどの時間割合が含まれます。
- &lt;strong&gt;CPL&lt;/strong&gt;：CPU負荷状況。過去1分間、5分間、15分間の実行キュー内の平均プロセス数、コンテキストスイッチ回数、割り込み発生回数など。
- MEM：メモリ使用状況。物理メモリの総量、空きメモリ、ページキャッシュメモリ、ファイルキャッシュメモリ、カーネル占有メモリなどを含む。
- &lt;strong&gt;SWP&lt;/strong&gt;：スワップスペースの使用状況を示し、スワップ領域の合計サイズと利用可能なスワップスペースのサイズを含みます。
- ページング状況、例えばスワップインおよびスワップアウトされたメモリページの数。
- ディスク使用状況：各ディスクデバイスに対応する行で、デバイス識別子、ビジー状態時間比率、読み書きリクエスト数を示します。
- ネットワーク状況を表示し、転送層のTCPとUDP、IP層、および各アクティブポートの受信・送信パケットサイズを示します。&lt;/p&gt;
&lt;p&gt;リアルタイムシステム指標を確認する
- 5秒ごとにシステム指標を確認する：&lt;code&gt;atop 5&lt;/code&gt;
- 現在の時刻のあと5分間（合計30回、10秒間隔で）のシステム指標を確認します：&lt;code&gt;atop -M 10 30&lt;/code&gt;
- 現在時刻のあと10分間（10回、60秒間隔で）のシステム指標を確認し、結果をファイルに書き込む：&lt;code&gt;atop -M 60 10 &amp;gt; /log/atop.mem&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;atop起動後、収集記録はデフォルトで &lt;code&gt;/var/log/atop&lt;/code&gt; ディレクトリに保存されます。確認する際は、指定した日付のログファイルが存在することを確認してください。存在しない場合はエラーになります。
- 当日の履歴指標ログを確認する：&lt;code&gt;atop -r&lt;/code&gt;
- 昨日履歴指標ログを見る：&lt;code&gt;atop -r y&lt;/code&gt;
- 指定日の履歴指標ログを確認します。例えば、2024年11月06日：&lt;code&gt;atop -r 20241106&lt;/code&gt;
- 指定された日付から指定時間からの過去の指標ログを表示します。例えば、2024年11月06日14:00以降の場合：&lt;code&gt;atop -r 20241106 -b 14:00&lt;/code&gt;
- 指定された日付の特定の期間における履歴指標ログを確認します。例えば、2024年11月5日00時04分から00時08分：&lt;code&gt;atop -r 20241105 -b 00:04 -e 00:08&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;システムアクティビティレポートの確認
- 現在のシステムにおけるCPU使用率レポートを1分間（12回、5秒間隔）で確認します: &lt;code&gt;atopsar -c 5 12&lt;/code&gt;
- 当日指定時間帯のメモリ指標レポートを確認します。例：18:00～18:01 &lt;code&gt;atopsar -m -b 18:00 -e 18:01&lt;/code&gt;
- 指定日付内の指定時間範囲のメモリ指標レポートを確認します。例えば、2024年11月5日18:00から18:01まで：&lt;code&gt;atopsar -m -r 20241105 -b 18:00 -e 18:01&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;その他操作&#34;&gt;その他操作
&lt;/h2&gt;&lt;p&gt;天级别ログローテーションポリシーを設定します。毎日atop指標ログファイルを生成したい場合は、以下の手順を実行してください。
- （オプションで）必要に応じて監視期間、ログ保持時間、およびログ保存パスを調整できます。
- コマンドを実行して、毎日のログローテーションに関連するサービスを起動し、起動時に自動開始するように設定します。&lt;code&gt;sudo systemctl enable --now atop atopacct atop-rotate.timer&lt;/code&gt;
- ビジネスがログ処理に複雑な要件を持つ場合、logrotateやカスタムスクリプトを組み合わせてログ管理を実現することもできます。&lt;/p&gt;
&lt;p&gt;オプションのnetatopカーネルモジュールをロードします。ネットワーク使用状況を監視する必要がある場合は、netatopモジュールをインストールできます（atopではデフォルトでインストールされていません）。例として、Alibaba Cloud Linux 3システムの場合：
- カーネル開発パッケージおよびコンパイルに必要なソフトウェア環境をインストールします。&lt;code&gt;sudo yum install -y kernel-devel dkms elfutils-libelf-devel&lt;/code&gt;
- 最新バージョンのnetatopソースコードを特定のディレクトリにダウンロードします。&lt;code&gt;cd /usr/src/ &amp;amp;&amp;amp; sudo wget https://www.atoptool.nl/download/netatop-3.2.2.tar.gz --no-check-certificate&lt;/code&gt;
- ソースコードを解凍し、ソースディレクトリへ移動します。&lt;code&gt;sudo tar -zxvf netatop-3.2.2.tar.gz &amp;amp;&amp;amp; cd netatop-3.2.2&lt;/code&gt;
- ソースコードからモジュールとデーモンを構築してインストールします。&lt;code&gt;sudo make &amp;amp;&amp;amp; sudo make install&lt;/code&gt;
- netatopサービスを開始します：&lt;code&gt;sudo systemctl start netatop&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;atopツールは機能が強力で使い勝手が良く、適切なインストール、設定、使用によって、Linuxシステムの動作状況をより深く理解し、潜在的な問題を早期に発見・解決することができます。この記事が皆様のLinuxシステム監視スキル向上に役立つことを願っています。&lt;/p&gt;
&lt;h2 id=&#34;六参照リンク&#34;&gt;六、参照リンク
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.atoptool.nl/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;atop公式サイト&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;atop監視ツールをインストール、設定し、使用する&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Visual Studio で「非対応」の PDB ファイルを読み込む</title>
        <link>https://ttf248.life/ja/p/visual-studio-loading-unmatched-pdb-files/</link>
        <pubDate>Thu, 23 Jan 2025 20:04:33 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/visual-studio-loading-unmatched-pdb-files/</guid>
        <description>&lt;p&gt;Windows 環境で Visual Studio でプログラムをデバッグする際、pdb ファイルと実行ファイルが一致しない場合、「シンボルファイルを読み込めません」というエラーが表示されます。プログラムのクラッシュが発生し、ダンプファイルが生成された場合でも、不一致の pdb ファイルであると、Visual Studio は正常にクラッシュ現場に入り込むことができません。&lt;/p&gt;
&lt;h2 id=&#34;pdbファイルとは何か&#34;&gt;pdbファイルとは何か
&lt;/h2&gt;&lt;p&gt;PDBファイルは、Microsoftが提供するデバッグ情報ファイルで、プログラムのデバッグに用いられます。PDBファイルには、プログラムのシンボルテーブル、ソースコードファイル名、行番号などの情報が含まれています。プログラムのコンパイル時に、PDBファイルを生成し、デバッグに利用できます。&lt;/p&gt;
&lt;h2 id=&#34;windbg-デバッグ&#34;&gt;WinDbg デバッグ
&lt;/h2&gt;&lt;p&gt;WinDbgは、Microsoftが提供するデバッグツールで、Windowsプログラムのデバッグに利用できます。WinDbgはミスマッチしたpdbファイルを読み込めますが、手動でのロードが必要です。&lt;code&gt;.reload /f /i&lt;/code&gt;コマンドを使用することで、ミスマッチしたpdbファイルを強制的にロードできます。&lt;/p&gt;
&lt;p&gt;しかし、WinDbg は Visual Studio ほど使いやすくないので、Visual Studio でもミスマッチの PDB ファイルをロードできるようにしたいと考えています。&lt;/p&gt;
&lt;h2 id=&#34;visual-studio-で互換性のない-pdb-ファイルを読み込む&#34;&gt;Visual Studio で互換性のない PDB ファイルを読み込む
&lt;/h2&gt;&lt;p&gt;ソースコードは通常、git で管理されているので、対応するバージョンのコードを見つけて再コンパイルし、対応する pdb ファイルを生成できます。なぜロードできないのでしょうか？主にメタデータが一致しません。&lt;/p&gt;
&lt;p&gt;小さなツールがあり、それを使うとメタデータを修正し、exeファイルの情報に基づいて新しいpdbファイルを生成して、Visual Studioがロードできるようにする。&lt;/p&gt;
&lt;p&gt;chkmatch ダウンロード先：&lt;a class=&#34;link&#34; href=&#34;https://www.debuginfo.com/tools/chkmatch.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.debuginfo.com/tools/chkmatch.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;サイトキャッシュアドレス：&lt;a class=&#34;link&#34; href=&#34;chkmatch.zip&#34; &gt;chkmatch.zip&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;ChkMatch utility can be used to check whether an executable and debug information file match. It can also be used to enforce matching between an executable and debug information file, if they are compatible.

For more information about debug information matching and related issues, see this article.

Supported debug information formats: DBG, PDB 2.0, PDB 7.0.

chkmatch [-c ExeFile DebugInfoFile ] |
         [-m ExeFile DebugInfoFile]
-c
Check matching between the executable and the debug information file.
-m
Make the executable and the debug information file match.
ExeFile
The name of the executable file.
DebugInfoFile
The name of the debug information file.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;chkmatchを使用する&#34;&gt;chkmatchを使用する
&lt;/h2&gt;&lt;p&gt;まずチェック処理を実行し、不一致の原因を分析後、署名が一致しない旨を表示します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\tianlong.xiang\Downloads\chkmatch&amp;gt;ChkMatch.exe -c &amp;quot;D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe&amp;quot; E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb
ChkMatch - version 1.0
Copyright (C) 2004 Oleg Starodumov
http://www.debuginfo.com/


Executable: D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe
Debug info file: E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb

Executable:
TimeDateStamp: c26d9be3
Debug info: 2 ( CodeView )
TimeStamp: f86b0a4f  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 122  RVA: 001cdc44  FileOffset: 001cbe44
CodeView format: RSDS
Signature: {428c9b95-39a3-4a8d-a8e5-7be453684757}  Age: 1
PdbFile: D:\stock_UAT\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\obj\Release\YinTrade.Main.pdb
Debug info: 16 ( Unknown )
TimeStamp: 00000000  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 0  RVA: 00000000  FileOffset: 00000000

Debug information file:
Format: PDB 7.00
Signature: {06fae08e-c0a2-4f3d-9c7c-dfc684445dd1}  Age: 1

Result: Unmatched (reason: Signature mismatch)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;そして、pdbファイルとexeファイルが一致するように修正処理を実行します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\tianlong.xiang\Downloads\chkmatch&amp;gt;ChkMatch.exe -m &amp;quot;D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe&amp;quot; E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb
ChkMatch - version 1.0
Copyright (C) 2004 Oleg Starodumov
http://www.debuginfo.com/


Executable: D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe
Debug info file: E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb

Executable:
TimeDateStamp: c26d9be3
Debug info: 2 ( CodeView )
TimeStamp: f86b0a4f  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 122  RVA: 001cdc44  FileOffset: 001cbe44
CodeView format: RSDS
Signature: {428c9b95-39a3-4a8d-a8e5-7be453684757}  Age: 1
PdbFile: D:\stock_UAT\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\obj\Release\YinTrade.Main.pdb
Debug info: 16 ( Unknown )
TimeStamp: 00000000  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 0  RVA: 00000000  FileOffset: 00000000

Debug information file:
Format: PDB 7.00
Signature: {06fae08e-c0a2-4f3d-9c7c-dfc684445dd1}  Age: 1

Writing to the debug information file...
Result: Success.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;参照資料&#34;&gt;参照資料
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://stackoverflow.com/questions/38147487/forcing-to-load-unmatched-symbols-in-visual-studio-2015-debugger&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;forcing-to-load-unmatched-symbols-in-visual-studio-2015-debugger&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>カーサーAI プログラミングIDE 体験</title>
        <link>https://ttf248.life/ja/p/cursor-ai-programming-ide-trial/</link>
        <pubDate>Thu, 23 Jan 2025 19:30:13 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/cursor-ai-programming-ide-trial/</guid>
        <description>&lt;p&gt;気がつけばまた一年が過ぎた。仕事における最大の変化は、やはりAIの関与が顕著に高まっていることだ。これまで、開発言語間の切り替えには、開発者が様々な言語の異なるAPIインターフェースを理解する必要があったが、今ではこれらの基礎コードもAIによって生成できるようになった。これは開発者にとって大きな福音と言えるだろう。&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;23年頃に簡単な入門紹介を2つほどやったことがあったのに、気がつけばもう25年も経っている。どう言えばいいのか分からないが、目に見えるような進歩は感じられない。自分の認知を確立し、タスクを合理的に分割できるようになる必要がある。もちろん、最も重要なのはAI生成コードにバグがないかどうかを見抜くことだ。&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;Github copilot
&lt;/h2&gt;&lt;p&gt;いつになったか覚えていないが、資料を見たところシンガポールにサーバーが設置され、国内で利用できるようになったらしい。これにより、もう長期間VPNを使わなくてもよくなった。もちろん、ログイン時にはまだVPNが必要だが、ログインが終われば閉じるだけで良い。&lt;/p&gt;
&lt;p&gt;普段使いとしては、やはり Github Copilot の方が多いです。このプラグインは、VS Code や Visual Studio で直接使えるので、2つのソフトウェア間を切り替える必要がありません。ChatGPT と比較すると、Github Copilot はプロジェクトのサポートがより良く、インタラクションも友好的です。さらに、ローカルファイルの一部を選択して AI に「訓練」させることができ、その結果生成されるコードはあなたのプロジェクトに合致しやすくなります。&lt;/p&gt;
&lt;h2 id=&#34;cursor-ai&#34;&gt;Cursor AI
&lt;/h2&gt;&lt;p&gt;最近新しいAIプログラミングIDE、Cursor AIを見ました。このIDEはGithub Copilotをベースにしていますが、さらにスマートで、ファイルを作成してくれます。&lt;/p&gt;
&lt;p&gt;軽く使ってみましたが、なかなか良い感じです。ただ、既存プロジェクトの理解はまだ足りません。ローカルプロジェクトファイルが多い場合や、大規模なリファクタリングや最適化調整を行う場合は、やはり&lt;strong&gt;開発者がタスクを分割する必要&lt;/strong&gt;があります。&lt;/p&gt;
&lt;p&gt;curso のプロジェクトモードに切り替えて、次のような内容を入力してください：新しい個人履歴ウェブページの作成、複数の異なるスタイルへの切り替えをサポートし、データ表示のためにいくつかの個人情報を入力してください。&lt;/p&gt;
&lt;p&gt;何度か試行錯誤すると、次のようなウェブページを入手できます。もちろん、このウェブページはまだシンプルなものですが、初心者にとっては良いでしょう。&lt;/p&gt;
&lt;p&gt;現在登録ユーザーは、高機能APIを150回無料で試用できます。有料ユーザーは、高機能APIの利用が5000回に制限されます。&lt;/p&gt;
&lt;p&gt;履歴書&lt;/p&gt;</description>
        </item>
        <item>
        <title>C&#43;&#43; ビット演算の基礎：ビットごとの値の取得とフラグ設定</title>
        <link>https://ttf248.life/ja/p/cpp-bitwise-operations-basics-flags/</link>
        <pubDate>Fri, 17 Jan 2025 02:23:56 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/cpp-bitwise-operations-basics-flags/</guid>
        <description>&lt;p&gt;実際のC++開発において、ビット演算は一般的な技術であり、特にシステム状態、フラグ、または制御ビットを扱う際には、非常に効率的な解決策を提供します。本稿では、例を通して、ビット演算を使用して特定のフラグを取得および設定する方法について解説します。&lt;/p&gt;
&lt;h3 id=&#34;ビット演算の基本概念&#34;&gt;ビット演算の基本概念
&lt;/h3&gt;&lt;p&gt;コンピュータでは、データは2進数のビット（0と1）で格納されます。ビット演算とは、これらの2進数のビットに対して行う操作のことです。C++にはいくつかの一般的なビット演算子があります。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ビットごとの論理積(&amp;amp;)：あるビットが1であるかどうかを確認するために使用されます。&lt;/li&gt;
&lt;li&gt;ビットごとに、または（|）を使用します。あるビットを1に設定するために使用されます。&lt;/li&gt;
&lt;li&gt;ビットごとの排他的OR（^）：あるビットを反転するために使用されます。&lt;/li&gt;
&lt;li&gt;各ビットを反転する。&lt;/li&gt;
&lt;li&gt;左シフト（&amp;laquo;）：すべてのビットをいくつか左にずらす。&lt;/li&gt;
&lt;li&gt;右シフト（&amp;raquo;）：すべてのビットをいくつか右に移動します。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;この例では、&lt;code&gt;unsigned short&lt;/code&gt; 型の変数 &lt;code&gt;wInfo&lt;/code&gt; に対して一連のビット演算を行い、異なるフラグによって異なる状態を表します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;flowchart LR
    A[原始数值: 00010000] --&amp;gt; B[左移: 00010000 &amp;lt;&amp;lt; 1]
    B --&amp;gt; C[结果: 00100000]
    C --&amp;gt; D[右移: 00100000 &amp;gt;&amp;gt; 1]
    D --&amp;gt; E[结果: 00010000]

    subgraph 左移操作
        direction LR
        A --&amp;gt; B --&amp;gt; C
    end

    subgraph 右移操作
        direction LR
        C --&amp;gt; D --&amp;gt; E
    end
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;要求分析&#34;&gt;要求分析
&lt;/h3&gt;&lt;p&gt;題目の説明に基づき、異なる状態を表すために使用される16ビットのフラグがあります。これらの状態は、様々な二進数のビットによって示され、各二進数のビットは特定の意味に対応しています。例えば：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ビット０は失敗したか？&lt;/li&gt;
&lt;li&gt;ビット1は圧縮されていますか？&lt;/li&gt;
&lt;li&gt;bit2は増分されているか&lt;/li&gt;
&lt;li&gt;bit3に後続パッケージはありますか。&lt;/li&gt;
&lt;li&gt;通常リクエストまたはログアウト&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;位演算を使用する&#34;&gt;位演算を使用する
&lt;/h3&gt;&lt;p&gt;これらのフラグビットを設定および取得するには、ビット演算を使用します。具体的には：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ビットごとの値を取得する。&lt;/li&gt;
&lt;li&gt;ビット設定：あるビットを1に設定する。&lt;/li&gt;
&lt;li&gt;ビットクリア：あるビットを0に設定する。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;まず、これらのフラグを保持するために &lt;code&gt;unsigned short&lt;/code&gt; 型の変数 &lt;code&gt;wInfo&lt;/code&gt; を定義します。その後、ビット演算を使用して、対応するフラグを確認および設定します。&lt;/p&gt;
&lt;h3 id=&#34;cサンプルコード&#34;&gt;C++サンプルコード
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;bitset&amp;gt;

// 定义标志位常量
const unsigned short BIT_0_FAIL = 1 &amp;lt;&amp;lt; 0;    // bit0 是否失败
const unsigned short BIT_1_COMPRESSED = 1 &amp;lt;&amp;lt; 1; // bit1 是否压缩
const unsigned short BIT_2_INCREMENT = 1 &amp;lt;&amp;lt; 2;  // bit2 是否增量
const unsigned short BIT_3_HAS_MORE = 1 &amp;lt;&amp;lt; 3;   // bit3 是否有后续包
const unsigned short BIT_5_CANCEL = 1 &amp;lt;&amp;lt; 5;     // bit5 正常请求(0)或注销(1)

// 检查某一位是否为1
bool isBitSet(unsigned short wInfo, unsigned short bitMask) {
    return (wInfo &amp;amp; bitMask) != 0;
}

// 设置某一位为1
void setBit(unsigned short&amp;amp; wInfo, unsigned short bitMask) {
    wInfo |= bitMask;
}

// 清除某一位（设置为0）
void clearBit(unsigned short&amp;amp; wInfo, unsigned short bitMask) {
    wInfo &amp;amp;= ~bitMask;
}

int main() {
    // 假设wInfo的初始值为0
    unsigned short wInfo = 0;

    // 设置bit0（失败标志）
    setBit(wInfo, BIT_0_FAIL);
    
    // 设置bit1（压缩标志）
    setBit(wInfo, BIT_1_COMPRESSED);
    
    // 打印wInfo的二进制值
    std::cout &amp;lt;&amp;lt; &amp;quot;wInfo (in binary): &amp;quot; &amp;lt;&amp;lt; std::bitset&amp;lt;16&amp;gt;(wInfo) &amp;lt;&amp;lt; std::endl;

    // 检查各个标志位
    std::cout &amp;lt;&amp;lt; &amp;quot;bit0 (是否失败): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_0_FAIL) ? &amp;quot;是&amp;quot; : &amp;quot;否&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit1 (是否压缩): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_1_COMPRESSED) ? &amp;quot;是&amp;quot; : &amp;quot;否&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit2 (是否增量): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_2_INCREMENT) ? &amp;quot;是&amp;quot; : &amp;quot;否&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit3 (是否有后续包): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_3_HAS_MORE) ? &amp;quot;是&amp;quot; : &amp;quot;否&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit5 (是否注销): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_5_CANCEL) ? &amp;quot;是&amp;quot; : &amp;quot;否&amp;quot;) &amp;lt;&amp;lt; std::endl;

    // 清除bit1（压缩标志）
    clearBit(wInfo, BIT_1_COMPRESSED);
    
    // 打印更新后的wInfo
    std::cout &amp;lt;&amp;lt; &amp;quot;Updated wInfo (in binary): &amp;quot; &amp;lt;&amp;lt; std::bitset&amp;lt;16&amp;gt;(wInfo) &amp;lt;&amp;lt; std::endl;

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;コード実行、おすすめは旧友：&lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;wInfo (in binary): 0000000000000011
bit0 (是否失败): 是
bit1 (是否压缩): 是
bit2 (是否增量): 否
bit3 (是否有后续包): 否
bit5 (是否注销): 否
Updated wInfo (in binary): 0000000000000001
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;コードの説明&#34;&gt;コードの説明
&lt;/h3&gt;&lt;p&gt;フラグの定義：ビットシフト演算（&lt;code&gt;1 &amp;lt;&amp;lt; n&lt;/code&gt;）を使用して、各フラグを定義します。例えば、&lt;code&gt;1 &amp;lt;&amp;lt; 0&lt;/code&gt;は&lt;code&gt;bit0&lt;/code&gt;に対応し、&lt;code&gt;1 &amp;lt;&amp;lt; 1&lt;/code&gt;は&lt;code&gt;bit1&lt;/code&gt;に対応します。このように、各フラグに一意な二進数の位置を割り当てます。&lt;/p&gt;
&lt;p&gt;特定のビットを確認する：&lt;code&gt;isBitSet&lt;/code&gt;関数は、ビット演算&lt;code&gt;wInfo &amp;amp; bitMask&lt;/code&gt;によって特定のフラグが1であるかどうかを確認します。そのビットが1であれば、関数は&lt;code&gt;true&lt;/code&gt;を返し、そうでなければ&lt;code&gt;false&lt;/code&gt;を返します。&lt;/p&gt;
&lt;p&gt;設定ビット：&lt;code&gt;setBit&lt;/code&gt;関数は、ビット単位のOR演算&lt;code&gt;wInfo |= bitMask&lt;/code&gt;によって特定のフラグを1に設定します。&lt;/p&gt;
&lt;p&gt;特定のビットをクリアする：&lt;code&gt;clearBit&lt;/code&gt;関数は、ビットAND演算&lt;code&gt;wInfo &amp;amp;= ~bitMask&lt;/code&gt;によって特定フラグを0に設定します。&lt;/p&gt;
&lt;h3 id=&#34;まとめ&#34;&gt;まとめ
&lt;/h3&gt;&lt;p&gt;ビット演算を用いることで、複数の状態フラグを効率的に処理できます。特に開発現場では、この技術は非常に役立ちます。例えば、組み込み開発、ネットワークプロトコル、システムの状態管理など、多くの場面でビットフラグを用いて複数の二進数状態を表し、スペースの節約と効率向上を図ることがあります。&lt;/p&gt;
&lt;p&gt;このブログが、C++でビット演算を使用してビット単位での値の取得と設定をどのように行うかを理解するのに役立つことを願っています。これらのスキルを習得することは、効率的で保守しやすいコードを作成する上で非常に役立ちます！&lt;/p&gt;</description>
        </item>
        <item>
        <title>デスクトップを2.5Gネットワークカードにアップグレードし、ローカルエリアネットワークの接続を高速化</title>
        <link>https://ttf248.life/ja/p/desktop-upgrade-to-25g-network-card-accelerate-lan-interconnection/</link>
        <pubDate>Fri, 10 Jan 2025 00:37:52 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/desktop-upgrade-to-25g-network-card-accelerate-lan-interconnection/</guid>
        <description>&lt;p&gt;デスクトップPCのハードウェア関連製品が立て続けに登場、前回の記事ではPCIe変換アダプターについて触れましたが、古いSSDはどうなったのでしょうか？もちろん無駄にはしていません。故障もなく、一年前に購入した&lt;code&gt;メカニズムクリエイターMini-3765H&lt;/code&gt;（機械師）に取り付けました。&lt;/p&gt;
&lt;p&gt;新しい機械、ハードウェアのスペックはやはり素晴らしいです。2.5Gデュアルネットワークポート、PCIE4.0、Wi-Fi 6。&lt;/p&gt;
&lt;p&gt;最近引っ越したばかりで、部屋に個別のルーターがなかったので、機器はすべて無線ネットワークに接続していました。ASUSのマザーボード搭載のデスクトップPCの無線LANカードの性能が悪かったのかもしれませんし、ルーターの無線アクセスやローカルネットワーク間のアップロード速度が悪いことが原因で、PC間の通信速度が良くありませんでした。そこで新しい2.5GのNICを購入して、デスクトップPCに取り付けました。&lt;/p&gt;
&lt;p&gt;マザーボードの拡張スロットはこれですべて埋まりました：グラフィックカード、ワイヤレスLANカード、2.5Gネットワークカード、SSD用のPCIEアダプター。&lt;/p&gt;
&lt;h2 id=&#34;ネットワーク説明&#34;&gt;ネットワーク説明
&lt;/h2&gt;&lt;p&gt;２台の機器は引き続き元の無線LANカードでインターネットに接続していますが、両者は有線で直接接続され、両端とも2.5Gのネットワークカードです。有線を介して２台の機器を直接接続する方法については、ここでは詳しく説明しません。オンラインには多くのチュートリアルがありますので、参考にしてください。ファイアウォールも忘れずに開放し、どちらか１台をゲートウェイとして設定してください。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TD;
    A[机器1&amp;lt;br&amp;gt;IP: 192.168.4.1&amp;lt;br&amp;gt;子网掩码: 255.255.255.0&amp;lt;br&amp;gt;默认网关: - &amp;lt;br&amp;gt;自动获取DNS] --&amp;gt;|网线直连（2.5G）| B[机器2&amp;lt;br&amp;gt;IP: 192.168.4.2&amp;lt;br&amp;gt;子网掩码: 255.255.255.0&amp;lt;br&amp;gt;默认网关: 192.168.4.1&amp;lt;br&amp;gt;自动获取DNS];
    A --&amp;gt;|无线网卡| Internet;
    B --&amp;gt;|无线网卡| Internet;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;二つのネットワークセグメントの速度測定&#34;&gt;二つのネットワークセグメントの速度測定
&lt;/h2&gt;&lt;h3 id=&#34;ルーターローカルエリアネットワーク&#34;&gt;ルーター、ローカルエリアネットワーク
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core\Desktop\iperf-3.1.3-win32&amp;gt;iperf3.exe -c 192.168.3.237
Connecting to host 192.168.3.237, port 5201
[  4] local 192.168.3.122 port 1656 connected to 192.168.3.237 port 5201
[ ID] Interval           Transfer     Bandwidth
[  4]   0.00-1.00   sec  9.17 MBytes  76.7 Mbits/sec
[  4]   1.00-2.00   sec  9.91 MBytes  83.2 Mbits/sec
[  4]   2.00-3.00   sec  8.74 MBytes  73.3 Mbits/sec
[  4]   3.00-4.00   sec  10.2 MBytes  85.2 Mbits/sec
[  4]   4.00-5.00   sec  9.23 MBytes  77.1 Mbits/sec
[  4]   5.00-6.00   sec  8.80 MBytes  73.9 Mbits/sec
[  4]   6.00-7.01   sec  8.00 MBytes  66.8 Mbits/sec
[  4]   7.01-8.00   sec  7.69 MBytes  64.9 Mbits/sec
[  4]   8.00-9.01   sec  9.72 MBytes  81.1 Mbits/sec
[  4]   9.01-10.01  sec  7.63 MBytes  63.6 Mbits/sec
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bandwidth
[  4]   0.00-10.01  sec  89.0 MBytes  74.6 Mbits/sec                  sender
[  4]   0.00-10.01  sec  89.0 MBytes  74.6 Mbits/sec                  receiver

iperf Done.
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;ダイレクトlan&#34;&gt;ダイレクトLAN
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core\Desktop\iperf-3.1.3-win32&amp;gt;iperf3.exe -c 192.168.4.1
Connecting to host 192.168.4.1, port 5201
[  4] local 192.168.4.2 port 1524 connected to 192.168.4.1 port 5201
[ ID] Interval           Transfer     Bandwidth
[  4]   0.00-1.01   sec   178 MBytes  1.48 Gbits/sec
[  4]   1.01-2.00   sec   204 MBytes  1.72 Gbits/sec
[  4]   2.00-3.00   sec   214 MBytes  1.80 Gbits/sec
[  4]   3.00-4.00   sec   229 MBytes  1.92 Gbits/sec
[  4]   4.00-5.00   sec   202 MBytes  1.69 Gbits/sec
[  4]   5.00-6.00   sec   213 MBytes  1.79 Gbits/sec
[  4]   6.00-7.00   sec   230 MBytes  1.93 Gbits/sec
[  4]   7.00-8.00   sec   192 MBytes  1.61 Gbits/sec
[  4]   8.00-9.00   sec   220 MBytes  1.84 Gbits/sec
[  4]   9.00-10.00  sec   230 MBytes  1.93 Gbits/sec
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bandwidth
[  4]   0.00-10.00  sec  2.06 GBytes  1.77 Gbits/sec                  sender
[  4]   0.00-10.00  sec  2.06 GBytes  1.77 Gbits/sec                  receiver

iperf Done.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;参照資料&#34;&gt;参照資料
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;HugoにMermaidのサポートを追加する&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>華碩マザーボードZ490、ディスクが多くなるとたまに認識しない。</title>
        <link>https://ttf248.life/ja/p/asus-motherboard-z490-too-many-disks-intermittent-disk-recognition/</link>
        <pubDate>Fri, 10 Jan 2025 00:08:51 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/asus-motherboard-z490-too-many-disks-intermittent-disk-recognition/</guid>
        <description>&lt;p&gt;前回の続きで、無線LANカードが認識されない問題が発生し、パーティションを再構築する前に、オンラインで他の解決策も調べましたが、例えばマザーボードのバッテリーを取り外して15分間電源を切る、最新バージョンのBIOSドライバにアップデートするなど、それらも問題がありました。&lt;/p&gt;
&lt;p&gt;まだ処理しなければいけないことがあったので、低速ネットワークに切り替えて、リビングから部屋までLANケーブルを引っ張ってきたところ、また問題が発生し、有線ネットワークも認識されない。思い切ってシステムを再インストールすると、起動パーティションが見つからない。もしずっと問題が起きていなければ、こんなに手間をかけていないだろう。ASUSのこのディスクの競合は、偶発的なもので、システムの再起動不安定さが引き金になっているのだろう。&lt;/p&gt;
&lt;p&gt;先週、デスクトップに新しいディスクを追加しました。長江メモリの2TBのSSDで、M.2インターフェースです。その後、昨日まで再起動しませんでした。一度シャットダウンしたことがきっかけです。&lt;/p&gt;
&lt;p&gt;ディスクファミリー&lt;/p&gt;
&lt;h2 id=&#34;システムを再インストールする&#34;&gt;システムを再インストールする
&lt;/h2&gt;&lt;p&gt;計算してみると、システムを再インストールしてからも2年が経っていた。Cドライブの容量はもう足りないし、Windows特有の問題も発生している。普段から色々なソフトウェアがCドライブに何かデータを保存したがる。それで、システムを再インストールすることにした。システムを再インストールした後、ネットワークアダプターの問題は正常になった。翌日には日常の開発環境を復旧させ、システムのバックアップを作成しようとしたとき、新しい問題が発生した。システムを再起動すると、ブートパーティションが消えてしまった。&lt;/p&gt;
&lt;p&gt;前の記事の手順に従ってブートパーティションを再構築しましたが、不安定です。再起動後、ブートパーティションが読み込まれない可能性があります。ケースの改造を疑い始めたところ、ハードディスクケーブルが緩んでいたようです。何度か確認しましたが、問題ありませんでした。&lt;/p&gt;
&lt;h2 id=&#34;記憶の回帰&#34;&gt;記憶の回帰
&lt;/h2&gt;&lt;p&gt;数年前にこの機械は一度SSDを増設したことがあり、その際、PCIE変換器（グラフィックカードのインターフェースに接続）を使って、直接マザーボードに取り付けなかった。今回、直接マザーボードに取り付けたので、マザーボードの問題かもしれない。&lt;/p&gt;
&lt;p&gt;固体変換器&lt;/p&gt;
&lt;h2 id=&#34;マザーボード取扱説明書&#34;&gt;マザーボード取扱説明書
&lt;/h2&gt;&lt;p&gt;マザーボードの説明書に問題があり、記載されているSATAインターフェースの位置と実際の場所が異なっている。ディスクが多く、すべてのインターフェースにHDDが取り付けられているため、古いSSDもすべてSATAインターフェースである。マザーボードの説明書によると、これらのインターフェース間には競合が存在するはずだが、実際にテストしたところ、この競合は不安定に発生し、発生すると対応するディスクを読み込めなくなる。まさにそのディスクがシステムディスクであり、ブートローダーも同じディスク上にあるため、システムの起動時にブートロードの失敗が発生する。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/asus-motherboard-z490-too-many-disks-intermittent-disk-recognition/20250110002401.png&#34;
	width=&#34;807&#34;
	height=&#34;847&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Z490&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;95&#34;
		data-flex-basis=&#34;228px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;解決策&#34;&gt;解決策
&lt;/h2&gt;&lt;p&gt;PCIE変換器にSSDを再インストールすると、マザーボードのSATAインターフェースとの競合がなくなり、システムは正常に起動します。&lt;/p&gt;</description>
        </item>
        <item>
        <title>ESP パーティション、GPT パーティションテーブル、そして Windows オペレーティングシステムの協調の謎を探る</title>
        <link>https://ttf248.life/ja/p/exploring-esp-gpt-and-windows-cooperation/</link>
        <pubDate>Thu, 09 Jan 2025 23:58:20 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/exploring-esp-gpt-and-windows-cooperation/</guid>
        <description>&lt;p&gt;昨日退社後、自宅に戻り、いつものようにデスクトップPCを起動したところ、システムは正常に起動したが無線LANカードが読み込まれない。カードの接触不良かと思い、分解して無線LANカードを再インストールしたが、さらに問題が悪化し、システムが直接起動せず、ブートローダーが失敗した。&lt;/p&gt;
&lt;p&gt;久しぶりなのでデスクトップPCをいじると、パーティションの構成が少し戸惑う。DisGeniusで空き領域を再パーティション化する（通常はディスクの前方に）、そしてESPパーティションとして割り当てる（デフォルト300M）。PEシステムに入り、ブートを再構築する。関連資料はネットで調べられる。&lt;/p&gt;
&lt;p&gt;新しいESPパーティション&lt;/p&gt;
&lt;p&gt;MSRパーティションを取り除くことはできます。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;コンピュータのストレージの世界において、ESPパーティション、GPTパーティションテーブル、そしてWindowsオペレーティングシステムは密接に結びついており、それぞれが独自の重要な役割を果たし、システムの安定した動作と効率的な管理を支えています。しかし、それらを深く理解する前に、避けて通れないのがコンピュータのパーティションの歴史における「先輩」ともいえるMBRパーティションテーブル形式です。この形式は、その後の新しい技術と相互に映照し合い、テクノロジーの進化の軌跡を際立たせています。それでは、今日、これらの内なる関連性と巧妙さを深く分析していきましょう。&lt;/p&gt;
&lt;h2 id=&#34;一mbrパーティションテーブル従来のハードディスクの基礎&#34;&gt;一、MBRパーティションテーブル——従来のハードディスクの「基礎」
&lt;/h2&gt;&lt;p&gt;MBR、正式名称はマスターブートレコード（Master Boot Record）であり、パーソナルコンピュータの黎明期から存在し、長年にわたりハードディスクパーティション領域を支配してきた。&lt;/p&gt;
&lt;h3 id=&#34;基本アーキテクチャ&#34;&gt;基本アーキテクチャ
&lt;/h3&gt;&lt;p&gt;それはハードディスクの最初のセクタ、つまり0セクタに位置し、512バイトの領域を占有しています。この512バイトは主に3つの部分に分けられます。まず、ブートローダーコードがあり、コンピュータ起動時にオペレーティングシステムのブートローダをロードする役割を担い、通常446バイトです。次に、ディスクパーティションテーブルがあり、64バイトを占有し、最大で4つのプライマリパーティション情報を定義できます。各パーティション記述は16バイトを占有し、パーティションの開始ヘッド、セクタ、シリンダー、およびパーティションタイプ、サイズなどの重要なパラメータが記録されています。最後に、2バイトがMBR終了フラグ「55 AA」としてあり、このセクタが有効なMBRであることを識別します。&lt;/p&gt;
&lt;h3 id=&#34;歴史的功績と限界&#34;&gt;歴史的功績と限界
&lt;/h3&gt;&lt;p&gt;かつて、MBRパーティションテーブルは、個人用コンピューターの比較的単純なストレージ要件を十分に満たしていました。これにより、オペレーティングシステムはハードディスクのパーティションを円滑に認識し、データの順序付けられた保存と読み込みを実現できました。しかし、時代が進展するにつれて、その限界がますます明らかになってきました。一方、64バイトという制限されたパーティションテーブルスペースにより、最大で4つのプライマリパーティションしか作成できず、より多くのパーティションを作成するには、拡張パーティションや論理パーティションといったやや複雑な方法を用いる必要があり、ディスク管理に不便をきたします。他方、最大2TBのハードディスク容量しかサポートしていないため、現在の数TBから数十TBという大容量ハードディスクの前では力不足であり、ストレージ技術のさらなる発展を制約するボトルネックとなっています。&lt;/p&gt;
&lt;h2 id=&#34;二espパーティションシステムの見えない起動キー&#34;&gt;二、ESPパーティション——システムの「見えない起動キー」
&lt;/h2&gt;&lt;p&gt;ESPは、EFI System Partitionの略で、UEFI（Unified Extensible Firmware Interface）規格に基づくコンピューターに不可欠な特殊なパーティションです。&lt;/p&gt;
&lt;h3 id=&#34;機能特徴&#34;&gt;機能特徴
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;起動ブート&lt;/strong&gt;: コンピュータの電源を入れると、UEFIファームウェアはまずハードディスク上のESPパーティションを探し、そこに保存されている起動ローダー（Windows Boot Managerなど）を読み込み、その上でオペレーティングシステムを起動します。これはまるで精密な鍵のように、システムの起動という扉を開き、これがないとシステムは起動時に戸惑い、方向を見失います。&lt;/li&gt;
&lt;li&gt;ストレージドライバ：ESPパーティションには、システム起動時に不可欠ないくつかのドライバが格納されており、これにより、ハードウェアデバイス（HDDコントローラ、グラフィックカードなど）が初期起動段階で正常に動作し、その後のオペレーティングシステムの円滑な引き継ぎを可能にします。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;空間要件とフォーマット&#34;&gt;空間要件とフォーマット
&lt;/h3&gt;&lt;p&gt;通常の場合、ESP パーティションの推奨サイズは100MB～500MBの間で、一般的には約200MBを割り当てれば基本的なニーズを満たすことができます。ファイルシステム形式はFAT32である必要があります。これは、UEFIファームウェアが起動ファイルを読み取るためにFAT32形式のみを認識するためであり、互換性とクロスプラットフォーム性を確保します。&lt;/p&gt;
&lt;h2 id=&#34;gptパーティション表ハードディスクのスマート管理係&#34;&gt;GPTパーティション表——ハードディスクの「スマート管理係」
&lt;/h2&gt;&lt;p&gt;GPT（GUIDパーティションテーブル）は、グローバルに固有の識別子を持つパーティションテーブルであり、従来のMBRパーティションテーブルを代替する新しいパーティション方式です。&lt;/p&gt;
&lt;h3 id=&#34;強み発揮&#34;&gt;強み発揮
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;大容量サポート&lt;/strong&gt;: データの爆発的な増加が進む現代において、大容量ハードディスクが次々と登場しています。GPTパーティションテーブルはMBRの2TBという容量制限を突破し、理論上は最大9.4ZB（ゼタバイト、1ZB=1024EB、1EB=1024PB、1PB=1024TB）という超大容量ストレージスペースをサポートし、膨大なデータストレージの可能性を開きます。&lt;/li&gt;
&lt;li&gt;MBR とは異なり、最大で 4 つのプライマリパーティションしか作成できないのに対し、GPT では最大 128 個までパーティションを作成できるため、ユーザーやシステム管理者は複数のシステムパーティション、データパーティションを割り当てたり、特殊な用途のためにパーティションを予約したりするなど、非常に柔軟に対応できます。&lt;/li&gt;
&lt;li&gt;信頼性が高い：GPT パーティションテーブルは、冗長バックアップメカニズムを採用しており、ディスクのヘッダー部とテール部にそれぞれパーティションテーブル情報を保存しています。万が一、ある場所のパーティションテーブルが破損した場合でも、システムは別のバックアップから自動的に復旧するため、パーティションテーブルの故障によるデータ損失のリスクを大幅に低減し、データの安全性を確保します。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;構造分析&#34;&gt;構造分析
&lt;/h3&gt;&lt;p&gt;GPTパーティションテーブルは複数の部分で構成されており、保護MBR（従来のBIOSとの互換性を保つために残された小さなMBR構造ですが、実際のパーティション管理には使用されません）、GPTヘッダ（パーティションテーブルのバージョン、パーティション数、パーティションテーブルサイズなどの基本的な情報を格納します）、そしてパーティションエントリ配列（各パーティションエントリは、開始セクタ、終了セクタ、パーティションタイプGUID、パーティションの一意な識別子などの重要な情報を詳細に記録します）が含まれます。これらの構造が相互に連携し、ハードディスクのスペースを正確に計画・管理します。&lt;/p&gt;
&lt;h2 id=&#34;四windows-オペレーティングシステムユーザーのデジタルインタラクションの世界&#34;&gt;四、Windows オペレーティングシステム——ユーザーの「デジタルインタラクションの世界」
&lt;/h2&gt;&lt;p&gt;Windowsは、世界中で広く使用されているオペレーティングシステムであり、人とコンピュータハードウェアの間の友好的な橋を架けています。&lt;/p&gt;
&lt;h3 id=&#34;esp-パーティションと-gpt-パーティションテーブルの統合&#34;&gt;ESP パーティションと GPT パーティションテーブルの統合
&lt;/h3&gt;&lt;p&gt;UEFI ベースで起動する Windows システムのインストールプロセスにおいて、インストーラーは自動的に ESP パーティションを作成し、そこにブートファイルをデプロイします。同時に、ディスクは GPT パテーションテーブル形式で初期化され、システム予約パーティション（システム重要ファイルを格納し、従来の BIOS のシステムブートファイル領域に類似）、Windows システムパーティション（システムコアファイルをインストールする場所）、およびその他のユーザーが定義したデータパーティションなどが作成されます。Windows システムは、GPT パーティションテーブルによって各パーティションを正確に識別し、ESP パーティションを通じてスムーズに起動します。これら三者はシームレスに連携し、ユーザーに快適な起動と使用体験をもたらします。&lt;/p&gt;
&lt;h3 id=&#34;システム管理と最適化の基盤&#34;&gt;システム管理と最適化の基盤
&lt;/h3&gt;&lt;p&gt;Windowsは動作中にGPTパーティションテーブルの利点を最大限に活用してディスク管理を行います。例えば、ディスク管理ツールではGPTパーティションを簡単に識別でき、ユーザーはパーティションの作成、削除、フォーマット、サイズ変更などの操作を容易に行い、さまざまな段階でのデータストレージニーズに対応できます。また、システム更新やソフトウェアインストールなどのプロセスもパーティションレイアウトと密接に関連しており、適切なパーティション構成はシステムのパフォーマンスと安定性を向上させ、ディスク容量不足やパーティションの混乱によって引き起こされる問題を軽減するのに役立ちます。&lt;/p&gt;
&lt;h2 id=&#34;五実践のヒント保守とトラブルシューティング&#34;&gt;五、実践のヒント：保守とトラブルシューティング
&lt;/h2&gt;&lt;p&gt;それらの密接な関係を理解することで、日々のメンテナンスとトラブルシューティングに手順が確立される。&lt;/p&gt;
&lt;h3 id=&#34;ディスクスペース管理&#34;&gt;ディスクスペース管理
&lt;/h3&gt;&lt;p&gt;ESP パーティションの空き容量を定期的に確認し、過剰な起動項目関連ソフトウェアのインストールによる容量不足を防ぎ、システム起動への影響を避けてください。GPT パーティション下のデータパーティションについては、適切なストレージ計画を立て、不要なファイルをタイムリーに削除することで、単一パーティションが満杯になりシステム動作に影響を与えるのを防いでください。&lt;/p&gt;
&lt;h3 id=&#34;トラブルシューティングの開始&#34;&gt;トラブルシューティングの開始
&lt;/h3&gt;&lt;p&gt;システムが起動しない場合、まずESPパーティションが破損していないか、ファイルが失われていないかを確認してください。UEFIファームウェアに付属している起動項目修復ツールを使用するか、Windowsのインストールメディアから回復環境に入り、ESPパーティションの起動ファイルを再構築できます。GPTパーティションテーブルの故障が疑われる場合は、専門的なディスクツール（DiskGeniusなど）を使用してパーティションテーブルの完全性を確認し、パーティションテーブル情報をバックアップして失われたパーティションを復元してみてください。&lt;/p&gt;
&lt;p&gt;ESP パーティション、GPT ディスク構造、そして Windows オペレーティングシステムは、まるで精密に連携するチームのように、それぞれの得意分野を発揮し、安定した高効率なコンピューター環境を作り上げています。これらを深く理解することは、システムインストールやメンテナンスをスムーズに進めるだけでなく、コンピューターの基盤となる動作原理を理解し、デジタル世界を自由に旅することを可能にします。同時に、MBR ディスク構造の盛衰を振り返ることは、技術進歩の力に感銘を与えられます。それはストレージ技術を常に前進させ、日々増大するデータストレージの需要に適応させています。&lt;/p&gt;</description>
        </item>
        <item>
        <title>GCC、GLIBC と C&#43;&#43; プログラムの互換性問題に関する深い理解</title>
        <link>https://ttf248.life/ja/p/deep-understanding-gcc-glibc-cpp-compatibility-issues/</link>
        <pubDate>Mon, 06 Jan 2025 19:51:16 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/deep-understanding-gcc-glibc-cpp-compatibility-issues/</guid>
        <description>&lt;p&gt;C++の開発分野において、GCCとGLIBCは避けて通れない重要な要素であり、プログラムのリリース後の互換性の問題も開発者を悩ませることがよくあります。本稿では、これらの本質を深く分析し、互換性の問題の根本原因とその対策について探求します。&lt;/p&gt;
&lt;h2 id=&#34;一gcc堅固なコンパイラ基盤&#34;&gt;一、GCC：堅固なコンパイラ基盤
&lt;/h2&gt;&lt;p&gt;定義と機能&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GCC（GNU コンパイラ コレクション）は、GNUプロジェクトが開発したオープンソースのコンパイラスイートです。これは単なるコンパイラではなく、C、C++、Objective-C、Fortran、Ada、Goなど、多様な主要言語をサポートし、クロス言語開発のためのワンストップソリューションを提供します。&lt;/li&gt;
&lt;li&gt;C++ を例にとると、クラス、テンプレート、関数オーバーロードなどの複雑な機能を備えたソースファイルを記述する際、GCC は C++ の厳格な文法と意味規則に基づいて、高度な C++ コードを、基盤となる機械が理解し実行できる命令シーケンスに変換することができます。このプロセスには、語彙解析、構文解析、意味解析、最適化、コード生成など、複数の精緻な段階が含まれます。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;コンパイルプロセス詳解&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;前処理段階&lt;/strong&gt;: GCCはまず、ソースファイルを前処理します。この間、 &lt;code&gt;#&lt;/code&gt;で始まるすべてのプリプロセッサディレクティブを処理します。例えば、&lt;code&gt;#include&lt;/code&gt;ディレクティブは、指定されたヘッダファイル（C++の入出力ストリーム操作に使用される&lt;code&gt;&amp;lt;iostream&amp;gt;&lt;/code&gt;など）の内容全体をソースファイルの対応する位置に埋め込み、プログラムがヘッダファイルで宣言されている関数やクラスなどのリソースを使用できるようにします。また、&lt;code&gt;#define&lt;/code&gt;ディレクティブで定義されたマクロもこの段階で展開置換されます。例えば、&lt;code&gt;#define PI 3.14159&lt;/code&gt;の場合、ソースファイル内のすべての&lt;code&gt;PI&lt;/code&gt;の箇所が&lt;code&gt;3.14159&lt;/code&gt;に置き換えられます。前処理後、ソースファイルは初期「拡充」されます。&lt;/li&gt;
&lt;li&gt;コンパイル段階：前処理されたファイルはコンパイルの段階に入り、GCC は C++ 言語標準に基づいてソースファイルをアセンブリ言語コードに変換します。クラスの継承、ポリモーフィズムの実装、関数呼び出しパラメータのマッチングなど、コード構造を厳密にチェックし、文法や意味に合致しないエラーが見つかった場合は、速やかにエラーを出力してコンパイルプロセスを終了します。例えば、関数宣言と定義のパラメータリストが一致しない場合、GCC は問題箇所を正確に指摘します。&lt;/li&gt;
&lt;li&gt;アセンブリ段階：アセンブラは前段階で生成されたアセンブリコードを機械語に変換し、&lt;code&gt;.o&lt;/code&gt;という拡張子のオブジェクトファイルを生成します。これらのオブジェクトファイルには、機械が直接実行できるバイナリ命令が含まれていますが、通常、完全なプログラムは複数のモジュールから構成され、各モジュール間の関数や変数の参照関係が解決されていないため、単独で実行することはできません。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;リンク段階&lt;/strong&gt;：これは実行可能ファイルを生成する最後のスパートです。リンカは複数のオブジェクトファイルと必要なライブラリファイル（静的ライブラリまたは動的ライブラリ）を統合します。例えば、C++標準テンプレートライブラリのコンテナクラスを使用する場合、リンク時には対応するライブラリの実装コードを見つける必要があります。プログラム実行時に&lt;code&gt;vector&lt;/code&gt;や&lt;code&gt;list&lt;/code&gt;などのコンテナ機能を正しく呼び出せるようにし、最終的に完全な実行可能プログラムを生成します。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;二glibccプログラムを支える舞台裏&#34;&gt;二、GLIBC：C++プログラムを支える舞台裏
&lt;/h2&gt;&lt;p&gt;本質と役割&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GLIBC（GNU C Library）は、C標準ライブラリのGNUエコシステムにおける具体的な実装です。名前がCを強調していますが、C++プログラムもそれに強く依存しており、なぜならC++はCの基礎部分を受け継いでいるからです。メモリ管理のための&lt;code&gt;malloc&lt;/code&gt;（動的メモリ割り当て）、&lt;code&gt;free&lt;/code&gt;（メモリ解放）のような膨大な基本関数を提供し、これらはC++で動的な配列やオブジェクトを作成する際に不可欠です。また、&lt;code&gt;strcpy&lt;/code&gt;（文字列コピー）、&lt;code&gt;strcat&lt;/code&gt;（文字列連結）といった文字列処理関数も、C++に&lt;code&gt;string&lt;/code&gt;クラスがあるにも関わらず、Cコードとの連携や最高のパフォーマンスを追求する場合に利用されます。さらに、&lt;code&gt;printf&lt;/code&gt;、&lt;code&gt;scanf&lt;/code&gt;などの標準入出力関数も、C++の初期開発段階や、性能に敏感で簡潔さを追求する場面で頻繁に見られます。
システムとの連携&lt;/li&gt;
&lt;li&gt;GLIBCは、オペレーティングシステムとアプリケーションの間の重要な橋渡し役を果たします。Linuxシステムにおいて、C++プログラムがシステムコールを発行する際、例えばファイルを開く（&lt;code&gt;open&lt;/code&gt;関数を使用し、その基盤としてGLIBCの実装に依存）場合、GLIBCはそのプログラムのリクエストをオペレーティングシステムのカーネルが定める方法でカプセル化し、カーネルに渡します。カーネルの処理が完了すると、GLIBCは結果をアプリケーションに戻します。これにより、アプリケーションはオペレーティングシステムの複雑なシステムコールインターフェースの詳細を深く理解することなく、ファイルシステム、ネットワーク、プロセス管理などの様々なシステムリソースを簡単に利用できるようになります。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cプログラム公開後の互換性の問題分析&#34;&gt;C++プログラム公開後の互換性の問題分析
&lt;/h2&gt;&lt;p&gt;GLIBCバージョンの違いによる互換性の問題&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;異なる Linux ディストリビューションは、しばしば異なるバージョンの GLIBC を搭載しています。C++ プログラムが高バージョン GLIBC 環境でコンパイルされると、意図せずしてそのバージョンで新たに追加された関数機能を利用したり、より最適化された関数実装に依存したりすることがあります。例えば、新しい GLIBC バージョンではメモリ割り当てアルゴリズムが改善されており、プログラムは実行時にこの新アルゴリズムを頻繁に利用することでパフォーマンスを向上させます。しかし、このプログラムを低バージョン GLIBC システム上で動作させると、対応する関数が見つからない（低バージョンで導入されていないため）あるいは関数の挙動が異常になる（旧版の関数実装ロジックと新版にずれがある）といった問題が発生し、プログラムがクラッシュしたり、結果が誤ったものになったりする可能性があります。
コンパイラの違いによる互換性の問題&lt;/li&gt;
&lt;li&gt;たとえ同じGCCコンパイラを使用した場合でも、異なるバージョンのGCCでは、コード生成、標準ライブラリのサポート、およびC++機能の実装の詳細に違いがあります。新しいバージョンのGCCは、C++20の新機能（モジュールやコルーチンなど）を完全にサポートしている可能性がありますが、これらの最先端機能を活用したプログラムを古いバージョンのGCCでコンパイルすると、コンパイラが新しい構文構造を認識できないためにエラーが発生します。また、構文エラーがない場合でも、異なるGCCバージョン間の最適化戦略の違いにより、生成される機械語の実行効率やメモリ使用量が大きく異なり、パフォーマンスが重要なシナリオでは、プログラムの動作が異なる環境で大きく異なる結果になる可能性があります。
システムアーキテクチャの差異がもたらす課題&lt;/li&gt;
&lt;li&gt;C++プログラムは、x86、ARM、PowerPCなどの異なるハードウェアシステムアーキテクチャ上で動作する必要がある場合があります。各アーキテクチャには、独自の命令セット、メモリレイアウト、データアライメント要件があります。例えば、データアライメントに関して言えば、x86アーキテクチャで正常に動作する構造体データの格納レイアウトが、ARMアーキテクチャではアライメント規則の違いによりメモリアクセス異常を引き起こし、結果としてプログラムのエラーにつながる可能性があります。さらに、GCCは異なるアーキテクチャ向けにコンパイルすると生成される機械語が大きく異なり、プログラム中にハードコードされたアーキテクチャ固有の命令や仮定が存在する場合、クロスアーキテクチャでの実行時に頻繁な障害が発生するでしょう。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;四互換性の問題への対応策&#34;&gt;四、互換性の問題への対応策
&lt;/h2&gt;&lt;p&gt;静的リンクライブラリの応用&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;静的にリンクされたライブラリを使用することを検討してください。プログラムが依存する GLIBC などのライブラリのコードを、実行ファイルに直接パッケージングします。そうすることで、プログラムは実行時にターゲットシステム上の特定の GLIBC のバージョンに依存しなくなり、GLIBC のバージョンの不一致によって引き起こされる問題を効果的に回避できます。ただし、静的リンクは実行ファイルのサイズを大幅に増加させるため、ストレージリソースが限られたシナリオでは、メリットとデメリットを比較検討する必要があります。
コンテナデプロイメント&lt;/li&gt;
&lt;li&gt;Dockerなどのコンテナ化技術を活用し、C++プログラムとその実行環境（特定のバージョンのGCC、GLIBCなど）を独立したコンテナにパッケージングします。これにより、基盤となるオペレーティングシステムが何であれ、コンテナ内部は常にプログラム開発時の環境を維持し、プログラムが期待通りに動作することを保証します。また、異なる環境へのデプロイメントの複雑さを大幅に軽減します。
互換性テストと継続的インテグレーション&lt;/li&gt;
&lt;li&gt;包括さまざまなGLIBCバージョン、GCCバージョン、および一般的なシステムアーキテクチャを網羅した、包括的な互換性テスト体系を構築する。開発プロセス中に、継続的インテグレーションツールを使用して、複数の環境で定期的に自動テストを実施し、互換性の問題が発見された場合は迅速に修正することで、潜在的な問題を初期段階で扼殺し、プログラムのリリース後の安定性を確保する。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上記を総合すると、GCCとGLIBCの動作メカニズムを深く理解し、C++プログラムの互換性問題の根本原因を正確に把握し、柔軟に対処戦略を用いることは、すべてのC++開発者が堅牢でクロスプラットフォームなアプリケーションを構築するために不可欠なスキルです。そうすることで初めて、私たちのC++作品は多様な技術エコシステムの中で円滑に進むことができるでしょう。&lt;/p&gt;</description>
        </item>
        <item>
        <title>Windowsに標準搭載されているディスククリーンアップツール：ストレージ</title>
        <link>https://ttf248.life/ja/p/windows-disk-cleanup-storage/</link>
        <pubDate>Mon, 06 Jan 2025 19:29:45 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/windows-disk-cleanup-storage/</guid>
        <description>&lt;p&gt;どのバージョンからかはっきりとは分からないが、Windows 11ではディスククリーンアップツールが大幅に改善され、よりスマートになっている。&lt;/p&gt;
&lt;p&gt;重要なのは、これは公式ツールであり、ファイルが誤って削除されることはなく、広告もポップアップもバックグラウンドプロセスもなく、不要なものが一切ないということです。&lt;/p&gt;
&lt;p&gt;Windows 11では、「設定」-「システム」-「ストレージ」-「一時ファイル」からディスククリーンアップツールを開くことができます。&lt;/p&gt;
&lt;p&gt;保存画面&lt;/p&gt;
&lt;p&gt;通常ユーザーは「おすすめのクリーンアップ」を選択すればよいです。システムはあなたの利用状況に基づいて、いくつかの提案を提示します。&lt;/p&gt;
&lt;p&gt;私は開発者なので、ディスク上に多くの仮ファイルがあり、「一時ファイル」を選択しました。そこには、例えば「Visual Studio」の仮ファイルや「Windows Update」の仮ファイルなど、たくさんの仮ファイルが含まれています。&lt;/p&gt;
&lt;p&gt;仮ファイル&lt;/p&gt;</description>
        </item>
        <item>
        <title>Docker国内镜像代理失効</title>
        <link>https://ttf248.life/ja/p/docker-domestic-mirror-failure/</link>
        <pubDate>Sat, 04 Jan 2025 18:29:25 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/docker-domestic-mirror-failure/</guid>
        <description>&lt;p&gt;国内サーバーにDockerをデプロイし、デプロイ後、もし会社がイメージセンターを提供していない場合、開発者がまず行うべきことは、国内のイメージ加速アドレスを設定することです。ちょうど今日、一台のサーバーがあり、イメージ加速アドレスを設定しましたが、イメージのプルダウンがずっとできません。&lt;/p&gt;
&lt;p&gt;エラー応答: デーモンからのエラー: &lt;code&gt;https://registry-1.docker.io/v2/&lt;/code&gt; への接続を待機中にタイムアウトが発生しました (&lt;code&gt;net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;二日ぶりのことですが、全てのサーバーが復旧しました。なぜこれが話題にならないのか、国内のすべてのミラープロキシはダウンしています。&lt;/p&gt;
&lt;h2 id=&#34;トラブルシューティングと修理の試み&#34;&gt;トラブルシューティングと修理の試み
&lt;/h2&gt;&lt;p&gt;当初、別のミラーの加速アドレスに切り替えることを試みましたが、期待した効果はなく、問題は依然として解決されませんでした。&lt;/p&gt;
&lt;p&gt;直ちに、ローカルDNSの設定変更に着手し、ネットワーク解析のレベルで突破口を探りましたが、何度かデバッグしても、問題は依然として解決しませんでした。&lt;/p&gt;
&lt;p&gt;現時点では、ローカルネットワークの安定性が疑われているため、思い切って携帯電話のテザリングに切り替え、考えられるローカルネットワークの問題点を回避しようとしましたが、結果は落胆するもので、問題は全く改善されません。&lt;/p&gt;
&lt;h2 id=&#34;問題が拡大&#34;&gt;問題が拡大
&lt;/h2&gt;&lt;p&gt;現在も&lt;strong&gt;国内にいくつかサーバー&lt;/strong&gt;があり、それらはすべて Docker 環境がインストールされています。これらのサーバーでイメージのプルを試みましたが、別の方法を見つけられるのではないかと考えていましたが、例外なくすべて失敗し、エラーメッセージは全く同じでした。これは問題が特定のデバイスに限られたものではないことを示しています。&lt;/p&gt;
&lt;p&gt;さらに調査したところ、ミラープロキシが一時的に機能しなくなったようです。この緊急事態において、すぐに海外のサーバーに切り替えて試みると、幸いなことに、ここでミラーの取得は正常に戻り、問題はおおむね国内のネットワーク経路または関連設定にある可能性が高いことを意味します。&lt;/p&gt;
&lt;h2 id=&#34;戦術調整間接解決&#34;&gt;戦術調整：間接解決
&lt;/h2&gt;&lt;p&gt;国内の直接リソースミラーリングが様々な妨害を受けている現状と、海外ミラーは正常にアクセスできる状況を踏まえ、プロジェクトを迅速に進めるため、回り道をすることに決定しました。まず海外サーバーへ切り替え、必要なリソースミラーを問題なく取得した後、国内のリソースミラー倉庫へプッシュし、「データブリッジ」を構築します。&lt;/p&gt;
&lt;p&gt;同時に、Dockerfile ファイルも修正し、イメージのアドレスを国内環境に適合したアドレスに置き換えた後、再度イメージを構築し、最終的に正常にデプロイすることができた。&lt;/p&gt;</description>
        </item>
        <item>
        <title>CentOS 8 Stream EOL</title>
        <link>https://ttf248.life/ja/p/centos-8-stream-eol/</link>
        <pubDate>Sat, 16 Nov 2024 23:24:50 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/centos-8-stream-eol/</guid>
        <description>&lt;p&gt;CentOS Streamは、Red Hat Enterprise Linuxのリリース前のアップストリームオープンソース開発プラットフォームです。
オープンソースオペレーティングシステムのライフサイクル[Red HatおよびCentOSのライフサイクル]({relref &amp;ldquo;/post/2020/07-redhat and centos life cycle&amp;rdquo;})&lt;/p&gt;
&lt;p&gt;期限切れです、何か問題がありますか？セキュリティの問題以外に、DNFが使えなくなりました。最近ツールをインストールしようとしたときにDNFが失敗し、ミラーソースを確認したところ、&lt;code&gt;CentOS 8 Stream&lt;/code&gt;の有効期限が切れていました。&lt;/p&gt;
&lt;h2 id=&#34;centos-streamのご紹介&#34;&gt;CentOS Streamのご紹介
&lt;/h2&gt;&lt;h3 id=&#34;位置付けと役割&#34;&gt;位置付けと役割
&lt;/h3&gt;&lt;p&gt;CentOS Streamは、Fedora Linux（上流開発）とRHEL（Red Hat Enterprise Linux、下流開発）の間で橋渡し役を果たします。&lt;/p&gt;
&lt;p&gt;最新Red Hat Linuxの機能を試すためのバージョンと見なすことができ、最新技術を体験したいユーザーに適しています。&lt;/p&gt;
&lt;h3 id=&#34;誕生と背景&#34;&gt;誕生と背景
&lt;/h3&gt;&lt;p&gt;時が経つにつれて、Red Hat社は企業向けLinuxプラットフォームを成長させるためのより効果的な方法を模索し始め、CentOS Streamを発表しました。&lt;/p&gt;
&lt;p&gt;CentOS 8は2021年末にサポート終了となり、その代替としてCentOS Streamがアップデートされ続け、CentOSプロジェクトの将来的な方向性となっています。&lt;/p&gt;
&lt;h3 id=&#34;特徴と利点&#34;&gt;特徴と利点
&lt;/h3&gt;&lt;p&gt;CentOS Streamは、より迅速なアップデートを提供するローリングリリース型のLinuxディストリビューションです。コミュニティ、パートナー、顧客の参加を促進し、高い透明性と機会を提供することで、ユーザーがRed Hat Enterprise Linuxに、より迅速かつ直接的に貢献できるようになります。&lt;/p&gt;
&lt;p&gt;CentOS Streamの内容は、Red Hatが次期安定版RHELに組み込むことを意図しているソフトウェアであり、コミュニティメンバーが開発およびテストのために安定したABI/APIを利用できるものです。&lt;/p&gt;
&lt;h3 id=&#34;利用シーンとターゲットユーザー&#34;&gt;利用シーンとターゲットユーザー
&lt;/h3&gt;&lt;p&gt;CentOS Streamは、最新のLinux機能アップデートを継続的に受けたいCentOSユーザーや、Red Hat Enterprise Linuxの開発に貢献したい開発者およびパートナーに適しています。&lt;/p&gt;
&lt;p&gt;コミュニティのメンバー、Red Hat パートナー、およびその他の関係者が、より安定し予測可能な Linux エコシステムの中で革新的なオープンソースプログラムを最大限に活用できるよう支援することを目的としています。&lt;/p&gt;
&lt;h2 id=&#34;満了日&#34;&gt;満了日
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Release&lt;/th&gt;
&lt;th&gt;Released&lt;/th&gt;
&lt;th&gt;Active Support&lt;/th&gt;
&lt;th&gt;Security Support&lt;/th&gt;
&lt;th&gt;Latest&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;3 years ago (15 Sep 2021)&lt;/td&gt;
&lt;td&gt;Ends in 2 years and 6 months (31 May 2027)&lt;/td&gt;
&lt;td&gt;Ends in 2 years and 6 months (31 May 2027)&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;5 years ago (24 Sep 2019)&lt;/td&gt;
&lt;td&gt;Ended 5 months and 3 weeks ago (31 May 2024)&lt;/td&gt;
&lt;td&gt;Ended 5 months and 3 weeks ago (31 May 2024)&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;解決策&#34;&gt;解決策
&lt;/h2&gt;&lt;p&gt;面倒なアップグレードの問題を避けるため、Ubuntu 24.04の長期サポートバージョンを選択しました。&lt;/p&gt;</description>
        </item>
        <item>
        <title>Hugoモジュールカスタムテーマ改修：アイデア解説</title>
        <link>https://ttf248.life/ja/p/hugo-module-custom-theme-ideas/</link>
        <pubDate>Fri, 15 Nov 2024 22:01:17 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/hugo-module-custom-theme-ideas/</guid>
        <description>&lt;p&gt;過去のコミット履歴を振り返ると、サイトは何度もテーマを変更してきた。たびにカスタムした変更があり、ここではその変更のアイデアを記録しておく。筆者のGitHubにもリポジトリがあり、一時的にEvenテーマをメンテナンスしていたが、強迫観念から最新版にHugoコンパイラをアップデートしようとした結果、Evenテーマとの互換性がなくなり、Stackテーマに戻した。&lt;/p&gt;
&lt;h2 id=&#34;ヒューゴのモジュール化&#34;&gt;ヒューゴのモジュール化
&lt;/h2&gt;&lt;p&gt;モジュール化と聞くと、NginxのモジュールやIDEAプラグインなどが思い浮かぶかもしれません。通常は、いくつかのモジュールをアップロードすることで、私の差別化されたニーズを満たすことができます。皆がこのモジュールを好む主な理由は、十分に柔軟性があり、あまり労せずして自身のニーズを満たせるからです。なぜなら、多くの場合、全体としては似ていても、細部には差異があるからです。これもまた、ソフトウェアの複雑さを物語っており、技術的な複雑さだけでなく、ビジネス上の複雑さも存在します。ほとんどの場合、私たちはビジネス上の複雑さに直面します。これは、ソフトウェア分野における「隔行如隔山」という言葉の最も良い説明です。現在では、インターネット業界だけでなく、金融業界や伝統的な製造業に至るまで、情報化システムを利用して企業の生産と管理を支援しています。同じ休暇申請システムでも、同じ業界であっても、異なる会社ごとに差異が生じることがあります。&lt;/p&gt;
&lt;p&gt;そして、Hugoのモジュールは、皆さんが想像するような機能単位で多様なニーズを満たすものではなく、むしろディレクトリ構造を主とし、同じ構造を識別することに重点を置いています。&lt;/p&gt;
&lt;p&gt;資料リンク：&lt;a class=&#34;link&#34; href=&#34;https://medium.com/@sunwei.xyz/07-hugo%E6%9E%B6%E6%9E%84-hugo%E7%9A%84%E6%A8%A1%E5%9D%97-8ef5a520a822&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;07. Hugo 架构 — Hugo 的模块&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[[imports]]
path = &amp;quot;github.com/CaiJimmy/hugo-theme-stack/v3&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Git サブモジュール方式は引き続き利用可能ですが、本稿では推奨しません。テーマの更新が発生した場合、個別の Git リポジトリでテーマを管理する必要があり、メンテナンスが煩雑になります。&lt;/p&gt;
&lt;h2 id=&#34;テーマの変更ロジック&#34;&gt;テーマの変更ロジック
&lt;/h2&gt;&lt;p&gt;モジュール化の基礎概念を理解した上で、カスタムテーマを理解するのは非常に簡単になります。現在Hugoが提供しているテーマも、複数の異なるモジュールを組み合わせて作られており、もし特定のモジュールを変更したい場合は、対応するテンプレートファイルを特定して修正すれば良いのです。&lt;/p&gt;
&lt;p&gt;Stack公式ドキュメントからの抜粋です。&lt;/p&gt;
&lt;p&gt;Using this method, there won&amp;rsquo;t be any file under &lt;code&gt;themes&lt;/code&gt; directory. In order to modify the theme, you will have to copy the file you want to modify to the same directory under &lt;code&gt;layouts&lt;/code&gt; directory.&lt;/p&gt;
&lt;p&gt;For example, in order to modify the &lt;code&gt;themes/hugo-theme-stack/layouts/partials/head/custom.html&lt;/code&gt; file, you will have to copy it to &lt;code&gt;layouts/partials/head/custom.html&lt;/code&gt; and modify it there (copy the code from theme&amp;rsquo;s repository). The same applies to &lt;code&gt;assets&lt;/code&gt; and &lt;code&gt;static&lt;/code&gt; directories。&lt;/p&gt;
&lt;h2 id=&#34;テンプレートファイルを見つけるにはどうすればいいですか&#34;&gt;テンプレートファイルを見つけるにはどうすればいいですか。
&lt;/h2&gt;&lt;h3 id=&#34;正統な発想&#34;&gt;正統な発想
&lt;/h3&gt;&lt;p&gt;テーマのソースファイルを確認し、デザインの意図を理解した上で、対応するテンプレートファイルを修正すればよい。&lt;/p&gt;
&lt;h3 id=&#34;乱暴な考え方&#34;&gt;乱暴な考え方
&lt;/h3&gt;&lt;p&gt;私はフロントエンドコードに詳しくないので、時には乱暴な方法を取ることがあります。例えば、ブラウザで該当のページを開いて、変更したい場所を見つけ、「要素を検証」機能を使って&lt;code&gt;css name&lt;/code&gt;を特定し、テーマソースコード内で検索して、対応するファイルを見つけたら、それをサイトディレクトリにコピーして修正するというものです。&lt;/p&gt;
&lt;h2 id=&#34;ちょっとしたコツ&#34;&gt;ちょっとしたコツ
&lt;/h2&gt;&lt;p&gt;公式デフォルトでスタイルをカスタマイズするためのファイルが用意されており、変更が必要な箇所は複数のファイルに分割し、&lt;code&gt;custom.scss&lt;/code&gt;ファイルから他のファイルをインポートすることで、よりスタイルのファイルを整理して管理できます。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/hugo-module-custom-theme-ideas/image.png&#34;
	width=&#34;141&#34;
	height=&#34;375&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;37&#34;
		data-flex-basis=&#34;90px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;変更点まとめ6h&#34;&gt;変更点まとめ(6h)
&lt;/h2&gt;&lt;p&gt;現在はすでに「AI」コーディングの元年であり、詳細についてはここでは割愛しますが、簡単な変更点としては、コピーボタンのスタイルの調整やコードブロックのスタイルの再設定などです。「ChatGPT」なら簡単に対応できます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;全体：グローバルテキストスタイル。以前の &lt;code&gt;even&lt;/code&gt; と &lt;code&gt;info cn&lt;/code&gt; の表示スタイルを継承し、中国語に親和性がある。&lt;/li&gt;
&lt;li&gt;ホームページ：右側のナビゲーションにマウスインタラクションアニメーションを追加&lt;/li&gt;
&lt;li&gt;トップページ：記事に要約プレビューを追加しました（時間がかかりすぎるので、多少の裏手回りを経て実現しました）。&lt;/li&gt;
&lt;li&gt;スクロールバー：スタイルを少し修正しました。&lt;/li&gt;
&lt;li&gt;コードブロックに &lt;code&gt;highlight.js&lt;/code&gt; コードハイライトプラグインが導入され、コードブロックのスタイルが改善されました。&lt;/li&gt;
&lt;li&gt;一部内容は転載であり、新規に著作者情報表示と原文リンク表示を追加しました。&lt;/li&gt;
&lt;li&gt;アーカイブページ：上部のカテゴリ画像、テーマに付属するカラーオーバーレイを削除し、オリジナルの画像をそのまま表示します。&lt;/li&gt;
&lt;li&gt;アーカイブページ：年ごとの分類による統計表示パネルを追加しました。&lt;/li&gt;
&lt;li&gt;アーカイブページ：2列表示レイアウト&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;スタックのテーマのコンポーネント再利用率が非常に高いため、ホームページの記事に概要プレビューを追加するのに時間がかかりました。対応するコンポーネントを変更した結果、記事の詳細ページも変更され、正文の内容が重複して表示されるようになりました。また、&lt;code&gt;golangテンプレート&lt;/code&gt;の構文にも詳しくなかったので、時間がかかりました。コンポーネント間のパラメータ伝送は最後までうまくいかず、最終的には裏技を使って、ホームページに個別の&lt;code&gt;JavaScript&lt;/code&gt;スクリプトを導入し、カスタム特殊変数を使用して概要プレビューを実現しました。&lt;/p&gt;
&lt;p&gt;コードの再利用率が時々高すぎると問題になることがあります。ある場所を変更すると、他の場所にも影響が出てしまうため、テーマを修正する際は、既存のロジックを壊さないように注意してください。&lt;/p&gt;
&lt;h3 id=&#34;コメント欄&#34;&gt;コメント欄
&lt;/h3&gt;&lt;p&gt;この男の人の修正はさらに完璧になりました：&lt;a class=&#34;link&#34; href=&#34;https://blog.reincarnatey.net/2024/0719-better-waline/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.reincarnatey.net/2024/0719-better-waline/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;このサイトでは簡単な &lt;code&gt;Waline&lt;/code&gt; コメントシステムを導入しています。&lt;code&gt;stack&lt;/code&gt; テーマはデフォルトで &lt;code&gt;Waline&lt;/code&gt; をサポートしており、&lt;code&gt;config.toml&lt;/code&gt; で設定するだけで利用できます。&lt;/p&gt;
&lt;p&gt;推奨ページ、メールお問い合わせ。当サイトではコメント欄は開放しておりません。&lt;/p&gt;</description>
        </item>
        <item>
        <title>Linuxバックエンドサービス、大量文字列データの処理が遅い</title>
        <link>https://ttf248.life/ja/p/linux-backend-slow-string-processing/</link>
        <pubDate>Wed, 13 Nov 2024 19:42:59 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/linux-backend-slow-string-processing/</guid>
        <description>&lt;p&gt;C++開発の過去プロジェクトにおいて、独自のプロトコルを使用して通信しており、そのプロトコルは二次元配列の形式を採用していました。大量のデータを処理する際、プロトコル内で配列を走査し、シリアライズ操作によってログを生成する必要がありましたが、効率が悪かったため、高負荷時にシステムが顕著にカクつき、業務部門からシステムの動作不良に関するフィードバックがありました。&lt;/p&gt;
&lt;h2 id=&#34;問題特定&#34;&gt;問題特定
&lt;/h2&gt;&lt;p&gt;問題の調査 során、まずシステムのパフォーマンス分析を行い、大量のデータを処理する際に CPU 使用率が大幅に増加し、システム応答時間が長くなることを発見しました。システムのログを分析した結果、大量のシリアライズ操作があり、これらの操作は 2 次元配列の処理において効率が悪く、システムパフォーマンスの低下につながっていました。&lt;/p&gt;
&lt;p&gt;pstackツールでサービスの糸処理情報を取得したところ、ログスレッドの大部分の時間文字列の結合処理に費やされていることがわかった。&lt;/p&gt;
&lt;p&gt;今日の焦点は、異なる累積方法による効率の大きな違いです。過去のコードでは「+」演算子を使用しており、この方法は頻繁に一時オブジェクトを作成するため、非常に非効率的です。それが非効率的だと知っていても、どれほど非効率的なのかを理解していないようなものです。&lt;/p&gt;
&lt;h2 id=&#34;デモ検証&#34;&gt;デモ検証
&lt;/h2&gt;&lt;p&gt;プロジェクトコードに基づいて、業務ロジックを分離し、文字列結合の効率に関する検証のために簡単なデモを作成しました。&lt;code&gt;windows&lt;/code&gt; の &lt;code&gt;vs2022&lt;/code&gt; コンパイラ、&lt;code&gt;linux&lt;/code&gt; の &lt;code&gt;gcc8.5&lt;/code&gt; コンパイラで、&lt;code&gt;Release&lt;/code&gt; モードでコンパイル・実行し、効率を比較します。&lt;/p&gt;
&lt;h3 id=&#34;重要なポイント説明&#34;&gt;重要なポイント説明
&lt;/h3&gt;&lt;p&gt;プロジェクトでは手法4を使用しており、テストデータを入手する前に、読者はどの方法が最も効率的か、またどの方法が最も非効率かを考えてみることができます。結果を見たときには、やはり驚きました。&lt;/p&gt;
&lt;p&gt;方法 1（&lt;code&gt;+=&lt;/code&gt; 連結）：各フィールドを &lt;code&gt;+=&lt;/code&gt; を使って文字列に連結します。
方法 2 ( &lt;code&gt;std::ostringstream&lt;/code&gt; による結合) ：ストリーム (&lt;code&gt;std::ostringstream&lt;/code&gt;) を用いて各フィールドを結合する方法です。この方法は特に、大量のデータを結合する場合に効率的です。
方法3（事前にメモリを割り当てた&lt;code&gt;+=&lt;/code&gt;連結）：&lt;code&gt;reserve&lt;/code&gt;を使って文字列に十分なメモリを事前に割り当てることで、メモリの再割り当てにかかるコストを削減し、パフォーマンスが向上します。
方法 4 ( &lt;code&gt;bodys = bodys + body + &amp;quot;\n&amp;quot;&lt;/code&gt; ) : 毎回新しい一時的な文字列オブジェクトを作成するため、パフォーマンスが低下します。特に大規模な結合の場合、結合ごとに新しいメモリ割り当てとコピーが発生するためです。&lt;/p&gt;
&lt;p&gt;参照結果を見ると、プロジェクトは効率が最も悪い方法が選択されたようです。&lt;/p&gt;
&lt;p&gt;さらに踏み込んで、各プラットフォームのコンパイラ最適化効率を分析してみましょう。MicrosoftのVisual Studioは相変わらず優れており、文字列の最適化効率は非常に高いですが、GCCコンパイラはその点では少し劣ります。&lt;/p&gt;
&lt;p&gt;コードを異なる機械で実行すると、2つのデータには直接的な比較の意味がないため、それぞれの結合方法間の差異を別々に比較できます。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;windows 平台下的 vs2022 编译器

----------------------------------------
Data Generation Time: 0.054 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.053 seconds.
+ ostringstream Data merging took: 0.054 seconds.
+ Pre-reserved Data merging took: 0.045 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 16.108 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;linux 平台下的 gcc8.5 编译器
----------------------------------------
Data Generation Time: 0.108 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.100 seconds.
+ ostringstream Data merging took: 0.083 seconds.
+ Pre-reserved Data merging took: 0.057 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 29.298 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;完全コード&#34;&gt;完全コード
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;random&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;sstream&amp;gt;
#include &amp;lt;iomanip&amp;gt;

typedef std::vector&amp;lt;std::string&amp;gt; DataRow;
typedef std::vector&amp;lt;DataRow&amp;gt; DataGroup;

struct ResponsePackage
{
    std::string ErrorInfo;
    DataRow Head;
    std::string ClientId;
    std::string UUID;
    std::string MsgID;
    std::string SessionID;
    std::string ExtraInfo1;
    std::string ExtraInfo2;
    DataGroup DataBody;
};

// Generate specified length of random string
std::string generateRandomString(size_t length)
{
    const char charset[] = &amp;quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&amp;quot;;
    const size_t max_index = sizeof(charset) - 1;
    std::string random_string;
    random_string.reserve(length);

    std::random_device rd;
    std::mt19937 generator(rd());
    std::uniform_int_distribution&amp;lt;&amp;gt; distribution(0, max_index);

    for (size_t i = 0; i &amp;lt; length; ++i)
    {
        random_string += charset[distribution(generator)];
    }

    return random_string;
}

void create_large_string()
{
    // Example request package with 50 fields
    ResponsePackage requestPackage;

    requestPackage.Head = {
        &amp;quot;Field1&amp;quot;, &amp;quot;Field2&amp;quot;, &amp;quot;Field3&amp;quot;, &amp;quot;Field4&amp;quot;, &amp;quot;Field5&amp;quot;,
        &amp;quot;Field6&amp;quot;, &amp;quot;Field7&amp;quot;, &amp;quot;Field8&amp;quot;, &amp;quot;Field9&amp;quot;, &amp;quot;Field10&amp;quot;,
        &amp;quot;Field11&amp;quot;, &amp;quot;Field12&amp;quot;, &amp;quot;Field13&amp;quot;, &amp;quot;Field14&amp;quot;, &amp;quot;Field15&amp;quot;,
        &amp;quot;Field16&amp;quot;, &amp;quot;Field17&amp;quot;, &amp;quot;Field18&amp;quot;, &amp;quot;Field19&amp;quot;, &amp;quot;Field20&amp;quot;,
        &amp;quot;Field21&amp;quot;, &amp;quot;Field22&amp;quot;, &amp;quot;Field23&amp;quot;, &amp;quot;Field24&amp;quot;, &amp;quot;Field25&amp;quot;,
        &amp;quot;Field26&amp;quot;, &amp;quot;Field27&amp;quot;, &amp;quot;Field28&amp;quot;, &amp;quot;Field29&amp;quot;, &amp;quot;Field30&amp;quot;,
        &amp;quot;Field31&amp;quot;, &amp;quot;Field32&amp;quot;, &amp;quot;Field33&amp;quot;, &amp;quot;Field34&amp;quot;, &amp;quot;Field35&amp;quot;,
        &amp;quot;Field36&amp;quot;, &amp;quot;Field37&amp;quot;, &amp;quot;Field38&amp;quot;, &amp;quot;Field39&amp;quot;, &amp;quot;Field40&amp;quot;,
        &amp;quot;Field41&amp;quot;, &amp;quot;Field42&amp;quot;, &amp;quot;Field43&amp;quot;, &amp;quot;Field44&amp;quot;, &amp;quot;Field45&amp;quot;,
        &amp;quot;Field46&amp;quot;, &amp;quot;Field47&amp;quot;, &amp;quot;Field48&amp;quot;, &amp;quot;Field49&amp;quot;, &amp;quot;Field50&amp;quot;
    };

    requestPackage.ClientId = &amp;quot;ClientID&amp;quot;;
    requestPackage.UUID = &amp;quot;UUID&amp;quot;;
    requestPackage.MsgID = &amp;quot;MsgID&amp;quot;;
    requestPackage.SessionID = &amp;quot;SessionID&amp;quot;;
    requestPackage.ExtraInfo1 = &amp;quot;ExtraInfo1&amp;quot;;
    requestPackage.ExtraInfo2 = &amp;quot;ExtraInfo2&amp;quot;;

    // Start timing for data generation
    auto start_gen = std::chrono::high_resolution_clock::now();

    // Generate 10,000 rows of data, each with 50 fields
    for (size_t i = 0; i &amp;lt; 10000; ++i)
    {
        DataRow dataRow(50, &amp;quot;This is a test string&amp;quot;);
        requestPackage.DataBody.push_back(dataRow);
    }

    // End timing for data generation
    auto end_gen = std::chrono::high_resolution_clock::now();
    std::chrono::duration&amp;lt;double&amp;gt; duration_gen = end_gen - start_gen;

    // Display result generation time
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Generation Time: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_gen.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    // Data merging using different methods
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Performance:\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    {
        // Method 1: Using &#39;+=&#39; string concatenation
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys(&amp;quot;&amp;quot;);
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (+=) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 2: Using ostringstream
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::ostringstream bodys;
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::ostringstream body;
            body &amp;lt;&amp;lt; &amp;quot;This is a test string&amp;quot;;
            for (auto&amp;amp; item : vec)
            {
                body &amp;lt;&amp;lt; item &amp;lt;&amp;lt; &amp;quot; &amp;quot;;
            }
            bodys &amp;lt;&amp;lt; body.str() &amp;lt;&amp;lt; &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ ostringstream Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 3: Pre-allocated memory
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys;
        bodys.reserve(1000 * 50 * 20); // Pre-allocate enough memory
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            body.reserve(50 * 20); // Pre-allocate memory for each row
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Pre-reserved Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 4: Using &#39;bodys = bodys + body + &amp;quot;\n&amp;quot;&#39;
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys(&amp;quot;&amp;quot;);
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            for (auto&amp;amp; item : vec)
            {
                body = body + item + &amp;quot; &amp;quot;; // Note the use of &#39;body = body + item&#39;
            }
            bodys = bodys + body + &amp;quot;\n&amp;quot;; // Again, using &#39;bodys = bodys + body&#39;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (bodys = bodys + body + \&amp;quot;\\n\&amp;quot;) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Complete.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;
}

int main()
{
    try
    {
        create_large_string();
    }
    catch (const std::exception&amp;amp; e)
    {
        std::cerr &amp;lt;&amp;lt; &amp;quot;Caught exception: &amp;quot; &amp;lt;&amp;lt; e.what() &amp;lt;&amp;lt; std::endl;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\nProgram finished.\n&amp;quot;;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>C&#43;&#43;ラムダ式パラメータのライフサイクル</title>
        <link>https://ttf248.life/ja/p/cpp-lambda-parameter-lifetime/</link>
        <pubDate>Wed, 13 Nov 2024 19:23:02 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/cpp-lambda-parameter-lifetime/</guid>
        <description>&lt;p&gt;C++において、ラムダ式は便利な匿名関数であり、外部変数をキャプチャしてその内部で使用できます。これにより、ラムダ式は柔軟なプログラミングツールとなります。ただし、ラムダ式のパラメータのライフサイクルは特に注意すべき点であり、特にキャプチャおよびパラメータの伝送時にはそうです。&lt;/p&gt;
&lt;h3 id=&#34;ラムダ式のパラメータのライフサイクル&#34;&gt;ラムダ式のパラメータのライフサイクル
&lt;/h3&gt;&lt;p&gt;ラムダ式のパラメータの寿命は、通常、他のC++関数と同様です。関数のパラメータは、関数呼び出し中に存在し、関数呼び出しが終了すると、パラメータの寿命は終了します。しかしながら、ラムダ式が外部変数にキャプチャする場合、パラメータの寿命はキャプチャ方法の影響も受けます。&lt;/p&gt;
&lt;h3 id=&#34;キャプチャとパラメータのライフサイクルとの関係&#34;&gt;キャプチャとパラメータのライフサイクルとの関係
&lt;/h3&gt;&lt;h4 id=&#34;21-外部変数の捕捉&#34;&gt;2.1 外部変数の捕捉
&lt;/h4&gt;&lt;p&gt;C++のラムダ式は、外部変数を2つの方法でキャプチャできます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;値キャプチャ：値キャプチャによって、外部変数の値がラムダ関数内にコピーされ、そのコピーのライフサイクルはラムダ関数のライフサイクルによって制御されます。&lt;/li&gt;
&lt;li&gt;参照獲得：参照獲得により、外部変数の参照は保持され、ラムダ内の参照は元の外部変数を示し、寿命はその外部変数に依存します。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int x = 10;
auto lambda_by_value = [x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };  // 捕获x的副本
auto lambda_by_reference = [&amp;amp;x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };  // 捕获x的引用

lambda_by_value();  // 打印10
lambda_by_reference();  // 打印10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;捕捉された変数のライフサイクルは以下の通りです。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;値によるキャプチャ：キャプチャされたとき、外部変数の値がラムダにコピーされます。そして、ラムダのライフサイクルが終わると、そのコピーが破棄されます。&lt;/li&gt;
&lt;li&gt;参照によるキャプチャ：ラムダが外部変数への参照を持つ場合、&lt;strong&gt;外部変数はラムダの使用前に有効である必要があり、そうでないと未定義の動作が発生する可能性がある&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;ラムダパラメータ&#34;&gt;ラムダパラメータ
&lt;/h4&gt;&lt;p&gt;ラムダのパラメータは通常の関数パラメータと同様で、そのライフサイクルはラムダ関数内に限定されます。つまり、ラムダパラメータはラムダ呼び出し時に作成され、ラムダ呼び出しが終了すると、パラメータのライフサイクルも終了します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;auto lambda = [](int a, int b) {
    std::cout &amp;lt;&amp;lt; a + b &amp;lt;&amp;lt; std::endl;
};
lambda(5, 10);  // a和b在这里是lambda的参数
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;この例では、&lt;code&gt;a&lt;/code&gt; と &lt;code&gt;b&lt;/code&gt; はラムダ式のパラメータであり、ラムダ式の呼び出し時に作成され、実行終了後に破棄されます。&lt;/p&gt;
&lt;h3 id=&#34;キャプチャした外部変数のライフサイクルに関する問題&#34;&gt;キャプチャした外部変数のライフサイクルに関する問題
&lt;/h3&gt;&lt;h4 id=&#34;キャプチャされた変数はラムダ関数外で有効に利用できるか&#34;&gt;キャプチャされた変数は、ラムダ関数外で有効に利用できるか。
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;値によるキャプチャ：ラムダ呼び出し後に外部変数が破棄されても、ラムダ内部は外部変数のコピーを保持します。したがって、外部変数はもう存在しなくても、ラムダ内部のコピーは安全に使用できます。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int x = 10;
auto lambda = [x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };
x = 20;  // x 在lambda调用后修改
lambda();  // 打印10，捕获的是x的副本
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;参照によるキャプチャ：ラムダが外部変数の参照をキャプチャする場合、ラムダ内部でのその参照へのアクセスは外部変数のライフサイクルに依存します。外部変数がラムダの実行前に破棄されると、ハングリング参照の問題が発生し、未定義の動作につながる可能性があります。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int x = 10;
auto lambda = [&amp;amp;x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };
x = 20;  // x 在lambda调用前修改
lambda();  // 打印20，捕获的是x的引用
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ラムダの実行順序が確定しない場合、ラムダが実行される際にキャプチャされた外部変数が有効であることを保証することが非常に重要です。&lt;/p&gt;</description>
        </item>
        <item>
        <title>Win11 Logitech G431 ヘッドホン ドライバーのインストール</title>
        <link>https://ttf248.life/ja/p/win11-logitech-g431-headphone-driver-installation/</link>
        <pubDate>Wed, 05 Jun 2024 07:20:17 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/win11-logitech-g431-headphone-driver-installation/</guid>
        <description>&lt;p&gt;続きは前回の話、戻ってみたらGhubがアップデートされているので少し嬉しい。カスタマーサポートで報告されていた問題駆動が正常にロードできない問題は解決したとのことだったのだが、色々試してインストールとアンインストールを繰り返しても、やはり正常に使えない。&lt;/p&gt;
&lt;h2 id=&#34;背景&#34;&gt;背景
&lt;/h2&gt;&lt;p&gt;引き続きカスタマーサポートに連絡して対応方法を確認しましたが、エンジニアによるリモートサポートが可能であるという回答でした。しかし、エンジニアの勤務時間と私の勤務時間が完全に同じで、結局諦めるしかありませんでした。以前の問題切り分けのために残しておいた資料を調べ、手動でのドライバーインストールを試みることにしました。&lt;/p&gt;
&lt;h2 id=&#34;ドライバーのインストールパッケージを取得する&#34;&gt;ドライバーのインストールパッケージを取得する
&lt;/h2&gt;&lt;p&gt;ロジクール公式では個別のデバイスのドライバインストールパッケージは提供していません。どうすればドライバファイルを入手できますか？&lt;/p&gt;
&lt;p&gt;前回のリインストール時に残ったシステムイメージのインストールパッケージを利用して、ローカル仮想マシンで再度システムをリインストールできます。完全にクリーンな状態になったシステムに、個別にGhubをデプロイし、ヘッドホンデバイスを仮想マシンに介入させます。すると、ドライバーのパスを見つけてコピーアウトすれば良いのです。&lt;/p&gt;
&lt;p&gt;関連パス：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C:\ProgramData\LGHUB&lt;/li&gt;
&lt;li&gt;C:\Windows\System32\DriverStore\FileRepository\logi_audio.inf_amd64_010b035044e24be4&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;デバイスマネージャー&#34;&gt;デバイスマネージャー
&lt;/h2&gt;&lt;p&gt;重点は、2つ目のパスをどうやって見つけるかだ。まず、Win11システムで手動でドライバーファイルを管理する方法について簡単に整理しよう。この内容は、&lt;strong&gt;制御変数法を使って識別する。仮想マシンの中で、デバイスの抜き差しを繰り返し、デバイスマネージャーのデバイス情報を分析することで、ヘッドホンに関して3つのドライバーを処理する必要があることが判明した&lt;/strong&gt;。そのうち2つはシステムに付属しているものであり、1つだけがロジテック製だ。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;ドライバーマネージャー&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;上記の画像中の2番目のドライバは、ロジクール製です。現在インストールされているデバイスのドライバを分析し、仮想マシン内で全てのドライバパスを探します。まずlogiで始まるファイルを見つけ、ファイルの比較を行うことで、ドライバファイルを特定できます。フォルダ全体をコピーすれば、ドライバインストーラパッケージを入手したことになります。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;ドライバーインストールパッケージ&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;ドライバーをインストールする&#34;&gt;ドライバーをインストールする
&lt;/h2&gt;&lt;p&gt;デバイスマネージャーの画面で、ドライバーの更新をクリックし、「私のコンピューターを検索してドライバーを見つける」をクリックすると、次のような画面になります。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;ドライバーインストール&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;もちろん、開くと普通のUSBドライバとしてしか見えますが、それが通常のUSBドライバです。ディスクからインストールを選択し、パスは先ほどコピーしたフォルダを指定してください。インストール後、プルダウンメニューにロジテック独自のドライバが表示されるので、デバイスドライバを新しくインストールされたドライバに切り替えてください。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;ディスクインストール&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;人体の機器駆動&#34;&gt;人体の機器駆動
&lt;/h2&gt;&lt;p&gt;このデバイスのドライバファイルはすべてシステムが提供するものなので、デバイスドライバの前に感嘆符が存在するかどうかを確認するだけです。もし感嘆符があれば、ドライバ選択画面に入り、他のタイプのドライバに任意で切り替えた後、元のドライバに戻せば正常に戻ります。&lt;/p&gt;
&lt;h2 id=&#34;完了&#34;&gt;完了
&lt;/h2&gt;&lt;p&gt;ヘッドホンのマイクの音量が正常に戻り、おなじみのイアホンモニター機能も復活しました。&lt;/p&gt;
&lt;p&gt;サイドサウンド&lt;/p&gt;</description>
        </item>
        <item>
        <title>ロジクールヘッドホン ドライバのインストールに失敗</title>
        <link>https://ttf248.life/ja/p/logitech-headset-driver-installation-failed/</link>
        <pubDate>Fri, 31 May 2024 21:46:12 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/logitech-headset-driver-installation-failed/</guid>
        <description>&lt;p&gt;もしこれらのことについて全く理解できないなら、最初から公式のカスタマーサポートに連絡していれば、こんなにも時間を費やすことはなかったでしょう。&lt;/p&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/logitech-headset-driver-installation-failed/20240531220709.png&#34;
	width=&#34;693&#34;
	height=&#34;489&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;GHUB&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;141&#34;
		data-flex-basis=&#34;340px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;最近、自宅のPC開発用のCドライブの容量が足りなくなったので、特別に256GBの半退役SSDを取り出してCドライブ用に使うことにしたのだが、しょっちゅう色々やらかしてしまっている。上海へ引っ越してからずっと様々な用事で忙しかったのだが、ようやく先週、時間を作ってOSを再インストールした。&lt;/p&gt;
&lt;p&gt;システムのリセットは順調に進み、普段使うソフトウェアのインストールや開発環境の構築にも問題がありませんでした。数日後、リラックスするためにゲームをしようとした時、マウスとヘッドセットのドライバがまだインストールされていないことに気づきました。これらのデバイスはどちらもロジクール製なので、GHUBというソフトウェアをダウンロードして、ハードウェアを自動的に認識し、ドライバをインストールしました。&lt;/p&gt;
&lt;p&gt;しかし、予期せぬことが起こった。マウスのドライバーは問題なくインストールされたが、ヘッドセットのドライバーは「読み込み中」の状態が続いた。最新版のWindows 11システムとロジクスのドライバーが互換性がないことが原因でインストールに失敗したのではないかと疑っている。そこで、資料を探し、手動でドライバーをインストールしようとしたが、問題は解決しなかった。&lt;/p&gt;
&lt;p&gt;これらのデバイスのドライバは、それぞれどのような役割を果たしているのか簡単に説明します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;マウスのドライバは主に、マウスの移動速度などの機能を調整するために使用されます。マクロ機能はほとんど使いませんが、以前に記憶されたパラメータを復元するだけで十分です。&lt;/li&gt;
&lt;li&gt;ヘッドホンのドライバは主にモニター機能に使われ、チームボイスチャットで非常に役立つ。自分の声をモニタリングできるからだ。システムのマイク設定にも同様の機能はあるが、ドライバによる実装の方が効果が良い。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;何度か試行錯誤しても、イヤホンのドライバーが正常に読み込まれない。今日、ようやくカスタマーサポートに問い合わせて状況を確認してみることにしたところ、最近サーバーに問題があり、その結果、ドライバーのダウンロードが異常になっているとのことだった。現在対応中であり、次回アップデートで問題が解決する見込みだと言われた。&lt;/p&gt;
&lt;p&gt;まだヘッドホンのドライバの問題を解決できていませんが、少なくとも原因はわかりました。早く問題が解決することを願っています。&lt;/p&gt;
&lt;h2 id=&#34;マウスドライバー設定&#34;&gt;マウスドライバー設定
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/logitech-headset-driver-installation-failed/20240531220930.png&#34;
	width=&#34;1024&#34;
	height=&#34;768&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;G502&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/logitech-headset-driver-installation-failed/20240531220903.png&#34;
	width=&#34;1024&#34;
	height=&#34;768&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;G502&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>Python辞書にカスタムオブジェクトを格納する際の参照とdeepcopyの重要性</title>
        <link>https://ttf248.life/ja/p/python-dictionary-custom-objects-reference-vs-deepcopy/</link>
        <pubDate>Fri, 22 Mar 2024 01:08:05 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/python-dictionary-custom-objects-reference-vs-deepcopy/</guid>
        <description>&lt;p&gt;Pythonプログラミングにおいて、辞書は非常に強力なデータ構造であり、キーと値を関連付けて、これらのデータを効率的に検索および操作できます。辞書にカスタムオブジェクトを格納しようとするとき、重要な概念に出くわします。Pythonにおけるオブジェクトの代入は実際には参照による代入であり、オブジェクト自体の深いコピーではありません。つまり、カスタムオブジェクトを辞書に格納すると、辞書に格納されるのはオブジェクトへの参照であり、オブジェクトの新しいコピーではありません。&lt;/p&gt;
&lt;h2 id=&#34;カスタムオブジェクトの保存に関する基本的な例&#34;&gt;カスタムオブジェクトの保存に関する基本的な例
&lt;/h2&gt;&lt;p&gt;仮に、単純な &lt;code&gt;Person&lt;/code&gt; クラスがあるとします。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Person:
    def __init__(self, name, age):
        self.name = name
        self.age = age

# 创建一个 Person 对象
p1 = Person(&amp;quot;Alice&amp;quot;, 30)

# 将对象存储到字典中
people_dict = {}
people_dict[&amp;quot;alice&amp;quot;] = p1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;この例では、&lt;code&gt;people_dict&lt;/code&gt; ディクショナリはキーが &lt;code&gt;&amp;quot;alice&amp;quot;&lt;/code&gt; の項目を含み、その値は &lt;code&gt;Person&lt;/code&gt; 型の &lt;code&gt;p1&lt;/code&gt; オブジェクトへの参照です。もし &lt;code&gt;p1&lt;/code&gt; の属性を修正すると:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;p1.age = 31
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;そうすると、辞書を通してこのオブジェクトにアクセスしたとき、その年齢も更新されていることがわかります。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(people_dict[&amp;quot;alice&amp;quot;].age)  # 输出：31
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;辞書に格納されているのは、&lt;code&gt;Person&lt;/code&gt;オブジェクトの独立したコピーではなく、同じメモリのアドレスを指す参照です。&lt;/p&gt;
&lt;h2 id=&#34;深いコピーと浅いコピーの違い&#34;&gt;深いコピーと浅いコピーの違い
&lt;/h2&gt;&lt;p&gt;ネストされたデータ構造やカスタムオブジェクトを扱う場合、この参照動作は予期せぬ結果を引き起こす可能性があります。例えば、カスタムオブジェクトに可変型の属性（リストや別のカスタムオブジェクトなど）が含まれている場合、そのようなオブジェクトを直接辞書に格納し、それを変更すると、辞書を通して取得したオブジェクトに影響が及ぶことがあります。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Address:
    def __init__(self, street, city):
        self.street = street
        self.city = city

class Person:
    def __init__(self, name, age, address):
        self.name = name
        self.age = age
        self.address = address

address = Address(&amp;quot;Main St.&amp;quot;, &amp;quot;Springfield&amp;quot;)
p1 = Person(&amp;quot;Bob&amp;quot;, 40, address)
people_dict[&amp;quot;bob&amp;quot;] = p1

# 修改原始地址对象
address.city = &amp;quot;Shelbyville&amp;quot;

# 字典中的人的地址也变了
print(people_dict[&amp;quot;bob&amp;quot;].address.city)  # 输出：Shelbyville
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;解決策：ディープコピー&lt;/p&gt;
&lt;p&gt;このような共有状態がもたらす問題を避けるために、辞書にオブジェクトの完全なコピーを格納し、参照ではなく、というようにすることが必要な場合があります。Python の &lt;code&gt;copy&lt;/code&gt; モジュールにある &lt;code&gt;deepcopy&lt;/code&gt; 関数は、この目的を達成するために使用できます。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import copy

# 使用深拷贝存储对象
people_dict[&amp;quot;bob_deepcopy&amp;quot;] = copy.deepcopy(p1)

# 此时即使修改原始地址对象，深拷贝的对象不会受影响
address.city = &amp;quot;Capital City&amp;quot;
print(people_dict[&amp;quot;bob&amp;quot;].address.city)  # 输出：Capital City
print(people_dict[&amp;quot;bob_deepcopy&amp;quot;].address.city)  # 输出：Shelbyville
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;要するに、Pythonで辞書を使ってカスタムオブジェクトを保存する場合、デフォルトではオブジェクトへの参照が格納されることに注意してください。独立した状態を維持する必要がある場合は、共有による予期せぬデータ変更を防ぐために&lt;code&gt;deepcopy&lt;/code&gt;を使用して深いコピーを作成してください。&lt;/p&gt;</description>
        </item>
        <item>
        <title>新規に敷設されたギガビット回線、なぜ速度測定では100メガのみ？</title>
        <link>https://ttf248.life/ja/p/new-gigabit-fiber-slow-speed/</link>
        <pubDate>Mon, 18 Mar 2024 00:29:02 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/new-gigabit-fiber-slow-speed/</guid>
        <description>&lt;p&gt;家庭のネットワークを稲妻のように高速にしたいですか？ 鍵は、LANケーブルの選択、ONU（光回線終端装置）とルーターの設定、そして些細に見える小さな工夫を理解することです。 このブログでは、6類LANケーブルでギガビットネットワークを構築する方法や、簡単なデバイスチェックと設定によってネットワーク速度に制限がないようにするための方法を分かりやすく解説します。 さあ、一緒に探求して、家庭のインターネット回線を高速化させましょう！&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;手動修復&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;第1章ネットワーク伝送媒体の徹底分析&#34;&gt;第1章：ネットワーク伝送媒体の徹底分析
&lt;/h2&gt;&lt;p&gt;ギガビットネットワーク接続を実現するときの、情報高速伝送を支える媒体であるLANケーブルの役割は非常に重要です。以下に、カテゴリー5、カテゴリー6、カテゴリー7のLANケーブルについて詳しく解説します。&lt;/p&gt;
&lt;h3 id=&#34;カテゴリー5ケーブル-cat5&#34;&gt;カテゴリー5ケーブル (CAT5)
&lt;/h3&gt;&lt;p&gt;5種類のLANケーブル、別名CAT5は、比較的初期に普及したツイストペアケーブルの一種で、各芯線が精密な螺旋構造によって設計され、クロストークを低減しています。主に10/100Mbpsの高速イーサネットに適しており、最大伝送周波数はおよそ100MHzです。過去には広く利用されていましたが、現在のギガビット以上の速度に対応するニーズに対しては、物理的な限界から5種類のLANケーブルでは要求を満たすことができません。&lt;/p&gt;
&lt;h3 id=&#34;カテゴリー6ケーブル&#34;&gt;カテゴリー6ケーブル
&lt;/h3&gt;&lt;p&gt;技術の発展に伴い、カテゴリー6ケーブルが登場しました。カテゴリー5ケーブルと比較して、カテゴリー6ケーブルはより厳格な製造基準と高度な構造設計を採用しており、耐干渉性と伝送効率が大幅に向上しています。1Gbpsまでのデータ転送速度をサポートし、理想的な条件下では100メートルの伝送距離を実現します。これはまさにギガビットネットワークのアクセスニーズに合致しています。&lt;/p&gt;
&lt;h3 id=&#34;カテゴリー7ケーブル-cat7&#34;&gt;カテゴリー7ケーブル (CAT7)
&lt;/h3&gt;&lt;p&gt;カテゴリー7のケーブルは、現在のツイストペア技術における最高水準を示しています。これは、伝送速度が飛躍的に向上しているだけでなく、理論上は最大10Gbpsの超高速をサポートし、さらに設計に完全なシールドシステムを採用しており、各線対間のシールドと全体の外側のシールドを含み、外部からの電磁干渉や近接クロストークを大幅に低減することで、データ転送の安定性と正確性を確保しています。ただし、カテゴリー7ケーブルは主に将来の10ギガビットイーサネットまたは特定の高要求なシナリオで使用されます。&lt;/p&gt;
&lt;p&gt;ギガホームネットワーク環境を構築する際、ギガファイバーの潜在能力を最大限に引き出すためには、カテゴリー6ケーブルを選択することが最も経済的かつ効率的な選択です。同時に、すべての接続ケーブルの品質が適切であることを確認し、厳密に標準的な配線方法に従って操作することも、ネットワーク性能を確保するための重要な要素となります。&lt;/p&gt;
&lt;h2 id=&#34;第2章ネットワークの中枢機器における影響onuルーターのlanポート帯域幅の影響&#34;&gt;第2章：ネットワークの中枢機器における影響—ONU、ルーターのLANポート帯域幅の影響
&lt;/h2&gt;&lt;h3 id=&#34;光猫とlanポートの帯域幅の重要性&#34;&gt;光猫とLANポートの帯域幅の重要性
&lt;/h3&gt;&lt;p&gt;光ネコ（こうねこ）、正式名称は光ファイバーモデムであり、家庭ブロードバンド接続の中核となる機器です。その機能は、光ファイバー内の光信号をデジタル信号に変換し、家庭内ネットワーク機器が利用できるようにすることです。ギガビット光ファイバーユーザーにとって、光ネコがギガビット伝送に対応しているかどうかは特に重要です。光ネコのWANポートがギガビットに対応していない場合、戸別線路の光ファイバー速度がどれだけ高くても、このボトルネックによって100Mbps以内に制限されてしまいます。同様に、光ネコのLANポートもギガビット出力能力を備えている必要があります。そうでなければ、接続されたルーターやその他のデバイスは、真のギガビット速度を得ることができません。&lt;/p&gt;
&lt;h3 id=&#34;ルーターのlanポート帯域幅の役割&#34;&gt;ルーターのLANポート帯域幅の役割
&lt;/h3&gt;&lt;p&gt;ルーターのLANポートは、受信したデータを各端末デバイスに配信する役割を担います。ルーターのLANポートが100Mbpsの場合、他の機器の設定が再調整しても、100Mbpsの速度しか実現できないローカルエリアネットワーク通信となります。したがって、ギガホームネットワークを構築する際には、ルーターのWANポートがギガデータを受信できること、そしてLANポートもギガレベルのデータ出力能力を提供できるようにすることが重要です。そうすることで初めて、家庭内のすべてのスマートデバイスが高速ネットワークが生み出す快適な体験を享受できます。&lt;/p&gt;
&lt;p&gt;さらに注意すべき点として、一部の古いまたは低価格帯のルーターにはLANポートの自動速度ネゴシエーション機能が存在する場合があります。これは、ルーター自体がギガビットに対応していても、ケーブルやデバイスの互換性の問題などにより、100Mbpsモードに降格することがあるということです。したがって、ルーターの設定を適切に行い、強制ギガビットモードを有効にし、ギガビットスイッチまたは直接接続されたデバイスと組み合わせることが、全ギガビットネットワークを実現するための重要なステップの一つです。&lt;/p&gt;
&lt;p&gt;アップグレードをギガ光ファイバーに移行後、必ずギガ光回線終端装置（ONU）およびギガルーターに交換し、すべてのデバイスインターフェースがギガビットレベルに達していることを確認してください。&lt;/p&gt;
&lt;h2 id=&#34;第3章隠された謎一本途切れられたサブケーブルがテラビットネットワークにどのように影響するか&#34;&gt;第3章：隠された謎—一本途切れられたサブケーブルがテラビットネットワークにどのように影響するか
&lt;/h2&gt;&lt;h3 id=&#34;海底ケーブルの障害とネットワークパフォーマンスの低下&#34;&gt;海底ケーブルの障害とネットワークパフォーマンスの低下
&lt;/h3&gt;&lt;p&gt;測速期間中、ネットワークは常に接続されており、明確な断線は見られませんでした。新しく導入された回線のため、配電盤内が散らかっており、光モデムのケーブルや電源コンセントの位置を時々調整しているため、稀にギガビットまで速度が出ることがあります。&lt;/p&gt;
&lt;p&gt;先行きの資料に基づき、ケーブルの種類や光回線終端装置のLAN口の速度を分析・検証した結果、ついに原因がケーブル内部の茶色のサブワイヤーの断線であることが判明しました。&lt;/p&gt;
&lt;p&gt;設置の際に、水晶頭を取り付ける職人がこのLANケーブルを少し強く引っ張ったことが原因で、中の細い線が半分ほど切れていました。完全に断ち切られてはいなかったものの、その後、光モデムの位置を何度も調整するたびに移動させることが続き、最終的に完全に断裂しました。&lt;/p&gt;
&lt;h3 id=&#34;6種類のlanケーブルの8本の線の機能解説&#34;&gt;6種類のLANケーブルの8本の線の機能解説
&lt;/h3&gt;&lt;p&gt;カテゴリー6のLANケーブルは、TIA/EIA-568-B規格に準拠しており、8本のツイストペア線を持ち、カラーコードは以下の通りです。&lt;/p&gt;
&lt;p&gt;白橙 / 橙
白緑 / 緑
白藍／藍
白茶 / ほうじ茶&lt;/p&gt;
&lt;p&gt;ギガビットイーサネット（1000BASE-T）の規格において、この8本のケーブルのうち4対が同時に動作し、それぞれ以下の役割を担っています。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;白橙と橙のこのペアの線（1&amp;amp;2）は、データ送信（Tx+/-）に使用されます。&lt;/li&gt;
&lt;li&gt;白緑と緑のこのペア（3&amp;amp;6）は、データ受信（Rx+/-）に使用されます。&lt;/li&gt;
&lt;li&gt;白藍と青のペア（4&amp;amp;5）および白茶と茶のペア（7&amp;amp;8）は、ギガビットイーサネットでは通常はメインで使用されませんが、一部の高機能アプリケーション（例えば、特定のPoE給電や将来的な技術拡張など）において有効になる可能性があります。一方、従来の100Mbpsネットワークでは、1, 2, 3, 6の4本の線を使用するだけで十分です。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;切断されたファイバーがネットワーク速度に与える影響&#34;&gt;切断されたファイバーがネットワーク速度に与える影響
&lt;/h3&gt;&lt;p&gt;上記の状況において、もし茶色のサブケーブル（茶線または茶白線）が断線した場合、理論上はギガビットネットワーク環境では確かに速度低下が生じます。なぜならギガビットネットワークは全速を実現するために、4対の線全てで双方向通信を行う必要があるからです。しかしながら、家庭用ネットワーク機器にはオートネゴシエーション機能が備わっていることが多く、ケーブルに問題が発生した際に、正常動作する低いレートモード、つまり100Mbpsモードに切り替えます。これにより、サブケーブルが断線してもネットワークが接続され続け、100Mbpsの速度で動作することが説明できます。&lt;/p&gt;
&lt;p&gt;要言えば、単一の茶色のサブファイバーが切断されても、100Gbpsネットワークの基本的な動作には影響しませんが、ギガビットネットワーク環境下では、それがネットワーク速度を制限する重要な要因となり得ます。徹底的な診断と修復を行うことで初めて、ギガ光ファイバーの潜在能力を最大限に発揮できます。これも、同様の問題に遭遇した場合、一見すると基本的な接続に影響がないように見える小さな故障であっても、潜在的なネットワークインフラストラクチャの問題を無視してはならないことを示唆しています。そうした些細な問題が、高速ネットワーク体験の隠れた障害となる可能性があるからです。&lt;/p&gt;</description>
        </item>
        <item>
        <title>WPFのUIスレッドと、その応答性の問題とその解決策</title>
        <link>https://ttf248.life/ja/p/wpf-ui-thread-and-freezing-issues-solutions/</link>
        <pubDate>Tue, 12 Mar 2024 07:12:21 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/wpf-ui-thread-and-freezing-issues-solutions/</guid>
        <description>&lt;p&gt;デスクトップアプリケーションを開発する際、特にWindows Presentation Foundation (WPF) フレームワークを使用してリッチクライアントアプリケーションを構築する場合、ユーザーインターフェース（UI）スレッドを正しく処理することは、アプリケーションの滑らかさと応答性を保証するために非常に重要です。UIスレッドは、メインスレッドとも呼ばれ、ウィンドウやコントロールイベントの処理、レイアウト計算、およびインターフェースの描画を担当するコアスレッドです。UI要素とのインタラクションに関わる操作はすべて、UIスレッド上で実行されるべきであり、これはWPFをはじめとする多くのGUIフレームワークが遵守する基本的な原則です。&lt;/p&gt;
&lt;h2 id=&#34;uiスレッドとは何ですか&#34;&gt;UIスレッドとは何ですか？
&lt;/h2&gt;&lt;p&gt;WPFアプリケーションの起動時に、OSによってUIスレッドが作成され、アプリケーションのメインウィンドウが初期化されます。これは、アプリケーション内で直接UIコンポーネントの状態にアクセスおよび変更できる唯一のスレッドです。つまり、ボタンクリック、テキストボックスへの入力、ウィンドウサイズの変更など、すべてのユーザーインタラクションによって発生するイベントは、このスレッドのコンテキストで処理されます。同時に、WPFの依存プロパティシステム、データバインディングメカニズム、およびレイアウトロジックもUIスレッド上で同期的に実行されます。&lt;/p&gt;
&lt;h2 id=&#34;カクつき現象とその原因&#34;&gt;カクつき現象とその原因
&lt;/h2&gt;&lt;p&gt;UIスレッドが長時間占有またはブロックされると、例えば時間のかかる計算や大量のデータ読み込み、データベースクエリなどのI/O集約型のタスクを実行すると、UIスレッドはユーザーからのインタラクションリクエストにタイムリーに応答できなくなり、結果として画面がフリーズ（応答なし）したように見える、「カドゥン」と呼ばれる状態になります。このような状況下では、ユーザーはアプリケーションの遅延や不具合を強く感じることがあり、深刻な場合には「Application Not Responding」（ANR）警告が表示されることもあります。&lt;/p&gt;
&lt;h2 id=&#34;uiスレッドの2つの基本的なルール&#34;&gt;UIスレッドの2つの基本的なルール
&lt;/h2&gt;&lt;p&gt;上記のような状況を避けるために、WPF開発者は以下の2つの重要なルールに従うべきです。&lt;/p&gt;
&lt;p&gt;UIスレッドで時間のかかる処理を実行しないでください。UIスレッドがユーザーの入力にタイムリーに応答し、画面の変化をレンダリングできるように、可能な限り時間のかかる操作はバックグラウンドスレッドで実行するようにしてください。
UIスレッド以外のスレッドで直接UI要素を更新しないでください。WPFのセキュリティ機構により、UI要素の変更はUIスレッドのみが許可されています。他のスレッドから直接UIの状態を変更しようとすると例外が発生します。したがって、バックグラウンドスレッドで計算やデータ準備が完了した場合でも、適切なクロススレッド通信メカニズムを通じて結果をUIに表示する必要があります。&lt;/p&gt;
&lt;h2 id=&#34;解決策非同期プログラミングとスレッドセーフな更新&#34;&gt;解決策：非同期プログラミングとスレッドセーフな更新
&lt;/h2&gt;&lt;p&gt;UI のスムーズさを維持しながら、時間のかかるタスクを実行するために、WPF は開発者がこの目標を達成するのを支援するためのさまざまな非同期プログラミングモデルとツールを提供します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ディスパッチャオブジェクト：WPFのDispatcherクラスを使用すると、作業項目をUIスレッドのタスクキューに配置して実行できます。&lt;code&gt;Dispatcher.Invoke&lt;/code&gt;または&lt;code&gt;Dispatcher.BeginInvoke&lt;/code&gt;メソッドを使用して、バックグラウンドスレッドから安全にUIを更新できます。&lt;/li&gt;
&lt;li&gt;C#言語の非同期機能を利用することで、非同期メソッドを記述し、その中で&lt;code&gt;await&lt;/code&gt;キーワードを使用してバックグラウンドタスク完了を待機し、完了後に自動的にUIスレッドで実行して、後続のUI更新コードを実行できます。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;事例&#34;&gt;事例
&lt;/h2&gt;&lt;h3 id=&#34;dispatcherinvokeメソッドを使用してuiを更新する&#34;&gt;&lt;code&gt;Dispatcher.Invoke&lt;/code&gt;メソッドを使用してUIを更新する。
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;private void Button_Click(object sender, RoutedEventArgs e)
{
    // 假设这是一个耗时操作
    Task.Run(() =&amp;gt;
    {
        var result = LongRunningOperation(); // 这里是模拟一个耗时计算的方法
        
        // 当耗时操作完成后，在UI线程上更新UI
        Application.Current.Dispatcher.Invoke(() =&amp;gt;
        {
            LabelStatus.Text = $&amp;quot;计算结果: {result}&amp;quot;;
        });
    });
}

private string LongRunningOperation()
{
    // 模拟耗时操作
    Thread.Sleep(5000);
    return &amp;quot;已完成&amp;quot;;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;asyncawaitキーワードとtaskrunを組み合わせる&#34;&gt;&lt;code&gt;async/await&lt;/code&gt;キーワードと&lt;code&gt;Task.Run&lt;/code&gt;を組み合わせる。
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;private async void Button_ClickAsync(object sender, RoutedEventArgs e)
{
    Button button = sender as Button;
    button.IsEnabled = false; // 防止用户重复点击

    try
    {
        // 开启后台任务
        var result = await Task.Run(() =&amp;gt; LongRunningOperation());

        // 在后台任务完成后，自动切换回UI线程更新UI
        LabelStatus.Text = $&amp;quot;计算结果: {result}&amp;quot;;
    }
    catch (Exception ex)
    {
        MessageBox.Show($&amp;quot;发生错误: {ex.Message}&amp;quot;);
    }
    finally
    {
        button.IsEnabled = true; // 重新启用按钮
    }
}
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>GCCバージョンアップによりプログラムがクラッシュ：非標準コードの潜在的な問題</title>
        <link>https://ttf248.life/ja/p/upgrade-gcc-version-causes-program-crash-code-irregularities/</link>
        <pubDate>Sun, 10 Mar 2024 23:19:06 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/upgrade-gcc-version-causes-program-crash-code-irregularities/</guid>
        <description>&lt;p&gt;同一のビジネスコードの場合、プログラムは CentOS 7 環境で正常にコンパイルされ実行されたが、CentOS 8 に切り替えて更新版 GCC でコンパイルするとクラッシュした。問題が発生するのは &lt;strong&gt;Release モード&lt;/strong&gt; のみであり、&lt;strong&gt;Debug モード&lt;/strong&gt; では全く問題がない点が重要である。我々はこのような状況を初めて遭遇し、3 日間の調査の結果、ようやく問題の根本原因を見つけ出した。&lt;/p&gt;
&lt;h3 id=&#34;問題特定&#34;&gt;問題特定
&lt;/h3&gt;&lt;p&gt;一連の調査の結果、問題の根本原因は &lt;strong&gt;関数に返り値がないこと&lt;/strong&gt;です。Release モードでは GCC の新バージョンがより多くの最適化を行うため、元々明示的な返り値のない関数が実行中に予期せぬ動作を起こし、クラッシュを引き起こしています。結論として、&lt;strong&gt;コンパイラの警告を無視することは許されません。特に古いプロジェクトにおいては、一部の警告が無視されている可能性もありますが、すべての警告を遮断することは避けるべきです&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;環境説明&#34;&gt;環境説明
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;CentOS 7 GCCバージョン：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39)
Copyright © 2015 Free Software Foundation, Inc.
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CentOS 8 GCCバージョン：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-21)
Copyright (C) 2018 Free Software Foundation, Inc.
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;クラッシュ現象&#34;&gt;クラッシュ現象
&lt;/h3&gt;&lt;p&gt;プログラムクラッシュのスタックを解析した結果、以下のスタック情報が見られました。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[New LWP 1385902]
[Thread debugging using libthread_db enabled]
Using host libthread_db library &amp;quot;/lib64/libthread_db.so.1&amp;quot;.
Core was generated by `./pstack_main`.
Program terminated with signal SIGSEGV, Segmentation fault.
#0  0x00007ffe894b4420 in ?? ()
(gdb) bt
#0  0x00007ffe894b4420 in ?? ()
#1  0x00000000004008e9 in main ()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;このスタックは直感的ではなく、クラッシュした関数のスタック情報が「??」として表示されているため、問題の特定がより複雑になっています。&lt;/p&gt;
&lt;h3 id=&#34;コード例&#34;&gt;コード例
&lt;/h3&gt;&lt;p&gt;問題をより良く理解するために、クラッシュを再現する最小限のコード例を以下に示します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;map&amp;gt;

int test() {
    std::cout &amp;lt;&amp;lt; &amp;quot;1&amp;quot; &amp;lt;&amp;lt; std::endl;
}

int main() {
    test();
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;そのコードの &lt;code&gt;test()&lt;/code&gt; 関数は明らかに値を明示的に返していませんが、戻り値の型は &lt;code&gt;int&lt;/code&gt; です。C++ の仕様によると、関数が &lt;code&gt;int&lt;/code&gt; 型として宣言されている場合、必ず値を返す必要があり、そうしないと未定義の動作を引き起こす可能性があります。&lt;/p&gt;
&lt;h3 id=&#34;コンパイル警告&#34;&gt;コンパイル警告
&lt;/h3&gt;&lt;p&gt;私たちのプロジェクトでは、CMakeスクリプトによって多くのコンパイル時の警告が抑制されており、その中には以下の警告メッセージが含まれています。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;/root/pstack/main.cpp: In function ‘int test()’:
/root/pstack/main.cpp:7:1: warning: no return statement in function returning non-void [-Wreturn-type]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;この警告は、&lt;code&gt;test()&lt;/code&gt;関数が値を返していないことを示しており、これが問題の根本原因です。高度なバージョンのGCC（例えば8.5.0）は、コードを最適化する際に、このような未定義の振る舞いに不安定な最適化を行い、プログラムがクラッシュする可能性があります。&lt;/p&gt;
&lt;h3 id=&#34;アセンブリコードの差異&#34;&gt;アセンブリコードの差異
&lt;/h3&gt;&lt;p&gt;GCCコンパイラ最適化の動作の違いを説明するために、異なるバージョンのGCCが生成するアセンブリコードを比較しました。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;GCC 4.8.5 が生成したアセンブリコード：&lt;/p&gt;
&lt;p&gt;アセンブリコードは比較的冗長であり、標準出力ストリーム（例えば &lt;code&gt;std::cout&lt;/code&gt;）の処理ロジックも含まれています。これはコンパイラがより保守的な最適化を行ったことを示しており、&lt;code&gt;test()&lt;/code&gt; 関数における戻り値がない問題に対して過度な最適化を行わず、その結果、クラッシュを回避できた可能性があります。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GCC 8.5.0 が生成したアセンブリコード：&lt;/p&gt;
&lt;p&gt;新しいバージョンのGCCでは、より多くの最適化が行われ、コード量が削減されました。しかし、この最適化により、戻り値がない関数の実行時に動作が不安定になり、プログラムがクラッシュする可能性があります。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;結論&#34;&gt;結論
&lt;/h3&gt;&lt;p&gt;今回の問題の調査を通じて、C++ においては&lt;strong&gt;関数の戻り値が明確に定義されている必要がある&lt;/strong&gt;ということを深く認識しました。特に、関数を &lt;code&gt;int&lt;/code&gt; として宣言した場合、必ず戻り値を返す必要があります。古いバージョンのコンパイラを使用しているプロジェクトでは、新しいバージョンの GCC にアップグレードすると、より多くの最適化や厳格な警告メカニズムが発生する可能性があります。したがって、コンパイル時に&lt;strong&gt;すべての警告を無視するのではなく&lt;/strong&gt;、関数からの戻り値や型の一致など、一般的な問題を中心に選択的に処理することをお勧めします。&lt;/p&gt;
&lt;p&gt;最終、&lt;code&gt;test()&lt;/code&gt;関数に返り値を加えることで問題が解決し、プログラムは正常に動作するようになりました。&lt;/p&gt;</description>
        </item>
        <item>
        <title>VMware仮想マシンCPUリソース使用量異常</title>
        <link>https://ttf248.life/ja/p/vmware-virtual-machine-cpu-resource-usage-anomaly/</link>
        <pubDate>Sun, 10 Mar 2024 22:14:59 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/vmware-virtual-machine-cpu-resource-usage-anomaly/</guid>
        <description>&lt;p&gt;背景：ローカルマシンにWindows版の業務システムがデプロイされており、CPUリソースの使用率は約5％です。VMwareにインストールされたCentOS8にはLinux版の業務システムがデプロイされていますが、リソース使用量が異常です。&lt;/p&gt;
&lt;h2 id=&#34;問題の説明&#34;&gt;問題の説明
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;ホストマシン：Windows 10 エンタープライズ版&lt;/li&gt;
&lt;li&gt;vmware：17.5&lt;/li&gt;
&lt;li&gt;仮想マシン：CentOS 8&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;仮想マシンリソースの割り当ては&lt;code&gt;4C8GB&lt;/code&gt;、ビジネスシステムを起動します。ビジネスシステムは仮想マシンLinuxシステムにデプロイされており、仮想マシン内部のtopコマンドでシステムリソースの使用状況を確認すると、CPU使用率は高くありません。外側のWindowsシステムではタスクマネージャーでCPUリソースの使用率が高いことが確認され、プロセスを確認した結果、vmwareプロセスがCPUリソースを多く消費していることがわかりました。&lt;/p&gt;
&lt;p&gt;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+
|         Windows           |
|                           |
|   +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+  |
|   |      VMware        |  |
|   |      Program       |  |
|   +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+  |
|                           |
+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&lt;/p&gt;
&lt;h2 id=&#34;知識点&#34;&gt;知識点
&lt;/h2&gt;&lt;p&gt;この問題のトラブルシューティングは順調に進まず、原因が通常のビジネスシステムではなく、仮想マシン自体の問題にあったためです。どのようにして思考を通常のビジネスコードからシステム負荷へ、そして負荷データの異常からソフト割り込みへと、最後に重要なポイントである「VMware ソフト割り込みの効率に影響を与えるものは何か？」という点に絞り込むのか。本稿ではまず各知識点を解説し、最後に解決策を示します。&lt;/p&gt;
&lt;h3 id=&#34;hyper-v&#34;&gt;hyper-v
&lt;/h3&gt;&lt;p&gt;Windows オペレーティングシステムの仮想化技術は大きな変革を遂げました。Microsoft が WSL を初めてリリースした際、Hyper-V サービスを有効にすると VMware の仮想マシンを同時に使用できなくなりました。しかし、その後のバージョンでは、VMware は Hyper-V サービスとの互換性が得られるようになりました。&lt;/p&gt;
&lt;h3 id=&#34;システム負荷&#34;&gt;システム負荷
&lt;/h3&gt;&lt;p&gt;Linuxシステムにおいて、「ロード」（load）とは、実行中または実行待ちのプロセスの数を指します。ロードは通常、1分間、5分間、および15分間の実行キュー内の平均プロセス数を示す3つの数字で表されます。これらの数値は、「uptime」コマンドまたは「top」コマンドを実行することで確認できます。&lt;/p&gt;
&lt;p&gt;具体的には、この3つの数字はそれぞれ以下のものを表しています。&lt;/p&gt;
&lt;p&gt;1分間の負荷：システムが過去1分間実行キューにいたプロセスの平均数。
5分間の負荷：システムが過去5分間実行キューにいたプロセスの平均数。
15分間の負荷：システムが過去15分間実行キューに保持していたプロセスの平均数。&lt;/p&gt;
&lt;p&gt;負荷の定義は、システム内で実行待ちのプロセスの数です。この数がシステムの論理CPU数を超えると、システム負荷が高いことを示し、多くのプロセスがプロセッサリソースを待機していることを意味します。これにより、システムが遅くなったり、応答しなくなったりする可能性があります。その程度やシステムの構成・性能によって異なります。&lt;/p&gt;
&lt;p&gt;理想的には、負荷はシステムの論理 CPU 数範囲内に維持されるべきであり、そうすることでシステムのパフォーマンスが最適化されます。もし負荷が継続的に CPU 数を超えた場合、システム内のプロセスをさらに分析し、高負荷の原因となっているものを特定し、それに応じてシステムリソースの割り当てを調整したり、プロセスの実行方法を最適化する対策を講じる必要があるかもしれません。&lt;/p&gt;
&lt;h3 id=&#34;負荷解析-mpstat&#34;&gt;負荷解析 mpstat
&lt;/h3&gt;&lt;p&gt;&lt;code&gt;mpstat&lt;/code&gt; コマンドは、単一または複数のプロセッサに関する様々な情報、例えば平均負荷、CPU 使用率、割り込み、コンテキストスイッチなどを報告するために使用されます。&lt;code&gt;sysstat&lt;/code&gt; パッケージに含まれる &lt;code&gt;mpstat&lt;/code&gt; は、システムの負荷状況を分析するのに非常に役立つツールです。以下に &lt;code&gt;mpstat&lt;/code&gt; を用いた負荷分析の手順を示します。&lt;/p&gt;
&lt;p&gt;sysstat のインストール
もしあなたのシステムに&lt;code&gt;sysstat&lt;/code&gt;がインストールされていない場合は、あなたのシステムに適したパッケージ管理ツールを使ってインストールしてください。&lt;/p&gt;
&lt;p&gt;mpstatを実行する。
&lt;code&gt;mpstat&lt;/code&gt; コマンドを使用して、CPU の使用状況と負荷を確認します。デフォルトでは、&lt;code&gt;mpstat&lt;/code&gt; は CPU 使用率の平均値を毎秒表示します。出力頻度は、時間間隔を指定することで調整できます。例えば、&lt;code&gt;mpstat&lt;/code&gt; を毎秒実行するには、次のコマンドを使用します: &lt;code&gt;mpstat -P ALL 2&lt;/code&gt; 、&lt;code&gt;irq&lt;/code&gt; はリソース使用状況を示します。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```shell
01:32:33 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
01:32:35 PM  all    0.00    0.00    0.26    0.00    3.73    0.26    0.00    0.00    0.00   95.76
01:32:35 PM    0    0.00    0.00    0.51    0.00    3.57    0.00    0.00    0.00    0.00   95.92
01:32:35 PM    1    0.00    0.00    0.00    0.00    3.59    0.51    0.00    0.00    0.00   95.90
01:32:35 PM    2    0.00    0.00    0.00    0.00    4.15    0.00    0.00    0.00    0.00   95.85
01:32:35 PM    3    0.00    0.00    0.52    0.00    3.61    0.52    0.00    0.00    0.00   95.36
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;分析出力：
mpstat の出力には、各 CPU の使用率とシステムの平均負荷が含まれています。平均負荷と各 CPU の使用率に特に注意を払うことで、システムの負荷状況を把握できます。負荷が高い場合は、どのプロセスが原因であるかをさらに分析し、パフォーマンスのボトルネックが存在するかどうかを確認できます。&lt;/p&gt;
&lt;p&gt;他のツールとの連携：
&lt;code&gt;mpstat&lt;/code&gt; 以外にも、&lt;code&gt;sar&lt;/code&gt;、&lt;code&gt;pidstat&lt;/code&gt;、&lt;code&gt;iostat&lt;/code&gt; などのツールを使用してシステムパフォーマンスを総合的に分析できます。複数のツールの出力を組み合わせることで、システムの負荷状況をより包括的に把握し、パフォーマンス問題の根本原因を見つけることができます。&lt;/p&gt;
&lt;h3 id=&#34;中断&#34;&gt;中断
&lt;/h3&gt;&lt;p&gt;ここでは内容を詳しく説明することは省略します。
推奨：&lt;a class=&#34;link&#34; href=&#34;https://www.codedump.info/post/20200522-sgfap-softirq/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;アプリケーション開発者向けシステムガイド CPU編 ソフトウェア割り込み&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;頻繁なソフト割り込みの発生も、システム負荷に現れます。&lt;/p&gt;
&lt;h2 id=&#34;問題の切り分け&#34;&gt;問題の切り分け
&lt;/h2&gt;&lt;p&gt;CPUの観点だけで問題を特定できない場合、システムに異常が発生しているのではないかと疑うべきでしょうか？ Linuxオペレーティングシステムの負荷が高すぎて、VMwareが過剰なCPUリソースを消費している可能性があります。 &lt;code&gt;mpstat&lt;/code&gt;を使用してローカル仮想マシンを分析した結果、&lt;code&gt;irq&lt;/code&gt;の使用率が異常で、単核は約25%です。正常時には、ビジネスプロセスを開始してもアイドル状態の時、&lt;code&gt;irq&lt;/code&gt;の割合は通常約5%であるべきです。&lt;/p&gt;
&lt;p&gt;グループ内の同僚の開発環境では、彼のCentOS 7はVMware上にデプロイされており、リソース使用量は正常に表示されています。一方、上海の開発環境でも同様にVMwareですが、ホストマシンのCPUリソース状況を直接観察することができません。このとき、私たちはVMware仮想マシン、Linuxオペレーティングシステム、そしてGCCバージョンという複数の変数に直面しています。&lt;/p&gt;
&lt;p&gt;転換してテスト環境を分析すると、深センのテスト環境は物理マシン上にデプロイされており、古いバージョンのGCCコンパイルサービスが稼働しており、CentOS 8上で動作している。興味深いことに、深セン環境では&lt;code&gt;irq&lt;/code&gt;の使用状況は正常である。&lt;/p&gt;
&lt;p&gt;問題の切り分けのため、より新しいバージョンの GCC でコンパイルしたプログラムを深セン環境にデプロイしてテストした結果、すべて正常でした。&lt;/p&gt;
&lt;p&gt;問題はより明確になりつつあり、オペレーティングシステムに問題があるのではないかと疑い始めています。結局のところ、CentOS 8 は公式サポートが終了しているのです。しかし、クリーンな CentOS 7 と CentOS 8 を再デプロイしても、問題は依然として存在します。&lt;/p&gt;
&lt;p&gt;今のところ、唯一の不確定要素であるVMware仮想マシンソフトウェアを疑い始めています。すると突然、Hyper-V技術が頭に浮かびました。以前にHyper-Vが有効になっていて、完全にシャットダウンされなかったために、このような問題が発生したのでしょうか？結局のところ、ソフト割り込みも仮想マシンソフトウェアによって実現されています。異なる仮想化技術にバグは存在しないのでしょうか？これらの問題は深く考察し、調査する価値があります。&lt;/p&gt;
&lt;h2 id=&#34;結論&#34;&gt;結論
&lt;/h2&gt;&lt;p&gt;マイクロソフトの公式マニュアルによると、ローカルのHyper-Vサービスを完全にシャットダウンしたところ、VMwareがホスト上で正常に復旧しました。これで問題はついに解決しました。当初から述べたように、この経験は紆余曲折し、包括的な分析と判断が必要でした。これも初めて問題をトラブルシューティングし、仮想マシンレベルまで特定することになった事例です。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Disable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V-Hypervisor
bcdedit /set hypervisorlaunchtype off
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/troubleshoot/windows-client/application-management/virtualization-apps-not-work-with-hyper-v&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://learn.microsoft.com/zh-cn/troubleshoot/windows-client/application-management/virtualization-apps-not-work-with-hyper-v&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>C&#43;&#43;プログラミングの落とし穴：`std::map` の誤った使用によるプログラムクラッシュの詳細解説</title>
        <link>https://ttf248.life/ja/p/cpp-programming-traps-std-map-crash-details/</link>
        <pubDate>Sun, 10 Mar 2024 22:03:06 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/cpp-programming-traps-std-map-crash-details/</guid>
        <description>&lt;p&gt;C++プログラミングにおいて、&lt;code&gt;std::map&lt;/code&gt;コンテナの誤った使用がプログラムをクラッシュさせる可能性があることを明らかにすることを目的としています。角括弧演算子で存在しないキーにアクセスしようとすると、自動的に空要素が追加されます。この誤解について深く分析し、サンプルコードを通じて潜在的なリスクを示します。&lt;/p&gt;
&lt;p&gt;単純な値を格納する分には問題ありませんが、ポインタを格納すると問題が発生します。ポインタはアドレスであり、初期化されていない場合、そのアドレスは未確定となり、プログラムのクラッシュにつながる可能性があります。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文
&lt;/h2&gt;&lt;p&gt;C++標準ライブラリにおいて、&lt;code&gt;std::map&lt;/code&gt;は関連コンテナであり、キーによる昇順に要素を格納し、効率的なキーワード検索機能を提供します。しかし、初心者開発者は、&lt;code&gt;std::map&lt;/code&gt;の角括弧演算子 &lt;code&gt;[]&lt;/code&gt; の動作に関する理解違いから苦労することがあります。実際には、&lt;code&gt;[]&lt;/code&gt;を使って存在しないキーにアクセスすると、&lt;code&gt;std::map&lt;/code&gt;は新しいキーと値のペアを挿入し、デフォルトコンストラクタを使用してそのキーに対応する値の型を初期化します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;map&amp;gt;

int main() {
    std::map&amp;lt;std::string, int&amp;gt; myMap;
    
    // 错误的用法：假设这里试图访问一个不存在的键并认为会得到0
    std::cout &amp;lt;&amp;lt; &amp;quot;Value for &#39;nonexistent_key&#39;: &amp;quot; &amp;lt;&amp;lt; myMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;

    // 实际上，上述行代码创建了一个新的键值对，其中值被默认初始化为int的默认值（通常是0）
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上記のコードはプログラムを直接クラッシュさせることはありませんが、このような暗黙的な挿入処理は、リソースリークや予期しない状態変化といった副作用を引き起こす可能性があります。さらに悪いことに、マルチスレッド環境で未初期化のメモリ領域に同時にアクセスすると、プログラムがクラッシュする可能性もあります。&lt;/p&gt;
&lt;p&gt;そのような問題を防ぐために、&lt;code&gt;std::map::find()&lt;/code&gt;または&lt;code&gt;std::map::count()&lt;/code&gt;メソッドを使用してキーの存在を確認するか、&lt;code&gt;std::map::insert()&lt;/code&gt;メソッドを用いて明示的に要素を挿入することを推奨します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;std::map&amp;lt;std::string, int&amp;gt; safeMap;
if (safeMap.count(&amp;quot;nonexistent_key&amp;quot;) == 0) {
    std::cout &amp;lt;&amp;lt; &amp;quot;Key does not exist.&amp;quot; &amp;lt;&amp;lt; std::endl;
} else {
    std::cout &amp;lt;&amp;lt; &amp;quot;Value for existing key: &amp;quot; &amp;lt;&amp;lt; safeMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;
}

// 或者明确插入一个键值对，指定初始值
safeMap.insert({ &amp;quot;new_key&amp;quot;, 0 });
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;もしmapコンテナ内にポインタ型のオブジェクトが格納されている場合、要素を自動的に挿入すると初期化されていないポインタが保存され、そのポインタに対するいかなる操作もプログラムのクラッシュにつながる可能性があります。&lt;/p&gt;</description>
        </item>
        <item>
        <title>pstackでプロセスフリーズを調査</title>
        <link>https://ttf248.life/ja/p/pstack-troubleshooting-process-hang/</link>
        <pubDate>Sat, 24 Feb 2024 23:55:59 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/pstack-troubleshooting-process-hang/</guid>
        <description>&lt;p&gt;ソフトウェア開発と運用において、プロセスがフリーズする状況に遭遇することがよくあります。この状況はシステムパフォーマンスの低下やサービス停止を引き起こす可能性があります。本稿では、pstackツールを使用してプロセスフリーズの問題をトラブルシューティングする方法について説明します。プロセスのスタック情報を分析することで、問題の原因を特定し解決します。&lt;/p&gt;
&lt;p&gt;風控システムの子サービスがフリーズし、風控サービスが利用できなくなった。サービス可用性の監視が不足していたため、プロセスのフリーズをタイムリーに発見できず、システムが利用不能となった。&lt;/p&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文
&lt;/h2&gt;&lt;p&gt;プロセスが応答しなくなる現象を「プロセスデッドロック」と呼びます。これは、プロセスが終了することなく停止した状態です。この状況は、デッドロック、リソース枯渇、例外など、さまざまな原因によって引き起こされる可能性があります。このような問題を解決するために、pstackツールを使用してプロセスのスタック情報を分析し、問題の根本原因を特定することができます。&lt;/p&gt;
&lt;h2 id=&#34;手順&#34;&gt;手順
&lt;/h2&gt;&lt;p&gt;pstack は、よく使われるツールで、通常は gdb (GNU デバッガー) と一緒に提供されます。以下のコマンドでインストールできます:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt-get install gdb
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;プロセスIDの取得：まず、スリープ状態のプロセスのプロセスID（PID）を取得する必要があります。psコマンドを使用してすべてのプロセスをリストし、調査対象のプロセスIDを見つけます。
pstack ツールを使用してプロセススタックを分析します。プロセス ID を取得したら、pstack ツールを使用してそのプロセスのスタック情報を取得できます。以下のコマンドを実行してください:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pstack &amp;lt;PID&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;このプロセスが実行している関数呼び出しシーケンスを表示し、スタック情報を出力します。これらの情報から、プロセスの停止位置を特定し、問題の箇所を突き止めることができます。&lt;/p&gt;
&lt;p&gt;スタック情報を解析することで、プロセスの応答なしの原因を特定できます。デッドロック、無限ループ、その他の異常な状況が発見される可能性があります。具体的な状況に応じて、ロックの解放やコードロジックの修正などの適切な対策を講じてください。&lt;/p&gt;
&lt;h2 id=&#34;事例&#34;&gt;事例
&lt;/h2&gt;&lt;p&gt;シンプルなデモで、メイン関数が起動した後、新しいスレッドを作成し、実際の実行関数に入ると無限ループに陥り、プログラムが正常に終了せず、フリーズした状態になります。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cmake_minimum_required(VERSION 3.0.0)
project(pstack_main VERSION 0.1.0 LANGUAGES C CXX)

include(CTest)
enable_testing()

# 查找线程库
find_package(Threads REQUIRED)

add_executable(pstack_main main.cpp)

# 链接线程库
target_link_libraries(pstack_main PRIVATE Threads::Threads)

set(CPACK_PROJECT_NAME ${PROJECT_NAME})
set(CPACK_PROJECT_VERSION ${PROJECT_VERSION})
include(CPack)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;thread&amp;gt;
#include &amp;lt;chrono&amp;gt;

void infiniteLoop() {
    while (true) {
        // 主线程进入死循环
    }
}

int main() {
    std::thread thread(infiniteLoop); // 创建一个线程，执行死循环函数
    thread.join(); // 等待线程结束
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;プログラムを開始し、pstack の結果を実行します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Thread 2 (Thread 0x7eff3619b700 (LWP 1315017)):
#0  infiniteLoop () at /root/pstack/main.cpp:6
#1  0x0000000000402ca9 in std::__invoke_impl&amp;lt;void, void (*)()&amp;gt; (__f=@0x2260eb8: 0x4029a6 &amp;lt;infiniteLoop()&amp;gt;) at /usr/include/c++/8/bits/invoke.h:60
#2  0x0000000000402b02 in std::__invoke&amp;lt;void (*)()&amp;gt; (__fn=@0x2260eb8: 0x4029a6 &amp;lt;infiniteLoop()&amp;gt;) at /usr/include/c++/8/bits/invoke.h:95
#3  0x0000000000403150 in std::thread::_Invoker&amp;lt;std::tuple&amp;lt;void (*)()&amp;gt; &amp;gt;::_M_invoke&amp;lt;0ul&amp;gt; (this=0x2260eb8) at /usr/include/c++/8/thread:244
#4  0x0000000000403126 in std::thread::_Invoker&amp;lt;std::tuple&amp;lt;void (*)()&amp;gt; &amp;gt;::operator() (this=0x2260eb8) at /usr/include/c++/8/thread:253
#5  0x000000000040310a in std::thread::_State_impl&amp;lt;std::thread::_Invoker&amp;lt;std::tuple&amp;lt;void (*)()&amp;gt; &amp;gt; &amp;gt;::_M_run (this=0x2260eb0) at /usr/include/c++/8/thread:196
#6  0x00007eff36bceb23 in execute_native_thread_routine () from /lib64/libstdc++.so.6
#7  0x00007eff36ea91ca in start_thread () from /lib64/libpthread.so.0
#8  0x00007eff361d58d3 in clone () from /lib64/libc.so.6
Thread 1 (Thread 0x7eff372e1740 (LWP 1315016)):
#0  0x00007eff36eaa6cd in __pthread_timedjoin_ex () from /lib64/libpthread.so.0
#1  0x00007eff36bceda7 in std::thread::join() () from /lib64/libstdc++.so.6
#2  0x00000000004029d2 in main () at /root/pstack/main.cpp:13
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;確認すると、プロセスのフリーズの原因は無限ループです。メインスレッドが無限ループに入り、サブスレッドが終了できず、結果としてプロセスがフリーズします。&lt;/p&gt;</description>
        </item>
        <item>
        <title>C&#43;&#43;関数呼び出しにかかる時間</title>
        <link>https://ttf248.life/ja/p/cpp-function-call-timing/</link>
        <pubDate>Wed, 24 Jan 2024 14:11:33 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/cpp-function-call-timing/</guid>
        <description>&lt;p&gt;設計のSDKについて、様々なコールバック関数の実装方法で、時間のかかるテストを実施しました。最近はC++の関数プログラミングを見ており、関数がファーストクラスオブジェクトとなり、プログラム内で流通すると、パフォーマンスに違いはありますか？&lt;/p&gt;
&lt;p&gt;先行記事へのリンク：[コンパイラ、コールバック関数、パフォーマンステスト]({&amp;lt; relref &amp;ldquo;/post/2023/02-15-コンパイラ、コールバック関数、パフォーマンステスト&amp;rdquo; &amp;gt;}})&lt;/p&gt;
&lt;p&gt;雷冒大佬正好也做了类似测试，借了代码来用。&lt;/p&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文
&lt;/h2&gt;&lt;p&gt;実行プラットフォームは、引き続き弊社の旧友である &lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt; です。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;cassert&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;functional&amp;gt;
#include &amp;lt;iostream&amp;gt;
#include &amp;lt;vector&amp;gt;

int add_one(int input) { return input + 1; }

bool validate_vector_add_one(std::vector&amp;lt;int&amp;gt; const&amp;amp; input_vector,
                             std::vector&amp;lt;int&amp;gt; const&amp;amp; output_vector)
{
    bool is_valid{true};
    for (size_t i{0}; i &amp;lt; input_vector.size(); ++i)
    {
        if (output_vector.at(i) != input_vector.at(i) + 1)
        {
            is_valid = false;
            break;
        }
    }
    return is_valid;
}

void reset_vector(std::vector&amp;lt;int&amp;gt;&amp;amp; input_vector)
{
    for (size_t i{0}; i &amp;lt; input_vector.size(); ++i)
    {
        input_vector.at(i) = 0;
    }
}

template &amp;lt;typename T, typename Func&amp;gt;
void unitary_function_pass_by_lambda_function(T&amp;amp; output, T const&amp;amp; input,
                                              Func const func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_std_function_value(T&amp;amp; output, T const&amp;amp; input,
                                                 std::function&amp;lt;T(T)&amp;gt; const func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_std_function_reference(
    T&amp;amp; output, T const&amp;amp; input, std::function&amp;lt;T(T)&amp;gt; const&amp;amp; func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_function_pointer(T&amp;amp; output, T const&amp;amp; input,
                                               T (*func)(T))
{
    output = func(input);
}

int main()
{
    // Set floating point format std::cout with 3 decimal places.
    std::cout.precision(3);

    size_t const num_elements{10000000};
    std::vector&amp;lt;int&amp;gt; input_vector(num_elements, 0);
    std::vector&amp;lt;int&amp;gt; output_vector(num_elements, 0);

    auto const lambda_function_add_one{[](int const&amp;amp; input) -&amp;gt; int
                                       { return input + 1; }};
    std::function&amp;lt;int(int)&amp;gt; const std_function_add_one{lambda_function_add_one};

    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a function pointer: &amp;quot; &amp;lt;&amp;lt; sizeof(&amp;amp;add_one)
              &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a std::function pointer: &amp;quot;
              &amp;lt;&amp;lt; sizeof(&amp;amp;std_function_add_one) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a std::function: &amp;quot; &amp;lt;&amp;lt; sizeof(std_function_add_one)
              &amp;lt;&amp;lt; std::endl;

    // Call function frequently in a vanilla way.
    // The compiler knows what function to call at compile time and can optimize
    // the code.
    // This is the best performance we could get.
    std::chrono::steady_clock::time_point const time_start_vanilla{
        std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        output_vector.at(i) = add_one(input_vector.at(i));
    }
    std::chrono::steady_clock::time_point const time_end_vanilla{
        std::chrono::steady_clock::now()};
    auto const time_elapsed_vanilla{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(time_end_vanilla -
                                                             time_start_vanilla)
            .count()};
    float const latency_vanilla{time_elapsed_vanilla /
                                static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass Vanilla: &amp;quot; &amp;lt;&amp;lt; latency_vanilla &amp;lt;&amp;lt; &amp;quot; ns&amp;quot;
              &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // Sometimes, we don&#39;t know what function to call at compile time.
    // We can use std::function to pass a function as an argument.
    // In this case, we pass the std::function by value.
    // Because the size of a std::function is 32 bytes, passing by value
    // results in a lot of copying and bad performance.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_std_function_value{std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_std_function_value(
            output_vector.at(i), input_vector.at(i), std_function_add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_std_function_value{std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_std_function_value{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_std_function_value -
            time_start_pass_by_std_function_value)
            .count()};
    float const latency_pass_by_std_function_value{
        time_elapsed_pass_by_std_function_value /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Std Function Value: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_std_function_value &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // Instead of passing the std::function by value, we can pass it by
    // reference (pointer). In this case, object copying is eliminated. The
    // performance is better than passing the std::function by value. However,
    // the performance is still not as good as the vanilla way.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_std_function_reference{
            std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_std_function_reference(
            output_vector.at(i), input_vector.at(i), std_function_add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_std_function_reference{
            std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_std_function_reference{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_std_function_reference -
            time_start_pass_by_std_function_reference)
            .count()};
    float const latency_pass_by_std_function_reference{
        time_elapsed_pass_by_std_function_reference /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Std Function Reference: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_std_function_reference &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // std::function is a general purpose wrapper for function pointers,
    // callable objects, and lambda functions. Because it&#39;s general purpose,
    // it&#39;s not as efficient as a function pointer. In this case, we pass a
    // function pointer to a function. The performance is better than passing
    // the std::function by reference.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_function_pointer{std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_function_pointer(output_vector.at(i),
                                                  input_vector.at(i), &amp;amp;add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_function_pointer{std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_function_pointer{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_function_pointer -
            time_start_pass_by_function_pointer)
            .count()};
    float const latency_pass_by_function_pointer{
        time_elapsed_pass_by_function_pointer /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Function Pointer: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_function_pointer &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // We can also pass a lambda function to a function.
    // The compiler knows what function to call at compile time and can optimize
    // the code. The performance is also better than passing the std::function
    // by reference.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_lambda_function{std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_lambda_function(
            output_vector.at(i), input_vector.at(i), lambda_function_add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_lambda_function{std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_lambda_function{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_lambda_function -
            time_start_pass_by_lambda_function)
            .count()};
    float const latency_pass_by_lambda_function{
        time_elapsed_pass_by_lambda_function /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Lambda Function: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_lambda_function &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 组里常规也就开启 O2 优化，编译选用了 gcc13，不同版本的 gcc 性能耗时略有不同，版本越高 lambda 效果越好
The size of a function pointer: 8
The size of a std::function pointer: 8
The size of a std::function: 32
Latency Pass Vanilla: 0.418 ns
Latency Pass By Std Function Value: 3.47 ns
Latency Pass By Std Function Reference: 1.36 ns
Latency Pass By Function Pointer: 0.396 ns
Latency Pass By Lambda Function: 0.44 ns
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;参照資料&#34;&gt;参照資料
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leimao.github.io/blog/CPP-Function-Call-Performance/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://leimao.github.io/blog/CPP-Function-Call-Performance/&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>プログラムがデバッグを回避する方法</title>
        <link>https://ttf248.life/ja/p/program-how-to-anti-debug/</link>
        <pubDate>Tue, 23 Jan 2024 19:46:36 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/program-how-to-anti-debug/</guid>
        <description>&lt;p&gt;ふと思いついて、新しい壁紙を探してみることに。普段は黒系のシリーズを使っているから、一部の領域にカラフルなものを配置し、デスクトップにはアイコンを置きたい。他の配色で壁紙にすると、アイコンがぼやけてしまうだろう。&lt;/p&gt;
&lt;p&gt;上のアセンブリコードをしばらく考えてみたけど、理解できない。AIに頼んでみると、命令は説明してくれたものの、状況の説明はない。これは必ず特定の状況で使われる命令だろう。通常のコードではありえない。&lt;/p&gt;
&lt;p&gt;AIは今のところ検索エンジンに劣りますね、アセンブリ言語の知識が足りていないからです。&lt;/p&gt;
&lt;h2 id=&#34;壁紙&#34;&gt;壁紙
&lt;/h2&gt;&lt;p&gt;黒色の集合壁紙&lt;/p&gt;
&lt;h2 id=&#34;アセンブリコード&#34;&gt;アセンブリコード
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;PUSHFD
MOV DWORD PTR [ESP],0X100
POPFD
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;現実的な応用シーン&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;bool IsDebugged()
{
    __try
    {
        __asm
        {
            pushfd
            mov dword ptr [esp], 0x100
            popfd
            nop
        }
        return true;
    }
    __except(GetExceptionCode() == EXCEPTION_SINGLE_STEP
        ? EXCEPTION_EXECUTE_HANDLER
        : EXCEPTION_CONTINUE_EXECUTION)
    {
        return false;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;説明&#34;&gt;説明
&lt;/h2&gt;&lt;p&gt;TrapFlagは、フラグレジスタ内のフラグであり、このフラグが設定されると例外SINGLE_STEPが発生します。もしコードをトレースしている場合、デバッガによってこのフラグはクリアされるため、この例外を見ることができません。&lt;/p&gt;
&lt;p&gt;実際のテストでは、検出デバッグの関数をステップオーバーで通過すると、デバッグが検出されないことがわかった。検出関数を実行する際にステップインした場合のみ検出される。(資料調査、未検証)&lt;/p&gt;
&lt;h2 id=&#34;参照資料&#34;&gt;参照資料
&lt;/h2&gt;&lt;p&gt;関連資料は、ウェブサイトの英語版を翻訳したもので、サイトでは様々なデバッグ対策技術が解説されています。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://anti-debug.checkpoint.com/techniques/assembly.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://anti-debug.checkpoint.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://song-10.gitee.io/2021/08/08/Reverse-2021-08-08-anti-debug/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://song-10.gitee.io/2021/08/08/Reverse-2021-08-08-anti-debug/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>焦点インタビュー/CCTVビデオファイルのダウンロード方法</title>
        <link>https://ttf248.life/ja/p/how-to-download-focus-interview-cctv-video-files/</link>
        <pubDate>Tue, 23 Jan 2024 19:23:35 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/how-to-download-focus-interview-cctv-video-files/</guid>
        <description>&lt;p&gt;最近、誰かが「焦点訪談の動画をダウンロードするにはどうすればいいか」と問い合わせてきた。頭の中で十に八九はまた &lt;code&gt;m3u8&lt;/code&gt; の形式で暗号化されているのだろうと考えていたので、簡単に処理してみた。&lt;/p&gt;
&lt;h2 id=&#34;ダウンローダー&#34;&gt;ダウンローダー
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/nilaoda/N_m3u8DL-CLI&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/nilaoda/N_m3u8DL-CLI&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;m3u8 ダウンローダー。オープンソースのコマンドライン m3u8/HLS/dash ダウンローダーで、標準的な AES-128-CBC 復号化、マルチスレッド、カスタムリクエストヘッダなどをサポートします。簡体中文、繁体中文、英語をサポートしています。English Supported&lt;/p&gt;
&lt;h2 id=&#34;ブラウザ拡張機能&#34;&gt;ブラウザ拡張機能
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://microsoftedge.microsoft.com/addons/detail/ngjclnbcdbahekojpkhancmiobdahemb&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Live Stream Downloader&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;蜜に浸した自信&#34;&gt;蜜に浸した自信
&lt;/h2&gt;&lt;p&gt;住所の情報を入手したと思ったのに、結局何も解決せず、セグメントの内容を正常に解析できず。資料を確認すると、公式側でダウンロードアドレスが処理されていることがわかり、プラグインから解析された&lt;code&gt;key&lt;/code&gt;を手動で下のリンクにコピー＆リプレースする必要がある。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;https://newcntv.qcloudcdn.com/asp/hls/2000/0303000a/3/default/***********************/2000.m3u8
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;2024年1月まで、住所テストは有効です。その後の変更については、ご自身でウェブページを解析してください。&lt;/p&gt;
&lt;p&gt;過去のアドレスのバックアップ：&lt;code&gt;https://hlswx.cntv.kcdnvip.com/asp/hls/main/0303000a/3/default/一連の文字/main.m3u8?maxbr=2000&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;参照資料&#34;&gt;参照資料
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://jln.cn/post/517.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://jln.cn/post/517.html&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>一括でSQL Serverデータベースディスクファイル権限を変更する</title>
        <link>https://ttf248.life/ja/p/bulk-modify-sqlserver-database-disk-file-permissions/</link>
        <pubDate>Tue, 23 Jan 2024 19:06:36 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/bulk-modify-sqlserver-database-disk-file-permissions/</guid>
        <description>&lt;p&gt;会社のセキュリティポリシー変更により、&lt;code&gt;機械師mini&lt;/code&gt;は結局、バックアップサーバーとして自宅へ移設され、マシンシステムを再インストールしました。&lt;code&gt;Ubuntu&lt;/code&gt;から&lt;code&gt;Windows Server&lt;/code&gt;に移行しましたが、認証の方法が正規ではないため、自宅で使用する分には認証なしでも問題なさそうです。&lt;/p&gt;
&lt;p&gt;非正規品による起動で、Microsoftの検出がトリガーされました（半月ほど正常に動作していました）。サーバーを起動して1時間後に自動的にシャットダウンされ、システムログを確認したところ、違法コピーが原因であることがわかりました。&lt;/p&gt;
&lt;p&gt;どうにもならない、再度OSを入れ直すしかない。&lt;code&gt;SqlServer&lt;/code&gt;も再インストールが必要になりそう。毎回面倒くさいことになり、ファイル権限の管理が厳しすぎて、データベースを正常にアタッチできない。&lt;/p&gt;
&lt;h2 id=&#34;エラーメッセージ&#34;&gt;エラーメッセージ
&lt;/h2&gt;&lt;p&gt;システムを再インストールした後、&lt;code&gt;SqlServer&lt;/code&gt;がデータベースの追加時に5120エラーやオペレーティングシステムのアクセス拒否が発生する可能性があります。&lt;/p&gt;
&lt;h2 id=&#34;スクリプト処理&#34;&gt;スクリプト処理
&lt;/h2&gt;&lt;p&gt;前の関連記事：&lt;a class=&#34;link&#34; href=&#34;https://ttf248.life/ja/p/bulk-update-local-git-repository-and-legacy-permission-issues/&#34; &gt;ローカルGitリポジトリの一括更新&lt;/a&gt;。またこの馴染み深いスクリプトですが、改造してフォルダをトラバースしながらファイルの権限を変更します。現在、完全に編集する権限を持っています。&lt;/p&gt;
&lt;p&gt;オンラインのチュートリアルはほとんどが手動での修正を求めてくるけど、彼らは毎回数ファイルしか変更しないの？私は毎回大量のファイルを処理しなければならないし、全部手動でやるから精神が疲弊する。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$currentUserName = [System.Security.Principal.WindowsIdentity]::GetCurrent().Name
[Console]::OutputEncoding = [System.Text.Encoding]::UTF8
$rootDirectory = &amp;quot;D:\data\2013_RujiaInfo&amp;quot;

Get-ChildItem -Path $rootDirectory -Recurse | ForEach-Object {
    $itemPath = $_.FullName

    if ($_ -is [System.IO.DirectoryInfo]) {
        $icaclsResult = icacls $itemPath /setowner &amp;quot;$currentUserName&amp;quot; 2&amp;gt;&amp;amp;1
        if ($LASTEXITCODE -eq 0) {
            Write-Host &amp;quot;已更改文件夹 $itemPath 的所有者为 $currentUserName&amp;quot;
            # 授予当前用户写入权限
            Invoke-Expression &amp;quot;icacls `&amp;quot;$itemPath`&amp;quot; /grant `&amp;quot;$($currentUserName):(OI)(CI)F`&amp;quot;&amp;quot;
            Write-Host &amp;quot;已授予 $currentUserName 编辑文件夹的权限&amp;quot;
        } else {
            Write-Host &amp;quot;无法更改文件夹 $itemPath 的所有者。错误信息: $icaclsResult&amp;quot;
        }
    } else {
        $takeownResult = icacls $itemPath /setowner &amp;quot;$currentUserName&amp;quot; 2&amp;gt;&amp;amp;1
        if ($LASTEXITCODE -eq 0) {
            # 授予当前用户写入权限
            Invoke-Expression &amp;quot;icacls `&amp;quot;$itemPath`&amp;quot; /grant `&amp;quot;$($currentUserName):(F)`&amp;quot;&amp;quot;
            Write-Host &amp;quot;已授予 $currentUserName 编辑文件的权限&amp;quot;
        } else {
            Write-Host &amp;quot;无法更改文件 $itemPath 的所有者。错误信息: $takeownResult&amp;quot;
        }
    }
}

&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Linuxシステムベンチマークテスト</title>
        <link>https://ttf248.life/ja/p/linux-system-benchmark-test/</link>
        <pubDate>Tue, 09 Jan 2024 10:56:23 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/linux-system-benchmark-test/</guid>
        <description>&lt;p&gt;ウィンドウズプラットフォームには、魯大师（ユーエンターマスター）というソフトがあります。データが正確とは言えませんが、まあ参考程度にはなるでしょう。もちろん、他のプロフェッショナルなベンチマークソフトもあります。Linuxシステムでは、特によく合うベンチマークソフトにまだ出会っていません。&lt;/p&gt;
&lt;p&gt;Sysbenchは、CPU、メモリ、ファイルI/O、スレッドパフォーマンスなどをテストできる多機能なベンチマークツールです。さまざまなパフォーマンス・テストのタスクを実行するためにsysbenchを使用できます。&lt;/p&gt;
&lt;p&gt;現在、テスト用にちょうど3つの機械があります：メカニストミニローカルホスト、アリババクラウド開発雲サーバー、ファーウェイクラウド開発サーバー。&lt;/p&gt;
&lt;h2 id=&#34;sysbenchのインストール&#34;&gt;Sysbenchのインストール
&lt;/h2&gt;&lt;p&gt;ほとんどのLinuxディストリビューションでは、パッケージマネージャーを使用してSysbenchをインストールできます。例えば、CentOS 8では、以下のコマンドでインストールできます。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo dnf install sysbench
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;sysbenchの使用例&#34;&gt;Sysbenchの使用例
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;CPU性能テスト：&lt;code&gt;sysbench --test=cpu run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;メモリ読み取りパフォーマンスのテスト：&lt;code&gt;sysbench --test=memory run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;テストファイルI/Oパフォーマンス：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sysbench --test=fileio --file-test-mode=rndrw prepare
sysbench --test=fileio --file-test-mode=rndrw run
sysbench --test=fileio --file-test-mode=rndrw cleanup
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;マルチスレッドパフォーマンスのテスト: &lt;code&gt;sysbench --test=threads --num-threads=4 run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;MySQLデータベースのパフォーマンスをテストする（データベースの最大接続数を調整する必要があります）。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword --oltp-table-size=1000000 prepare
sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword --max-time=60 --oltp-read-only=off --oltp-test-mode=complex --max-requests=0 run
sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword cleanup
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;データ分散報告&#34;&gt;データ分散報告
&lt;/h2&gt;&lt;meta http-equiv=&#34;Content-Type&#34; content=&#34;text/html; charset=utf-8&#34;&gt;&lt;link type=&#34;text/css&#34; rel=&#34;stylesheet&#34; href=&#34;resources/sheet.css&#34; &gt;
&lt;style type=&#34;text/css&#34;&gt;.ritz .waffle a { color: inherit; }.ritz .waffle .s0{background-color:#ffffff;text-align:left;color:#000000;font-family:&#39;Arial&#39;;font-size:10pt;vertical-align:bottom;white-space:nowrap;direction:ltr;padding:2px 3px 2px 3px;}&lt;/style&gt;&lt;div class=&#34;ritz grid-container&#34; dir=&#34;ltr&#34;&gt;&lt;table class=&#34;waffle&#34; cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th class=&#34;row-header freezebar-origin-ltr&#34;&gt;&lt;/th&gt;&lt;th id=&#34;0C0&#34; style=&#34;width:100px;&#34; class=&#34;column-headers-background&#34;&gt;A&lt;/th&gt;&lt;th id=&#34;0C1&#34; style=&#34;width:421px;&#34; class=&#34;column-headers-background&#34;&gt;B&lt;/th&gt;&lt;th id=&#34;0C2&#34; style=&#34;width:398px;&#34; class=&#34;column-headers-background&#34;&gt;C&lt;/th&gt;&lt;th id=&#34;0C3&#34; style=&#34;width:422px;&#34; class=&#34;column-headers-background&#34;&gt;D&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R0&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;1&lt;/div&gt;&lt;/th&gt;&lt;td&gt;&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;本地机械师&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;阿里云&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;华为云&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R1&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;2&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;系统配置&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Information&lt;br&gt;  Operating System              Ubuntu 23.04&lt;br&gt;  Kernel                        Linux 6.2.0-36-generic x86_64&lt;br&gt;  Model                         Machenike Machenike DT Computer&lt;br&gt;  Motherboard                   Machenike Machenike DT Computer&lt;br&gt;  BIOS                          American Megatrends International, LLC.&lt;br&gt;DB19V012&lt;br&gt;&lt;br&gt;CPU Information&lt;br&gt;  Name                          Intel Core i7-12650H&lt;br&gt;  Topology                      1 Processor, 10 Cores, 16 Threads&lt;br&gt;  Identifier                    GenuineIntel Family 6 Model 154 Stepping 3&lt;br&gt;  Base Frequency                4.60 GHz&lt;br&gt;  L1 Instruction Cache          32.0 KB x 8&lt;br&gt;  L1 Data Cache                 48.0 KB x 8&lt;br&gt;  L2 Cache                      1.25 MB x 2&lt;br&gt;  L3 Cache                      24.0 MB&lt;br&gt;&lt;br&gt;Memory Information&lt;br&gt;  Size                          62.6 GB&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Information&lt;br&gt;  Operating System              CentOS Stream 8&lt;br&gt;  Kernel                        Linux 4.18.0-513.el8.x86_64 x86_64&lt;br&gt;  Model                         Alibaba Cloud Alibaba Cloud ECS&lt;br&gt;  Motherboard                   N/A&lt;br&gt;  BIOS                          SeaBIOS 449e491&lt;br&gt;&lt;br&gt;CPU Information&lt;br&gt;  Name                          Intel(R) Xeon(R) Platinum&lt;br&gt;  Topology                      1 Processor, 1 Core, 2 Threads&lt;br&gt;  Identifier                    GenuineIntel Family 6 Model 85 Stepping 4&lt;br&gt;  Base Frequency                2.50 GHz&lt;br&gt;  L1 Instruction Cache          32.0 KB&lt;br&gt;  L1 Data Cache                 32.0 KB&lt;br&gt;  L2 Cache                      1.00 MB&lt;br&gt;  L3 Cache                      33.0 MB&lt;br&gt;&lt;br&gt;Memory Information&lt;br&gt;  Size                          1.65 GB&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Information&lt;br&gt;  Operating System              Ubuntu 22.04.1 LTS&lt;br&gt;  Kernel                        Linux 5.15.0-60-generic x86_64&lt;br&gt;  Model                         OpenStack Foundation OpenStack Nova&lt;br&gt;  Motherboard                   N/A&lt;br&gt;  BIOS                          SeaBIOS&lt;br&gt;rel-1.10.2-0-g5f4c7b1-20181220_000000-szxrtosci10000&lt;br&gt;&lt;br&gt;CPU Information&lt;br&gt;  Name                          Intel(R) Xeon(R) Gold 6278C CPU @ 2.60GHz&lt;br&gt;  Topology                      1 Processor, 1 Core, 2 Threads&lt;br&gt;  Identifier                    GenuineIntel Family 6 Model 85 Stepping 7&lt;br&gt;  Base Frequency                2.60 GHz&lt;br&gt;  L1 Instruction Cache          32.0 KB&lt;br&gt;  L1 Data Cache                 32.0 KB&lt;br&gt;  L2 Cache                      1.00 MB&lt;br&gt;  L3 Cache                      35.8 MB&lt;br&gt;&lt;br&gt;Memory Information&lt;br&gt;  Size                          3.64 GB&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R2&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;3&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;CPU&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  4032.48&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0004s&lt;br&gt;    total number of events:              40330&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.25&lt;br&gt;         avg:                                    0.25&lt;br&gt;         max:                                    0.73&lt;br&gt;         95th percentile:                        0.25&lt;br&gt;         sum:                                 9997.55&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           40330.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9975/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  1062.51&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0008s&lt;br&gt;    total number of events:              10628&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.91&lt;br&gt;         avg:                                    0.94&lt;br&gt;         max:                                   22.84&lt;br&gt;         95th percentile:                        1.06&lt;br&gt;         sum:                                 9993.46&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           10628.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9935/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  1125.56&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0005s&lt;br&gt;    total number of events:              11258&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.86&lt;br&gt;         avg:                                    0.89&lt;br&gt;         max:                                    1.70&lt;br&gt;         95th percentile:                        0.99&lt;br&gt;         sum:                                 9995.40&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           11258.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9954/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R3&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;4&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;内存&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 101993199 (10198146.52 per second)&lt;br&gt;&lt;br&gt;99602.73 MiB transferred (9959.13 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              101993199&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                    0.03&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4059.50&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           101993199.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.0595/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 48418803 (4841004.79 per second)&lt;br&gt;&lt;br&gt;47283.99 MiB transferred (4727.54 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              48418803&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                   25.26&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4578.95&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           48418803.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.5789/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 57056904 (5704765.11 per second)&lt;br&gt;&lt;br&gt;55719.63 MiB transferred (5571.06 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              57056904&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                    0.06&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4556.06&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           57056904.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.5561/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R4&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;5&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;硬盘&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 1.81 seconds (1129.59 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      3373.41&lt;br&gt;    writes/s:                     2248.94&lt;br&gt;    fsyncs/s:                     7201.80&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  52.71&lt;br&gt;    written, MiB/s:               35.14&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0127s&lt;br&gt;    total number of events:              128288&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.08&lt;br&gt;         max:                                    5.14&lt;br&gt;         95th percentile:                        0.34&lt;br&gt;         sum:                                 9977.78&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           128288.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9778/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 19.29 seconds (106.16 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      1593.12&lt;br&gt;    writes/s:                     1062.08&lt;br&gt;    fsyncs/s:                     3406.64&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  24.89&lt;br&gt;    written, MiB/s:               16.60&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0164s&lt;br&gt;    total number of events:              60600&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.16&lt;br&gt;         max:                                   31.32&lt;br&gt;         95th percentile:                        0.54&lt;br&gt;         sum:                                 9956.30&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           60600.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9563/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 18.29 seconds (111.98 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      1665.88&lt;br&gt;    writes/s:                     1110.59&lt;br&gt;    fsyncs/s:                     3563.77&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  26.03&lt;br&gt;    written, MiB/s:               17.35&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0112s&lt;br&gt;    total number of events:              63355&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.16&lt;br&gt;         max:                                  205.01&lt;br&gt;         95th percentile:                        0.78&lt;br&gt;         sum:                                 9972.64&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           63355.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9726/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R5&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;6&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;多线程&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0002s&lt;br&gt;    total number of events:              197956&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.16&lt;br&gt;         avg:                                    0.20&lt;br&gt;         max:                                    0.34&lt;br&gt;         95th percentile:                        0.21&lt;br&gt;         sum:                                39970.47&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           49489.0000/5.70&lt;br&gt;    execution time (avg/stddev):   9.9926/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0174s&lt;br&gt;    total number of events:              18360&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.57&lt;br&gt;         avg:                                    2.18&lt;br&gt;         max:                                   32.77&lt;br&gt;         95th percentile:                        2.61&lt;br&gt;         sum:                                40050.41&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           4590.0000/94.36&lt;br&gt;    execution time (avg/stddev):   10.0126/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0004s&lt;br&gt;    total number of events:              28536&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.23&lt;br&gt;         avg:                                    1.40&lt;br&gt;         max:                                    3.56&lt;br&gt;         95th percentile:                        1.47&lt;br&gt;         sum:                                39975.16&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           7134.0000/39.87&lt;br&gt;    execution time (avg/stddev):   9.9938/0.01&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;
&lt;h2 id=&#34;あとがき&#34;&gt;あとがき
&lt;/h2&gt;&lt;p&gt;ChatGPTは依然として便利なものだ。上の表は、以前習得したMarkdownだけでは完全にレイアウトできず、表にしないと表示効果が非常に悪くなる。カスタムテーマはページ幅の最大値を制限しており、ページの構成を調整し、幅をパーセント制限に変更した。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;シンプルな方法としては、TablesGeneratorのようなオンラインツールを使ってHTMLテーブルを生成する（複雑なコンテンツには向いていない）。&lt;/li&gt;
&lt;li&gt;またはGoogleドキュメントで作成し、HTML形式でダウンロードして、そのままブログにコピーする。（簡単で直接的、最終的に採用）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;設定でunsafeの設定項目が有効になっていることを確認し、ページごとに幅を設定してください。&lt;/p&gt;
&lt;p&gt;Hugoにおいて、ページごとに幅を設定できます。これは、ページのFront Matterにカスタムパラメータを追加することで実現できます。以下はその例です。&lt;/p&gt;
&lt;p&gt;あなたのMarkdownページのFront Matterセクション（通常ファイルの先頭部分）に、例えば&lt;code&gt;custom_width&lt;/code&gt;のようなカスタムパラメータを追加してください。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;---
title: &amp;quot;我的页面&amp;quot;
date: 2024-01-09
custom_width: &amp;quot;800px&amp;quot;  # 设置宽度为 800 像素
---

正文内容...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;あなたのHugoテーマで、対応するシングルページテンプレートファイルを見つけたり作成したりしてください（例：&lt;code&gt;layouts/_default/single.html&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;シングルページテンプレートでは、ページのFront Matterに&lt;code&gt;custom_width&lt;/code&gt;パラメータがあるか確認し、あればそれに応じてHTML要素（例：&lt;code&gt;div&lt;/code&gt;）に適用する。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;{{ define &amp;quot;main&amp;quot; }}
  &amp;lt;div style=&amp;quot;max-width: {{ with .Params.custom_width }}{{ . }}{{ else }}100%{{ end }}; margin: 0 auto;&amp;quot;&amp;gt;
    {{ .Content }}
  &amp;lt;/div&amp;gt;
{{ end }}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;この例では、インラインスタイル（&lt;code&gt;style&lt;/code&gt;属性）を使用して&lt;code&gt;div&lt;/code&gt;要素に&lt;code&gt;max-width&lt;/code&gt;属性を設定し、&lt;code&gt;custom_width&lt;/code&gt;パラメータが指定されていない場合に幅を100%のデフォルト値に設定しています。&lt;code&gt;margin: 0 auto;&lt;/code&gt;は、&lt;code&gt;div&lt;/code&gt;要素を中心に配置するために使用されています。&lt;/p&gt;
&lt;p&gt;実際の応用では、テーマ構造やCSSスタイルの詳細に応じて、上記の例を調整する必要があるかもしれません。スタイルを調整する際は、テーマの一貫性と可読性を保つようにしてください。&lt;/p&gt;
&lt;p&gt;有効にしたテーマが少し異なっていたため、サイトのカスタムCSS設定を最終調整しました。&lt;/p&gt;</description>
        </item>
        <item>
        <title>Gitが無効なHTTPリポジトリ</title>
        <link>https://ttf248.life/ja/p/git-disable-http-repositories/</link>
        <pubDate>Mon, 08 Jan 2024 21:22:04 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/git-disable-http-repositories/</guid>
        <description>&lt;p&gt;ソフトウェアのバージョンを更新する習慣があり、どのバージョンの&lt;code&gt;Git&lt;/code&gt;からか不明ですが、&lt;code&gt;Http&lt;/code&gt;リポジトリからのコードのプルが禁止されています。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;fatal: Unencrypted HTTP is not supported for GitLab. Ensure the repository remote URL is using HTTPS
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;背景説明&#34;&gt;背景説明
&lt;/h2&gt;&lt;p&gt;環境：Windowsプラットフォーム、いつもTortoiseGitを使ってgitを操作しており、秘密鍵の設定もTortoiseGit経由で行っています。以前にスクリプトを作成して、ローカルのリポジトリを一括で更新したことがあります。&lt;/p&gt;
&lt;p&gt;前の投稿へのリンク：[ローカルのGitリポジトリを一括更新する]({&amp;lt; relref &amp;ldquo;/post/2023/10-19-批量更新本地git仓库&amp;rdquo; &amp;gt;}})&lt;/p&gt;
&lt;p&gt;今日家に帰ってコードのアップデートを実行したところ、先ほどのエラーが発生し、リポジトリが正常に更新されなくなりました。&lt;code&gt;Git&lt;/code&gt;には設定があるはずだと考え、&lt;code&gt;http&lt;/code&gt;プロトコルで引き続きリポジトリをアップデートできるようにしようと思ったのですが、探しても該当の設定項目は見つかりませんでした。&lt;/p&gt;
&lt;p&gt;最も簡単な解決策は、もちろん &lt;code&gt;ssh&lt;/code&gt; プロトコルに切り替えてリポジトリを更新することです。会社の構成上、&lt;code&gt;gitlab&lt;/code&gt; は当面の間、&lt;code&gt;https&lt;/code&gt; プロトコルを提供しません。&lt;/p&gt;
&lt;h2 id=&#34;遺棄問題&#34;&gt;遺棄問題
&lt;/h2&gt;&lt;p&gt;大量ローカルリポジトリを更新するスクリプトを作成する際に、当初は &lt;code&gt;ssh&lt;/code&gt; でリポジトリをプルすることを考えていましたが、なぜそうしたのか詳しく調べていませんでした。結果として、TortoiseGit の設定情報が &lt;code&gt;config&lt;/code&gt; に同期されていなかったため、コマンドラインで実行すると&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git pull #提示没有权限，无法正常更新仓库
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;コマンドで鍵の設定を確認することも正しいです：&lt;code&gt;ssh -T git@gitlab.yintech.net&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;もしGit Small Turtle (TortoiseGit) でコードを正常にプルできるのに、コマンドラインでgit pull コマンドを実行した際にキーが正しくないというエラーが表示される場合、これは Git Small Turtle が PuTTY の SSH キーを使用しているのに対し、コマンドラインが OpenSSH の SSH キーを使用していることが原因である可能性があります。&lt;/p&gt;
&lt;p&gt;小さなカメの鍵設定は、システム.sshフォルダから鍵ファイル情報を読み込むのではなく、インターフェースのリポジトリ設定時に、個別に鍵ファイルのパスを設定します。便利なテクニックとして、最初にリポジトリを構成した際に鍵を設定すれば、他のリポジトリもこの鍵ファイルを再利用できます。PuTTYが鍵をロードした後、すぐに終了するのではなく、プロキシサービスを開始します。&lt;/p&gt;
&lt;p&gt;グローバル設定を調整し、システムデフォルトの &lt;code&gt;ssh&lt;/code&gt; 設定を使用しないようにすることで、この構成では Git Bash は TortoisePlink を使用して SSH 接続を行います。 このような設定は、TortoiseGit に付属している PuTTY ツールを使用する場合に適しています。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git config --global core.sshCommand &amp;quot;&#39;C:/Program Files/TortoiseGit/bin/TortoisePlink.exe&#39; -batch -ssh&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;設定されている実行ファイルパスを、必要に応じて小烏龜のパスに合わせて変更してください。完全なパスが設定されているため、システム環境変数への追加は不要です。&lt;/p&gt;</description>
        </item>
        <item>
        <title>AIプログラミングとタスク分解</title>
        <link>https://ttf248.life/ja/p/ai-programming-and-task-decomposition/</link>
        <pubDate>Fri, 22 Dec 2023 08:44:26 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ai-programming-and-task-decomposition/</guid>
        <description>&lt;p&gt;2年前にサイトに追加したコード領域のコピー機能ですが、あれから半日ほど格闘した結果、最終的なレンダリングの効果は少し期待外れでした。半熟前開発者だったため、改善しようともせず、動けば良いと思っていました。今年は&lt;code&gt;AI&lt;/code&gt;で小程序を開発し、フロントエンドの開発にもより慣れたので、一新（AIによる再設計）。&lt;/p&gt;
&lt;p&gt;悟道：タスクを分解して、多くの小さなタスクに分けました。AIで開発するのはまだスムーズです。すでに閉鎖された小程序ですが、75%のコードはAIによって提供され、複数のタスクに分割して割り当て、人工でプロジェクトコードを組み立てています。&lt;/p&gt;
&lt;h2 id=&#34;前文&#34;&gt;前文
&lt;/h2&gt;&lt;p&gt;簡単なことだと思っていることを、コードコピーボタンを追加する。&lt;/p&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文
&lt;/h2&gt;&lt;p&gt;CSSとJavaScriptのコードを設計し、class=&amp;ldquo;highlight&amp;rdquo; のウェブ要素を見つけて、その要素のコンテナ内にコピーボタンを追加して、コードをコピーする機能を実現してください。&lt;/p&gt;
&lt;p&gt;最初のドラフトのコードを見ると問題があり、再生成したところ、ほぼ使えるようになったが、コピーされた内容に誤りがあり、重複するテキストも含まれている。再度最適化を促し、手動で主要なカラーデザインを指定し、どのようなエフェクトが含まれるかを指示した。&lt;/p&gt;
&lt;p&gt;ボタンのサイズと色に関して特定の要件があることを承知いたしました。これらの要件に合わせて、ボタンのスタイルを再設計できます。以下に、ご提供いただいたカラースキームを含め、ボタンのサイズを最適化した調整後のCSSスタイルを示します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.copy-btn {
  position: absolute;
  top: 2px; /* 调整位置 */
  right: 2px;
  padding: 3px 6px; /* 缩小尺寸 */
  font-size: 12px; /* 减小字体大小 */
  background-color: #8FD1E1; /* 按钮背景色 */
  color: #272822; /* 文字颜色 */
  border: 1px solid #272822; /* 边框颜色 */
  border-radius: 3px; /* 圆角 */
  cursor: pointer;
  opacity: 0.7; /* 默认半透明 */
  transition: opacity 0.3s ease, background-color 0.3s ease; /* 平滑过渡效果 */
}

.copy-btn:hover {
  opacity: 1; /* 鼠标悬停时不透明 */
  background-color: #A3D4E5; /* 鼠标悬停时的背景色 */
}

.highlight {
  position: relative;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;このスタイルでは、ボタンのサイズとフォントサイズを小さくし、より洗練された印象にしました。同時に、ボタンのデフォルト状態は半透明で、マウスがボタンの上にかかると不透明になり、背景色が少し明るくなることで視覚的なフィードバックを提供します。このようなデザインは、お客様の色に関する要件を満たしつつ、モダンさと使いやすさを維持しています。&lt;/p&gt;
&lt;p&gt;対応する簡単な &lt;code&gt;JavaScript&lt;/code&gt; を提供しました。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-JavaScript&#34;&gt;document.addEventListener(&#39;DOMContentLoaded&#39;, function() {
  // 查找所有 .highlight 元素
  const highlights = document.querySelectorAll(&#39;.highlight&#39;);

  highlights.forEach(function(highlight) {
    // 创建复制按钮
    const copyBtn = document.createElement(&#39;button&#39;);
    copyBtn.textContent = &#39;复制&#39;;
    copyBtn.classList.add(&#39;copy-btn&#39;);

    // 将按钮添加到每个 .highlight 元素中
    highlight.appendChild(copyBtn);

    // 添加点击事件监听器
    copyBtn.addEventListener(&#39;click&#39;, function() {
      // 假设 .highlight 下的第一个 &amp;lt;code&amp;gt; 元素包含要复制的代码
      const code = highlight.querySelector(&#39;code&#39;) ? highlight.querySelector(&#39;code&#39;).textContent : &#39;&#39;;

      navigator.clipboard.writeText(code).then(() =&amp;gt; {
        // 显示复制成功信息
        copyBtn.textContent = &#39;已复制!&#39;;
        setTimeout(() =&amp;gt; {
          copyBtn.textContent = &#39;复制&#39;;
        }, 2000);
      }).catch(err =&amp;gt; {
        console.error(&#39;复制失败: &#39;, err);
      });
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;あとがき&#34;&gt;あとがき
&lt;/h2&gt;&lt;p&gt;コピーボタンをコード領域の右上隅、または上部に新たに追加することを期待していたのですが、フロントエンドについて十分な知識がないため、キーワードに基づいて機能を正確に説明できず、AI と何度かやり取りしても、期待通りの結果が得られませんでした。&lt;/p&gt;
&lt;p&gt;時間が経つにつれて、AIがプログラミング開発にどれほどの影響を与えるか分かりません。&lt;/p&gt;</description>
        </item>
        <item>
        <title>クラウドサーバーとスクリプトキッド</title>
        <link>https://ttf248.life/ja/p/cloud-servers-and-script-kids/</link>
        <pubDate>Mon, 20 Nov 2023 15:08:53 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/cloud-servers-and-script-kids/</guid>
        <description>&lt;p&gt;ダブルイレブンに合わせてキャンペーンを実施中、アリババクラウドが新たに一台のサーバーを入手しました。経済的なバージョンで、年間99元です。スペックは高くありませんが、踏み台として自宅のサービスを代理するのにも良いでしょう。キャンペーンは2026年まで続きます。&lt;/p&gt;
&lt;p&gt;上海地域のサーバーを特別に選び、自宅の機械に低遅延プロキシを設定しました。win11とwindows server 2022ですが、serverバージョンは後からデプロイしたもので、使用しようとしたところ、突然アクセス拒否メッセージを受け取りました。サーバーの更新だと思って待っていたのですが、しばらくすると正常に戻ると考えました。5分経って再度試してみたところ、やはりログインできず、関連のエラーを検索したところ、誰かがログインを試みていることと、パスワードの入力ミスが多すぎるため、現在ログインできないとのことでした。&lt;/p&gt;
&lt;p&gt;以前にもセキュリティ攻撃のスクリプトに触れたことがあり、すぐにこれらのログインは正常な行動ではないと気づいた。誰かがサービスを攻撃し、ログインサーバーをブルートフォースでクラックしようとしているのだろう。サーバーのファイアウォール設定が手抜きだったため、ホワイトリストを設定していなかった。2台のマシンの3389ポートをプロキシ化し、それを公衆ネットワークに晒してしまっていた。まさに池の中の餌のようなものだ。スクリプトキッドが攻撃していることが分かったので、次のことは簡単だ。ファイアウォールにホワイトリストを設定し、会社のIPアドレスと自宅のIPアドレスのみがプロキシサービスにアクセスできるようにする。&lt;/p&gt;
&lt;p&gt;frps 代理服务端以前も実行ログを設定していなかったが、ログを有効にすると見ていて楽しかった。全国各地のプロキシIPアドレスが私のサーバーへのログインを試みている。幸いなことに、serverバージョンだったので問題に気づいた。そうでないと、win11 のそのマシンはいつか必ず突破されてしまうだろう。パスワードの設定は比較的簡単だった。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;2023/11/17 16:51:14 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [101.43.98.211:50486]
2023/11/17 16:51:14 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [218.93.202.63:56970]
2023/11/17 16:51:14 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [222.179.106.174:60812]
2023/11/17 16:51:15 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [58.16.204.238:2839]
2023/11/17 16:51:15 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [124.223.47.24:50274]
2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [43.248.128.22:55883]
2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [43.143.53.138:56955]
2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [43.228.7.250:61550]
2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [125.76.228.9:55842]
2023/11/17 16:51:17 [I] [proxy.go:204] [4dfcc2259937dcb9] [winserver-remote] get a user connection [91.240.118.187:49326]
2023/11/17 16:51:17 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [91.240.118.187:49324]
2023/11/17 16:51:17 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [89.248.163.79:51712]
2023/11/17 16:51:18 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [218.63.75.24:62387]
2023/11/17 16:51:19 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [103.186.109.227:51396]
2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [116.233.234.104:51567]
2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [222.187.193.202:51585]
2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [59.48.98.42:57489]
2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [146.56.241.134:53558]
2023/11/17 16:51:21 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [222.179.106.174:30620]
2023/11/17 16:51:23 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [183.14.214.51:62128]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ついでにLinuxサービスのログインログを確認したところ、阿里云のサーバー以外に、友人のHuawei Cloudのサーバーもあった。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo grep &amp;quot;Failed password&amp;quot; /var/log/secure  centos系列
sudo grep &amp;quot;Failed password&amp;quot; /var/log/auth.log  ubuntu系列
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Nov 16 04:46:34 aliyun-sh sshd[156625]: Failed password for root from 120.55.164.64 port 53410 ssh2
Nov 16 04:46:34 aliyun-sh sshd[156623]: Failed password for root from 111.16.215.122 port 36548 ssh2
Nov 16 04:46:58 aliyun-sh sshd[156630]: Failed password for invalid user share from 139.9.233.78 port 53872 ssh2
Nov 16 04:47:23 aliyun-sh sshd[156634]: Failed password for invalid user spark from 139.9.233.78 port 36134 ssh2
Nov 16 04:47:26 aliyun-sh sshd[156636]: Failed password for root from 120.55.164.64 port 46142 ssh2
Nov 16 04:47:47 aliyun-sh sshd[156640]: Failed password for root from 111.16.215.122 port 42962 ssh2
Nov 16 04:48:24 aliyun-sh sshd[156652]: Failed password for root from 120.55.164.64 port 38868 ssh2
Nov 16 04:48:25 aliyun-sh sshd[156654]: Failed password for root from 111.16.215.122 port 46164 ssh2
Nov 16 04:48:39 aliyun-sh sshd[156657]: Failed password for invalid user test from 139.9.233.78 port 39386 ssh2
Nov 16 04:48:50 aliyun-sh sshd[156659]: Failed password for root from 111.16.215.122 port 38892 ssh2
Nov 16 04:48:53 aliyun-sh sshd[156662]: Failed password for root from 120.55.164.64 port 49348 ssh2
Nov 16 04:48:53 aliyun-sh sshd[156664]: Failed password for invalid user test from 139.9.233.78 port 49864 ssh2
Nov 16 04:50:02 aliyun-sh sshd[156672]: Failed password for root from 111.16.215.122 port 45294 ssh2
Nov 16 04:50:30 aliyun-sh sshd[156680]: Failed password for invalid user zabbix from 139.9.233.78 port 52206 ssh2
Nov 16 04:50:50 aliyun-sh sshd[156683]: Failed password for root from 120.55.164.64 port 34820 ssh2
Nov 16 04:50:51 aliyun-sh sshd[156685]: Failed password for root from 111.16.215.122 port 58978 ssh2
Nov 16 04:51:18 aliyun-sh sshd[156689]: Failed password for root from 120.55.164.64 port 45306 ssh2
Nov 16 04:51:25 aliyun-sh sshd[156692]: Failed password for root from 111.16.215.122 port 33938 ssh2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ファーウェイのクラウドのマシンは起動してから時間が経っており、辞書攻撃の中盤に入りつつあり、奇妙なユーザーが次々と現れ始めています。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Nov 16 20:30:35 hecs-411458 sshd[182965]: Failed password for invalid user oeh from 39.129.9.180 port 26459 ssh2
Nov 16 20:32:17 hecs-411458 sshd[182967]: Failed password for invalid user dnu from 39.129.9.180 port 27079 ssh2
Nov 16 20:34:12 hecs-411458 sshd[182971]: Failed password for invalid user rq from 39.129.9.180 port 27742 ssh2
Nov 16 20:36:07 hecs-411458 sshd[182979]: Failed password for invalid user zw from 39.129.9.180 port 28415 ssh2
Nov 16 20:37:59 hecs-411458 sshd[182981]: Failed password for invalid user egi from 39.129.9.180 port 29068 ssh2
Nov 16 20:39:52 hecs-411458 sshd[182984]: Failed password for invalid user bjb from 39.129.9.180 port 29723 ssh2
Nov 16 20:41:53 hecs-411458 sshd[182988]: Failed password for invalid user hna from 39.129.9.180 port 30375 ssh2
Nov 16 20:43:46 hecs-411458 sshd[182994]: Failed password for invalid user gar from 39.129.9.180 port 31036 ssh2
Nov 16 20:45:40 hecs-411458 sshd[183003]: Failed password for invalid user mze from 39.129.9.180 port 31703 ssh2
Nov 16 20:47:35 hecs-411458 sshd[183007]: Failed password for invalid user tmh from 39.129.9.180 port 32381 ssh2
Nov 16 21:23:01 hecs-411458 sshd[183047]: Failed password for invalid user amax from 112.4.65.118 port 41188 ssh2
Nov 16 22:31:20 hecs-411458 sshd[183116]: Failed password for root from 211.228.203.123 port 60213 ssh2
Nov 16 22:53:44 hecs-411458 sshd[183162]: Failed password for root from 112.132.249.164 port 39272 ssh2
Nov 17 11:44:26 hecs-411458 sshd[184811]: Failed password for invalid user jsh from 43.157.103.27 port 54608 ssh2
Nov 17 11:47:23 hecs-411458 sshd[184818]: Failed password for invalid user mrunal from 43.157.103.27 port 50448 ssh2
Nov 17 11:48:46 hecs-411458 sshd[184820]: Failed password for invalid user robertsheen from 43.157.103.27 port 50560 ssh2
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;あとがき&#34;&gt;あとがき
&lt;/h2&gt;&lt;p&gt;自作のサーバーを開発する場合、Windows の公衆網アクセスにはホワイトリストを設定し、Linux ではパスワードログインを禁止して、秘鍵ファイルによるログインを有効にすることを推奨します。&lt;/p&gt;</description>
        </item>
        <item>
        <title>一括でローカルのGitリポジトリと、過去の権限問題を更新する</title>
        <link>https://ttf248.life/ja/p/bulk-update-local-git-repository-and-legacy-permission-issues/</link>
        <pubDate>Thu, 19 Oct 2023 14:16:22 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/bulk-update-local-git-repository-and-legacy-permission-issues/</guid>
        <description>&lt;p&gt;チーム内のプロジェクト間には依存関係があり、過去の経緯から&lt;code&gt;submodule&lt;/code&gt;を利用して依存関係を管理していなかったため、日々の開発では倉庫コードを手動で順番に更新する必要がある。そうしないと、様々な奇妙な問題が発生する可能性がある。&lt;/p&gt;
&lt;p&gt;オンラインの資料を参考に、構造は基本的に似ているので、ローカルで手動で倉庫ディレクトリ &lt;strong&gt;git_list.txt&lt;/strong&gt; を維持し、スクリプトを作成してディレクトリをトラバースし、一度実行して更新し、その後作業を開始する前にスクリプトを実行します。&lt;/p&gt;
&lt;h2 id=&#34;linux&#34;&gt;linux
&lt;/h2&gt;&lt;p&gt;create new file: batch_pull.sh&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#!/bin/bash

echo &amp;quot;============ 更新仓库 ===================&amp;quot;

# 检查 git_list.txt 是否存在
if [ ! -f &amp;quot;git_list.txt&amp;quot; ]; then
  echo &amp;quot;git_list.txt 文件不存在！请创建并添加要拉取的 git 仓库 URL。&amp;quot;
  exit 1
else
  echo &amp;quot;============ 检测到了 git 仓库清单文件 ====&amp;quot;
fi

# 逐行读取 git_list.txt 中的 URL，并执行拉取操作
while read -r url; do
  if [ -d &amp;quot;$url&amp;quot; ]; then
    cd &amp;quot;$url&amp;quot; || continue
    git pull
    cd ..
    echo &amp;quot;Pull $url 完成！&amp;quot;
    echo &amp;quot;========================================&amp;quot;
  else
    echo &amp;quot;目录 $url 不存在，跳过拉取。&amp;quot;
  fi
done &amp;lt; &amp;quot;git_list.txt&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;windows&#34;&gt;windows
&lt;/h2&gt;&lt;p&gt;create a new file: batch_pull.bat&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bat&#34;&gt;@echo off
chcp 65001 &amp;gt; nul
rem 进入脚本所在目录
cd /d &amp;quot;%~dp0&amp;quot;

rem 检查 git_list.txt 是否存在
if not exist &amp;quot;git_list.txt&amp;quot; (
  echo git_list.txt 文件不存在！请创建并添加要拉取的 git 仓库 URL。
  exit /b 1
) else (
  echo ============ 检测到了 git 仓库清单文件 ====
)

rem 逐行读取 git_list.txt 中的 URL，并执行拉取操作
for /f %%i in (git_list.txt) do (
  if exist &amp;quot;%%i&amp;quot; (
    pushd &amp;quot;%%i&amp;quot;
    git pull
    popd
    echo Pull %%i 完成！
    echo ========================================
  ) else (
    echo 目录 %%i 不存在，跳过拉取。
  )
)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;歴史的遺棄問題&#34;&gt;歴史的遺棄問題
&lt;/h3&gt;&lt;p&gt;システムを再インストールした後で遭遇した&lt;code&gt;git&lt;/code&gt;フォルダの権限ファイルに関する問題：&lt;strong&gt;&amp;ldquo;unsafe repository (&amp;rsquo;/home/repon&amp;rsquo; is owned by someone else)&amp;ldquo;という致命的なエラー&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;オンラインで推奨されている方法は、ほとんどの場合 &lt;code&gt;stack overflow&lt;/code&gt; から来ています。&lt;/p&gt;
&lt;p&gt;リポジトリディレクトリへの信頼追加：&lt;code&gt;git config --global --add safe.directory /home/repon&lt;/code&gt;
手動で設定ファイル&lt;code&gt;.gitconfig&lt;/code&gt;を修正し、ディレクトリを追加して信頼を設定する。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[safe]
    directory = /home/repon
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;処理が終わった後、倉庫のアップデートは正常になりましたが、毎回 &lt;code&gt;git pull&lt;/code&gt; を実行すると、コンソールに多くの警告メッセージが表示され、ユーザー権限のエラーを促されています。&lt;/p&gt;
&lt;h3 id=&#34;デスクトップのosを入れ替える&#34;&gt;デスクトップのOSを入れ替える
&lt;/h3&gt;&lt;p&gt;開発した機械、あまりにも長い間再インストールしていないのでシステムディスクのゴミファイルが爆発してしまい、どうしようもない。時間を作って再インストールしたらまたこの権限の問題に遭遇し、昔のスクリプトが動かず、修正した権限が不完全だった。&lt;/p&gt;
&lt;p&gt;新しいプランを使って、直接&lt;code&gt;*&lt;/code&gt;を追加すれば、&lt;code&gt;git&lt;/code&gt;はすべてのディレクトリを自動的に信頼する。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git config --global --add safe.directory &amp;quot;*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;不明瞭です、ユーザー権限の問題なのか、それとも皆さんが&lt;code&gt;windows&lt;/code&gt;プラットフォームにも&lt;code&gt;chown&lt;/code&gt;のようなコマンドがあることに慣れていないのか。フォルダの所有者を変更するには、ディレクトリが少ない場合は手動で所有者を変更しても良いのですが、このワークステーションにはドメイン情報が追加されています。会社のドメインに異常があるのか、それともローカルシステムの設定に異常があるのかわかりません。ユーザーリストにはログインに使用しているユーザーが見つかりませんでした。結局、コマンドラインで処理しました。&lt;/p&gt;
&lt;p&gt;管理者権限で、&lt;code&gt;powershell&lt;/code&gt;スクリプト&lt;code&gt;change_ower.ps1&lt;/code&gt;を実行してください。スクリプトファイルのエンコーディングを&lt;code&gt;gbk&lt;/code&gt;に調整することを忘れずに。中国語のオペレーティングシステムなので、そうしないと文字化けします。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;# 获取当前用户的用户名
$currentUserName = [System.Security.Principal.WindowsIdentity]::GetCurrent().Name

# 设置 PowerShell 的字符编码为 UTF-8
[Console]::OutputEncoding = [System.Text.Encoding]::UTF8

# 要更改所有者的根目录路径
$rootDirectory = &amp;quot;G:\workspace&amp;quot;  # 替换为实际的目录路径

# 递归遍历目录并更改文件和文件夹的所有者
Get-ChildItem -Path $rootDirectory -Recurse | ForEach-Object {
    $itemPath = $_.FullName

    # 检查是文件还是文件夹
    if ($_ -is [System.IO.DirectoryInfo]) {
        # 如果是文件夹，使用 icacls 更改所有者权限
        $icaclsResult = icacls $itemPath /setowner &amp;quot;$currentUserName&amp;quot; 2&amp;gt;&amp;amp;1
        if ($LASTEXITCODE -eq 0) {
            Write-Host &amp;quot;已更改文件夹 $itemPath 的所有者为 $currentUserName&amp;quot;
        } else {
            Write-Host &amp;quot;无法更改文件夹 $itemPath 的所有者。错误信息: $icaclsResult&amp;quot;
        }
    } else {
        # 如果是文件，使用 icacls 更改所有者权限
        $takeownResult = icacls $itemPath /setowner &amp;quot;$currentUserName&amp;quot; 2&amp;gt;&amp;amp;1
        if ($LASTEXITCODE -eq 0) {
            # Write-Host &amp;quot;已更改文件 $itemPath 的所有者为 $currentUserName&amp;quot;
        } else {
            Write-Host &amp;quot;无法更改文件 $itemPath 的所有者。错误信息: $takeownResult&amp;quot;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;予期せぬ事態が発生し、やはり予想外のことが起きた。スクリプト実行時の中国語情報が文字化けし、コンソールの文字コード設定やスクリプトのエンコーディング調整を試みたが、すべて文字化けした。頭が働いていないのだろうか。試しにコントロールパネル-地域-言語設定のベータ機能を有効にし、グローバルでUnicodeエンコーディングを有効にしたところ、スクリプトは正常に実行されるようになった。しかし、いくつかの開発ソフトウェアが正常に動作しなくなった。後で資料を整理したところ、ようやくスクリプトファイルのエンコーディングを&lt;code&gt;gbk&lt;/code&gt;に設定する必要があることに気づいた。&lt;/p&gt;
&lt;h2 id=&#34;資料&#34;&gt;資料
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://ganzhixiong.com/p/f1b9f4fc/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ganzhixiong.com/p/f1b9f4fc/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://stackoverflow.com/questions/71901632/fatal-error-unsafe-repository-home-repon-is-owned-by-someone-else&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stackoverflow.com/questions/71901632/fatal-error-unsafe-repository-home-repon-is-owned-by-someone-else&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>WPF学習資料</title>
        <link>https://ttf248.life/ja/p/wpf-learning-resources/</link>
        <pubDate>Tue, 17 Oct 2023 10:49:24 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/wpf-learning-resources/</guid>
        <description>&lt;p&gt;小程序的開発設計の穴はまだ埋まっていないのに、新たに&lt;strong&gt;WPF&lt;/strong&gt;を掘り起こし、最近会社も動揺しているので、遠隔での共同作業やコミュニケーションは効率があまり良くないため、思い切ってクライアント側のインターフェースの開発を引き受けた。&lt;/p&gt;
&lt;h2 id=&#34;wpf&#34;&gt;WPF
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/dotnet/desktop/wpf/introduction-to-wpf?view=netframeworkdesktop-4.8&amp;amp;preserve-view=true&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;WPF マイクロソフト公式学習資料の推奨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;WPF基礎まとめ（学習アドバイス）&lt;/li&gt;
&lt;li&gt;WPF中文网&lt;/li&gt;
&lt;li&gt;WPF 個人まとめと学習推奨&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;WPFインターフェース設計で使用される多くのコンセプトは、ウェブフロントエンド設計に似ており、可能な限りUIデザインとビジネスロジックを分離し、UIのデザインを独立させることは、インターネット企業が期待する分工方法です。今年ちょうど小程序を色々試しましたが、多くのコンセプトで共通点があり、比較的簡単に習得できます。これらは現代のUIデザインにおける&lt;strong&gt;道&lt;/strong&gt;であり、基本的なフレームワークの概念を理解していれば、後の道のりは間違えにくくなります。&lt;/p&gt;
&lt;p&gt;以前に&lt;code&gt;Winform&lt;/code&gt;の開発経験がある読者の皆様へ、&lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/zh7791/p/11502696.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;WPF 基礎まとめ(学習アドバイス)&lt;/a&gt; をおすすめします。内容は短く、経験豊富な読者の方々の学習ルートの計画に役立つでしょう。&lt;/p&gt;
&lt;p&gt;ゼロからの学習者向けに推奨するサイトです。&lt;a class=&#34;link&#34; href=&#34;http://www.wpfsoft.com/introduction&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;WPF 中国語サイト&lt;/a&gt; は、基礎概念、発展の歴史、そして基盤となるクラスの理解について、ゼロから解説しています。このサイトは偶然にも今年8月に作者が公開したばかりで、こちらのタイミングとちょうど合致しました。もう少し遅れていたら、おそらく縁はなかったでしょう。&lt;/p&gt;
&lt;p&gt;最も正統な学習資料は、もちろんマイクロソフトの公式サイトにあるものです。少し退屈かもしれませんが、新しい読者は辛抱強く待つ必要があります。&lt;/p&gt;
&lt;p&gt;古典的な電子書籍もたくさんありますが、あまりお勧めできません。日々の仕事が忙しく、じっくりと読書に集中する時間がなかなかありません。一度に読み進めるのは難しいため、プロジェクト演習の方が向いています。&lt;/p&gt;
&lt;h2 id=&#34;c-と-net-のリリース履歴&#34;&gt;C# と .NET のリリース履歴
&lt;/h2&gt;&lt;p&gt;以前学習した言語に比べて、ここ数年で新機能が少し多いのと、文法も毎年バージョンアップされています。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/C_Sharp_%28programming_language%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://en.wikipedia.org/wiki/C_Sharp_(programming_language)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;公式学習資料：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/dotnet/csharp/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://learn.microsoft.com/zh-cn/dotnet/csharp/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/dotnet/core/tutorials/with-visual-studio?pivots=dotnet-7-0&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://learn.microsoft.com/zh-cn/dotnet/core/tutorials/with-visual-studio?pivots=dotnet-7-0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>場所を問わないローカルエリアネットワークZeroTier</title>
        <link>https://ttf248.life/ja/p/zero-tier-remote-lan/</link>
        <pubDate>Tue, 19 Sep 2023 04:58:03 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/zero-tier-remote-lan/</guid>
        <description>&lt;p&gt;オフィスに新しいminiサーバーを購入しました。環境構築が簡単で、時々自宅からアクセスするニーズもあるので、一時的に内網穿通をデプロイします。これまでの経験から、frpサービスをデプロイし、ポートフォワードを指定します。通常は公衆回線上のサーバーが必要で、接続の品質は公衆回線の帯域幅に依存します。新しいZerotier仮想マシンローカルエリアネットワークを試してみます。VPNに似ており、ローカルに仮想NICを作成し、すべてのマシンを仮想ネットワークに追加します。&lt;/p&gt;
&lt;h2 id=&#34;ゼロティアとは何ですか&#34;&gt;ゼロティアとは何ですか。
&lt;/h2&gt;&lt;p&gt;ZeroTierは、さまざまな地理的な場所にあるデバイス間でセキュアな仮想ネットワークを作成できる、ソフトウェア定義の広域ネットワーク（SD-WAN）ソリューションです。ZeroTierを使用すると、複数のコンピューター、サーバー、およびデバイスをあたかも同じローカルエリアネットワークにいるかのように、仮想的で暗号化されたネットワークに簡単に接続できます。これにより、プログラマーやIT専門家は、複雑なネットワーク設定やVPN構成なしに、さまざまな場所間で安全にデータとリソースを共有できます。&lt;/p&gt;
&lt;p&gt;ゼロティアネットワークは、仮想的なグローバルなローカルエリアネットワークであり、異なるデバイスがインターネット経由で接続し、あたかも同じ物理ネットワーク上に存在するかのように動作します。このネットワークは複数のサブネットを含み、すべてのデバイスはゼロティアの技術によって接続されています。&lt;/p&gt;
&lt;p&gt;惑星サーバー：惑星サーバーはZerotierネットワークの重要なコンポーネントの一つです。これはグローバルであり、Zerotierネットワーク全体のトポロジー構造、ルーティング情報、およびネットワーク状態を維持・管理する役割を担います。惑星サーバーはネットワーク全体を制御する中心的な役割を果たしますが、データそのものを直接転送しません。ユーザーのデバイスはZerotierネットワークに参加するために、少なくとも1つの惑星サーバーに接続する必要があります。&lt;/p&gt;
&lt;p&gt;転送サーバー：転送サーバーはZerotierネットワーク内の補助ノードであり、デバイス間のダイレクト接続を確立するのを支援します。デバイスが直接接続できない場合、データは転送サーバーを通じて送信されます。これにより、ネットワークの到達性とパフォーマンスが向上します。転送サーバーは通常、世界中に配置され、データの転送地点として機能します。&lt;/p&gt;
&lt;p&gt;全体的に見て、Zerotierは、惑星サーバーとリレーサーバーの協力を通じて、デバイスが世界中で仮想ローカルエリアネットワークを構築し、安全かつ高速なデバイス間の通信を実現します。惑星サーバーはグローバルネットワーク管理を担当し、リレーサーバーは必要に応じてデバイス間の通信接続を確立するのに役立ちます。&lt;/p&gt;
&lt;h2 id=&#34;インストールとデプロイ&#34;&gt;インストールとデプロイ
&lt;/h2&gt;&lt;p&gt;ZeroTierの公式サイト（&lt;a class=&#34;link&#34; href=&#34;https://www.zerotier.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.zerotier.com/&lt;/a&gt;）にアクセスして、インストールファイルとドキュメントを入手してください。
お客様のオペレーティングシステムに応じて、ZeroTier Oneクライアントをダウンロードしてインストールしてください。Windows、macOS、Linuxなど、多くのプラットフォームで利用可能です。
インストールが完了したら、ZeroTier Oneクライアントを起動してください。
ZeroTierアカウントを登録してください。まだアカウントをお持ちでない場合は。クライアントで作成できます。
ZeroTierアカウントにログインし、新しいネットワークを作成してください。ネットワークには一意の16桁のIDが割り当てられ、それを覚えておく必要があります。
あなたのデバイスにこのネットワークを追加してください。クライアントでネットワークIDを入力するか、QRコードスキャン機能を使用できます。
ZeroTierクライアントをインストールして設定したデバイスは、同じ仮想ネットワークに追加されます。これらのデバイス間では、あたかも同一のローカルエリアネットワークに接続されているかのように直接通信できるようになります。
ZeroTierのコントロールパネルで、ネットワーク設定の管理、デバイスの追加、ネットワークトラフィックの監視などを行うことができます。&lt;/p&gt;
&lt;h2 id=&#34;moon-のインストールとデプロイ&#34;&gt;moon のインストールとデプロイ
&lt;/h2&gt;&lt;p&gt;国内の通信事業者は多くの場合、&lt;code&gt;UDP&lt;/code&gt;ポートフォワードを禁止しています。&lt;code&gt;frp&lt;/code&gt;サービスは安定しており、&lt;code&gt;TCP&lt;/code&gt;プロトコルを使用しているため、&lt;code&gt;Zerotier&lt;/code&gt;のリレーサーバーをデプロイすることで同様の効果を実現できます。ファイアウォールで&lt;code&gt;udp 9993&lt;/code&gt;を開放する必要があります。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;curl -s https://install.zerotier.com/ | sudo bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;インストールが正常に完了しているか確認してください。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;zerotier-cli info
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ローカルネットワークに参加する&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;zerotier-cli join network-id
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;moon&lt;/code&gt; を作成する&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd /var/lib/zerotier-one &amp;amp;&amp;amp; sudo zerotier-idtool initmoon identity.public &amp;gt; moon.json
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;設定ファイルを編集し、&lt;code&gt;stableEndpoints&lt;/code&gt;ノードを「サーバーのグローバルIPアドレス/9993」に調整してください。&lt;/p&gt;
&lt;p&gt;署名設定を生成し、&lt;code&gt;moons.d&lt;/code&gt;フォルダを作成。そこにファイルを移動後、サービスを再起動する。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo zerotier-idtool genmoon moon.json
mkdir moons.d &amp;amp;&amp;amp; mv 000000eb444ec0d8.moon moons.d/
systemctl restart zerotier-one.service
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;クライアントノードはmoonサーバーに参加し、IDは前のJSON設定ファイル内のidフィールドから取得されます。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;zerotier-cli.bat orbit ztaddr ztaddr
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 观察是否出现新的 mooon 节点，id 和信息为服务器配置的相同
[root@idv-36f9d5 ~]# zerotier-cli listpeers
200 listpeers &amp;lt;ztaddr&amp;gt; &amp;lt;path&amp;gt; &amp;lt;latency&amp;gt; &amp;lt;version&amp;gt; &amp;lt;role&amp;gt;
200 listpeers 0cccb***** 35.236.*.*/64393;110;10726 327 1.6.3 LEAF
200 listpeers 3a46f***** 185.180.*.*/9993;110;757 -1 - PLANET
200 listpeers 3ed7c***** 39.97.*.*/9993;172;79 32 1.6.3 MOON
200 listpeers 4f838***** - -1 - LEAF
200 listpeers 62f86***** 50.7.*.*/9993;110;4796 351 - PLANET
200 listpeers 778cd***** 103.195.*.*/9993;5148;4887 253 - PLANET
200 listpeers 992fc***** 195.181.*.*/9993;10161;4921 226 - PLANET
200 listpeers 9d2b5***** - -1 - LEAF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Windows プラットフォームでは管理者権限でターミナルを起動し、zerotier-cli.bat コマンドライン操作を行い、Linux プラットフォームでは zerotier-cli 操作を行います。peers サブコマンドで接続状況を確認し、listpeers で全てのノードを表示します。「moon」ノードが正常に表示されていれば、接続は成功しています。&lt;/p&gt;
&lt;h2 id=&#34;どうやってアンインストールしますか&#34;&gt;どうやってアンインストールしますか。
&lt;/h2&gt;&lt;p&gt;Windowsプラットフォームのアンインストール方法はここでは割愛します。通常の操作で、コントロールパネルからアンインストールできます。Ubuntuについては重点的に説明します。&lt;/p&gt;
&lt;p&gt;dpkgを使ってzerotier-oneサービスを削除します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo dpkg -P zerotier-one
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ゼロタイアーワンフォルダを削除してください。このフォルダにはアドレスが保存されており、削除後に再インストールすると新しいアドレスが割り当てられます。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo rm -rf /var/lib/zerotier-one/
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;あとがき&#34;&gt;あとがき
&lt;/h2&gt;&lt;p&gt;元々全てアンインストール済みだったのですが、サーバーが到着しても適切なプロキシノードとなるサービスがなく、アリババクラウドが業績のために開発限定のサーバーを提供してくれました。スペックはそれほど高くありませんが、年間99元と手頃な価格で、2年ほど利用しています。重視したのは、サーバーが提供する帯域幅です。&lt;/p&gt;
&lt;h2 id=&#34;参照資料&#34;&gt;参照資料
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.wnark.com/archives/152.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.wnark.com/archives/152.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/Yogile/p/12642423.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.cnblogs.com/Yogile/p/12642423.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>VMware仮想マシンディスクスペース最適化</title>
        <link>https://ttf248.life/ja/p/vmware-virtual-disk-space-optimization/</link>
        <pubDate>Wed, 21 Jun 2023 18:35:41 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/vmware-virtual-disk-space-optimization/</guid>
        <description>&lt;p&gt;VMware仮想マシンをインストールして開発システムを使用する際、通常はディスクスペースを多めに確保しますが、使用期間が長くなると、ローカルで占有するディスクスペースは仮想マシンの実際のファイルの内容を大幅に上回ることがあります。&lt;/p&gt;
&lt;h2 id=&#34;シーン描写&#34;&gt;シーン描写
&lt;/h2&gt;&lt;p&gt;df -h コマンドで現在の機械のディスク情報を確認したところ、実際に使用しているのは 60GB であり、全てのスナップショットとクローンイメージを削除しても、ローカル仮想マシンが占有するディスクスペースは依然として 60GB を大幅に上回る。すでに逼迫していたハードディスクの状況を悪化させることになった。&lt;/p&gt;
&lt;h2 id=&#34;前提条件&#34;&gt;前提条件
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;仮想マシンをインストールする際に、予約割り当てディスクにチェックが入っていませんでした。&lt;/li&gt;
&lt;li&gt;仮想マシンのディスクを保存するローカルディスクの空き容量が、現在の仮想マシンが使用している容量よりも大きい場合&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;残りのスペースが足りないため、一時的に仮想マシンを外付けハードディスクに移動し、ディスクを最適化した後に移行に戻すことを検討してください。&lt;/p&gt;
&lt;h2 id=&#34;道具&#34;&gt;道具
&lt;/h2&gt;&lt;p&gt;公式が &lt;code&gt;open-vm-tools&lt;/code&gt; パッケージを提供しており、yum でインストールするか、VMware Tools のイメージパッケージでインストールできます。&lt;/p&gt;
&lt;h2 id=&#34;命令&#34;&gt;命令
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;vmware-toolbox-cmd disk shrink /
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;実行後、仮想マシンは自動的にシャットダウンされ、VMwareのホストプログラムがディスク圧縮を実行します。 処理時間は、仮想マシンのサイズとディスクのアクセス速度によって異なります。&lt;/p&gt;
&lt;p&gt;実行結果はまだかなり良いです。仮想マシンのディスクスペース使用量は、&lt;code&gt;df -h&lt;/code&gt;のディスク情報とほぼ等しいです。&lt;/p&gt;</description>
        </item>
        <item>
        <title>Stable Diffusion - ゼロからのインストールにおける愛憎劇</title>
        <link>https://ttf248.life/ja/p/stable-diffusion-zero-install-saga/</link>
        <pubDate>Thu, 13 Apr 2023 00:23:54 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/stable-diffusion-zero-install-saga/</guid>
        <description>&lt;p&gt;国内の資料は、基本的に&lt;strong&gt;秋葉&lt;/strong&gt;大佬の一括デプロイパッケージを推奨している。&lt;code&gt;Python&lt;/code&gt;ベースのオープンソースプロジェクトなので、デプロイもそれほど複雑ではないはずだ。ゼロからやってみるか。&lt;/p&gt;
&lt;p&gt;AI生成画像の作成に手間取って、わざとグラフィックカードを交換した。エントリーモデルの&lt;code&gt;3060 12g&lt;/code&gt;です。7年間活躍してきた&lt;code&gt;960&lt;/code&gt;は退役しました。&lt;/p&gt;
&lt;p&gt;コアの&lt;code&gt;pytorch cuda&lt;/code&gt;インストールですが、以前Pythonゲームアシスタントスクリプトを書く際にローカルにインストールしたことがありますが、やはり問題が発生し、&lt;code&gt;cuda&lt;/code&gt;のライセンス認証がどうしてもできません。&lt;/p&gt;
&lt;h2 id=&#34;保留&#34;&gt;保留
&lt;/h2&gt;&lt;p&gt;記事の構成を再計画し、まずpytorchについて、バージョン対応関係、そしてバージョン確認方法を紹介する。
ローカル環境で仮想環境を新たに作成し、PyTorch をデプロイするにはどうすればよいか。
翻訳資料、ゼロから始めるStable Diffusion &lt;a class=&#34;link&#34; href=&#34;https://stable-diffusion-art.com/install-windows/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stable-diffusion-art.com/install-windows/&lt;/a&gt;
資料を整理する&lt;/p&gt;
&lt;h2 id=&#34;手順&#34;&gt;手順
&lt;/h2&gt;&lt;p&gt;中国語で検索しても、ステップバイステップのインストールチュートリアルが見つからないかもしれません。Googleで英語で検索すると、最初から始めるチュートリアルがたくさんあります。必要なものを説明した後、gitをインストールし、pythonをインストールする必要があることが説明されています。それから、リポジトリをダウンロードして、スクリプトをダブルクリックするだけで終わりました。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/AUTOMATIC1111/stable-diffusion-webui&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;詳細な使い方とFAQについては、&lt;code&gt;issues&lt;/code&gt; を参照し、&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki&lt;/a&gt; をご確認ください。&lt;/p&gt;
&lt;p&gt;なぜか誰もこの倉庫が何のためにあるのか説明してくれない。実は名前からでもわかるように、これはインターフェースコンソールで、使う私たちをより便利にするものだ。実際、インストール時に公式の倉庫の内容をダウンロードし、実際の&lt;code&gt;SD&lt;/code&gt;コードを入手する。&lt;/p&gt;
&lt;p&gt;倉庫でも、インストール起動スクリプトを作成しました。現在のフォルダに &lt;code&gt;Python&lt;/code&gt; 仮想環境があるかどうかを自動的に認識し、もしあれば、そのパスの &lt;code&gt;python&lt;/code&gt; をデフォルトで使用します。&lt;/p&gt;
&lt;p&gt;もし完全に初心者の方でしたら、こちらをご覧ください。&lt;a class=&#34;link&#34; href=&#34;https://stable-diffusion-art.com/install-windows/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stable-diffusion-art.com/install-windows/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;pytorch&#34;&gt;pytorch
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/get-started/locally/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://pytorch.org/get-started/locally/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;こここそが今日私が言いたかったことです。まず、彼らの手順に従ってスクリプトを直接起動しないでください。Pythonはrequirementファイルで依存ライブラリをインストールします。これは些細な問題です。重要なのは、グラフィックカードのドライバーバージョンとPyTorchが対応していること。これについても多くの人が説明していますので、ネットで検索すればすぐに見つかります。&lt;/p&gt;
&lt;p&gt;参照：&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/weixin_40660408/article/details/129896700&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/weixin_40660408/article/details/129896700&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;仮想環境を作成し、空の仮想環境にして、そこで直接公式サイトでスクリプトを実行して、PyTorchをインストールします。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -c &amp;quot;import torch; print(torch.version.cuda)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -c &amp;quot;import torch; print(torch.__version__, torch.cuda.is_available())&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上記の2つのスクリプトは、インストールする必要があるCUDAのバージョンを確認したり、インストールが成功したかどうかを確認したりできます。&lt;/p&gt;
&lt;p&gt;ここでは、ごちゃごちゃした操作は推奨しません。まずは公式ページのロジックに従ってコピーしてきて、そのままインストールしてください。pipでインストールしようとすると、うまくいかないか、CUDAが有効にならない可能性が高いです。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;重要：フォルダのパスに余計なものが含まれていると、PyTorchが正常に使えない可能性があります。&lt;/p&gt;
&lt;p&gt;何度も中間でやり直しを重ね、公式のインストールファイルをダウンロードして手動でインストールすることも試しました。2.0版にアップデートしようとしたのですが、公式ドキュメントには2.0の方が速度が速いと書いてあったからです。ただ、以前からあまり使っていなかったので、Pythonのバージョンやこれが影響しているのかもわかりません。その間、公式のマニュアルも確認し、3.8のバージョンを使うことを推奨していました。そこで少し競合が発生しました。以前はワンクリックインストールパッケージを使っていて、そこには3.10のバージョンが入っていました。最終的には、最初からすべてやり直しで、まず新しいフォルダを作成し、仮想環境を作成して、torchが正常にインストールされていることを確認しました。&lt;/p&gt;
&lt;p&gt;インストールした仮想環境を、Web UIのフォルダの中に移動してください。その後でスクリプトのインストールを開始すれば、他の依存関係の問題はほとんどなくなります。&lt;/p&gt;
&lt;p&gt;移動後に、実行する必要があります：python -m pip install &amp;ndash;upgrade &amp;ndash;force-reinstall pip で、pip を修正してください。&lt;/p&gt;
&lt;p&gt;見た目はなんだかよくわからないかもしれませんが、この場所でかなり色々試しました。私のtorchが正しく認識されなかったからです。すべての干渉要因を排除するために、まずこれをインストールしてから、他の依存関係ライブラリをインストールすることにしました。&lt;/p&gt;
&lt;h2 id=&#34;xformers&#34;&gt;Xformers
&lt;/h2&gt;&lt;p&gt;推奨します。画像生成を高速化し、既存の占有量を減らすことができます。副作用は、同じパラメータグループを使用した場合、&lt;strong&gt;生成される画像の安定性がそれほど高くない&lt;/strong&gt;ことです。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;stable-diffusion-webui:Xformers&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/diffusers/optimization/xformers&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;huggingface optimization&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Optimization Ratio&lt;/th&gt;
&lt;th&gt;Time taken&lt;/th&gt;
&lt;th&gt;Torch active/reserved&lt;/th&gt;
&lt;th&gt;Sys VRAM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;100.00%&lt;/td&gt;
&lt;td&gt;2m 57.03s&lt;/td&gt;
&lt;td&gt;7440/10058 MiB&lt;/td&gt;
&lt;td&gt;12288/12288 MiB (100.0%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;51.02%&lt;/td&gt;
&lt;td&gt;1m 29.21s&lt;/td&gt;
&lt;td&gt;4547/7164 MiB&lt;/td&gt;
&lt;td&gt;9298/12288 MiB (75.67%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;((masterpiece)),((best quality)),((high detial)),((realistic,))
Industrial age city, deep canyons in the middle,chinese architectural streets,bazaars, Bridges, (rainy days:1.2), (steampunk:0.8), chinese architecture
Negative prompt: nsfw,((cowboy)),(((pubic))), ((((pubic_hair))))sketch, duplicate, ugly, huge eyes, text, logo, monochrome, worst face, (bad and mutated hands:1.3), (worst quality:2.0), (low quality:2.0), (blurry:2.0), horror, geometry, bad_prompt, (bad hands), (missing fingers), multiple limbs, bad anatomy, (interlocked fingers:1.2), Ugly Fingers, (extra digit and hands and fingers and legs and arms:1.4), crown braid, ((2girl)), (deformed fingers:1.2), (long fingers:1.2),succubus wings,horn,succubus horn,succubus hairstyle, (bad-artist-anime), bad-artist, bad hand, borrowed character, text focus, watermark, sample watermark, character watermark, lofter username, photo date watermark, movie poster, magazine cover, journal, cover, cover page, doujin cover, album cover, manga cover, brand name imitation, EasyNegative,Tights, silk stockings,shorts
Steps: 35, Sampler: DPM adaptive, CFG scale: 5.5, Seed: 2223996555, Size: 1088x1088, Model hash: 543bcbc212, Model: base_Anything-V3.0-pruned, Clip skip: 2, ENSD: 31337
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;あとがき&#34;&gt;あとがき
&lt;/h2&gt;&lt;p&gt;なぜ、あのワンクリックデプロイパッケージをおすすめしないかというと、そのパッケージには作者が独自にカスタマイズした設定が含まれており、公式のものをそのままコピーしたものではないからです。もしあなたが初心者であれば、なぜパラメータを設定する必要があるのか理解できないかもしれませんが、まずは公式のものから使い始めるのが一番です。使用時間が長くなるにつれて、公式のマニュアルをよく読んでみれば、どのパラメータを調整すれば良いか分かるようになるでしょう。&lt;/p&gt;
&lt;h2 id=&#34;グラフィックカードの選択&#34;&gt;グラフィックカードの選択
&lt;/h2&gt;&lt;p&gt;データマイニングが終わった後は、グラフィックカードの価格は以前ほど高くはないので、初心者の方は3060と3060tiの間で迷うことが多いですが、一般的には大容量12GB版の3060が推奨されます。なぜなら、より高解像度の画像を作成できるからです。高い解像度が必要なのは、生成時に解像度を高く設定することで、より鮮明で繊細な画像を生成できるからです。もし小さな画像を作成したいのであれば、8GBのVRAMでも十分です。&lt;/p&gt;
&lt;p&gt;まだ一点、&lt;strong&gt;高精細拡大&lt;/strong&gt;オプションは、ディテールを具体化し、映像のディテールをより豊かにしますが、より多くのビデオメモリも必要となります。&lt;/p&gt;
&lt;p&gt;以下はNVIDIA GeForce GTX 970、GeForce RTX 3060 Ti、GeForce RTX 3060、GeForce RTX 3080およびGeForce RTX 3080 Tiの単精度（FP32）、半精度（FP16）および倍精度（FP64）浮動小数点演算能力の仕様概要表です。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;GPUモデル&lt;/th&gt;
&lt;th&gt;リリース年&lt;/th&gt;
&lt;th&gt;単精度浮動小数点演算性能 (TFLOPS)&lt;/th&gt;
&lt;th&gt;複精度浮動小数点演算性能 (TFLOPS)&lt;/th&gt;
&lt;th&gt;倍精度浮動小数点演算性能 (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;GeForce GTX 970&lt;/td&gt;
&lt;td&gt;2014&lt;/td&gt;
&lt;td&gt;3.49&lt;/td&gt;
&lt;td&gt;87.2&lt;/td&gt;
&lt;td&gt;0.109&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GeForce RTX 3060 Ti&lt;/td&gt;
&lt;td&gt;2020&lt;/td&gt;
&lt;td&gt;16.2&lt;/td&gt;
&lt;td&gt;32.4&lt;/td&gt;
&lt;td&gt;0.51&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GeForce RTX 3060&lt;/td&gt;
&lt;td&gt;2021&lt;/td&gt;
&lt;td&gt;12.7&lt;/td&gt;
&lt;td&gt;25.4&lt;/td&gt;
&lt;td&gt;0.39&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GeForce RTX 3080&lt;/td&gt;
&lt;td&gt;2020&lt;/td&gt;
&lt;td&gt;29.8&lt;/td&gt;
&lt;td&gt;58.9&lt;/td&gt;
&lt;td&gt;0.93&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GeForce RTX 3080 Ti&lt;/td&gt;
&lt;td&gt;2021&lt;/td&gt;
&lt;td&gt;34.8&lt;/td&gt;
&lt;td&gt;68.7&lt;/td&gt;
&lt;td&gt;1.36&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;引用した、&lt;a class=&#34;link&#34; href=&#34;https://docs.google.com/spreadsheets/d/1Zlv4UFiciSgmJZncCujuXKHwc4BcxbjbSBg71-SdeNk/edit#gid=0&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;様々なグラフィックカードの性能テストデータ&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;アップデート&#34;&gt;アップデート
&lt;/h2&gt;&lt;p&gt;半年の間が空いたので、本来ならインストール手順を整理したり、もっと基本的な概念を紹介したかったのですが、結果として、一般の人々がAIで絵を描くというのは、結局のところ、大佬が提供する画像パラメータに基づいて調整したり、既存の画像を元にフォーマットされたリレンダリングを行うだけなのだということが分かりました。&lt;/p&gt;
&lt;p&gt;途中でプロジェクトがあり、AIを使ってミニプログラムのUI素材を描くことを試みましたが、色々手間取った結果、効果は期待通りではありませんでした。むしろ、公式のミニプログラムからリソース画像を引き出した方が良いでしょう。&lt;/p&gt;</description>
        </item>
        <item>
        <title>プログラム最適化は、ハードウェアに逆らうようなことはしないこと。</title>
        <link>https://ttf248.life/ja/p/program-optimization-dont-fight-hardware/</link>
        <pubDate>Fri, 07 Apr 2023 16:30:15 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/program-optimization-dont-fight-hardware/</guid>
        <description>&lt;p&gt;ワンループスレッドの処理時間はすでにマイクロ秒レベルにあり、サーバーを入れ替えたことで、最大で6万パケットが溜積される状態から、ほとんど溜積しなくなった。&lt;/p&gt;
&lt;p&gt;シングルスレッドでデータを処理する場合、CPUの性能はクロック周波数、キャッシュサイズ、命令セットアーキテクチャなどの要素に左右されます。一般的に、クロック周波数が高く、キャッシュが大きく、命令セットアーキテクチャが高度なCPUほど、シングルスレッドでのデータ処理性能が高いと言えます。&lt;/p&gt;
&lt;h2 id=&#34;シングルスレッド&#34;&gt;シングルスレッド
&lt;/h2&gt;&lt;p&gt;パフォーマンスの向上は、スレッドを増やすことが必ずしも必要なわけではありません。プロジェクトのプロセスを見直し、ボトルネックとなっている箇所を特定し、シングルスレッドで要件を満たせるかどうか検討しましょう。シングルスレッドであれば考慮すべき点が少なく、問題が発生しにくいという利点もあります。&lt;/p&gt;
&lt;p&gt;来てすぐ、何か言われたり、追加の作業を頼まれたりする。少しばかり問題がある。&lt;/p&gt;
&lt;h2 id=&#34;事件&#34;&gt;事件
&lt;/h2&gt;&lt;p&gt;扱っているのは&lt;strong&gt;市場データで、遅延が重要&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ぐったりしながら徹夜で頑張って、新しい最適化バージョンをリリース。ローカルでインターフェースを分離してテストしたところ、速度もまあまあ。TPS: 4.2万&lt;/p&gt;
&lt;p&gt;サーバーにデプロイするとTPSが急落：2.1万。自宅でデスクトップPCを試すと、TPS：7.9万。内部サービス仮想化に何か問題があるのではないかと疑い始めた。まずCPUのクロック周波数が原因ではないかと思われ、家庭用デスクトップPCとサーバーの&lt;code&gt;CPU&lt;/code&gt;の違いは、主にクロック周波数にある。&lt;/p&gt;
&lt;p&gt;テストサーバーA&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;processor	: 7
vendor_id	: GenuineIntel
cpu family	: 6
model		: 47
model name	: Intel(R) Xeon(R) CPU E7- 4807  @ 1.87GHz
stepping	: 2
microcode	: 0x34
cpu MHz		: 1866.733
cache size	: 18432 KB
physical id	: 1
siblings	: 4
core id		: 3
cpu cores	: 4
apicid		: 7
initial apicid	: 7
fpu		: yes
fpu_exception	: yes
cpuid level	: 11
wp		: yes
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss ht syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 cx16 sse4_1 sse4_2 popcnt aes hypervisor lahf_lm pti dtherm arat
bugs		: clflush_monitor cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit
bogomips	: 3733.46
clflush size	: 64
cache_alignment	: 64
address sizes	: 40 bits physical, 48 bits virtual
power management:
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;テストサーバーB&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;processor	: 7
vendor_id	: GenuineIntel
cpu family	: 6
model		: 63
model name	: Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz
stepping	: 2
microcode	: 0x3c
cpu MHz		: 2599.998
cache size	: 20480 KB
physical id	: 14
siblings	: 1
core id		: 0
cpu cores	: 1
apicid		: 14
initial apicid	: 14
fpu		: yes
fpu_exception	: yes
cpuid level	: 15
wp		: yes
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cpuid_fault epb pti fsgsbase smep xsaveopt cqm_llc cqm_occup_llc dtherm ida arat pln pts
bugs		: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit
bogomips	: 5199.99
clflush size	: 64
cache_alignment	: 64
address sizes	: 40 bits physical, 48 bits virtual
power management:
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;openaiに問い合わせる&#34;&gt;OpenAIに問い合わせる
&lt;/h2&gt;&lt;p&gt;まず、コア数とクロック周波数についてですが、Intel(R) Xeon(R) CPU E7-4807 @ 1.87GHzは6つの物理コアと12個の論理コアを持ち、クロック周波数は1.87GHzです。一方、Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHzは8つの物理コアと16個の論理コアを持ち、クロック周波数は2.60GHzです。したがって、コア数とクロック周波数に関して見ると、E5-2640 v3は単スレッドでのデータ処理において、E7-4807よりも優位性があると考えられます。&lt;/p&gt;
&lt;p&gt;次に、キャッシュサイズに関して、E7-4807は12MBのキャッシュサイズであり、E5-2640 v3は20MBです。したがって、E5-2640 v3の方がキャッシュスペースが大きく、データのアクセス速度とキャッシュヒット率を向上させることができます。&lt;/p&gt;
&lt;p&gt;最後にアーキテクチャについてですが、E5-2640 v3はより高度なHaswellアーキテクチャを採用しており、一方、E7-4807は古いNehalemアーキテクチャを採用しています。HaswellアーキテクチャはNehalemアーキテクチャと比較して性能が向上しており、このことがE5-2640 v3のシングルスレッドでのデータ処理性能に影響を与える可能性があります。&lt;/p&gt;
&lt;p&gt;したがって、総合的に考えると、シングルスレッドでデータを処理するシナリオでは、E5-2640 v3の方がE7-4807よりも優れた性能を発揮するはずです。ただし、具体的な性能差は、データ処理のアルゴリズム、メモリ帯域幅、システム負荷など、さまざまな要因の影響を受けます。そのため、個別の問題に対して個別に分析する必要があります。&lt;/p&gt;
&lt;h2 id=&#34;ハードウェア資料&#34;&gt;ハードウェア資料
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cpubenchmark.net/compare/3786.2vs2365.2/%5BDual-CPU%5D-Intel-Xeon-E7%e2%80%934807-vs-%5BDual-CPU%5D-Intel-Xeon-E5-2640-v3&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.cpubenchmark.net/compare/3786.2vs2365.2/%5BDual-CPU%5D-Intel-Xeon-E7–4807-vs-%5BDual-CPU%5D-Intel-Xeon-E5-2640-v3&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Specification&lt;/th&gt;
&lt;th&gt;Xeon E7-4807 (LGA1567)&lt;/th&gt;
&lt;th&gt;Xeon E5-2640 v3 (LGA2011-v3)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Price&lt;/td&gt;
&lt;td&gt;Search Online  $78 - BUY&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Socket Type&lt;/td&gt;
&lt;td&gt;LGA1567&lt;/td&gt;
&lt;td&gt;LGA2011-v3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CPU Class&lt;/td&gt;
&lt;td&gt;Server&lt;/td&gt;
&lt;td&gt;Server&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Clockspeed&lt;/td&gt;
&lt;td&gt;1.9 GHz&lt;/td&gt;
&lt;td&gt;2.6 GHz&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Turbo Speed&lt;/td&gt;
&lt;td&gt;Not Supported&lt;/td&gt;
&lt;td&gt;Up to 3.4 GHz&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;# of Physical Cores&lt;/td&gt;
&lt;td&gt;6 (Threads: 12)&lt;/td&gt;
&lt;td&gt;8 (Threads: 16)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cache&lt;/td&gt;
&lt;td&gt;NA2&lt;/td&gt;
&lt;td&gt;NA2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Max TDP&lt;/td&gt;
&lt;td&gt;95W x 2&lt;/td&gt;
&lt;td&gt;90W x 2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Yearly Running Cost&lt;/td&gt;
&lt;td&gt;$34.68&lt;/td&gt;
&lt;td&gt;$32.85&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Other&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;First Seen on Chart&lt;/td&gt;
&lt;td&gt;Q3 2020&lt;/td&gt;
&lt;td&gt;Q3 2014&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;# of Samples&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;46&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CPU Value&lt;/td&gt;
&lt;td&gt;69.1&lt;/td&gt;
&lt;td&gt;225.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Single Thread Rating&lt;/td&gt;
&lt;td&gt;721 (-59.2%)&lt;/td&gt;
&lt;td&gt;1767 (0.0%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CPU Mark&lt;/td&gt;
&lt;td&gt;6223 (-64.6%)&lt;/td&gt;
&lt;td&gt;17600 (0.0%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</description>
        </item>
        <item>
        <title>プロンプトエンジニア</title>
        <link>https://ttf248.life/ja/p/prompt-engineer/</link>
        <pubDate>Sun, 26 Mar 2023 20:46:53 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/prompt-engineer/</guid>
        <description>&lt;p&gt;かつて検索エンジンのテクニックを学ぶように、私たちもAIとコミュニケーションをとるためのテクニックを学び、合理的で十分な制約を与え、必要な答えを効率的に得る必要があります。&lt;/p&gt;
&lt;p&gt;もし別の角度から考えると、現在のAIは記憶力の良い子供のようなもので、一度見たものはすべて覚える能力があり、宿題を写すような能力があります。私たちがやるべきことは、AIと正しく効果的にコミュニケーションを取り、ニーズを正確に記述し、AIが期待される結果を生み出すのを助けることです。&lt;/p&gt;
&lt;h2 id=&#34;科学普及&#34;&gt;科学普及
&lt;/h2&gt;&lt;p&gt;火が出天际の&lt;code&gt;AI&lt;/code&gt;、正確に言うと&lt;code&gt;Generative Pre-Training（生成事前学習）&lt;/code&gt;です。直訳すると生成的な事前訓練となります。これは、インターネットで利用可能なデータでトレーニングされたテキスト生成深層学習モデルであり、質問応答、テキスト要約生成、機械翻訳、分類、コード生成、対話AIなどのタスクに使用されます。現在ではGPT-1、GPT-2、GPT-3、GPT-4など、さまざまなバージョンのモデルが存在し、各バージョンは前のバージョンよりも大きく、強力です。&lt;/p&gt;
&lt;h2 id=&#34;結局知能は存在するのか&#34;&gt;結局、知能は存在するのか。
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;類似度が十分高いほど、精度も上がる。&lt;/li&gt;
&lt;li&gt;基本的な、反復的な作業は、特定の訓練を経れば、もはや手作業の介在は不要となる。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;生成AIとは、既存のテキスト、音声、画像などのデータを利用して新しいコンテンツを作成する技術です。テキスト生成、音声合成、画像生成、対話システムなど、さまざまなタスクに使用できます。生成AIの論理性は、トレーニングデータとモデル構造に依存します。一般的に、生成AIは文法、論理、常識をある程度遵守できますが、誤り、偏見、または虚偽の内容を生み出す可能性もあります。したがって、生成AIの出力には人間の判断と検証が必要であり、盲目的に信じたり使用したりすることはできません。&lt;/p&gt;
&lt;h2 id=&#34;プロンプトエンジニア&#34;&gt;プロンプトエンジニア
&lt;/h2&gt;&lt;p&gt;時の流れは二度と戻らない、人は時代の流れに適応する必要がある。あなたはAIが賢くないとか、論理的ではないとか考えるかもしれない。それは、しばしば役に立たないコードを生成するからだ。&lt;/p&gt;
&lt;p&gt;もし別の角度から考えると、現在のAIは記憶力の良い子供のようなもので、一度見たものはすべて覚える能力があり、宿題を写すような能力があります。私たちがやるべきことは、AIと正しく効果的にコミュニケーションを取り、ニーズを正確に説明し、AIが期待される結果を生み出すのを助けることです。&lt;/p&gt;
&lt;h2 id=&#34;対話モード&#34;&gt;対話モード
&lt;/h2&gt;&lt;p&gt;2 年前 Github Copilot が発表されたとき、誰しも 2 年後に OpenAI が突如として現れ、人間が大規模言語モデルの能力に気づくとは思いもしなかった。&lt;/p&gt;
&lt;p&gt;アノテーションベースのプログラミングと対話型プログラミングに基づく場合、インタラクションロジックは完全に異なり、対話形式は初心者ユーザーにとってフレンドリーな体験を提供します。この点において、NewBingが各質問の後で提示する追質問の提案は言及せざるを得ません。これは、Microsoftがユーザーを誘導し、AIナレッジベースからより多くの情報を取得しようとする試みです。&lt;/p&gt;
&lt;h2 id=&#34;例えば&#34;&gt;例えば
&lt;/h2&gt;&lt;p&gt;長時間の新幹線の移動中、コーディングは良い選択肢だ。データ通信量が限られているので、画像を数枚処理し、画像素材を入手した。ソフトウェアをダウンロードして画像を処理するのは少し贅沢すぎるし、ネットワーク環境もそれを許さない。&lt;/p&gt;
&lt;p&gt;要件：一連の画像素材があり、それらは透明な背景を持つものとします。これらの画像をミニプログラムのナビゲーションバーに使用し、選択された状態はカラー表示、未選択の状態は白黒表示にしたいと考えています。素材自体はすべてカラーなので、事前に処理する必要があります。&lt;/p&gt;
&lt;p&gt;フォルダ内のすべての画像を読み込み、画像を白黒に変換し、透明な背景を維持し、画像の品質を最適化してファイルサイズを縮小しながら画像を保存するPythonコードを作成してください。コンソールには、最適化前のファイルサイズと最適化後のファイルサイズの比較を表示します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 导入必要的库
import os
import PIL
from PIL import Image

# 定义一个函数，将图片转换成黑白，维持透明背景，保存图片，并返回文件体积
def convert_and_save(image_file):
    # 打开图片
    image = Image.open(image_file)
    # 获取图片的模式，如果是 RGBA 模式，说明有透明背景
    mode = image.mode
    if mode == &amp;quot;RGBA&amp;quot;:
        # 创建一个和图片大小一致的白色背景图片
        background = Image.new(&amp;quot;RGB&amp;quot;, image.size, (255, 255, 255))
        # 将原图片粘贴到白色背景上，忽略透明像素
        background.paste(image, mask=image.split()[3])
        # 将合成的图片转换成灰度模式
        gray_image = background.convert(&amp;quot;L&amp;quot;)
        # 将灰度图片再转换成 RGBA 模式，以便保留透明背景
        final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
    else:
        # 如果不是 RGBA 模式，直接将图片转换成灰度模式
        final_image = image.convert(&amp;quot;L&amp;quot;)
    # 获取原图片的文件名和扩展名
    file_name, file_ext = os.path.splitext(image_file)
    # 定义新图片的文件名，添加 _bw 后缀表示黑白
    new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # 保存新图片，并优化质量，减少文件体积
    final_image.save(new_file_name, optimize=True)
    # 获取原图片和新图片的文件体积，并返回
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return old_size, new_size

# 定义一个文件夹路径，存放所有的图片
folder_path = &amp;quot;images&amp;quot;
# 遍历文件夹中的所有文件
for file in os.listdir(folder_path):
    # 拼接完整的文件路径
    file_path = os.path.join(folder_path, file)
    # 判断是否是图片文件，根据扩展名判断，可以根据需要添加或修改扩展名
    if file_path.endswith((&amp;quot;.png&amp;quot;, &amp;quot;.jpg&amp;quot;, &amp;quot;.jpeg&amp;quot;, &amp;quot;.gif&amp;quot;)):
        # 调用函数，转换并保存图片，并获取文件体积
        old_size, new_size = convert_and_save(file_path)
        # 在控制台展示优化前后的文件体积大小对比
        print(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;AIはすぐに答えを出力し、見た目も良く問題なく動作するものの、経験豊富なプログラマーなら、下記のコードが十分に汎用的ではなく、本番環境にデプロイするには向いていないと感じるだろう。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;パラメータが固定されました。&lt;/li&gt;
&lt;li&gt;ログファイルはなく、情報はすべてコンソールに出力されています。&lt;/li&gt;
&lt;li&gt;画像の処理タスクは、マルチスレッドモデルに適しています。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ニュービングが登場し、プロンプトに従って質問を選びました。&lt;strong&gt;このコードには改善できる点はありますか？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;今回いただいた回答は、正直言って、完全に予想を上回っています。一般的なプログラマーが思いつくような最適化策に対して、AI が対応する提案を出してくるほどです。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;这段代码可能还有一些可以改进的地方，比如：

可以使用 argparse 库，让用户可以通过命令行参数指定文件夹路径和扩展名，而不是写死在代码里。
可以使用 logging 库，记录程序的运行情况，而不是直接打印到控制台。
可以使用 try-except 语句，捕获可能出现的异常，比如文件打开失败，图片转换失败等，并做相应的处理。
可以使用 multiprocessing 库，利用多核处理器，加速图片的转换和保存过程。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;非常にフレンドリーな対応で、デプロイ環境の違いを考慮し、マルチプロセスをサポートしていないことを許可します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;当然，我很乐意帮你修改一下代码。我尝试添加了 argparse, logging 和 try-except 语句，但没有添加 multiprocessing 库，因为我不确定你的电脑是否支持多核处理。修改后的代码如下：
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 导入必要的库
import argparse
import logging
import multiprocessing
import os

from PIL import Image


# 定义一个函数，将图片转换成黑白，维持透明背景，保存图片，并返回文件体积
def convert_and_save(image_file):
    # 打开图片
    try:
        image = Image.open(image_file)
    except Exception as e:
        logging.error(f&amp;quot;Failed to open {image_file}: {e}&amp;quot;)
        return None, None
    # 获取图片的模式，如果是 RGBA 模式，说明有透明背景
    mode = image.mode
    if mode == &amp;quot;RGBA&amp;quot;:
        # 创建一个和图片大小一致的白色背景图片
        background = Image.new(&amp;quot;RGB&amp;quot;, image.size, (255, 255, 255))
        # 将原图片粘贴到白色背景上，忽略透明像素
        background.paste(image, mask=image.split()[3])
        # 将合成的图片转换成灰度模式
        gray_image = background.convert(&amp;quot;L&amp;quot;)
        # 将灰度图片再转换成 RGBA 模式，以便保留透明背景
        final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
    else:
        # 如果不是 RGBA 模式，直接将图片转换成灰度模式
        final_image = image.convert(&amp;quot;L&amp;quot;)
    # 获取原图片的文件名和扩展名
    file_name, file_ext = os.path.splitext(image_file)
    # 定义新图片的文件名，添加 _bw 后缀表示黑白
    new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # 保存新图片，并优化质量，减少文件体积
    try:
        final_image.save(new_file_name, optimize=True)
    except Exception as e:
        logging.error(f&amp;quot;Failed to save {new_file_name}: {e}&amp;quot;)
        return None, None
    # 获取原图片和新图片的文件体积，并返回
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return file_name, old_size, new_size

# 定义一个函数，解析命令行参数，并返回文件夹路径和扩展名列表
def parse_args():
    # 创建一个解析器对象
    parser = argparse.ArgumentParser(description=&amp;quot;Convert images to black and white and optimize quality.&amp;quot;)
    # 添加一个必选的位置参数，表示文件夹路径
    parser.add_argument(&amp;quot;folder_path&amp;quot;, help=&amp;quot;The path of the folder that contains the images.&amp;quot;)
    # 添加一个可选的参数，表示扩展名列表，默认为 png, jpg, jpeg 和 gif
    parser.add_argument(&amp;quot;-e&amp;quot;, &amp;quot;--extensions&amp;quot;, nargs=&amp;quot;+&amp;quot;, default=[&amp;quot;.png&amp;quot;, &amp;quot;.jpg&amp;quot;, &amp;quot;.jpeg&amp;quot;, &amp;quot;.gif&amp;quot;], help=&amp;quot;The extensions of the image files.&amp;quot;)
    # 解析命令行参数，并返回结果对象
    args = parser.parse_args()
    return args.folder_path, args.extensions

# 定义一个函数，打印优化前后的文件体积大小对比
def print_result(result):
    # 如果结果不为空，说明转换和保存成功
    if result:
        # 解包结果为文件名和文件体积元组
        if len(result) == 3:
            file, old_size, new_size = result
            # 在控制台展示优化前后的文件体积大小对比
            logging.info(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)
        else:
            logging.info(f&amp;quot;{result}&amp;quot;)

# 配置日志记录器，将日志输出到控制台和文件中，设置日志等级为 INFO
logging.basicConfig(level=logging.INFO,
                    format=&amp;quot;%(asctime)s %(levelname)s %(message)s&amp;quot;,
                    handlers=[logging.StreamHandler(),
                              logging.FileHandler(&amp;quot;log.txt&amp;quot;)])

# 调用函数，获取文件夹路径和扩展名列表
folder_path, extensions = parse_args()

if __name__ == &amp;quot;__main__&amp;quot;:
    # Windows 需要这个函数的原因是 Windows 缺乏 fork() 函数（这不完全正确）。
    # 因此，在 Windows 上，fork() 是通过创建一个新的进程来模拟的，这个新的进程中运行的代码，在 Linux 上是在子进程中运行的。
    # 由于这些代码要在技术上无关的进程中运行，所以它必须在运行之前被传递到那里。
    # 传递的方式是先将它们序列化，然后通过管道从原始进程发送到新的进程。
    # 另外，这个新的进程被通知它必须运行通过管道传递的代码，通过向它传递 --multiprocessing-fork 命令行参数。
    # 如果你看一下 freeze_support() 函数的实现，它的任务是检查它运行在哪个进程中，是否应该运行通过管道传递的代码
    multiprocessing.freeze_support()

    # 创建一个进程池，根据电脑的核心数自动分配进程
    pool = multiprocessing.Pool()
    # 创建一个空列表，用于存放异步任务的结果对象
    results = []
    # 遍历文件夹中的所有文件
    for file in os.listdir(folder_path):
        # 拼接完整的文件路径
        file_path = os.path.join(folder_path, file)
        # 判断是否是图片文件，根据扩展名判断，可以根据需要修改扩展名列表
        if any(file_path.endswith(ext) for ext in extensions):
            # 调用函数，转换并保存图片，并获取文件体积，使用异步方式，不阻塞主进程
            result = pool.apply_async(convert_and_save, args=(file_path,), callback=print_result)
            # 将结果对象添加到列表中
            results.append((file, result))
    # 关闭进程池，不再接受新的任务
    pool.close()
    # 等待所有的任务完成
    pool.join()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;あとがき&#34;&gt;あとがき
&lt;/h2&gt;&lt;p&gt;ローカル開発環境が&lt;code&gt;Windows&lt;/code&gt;システムであるため、&lt;code&gt;AI&lt;/code&gt;が最初に提示した回答には&lt;code&gt;main&lt;/code&gt;関数も&lt;code&gt;multiprocessing.freeze_support&lt;/code&gt;も含まれていませんでした。質問への対応でエラーが発生し、それによってコードを修正しました。&lt;/p&gt;
&lt;p&gt;かつて検索エンジンのテクニックを学ぶように、私たちもAIとコミュニケーションをとるためのテクニックを学び、合理的で十分な制約を与え、必要な答えを効率的に得る必要があります。&lt;/p&gt;
&lt;p&gt;注意：プログラミング初心者の方で、与えられたコメントに基づいて理解できない部分があれば、関連コードについてさらに質問してください。&lt;/p&gt;</description>
        </item>
        <item>
        <title>WeChatミニプログラムの背景と開発環境</title>
        <link>https://ttf248.life/ja/p/wechat-mini-program-background-and-development-environment/</link>
        <pubDate>Fri, 24 Mar 2023 21:59:11 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/wechat-mini-program-background-and-development-environment/</guid>
        <description>&lt;p&gt;微信ミニプログラムの紹介と開発準備&lt;/p&gt;
&lt;h2 id=&#34;なぜ小程序があるのか&#34;&gt;なぜ小程序があるのか
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;より良い体験：埋め込みウェブページの読み込みが遅い、白い画面が表示される。ネイティブアプリの体験は、より高速な読み込みを実現します。&lt;/li&gt;
&lt;li&gt;規格と管理：WeChatにとって、接続と管理&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;小番組がリリースされる前に、微信は「JSSDK」というSDKを公開し、微信のネイティブ機能の一部（微信決済、カード）を開放していました。しかし、開発者はWeb開発言語のロジックに基づいて開発を行っていたため、微信の一部の規制を回避することができました。小番組には独自の記述言語があります。&lt;/p&gt;
&lt;h2 id=&#34;ミニプログラムとは何ですか&#34;&gt;ミニプログラムとは何ですか。
&lt;/h2&gt;&lt;p&gt;ミニプログラムは、ダウンロードやインストールが不要で利用できるアプリケーションであり、アプリケーションを&lt;strong&gt;誰でも手の届く範囲に置く&lt;/strong&gt;という夢を実現しています。&lt;/p&gt;
&lt;p&gt;ユーザーがスキャンするか検索するだけでアプリが開くことからも、&lt;strong&gt;使ってすぐに去る&lt;/strong&gt;というコンセプトが伝わります。&lt;/p&gt;
&lt;p&gt;ユーザーは、インストールしすぎたアプリについて心配する必要はありません。アプリはどこにでもあり、いつでも利用できるけれど、&lt;strong&gt;インストールやアンインストールは不要&lt;/strong&gt;です。&lt;/p&gt;
&lt;h2 id=&#34;小程序とモバイルアプリの違い&#34;&gt;小程序とモバイルアプリの違い
&lt;/h2&gt;&lt;p&gt;インストール不要、メモリを占有しない、拡散しやすい：QRコード、ミニプログラムカード、検索&lt;/p&gt;
&lt;h2 id=&#34;微信ミニプログラムは何ができますか&#34;&gt;微信ミニプログラムは何ができますか。
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;コンテンツツール：知乎ホットトピック、微博トレンド、モバイクシェアサイクル、今日ヘッドライン、テンセントマップ、テンセント翻訳&lt;/li&gt;
&lt;li&gt;小売：ピンタオドゥオ、ジーディーモール、モゴグマオ、メルアイフレッシュ、シャオミストア、クエションシー&lt;/li&gt;
&lt;li&gt;ゲーム：跳一跳、欢乐斗地主、欢乐麻将、斗鱼直播、YYライブ&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;コースの内容は2018年のもので、今となっては、一部のアプリケーションベンダーがすでに倒産しています。&lt;/p&gt;
&lt;h2 id=&#34;開発準備&#34;&gt;開発準備
&lt;/h2&gt;&lt;p&gt;小さなプログラムのアカウント登録：通常通り情報を入力すれば登録できます。メールの認証リンクをクリックして有効にしてください。
情報登録
3. ミニプログラム管理后台にログインする。
小程序情報を完善する
開発者バインディング：個人開発者は、ログインするWeChatアカウントが管理者アカウントであるため、追加のバインド作業は不要です。&lt;/p&gt;
&lt;p&gt;メールアドレスには制限があり、新しいメールアドレスが必要ですが、&lt;code&gt;QQ&lt;/code&gt;メイルはエイリアスを申請できます。WeChatの管理画面では検証されません。試してみたところ、ミニプログラムの名前はやや面倒でしたが、商標に関わるものは審査に落ちやすいようです。&lt;/p&gt;
&lt;p&gt;サービスカテゴリは選択可能で、カスタム追加もできます。1つのミニプログラムでは5つのカテゴリを追加できます。&lt;/p&gt;
&lt;p&gt;設定内で、ミニプログラムの&lt;code&gt;ID&lt;/code&gt;情報を確認できたり、メッセージプッシュを有効にしたりできます。メッセージプッシュを有効にすると、メッセージテンプレート機能が利用できるようになります。&lt;/p&gt;
&lt;h2 id=&#34;開発者ツール筆者の記述&#34;&gt;開発者ツール（筆者の記述）
&lt;/h2&gt;&lt;p&gt;通常通りダウンロードとインストールは問題なく、特に注意点はありません。簡単に理解し、そのままゲストモードで入ります。もし携帯電話のデバッグを有効にしたい場合は、つまり携帯電話からミニプログラムの開発バージョンを確認したい場合は、ミニプログラムの開発者アカウントにログインし、設定をクリックして、プロジェクトの詳細内で指定されたミニプログラムIDに切り替えてください。&lt;/p&gt;
&lt;h2 id=&#34;コード構造&#34;&gt;コード構造
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;JS: 双方向インタラクション&lt;/li&gt;
&lt;li&gt;JSON：データ設定&lt;/li&gt;
&lt;li&gt;wXML：インターフェースの要素&lt;/li&gt;
&lt;li&gt;スタイルシート&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>オフィス移転のため、サーバーにアクセスできません。</title>
        <link>https://ttf248.life/ja/p/office-migration-server-unavailable/</link>
        <pubDate>Sat, 11 Mar 2023 01:42:05 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/office-migration-server-unavailable/</guid>
        <description>&lt;p&gt;周知いたします。オフィスが変更になり、元の2階から15階へ移転します。これは通常の席の移動です。&lt;/p&gt;
&lt;h2 id=&#34;デザイン性&#34;&gt;デザイン性
&lt;/h2&gt;&lt;p&gt;オフィスビル&lt;/p&gt;
&lt;h2 id=&#34;移動&#34;&gt;移動
&lt;/h2&gt;&lt;p&gt;退社して荷物をまとめて、慣れた手つきで新しい席へ。パソコンの配線を整えて、楽な姿勢で作業開始。&lt;/p&gt;
&lt;p&gt;（´д`||）！、ネットケーブルを繋いでみたけど、チームでよく使うサーバーにアクセスできない。無線ネットワークに切り替えたら、またアクセスできるようになった。&lt;/p&gt;
&lt;p&gt;当初はサーバーのネットワークセグメント設定の問題かと思った。新しい作業場所の有線ネットワークが、ファイアウォールの設定リストに登録されていないだけだろうと。IT担当者に連絡して調整すれば良いはずだ。しかし、このネットワークセグメントには一台のサーバーだけでなく、他のサーバーにもアクセスしてみると正常だったため、徐々に疑問が生じた。専門的なことは専門の人に任せることにし、最終的に運用部門の担当者が調査した結果、このサーバーが&lt;code&gt;docker&lt;/code&gt;をデプロイしていたために、サービスのデフォルトネットワーク&lt;code&gt;docker0&lt;/code&gt;とオフィス有線ネットワークの設定セグメントが衝突しており、送信されたデータパケットが応答を受け取れずに&lt;code&gt;docker&lt;/code&gt;サービスにルーティングされてしまっていたことが判明した。&lt;/p&gt;
&lt;p&gt;他のサーバーには&lt;code&gt;docker&lt;/code&gt;サービスはデプロイされていないので、この台だけが利用できており、よく使う。時々コンテナでテストサービスをデプロイすることもあるが、まさかこんな状況に遭遇するとは思いもよらなかった。後で考えると、グループ全体が同じオフィスビルに入っているため、IT部門の同僚がネットワークセグメントを分けて&lt;code&gt;172&lt;/code&gt;から始まるアドレスを使っているのも不思議ではない。&lt;/p&gt;
&lt;h2 id=&#34;docker0&#34;&gt;docker0
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# vim /etc/docker/daemon.json
{
    &amp;quot;bip&amp;quot;:&amp;quot;172.200.0.1/24&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;サービスを再起動し、新しいネットワークに切り替えると、サーバーは通常通りアクセスできるようになります。&lt;/p&gt;
&lt;h2 id=&#34;参照資料&#34;&gt;参照資料
&lt;/h2&gt;&lt;p&gt;Docker 入門から実践 - docker0&lt;/p&gt;</description>
        </item>
        <item>
        <title>組み込み入門 1 - 専門用語</title>
        <link>https://ttf248.life/ja/p/embedded-introduction-professional-terms/</link>
        <pubDate>Tue, 07 Mar 2023 13:42:36 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/embedded-introduction-professional-terms/</guid>
        <description>&lt;p&gt;組み込みシステムといえば、やはり昔から学校の実験室にあった51マイクロコントローラーやfreescaleが思い浮かぶ。&lt;/p&gt;
&lt;p&gt;LPA3399Proは、ルネテックRK3399Proプラットフォームをベースとしたビジョンホストであり、大量のビジョンプrocessingを必要とするポータブルコンピューティングホスト向けに開発されました。NPU計算ユニットを内蔵し、3.0TOPSの演算能力を持ち、様々なアルゴリズムモデルをサポートしています。&lt;/p&gt;
&lt;p&gt;RV1109は、聯芯科技（RuiXinTech）のAIおよびマシンビジョン分野に特化したSoCであり、内蔵型NPUを搭載しています。RV1109は、1TOPSの演算能力を提供します。&lt;/p&gt;
&lt;h2 id=&#34;system-on-chip&#34;&gt;System on Chip
&lt;/h2&gt;&lt;p&gt;SoCは、System on a Chipの略で、「チップ上のシステム」を意味します。これは、複数の電子システムを1つのチップに統合する技術です。この技術により、電子製品のサイズと重量を大幅に削減しながら、性能を向上させ、消費電力を抑えることができます。&lt;/p&gt;
&lt;p&gt;SoC（システムオンチップ）とCPU（中央処理装置）は、どちらもコンピューターシステムの重要な構成要素ですが、いくつかの違いがあります。&lt;/p&gt;
&lt;p&gt;CPUはコンピュータシステムの主要なプロセッサであり、プログラム命令の実行を担います。演算ユニット、制御ユニット、レジスタなどの基本的な部品で構成されています。&lt;/p&gt;
&lt;p&gt;SoCは、複数の電子システムを1つのチップに統合したものであり、CPUの他に、メモリ、グラフィックプロセッサ、入出力インターフェースなどの他のコンポーネントも集積できます。これにより、電子製品のサイズと重量を大幅に削減しつつ、性能を向上させ、消費電力を低減することができます。&lt;/p&gt;
&lt;p&gt;要するに、CPUはSoCの構成要素であり、SoCはより複雑で集積度の高い電子システムです。&lt;/p&gt;
&lt;h2 id=&#34;microcontroller-unit&#34;&gt;Microcontroller Unit
&lt;/h2&gt;&lt;p&gt;SoC（システムオンチップ）とMCU（マイクロコントローラーユニット）は、複数の電子システムを1つのチップに統合する技術ですが、それらにはいくつかの違いがあります。&lt;/p&gt;
&lt;p&gt;MCUは、CPU、メモリ、入出力インターフェースなどの基本的な部品を含むマイクロコントローラーの一種です。家電製品や自動車の電子システムなど、他の電子機器を制御するために一般的に使用されます。&lt;/p&gt;
&lt;p&gt;SoCは、より多くの電子システムを1つのチップに統合したものであり、MCUの基本的な構成要素に加え、グラフィックプロセッサや無線通信モジュールなどの他のコンポーネントも集積できます。これにより、電子製品のサイズと重量を大幅に削減しつつ、性能を向上させ、消費電力を低減することができます。&lt;/p&gt;
&lt;p&gt;要するに、MCUはシンプルなマイクロコントローラーであり、SoCはより複雑で統合度の高い電子システムです。&lt;/p&gt;</description>
        </item>
        <item>
        <title>AI支援によるプログラミング、生産性の進化</title>
        <link>https://ttf248.life/ja/p/ai-assisted-programming-productivity-evolution/</link>
        <pubDate>Tue, 28 Feb 2023 17:05:17 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ai-assisted-programming-productivity-evolution/</guid>
        <description>&lt;p&gt;GitHub Copilotのリリースから2年も経っていないうちに、ChatGPTが登場しました。その裏側の仕組みはよく分かりませんが、しばらく使っています。この二つのツールは補助的な面で全く異なりながらも、いずれも生産性を大きく向上させています。&lt;/p&gt;
&lt;p&gt;あまりに複雑なことは、AIではまだできません。結局のところ、彼らには論理がないからです。パターンが決まっていることや、固定されたパラダイムのようなことに対しては、学習データが十分であれば、AIの効果は9割程度期待できます。&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;github copilot
&lt;/h2&gt;&lt;p&gt;公開されたとき、公式サイトのデモを見て、あまり賢そうではないし、試してみたけれど使い勝手が悪く、諦めた。&lt;/p&gt;
&lt;p&gt;2022年以前、暇な時に新しいバージョンを試してみたら、すでに効果はかなり良いです。ただ、国内の速度が少し遅いので、おそらくネットワークの問題でしょう。&lt;code&gt;Python&lt;/code&gt;のような言語で、コメントを参照して書かれたコードはなかなか良く、自分で資料を探して書くよりもずっと速いです。&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;GitHub Copilotはまだ、プログラマー、つまり開発の視点から製品を設計している段階で、プログラミングの方法を知り、徐々にコメントを通じてAIによる補助的なプログラミングを促す必要があります。&lt;/p&gt;
&lt;p&gt;ChatGPT が次のレベルに進化し、&lt;strong&gt;素人でもすぐに使いこなせる&lt;/strong&gt;ようになりました。 会話形式のインタラクティブなデザインなので、どんな質問や要望でも気軽に投げかけられ、わからないことがあれば、遠慮なく追加で質問できます。&lt;/p&gt;
&lt;p&gt;単純な例として、トークン化の概念は知っているけれど、どのようにコーディングすればいいのかわからない。文字列の類似度を計算したいと考えている場合：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Python 分词计算 維天運通 LOGORY 和 合肥維天運通信息科技股份有限公司 两个字符串的相似度；
比较前，统一处理字符串，英文转换为小写；
第二个字符中如果能找到第一个字符的首字符，将第二个字符串截位，截位的长度为第一个字符串的长度
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;こんにちは、これはBingです。😊&lt;/p&gt;
&lt;p&gt;オンラインの情報によると123、Pythonの形態素解析には、jiebaライブラリを使用できます。jiebaライブラリは、厳密モード、フルモード、そして検索エンジンモードという3つの形態素解析モードをサポートしています。ニーズに合わせて適切なモードを選択してください。&lt;/p&gt;
&lt;p&gt;文字列の類似度を比較するためには、まず文字列をトークン化し、次に単語ベクトルや編集距離などの指標を計算する必要があります。numpy や scipy などのライブラリを使用して数学演算を行うことができます。&lt;/p&gt;
&lt;p&gt;文字列を統一的に処理するために、英字を小文字に変換するには、Python の組み込み関数lower()を使用できます。&lt;/p&gt;
&lt;p&gt;2番目の文字列を切り出すには、Pythonのスライス演算子[]を使用できます。&lt;/p&gt;
&lt;p&gt;以下はサンプルコードです。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import jieba
import numpy as np
from scipy.spatial.distance import cosine

# 定义两个字符串
str1 = &amp;quot;維天運通 LOGORY&amp;quot;
str2 = &amp;quot;合肥維天運通信息科技股份有限公司&amp;quot;

# 统一处理字符串，英文转换为小写
str1 = str1.lower()
str2 = str2.lower()

# 找到第二个字符串中第一个字符的位置
index = str2.find(str1[0])

# 如果找到了，截取第二个字符串
if index != -1:
    str2 = str2[index:index+len(str1)]

# 使用 jieba 库进行分词
words1 = list(jieba.cut(str1))
words2 = list(jieba.cut(str2))

# 计算两个字符串的词向量（以词频作为权重）
vector1 = np.zeros(len(words1))
vector2 = np.zeros(len(words1))

for i, word in enumerate(words1):
    vector1[i] += 1 # 统计第一个字符串中每个词出现的次数
    if word in words2:
        vector2[i] += 1 # 统计第二个字符串中每个词出现的次数

# 计算两个字符串的相似度（以余弦距离作为指标）
similarity = 1 - cosine(vector1, vector2)

print(&amp;quot;两个字符串的相似度是：&amp;quot;, similarity)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;さらに進めて、実行結果について問い合わせたところ、問題が見つかりました。結果はでっち上げられており、実際にはコードが実行されていないようですが、なかなか良い結果を返してきます。&lt;/p&gt;
&lt;h3 id=&#34;くり&#34;&gt;くり
&lt;/h3&gt;&lt;p&gt;質問：SQL文で、製品コード表から、製品コードが80000～89999の範囲にあるレコードを抽出するにはどうすればよいでしょうか。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;你好，这是 Bing。😊

根据搜索结果12，你可以使用 SQL BETWEEN 运算符来选择给定区间内的值。BETWEEN 运算符包含了开始和结束的值。

你需要先指定要查询的表名和列名，然后在 WHERE 子句中使用 BETWEEN 运算符和区间值。

例如，如果你要查询产品代码表中，产品代码在 80000 到 89999 之间的记录，你可以使用以下语句：

SELECT * FROM product_code
WHERE code BETWEEN 80000 AND 89999;
这里，* 表示选择所有列3。如果你只想选择特定的列，比如产品名称和价格，你可以用逗号分隔它们，如下：

SELECT name, price FROM product_code
WHERE code BETWEEN 80000 AND 89999;
希望这能帮助到你。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;引き続き質問し、否定してください。製品コードは文字列です。あなたのコードが間違っています。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;抱歉，我没有注意到产品代码是字符串。如果是这样的话，你需要在区间值两边加上单引号，如下：

SELECT * FROM product_code
WHERE code BETWEEN &#39;80000&#39; AND &#39;89999&#39;;
请原谅我的错误。🙏
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;おめでとうございます、間違えるでしょう。&lt;/p&gt;</description>
        </item>
        <item>
        <title>いくつかのあまり使われないGitコマンドまとめ</title>
        <link>https://ttf248.life/ja/p/git-less-common-commands-summary/</link>
        <pubDate>Fri, 17 Feb 2023 10:08:57 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/git-less-common-commands-summary/</guid>
        <description>&lt;p&gt;あまり使わないけれど役に立つ&lt;code&gt;git&lt;/code&gt;コマンド&lt;/p&gt;
&lt;h3 id=&#34;システム再インストールによりwindows上のフォルダの所有者情報が変更されました&#34;&gt;システム再インストールにより、Windows上のフォルダの所有者情報が変更されました。
&lt;/h3&gt;&lt;p&gt;新しいバージョンの&lt;code&gt;git&lt;/code&gt;にセキュリティチェックが追加され、警告が表示されるため、操作を続行できません。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git config --global --add safe.directory
git config --global --add safe.directory &amp;quot;*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;新しいコンピューターにアカウントとパスワードの情報を保存します&#34;&gt;新しいコンピューターにアカウントとパスワードの情報を保存します。
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git config --global credential.helper store
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;情報が更新される必要があれば、まず古い記録を削除してください。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git config --system --unset credential.helper
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>コンパイラ、コールバック関数、パフォーマンス テスト</title>
        <link>https://ttf248.life/ja/p/compiler-callback-function-performance-testing/</link>
        <pubDate>Wed, 15 Feb 2023 13:59:25 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/compiler-callback-function-performance-testing/</guid>
        <description>&lt;p&gt;昨年、SDKを設計しました。いくつかのイベントの処理とカプセル化を担当し、クラスインターフェースとして外部に提供します。サービス初期化時に、呼び出し元は対応するクラスを実装し、オブジェクトポインタをモジュールに渡します。
C11に触れたことがあり、好奇心から、これらのインターフェースをラムダ関数オブジェクトのコールバックで実装するとどうなるだろうかと考えた結果、純粋な仮想関数のインターフェース定義と比較して、より柔軟になるように思えた。
疑問が生じました。二つの異なる文法、パフォーマンスの観点から言えば、どちらがより高速でしょうか？コンパイラ原理は理解していませんが、コードを書いて試してみます。&lt;/p&gt;
&lt;h2 id=&#34;まえがき&#34;&gt;まえがき
&lt;/h2&gt;&lt;p&gt;オンラインのウェブサイトで、さまざまなコンパイラやコンパイルパラメータを選択し、Linuxプラットフォーム上でコードを実行したり、対応するアセンブリコードを確認したりできます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wandbox.org：時々技術検証をする際に、ウェブページ上で短いコードの実行が手間を省くのに便利です。&lt;/li&gt;
&lt;li&gt;Godbolt.org は、異なる色で異なるアセンブリコードに対応するコードを区別するため、ローカルのデバッガーよりも見やすくなります。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文
&lt;/h2&gt;&lt;p&gt;標準委員会は文法の規則を策定し、コンパイルレベルでの実装方法は各々のコンパイラに依存しますが、ここで言及せざるを得ないのは、Microsoftのコンパイラが非常に優れていることだ。シンタックスシュガーは万能ではなく、コールバックインターフェースも多くはないので、&lt;code&gt;lambda&lt;/code&gt;を使用する方がより便利であり、空のコールバック関数インターフェースを定義する必要もない。コールバックインターフェースの種類が多くなる場合は、従来の仮想関数の方がビジネスインターフェースの統一に有利である。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Windowsプラットフォームですが、両者の性能はほぼ同等で、大きな違いはありません。&lt;/li&gt;
&lt;li&gt;Linuxプラットフォーム、仮想関数とラムダの比較、単回で1.35ns増加&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通常のビジネスシステム開発においては、このレベルのパフォーマンス損失は無視できる。&lt;code&gt;lambda&lt;/code&gt;を導入することで、設計においてより多くの利便性が得られる。特に多信号処理を行う場合、その効果が顕著になる。イベントトリガーがあり、ログを記録する必要がある場合は、ログオブジェクトの処理関数が必要となる。より多くのビジネス処理インターフェースが必要な場合は、&lt;code&gt;vector&lt;/code&gt;で&lt;code&gt;lambda&lt;/code&gt;オブジェクトを保存し、イベントトリガー時に順に呼び出す。これは、&lt;code&gt;QT&lt;/code&gt;におけるシグナルとスロットに似ており、ログ、監視、ビジネス1、ビジネス2などが完全に疎結合になる。&lt;/p&gt;
&lt;h2 id=&#34;コード&#34;&gt;コード
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Counter: 1000000
Time: 3966us
Counter: 1000000
Time: 5316us
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;memory&amp;gt;
#include &amp;lt;functional&amp;gt;
#include &amp;lt;atomic&amp;gt;
#include &amp;lt;string&amp;gt;

std::atomic_int64_t counter = 0;

// 定义回调接口
class UserInterface
{
public:
    virtual void name() = 0;
    virtual void full_name() = 0;
};

class User : public UserInterface
{
public:
    void name() {}
    void full_name() { counter++; }
};

void to_string(UserInterface* user)
{
    user-&amp;gt;name();
    user-&amp;gt;full_name();
}

using name_handler = std::function&amp;lt;void()&amp;gt;;
using full_name_handler = std::function&amp;lt;void()&amp;gt;;

class Test
{
    name_handler name_;
    full_name_handler full_name_;

public:
    void set_name_handler(name_handler name)
    {
        name_ = name;
    }

    void set_full_name_handler(full_name_handler full_name)
    {
        full_name_ = full_name;
    }

    void to_string()
    {
        name_();
        full_name_();
    }
};

int main()
{
    User user;

    auto start = std::chrono::high_resolution_clock::now();

    for (int i = 0; i &amp;lt; 1000000; i++)
    {
        to_string(&amp;amp;user);
    }

    auto end = std::chrono::high_resolution_clock::now();
    std::cout &amp;lt;&amp;lt; &amp;quot;Counter: &amp;quot; &amp;lt;&amp;lt; counter &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;Time: &amp;quot; &amp;lt;&amp;lt; std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(end - start).count() &amp;lt;&amp;lt; &amp;quot;us&amp;quot; &amp;lt;&amp;lt; std::endl;

    counter = 0;
    auto name = []() {};
    auto full_name = []() { counter++; };

    Test test;
    test.set_name_handler(name);
    test.set_full_name_handler(full_name);

    start = std::chrono::high_resolution_clock::now();

    for (int i = 0; i &amp;lt; 1000000; i++)
    {
        test.to_string();
    }

    end = std::chrono::high_resolution_clock::now();
    std::cout &amp;lt;&amp;lt; &amp;quot;Counter: &amp;quot; &amp;lt;&amp;lt; counter &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;Time: &amp;quot; &amp;lt;&amp;lt; std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(end - start).count() &amp;lt;&amp;lt; &amp;quot;us&amp;quot; &amp;lt;&amp;lt; std::endl;

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;あとがき&#34;&gt;あとがき
&lt;/h2&gt;&lt;p&gt;資料を探しているとき、似たようなコードスニペット&lt;a class=&#34;link&#34; href=&#34;https://gist.githubusercontent.com/benloong/8050171/raw/fa577ec923b460862078b8b40233a42a1c619eeb/functionperformance.cpp&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;functionperformance.cpp&lt;/a&gt;にたどり着きました。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;memory&amp;gt;
#include &amp;lt;functional&amp;gt;

using namespace std;
using namespace std::chrono;

class Base
{
public:
	Base(){}
	virtual ~Base(){}
	virtual int func(int i) = 0;
};

class Derived : public Base
{
public:
	Derived(int base = 10) : base{base}
	{

	}
	~Derived(){}

	virtual int func(int i)
	{
		return i*base;
	}
private:
	int base;
};

struct Func
{
	int base;
	int operator()(int i)
	{
		return i*base;
	}
	Func(int base) : base {base}
	{

	}
};
const int base = 10;
int calculate(int i)
{
	return base*i;
}

int main()
{
	const int num = 10000;
	Base *p = new Derived{10};
	int total = 0;
	auto start = high_resolution_clock::now();
	for (int i = 0; i &amp;lt; num; ++i)
	{
		total += p-&amp;gt;func(i);
	}
	auto end = high_resolution_clock::now();
	std::cout&amp;lt;&amp;lt;&amp;quot;result: &amp;quot;&amp;lt;&amp;lt;total&amp;lt;&amp;lt;&amp;quot;\nvirtual call elapsed: \t&amp;quot;&amp;lt;&amp;lt;duration_cast&amp;lt;nanoseconds&amp;gt;(end-start).count()&amp;lt;&amp;lt;&amp;quot; nanoseconds.\n&amp;quot;&amp;lt;&amp;lt;std::endl;

	total = 0;
	start = high_resolution_clock::now();
	for (int i = 0; i &amp;lt; num; ++i)
	{
		total += calculate(i);
	}
	end = high_resolution_clock::now();
	std::cout&amp;lt;&amp;lt;&amp;quot;result: &amp;quot;&amp;lt;&amp;lt;total&amp;lt;&amp;lt;&amp;quot;\ndirect function call elapsed: \t&amp;quot;&amp;lt;&amp;lt;duration_cast&amp;lt;nanoseconds&amp;gt;(end-start).count()&amp;lt;&amp;lt;&amp;quot; nanoseconds.\n&amp;quot;&amp;lt;&amp;lt;std::endl;

	Func functor{10};
	total = 0;
	start = high_resolution_clock::now();
	for (int i = 0; i &amp;lt; num; ++i)
	{
		total += functor(i);
	}
	end = high_resolution_clock::now();
	std::cout&amp;lt;&amp;lt;&amp;quot;result: &amp;quot;&amp;lt;&amp;lt;total&amp;lt;&amp;lt;&amp;quot;\nfunctor call elapsed: \t&amp;quot;&amp;lt;&amp;lt;duration_cast&amp;lt;nanoseconds&amp;gt;(end-start).count()&amp;lt;&amp;lt;&amp;quot; nanoseconds.\n&amp;quot;&amp;lt;&amp;lt;std::endl;
	int base = 10;
	function&amp;lt;int(int)&amp;gt; lambda = [base](int i)
	{
		return i*base;
	};
	total = 0;
	start = high_resolution_clock::now();
	for (int i = 0; i &amp;lt; num; ++i)
	{
		total += lambda(i);
	}
	end = high_resolution_clock::now();
	std::cout&amp;lt;&amp;lt;&amp;quot;result: &amp;quot;&amp;lt;&amp;lt;total&amp;lt;&amp;lt;&amp;quot;\nlambda call elapsed: \t&amp;quot;&amp;lt;&amp;lt;duration_cast&amp;lt;nanoseconds&amp;gt;(end-start).count()&amp;lt;&amp;lt;&amp;quot; nanoseconds.\n&amp;quot;&amp;lt;&amp;lt;std::endl;
	return 0;
}

/*
test on mac mini i7 2.7GHz
clang++ -std=c++11 chronotest.cpp -O0
output:
result: 499950000
virtual call elapsed: 	43171 nanoseconds.

result: 499950000
direct function call elapsed: 	31379 nanoseconds.

result: 499950000
functor call elapsed: 	41497 nanoseconds.

result: 499950000
lambda call elapsed: 	207416 nanoseconds.
===================================================
clang++ -std=c++11 chronotest.cpp -O1
output:
result: 499950000
virtual call elapsed: 	26144 nanoseconds.

result: 499950000
direct function call elapsed: 	22384 nanoseconds.

result: 499950000
functor call elapsed: 	33477 nanoseconds.

result: 499950000
lambda call elapsed: 	55799 nanoseconds.
===================================================
clang++ -std=c++11 chronotest.cpp -O2
result: 499950000
virtual call elapsed: 	22284 nanoseconds.

result: 499950000
direct function call elapsed: 	36 nanoseconds.

result: 499950000
functor call elapsed: 	30 nanoseconds.

result: 499950000
lambda call elapsed: 	28292 nanoseconds.

===================================================
clang++ -std=c++11 chronotest.cpp -O3
result: 499950000
virtual call elapsed: 	18975 nanoseconds.

result: 499950000
direct function call elapsed: 	29 nanoseconds.

result: 499950000
functor call elapsed: 	30 nanoseconds.

result: 499950000
lambda call elapsed: 	22542 nanoseconds.
===================================================
clang++ -std=c++11 chronotest.cpp -O4

result: 499950000
virtual call elapsed: 	22141 nanoseconds.

result: 499950000
direct function call elapsed: 	30 nanoseconds.

result: 499950000
functor call elapsed: 	30 nanoseconds.

result: 499950000
lambda call elapsed: 	22584 nanoseconds.
*/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ここに2つのモード、普通の関数とラムダ関数が増えましたが、インターフェースコールバック方式と直接呼び出しの比較、パフォーマンス損失は桁違いの差異があります。ラムダ関数の性能は関数に近く、場合によってはラムダ関数の性能の方が優れています。コンパイラ原理に関しては知識の空白ですが、推測ではアクセスする変数のアドレスと関数が隣接しているため、CPU処理に有利であると考えられます。&lt;/p&gt;
&lt;p&gt;添付した &lt;code&gt;wandbox&lt;/code&gt; の実行結果&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;result: 499950000
virtual call elapsed: 6143 nanoseconds.

result: 499950000
direct function call elapsed: 30 nanoseconds.

result: 499950000
functor call elapsed: 31 nanoseconds.

result: 499950000
lambda call elapsed: 15134 nanoseconds.
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>ホストオーダー、ネットワークオーダー。デバッガーで直接観察。</title>
        <link>https://ttf248.life/ja/p/host-order-network-order-debugger-observation/</link>
        <pubDate>Tue, 10 Jan 2023 14:18:12 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/host-order-network-order-debugger-observation/</guid>
        <description>&lt;p&gt;コンピュータの発展史の中で、データをどのように保存するかという統一された基準はありませんでした。&lt;/p&gt;
&lt;p&gt;バイトの配置には、2つの一般的な規則があります。例えば、多桁数の下位を小さいアドレスに、上位を大きいアドレスに配置する場合をリトルエンディアンと呼び、その逆をビッグエンディアンと呼びます。ネットワークアプリケーションでは、異なるマシンタイプが異なる標準のエンディアンを採用する可能性があるため、バイトオーダーは考慮すべき要素であり、すべてネットワーク標準に変換されます。&lt;/p&gt;
&lt;p&gt;読み方の習慣に則して、ビッグエンディアンのバイトオーダーは左から右への読書順に合致する。&lt;/p&gt;
&lt;h2 id=&#34;プロセッサアーキテクチャ&#34;&gt;プロセッサアーキテクチャ
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;x86、MOS Technology 6502、Z80、VAX、PDP-11などのプロセッサはリトルエンディアンです。&lt;/li&gt;
&lt;li&gt;モトローラ6800、モトローラ68000、PowerPC 970などのプロセッサは大Endianです。&lt;/li&gt;
&lt;li&gt;ARM、PowerPC（PowerPC 970を除く）、DEC Alpha、SPARC V9、MIPS、PA-RISCおよびIA64のバイトオーダーは構成可能です。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ネットワークまえがき&#34;&gt;ネットワークまえがき
&lt;/h2&gt;&lt;p&gt;ネットワーク転送では通常、ビッグエンディアンが採用され、ネットワークバイトオーダーまたはネットワーク順とも呼ばれます。IPプロトコルでは、ビッグエンディアンをネットワークバイトオーダーとして定義しています。
バークレーソケットは、ネットワークバイトオーダーとローカルバイトオーダーの間での16ビットおよび32ビット整数の変換を行うための変換関数群を定義しています。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;arpa/inet.h&amp;gt;

uint32_t htonl(uint32_t hostlong); //把uint32_t类型从主机序转换到网络序
uint16_t htons(uint16_t hostshort); //把uint16_t类型从主机序转换到网络序
uint32_t ntohl(uint32_t netlong); //把uint32_t类型从网络序转换到主机序
uint16_t ntohs(uint16_t netshort); //把uint16_t类型从网络序转换到主机序
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;もし&lt;code&gt;asio&lt;/code&gt;をネットワークライブラリとして選択した場合、組み込みのネームスペースにはクロスプラットフォーム対応の関数名が存在します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;boost::asio::detail::socket_ops::network_to_host_long&lt;/li&gt;
&lt;li&gt;boost::asio::detail::socket_ops::network_to_host_short&lt;/li&gt;
&lt;li&gt;boost::asio::detail::socket_ops::host_to_network_long&lt;/li&gt;
&lt;li&gt;boost::asio::detail::socket_ops::host_to_network_short&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ビジュアルスタジオ-デバッガー&#34;&gt;ビジュアルスタジオ デバッガー
&lt;/h2&gt;&lt;p&gt;デバッグモードで、デバッグメニューのウィンドウを選択し、メモリウィンドウにチェックを入れます。&lt;/p&gt;
&lt;p&gt;Visual Studio では、デバッガー内でメモリ内のデータを確認できます。以下のような図を参照してください。&lt;/p&gt;
&lt;p&gt;デバッグメニュー&lt;/p&gt;
&lt;h3 id=&#34;メモリの確認方法&#34;&gt;メモリの確認方法
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;ウィンドウで変数名を直接出力し、対応する変数のアドレスにジャンプします。&lt;/li&gt;
&lt;li&gt;もし変数が元々ポインタであれば、変数を選択し、メモリウィンドウにドラッグすると、そのアドレスの内容が表示されます。&lt;/li&gt;
&lt;li&gt;もし変数がポインタでない場合、計算ウィンドウに追加し、アドレスを取得後、手動でメモリウィンドウにコピーする。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;例えば&#34;&gt;例えば
&lt;/h3&gt;&lt;p&gt;データを受信し、&lt;code&gt;buffer&lt;/code&gt;オブジェクトに格納しました。ネットワークバイト順からホストバイト順に変換し、&lt;code&gt;body_length&lt;/code&gt;を30としました。サーバー側では、このデータを送信するために4バイトが割り当てられています。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;bool NetworkMessage::decode_header()
{
    // 网络序转成主机序
    body_length_ = boost::asio::detail::socket_ops::network_to_host_long(*(int *)buffer_.data());
    return auto_reserve(body_length_);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;ビッグエンディアン：メモリウィンドウで &lt;code&gt;buffer_&lt;/code&gt; の内容を観察する。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/host-order-network-order-debugger-observation/buffer_.png&#34;
	width=&#34;603&#34;
	height=&#34;318&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;buffer_&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;189&#34;
		data-flex-basis=&#34;455px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;リトルエンディアン：メモリウィンドウで &lt;code&gt;body_length_&lt;/code&gt; の内容を確認してください。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/host-order-network-order-debugger-observation/body_length_.png&#34;
	width=&#34;581&#34;
	height=&#34;333&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;body_length_&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;174&#34;
		data-flex-basis=&#34;418px&#34;
	
&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>C11: sleep for vs yield</title>
        <link>https://ttf248.life/ja/p/c11-sleep-for-vs-yield/</link>
        <pubDate>Tue, 20 Sep 2022 20:54:51 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/c11-sleep-for-vs-yield/</guid>
        <description>&lt;p&gt;コードを見返しているとき、&lt;code&gt;std::this_thread::yield()&lt;/code&gt;が突然目に飛び込んできた。&lt;code&gt;C11&lt;/code&gt;の文法糖化は結構使われているけど、&lt;code&gt;yield&lt;/code&gt;自体は初めて見かける。今まで気にしてなかった。&lt;/p&gt;
&lt;p&gt;マニュアルを確認する前に、最初に考えたのは非同期処理との関連性だった。「yield」がBoostライブラリのコルーチンの実装で使用されているため、ここではコルーチンとは関係ないだろう。制御ロジックは通常のスレッドに関連している。&lt;/p&gt;
&lt;h2 id=&#34;文書&#34;&gt;文書
&lt;/h2&gt;&lt;h3 id=&#34;yield&#34;&gt;yield
&lt;/h3&gt;&lt;p&gt;この関数の正確性は、実装に依存し、特に使用されているOSスケジューラメカニズムとシステムの状態に左右されます。例えば、先着順のリアルタイムスケジューラ（Linux の SCHED_FIFO ）は、現在のスレッドを中断し、同じ優先度のスレッドが実行可能になるキューの末尾に配置します（他のスレッドがない場合、yield は効果がありません）。&lt;/p&gt;
&lt;h3 id=&#34;sleep_for&#34;&gt;sleep_for
&lt;/h3&gt;&lt;p&gt;スレッドの実行をブロックし、指定されたsleep_duration時間だけ待機します。
この関数は、スケジューリングやリソースの競合が遅延させるため、sleep_durationよりも長い時間ブロックされる可能性があります。
標準ライブラリでは、安定したクロックで時間を計測することを推奨します。実装がシステム時間を使用する場合、待ち時間もクロック調整に影響される可能性があります。&lt;/p&gt;
&lt;h3 id=&#34;分析&#34;&gt;分析
&lt;/h3&gt;&lt;p&gt;二つの関数は、現在のスレッドがスレッドを占有しなくなるようにするもので、効果はプラットフォームによって異なるようですね。ここまでの説明だけではまだよく分からないので、コードを実行して実行結果を確認してみます。&lt;/p&gt;
&lt;p&gt;シンパッド ノートPC（Visual Studio Community Edition 2022）、テンセントクラウド S2 スタンダードサーバー（gcc8.5）&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;実行プラットフォーム&lt;/th&gt;
&lt;th&gt;関数&lt;/th&gt;
&lt;th&gt;初回/μs&lt;/th&gt;
&lt;th&gt;第2回/μs&lt;/th&gt;
&lt;th&gt;第3回/μs&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Windows&lt;/td&gt;
&lt;td&gt;sleep_for&lt;/td&gt;
&lt;td&gt;9872&lt;/td&gt;
&lt;td&gt;1884&lt;/td&gt;
&lt;td&gt;11302&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Windows&lt;/td&gt;
&lt;td&gt;yield&lt;/td&gt;
&lt;td&gt;119&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Linux&lt;/td&gt;
&lt;td&gt;sleep_for&lt;/td&gt;
&lt;td&gt;171&lt;/td&gt;
&lt;td&gt;168&lt;/td&gt;
&lt;td&gt;167&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Linux&lt;/td&gt;
&lt;td&gt;yield&lt;/td&gt;
&lt;td&gt;101&lt;/td&gt;
&lt;td&gt;102&lt;/td&gt;
&lt;td&gt;101&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;実行結果から容易に理解できるように、オペレーティングシステムの実現方法によって、高精度スリープの &lt;code&gt;sleep_for&lt;/code&gt; の安定性は大きく異なります。高精度なスリープが必要な場合は、 &lt;code&gt;yield&lt;/code&gt; の使用がより適切です。&lt;/p&gt;
&lt;p&gt;時間精度が&lt;code&gt;ms&lt;/code&gt;に向上しても、両者の差はそれほど顕著ではない。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;thread&amp;gt;
 
// 建议其他线程运行一小段时间的“忙睡眠”
void little_sleep(std::chrono::microseconds us)
{
    auto start = std::chrono::high_resolution_clock::now();
    auto end = start + us;
    do {
        std::this_thread::yield();
    } while (std::chrono::high_resolution_clock::now() &amp;lt; end);
}
 
int main()
{
    auto start = std::chrono::high_resolution_clock::now();
 
    little_sleep(std::chrono::microseconds(100));
    std::this_thread::sleep_for(std::chrono::microseconds(100));
 
    auto elapsed = std::chrono::high_resolution_clock::now() - start;
    std::cout &amp;lt;&amp;lt; &amp;quot;waited for &amp;quot;
              &amp;lt;&amp;lt; std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(elapsed).count()
              &amp;lt;&amp;lt; &amp;quot; microseconds\n&amp;quot;;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;参照&#34;&gt;参照
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Linuxサーバー、MySQLパスワードリセット</title>
        <link>https://ttf248.life/ja/p/linux-server-reset-mysql-password/</link>
        <pubDate>Tue, 20 Sep 2022 14:27:35 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/linux-server-reset-mysql-password/</guid>
        <description>&lt;p&gt;台に余っているテンセントクラウドのサーバーがあり、年末で契約が満了するので、更新する気もなく、開発用のデータベースとしてMySQLをデプロイしました。OSを再インストールした際、手間を省くため、テンセントクラウドが提供しているサードパーティ製のイメージを選択し、MySQLデータベースはすでにインストールされていました。システム内にReadmeのようなファイルがデフォルトで付属しているだろうと予想していたのですが、パスワードやデプロイメントパスなどが記載されていないようです。&lt;/p&gt;
&lt;p&gt;テンスンクラウドのシステムを再インストールすると、すぐに、1分くらいで再インストール完了の通知が来る。ログインして &lt;code&gt;systemctl status mysql&lt;/code&gt; サービスを確認すると起動している。パスワードはどこにあるか探したが見つからない。徐々に落ち込んでいく。&lt;/p&gt;
&lt;p&gt;そのように考えていると、すでにサーバーにアクセスし、&lt;code&gt;root&lt;/code&gt;権限を持っているのだから、きっとパスワードをリセットする方法はあるはずだ。資料を調べてみると、アリババクラウドのフォーラムに投稿があり、さらに試してみることにした。&lt;/p&gt;
&lt;h2 id=&#34;パスワードリセット&#34;&gt;パスワードリセット
&lt;/h2&gt;&lt;p&gt;設定ファイルを編集します。&lt;code&gt;vim /etc/my.cnf&lt;/code&gt;、&lt;code&gt;mysqld&lt;/code&gt;ノードに以下の設定を追加します。&lt;code&gt;skip-grant-tables&lt;/code&gt;、コマンドを実行してデータを再起動します。&lt;code&gt;systemctl restart mysql&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;再利用&lt;code&gt;mysql&lt;/code&gt;で直接データにログインし、あとは通常通り操作します。&lt;code&gt;root&lt;/code&gt;ユーザーのパスワードをリセットし、ついでにリモートログインを有効にします。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;USE mysql;
UPDATE user SET authentication_string = password (&#39;pass&#39;) WHERE User = &#39;root&#39;;
grant all privileges on *.* to &#39;root&#39;@&#39;%&#39; identified by &#39;pass&#39; with grant option;
flush privileges;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;設定ファイルを戻して変更し、データベースを再起動すれば大丈夫です。&lt;/p&gt;
&lt;h2 id=&#34;参照資料&#34;&gt;参照資料
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://help.aliyun.com/document_detail/42520.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://help.aliyun.com/document_detail/42520.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>自動テストの簡単な考察</title>
        <link>https://ttf248.life/ja/p/shallow-discussion-on-automation-testing/</link>
        <pubDate>Thu, 04 Aug 2022 11:39:18 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/shallow-discussion-on-automation-testing/</guid>
        <description>&lt;p&gt;金融取引システムにおけるテストへの投資は、他のシステムを大きく上回っており、煩雑なテスト手順が繰り返され、&lt;code&gt;ROI&lt;/code&gt; が低すぎる。プロジェクトや人員の交代に伴い、避けられない形で多くの制御不能な要因が導入され、よくあるのはAインターフェースの出力する特定のフィールドを変更した結果、Bインターフェースの結果に影響が出てしまうというケースだ。バージョンリリースごとにリスクも蓄積している。&lt;/p&gt;
&lt;h2 id=&#34;理論知識&#34;&gt;理論知識
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;自動化の価値をどのように測るか？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;自動化テストケースのROI = （手動実行時間）*（実行回数） / （開発コスト + メンテナンスコスト）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;どの機能を自動テストする必要がありますか？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ユーザーがよく使う機能、頻繁に変更されない機能。このタイプのインターフェースに対して自動テストコードを書くことで、最も効果が得られます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;なぜこのタイミングで自動テストを推進するのか。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;プロジェクトのリリースが近づいている時期では、明らかに不適切です。遠い水を近くの渇きを癒すことはできず、自動化は長期的な収益モデルです。プロジェクトはすでに&lt;strong&gt;本番環境&lt;/strong&gt;にリリースされ、安定したリリースサイクルに入っており、まさにこのタイミングが最適です。&lt;/p&gt;
&lt;h2 id=&#34;フレームの選択&#34;&gt;フレームの選択
&lt;/h2&gt;&lt;p&gt;関連する実践経験がないまま、自動テストというタスクを得て、典型的な始め方：検索エンジンを開いて、現在のシステム&lt;strong&gt;技術スタック&lt;/strong&gt;で利用できるツールやフレームワークを探し、マニュアルを一度通して、作業開始だ。すぐに適切なツールが見つかれば、おめでとうございます、&lt;strong&gt;完璧なスタート&lt;/strong&gt;です。&lt;/p&gt;
&lt;p&gt;先に謝罪いたします。関連資料を調べたところ、存在しないというわけではなく、単にフレームワーク自体が複雑で、デプロイに必要なリソースも多すぎるようです。初心者向けのものは小さくて簡潔なものが求められます。テストチームの同僚に相談したところ、&lt;code&gt;Python&lt;/code&gt; で自作のフレームワークを作るという提案があり、簡単に言うと、既存のユニットテストフレームワークを使い、自動テストフレームワークとしてパッケージ化するというものです。&lt;/p&gt;
&lt;p&gt;このプロジェクトのデザインのアイデアを参考にしてください：&lt;a class=&#34;link&#34; href=&#34;https://github.com/wintests/pytestDemo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/wintests/pytestDemo&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;フレームが必要な理由は何ですか&#34;&gt;フレームが必要な理由は何ですか？
&lt;/h2&gt;&lt;p&gt;サービスには複数の異なるデプロイ環境があり、開発環境、テスト環境、本番環境があります。フレームワークの役割は、これらの環境を分離し、テストケースとデータを切り離すことです。異なる環境ごとに異なるテストデータが設定されており、もちろん共通データもサポートしています。&lt;/p&gt;
&lt;p&gt;根本的なロジックは、自動化の活用率を向上させるためのものです。 シナリオがいくら複雑になっても、異なる環境間のデータは互換性がなく、全く関係ありません。 設定事例データを追加する際は、&lt;code&gt;label&lt;/code&gt;タグを追加して、現在のデータがサポートしている環境を指定してください。&lt;/p&gt;
&lt;h2 id=&#34;参照資料&#34;&gt;参照資料
&lt;/h2&gt;&lt;p&gt;最もコストパフォーマンスの高い自動テストをする&lt;/p&gt;</description>
        </item>
        <item>
        <title>新しい言語を学ぶ必要があるのはなぜか。</title>
        <link>https://ttf248.life/ja/p/why-learn-a-new-language/</link>
        <pubDate>Thu, 04 Aug 2022 11:27:30 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/why-learn-a-new-language/</guid>
        <description>&lt;p&gt;学校時代から数えても、すでに10年以上前からC++に触れているのに、他のプログラミング言語を学ぶ必要性がどこにあるのだろうか。&lt;/p&gt;
&lt;p&gt;仕事経験：エレガントなモジュール設計の経験は乏しいが、&lt;code&gt;C++&lt;/code&gt; の文法は自由度が高く、他の言語を学ぶことでよりエレガントな設計を書けるようになる。&lt;/p&gt;
&lt;p&gt;ツールを開発するときに、よく使う。&lt;/p&gt;
&lt;p&gt;基盤ライブラリの設計も、ビジネスモジュールの実装も、設計の原則は同じです。&lt;/p&gt;</description>
        </item>
        <item>
        <title>ビジュアルスタジオのコンパイル文字セット[転]</title>
        <link>https://ttf248.life/ja/p/visual-studio-compilation-character-set-translation/</link>
        <pubDate>Thu, 04 Aug 2022 10:51:43 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/visual-studio-compilation-character-set-translation/</guid>
        <description>&lt;p&gt;C++のクロスプラットフォーム開発で、中国語OSではよく「エラーC2001 定数に改行が含まれています」という問題に遭遇することがあります。&lt;/p&gt;
&lt;h2 id=&#34;visual-studio&#34;&gt;visual studio
&lt;/h2&gt;&lt;p&gt;CMakeはプロジェクトのビルドスクリプトを構成し、Windowsシステムでの開発時に一時的にソリューションファイルを生成します。プラットフォーム間の互換性のために、ファイルエンコーディングはUTF-8を選択しています。&lt;/p&gt;
&lt;p&gt;参照資料は、原因を詳細に説明するために、原理から出発して解説している。&lt;/p&gt;
&lt;p&gt;コーディングに関して、&lt;code&gt;MSVC&lt;/code&gt;には専用のコンパイルオプション&lt;code&gt;/source-charset&lt;/code&gt;と&lt;code&gt;/execution-charset&lt;/code&gt;があり、前者はファイルのエンコードを表し、後者はコンパイル後の文字配列内のバイトがどのようなエンコードであるかを示すもので、これらのオプションでエンコードの問題を基本的に解決できます。&lt;/p&gt;
&lt;p&gt;例えば、&lt;code&gt;windows&lt;/code&gt;の&lt;code&gt;cmd&lt;/code&gt;コンソールはデフォルトでは&lt;code&gt;GBK&lt;/code&gt;エンコーディングしか表示できないが、コードファイル自体は&lt;code&gt;UTF-8&lt;/code&gt;であるため、プラットフォーム間の互換性の問題で直接&lt;code&gt;GBK&lt;/code&gt;に変換するのが都合悪い。もちろん、ここでは異なるプラットフォーム向けにエンコーディング変換コードを書くという方法論は含めない。&lt;code&gt;Win10&lt;/code&gt;では、コンパイラオプションを&lt;code&gt;/source-charset:utf-8 /execution-charset:gbk&lt;/code&gt;に設定することで、コンパイラが&lt;code&gt;UTF-8&lt;/code&gt;エンコーディングでファイルを読み込み、それを&lt;code&gt;GBK&lt;/code&gt;に変換して配列内に保存し、その結果、&lt;code&gt;printf&lt;/code&gt;を使って&lt;code&gt;cmd&lt;/code&gt;コンソール上で漢字を正常に表示できる。&lt;/p&gt;
&lt;h2 id=&#34;cmake-visual-studio-設定&#34;&gt;CMake Visual Studio 設定
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cmake&#34;&gt;if( WIN32 )
    message( STATUS &amp;quot;Configuring trade on WIN32&amp;quot;)
    set( CMAKE_CXX_FLAGS &amp;quot;${CMAKE_CXX_FLAGS} /source-charset:utf-8 /execution-charset:gbk&amp;quot;)
endif()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;参照資料&#34;&gt;参照資料
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/146543940&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://zhuanlan.zhihu.com/p/146543940&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Windows プラットフォームでのフォルダサイズ高速統計</title>
        <link>https://ttf248.life/ja/p/windows-platform-quick-folder-size-statistics/</link>
        <pubDate>Mon, 01 Aug 2022 19:54:18 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/windows-platform-quick-folder-size-statistics/</guid>
        <description>&lt;p&gt;Linux プラットフォームなら簡単です。「du -sh *」たった一行のコードで終わります。Windows はどうでしょうか？ディスクがたくさんあって、整理したいとき、ファイルが大量にある場合、標準のリソースエクスプローラーではフォルダサイズを統計的に算出するのも遅くて、諦めたくなります。&lt;/p&gt;
&lt;h2 id=&#34;everything&#34;&gt;Everything
&lt;/h2&gt;&lt;p&gt;Windows プラットフォームで開発をしている方なら、自分で使ったことがなくても、友人から聞いたことがあるはずです。「Everything」は、標準のファイルエクスプローラーを大きく上回る検索速度を誇ります。システムレベルでファイルの高速インデックスがサポートされているのであれば、同様のツールを見つけて、ファイルのインデックスを作成すると同時に、ファイルサイズも統計的に把握できるはずです。&lt;/p&gt;
&lt;h2 id=&#34;wiztree&#34;&gt;WizTree
&lt;/h2&gt;&lt;p&gt;公式サイト：&lt;a class=&#34;link&#34; href=&#34;https://www.diskanalyzer.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.diskanalyzer.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;標準的なインストールモードまたはグリーン版の展開実行&lt;/p&gt;
&lt;p&gt;高速で、データ表示の種類が豊富です。左側はツリー図モード、右側はファイルタイプで、もちろんグラフィカルな表示もあり、ソフトウェアの最下部にあります。&lt;/p&gt;
&lt;h2 id=&#34;spacesnifferアップデート2023でサポート終了&#34;&gt;SpaceSniffer（アップデート2023でサポート終了）
&lt;/h2&gt;&lt;p&gt;ソフトウェア公式サイト：&lt;a class=&#34;link&#34; href=&#34;http://www.uderzo.it/main_products/space_sniffer/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://www.uderzo.it/main_products/space_sniffer/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;操作は簡単です。対応するディスクを選択すると、ソフトウェアがグラフィカルにフォルダの容量を表示します。容量が大きいほど、画像内のマトリックスも大きくなります。その他の操作は、クリックすれば理解できるはずです。ファイルに対して条件フィルタリングをサポートしています。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ファイルサイズフィルタ&lt;/li&gt;
&lt;li&gt;書類の日付フィルタ&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;基本の使い方&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;高度な使い方&lt;/p&gt;
&lt;h2 id=&#34;参照資料&#34;&gt;参照資料
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://moe.best/software/spacesniffer.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://moe.best/software/spacesniffer.html&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>ウェブページのスタイルシート（CSS）をコピーする方法：要素の検査</title>
        <link>https://ttf248.life/ja/p/how-to-copy-webpage-css-element-inspection/</link>
        <pubDate>Sun, 31 Jul 2022 23:36:48 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/how-to-copy-webpage-css-element-inspection/</guid>
        <description>&lt;p&gt;海外のテンプレートをベースにして修正・調整するものが主流で、中国語コンテンツのレイアウトについてはあまり考慮されていない。&lt;/p&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文
&lt;/h2&gt;&lt;p&gt;半月ほど前にブログのスタイルシートを調整しました。長年バックエンドサービスの開発をしていて、フロントエンドは初心者です。色々試しましたが、デザインがよくわかりません。ふと、いつも参考にしている技術ブログ：infoq、开源中国のようなサイトのデザインはとても良いなと思い、もし借用できるだろうかと考えました。しばらくソースコードを見ましたが、関連要素を特定してしまい、混乱しました。&lt;/p&gt;
&lt;p&gt;ここにいるフロントエンドエンジニアは、ここまで読んで笑っているかもしれませんね…指定の要素を特定することさえわからない。わからなくても大丈夫です。週末に時間があるので、立ち止まって考えてみましょう。昔、Pythonでスクレイピングしていたときには、似たようなものを使ったような気がします。&lt;/p&gt;
&lt;h3 id=&#34;元素審査&#34;&gt;元素審査
&lt;/h3&gt;&lt;p&gt;その通りです。ブラウザに標準搭載されている要素検査ツールを使えば、スタイルシートのコピーや特定要素の位置特定もあっという間にできます。&lt;code&gt;selector&lt;/code&gt; で要素を特定し、&lt;code&gt;hugo&lt;/code&gt; で &lt;code&gt;user define css&lt;/code&gt; を作成します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;要素を複製する&lt;/li&gt;
&lt;li&gt;outerHTMLをコピーする&lt;/li&gt;
&lt;li&gt;セレクタを複製&lt;/li&gt;
&lt;li&gt;JS パスをコピーする&lt;/li&gt;
&lt;li&gt;スタイルを複製する&lt;/li&gt;
&lt;li&gt;XPathをコピー&lt;/li&gt;
&lt;li&gt;XPathを完全にコピーします。&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Windowsプラットフォーム向け、巨大ファイルの編集：EmEditor（テキストエディタ）</title>
        <link>https://ttf248.life/ja/p/windows-platform-editing-large-files-emeditor-text-editor/</link>
        <pubDate>Sun, 31 Jul 2022 23:21:24 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/windows-platform-editing-large-files-emeditor-text-editor/</guid>
        <description>&lt;p&gt;上海国安データベース事件は、ハッカー界隈で騒がしくなっているが、真偽は定かではない。2年後も覚えていれば、また振り返ってみよう。過去の経験から、ローカルの社会員データベース資料を更新したところ、巨大なSQLファイル：17.9Gを発見した。普通のテキストエディタではプレビューですら問題があり、ましてや開くことなどできない。ネットユーザーとの雑談で：EmEditorという名前が出てきた。&lt;/p&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文
&lt;/h2&gt;&lt;p&gt;公式サイト：&lt;a class=&#34;link&#34; href=&#34;https://www.emeditor.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.emeditor.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;週末に時間を作って試してみたところ、なかなか便利だった。デザインも大規模ファイルの編集に対応していて、メモリが十分な場合、ファイル全体をメモリに読み込めるので、検索や編集の速度も速いし、ファイルの分割にも対応している。&lt;/p&gt;</description>
        </item>
        <item>
        <title>思ったより簡単なことだが、コードコピーボタンを追加する。</title>
        <link>https://ttf248.life/ja/p/add-code-copy-button/</link>
        <pubDate>Fri, 25 Feb 2022 01:23:39 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/add-code-copy-button/</guid>
        <description>&lt;p&gt;四時間も格闘して、この文を見たときは笑ってしまった。こんなに時間がかかるなんてありえないと思ったのに。よく見たら三時間だった。&lt;/p&gt;
&lt;p&gt;算是二零二二年開年の第一篇稿子，要搞的東西不複雜，就和標題說的一模一樣（此時的我還很年輕），以為照抄 &lt;a class=&#34;link&#34; href=&#34;https://ouuan.github.io/post/from-hexo-to-hugo/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;作業&lt;/a&gt; 就行，放到收藏夾裡面，拖拖拉拉等了一個多月，終於想起來這件事情。 算是二零二年年初的第一篇文章，要搞的東西不複雜，和標題完全一樣（當時的我還很年輕），以為照抄&lt;a class=&#34;link&#34; href=&#34;https://ouuan.github.io/post/from-hexo-to-hugo/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;作業&lt;/a&gt;就夠了，放進收藏夾裡，拖拖拉拉等了一個多月，終於想起來這件事。&lt;/p&gt;
&lt;p&gt;Hugoに移行したときから、プラグインが少なすぎると感じていました。コードのコピー＆ペーストができず、多くのノートを印象ノートからブログへ移行する際に、コードのコピーに関する作業が煩雑になり、ブログを書くモチベーションを著しく損ねてしまいました。&lt;/p&gt;
&lt;h2 id=&#34;前章&#34;&gt;前章
&lt;/h2&gt;&lt;p&gt;まずは原著者の稿をよく見て、一度通読してから作者紹介を見てみよう。うわー、すごい人だ。清華大学の在校生で、早い段階からコンピュータに触れている。あー、なんとなく、まずこのブログを見てみよう。完全に何をしようとしていたか思い出せない。ついでに作者の&lt;code&gt;Github&lt;/code&gt;リポジトリも見てみよう。この修正された&lt;code&gt;even&lt;/code&gt;テーマは今のものよりずっといいし、機能も多い。やってみるか。まずは関連コードをマージしてしまおう。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/add-code-copy-button/2022-02-25-02-08-19.png&#34;
	width=&#34;215&#34;
	height=&#34;150&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;143&#34;
		data-flex-basis=&#34;344px&#34;
	
&gt; &lt;img src=&#34;https://ttf248.life/p/add-code-copy-button/2022-02-25-02-08-40.png&#34;
	width=&#34;217&#34;
	height=&#34;167&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;129&#34;
		data-flex-basis=&#34;311px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;新機能記事履歴の確認関連提出記録の閲覧&#34;&gt;新機能：記事履歴の確認、関連提出記録の閲覧
&lt;/h3&gt;&lt;p&gt;効果はまだ良いです、記事の最後に引っ張れば体験できます。&lt;/p&gt;
&lt;p&gt;手を出す前に作者の元のリポジトリの履歴を細かく見ていなかった、単純なマージで済むだろうと思っていた。結局、大量のコードをマージしてしまい、途中で何度もコンフリクトが発生し、無駄に上書きしてしまった。すべてはフロントエンドとレンダリングのテンプレートコードで、私の望むものが優先された。&lt;/p&gt;
&lt;p&gt;倉庫アドレス：&lt;a class=&#34;link&#34; href=&#34;https://github.com/TianlongXiang/hugo-theme-even&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/TianlongXiang/hugo-theme-even&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;中国の一つの落とし穴ですが、&lt;code&gt;git&lt;/code&gt;でこのパラメータを調整しないと、現在の記事の&lt;code&gt;コミットハッシュ&lt;/code&gt;が取得できず、過去のリンクの生成に失敗します。完全な記事履歴を生成する際も、自動統合スクリプトを変更する必要があり、現在のリポジトリ全体の履歴レコードを必ずプルしてください。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;機能：完全なGitHubリポジトリの取得を試み、記事の最終更新記録を動的に更新する&lt;/li&gt;
&lt;li&gt;パスが存在する中国語です。HugoのGitInfoの設定を有効にする必要があります。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;name: Build Github
run: git config --global core.quotePath false &amp;amp;&amp;amp; hugo -b &amp;quot;https://www.xiangtianlong.com/&amp;quot; -d &amp;quot;github_public&amp;quot; &amp;amp;&amp;amp; ls
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;スタイル調整&#34;&gt;スタイル調整
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;サイトコンテンツの幅を調整する。以前のデザインはモバイルとPC向けだったが、実際には誰もスマホで見ていないし、私もPCで見ている。&lt;/li&gt;
&lt;li&gt;目次バーは自動伸縮に対応しています。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文
&lt;/h2&gt;&lt;p&gt;参照 &lt;code&gt;ouuan&lt;/code&gt; のコード記録を半時間以上見ていても、どうやってコピーボタンを追加しているのかよくわからなかった。&lt;/p&gt;
&lt;p&gt;時間が過ぎて、一ヶ月後、またこのことを思い出した。&lt;/p&gt;
&lt;p&gt;既然この課題が理解できないなら、別の課題を写し転がせば、なんとかなるだろう。検索した結果は結構意外だった。&lt;code&gt;hugo&lt;/code&gt;の公式フォーラムにもコピーボタンを追加する方法についての投稿があったので行ってみると、論理は明確だった。そして、驚いたことに、再現されたコードブロックのスタイルが資料の説明と異なっていた。このあたりは少し面倒なので、簡単に記録しておく。&lt;/p&gt;
&lt;p&gt;基本的なフロントエンド開発がほとんど分からないので、分からない箇所はブラウザの「要素を検証」を開き、コードと右側のスタイル情報を見て、少しずつ論理を理解しました。「JavaScript」は理解できませんでしたが、コンソールにログを出力しました。分からないことはたくさんありましたが、落ち着いてゆっくりと論理を整理・分解することで、必ず解決策が見つかります。&lt;/p&gt;
&lt;p&gt;プレタグが複数あり、ここでは単一のコードブロックを指しますが、テーマ自体が行番号を出力しているため、コピーボタンが2つ表示されるようになります。
コードハイライトのレンダリングをテーマに組み込みたいのだが、このテーマの設定がよくわからない。
Hugoの公式サイトで資料を見たところ、半分くらい理解できた。コードハイライトを制御できる&lt;code&gt;markup&lt;/code&gt;設定があることは分かった。
設定ファイルを調整しても、どうにもうまくいかず、レンダリング結果が期待と異なっている。
この設定&lt;code&gt;pygmentsOptions&lt;/code&gt;の山をいくつか見つけたので、さらに資料を調べ、設定を調整する。とりあえず行番号は取り除く。
カスタムの&lt;code&gt;css&lt;/code&gt;スタイルシートとカスタムの&lt;code&gt;js&lt;/code&gt;スクリプトを設定します。
色々やらかしてしまったので、ふと最近見た配色図が良さそうだなと思い、ボタンのスタイルを少し変更してみることに。中国風の天青色でやってみるか。&lt;/p&gt;
&lt;img class=&#34;special-img-class&#34; style=&#34;width:20%&#34; src=&#34;2022-02-25-02-01-22.png&#34; /&gt;
&lt;img class=&#34;special-img-class&#34; style=&#34;width:20%&#34; src=&#34;2022-02-25-02-01-33.png&#34; /&gt;
&lt;p&gt;四時間かけてやったのに、この文を見たときは笑ってしまった。こんなに時間がかかるなんてありえないと思った。でもよく見たら三時間だった。&lt;/p&gt;
&lt;h2 id=&#34;参照リンク&#34;&gt;参照リンク
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://ouuan.github.io/post/from-hexo-to-hugo/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ouuan.github.io/post/from-hexo-to-hugo/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://gohugobrasil.netlify.app/content-management/syntax-highlighting/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://gohugobrasil.netlify.app/content-management/syntax-highlighting/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://gohugo.io/getting-started/configuration-markup#highlight&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://gohugo.io/getting-started/configuration-markup#highlight&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.dannyguo.com/blog/how-to-add-copy-to-clipboard-buttons-to-code-blocks-in-hugo/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.dannyguo.com/blog/how-to-add-copy-to-clipboard-buttons-to-code-blocks-in-hugo/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>カオスエンジニアリング</title>
        <link>https://ttf248.life/ja/p/chaos-engineering/</link>
        <pubDate>Wed, 28 Jul 2021 14:35:07 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/chaos-engineering/</guid>
        <description>&lt;p&gt;システムを破壊するパターン、システム安定性テストを行う&lt;/p&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文
&lt;/h2&gt;&lt;p&gt;国内のインターネット業界はいつも何か新しいものを生み出したがるので、時々名前を聞いて、それが何なのか全く想像できないことがある。&lt;/p&gt;
&lt;p&gt;記事の一部を読んだのですが、カオスエンジニアリング初期の定義に関する記述が一番受け入れやすいです。&lt;/p&gt;
&lt;p&gt;カオスエンジニアリングの初期的な探求は、業界では以前から存在しており、障害テストやディザスタリカバリー演習といった形で存在していました。しかし、マイクロサービスアーキテクチャの発展と分散システムの拡大に伴い、カオスエンジニアリングはその頭角を現し始め、ますます重視されるようになりました。Netflixが正式にカオスエンジニアリングの概念を提起したことで、関連理論も急速に豊かになり、Netflixの実践は、安定性という分野におけるカオスエンジニアリングの大きな意義を証明しました。&lt;/p&gt;
&lt;h2 id=&#34;参照リンク&#34;&gt;参照リンク
&lt;/h2&gt;&lt;p&gt;バイトダンスの混沌エンジニアリング実践まとめ&lt;/p&gt;</description>
        </item>
        <item>
        <title>Kubernetesポッドの一時停止</title>
        <link>https://ttf248.life/ja/p/kubernetes-pause-pod/</link>
        <pubDate>Mon, 12 Jul 2021 11:23:09 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/kubernetes-pause-pod/</guid>
        <description>&lt;p&gt;デプロイメントコントローラーは、Kubernetesクラスタにおいて非常に重要な機能である、Podの水平的な拡張と縮小機能を実装しています。この機能は、従来のクラウド時代プラットフォームにとって不可欠な能力です。&lt;/p&gt;
&lt;p&gt;業務シーンで、データベース内のデータを修正し、調整後にPodノードを再起動する必要がある。しかし、Podの実行中にテーブルのフィールドをずっと変更しており、一時的にアプリケーションへのテーブル更新を停止し、データを調整した後、Podを復旧させる必要がある。&lt;/p&gt;
&lt;p&gt;暴力削除のデプロイメント以外に、同様の効果を実装する方法はありますか？&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubectl scale --replicas=0 deployment/&amp;lt;your-deployment&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;答えを見て初めて、多くの人は思いもよらなかったでしょう。答えを見ると、思わず微笑み、頭がなかなか回らず、まだプロセスを直接操作する時代に思考が留まっている。直接ビジネスプロセスを操作しようとするのです。&lt;/p&gt;
&lt;h2 id=&#34;参照リンク&#34;&gt;参照リンク
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://stackoverflow.com/questions/54821044/how-to-stop-pause-a-pod-in-kubernetes&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;how to stop/pause a pod in kubernetes&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>Dockerの豆知識</title>
        <link>https://ttf248.life/ja/p/docker-two-three-things/</link>
        <pubDate>Thu, 21 Jan 2021 09:26:07 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/docker-two-three-things/</guid>
        <description>&lt;p&gt;長年作業で触れてきたのは&lt;code&gt;CentOS&lt;/code&gt;オペレーティングシステムばかりなので、もし&lt;code&gt;Mac&lt;/code&gt;ユーザーや&lt;code&gt;Ubuntu&lt;/code&gt;ユーザーであれば、一部の内容が適用できない場合があります。&lt;/p&gt;
&lt;p&gt;インストール手順については、清華大学のマニュアルを参照してください：[https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/]&lt;/p&gt;
&lt;h2 id=&#34;設置&#34;&gt;設置
&lt;/h2&gt;&lt;p&gt;未知な神秘的な力により、ローカルにDockerをインストールする際は、クラウドプロバイダーが提供するリポジトリのアドレスを設定することを推奨します。ここでは&lt;strong&gt;アリババクラウド&lt;/strong&gt;の使用をお勧めします。&lt;/p&gt;
&lt;h3 id=&#34;倉庫ソースアドレスを設定する&#34;&gt;倉庫ソースアドレスを設定する
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum install yum-utils device-mapper-persistent-data lvm2 &amp;amp;&amp;amp; \
sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;部署最新バージョン&#34;&gt;部署最新バージョン
&lt;/h3&gt;&lt;p&gt;Dockerはよく使用されるバックグラウンドサービスなので、推奨としては起動時に自動的に開始するように設定し、現在のコマンドはCentOS 7に適用されます。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo yum install -y docker-ce docker-ce-cli containerd.io &amp;amp;&amp;amp; systemctl enable --now docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;部門指定バージョン&#34;&gt;部門指定バージョン
&lt;/h3&gt;&lt;p&gt;KubernetesとDockerのリリースは完全に同期していないため、次にKubernetesをデプロイする場合は、Kubernetesのデプロイ手順を参照し、指定されたバージョンのDockerをインストールしてください。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum list docker-ce --showduplicates | sort -r
sudo yum install -y docker-ce-18.09.2-3.el7 docker-ce-cli-18.09.2-3.el7 containerd.io-18.09.2-3.el7 &amp;amp;&amp;amp; systemctl enable --now docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;通常ユーザーにdocker権限を追加する&#34;&gt;通常ユーザーにDocker権限を追加する
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo usermod -aG docker ${USER}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;アンインストール&#34;&gt;アンインストール
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo yum erase -y docker-ce docker-ce-cli containerd.io
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;日常利用&#34;&gt;日常利用
&lt;/h2&gt;&lt;h3 id=&#34;ミラーアクセラレーション&#34;&gt;ミラーアクセラレーション
&lt;/h3&gt;&lt;p&gt;依然未知な神秘的な力が存在するせいで、イメージの引き出しがうまくいかないことがあります。そこで、国内のクラウドベンダーが多くのアクセラレーションサービスを提供してくれました。やはり&lt;strong&gt;阿里云&lt;/strong&gt;をおすすめします。&lt;/p&gt;
&lt;p&gt;加速されたアドレスは、ご自身でアカウントを登録してAliyun（アリババクラウド）から入手してください。このサービスは無料で、Aliyunは無料のイメージ構築サービスも提供しています。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cat &amp;gt; /etc/docker/daemon.json &amp;lt;&amp;lt;EOF
{
  &amp;quot;registry-mirrors&amp;quot;: [
    &amp;quot;https://docker.nju.edu.cn&amp;quot;,
    &amp;quot;https://mirror.baidubce.com&amp;quot;,
    &amp;quot;https://docker.m.daocloud.io&amp;quot;,
    &amp;quot;https://docker.mirrors.sjtug.sjtu.edu.cn&amp;quot;
  ]
}
EOF
systemctl daemon-reload &amp;amp;&amp;amp; \
systemctl restart docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;強く推奨されるコントロールパネル&#34;&gt;強く推奨されるコントロールパネル
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker volume create portainer_data &amp;amp;&amp;amp; \
docker run -d --name=portainer --restart=always -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:2.20.3-alpine
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;よく使うミラーの引き出しまとめ&#34;&gt;よく使うミラーの引き出しまとめ
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker pull rancher/rancher:stable &amp;amp;&amp;amp; docker pull  portainer/portainer-ce:2.0.1 &amp;amp;&amp;amp; \
docker pull centos:7 &amp;amp;&amp;amp; docker pull ubuntu:20.04 &amp;amp;&amp;amp; docker pull ubuntu:18.04 &amp;amp;&amp;amp; \
docker pull redis:5 &amp;amp;&amp;amp; docker pull redis:6 &amp;amp;&amp;amp; \
docker pull alpine:3.11 &amp;amp;&amp;amp; docker pull busybox:1.32 &amp;amp;&amp;amp; \
docker pull rabbitmq:3.7-management &amp;amp;&amp;amp; \
docker pull mariadb:10.2 &amp;amp;&amp;amp; \
docker pull nginx:1.18 &amp;amp;&amp;amp; docker pull nginx:1.19 &amp;amp;&amp;amp; \
docker pull mysql:5.6 &amp;amp;&amp;amp; docker pull mysql:8 &amp;amp;&amp;amp; \
docker pull elasticsearch:6.8.11 &amp;amp;&amp;amp; docker pull logstash:6.8.11 &amp;amp;&amp;amp; docker pull kibana:6.8.11 &amp;amp;&amp;amp; \
docker pull zookeeper:3.4 &amp;amp;&amp;amp; \
docker pull influxdb:1.7 &amp;amp;&amp;amp; docker pull grafana/grafana:7.3.1 &amp;amp;&amp;amp; \
docker pull percona:8 &amp;amp;&amp;amp; docker pull percona:5.6 &amp;amp;&amp;amp; \
docker pull cloverzrg/frps-docker:0.34.3 &amp;amp;&amp;amp; docker pull cloverzrg/frpc-docker:0.34.3
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;よく使うコマンドの組み合わせ&#34;&gt;よく使うコマンドの組み合わせ
&lt;/h3&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.docker.com/engine/reference/commandline/docker/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://docs.docker.com/engine/reference/commandline/docker/&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;コンテナの実行状態を確認し、&lt;code&gt;format&lt;/code&gt;パラメータを追加して詳細なコンテナ情報を確認します。この際、イメージ情報は気にしません。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker ps --format &amp;quot;{{.Names}}: {{.Ports}}: {{.Size}}&amp;quot;
#portainer: 0.0.0.0:8000-&amp;gt;8000/tcp, 0.0.0.0:9000-&amp;gt;9000/tcp: 0B (virtual 172MB)
#influxdb: 0.0.0.0:8086-&amp;gt;8086/tcp: 183B (virtual 311MB)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;全コンテナを停止&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker stop $(docker ps -a -q)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ワンクリックですべてのイメージを削除します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;dokcer rmi $(docker images -a -q)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;イメージエクスポート&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker save &amp;lt;IMAGE NAME&amp;gt;:&amp;lt;IMAGE TAG&amp;gt; &amp;gt; -o XXX.tar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;イメージをエクスポートして圧縮する&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker save &amp;lt;IMAGE NAME&amp;gt;:&amp;lt;IMAGE TAG&amp;gt; | gzip &amp;gt; XXX.tar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;イメージのインポート&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker load -i XXX.tar
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>LinuxでJMeterテスト環境を構築する</title>
        <link>https://ttf248.life/ja/p/linux-setup-jmeter-testing-environment/</link>
        <pubDate>Tue, 22 Dec 2020 10:12:50 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/linux-setup-jmeter-testing-environment/</guid>
        <description>&lt;p&gt;著者はハードウェアに強い興味を持ち、Jmeterを用いて負荷テストを実施し、CentOS 7上にJmeter、InfluxDB、Grafanaをデプロイした過程を記録した。Jmeterのインストールとコマンドの使用方法、InfluxDBの特徴とDockerのインストール方法、そしてGrafanaの簡単なデプロイと設定について共有している。高性能プログラムのパターンに関する経験と参考文献をまとめた。&lt;/p&gt;
&lt;h2 id=&#34;背景&#34;&gt;背景
&lt;/h2&gt;&lt;p&gt;周知の通り、私はハードウェアに強い興味があります。たまたまテストチームがJmeterでパフォーマンステストを行っているところを見かけ、性能が上がらないというので、好奇心旺盛な私が早速乗り出し、会社のパフォーマンステストを試してみることにしました。 ここでちょっとしたエピソードがあります。ある昔のことですが、OSC（开源中国）で記事を拝見し、より高尚に見えるパフォーマンステストのグラフを描く方法について学んだことがあります。Windows版のテストを実行しているところを見学し、TPSデータを可視化するまで来ています。それに加えてWebパネルを設定することにどのようなメリットがあるのでしょうか？&lt;/p&gt;
&lt;p&gt;考えたことがすべて思い込みで、試してみないとわからない。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Don&amp;rsquo;t use GUI mode for load testing! only for Test creation and Test debuggin.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;公式的には、コマンドラインで結果を取得し、GUIで表示する方法ではデータの誤差が生じる可能性があるとのことです。JMeterについてはあまり詳しくないのですが、せめてLinux版のコンソールパネルを試してみる理由にはなります。&lt;/p&gt;
&lt;p&gt;オープンソース中国のフォーラムでの投稿ですが、主要コンポーネントのデプロイメントは友好的ではありません。必要なファイルも公众号をフォローしないとダウンロードできないので、新しい世代として当然Dockerで代替しました。結局のところ、自分のサーバーが国内にあること、そしてクロスボーダーのソースアドレスへのアクセス速度が非常に遅いことが原因です。少なくともイメージサービスに関しては、アリババクラウドには無料のアクセラレーションがあります。&lt;/p&gt;
&lt;p&gt;Dockerのインストールとデプロイについては、ここでは詳細を述べません。以前の記事をご参照ください。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;今後の内容は大きく分けて二つです。基本的なテスト環境コンポーネントの構築と、各コンポーネントの簡単な説明。&lt;/p&gt;
&lt;h2 id=&#34;jmeter&#34;&gt;Jmeter
&lt;/h2&gt;&lt;p&gt;Apache JMeterは、Apache Foundationが開発したJavaベースの負荷テストツールです。ソフトウェアの負荷テストに用いられ、当初はWebアプリケーションのテスト用に設計されましたが、その後他のテスト分野にも拡張されています。静的なリソースや動的なリソースなど、さまざまなものをテストできます。例えば、静的ファイル、Javaマイクロサービス、CGIスクリプト、Javaオブジェクト、データベース、FTPサーバーなどです。JMeterは、サーバー、ネットワーク、またはオブジェクトに対して巨大な負荷をシミュレートし、さまざまなプレッシャーカテゴリー下での強度をテストし、全体的なパフォーマンスを分析するために使用できます。また、アサーションを含むスクリプトを作成することで、アプリケーションの機能/回帰テストを行い、プログラムが期待される結果を返すことを検証できます。最大限の柔軟性を実現するため、JMeterは正規表現を使用してアサーションを作成することを許可しています。&lt;/p&gt;
&lt;p&gt;Apache JMeterは、静的なリソースと動的なリソース（ファイル、サーブレット、Perlスクリプト、Javaオブジェクト、データベースおよびクエリ、FTPサーバーなど）のパフォーマンスをテストするために使用できます。サーバー、ネットワーク、またはオブジェクトに過剰な負荷をかけて強度をテストしたり、さまざまな種類のプレッシャー下での全体的なパフォーマンスを分析したりすることができます。パフォーマンスのグラフ解析や、高並行負荷テストでサーバー/スクリプト/オブジェクトを使用することも可能です。&lt;/p&gt;
&lt;h3 id=&#34;jmeter-部署-centos7&#34;&gt;JMeter 部署 CentOS7
&lt;/h3&gt;&lt;p&gt;JDKランタイム環境をインストールし、Jmeterのインストーラパッケージをダウンロードする。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum install java-1.8.0-openjdk -y &amp;amp;&amp;amp; \
wget https://mirrors.bfsu.edu.cn/apache//jmeter/binaries/apache-jmeter-5.4.tgz &amp;amp;&amp;amp; tar -xf apache-jmeter-5.4.tgz
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;環境変数を設定する&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export JMETER_HOME=$HOME/jmeter/apache-jmeter-5.4
export PATH=$JMETER_HOME/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;jmeter-コマンド&#34;&gt;JMeter コマンド
&lt;/h3&gt;&lt;p&gt;最後に&lt;code&gt;Grafana&lt;/code&gt;コントロールパネルと接続し、&lt;code&gt;-l&lt;/code&gt;パラメータを入力せずに&lt;code&gt;web&lt;/code&gt;コンソールでデータを観察できます。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;jmeter -n -t /tmp/order-500-10s.jmx -l /tmp/jmeter-order-report-20200109/order-500-10s.jtl
# 一般不用测试结果和测试报告，简化命令
jmeter -n -t /tmp/order-500-10s.jmx
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;influxdb&#34;&gt;InfluxDB
&lt;/h2&gt;&lt;p&gt;InfluxDBは、外部依存関係なしにGo言語で記述されたオープンソースの分散型時系列、イベント、および指標データベースです。現在、このデータベースは主に、DevOpsモニタリングデータ、APPメトリクス、IoTセンサーデータ、リアルタイム解析データなど、大量の時間スタンプデータを保存するために使用されています。&lt;/p&gt;
&lt;h3 id=&#34;influxdbの特徴&#34;&gt;InfluxDBの特徴
&lt;/h3&gt;&lt;p&gt;InfluxDBの特徴は、以下の9つの側面からまとめられます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;構造（パターン）なし：任意の数の列が可能です。&lt;/li&gt;
&lt;li&gt;メトリクスの保存期間を設定できます。&lt;/li&gt;
&lt;li&gt;時間に関連する関数（最小値、最大値、合計、カウント、平均、中央値など）をサポートし、統計処理に便利です。&lt;/li&gt;
&lt;li&gt;サポートされているストレージポリシー：データの削除と変更に使用できます。（InfluxDBはデータの削除および変更の方法を提供していません。）&lt;/li&gt;
&lt;li&gt;継続クエリのサポート：データベース内で自動的にスケジュールされた一連の文であり、ストレージポリシーと組み合わせることでInfluxDBのシステムリソース使用量を削減できます。&lt;/li&gt;
&lt;li&gt;ネイティブなHTTPサポート、組み込みHTTP API。&lt;/li&gt;
&lt;li&gt;SQLに類似した構文をサポートします。&lt;/li&gt;
&lt;li&gt;クラスタ内のデータレプリカ数を設定する機能をサポートします。&lt;/li&gt;
&lt;li&gt;定期サンプリングデータをサポートし、別のmeasurementに書き込むことで、細分化されたデータストレージを容易にする。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;influxdb-docker-インストール&#34;&gt;InfluxDB Docker インストール
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mkdir influxdb &amp;amp;&amp;amp; cd influxdb &amp;amp;&amp;amp; \
docker run -p 8086:8086 -d --name influxdb -v $PWD:/var/lib/influxdb influxdb:1.7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;コンテナに入り、コマンドを実行して、手動でデータベースを作成します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;root@bce0a55bbc72:/# influx
Connected to http://localhost:8086 version 1.7.10
InfluxDB shell version: 1.7.10
&amp;gt; 交互面板执行命令
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;influxdb-データベースとユーザーの作成&#34;&gt;InfluxDB データベースとユーザーの作成
&lt;/h3&gt;&lt;p&gt;データベースを作成します：create database jmeter_t2
データベースを確認する：show databases
データベースを切り替えます：use jmeter_t2
ユーザーを作成：パスワード&amp;rsquo;admin&amp;rsquo;でユーザー&amp;quot;admin&amp;quot;を全権限で作成する
ユーザーを表示&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;&amp;gt; show users
user  admin
----  -----
admin true
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ユーザー権限&lt;code&gt;admin&lt;/code&gt;が&lt;code&gt;true&lt;/code&gt;に表示されれば、データベースの準備は完了です。&lt;/p&gt;
&lt;h2 id=&#34;grafana&#34;&gt;Grafana
&lt;/h2&gt;&lt;p&gt;テストケースを作成していると、グラフ表示はそれほど必須ではないことがわかった。インターフェースの&lt;code&gt;tps&lt;/code&gt;データはコマンドラインで実行すれば確認できるし、むしろプログラム内部の処理時間を知りたいだけだ。&lt;/p&gt;
&lt;p&gt;シンプルな&lt;code&gt;Grafana&lt;/code&gt;コントロールパネルをデプロイし、設定ファイルをインポートして&lt;code&gt;InfluxDB&lt;/code&gt;に接続する。&lt;/p&gt;
&lt;p&gt;コントロールパネルでは、タグによるテスト結果のフィルタリングが可能で、通常は &lt;code&gt;InfluxDB&lt;/code&gt; データベースを一つ設定するだけで済みます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;アプリケーション名&lt;/li&gt;
&lt;li&gt;テストケース名&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/linux-setup-jmeter-testing-environment/Snipaste_2021-03-09_19-44-22.png&#34;
	width=&#34;861&#34;
	height=&#34;357&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;grafana&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;241&#34;
		data-flex-basis=&#34;578px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -d --name=grafana -p 3000:3000 grafana/grafana:7.3.1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ウェブ版では、サンプラー間隔により計算される&lt;code&gt;TPS&lt;/code&gt;や関連数値が&lt;code&gt;Jmeter&lt;/code&gt;の集約レポートと一致しない場合があります。参考リンク：&lt;a class=&#34;link&#34; href=&#34;https://www.vinsguru.com/jmeter-real-time-results-influxdb-grafana/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.vinsguru.com/jmeter-real-time-results-influxdb-grafana/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;資料には、リスナーをカスタマイズする方法についても説明されています。&lt;/p&gt;
&lt;h2 id=&#34;あとがき&#34;&gt;あとがき
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;高性能なプログラムパターンは必ずしもone loop threadであり、ロック、キューへの入列と退列は不要なパフォーマンス損失を引き起こす。&lt;/li&gt;
&lt;li&gt;コアビジネスロジックの処理時間よりも、他のコードを導入する時間が長くなる場合がある。並行処理によってのみ効率を効果的に向上させることができ、コア処理時間が十分短い場合に限って、他のコードの導入は慎重に行うべきである。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;参照資料&#34;&gt;参照資料
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;JMeterシリーズ：JMeter+Grafana+InfluxDBによるリアルタイム監視&lt;/li&gt;
&lt;li&gt;InfluxDB公式イメージ&lt;/li&gt;
&lt;li&gt;Grafana公式イメージ&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://jmeter.apache.org/download_jmeter.cgi&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;JMeter公式サイト&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/@jasonli.studio/to-install-apache-jmeter-in-centos7-294bc72a97ba&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;To install Apache JMeter in CentOS7&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Red Hat と CentOS のライフサイクル</title>
        <link>https://ttf248.life/ja/p/redhat-centos-lifecycle/</link>
        <pubDate>Tue, 21 Jul 2020 20:02:35 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/redhat-centos-lifecycle/</guid>
        <description>&lt;p&gt;オンラインの生産環境オペレーティングシステムでは、Red HatとCentOSが主流な選択肢です。2つのシステムのライフサイクルに関する公式ウェブサイトへのリンクを記録し、CentOS 8からCentOS 8 Streamへのアップグレード経験を共有しています。&lt;/p&gt;
&lt;h2 id=&#34;まえがき&#34;&gt;まえがき
&lt;/h2&gt;&lt;p&gt;オンライン生産環境のオペレーティングシステムですが、現在の中国国内では、Red HatとCentOSが主流です。数年前にはRed Hat 6のEOL（End of Life）がありましたが、この記録として両システムのライフサイクル公式ウェブサイトへのリンクを記載します。&lt;/p&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://access.redhat.com/support/policy/updates/errata&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Red Hat Enterprise Linux Life Cycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;CentOS 製品仕様&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Red Hat Enterprise Linux（RHEL）とCentOSは、エンタープライズサーバーオペレーティングシステムの主要な選択肢です。RHELは安定したサポートとアップデートサイクルを提供し、企業向けアプリケーションに適しています。CentOSはRHELのコミュニティ版であり、同様の機能と安定性を提供しますが、公式サポートはありません。&lt;/p&gt;
&lt;h2 id=&#34;追い続き&#34;&gt;追い続き
&lt;/h2&gt;&lt;p&gt;この記事を公開した時、2年後にアップデートすることになるとは思ってもみませんでした。先日、普段使っている仮想マシンをCentOS 8からCentOS 8 Streamにアップグレードしました。本番環境でどう選ぶかは言及しないことにしますが、ローカル環境では最新バージョンを追求しています。&lt;/p&gt;
&lt;p&gt;CentOS 8 Streamは、ローリングリリース版であり、従来のCentOSよりも速いアップデートと新機能を提供するため、開発およびテスト環境での利用に適しています。&lt;/p&gt;</description>
        </item>
        <item>
        <title>パソコンの組み立てあれこれ</title>
        <link>https://ttf248.life/ja/p/computer-assembly-tips/</link>
        <pubDate>Sat, 18 Jul 2020 14:33:46 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/computer-assembly-tips/</guid>
        <description>&lt;p&gt;著者は幼い頃からパソコンの組み立てに興味を持ち、大学に進学してからはハードウェアの組み立てに触れるようになりました。CPU、SSD、HDD、メモリ周波数など、ハードウェア性能比較サイトや購入のアドバイスを紹介しています。ハードウェア選びの経験と注意点について共有しています。&lt;/p&gt;
&lt;h3 id=&#34;ご縁言葉では言い表せない&#34;&gt;ご縁、言葉では言い表せない。
&lt;/h3&gt;&lt;p&gt;幼い頃から自分のパソコンを組み立てたいと思っていたのだが、経済的な状況がそれを許してくれなかった。なんとか大学に進学できたものの、持ち運びの都合上、ノートパソコンを選んだ。具体的にいつからパソコンを組み立てることにしたのかという話をするなら、実家近くの図書館に遡ることになるだろう。それは市区レベルの図書館であり、電子閲覧室（実際に行ったことはなく、時間課金らしい）だけでなく、雑誌閲覧室もあった。そこで《大众软件》、《电脑报》といった雑誌をめくったのだ。パソコンにほとんど触れたことがなかった私にとって、それはまさに神のような科普資料だった。ダンジョン攻略の章を見ると、自分もパソコンを手に入れてモンスを集め、主力アタッカーになりたいと思った。そして、ブラックテクノロジーを見かけると、本に書かれている通りにやってみれば、説明されている効果を達成できるのではないか（ハックツールの使用について）という夢を見た。高校の授業は忙しかったが、当時の私の認識では、勉強もしたいし遊びもしたいので、「天真爛漫」な日々を送っていた。図書館に行く口実で、時々小さなバッグを持って歩いて行った。市内の規模は大きくないので、ほとんど徒歩で向かった。着くとエアコンの効いた空間で、小説や漫画、ゲーム雑誌を見たり、たまに真面目な本を読んだりした。&lt;/p&gt;
&lt;p&gt;年を取ると忘れっぽくなるのはよくあることですが、図書館での出来事は今回初めてではありません。中学校の頃、親戚の家でパソコンを組み立てたことがありますが、なぜあの時その機械を組み立てたのか思い出せません。オペレーティングシステムはWindows 2003で、ゲームは標準搭載のトランプとエイジオフエンパイアがありました。色々な「知恵比べ」をして、鍵を盗んで弟と一緒にゲームをするのが楽しみでした。&lt;/p&gt;
&lt;p&gt;中学に入ったばかりの頃から、学校ではコンピュータの初級トレーニングがあり、転校した際にもコンピュータコンテストの概念に触れました。高校に進学すると、NOIPを一度経験しました。そこで言及せざるを得ないのは、同窓会の力です。高校のコンピュータ棟は同窓会からの寄付で、コンピュータ教室と図書館を含んでいます。実際、その頃は国内のインターネットブームの最初の波でした。学校のリーダーシップもコンピュータコンテストへの参加を支援しており、前々回までの先輩たちがコンピュータを通じて重点大学に特待生として進学しているのですから。&lt;/p&gt;
&lt;p&gt;今まで、自分とパソコンの関係をこんな風に振り返ったことがなかった。卒業後に自動化専攻からコンピュータ業界へ固執して転身したのも無理はないことだ。種はすでに植えられていて、関係者は気づいていないだけだろう。小さい頃からよく触れていたので、自分がとても得意だと考えていたが、実際には表面的な知識しかなく、最大の強みは最初の熱意だった。&lt;/p&gt;
&lt;h3 id=&#34;ハードウェア組み立て&#34;&gt;ハードウェア組み立て
&lt;/h3&gt;&lt;p&gt;カードの掲示板やChiphell、知乎のパソコン組み立てスレッドを色々見て回ると、初心者でも比較的簡単に自分に必要なパーツリストを作成できます。2019年以降にCPUを選ぶ場合、経済状況があまり良くない中でより高いパフォーマンスを求めるなら、AMDが第一候補です。&lt;/p&gt;
&lt;p&gt;よく使われるハードウェア性能比較サイトを紹介します：&lt;a class=&#34;link&#34; href=&#34;https://cpu.userbenchmark.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://cpu.userbenchmark.com/&lt;/a&gt; 。価格については、メルカリの米国版と比較できるくらいです。本気の方ならメルカリで中古を探すと、かなり安く手に入るかもしれません。しかし、あまり詳しくない場合はメルカリはおすすめしません。私も偽メモリを買ってしまいましたが、今のところ問題なく使えているので、詳細はよくわかりません。型番やスペックが全く合っていないのです。&lt;/p&gt;
&lt;h4 id=&#34;sn550-vs-sn750&#34;&gt;SN550 VS SN750
&lt;/h4&gt;&lt;p&gt;SN550 1TBとSN750 1TBの違いは、持続的な読み書き速度が倍違うことくらいで、それぞれ850MBと1.6GBです。しかし日常使いでは違いを感じないでしょう。なぜなら4Kの性能はどちらも同じだからです。もちろんこれは1TB容量のSN550について言及しているのですが、500Gや250Gだとシーケンシャルリードライトはさらに遅くなります。正直、お金を気にしないのでなければ、日常使いであればSN550で十分だと思います。私がこれを買わなかった最大の理由は、シーケンシャルリードライトの速度ではなく、最大容量が1TBしかないことでした。一方、SN750は2TB容量があります。私にとって、追加購入なしに考えると、マザーボードのM.2 Nvmeスロットの方が、これらのSSDの価格差よりも価値があると感じます。&lt;/p&gt;
&lt;p&gt;ネットユーザーの意見を総合すると、変換アダプターを購入すれば、B150マザーボードでもM.2インターフェースに対応したSSDが利用できる。&lt;/p&gt;
&lt;h4 id=&#34;機械式ハードディスクの選び方&#34;&gt;機械式ハードディスクの選び方
&lt;/h4&gt;&lt;p&gt;機械式ハードディスクは現在価格が安定しており、大量のストレージを必要とするユーザーには、適切な機械式ハードディスクを選択する必要があります。頻繁にコンテンツをダウンロードするユーザーには、エンタープライズ向けのハードディスクをお勧めします。一般的なものとしては：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;西数字金盤&lt;/li&gt;
&lt;li&gt;シージェーエグゾス&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;大容量の機械式ハードディスクは、パーティション分割を推奨します。頻繁なダウンロード作業は特定のパーティションに固定し、故障が発生した場合もそのパーティションに集中させることで、現在のパーティションを廃棄すれば、機械式ハードディスクの寿命を効果的に延ばすことができます。&lt;/p&gt;
&lt;p&gt;シーゲイトシリーズ&lt;a class=&#34;link&#34; href=&#34;https://www.seagate.com/cn/zh/enterprise-storage/exos-drives/exos-e-drives/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;公式サイト紹介&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;シーゲ이트エンタープライズHDD概要&lt;/p&gt;
&lt;p&gt;シーゲ이트エンタープライズHDD概要&lt;/p&gt;
&lt;h4 id=&#34;メモリクロック&#34;&gt;メモリクロック
&lt;/h4&gt;&lt;p&gt;日常業務の観点からは、頻度はパフォーマンスに大きな影響を与えないでしょう。&lt;/p&gt;
&lt;p&gt;メモリタイミング(メモリアクセスタイミング) メモリ(放置されたメモリ)&lt;/p&gt;
&lt;p&gt;メモリタイミング（英語：Memory timingsまたはRAM timings）は、同期動的メモリアクセスストレージ（SDRAM）のパフォーマンスを記述する4つのパラメータ：CL、TRCD、TRP、TRASです。単位はクロックサイクルで、通常は7-8-8-24のようにハイフンで区切られた4つの数字で表記されます。第4パラメータ（RAS）は省略されることが多く、場合によっては第5パラメータであるコマンドレート（Command rate）が追加されます。これは通常2Tまたは1Tと表記され、2N、1Nとも書かれます。これらのパラメータは、ランダムアクセスメモリの速度に影響を与える潜伏時間（レイテンシ）を指定します。数値が小さいほど、一般的にパフォーマンスは向上します。システムパフォーマンスを決定する最終的な要素は、実際のレイテンシであり、通常ナノ秒で表されます。&lt;/p&gt;
&lt;p&gt;メモリタイミングを実際の遅延に変換する際、最も重要なことは、それがクロックサイクル単位で表されていることに注意することです。クロックサイクルの時間を把握していない場合、一連の数値が別の数値よりも高速であるかどうかを理解することはできません。&lt;/p&gt;
&lt;p&gt;例えば、DDR3-2000メモリのクロック周波数は1000MHzで、その周期は1nsです。この1nsの周期を基準にすると、CL=7の場合、絶対的な遅延は7nsとなります。一方、より高速なDDR3-2666（クロック1333MHz、サイクルごとに0.75ns）では、CL=9という大きな値を用いるかもしれませんが、それでも絶対的な遅延は6.75nsと短くなります。&lt;/p&gt;
&lt;p&gt;現代のDIMMには、シリアルプレゼンスディテクト（SPD）ROMチップが搭載されており、その中に自動構成を推奨するメモリタイミング情報が含まれています。PCのBIOSでは、ユーザーがタイミングを調整してパフォーマンスを向上させること（安定性が低下するリスクがある）、または特定の状況下で安定性を高めること（推奨タイミングを使用する場合など）が可能です。&lt;/p&gt;
&lt;p&gt;注意：メモリの帯域幅はメモリのスループットを測定するものですが、通常はレイテンシではなく転送速度によって制限されます。SDRAM の複数の内部バンクに交番してアクセスすることで、ピークレートで連続的なデータ転送が可能になります。帯域幅を増やすために、レイテンシを増加させる可能性があります。具体的には、新しい世代のDDRメモリは高い転送速度を備えていますが、絶対遅延は大きく変化しません。特に市場に出回った最初の新世代製品では、通常、前の世代よりも長い遅延になっています。&lt;/p&gt;
&lt;p&gt;メモリのレイテンシが増加しても、メモリ帯域幅を増やすことで、マルチプロセッサまたは複数の実行スレッドを持つコンピュータシステムのパフォーマンスを向上させることができます。より高い帯域幅は、専用ビデオメモリを持たない統合グラフィックスカードのパフォーマンスも向上させます。&lt;/p&gt;
&lt;p&gt;メモリタイミングパラメータの説明&lt;/p&gt;
&lt;h3 id=&#34;参照資料&#34;&gt;参照資料
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;メモリタイミングパラメータの説明&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>ウェブサイトの高速化とドメイン設定</title>
        <link>https://ttf248.life/ja/p/website-acceleration-and-domain-setup/</link>
        <pubDate>Sat, 20 Jun 2020 10:36:27 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/website-acceleration-and-domain-setup/</guid>
        <description>&lt;p&gt;国内アクセスがGitHub Pagesよりも遅いため、著者は個人ドメインを申請し、国内クラウドプロバイダーのCDNアクセラレーションサービスを購入しました。設定中に、wwwサブドメインにアクセスできない問題が発生しましたが、最終的にワイルドカードドメイン解析を削除し、セカンダリドメインを個別に設定することで解決しました。また、著者はCDNアクセラレーションの原理と設定経験、Nginxのリバースプロキシの試みと教訓についても共有しています。&lt;/p&gt;
&lt;h3 id=&#34;背景&#34;&gt;背景
&lt;/h3&gt;&lt;p&gt;GitHub Pagesにサイトをホストしているため、周知の理由により、国内からのGitHub Pagesへのアクセスは少し遅いです。そこで、個人ドメインを申請し、国内クラウドプロバイダーのCDN加速サービスを購入しました。加速サービスを設定する際に、開発マシンにあるDocker、frp、k8sなどのサービスが思い浮かびました。これらのサービスにはそれぞれダッシュボードがあるので、無駄にしないという考えで、いくつかのリバースプロキシを設定し、すべてを二级ドメインに割り当てました。&lt;/p&gt;
&lt;p&gt;サブドメインを快適に使っていると突然、wwwサブドメインにアクセスできなくなりました。アリババクラウドでは、www.xiangtianlong.comとxiangtianlong.comの両方をDNSで同時に解析するように設定しており、CDN加速が有効になっていないときは両方のドメインとも正常に使用できていました。&lt;/p&gt;
&lt;p&gt;CDN加速設定時に、セカンダリドメインが多すぎるため汎用ドメインルールを有効にし、すべて開発マシンにルーティングした結果、wwwというセカンダリドメインもダウンしてしまいました。はい、勘違いではありません、wwwプレフィックスはセカンダリドメインです。実際のウェブサイトはGitHub Pagesにデプロイされており、開発マシンにはウェブサイトのキャッシュ情報が一切ありません。&lt;/p&gt;
&lt;p&gt;開発マシンにサイトをデプロイしないのは、静的ブログで、GitHubの提供するアクションと組み合わせることで、自動的に統合して公開できるからだ。最高だ。&lt;/p&gt;
&lt;h3 id=&#34;ドメイン&#34;&gt;ドメイン
&lt;/h3&gt;&lt;p&gt;非専門的なウェブ開発では、ドメインの理解はSEOやクロスドメインの問題には及びません。ブログサイトとして、ベアドメインを使うことでブログ主のサイトが際立ちやすくなります。これは私のように漢字のピンインをドメインにしているような者にとって、それに加え現在のモバイルアクセスが多いことを考えると、入力できる文字数を減らせるというメリットがあります。&lt;/p&gt;
&lt;p&gt;パソコンでは、ショートカットキーを使えばwwwとcomの入力を省略できます。&lt;/p&gt;
&lt;h3 id=&#34;cdn&#34;&gt;CDN
&lt;/h3&gt;&lt;p&gt;アリババクラウドとテンセントクラウドの両方使ったことがあり、初心者でも使いやすいです。テンセントクラウドには関連する概念を個別に解説した動画もあります。CDNの加速原理は京東（ジードン）の倉庫と同じで、新商品を発売したら、事前に全国各地の倉庫に一斉配送し、配送リクエストが発生した際に、最寄りの倉庫から発送します。&lt;/p&gt;
&lt;p&gt;元のURL：ウェブサイトのリソースが最初に保存されていたアドレス&lt;/p&gt;
&lt;p&gt;キャッシュファイル設定、ブラウザのF12、管理コンソール、静的リソースと動的リソースの簡単な分析&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;全件0日有効&lt;/li&gt;
&lt;li&gt;.php;.jsp;.asp;.aspx 0日有効期限&lt;/li&gt;
&lt;li&gt;.jpg;.png;.js;.css;.woff2 有効期限1日&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;テンセントクラウド設定ルール：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;キャッシュの有効期限ルールは最大で10条まで設定可能です。&lt;/li&gt;
&lt;li&gt;複数のキャッシュ失効ルールの優先順位は、下位ルールから適用されます。&lt;/li&gt;
&lt;li&gt;キャッシュの有効期限は最大365日まで設定可能です。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;痛ましい告白&#34;&gt;痛ましい告白
&lt;/h3&gt;&lt;p&gt;以前使ったことがなかったのでNginxを理解しているつもりでしたが、ウェブサイトを検索すればリバースプロキシの設定がわかると思っていました。しかし、結果は混乱し、半日かけても302のリダイレクトを理解できませんでした。結局、何も成果が出ませんでした。そこで、思いつきでDNS解析からワイルドカードの汎用ドメイン解析を削除し、個々のセカンドレベルドメインを独立して設定しました。その時、突然、阿里云のDNS解析に「表示URLリダイレクト」というモードがあることに気づきました。試してみたところ、これがまさに私が求めていた302のリダイレクトでした。&lt;/p&gt;
&lt;p&gt;最初の二階建てドメインの設定は問題なくアクセスできたのに、2つ目の設定をしたら動かない。しばらく待ってみたら急に使えるようになったので、阿里云のDNS伝播が時々不安定になるようだ。&lt;/p&gt;
&lt;h3 id=&#34;参照資料&#34;&gt;参照資料
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;なぜ最近、ウェブサイトのドメイン名に「www」という接頭辞が付いていないものが増えているのか？&lt;/li&gt;
&lt;li&gt;wwwとしないドメインに違いはありますか？&lt;/li&gt;
&lt;li&gt;Docker nginx リバースプロキシ設定&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>ブログのIDE環境とつぶやき</title>
        <link>https://ttf248.life/ja/p/blog-ide-environment-and-ramblings/</link>
        <pubDate>Tue, 31 Mar 2020 13:54:27 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/blog-ide-environment-and-ramblings/</guid>
        <description>&lt;p&gt;この記事では、Markdown の基本的な概念と様々なソフトウェアでの応用について説明し、VSCode を IDE として推奨しています。また、推奨されるプラグインもリストアップされています。著者は Hexo から Hugo への移行経験を共有し、Hugo の柔軟性とカスタマイズ能力を強調しています。最後に、新しい技術を始めるためのヒントと、Hugo テーマのスタイルが更新されない問題を解決する小技を提供しています。&lt;/p&gt;
&lt;h2 id=&#34;まえがき&#34;&gt;まえがき
&lt;/h2&gt;&lt;h3 id=&#34;markdown&#34;&gt;Markdown
&lt;/h3&gt;&lt;p&gt;軽量なマークアップ言語で、人々が読みやすく書きやすいプレーンテキスト形式でドキュメントを作成できるようにするものです。&lt;/p&gt;
&lt;p&gt;詳細なMarkdownの文法については、この文章では余分な説明は省きます。電子書籍を推薦します。&lt;a class=&#34;link&#34; href=&#34;https://markdown-zh.readthedocs.io/en/latest/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;こちらをクリック&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;市場にはすでに多くのソフトウェアがmdを記述方法としてサポートしています。csdnのブログシステムはmd文法に対応したオンラインエディタをリリースし、初めて使用する際にはmd文法の紹介記事がデフォルトで用意されており、筆者はなかなか良いと感じました。印象ノートは2018年にmdノートへの対応を追加し、クイックバーには様々なmdマークアップのオプションがあり、普通の文章を編集するのとほぼ同じように使え、全体的な操作の流れは初心者にも優しいです。&lt;/p&gt;
&lt;h3 id=&#34;ide推奨&#34;&gt;IDE推奨
&lt;/h3&gt;&lt;p&gt;この記事を書いている時点ですでに2020年ですが、VSCodeなら当然聞いたことがあるでしょう。結局のところ、Git Pageを使ってブログシステムを構築しようと思えるのは、業界関係者だからです。昔はSublimeやAtomも良い選択肢でしたが、2年のオープンソースコミュニティの推進により、VSCodeは急速に発展し、初心者にとって最初の選択肢となりつつあります。&lt;/p&gt;
&lt;p&gt;マイクロソフトという巨大企業とオープンソースコミュニティの関係が、対立状態から順調に蜜月期へと移行した：オープンソースを積極的に受け入れるようになった。筆者が所属する会社もここ2年間でJavaエコシステムを積極的に導入しており、言い換えれば、現在のJavaのエコシステムは国内でのビジネス開発において非常に魅力的だ。&lt;/p&gt;
&lt;h3 id=&#34;vs-code-拡張機能の推奨&#34;&gt;VS Code 拡張機能の推奨
&lt;/h3&gt;&lt;p&gt;プラグインリスト&lt;/p&gt;
&lt;p&gt;プラグインにはそれぞれReadmeが付属しており、基本的な使い方や主要な機能について説明されています。一部のプラグイン作成者は、動的な効果を解説する画像も提供しています。&lt;/p&gt;
&lt;p&gt;貼り付けた画像、Hugoの画像プラグインと組み合わせることで、非常に手軽に画像を挿入できます。&lt;/p&gt;
&lt;p&gt;ショートカットキーを覚えていないので、VSCodeのショートカット管理メニューを開き、「md」を検索して何度か確認する。プラグインの使い方説明書をもう一度見る。&lt;/p&gt;
&lt;h2 id=&#34;hugo&#34;&gt;hugo
&lt;/h2&gt;&lt;p&gt;私はHexoからHugoに乗り換えたのですが、いじくり回すのが私の性格なので、結局は我慢できずに黙々と記事を書こうとしました。&lt;/p&gt;
&lt;p&gt;ヒューゴは、画像とmdドキュメントを個別のフォルダに配置することをサポートしています。
学術的なテーマは、デザインにおいて様々な種類の記事スタイルをサポートしています。
様々な便利なカスタマイズ拡張機能&lt;/p&gt;
&lt;h2 id=&#34;academic&#34;&gt;academic
&lt;/h2&gt;&lt;p&gt;公式サイトのデフォルトは&lt;code&gt;exampleSite&lt;/code&gt;、メニューの導入は&lt;code&gt;#コンポーネント&lt;/code&gt;方式を採用し、&lt;code&gt;url&lt;/code&gt;の使用を推奨します。&lt;/p&gt;
&lt;p&gt;URLのパターンで、ナビゲーションバーをクリックすれば単一ページへのジャンプが可能で、トップページでのスクロールではない。これは完全に個人的な好みによるものだ。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;スタイル：エッセイ、スピーチ、電子書籍&lt;/li&gt;
&lt;li&gt;柔軟性：全体スタイルをカスタマイズ、CSSスタイルをカスタマイズ&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;このテーマは中国語のサポートがまだ完全ではありません。主に視覚的な面で、フォントサイズが中国語の読書習慣にあまり合っていないことと、Hexoの開発者はほとんど中国人なので、その点でHugoよりも優れています。&lt;/p&gt;
&lt;p&gt;しかし、自分でやって服を整え、ブラウザで要素を検証する。要素の位置を特定したら、変更する必要があるCSSスタイルの名前を知りたいので、サイドバーで「Insert Style Rule Below」をクリックすると、ネストされた複数のCSSでも簡単にノード名を取得できる。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://sourcethemes.com/academic/docs/customization/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;カスタムCSSの導入&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://sourcethemes.com/academic/docs/customization/#add-scripts-js&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;カスタムJSの導入&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;テーマに組み込まれた文法ハイライト設定、&lt;a class=&#34;link&#34; href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/#highlighting-options.&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;公式リンク&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;結び&#34;&gt;結び
&lt;/h2&gt;&lt;p&gt;子供はやたらと文句を言い出す、どうして最初から最後まで曖昧なことばかり言って、具体的なことは何も言わないんだ。&lt;/p&gt;
&lt;p&gt;これがあれば、十分使えるはずです。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;公式マニュアル&lt;/li&gt;
&lt;li&gt;プラグインの説明&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;新しい技術を早く習得するには、まず公式サイトのドキュメントを読むことをお勧めします。&lt;strong&gt;大まかに目を通すだけで&lt;/strong&gt;、全てを一度で理解しようとしなくても構いません。少なくとも概要を把握することが重要です。検索エンジンの結果は、最新バージョンと一致していない場合があり、誤解を招く可能性があります。新刊を読む場合も同様です。まず目次を見て、著者が何を説明しようとしているのかを理解しましょう。時には序章から読むのが良いこともあります。特に海外の著作を翻訳したものは、翻訳者の序文が書籍の内容や核心部分を網羅していることがあります。&lt;/p&gt;
&lt;h2 id=&#34;イースターエッグ&#34;&gt;イースターエッグ
&lt;/h2&gt;&lt;p&gt;Hugo Academicの組み込みスタイルシートを変更し、サイトに公開しても、スタイルが変化しません。賢い人はすでに気づいているでしょう。ローカルブラウザのキャッシュをクリアすれば解決できます。そして、私が機智を発揮して、F12の開発者モードを開き、&lt;code&gt;network&lt;/code&gt;に切り替えて、&lt;code&gt;disable cache&lt;/code&gt;にチェックを入れて、リフレッシュ！これで完了です！&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/blog-ide-environment-and-ramblings/2020-03-31-14-27-15.png&#34;
	width=&#34;399&#34;
	height=&#34;142&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;network&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;280&#34;
		data-flex-basis=&#34;674px&#34;
	
&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>自動統合システム切り替え</title>
        <link>https://ttf248.life/ja/p/auto-integration-system-switch/</link>
        <pubDate>Sun, 29 Mar 2020 02:11:33 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/auto-integration-system-switch/</guid>
        <description>&lt;p&gt;GitHub Actionsを使用して、HugoブログをGitHub PagesとGiteeに自動デプロイします。&lt;/p&gt;
&lt;h4 id=&#34;背景説明&#34;&gt;背景説明
&lt;/h4&gt;&lt;p&gt;昨日ブログを更新した際、Travisのサービスが利用できないことに気づきました。Travisのウェブページを確認すると、進捗状況がソースコードの取得で止まっていることがわかり、GitHubが以前に発表したActionsサービスのことを思い出しました。&lt;/p&gt;
&lt;p&gt;その頃はかなり忙しく、アクションを使うためには申請が必要になるため、今は正式にオンラインになりました。週末に暇な時に、新しいおもちゃを試してみるか？&lt;/p&gt;
&lt;p&gt;公式資料は各自ウェブサイトでご確認ください。本文ではこれ以上の転載はいたしません。以前Kubernetesを使ったことがある人ならわかると思いますが、actionのYAMLファイルの設定とKubernetesがよく似ています。&lt;/p&gt;
&lt;p&gt;入門チュートリアル、あるいは中国語の紹介資料についてですが、&lt;strong&gt;阮一峰のブログ&lt;/strong&gt;を検索することをお勧めします。そこには2つの記事があり、1つ目は基本的な文法解説で、2つ目は実際の事例です。&lt;/p&gt;
&lt;h4 id=&#34;正文&#34;&gt;正文
&lt;/h4&gt;&lt;p&gt;必要な知識点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;github secrets&lt;/li&gt;
&lt;li&gt;アクション文法&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;既存のコンポーネントでコアとなるジョブを完了させ、コマンドを使用して国内のGiteeにプッシュする。このコマンド部分はかなり荒っぽく、強制プッシュであり、Travisを使用していた際のロジックを引き継いでいる。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;name: github pages and gitee pages

on:
  push:
    branches:
      - hugo

jobs:
  deploy:
    runs-on: ubuntu-18.04
    steps:
      - uses: actions/checkout@v2
        with:
          submodules: true

      - name: Setup Hugo
        uses: peaceiris/actions-hugo@v2
        with:
          hugo-version: &#39;latest&#39;
          extended: true

      - name: Build Github and Gitee ## 单个step只能写一个run命令
        run: hugo -b &amp;quot;https://www.xiangtianlong.com/&amp;quot; -d &amp;quot;github_public&amp;quot; &amp;amp;&amp;amp; hugo -b &amp;quot;https://www.xiangtianlong.com/&amp;quot; -d &amp;quot;gitee_public&amp;quot; &amp;amp;&amp;amp; ls

      - name: Deploy Github
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.BLOG_TOKEN }}
          publish_dir: ./github_public
          publish_branch: master
          cname: xiangtianlong.com

      - name: Deploy Gitee
        run: cd ./gitee_public &amp;amp;&amp;amp; git init &amp;amp;&amp;amp; git config user.name &amp;quot;TianlongXiang&amp;quot; &amp;amp;&amp;amp; git config user.email &amp;quot;tianlongxiang51@gmail.com&amp;quot; &amp;amp;&amp;amp; git add . &amp;amp;&amp;amp; git commit -m &amp;quot;Update TianlongXiang&#39;s Blog&amp;quot; &amp;amp;&amp;amp; git push --force &amp;quot;https://xiangtianlong:${{ secrets.GITEE_PASSWORD }}@gitee.com/xiangtianlong/xiangtianlong.git&amp;quot; master:master   
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;あとがき&#34;&gt;あとがき
&lt;/h4&gt;&lt;p&gt;公式ストアで提供されているアクションを見ると、現時点でサポートされている機能は豊富です。Dockerイメージを構築すれば、Docker Hubが提供するサービスに依存しなくなることもできます。&lt;/p&gt;
&lt;p&gt;Hugoのissueを確認したところ、GitHub Actionsを使ってGit Pagesを自動デプロイする場合、最終的に公開されるウェブページはmasterブランチに必要です。もし他のブランチにデプロイすると、設定画面でGitHubがウェブページの構文エラーを示唆します。&lt;/p&gt;
&lt;p&gt;実際は、hugoのソースファイルがmasterブランチに置かれていたため、GitHubがjellyブログのソースコードとしてそれを検出し、チェックやビルドができなかったためにエラーが発生したものです。&lt;/p&gt;
&lt;p&gt;解決策も簡単で、Hugoのソースファイルを別のブランチに置き、静的ファイルはマスターブランチで公開する。&lt;/p&gt;</description>
        </item>
        <item>
        <title>標準ライブラリコンテナのメモリ割り当て器：allocator</title>
        <link>https://ttf248.life/ja/p/standard-library-container-memory-allocator/</link>
        <pubDate>Mon, 30 Dec 2019 13:26:19 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/standard-library-container-memory-allocator/</guid>
        <description>&lt;p&gt;カスタムアロケータは、パフォーマンスの向上、メモリ効率の改善、および頻繁な小規模メモリ割り当ての問題解決に役立ちます。&lt;/p&gt;
&lt;h4 id=&#34;前の原因&#34;&gt;前の原因
&lt;/h4&gt;&lt;p&gt;最近、ネットワークデータパケットの開発に携わり、頻繁に小さなメモリ領域を確保・解放する必要がある。元々メモリプールを使用しようと考えていたが、既存のメモリプールをいくつか調べてみたところ、これを発見した&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/cacay/MemoryPool&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/cacay/MemoryPool&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;インターフェースを見たときから、ちょっと違和感がある。このメモリプールの実装がどうも奇妙だ。&lt;code&gt;MemoryPool&lt;/code&gt;の実装ロジックは、固定サイズのメモリ空間を確保している。Boostのメモリプールインターフェースを見ると、テンプレートで、使用時にインスタンス化される。ちょうどこのライブラリについてはすでに記事があり、&lt;code&gt;allocator&lt;/code&gt;という概念が言及されている。&lt;/p&gt;
&lt;h4 id=&#34;wikihttpszhwikipediaorgwikie58886e9858de599a8_c2b2b&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;wiki&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;C++プログラミングにおいて、アロケータ（allocator, 英語）はC++標準ライブラリの重要な構成要素です。C++ライブラリには、連結リストや集合など、さまざまな「コンテナ」と呼ばれるデータ構造が定義されており、これらのコンテナに共通する特徴の一つとして、そのサイズをプログラム実行時に変更できることが挙げられます。この実現のためには、動的なメモリ割り当てが不可欠であり、アロケータはそのメモリの割り当てと解放のリクエストを処理するために使用されます。言い換えれば、アロケータは標準テンプレートライブラリ（STL）コンテナにおけるメモリ管理の低レベルの詳細をカプセル化するものです。デフォルトでは、C++標準ライブラリは独自の汎用アロケータを使用しますが、必要に応じて、プログラマは独自のカスタムアロケータを作成して置き換えることもできます。&lt;/p&gt;
&lt;p&gt;アロケータは当初、アレクサンドル・ステパノフによってC++標準テンプレートライブラリ（STL）の一部として考案され、その目的は「ライブラリをより柔軟にし、基になるデータモデルに依存しない方法」を提供し、プログラマがカスタムのポインタや参照型をライブラリで利用できるようにすることであった。しかし、C++標準委員会が標準テンプレートライブラリをC++規格に組み込む際に、データモデルの完全な抽象化は許容できないパフォーマンス損失をもたらす可能性があることに気づき、その折衷案として、規格におけるアロケータの制限が厳しくなった。そして、これに鑑みて、現在の規格で記述されているアロケータのカスタマイズ性は、ステパノフの当初の構想と比較して大幅に制限されている。&lt;/p&gt;
&lt;p&gt;割り当てのカスタマイズには制限があるものの、多くの状況ではカスタムアロケータが必要となる場合があり、これは通常、共有メモリや回収済みメモリなどの異なる種類のメモリ空間へのアクセス方法をカプセル化するため、あるいはメモリプールを使用したメモリ割り当て時のパフォーマンス向上を目的として行われる。さらに、メモリ使用量と実行時間の観点からは、頻繁に少量ずつメモリを割り当てるプログラムにおいて、そのために特化したアロケータを導入することで大きな恩恵を得られる場合がある。&lt;/p&gt;
&lt;h4 id=&#34;利用要件&#34;&gt;利用要件
&lt;/h4&gt;&lt;p&gt;定義カスタムアロケータの主な理由の一つは、パフォーマンスの向上です。専用のカスタムアロケータを使用することで、プログラムのパフォーマンスを向上させたり、メモリ使用効率を高めたり、あるいはその両方を実現できます[4][8]。デフォルトのアロケータはnew演算子を使用してストレージ空間を割り当てますが、これはしばしばC言語のヒープ割り当て関数（malloc()）によって実装されます[9]。ヒープ割り当て関数は、頻繁に大量のメモリを割り当てるために最適化されていることが多いため、一度に大量のメモリを割り当てるコンテナ（ベクトルや双方向キューなど）の場合、デフォルトのアロケータは一般的に効率的です[8]。しかし、連想コンテナや双方向リンク付きリストなどの、頻繁に少量ずつメモリを割り当てる必要があるコンテナの場合、デフォルトのアロケータを使用すると通常、効率が非常に低くなります[4][9]。さらに、malloc()ベースのデフォルトアロケータには、参照局所性の低下[4]や、メモリ断片化を引き起こす可能性[4][9]などの問題も存在します。&lt;/p&gt;
&lt;p&gt;簡単に言うと、この部分（……）は、まるでこの規格がディスペンサーに対して行う「私には夢がある」という演説のようです。夢が実現するまでは、可搬性を気遣うプログラマーは、（使用に）ステートレスなカスタムディスペンサーに自分を限定してしまうでしょう。
——スコット・メイヤーズ『Effective STL』
この状況を鑑みると、頻繁な少量メモリ割り当ての問題を解決するために、メモリプールベースの割り当て器がよく用いられる[8]。デフォルトの「オンデマンド割り当て」とは異なり、メモリプールベースの割り当て器を使用する場合、プログラムは事前に大きなメモリブロック（「メモリプール」）を割り当てておき、メモリが必要な際には、カスタム割り当て器は単にプールのメモリへのポインタを要求者に返すだけです。オブジェクトが破棄される際にも、実際にメモリを解放する必要はなく、メモリプールのライフサイクルが終了した時点で初めてメモリを解放します[注 1][8]。&lt;/p&gt;
&lt;p&gt;「カスタムアロケータ」という話題に関して、すでに多くのC++専門家や関連著者が議論に参加しており、例えばスコット・メイヤーズの『Effective STL』やアンドレイ・アレクサンドレスクの『Modern C++ Design』にも言及されています。メイヤーズは、ある型Tに対するアロケータのすべてのインスタンスが等しいと要求する場合、可搬性のためのアロケータのインスタンスには状態が含まれてはならないことに気づきました。C++標準は、ライブラリの実装者がステートフルなアロケータをサポートすることを推奨していますが[文 4]、メイヤーズは関連する段落が「（一見）素晴らしい考え」であるものの、ほとんどナンセンスであり、アロケータの制限は「あまりにも厳しすぎる」と述べています[4]。例えば、STLのlistはspliceメソッドを許可しており、これはlistオブジェクトAのノードが直接別のlistオブジェクトBに移動できることを意味します。これにより、Aのアロケータによって割り当てられたメモリが、Bのアロケータによって解放される必要があり、それによりAとBのアロケータインスタンスが等しいことが推論されます。メイヤーズの結論は、アロケータを静的方法を使用する型として定義するのが最適であるということです。例えば、C++標準によると、アロケータはrebindメソッドを実装したotherクラステンプレートを提供する必要があります。&lt;/p&gt;
&lt;p&gt;另外、C++プログラミング言語の著者であるビヤニ・ストロストループは、「各オブジェクトの情報が異なることを防ぐための厳格なアロケータの制限」については「問題ない」（大意）と述べ、ほとんどのアロケータには状態が必要なく、むしろ状態がない方が性能が向上することさえあると指摘しています。彼は、メモリプール型アロケータ、共有メモリ型アロケータ、ガベージコレクション型アロケータという3つのカスタムアロケータの利用例を提示し、内部メモリプールを利用して少量メモリを迅速に割り当て/解放するアロケータの実装を示しました。しかし、彼はそのような最適化は既に彼が提供しているサンプルアロケータで実現されている可能性があると述べています[3]。&lt;/p&gt;
&lt;p&gt;カスタムアロケータの別の用途は、メモリ関連のエラーをデバッグすることです[10]。これを実現するには、割り当て時に追加のメモリを割り当てて、そこにデバッグ情報を格納するアロケータを作成できます。このようなアロケータは、メモリが同じ種類の割り当て/解放アロケータによって割り当て/解放されることを保証するだけでなく、ある程度プログラムをバッファオーバーフローから保護することもできます[11]。&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>AI on 向叔の手帳</title>
        <link>https://ttf248.life/ja/tags/ai/</link>
        <description>Recent content in AI on 向叔の手帳</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>ja</language>
        <lastBuildDate>Mon, 02 Jun 2025 19:00:25 +0800</lastBuildDate><atom:link href="https://ttf248.life/ja/tags/ai/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>旧習（こくしゅう）、華やかなりど（かやかなれど）</title>
        <link>https://ttf248.life/ja/p/old-ailment-stunning-flowers/</link>
        <pubDate>Mon, 26 May 2025 23:54:12 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/old-ailment-stunning-flowers/</guid>
        <description>&lt;p&gt;長年にわたりバックエンド開発に注力してきましたが、最近は &lt;code&gt;AI&lt;/code&gt; プログラミングを試したり、少しフロントエンド関連のことも取り組むようになりました。しかし、この間の苦労の中で、自分には昔からある古傷—「繁華なものに目を奪われる」—に気づきました。&lt;code&gt;AI&lt;/code&gt; を使ってフロントエンドインターフェースを実現しようとするのですが、実際にはそのような試みが現在の仕事に大きな実用的な助けにはなりかず、むしろ時間を浪費してしまいます。&lt;/p&gt;
&lt;h2 id=&#34;ai-の適用シナリオ&#34;&gt;AI の適用シナリオ
&lt;/h2&gt;&lt;p&gt;小規模なプロジェクトにおいては、AI ツールが大きな役割を果たすことができ、特に独立性が高く、システムとの結合度が低く、ビジネスロジックが単純な関数を作成する際に非常に役立ちます。このようなタスクは通常、明確な入力と出力があり、文脈依存が少ないため、現在の AI 支援プログラミングの能力範囲に最適です。&lt;/p&gt;
&lt;p&gt;しかしながら、複雑なシステムアーキテクチャや深いビジネスロジックに対処する場合、AI の限界が現れ始めます。それは、プロジェクトの実際のニーズから乖離した、見かけ上は合理的だが実際には機能しないコードを生成したり、デバッグが困難な潜在的な問題を導入したりする可能性があります。これらのシナリオにおいては、AI は補助ツールとして、完全に依存できるコード生成器としては適していません。生成されたコードに対して厳格なレビューとテストを実施し、実際の要件を満たしていることを確認する必要があります。&lt;/p&gt;
&lt;h2 id=&#34;誤りとその学習の代償&#34;&gt;誤りとその学習の代償
&lt;/h2&gt;&lt;p&gt;AI を使ってフロントエンドコードを生成しようと試みた際、多くの課題に直面しました。フロントエンドは私の馴染みのない分野であるため、問題の原因を特定するプロセスは時間と労力を要しました。プロンプトを調整して AI にコードを書き直しても、どうしても些細なエラーが発生してしまうのです。このような試行錯誤は時間を浪費するだけでなく、現在の私のエネルギーはバックエンドのビジネスロジックに集中すべきだと気づかせてくれました。&lt;/p&gt;
&lt;p&gt;週末に完成させたプロジェクトを振り返ってみると、バックエンド開発とユーザーインタラクションロジックに焦点を当て、コンソールを通じて機能を実装することが、現状で最も効率的な選択であるという確信が持てます。より多くの時間とエネルギーを得られるようになったときには、フロントエンドの知識を体系的に学ぶ方が良いかもしれません。&lt;/p&gt;
&lt;h2 id=&#34;フロントエンド学習の計画&#34;&gt;フロントエンド学習の計画
&lt;/h2&gt;&lt;p&gt;フロントエンド技術スタックは複雑で多様であり、短期間で習得するのは現実的ではありません。まずは、Vue.jsやReact.jsなどのフレームワークを選択し、そのコアな概念と使用方法を深く学ぶことを計画しています。基礎知識を習得した後で、AIを活用してフロントエンドコードを生成することで、不慣れによるエラーや時間の浪費を防ぐことができます。&lt;/p&gt;
&lt;p&gt;まとめると、現在の段階ではバックエンド開発に重点を置き、着実にコアスキルを向上させることに注力します。その時が来るまで、フロントエンドとAIの組み合わせを探求することは控え、より大きな成果が得られる可能性があります。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Claude4のリリース、開発を試す：hugoタグ、超リンク翻訳アシスタント</title>
        <link>https://ttf248.life/ja/p/claude-4-release-hugo-tags-hyperlink-translation-assistant/</link>
        <pubDate>Sat, 24 May 2025 03:05:31 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/claude-4-release-hugo-tags-hyperlink-translation-assistant/</guid>
        <description>&lt;p&gt;本サイトはHugoで開発されていますが、筆者自身は常に中国語のタイトルを使用しており、その結果、生成される記事の超リンクが使いにくい状態でした。つまり、送信する際に、中国語の文字が超リンク内で%E4%BD%A0%E5%A5%BDのような形式にエスケープされてしまうため、見た目が良くありません。設定でslugを設定することで解決できますが、毎回手動で設定する必要があり、非常に面倒でした。&lt;/p&gt;
&lt;p&gt;そこで、Claude4を使って翻訳アシスタントを開発し、中国語のタイトルを自動的に英語のslugに変換し、記事の中に超リンクを追加することを試みました。これにより、手動での設定を回避できます。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Claude4はマジで最高！文脈理解能力が大幅に向上し、複雑なタスクの処理効率も飛躍的に向上しています。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;プロジェクトアドレス&#34;&gt;プロジェクトアドレス
&lt;/h2&gt;&lt;p&gt;国内プロジェクトアドレス：&lt;a class=&#34;link&#34; href=&#34;https://cnb.cool/ttf248/hugo-content-suite&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://cnb.cool/ttf248/hugo-content-suite&lt;/a&gt;
国外プロジェクトアドレス：&lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/hugo-content-suite&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/hugo-content-suite&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;コードの実装&#34;&gt;コードの実装
&lt;/h2&gt;&lt;p&gt;まず、実装の思路について説明します。すべての文章をスキャンし、タグ情報と記事タイトルを抽出した後、ローカルの大規模言語モデル（例：gemma-3-12b-it）を呼び出して翻訳します。&lt;/p&gt;
&lt;p&gt;実際の開発においては、前世代の大規模言語モデルと比較して、&lt;code&gt;Claude4&lt;/code&gt; はいくつかの顕著な点を発揮しました。機能要件が多いため、&lt;code&gt;Claude4&lt;/code&gt; はインタラクティブメニューを自動的に設計し、さまざまな使用シナリオを考慮しました。例えば、タグ処理に関しては、&lt;code&gt;Claude4&lt;/code&gt; はタグの統計と分析だけでなく、分類統計もサポートし、さらに&lt;strong&gt;ラベルなしの記事&lt;/strong&gt;を検出することも可能です。また、プレビュー機能やタグページ生成機能も提供しています。&lt;/p&gt;
&lt;p&gt;ローカルの大規模言語モデルとの連携、翻訳キャッシュの追加、大規模なコードのリファクタリングなど、&lt;code&gt;Claude4&lt;/code&gt; はすべて一度に完了し、ほとんど問題が発生しませんでした。 プロジェクトの規模は小さいものの、多くの小さな機能を含んでいます。これまで開発プロセスにおいて、大規模モデルはしばしば前の内容を忘れてしまうことがありましたが、今回の &lt;code&gt;Claude4&lt;/code&gt; は非常に優れたパフォーマンスを示し、&lt;strong&gt;文脈の消失がほとんど見られませんでした&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;要するに、知能レベルが向上しており、今後の開発作業では &lt;code&gt;Claude4&lt;/code&gt; をより多く利用し、日常的なコーディングの主力モデルとして活用していく予定です。&lt;/p&gt;
&lt;h2 id=&#34;翻訳キャッシュ&#34;&gt;翻訳キャッシュ
&lt;/h2&gt;&lt;p&gt;この注文に関する説明では、大規模モデルの呼び出し回数を減らすだけでなく、実際に12Bモデルをローカルで実行すると効率が良く、時間ロスもありません。しかし、毎回大規模モデルを呼び出すと、やはり少し遅くなります。また、文章のリンクを固定するために、全量更新を実行した場合、文章のタイトルが非常に長い場合があり、稀に2回の翻訳結果が異なり、リンクが変わってしまうという状況が発生します。これは非常に困ります。&lt;/p&gt;
&lt;h2 id=&#34;機能最適化&#34;&gt;機能最適化
&lt;/h2&gt;&lt;p&gt;プロジェクト全体を &lt;code&gt;Claude4&lt;/code&gt; に委ね、最適化の余地を分析し、以下の提案を得ました：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;外部化の設定 - 可保守性と柔軟性の向上
構造化ログ - 問題の特定と監視の容易化
パフォーマンスモニタリング - システムの状態把握
ユーザーエクスペリエンス - プログレスバーなどの視覚的フィードバック
エラー処理 - より洗練された例外処理メカニズム
コード整理 - 明確なモジュール分割
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;コードをレビューし、問題点は一切ありませんでした。例えば、設定ファイルは、既存のコードからデフォルト設定に変換され、設定ファイルを読み込む際に、対応する設定ファイルが存在しない場合に自動的にデフォルト設定ファイルが生成されるため、ユーザーのエラーを防いでいます。 要件：原文を翻訳する際に、現在の翻訳効率を動的に計算し、残りの時間を予測し、関連情報をコンソールに出力します。現在、文章の文字数を取得し、各行の翻訳時に現在の翻訳文字数、時間、100文字あたりの翻訳時間の適合計算を行い、同時に文章全体の残りの翻訳推定時間を計算します。&lt;/p&gt;
&lt;p&gt;コードが完了しましたが、効果はそれほど良くありません。そこで、AIに新しい設計案を提案してもらいます：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;複数の効率計算方法を提供：リアルタイム効率、平均効率、スライディングウィンドウ効率&lt;/li&gt;
&lt;li&gt;表示方法の改善：プログレスバー、セクションごとの統計、動的更新&lt;/li&gt;
&lt;li&gt;より役立つ指標を追加：API呼び出し回数、成功率など&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;コードが完了した後、翻訳効率の統計情報がリアルタイムで大量に表示されることを見つけましたが、スクロールを無効にする機能はありませんでした。&lt;/p&gt;
&lt;h2 id=&#34;機能最適化-1&#34;&gt;機能最適化
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;原文を英語に翻訳（合計7163文字）...
53行の翻訳が必要と検出
  [1/53] Stage1/6 [░░░░░░░░░░░░░░░░░░░░░░░░░] 1.9% 354文字を翻訳中...
    ✅完了 (3.1s) | API呼び出し #1
    ✅完了 (1.5s) | API呼び出し #2
    ✅完了 (0.9s) | API呼び出し #3
    ✅完了 (0.2s) | API呼び出し #4
    ✅完了 (1.0s) | API呼び出し #5
    ✅完了 (1.0s) | API呼び出し #6
    ✅完了 (0.2s) | API呼び出し #7
    📊進捗: 行 13.2% (7/53) | 文字 12.9% (925/7163) 114.6文字/秒 📊
    ⚡効率: リアルタイム76.4 | 平均117.9 | 最近109.0 | フェーズ113.6文字/秒 📊
    🎯成功率: 100.0% (7/7) | 残り: 46行7秒] 9.4% 110文字を翻訳中...
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;機能最適化-2&#34;&gt;機能最適化
&lt;/h2&gt;&lt;p&gt;🎯 成功率: 100.0% (7/7) | 残り: 46行7 7s] 9.4% 翻訳 110 文字…
⏱️  推定残り時間: 55秒 | 予想完了時間: 00:10:19 8s] 11.3% 翻訳 114 文字…
💾 处理速度: 3211.3 行/分 | 総処理時間: 8秒] 13.2% 翻訳 16 文字…
[8/53] Stage1/6 [███░░░░░░░░░░░░░░░░░░░░░░] 15.1% 翻訳 166 文字…&lt;/p&gt;
&lt;h2 id=&#34;機能最適化-3&#34;&gt;機能最適化
&lt;/h2&gt;&lt;p&gt;以前制御プログラムの記述はあまり多くなく、どのように実装されているのか気になったので、コードを拝見しました。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;// 画面クリアと再表示（動的更新効果）
if translationCount &amp;gt; 1 {
    fmt.Print(&amp;quot;\033[6A\033[K&amp;quot;) // 上方向に6行移動し、内容をクリア
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;性能統計メニュー&#34;&gt;性能統計メニュー
&lt;/h3&gt;&lt;p&gt;新たに作成された&lt;strong&gt;性能統計メニュー&lt;/strong&gt;は、私自身で設計したものでも、これほど完璧とは言い難い。&lt;/p&gt;
&lt;p&gt;📊 性能統計：
🔄 翻訳回数：360
⚡ キャッシュヒット率：1.4% (5/365)
⏱️ 平均翻訳時間：315.927234ms
📁 ファイル操作：73
❌ エラー回数：0&lt;/p&gt;
&lt;h3 id=&#34;プログレスバーの表示&#34;&gt;プログレスバーの表示
&lt;/h3&gt;&lt;p&gt;新增の&lt;strong&gt;プログレスバーの表示&lt;/strong&gt;、詳細な進捗状況、経過時間、残り時間の推定
機能を選択してください (0-13): 10
🔍 翻訳対象を収集中&amp;hellip;
📄 キャッシュファイルが読み込まれました。翻訳記録は 0 件含まれます
📊 翻訳キャッシュ統計:
🏷️ ラベル総数: 229 個
📝 文章総数: 131 篇
✅ キャッシュ済み: 0 件
🔄 翻訳が必要: 360 件&lt;/p&gt;
&lt;h3 id=&#34;プログレスバー表示&#34;&gt;プログレスバー表示
&lt;/h3&gt;&lt;p&gt;完全な翻訳キャッシュを確認しますか？(y/n): y
🚀 完全な翻訳キャッシュの生成中&amp;hellip;
📄 キャッシュファイルが読み込まれ、0 件の翻訳記録が含まれています。
🔍 キャッシュ内の翻訳をチェック中&amp;hellip;
🔄 360 件の新ラベルを翻訳する必要があります
[░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 5/360 (1.4%) - 時間: 3秒 - 残り時間: 約3分8秒
💾 キャッシュファイルが保存され、5 件の翻訳記録が含まれています。
[█░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 10/360 (2. 8% - 実行時間：6秒 - 残り予想時間：3分28秒💾 キャッシュファイルが保存されました（翻訳記録10件を含む）
[██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 15/360 (4.2%) - 実行時間：9秒 - 残り予想時間：3分30秒💾 キャッシュファイルが保存されました（翻訳記録15件を含む）&lt;/p&gt;
&lt;h3 id=&#34;プログレスバー表示-1&#34;&gt;プログレスバー表示
&lt;/h3&gt;&lt;p&gt;[██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 20/360 (5.6%) - 経過時間: 13秒 - 残り時間予測: 3分36秒💾 キャッシュファイル（翻訳記録20件）を保存
[███░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 25/360 (6.9%) - 経過時間: 16秒 - 残り時間予測: 3分33秒💾 キャッシュファイル（翻訳記録25件）を保存
[████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 30/360 (8. 3% - 実行時間：19秒 - 残り推定時間：3分30秒💾 キャッシュファイルが保存されました（30件の翻訳記録を含む）
[████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 35/360 (9.7%) - 実行時間：22秒 - 残り推定時間：3分25秒💾 キャッシュファイルが保存されました（35件の翻訳記録を含む）&lt;/p&gt;
&lt;h3 id=&#34;プログレスバー表示-2&#34;&gt;プログレスバー表示
&lt;/h3&gt;&lt;hr&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;=== Hugo ブログ管理ツール ===

🚀 核心機能
  1. 一括処理 (フルブログの処理フロー)

📝 コンテンツ管理
  2. タグページを生成
  3. アーティクルスラグを生成
  4. 文章を多言語バージョンに翻訳

💾 キャッシュ管理
  5. キャッシュの状態を確認
  6. 全量翻訳キャッシュを生成
  7. 翻訳キャッシュをクリア

  0. プログラム終了
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>AIを使いすぎると、後遺症のようなものがある。</title>
        <link>https://ttf248.life/ja/p/ai-overuse-side-effects/</link>
        <pubDate>Wed, 14 May 2025 19:39:50 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ai-overuse-side-effects/</guid>
        <description>&lt;p&gt;新しい「AI 灵感碰撞坊」を立ち上げたことで、様々なものが溢れてきて、AIを使って記録したり、発信したりするものが増え続けていますが、静かに自分自身で考え込むようなものは減ってきているようです。今後はこの欄の出力をある程度コントロールし、月刊形式にまとめるのが良いかもしれません。毎月1本の内容を公開すればよいでしょう。&lt;/p&gt;
&lt;p&gt;これは一種の副作用、あるいは後遺症のようなものであり、効率は上がっていますが、思考の深さや幅は低下しているように感じます。&lt;/p&gt;
&lt;h2 id=&#34;効率向上否定できない&#34;&gt;効率向上：否定できない
&lt;/h2&gt;&lt;p&gt;以前、ブログのコーナー「魚の七秒鐘見聞」はメンテナンスされておらず、いくつかの話題事件について、怠惰な状態でのインターネット検索や記録整理が不足していました。しかし、様々なAIツールが登場し、大枠を整理するだけで、AIが自動的に関連するイベントをインターネットで検索・記録し、必要な文章を生成したり、簡単なフォーマット調整を行って公開したりすることが可能になりました。&lt;/p&gt;
&lt;p&gt;これはまさに怠け者にとっての福音であり、効率は大幅に向上しました。さらには、執筆やコーディングの場合も同様に、効率は実証されています。以前はAPIインターフェースドキュメントの詳細な読み込みが必要でしたが、現在は直接スキップできるようになり、このスキップは非常に重要です。APIを熟知することは「肉体労働」であり、「知的労働」ではありません。AIがこの部分を処理することで、まさに完璧です。&lt;/p&gt;
&lt;h2 id=&#34;垃圾コンテンツ&#34;&gt;垃圾コンテンツ
&lt;/h2&gt;&lt;p&gt;多くの稿子で、内容の質が低いと言わざるを得ません。読み応えがなく、煙火の息吹がないという点で、以前私が好まなかったスタイルです。まるで蝋を噛むような無駄感があります。&lt;/p&gt;
&lt;p&gt;別の角度から言えば、AI生成コンテンツは、まさに流水線のように生産されたものであり、魂が欠けていると言えるでしょう。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;新時代のインターネットのゴミ&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;忘却性&#34;&gt;忘却性
&lt;/h2&gt;&lt;p&gt;このタイプの稿子は、読者の状況が不明確であり、時間が経つにつれて、私の記憶も曖昧になり、つい忘れかけてしまうことがあります。&lt;/p&gt;
&lt;p&gt;同様の問題は、コードを書く際にも発生します。コードの提交記録を振り返らずに、自分がどのように考え、なぜそう書いたのか全く思い出せないのです。特に、コードとAIが繰り返しコミュニケーションを通じて生成されたコードは、当初のアイデアとは大きく異なり、場合によっては全く異なるものになってしまうことがあります。&lt;/p&gt;
&lt;h2 id=&#34;検索&#34;&gt;検索
&lt;/h2&gt;&lt;p&gt;最近、Googleや百度を開く回数が明らかに減りました。多くの問題はAIを使って検索したり、インタラクティブな部分も検索結果も、従来の検索エンジンよりもずっと良いからです。
現在では、まだ生きているかどうか分からない&lt;code&gt;bing ai&lt;/code&gt;を追悼しましょう。これは大手企業の中で最初にリリースされた、インターネットに接続して検索できるAIツールです。
Googleの使用頻度が減り、&lt;code&gt;stackoverflow&lt;/code&gt;へのアクセス回数も減りました。多くの問題は直接AIに質問するだけで済みます。このサイトも時代の淘汰にさらされるでしょう。&lt;/p&gt;
&lt;h2 id=&#34;おわりに&#34;&gt;おわりに
&lt;/h2&gt;&lt;p&gt;筆記がメンテナンスしているブログですが、元々アクセス数はほとんどなく、今ではさらに期待していません。よりは多くの記録場所であり、自分に向けて書くためのものです。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>コードを記述せず、カスタム株式選定モジュールを設計・開発する。</title>
        <link>https://ttf248.life/ja/p/design-develop-custom-stock-module-no-code/</link>
        <pubDate>Thu, 27 Feb 2025 23:20:39 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/design-develop-custom-stock-module-no-code/</guid>
        <description>&lt;p&gt;先月の当社では、cursorを試用しましたが、無料枠の制限により、複雑な機能開発は行わず、簡単なテストにとどまりました。その際に見つけたのは、Byte社も同様の製品を発表しており、両者は底層で呼び出している大規模言語モデルがClaude-3.5である点でした。
Byte社の製品はTraeといい、最初にリリースされたmac版は今年2月にWindows版もリリースされました。大手企業のものは良いもので、無料で利用でき、Claude-3.5を無制限に使用できるため、このモデルの性能は非常に優れています。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;最終的にはK線チャートの開発に詰まりました。Reactの知識がほとんどないため、諦めざるを得ませんでした。もし継続的に開発を進めるのであれば、筆者がフロントエンドの基礎知識を補強し、タスクをより細かく分割して、直接「K線チャートの開発」という大きなタスクを与えるのではなく行うべきです。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;発見された問題点&#34;&gt;発見された問題点
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;外国製のAIモデルを使用していたため、Vue3 + Element-Plusの学習データが不足しており、Reactをフロントエンドフレームワークとして採用しました。&lt;/li&gt;
&lt;li&gt;偶発的な構文エラーが存在する可能性があり、手動での修正が必要です。&lt;/li&gt;
&lt;li&gt;一部の複雑な問題に対する解決策は、人的指導が必要となります。&lt;/li&gt;
&lt;li&gt;コード構造の最適化には、人的指導が必要です。&lt;/li&gt;
&lt;li&gt;最も時間がかかったのは、フロントエンドコードをコンテナにパッケージングすることでした。筆者は環境が全く理解されておらず、&lt;code&gt;.env.production&lt;/code&gt;や&lt;code&gt;tsconfig.json&lt;/code&gt;といった概念自体を知らなかったため、途中で助けを求める豆包（ネットでの質問サイトのユーザー）に頼らざるを得ませんでした。フロントエンドの開発 devモードとbuildモードでは、コードチェックや差異が大きく異なりました。バックエンドのデータベースおよびサービスのコンテナスクリプトは、合計5分で完了しました。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AIは現状では開発効率を向上させる主な役割であり、基礎があることは最適です。AIがすべての問題を解決してくれるわけではありません&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;リポジトリアドレス&#34;&gt;リポジトリアドレス
&lt;/h2&gt;&lt;p&gt;タイトル通り、今回は手を動かさず、AIと雑談して、自選株モジュールを設計・開発してみます。最終的に何ができるのかを見てみたいと思います。&lt;/p&gt;
&lt;p&gt;リポジトリアドレス：&lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/trae-demo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/trae-demo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;詳細な使用方法は、リポジトリのREADME.mdファイルをご覧ください。&lt;/p&gt;
&lt;p&gt;このリポジトリには多数の提出記録が含まれており、ほとんどが私とTraeとの会話記録、およびTraeの機能に対する私のテストです。対応する機能を実装するために人工干渉を行ったかどうかを備考に記載しています。&lt;/p&gt;
&lt;h2 id=&#34;プロンプト&#34;&gt;プロンプト
&lt;/h2&gt;&lt;p&gt;プロジェクトは、ゼロから作成するものですが、以下はそのプロンプトです：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;プロジェクトのプロトタイプ図に基づいて、以下の機能を開発してください：株式の選定（ウォッチリスト）、新規追加、削除、修正、照会機能。選定株インターフェースには、基本的な市場データを表示する必要があります。複数の異なる市場への切り替えをサポートする必要があります。

フロントエンド：React
バックエンド：Golang Gin GORM
データベース：PostgreSQL

サーバーサイドは、クロスオリジンリクエストをサポートする必要があり、データの検証とエラー処理も考慮する必要があります。バックエンドサービスが利用できない場合、フロントエンドはアラートを表示する必要があります。

バックエンドは、リクエストとレスポンスのログを表示し、フロントエンドも通信ログを出力して問題のトラブルシューティングに役立てます。
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;uiとインタラクションの最適化&#34;&gt;UIとインタラクションの最適化
&lt;/h2&gt;&lt;p&gt;フロントエンドインターフェースのデザインは完全にGrokに依存しています。まず、Trae内で成果物のプロトタイプを作成しましたが、美観が欠けていました。使用していたモデルはコード能力は非常に高いものの、他の能力は弱いため、Grokを使用してフロントエンドのUIを最適化する必要があります。&lt;/p&gt;
&lt;p&gt;現在のインターフェースのスクリーンショットを撮影し、それをGrokにアップロードして、UIの最適化を依頼します。これにより、一度に多くの最適化提案を得ることができ、それらを人工的に評価し、Traeにコピーして実行し、最適化の効果を確認します。&lt;/p&gt;
&lt;h3 id=&#34;技術スタック&#34;&gt;技術スタック
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;フロントエンド：React + TypeScript&lt;/li&gt;
&lt;li&gt;バックエンド：Golang + Gin + GORM&lt;/li&gt;
&lt;li&gt;データベース：PostgreSQL 17&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;システムアーキテクチャ&#34;&gt;システムアーキテクチャ
&lt;/h2&gt;&lt;h2 id=&#34;后端アーキテクチャ&#34;&gt;后端アーキテクチャ
&lt;/h2&gt;&lt;p&gt;后端は Golang の Gin フレームワークを用いて RESTful API を実装しており、主なモジュールには以下が含まれます。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;データベースモジュール&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;GORM を ORM フレームワークとして使用&lt;/li&gt;
&lt;li&gt;環境変数でデータベース接続を設定可能&lt;/li&gt;
&lt;li&gt;データベーススキーマの自動移行機能&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ルーティングモジュール&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;RESTful API 設計&lt;/li&gt;
&lt;li&gt;一貫したエラーハンドリング機構&lt;/li&gt;
&lt;li&gt;内蔵のリクエストログ記録&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;クロスオリジン処理&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;ローカル開発環境でのクロスオリジンをサポート&lt;/li&gt;
&lt;li&gt;設定可能な CORS ポリシー&lt;/li&gt;
&lt;li&gt;Cookie によるクロスオリジンをサポート&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;フロントエンドアーキテクチャ&#34;&gt;フロントエンドアーキテクチャ
&lt;/h2&gt;&lt;p&gt;フロントエンドはReact + TypeScriptで構築され、以下の機能を実装しています。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;株価リストの表示&lt;/li&gt;
&lt;li&gt;お気に入り銘柄の管理&lt;/li&gt;
&lt;li&gt;相場データ表示&lt;/li&gt;
&lt;li&gt;エラー通知メカニズム&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>AI開発2年：ドッカーのリリース前の状態に似ている</title>
        <link>https://ttf248.life/ja/p/ai-development-two-years-like-docker-pre-release/</link>
        <pubDate>Thu, 20 Feb 2025 18:16:37 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ai-development-two-years-like-docker-pre-release/</guid>
        <description>&lt;p&gt;人工知能（AI）は近年、技術分野で最も議論を呼ぶトピックの一つであり、特に過去2年間でその進歩は目覚ましいものがありました。深層学習、自然言語処理、コンピュータビジョン、自動化意思決定システムなど、AIの応用範囲は多岐にわたります。しかしながら、技術が着実に進化を続けているにもかかわらず、AIはDockerのリリース前のボトルネックに似た状況にあります――つまり、市場を本格的に引き出す「ゲームチェンジャー」となる主要なアプリケーションが存在しないのです。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;プロンプト：記事を作成してください：AIは2年間の発展を経ており、Dockerのリリース前のボトルネックに似ています。既存技術に基づいて、完璧で実現可能なシナリオを作り出し、Dockerはあまり新しい技術を使用していませんが、全体的なソリューションは合理的に機能し、運用および開発ワークフローを変革します。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;aiの現状技術は成熟しているが応用には突破が必要&#34;&gt;AIの現状：技術は成熟しているが、応用には突破が必要
&lt;/h2&gt;&lt;p&gt;技術的な側面から見ると、AIは過去2年間で相当な進歩を遂げました。OpenAIが発表したGPTシリーズモデルや、GoogleのBERT、DeepMindのAlphaシリーズなど、AIの処理能力は以前の予測を大きく上回っています。特に自然言語処理分野では、GPT-4などのモデルが強力な生成能力に加えて、理解と推論においても驚くべきパフォーマンスを発揮しています。&lt;/p&gt;
&lt;p&gt;しかしながら、技術革新は日進月歩であるにもかかわらず、AIの実用的な応用においてはいくつかの課題が残されています。Dockerのリリース前の状況に似ており、AIの潜在力は巨大ですが、現状では広く普及し、産業を変革するようなゲームチェンジャーとなるアプリケーションはまだ出現していません。人々はAIの将来について議論していますが、必ずしも革命的な変化をもたらすことができる直接的な応用シナリオを見つけるとは限りません。&lt;/p&gt;
&lt;h2 id=&#34;dockerとaiの類似性技術は必ずしも革新ではなく解決策が重要&#34;&gt;DockerとAIの類似性：技術は必ずしも革新ではなく、解決策が重要
&lt;/h2&gt;&lt;p&gt;Dockerリリース前の歴史を振り返ると、技術環境とAIの現状には多くの類似点が見られることに気づきます。Dockerリリース前にコンテナ技術自体が新しいものではありませんでした。初期のLXC（Linux Containers）や仮想化技術もコンテナ化の基本的な能力を持っていました。しかし、Dockerは既存技術の巧みな統合と最適化を通じて、よりシンプルで直感的かつ効率的な解決策を提示しました。この解決策は、画期的な技術を導入したわけではありませんが、運用・開発プロセスにおける多くの課題を解決し、ソフトウェアのデプロイ、拡張、管理プロセスの大幅な簡素化を実現しました。&lt;/p&gt;
&lt;p&gt;同様に、AI分野も類似の状況に直面しています。 現在のAI技術は「新鮮なもの」ではなくなったとはいえ、本格的な大規模展開を実現するには、完璧な実現シナリオが必要であり、Dockerのように既存の技術を統合し最適化して、合理的なアプリケーションソリューションを形成することが求められます。AIの殺手級アプリケーションは、画期的な技術的ブレークスルーに依存するのではなく、既存の技術を組み合わせて、実際のビジネスにおける課題やニーズを解決することにあるかもしれません。&lt;/p&gt;
&lt;h2 id=&#34;aiのdocker-momentを見つけるには&#34;&gt;AIの「Docker Moment」を見つけるには？
&lt;/h2&gt;&lt;p&gt;AI技術が広く普及するためには、いくつかの側面から取り組む必要があります。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;実用的なシナリオの深掘り&lt;/strong&gt;
現在、多くのAIアプリケーションは実験的な性質を持ち、大規模な実用化に乏しいです。例えば、AIチャットボットやレコメンデーションシステムなどの分野は広く利用されていますが、その機能にはまだ多くの制約があり、業界のボトルネックを打破していません。真のブレイクスルーは、従来のやり方に困っている業界、例えば医療、製造業、物流などの分野から来る可能性があります。AIは、より効率的なデータ処理と予測分析を通じて、これらの複雑なシナリオにおいて企業が効率を高め、コストを削減するのを支援できます。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;製品化と使いやすさ&lt;/strong&gt;
Dockerのようにコンテナ化プロセスを簡素化し運用効率を向上させるのと同様に、AI製品の使いやすさは非常に重要です。 AIの普及は、技術の普及だけではなく、その製品化の普及でもある。AIを日常業務フローに統合し、ユーザーが技術を深く理解する必要なく、これらのツールを簡単に利用できるようにすることは、AIの実落地における重要な一歩である。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;エコシステムの構築と標準化&lt;/strong&gt;
新しい技術の広範な応用には、エコシステムの構築が不可欠である。Dockerが急速に台頭したのも、そのオープン性と互換性により、開発者がさまざまなクラウドプラットフォーム、ツール、サービスと容易に連携できたためである。同様に、AIの未来もエコシステムの構築に依存する。AIの標準化、モデルの共有、データのオープン、技術の統合可能性などが、AIが広範な産業応用を形成できるかどうかを左右するだろう。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;結論aiの未来は可能性に満ちているが更なる完成された落とし場所が必要である&#34;&gt;結論：AIの未来は可能性に満ちているが、更なる完成された落とし場所が必要である
&lt;/h2&gt;&lt;p&gt;過去2年間にわたり、AI技術は目覚ましい進歩を遂げているものの、現状では「決定的な応用例」が存在しない段階にある。Dockerリリース前のコンテナ化技術と似ているところもあるだろう。AIには、既存の技術をビジネスニーズと深く融合させる合理的な適用シナリオが必要であり、初めて大規模な応用と普及を実現できる。技術革新は重要であることはもちろんだが、業務プロセスを簡素化し、効率を高めるソリューションこそが、技術の普及と発展を促進するだろう。&lt;/p&gt;
&lt;p&gt;未来において、AIはDockerのように、画期的な技術的ブレークスルーではなく、既存技術を統合し、完璧な適用シナリオを構築することで、私たちの仕事や生活様式を変革していく可能性がある。&lt;/p&gt;</description>
        </item>
        <item>
        <title>ollama ローカル実行 deepseek-R1</title>
        <link>https://ttf248.life/ja/p/ollama-local-deployment-deepseek-r1/</link>
        <pubDate>Fri, 07 Feb 2025 22:41:02 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ollama-local-deployment-deepseek-r1/</guid>
        <description>&lt;p&gt;Ollamaは、大規模言語モデル (LLM) をローカルで実行およびデプロイできるように設計されたオープンソースのAIツールです。クラウドサービスへの依存を減らし、開発者がローカルマシン上でGPTのようなモデルを使用するための便利な効率的な方法を提供することを目的としています。Ollamaは複数のモデルをサポートし、パフォーマンスを最適化することに重点を置いており、リソースが限られたデバイスでもこれらのモデルをスムーズに実行できるようにします。&lt;/p&gt;
&lt;p&gt;Ollamaを通じて、テキストベースのAIアプリケーションを使用でき、ローカルでデプロイされたモデルとインタラクションできます。データプライバシーやAPIの使用料金に関する懸念なくです。コマンドラインインターフェース (CLI) を使用してさまざまなモデルを呼び出し、自然言語処理、質問応答などのタスクを実行できます。 &amp;gt; ollama は様々なモデルを試すのに適しており、Windows 版でテストしたところ、ハードウェアの性能を十分に発揮することができませんでした。これは Windows 版の問題である可能性があり、Linux 版の方が良いかもしれません。32b パラメータのモデルをデプロイする際、メモリや GPU の負荷が低い状況でも、応答速度が遅い。&lt;/p&gt;
&lt;h2 id=&#34;ハードウェア概要&#34;&gt;ハードウェア概要
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;オペレーティングシステム: Windows 11&lt;/li&gt;
&lt;li&gt;CPU: i7-10700K&lt;/li&gt;
&lt;li&gt;メモリ: 40GB&lt;/li&gt;
&lt;li&gt;グラフィックカード: RTX 3060 12GB&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;環境準備&#34;&gt;環境準備
&lt;/h2&gt;&lt;p&gt;以下のシステム環境変数を設定し、後続の使用を容易にします：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_MODELS=E:\ollama&lt;/code&gt;&lt;/strong&gt;
この変数で Ollama モデルの保存パスを指定します。 &lt;code&gt;E:\ollama&lt;/code&gt; はフォルダパスであり、ダウンロードまたはデプロイしたローカルモデルファイルをすべてここに格納します。Ollama はこのパスに基づいてモデルをロードおよび使用します。モデルファイルの場所を変更する場合は、このパスを更新してください。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_HOST=127.0.0.1:8000&lt;/code&gt;&lt;/strong&gt;
この環境変数は Ollama サービスのホストとポートを設定します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;127.0.0.1&lt;/code&gt; はローカルアドレス（localhost）であり、Ollama サービスは本機からのリクエストのみを待ち受けます。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;8000&lt;/code&gt; は指定するポート番号であり、Ollama サービスが 8000 ポートでリクエストを受信および処理します。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;環境準備-1&#34;&gt;環境準備
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_ORIGINS=*&lt;/code&gt;&lt;/strong&gt;
この環境変数によって、Ollama サービスにアクセスできるリクエストのソースを制御します。
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;*&lt;/code&gt; はすべてのソース（つまり、すべてのドメインと IP アドレス）が Ollama サービスにアクセスできるようにすることを意味します。これは通常、開発およびデバッグ環境で使用され、本番環境では、セキュリティを高めるために特定のドメインまたは IP アドレスのみがサービスへのアクセスを許可するようにより厳格なソース制御を指定することが一般的です。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;deepseek-r1-モデルのデプロイ&#34;&gt;DeepSeek-R1 モデルのデプロイ
&lt;/h2&gt;&lt;p&gt;ollama のインストールは、初心者向けで簡単なため、詳細は省略します。
インストール後の検証：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core&amp;gt;ollama -v
ollama version is 0.5.11
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;モデルのデプロイについては、公式ウェブサイトのモデルページを参照し、対応するパラメータのモデルを選択してください: &lt;code&gt;ollama run deepseek-r1:14b&lt;/code&gt;
14b パラメータは会話コンテキストを効果的に記憶でき、より小さなパラメータバージョンではコンテキストを記憶できません。32b パラメータバージョンは、ローカルでのデプロイ時に非常に遅延するため、詳細なテストは行っていません。&lt;/p&gt;
&lt;h2 id=&#34;参考文献&#34;&gt;参考文献
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ollama.com/library/deepseek-r1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.ollama.com/library/deepseek-r1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/x18990027/article/details/145368094&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/x18990027/article/details/145368094&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>DeepSeek（ディープシーク）が旧正月前に急激に人気を博し、NVIDIAの株価が暴落した：その裏にある機関投資家の動きと大規模言語モデルの思考連鎖</title>
        <link>https://ttf248.life/ja/p/deepseek-explodes-before-chinese-new-year-nvidia-stock-plummets-behind-the-scenes-and-large-language-model-reasoning/</link>
        <pubDate>Fri, 07 Feb 2025 20:36:05 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/deepseek-explodes-before-chinese-new-year-nvidia-stock-plummets-behind-the-scenes-and-large-language-model-reasoning/</guid>
        <description>&lt;p&gt;旧正月前夕，DeepSeek 一度成为热门话题，短短几天内便在社交媒体上引起了广泛关注。这种突然的爆火，不仅让人惊讶，还带动了市场的连锁反应。与此同时，英伟达的股票却迎来了暴跌，许多投资者对其前景产生了疑虑，部分机构在此期间进行了大规模的做空操作，似乎一切都指向了一个“精心策划”的局面。&lt;/p&gt;
&lt;h3 id=&#34;deepseek-の爆発的な人気短期間で急速に注目を集める&#34;&gt;&lt;strong&gt;DeepSeek の爆発的な人気：短期間で急速に注目を集める&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;DeepSeek は、AI を活用したツールであり、特に自然言語処理（NLP）および画像生成分野における深層学習モデルの最適化に焦点を当てています。旧正月前の数日間、このプロジェクトは投資家や技術者から急増するほどの関心を集めました。その背後にあるチームのパフォーマンスと展示された技術成果が、多くの人々を強く惹きつけました。開発者コミュニティやソーシャルメディアプラットフォームにおいて、DeepSeek に関する議論は技術界全体のあらゆる話題を占めています。&lt;/p&gt;
&lt;p&gt;しかし、DeepSeek の突然爆発的な人気は偶然ではありませんでした。分析の結果、何らかの組織による操作の可能性が疑われるようになり始めました。&lt;/p&gt;
&lt;h3 id=&#34;nvidia-株価暴落ショート売り戦略の裏黒幕&#34;&gt;&lt;strong&gt;NVIDIA 株価暴落：ショート売り戦略の裏黒幕&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;NVIDIA（エヌビディア）、世界をリードするグラフィックス処理ユニット（GPU）メーカーは、長年にわたり、多くの大規模言語モデルやAI計算における重要なハードウェアサプライヤーとして存在感を示してきました。AI市場の急速な発展に伴い、NVIDIA の株価は長期にわたって堅調で、投資家の注目を集めてきました。しかし、DeepSeek の爆発的な人気と市場におけるその技術への高い関心により、NVIDIA の株価は急落しました。
この現象の裏には、機関投資家によるショート売り戦略が潜んでいる可能性があります。過去数年間、AI 技術の普及に伴い、NVIDIA の株価は過度に高騰しており、多くの投資家がその株価に過剰な期待を抱いていると認識していました。特に DeepSeek などの技術が爆発的に人気を集めた後、一部の機関投資家が NVIDIA の株式をショートすることで、かなりの利益を得た可能性があります。&lt;/p&gt;
&lt;h3 id=&#34;大規模言語モデルの推論チェーンへの接触結果からプロセスへ&#34;&gt;&lt;strong&gt;大規模言語モデルの推論チェーンへの接触：結果からプロセスへ&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;従来の人工知能アプリケーションにおいて、多くの実務者や投資家は、AI モデルの「結果」—生成された画像、テキストなどの直接的なアウトプットに多く注目してきました。一方、DeepSeekに関連する議論の中で、ますます多くの人が、大規模言語モデルの背後に隠された推論チェーンこそがより注目すべき核心内容であることに気づき始めています。これまで、私たちはモデルが出力した結果しか見ることができませんでしたが、今では、その背後にあるロジック、アルゴリズム、そしてこれらの要素を調整することでモデルのパフォーマンスを最適化する方法を理解する必要があります。&lt;/p&gt;
&lt;p&gt;この思考様式の転換は、AI 研究およびアプリケーションに対する深い考察であることを意味します。 単純なブラックボックス操作から、モデル内部の動作メカニズムを真正に理解する変革へと移行し、多くの技術者や投資家が人工知能の将来的な発展方向を再考し始めた。DeepSeek の爆発的な人気は、まさにこの思考連鎖の画期的な応用であり、人々が単なる最終的な出力結果ではなく、全体のモデル構築と最適化プロセスに注目し始めるきっかけとなった。&lt;/p&gt;
&lt;h3 id=&#34;まとめ&#34;&gt;&lt;strong&gt;まとめ&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;DeepSeekの突然的な爆発、英偉達株の大暴落、そして市場の裏で機関がショートしたという事実は、すべてが緻密に設計された罠であるかのようだ。大規模言語モデルの思考連鎖を深く理解することで、AI技術の応用は表面的な現象の積み重ねではなく、モデル内部ロジックの深い掘り起こしと最適化であることを認識できる。技術の進歩とともに、今後もDeepSeekのような革新的なツールが登場し、AI研究・応用がより高度なレベルへと発展していく可能性がある。&lt;/p&gt;
&lt;p&gt;この現象は、AI技術の巨大な潜在能力を私たちに示すだけでなく、技術背後にあるビジネスの駆け引きや資本の動きについても考えさせ始めるきっかけとなった。今後の市場の動向は、技術と資本の博弈という継続的な焦点となるだろう。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Cursor AI プログラミングIDE のトライアル</title>
        <link>https://ttf248.life/ja/p/cursor-ai-programming-ide-trial/</link>
        <pubDate>Thu, 23 Jan 2025 19:30:13 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/cursor-ai-programming-ide-trial/</guid>
        <description>&lt;p&gt;一年又转眼即逝之际，在工作中最大的变化莫过于AI参与度显著提升了。相较于以往，不同开发语言之间的切换，需要开发者熟悉各种语言不同的API接口，现在这些基础代码都可以通过AI生成代码了，对于开发者来说，无疑是一个巨大的福音。&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;23年の時点で、簡単な入門紹介を既に2本作成していましたが、今では25年となり、どう表現しようか…顕著な進歩を感じ取ることはなく、自律的な認知能力を発展させ、タスクを合理的に分割できること、そして何よりもAIが生成したコードにバグがないかを識別することが重要です。&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;Github Copilot
&lt;/h2&gt;&lt;p&gt;いつの日か忘れましたが、情報を見てみるとシンガポールでサーバーがデプロイされ、国内で使用されているとのことです。これからは長期間VPNに接続する必要はなくなります。ただし、ログイン時にはやはりVPNを接続する必要があります。しかし、このVPNはログイン時のみ使用し、その後はオフにしてしまえば良いのです。&lt;/p&gt;
&lt;p&gt;普段使いではGithub Copilotの方がより多く利用されます。この拡張機能は、VS CodeやVisual Studioで直接使用できます。2つのソフトウェア間の切り替えが不要です。ChatGPTと比較して、Github Copilotはプロジェクトに対するサポートが優れており、インタラクションも友好的です。また、一部のローカルファイルをAIに「学習」させることで、生成されるコードをあなたのプロジェクトに合わせてより適切に調整することができます。&lt;/p&gt;
&lt;h2 id=&#34;cursor-ai&#34;&gt;Cursor AI
&lt;/h2&gt;&lt;p&gt;最近、Cursor AI という新しいAIプログラミングIDEを見つけました。このIDEもGithub Copilotをベースにしているのですが、よりスマートで、直接ファイルを作成するのを手伝ってくれます。&lt;/p&gt;
&lt;p&gt;簡単な使い心地を試したところ、なかなか良いと感じましたが、既存プロジェクトの理解はまだ十分ではなく、ローカルプロジェクトファイルの多さによっては、大規模なリファクタリングや最適化、調整には&lt;strong&gt;開発者がタスクを分割&lt;/strong&gt;する必要があります。&lt;/p&gt;
&lt;p&gt;例として、cursoにエンジニアモードを切り替えて、以下の内容を入力してみましょう。「複数の異なるスタイルで切り替え可能な個人用履歴書ウェブページの作成、データ表示のために個人情報を埋めることを忘れないで」&lt;/p&gt;
&lt;p&gt;何度かやり取りするうちに、以下のようなウェブページが得られました。もちろん、このウェブページは比較的シンプルですが、初心者にとっては非常に良いでしょう。 ## Cursor AI&lt;/p&gt;
&lt;p&gt;最近、Cursor AI という新しいAIプログラミングIDEを試してみました。これはGithub Copilotにも基づいているもので、このIDEはさらに賢く、直接ファイルを作成するのを手伝ってくれます。&lt;/p&gt;
&lt;p&gt;簡単な使い心地ですが、全体的に良い印象を受けました。しかし、既存のプロジェクトの理解はまだ十分ではなく、ローカルプロジェクトのファイルが多い場合は、大規模なリファクタリングや最適化、調整には&lt;strong&gt;開発者がタスクを分割&lt;/strong&gt;する必要があります。&lt;/p&gt;
&lt;p&gt;例として、curso のエンジニアモードに切り替えて、以下の内容を入力しました：「複数の異なるスタイルで切り替え可能な個人用履歴書ウェブページの作成、データ表示のためにいくつかの個人情報を埋めることを忘れないで」&lt;/p&gt;
&lt;p&gt;何度かやり取りするうちに、以下のようなウェブページが得られました。もちろん、このウェブページは比較的シンプルですが、初心者にとっては非常に良いものと言えるでしょう。&lt;/p&gt;
&lt;h2 id=&#34;cursor-ai-1&#34;&gt;Cursor AI
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://cursor/index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;履歴書&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>AIプログラミングとタスク分解</title>
        <link>https://ttf248.life/ja/p/ai-programming-and-task-decomposition/</link>
        <pubDate>Fri, 22 Dec 2023 08:44:26 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ai-programming-and-task-decomposition/</guid>
        <description>&lt;p&gt;2年前、サイトにコード領域のコピー機能を追加するために、半日ほど試行錯誤した結果、レンダリング効果があまり理想的ではなかった。半ば無能なフロントエンド開発者として、改善することも思わずに、動けばそれで十分と考えていた。今年、&lt;code&gt;AI&lt;/code&gt;を使って小程序を開発し、フロントエンドの開発もより慣れてきた。そして、リファクタリングを行った（&lt;code&gt;AI&lt;/code&gt;が再設計）。&lt;/p&gt;
&lt;p&gt;悟り：タスク分解をして、多くの小さなタスクは&lt;code&gt;AI&lt;/code&gt;で開発すると手馴れた。すでに閉鎖された小程序において、&lt;code&gt;75%&lt;/code&gt;のコードを&lt;code&gt;AI&lt;/code&gt;が提供し、複数のタスクを分割して引き渡すことで、人工によってプロジェクトコードが&lt;code&gt;組み立て&lt;/code&gt;られた。&lt;/p&gt;
&lt;h2 id=&#34;前文&#34;&gt;前文
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://ttf248.github.io/post/2022/001/%E4%BB%A5%E4%B8%BA%E5%BE%88%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%8B%E6%83%85%E5%A2%9E%E5%8A%A0%E4%B8%80%E4%B8%AA%E4%BB%A3%E7%A0%81%E5%A4%8D%E5%88%B6%E6%8C%89%E9%92%AE/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;簡単なことだと考えたこと、コードのコピーボタンを追加&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;promot&lt;/strong&gt;: CSSとJavaScriptコードを設計し、class=&amp;ldquo;highlight&amp;quot;のクラスを持つWebページの要素とそのコンテナ内にコピーボタンを追加して、コードをコピーできるようにする。最初のドラフトは一見問題があるため、基本的には使用可能なものを生成し、コピーされた内容が不正確で冗長な文字が含まれているため、再度最適化を誘導し、コアとなる色のデザインを指定し、エフェクトを含める。
お客様がボタンのサイズと色に関して特定の要件をお持ちであることを理解しましたので、これらの要件に合わせてボタンのスタイルを再設計できます。以下に、ご提供いただいたカラーパレットを使用し、ボタンのサイズを最適化したCSSスタイルの例を示します。&lt;/p&gt;
&lt;h2 id=&#34;本文&#34;&gt;本文
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.copy-btn {
  position: absolute;
  top: 2px; /* 位置の調整 */
  right: 2px;
  padding: 3px 6px; /* サイズ縮小 */
  font-size: 12px; /* フォントサイズの変更 */
  background-color: #8FD1E1; /* ボタンの背景色 */
  color: #272822; /* 文字の色 */
  border: 1px solid #272822; /* ボーダーの色 */
  border-radius: 3px; /* 角丸 */
  cursor: pointer;
  opacity: 0.7; /* デフォルトの透明度 */
  transition: opacity 0.3s ease, background-color 0.3s ease; /* 平滑なトランジション効果 */
}

.copy-btn:hover {
  opacity: 1; /* マウスオーバー時の透明度 */
  background-color: #A3D4E5; /* マウスオーバー時の背景色 */
}

.highlight {
  position: relative;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;正文-1&#34;&gt;正文
&lt;/h2&gt;&lt;p&gt;このスタイルでは、ボタンのサイズとフォントサイズを小さくし、より洗練された印象にしました。また、ボタンのデフォルト状態を半透明にし、マウスをホバーすると不透明になり、背景色がわずかに明るくなることで視覚的なフィードバックを提供します。これにより、お客様のご希望の色合いも反映させつつ、モダンでユーザーフレンドリーな特徴を維持しています。
対応するよりシンプルな &lt;code&gt;JavaScript&lt;/code&gt; を以下に示します：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-JavaScript&#34;&gt;document.addEventListener(&#39;DOMContentLoaded&#39;, function() {
  // すべての .highlight 要素を検索します
  const highlights = document.querySelectorAll(&#39;.highlight&#39;);

  highlights.forEach(function(highlight) {
    // コピーボタンを作成します
    const copyBtn = document.createElement(&#39;button&#39;);
    copyBtn.textContent = &#39;コピー&#39;;
    copyBtn.classList.add(&#39;copy-btn&#39;);

    // ボタンを各 .highlight 要素に追加します
    highlight.appendChild(copyBtn);
  });
});
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;本文-1&#34;&gt;本文
&lt;/h2&gt;&lt;p&gt;// 各 .highlight 要素にボタンを追加します。
highlight.appendChild(copyBtn);&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// クリックイベントリスナーを追加します。
copyBtn.addEventListener(&#39;click&#39;, function() {
  // .highlight の最初の &amp;lt;code&amp;gt; 要素がコピーするコードを含むと仮定します。
  const code = highlight.querySelector(&#39;code&#39;) ? highlight.querySelector(&#39;code&#39;).textContent : &#39;&#39;;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## 正文
navigator.clipboard.writeText(code).then(() =&amp;gt; {
    // 複製成功メッセージを表示
    copyBtn.textContent = &#39;已コピー！&#39;;
    setTimeout(() =&amp;gt; {
      copyBtn.textContent = &#39;コピー&#39;;
    }, 2000);
  }).catch(err =&amp;gt; {
    console.error(&#39;複製失敗: &#39;, err);
  });
});
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;終わりに&#34;&gt;終わりに
&lt;/h2&gt;&lt;p&gt;コード領域の右上隅、トップエリアにコピーボタンを追加することを望んでいたが、フロントエンドに関する知識が不足しており、キーワードに基づいて機能を正確に記述することができなかったため、AIとやり取りを繰り返すだけで期待された結果には至らなかった。&lt;/p&gt;
&lt;p&gt;しかし、時間の経過とともにAIがソフトウェア開発にどの程度影響を与えるのかはまだわからない。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>プロンプトエンジニア</title>
        <link>https://ttf248.life/ja/p/prompt-engineer/</link>
        <pubDate>Sun, 26 Mar 2023 20:46:53 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/prompt-engineer/</guid>
        <description>&lt;p&gt;例として、かつて検索エンジンのテクニックを学んだように、私たちはまた &lt;code&gt;AI&lt;/code&gt; とコミュニケーションするためのテクニックも習得する必要がある。合理的な制約条件を与え、効率的に必要な答えを得る方法を学ぶのだ。&lt;/p&gt;
&lt;p&gt;もし角度を変えて考えると、現在の &lt;code&gt;AI&lt;/code&gt; は記憶力に優れた小さな子供であり、完璧に暗記し、宿題をコピーできる能力を持っている。私たちがやるべきことは、&lt;code&gt;AI&lt;/code&gt; と正確かつ効果的にコミュニケーションする方法を学び、要求を正確に記述し、&lt;code&gt;AI&lt;/code&gt; が期待される結果を生み出すのを助けることだ。&lt;/p&gt;
&lt;h2 id=&#34;科学普及&#34;&gt;科学普及
&lt;/h2&gt;&lt;p&gt;話題となっている&lt;code&gt;AI&lt;/code&gt;（人工知能）を具体的に言うと&lt;code&gt;Generative Pre-Training&lt;/code&gt;（生成事前学習）です。これは、インターネットで利用可能なデータを用いて訓練されたテキスト生成のための深層学習モデルであり、質問応答、テキスト要約生成、機械翻訳、分類、コード生成、対話型AIなど様々なタスクに使用されます。現在、GPT-1、GPT-2、GPT-3、GPT-4といった異なるバージョンのモデルが存在し、それぞれが前バージョンよりも規模が大きく、性能も向上しています。&lt;/p&gt;
&lt;h2 id=&#34;到底有没有智能&#34;&gt;到底有没有智能
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;類似度が高ければ高いほど、精度も高くなる&lt;/li&gt;
&lt;li&gt;基本的な、反復性の仕事は、特定の訓練を受けることで、人工の介入が不要になる
生成式AIとは、既存のテキスト、音声、画像などのデータを活用して新しいコンテンツを作成する技術である。テキスト生成、音声合成、画像生成、対話システムなど、様々なタスクに使用できる。生成式AIの論理性は、その学習データとモデル構造に依存する。一般的に、生成式AIは一定程度、文法、論理、常識に従うことができるが、誤りや偏見、または不真実を含むコンテンツを生成することもある。そのため、生成式AIの出力は人間の判断と検証が必要であり、盲目的に信頼したり使用したりすることはできない。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;プロンプトエンジニア&#34;&gt;プロンプトエンジニア
&lt;/h2&gt;&lt;p&gt;時間は流れようと逆らえない。人は潮流に適応することを学ぶ必要がある。AIを無駄なものだと考え、論理性がないと考えてしまうことがあるだろう。実際には、現在のAIは記憶力に優れた幼い子供であり、丸わかり能力、つまりコピー能力を持っている。私たちがやるべきことは、AIとどのように正しく、効果的に、そしてうまくコミュニケーションをとるか、正確な要求を記述し、AIが期待される結果を生み出すのを助けることだ。&lt;/p&gt;
&lt;h2 id=&#34;対話モデル&#34;&gt;対話モデル
&lt;/h2&gt;&lt;p&gt;2年前、GitHub Copilotの発表は誰も予想していませんでした。その結果、OpenAIが横空に出現し、人類は大規模言語モデルの能力を認識するに至りました。&lt;/p&gt;
&lt;p&gt;コメントベースのプログラミングと対話ベースのプログラミングというインターフェースの違いにより、インタラクティブなロジックは完全に異なり、対話モデルは初心者ユーザーにとって親しみやすいインタラクション体験を提供します。ここでNewBingが各質問の後に提示するフォローアップのヒントを必ず言及する必要があります。Microsoftは、AI知識ベースからより多くのコンテンツを取得するために、ユーザーに誘導しようと試みています。&lt;/p&gt;
&lt;h2 id=&#34;例え話&#34;&gt;例え話
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;シナリオ:&lt;/strong&gt; 高速鉄道の旅は長く、コーディングは良い選択肢です。データ容量が限られている場合、いくつかの画像を処理し、画像素材を入手しました。ソフトウェアで画像を処理するのは少し贅沢で、ネットワーク条件も許容されていません。
&lt;strong&gt;要件:&lt;/strong&gt; 画像素材のコレクションがあり、透明背景付きで、小アプリのナビゲーションバーで使用します。選択された状態はカラフルで、未選択の状態は白黒です。素材はすべてカラフルであり、事前に処理する必要があります。
&lt;strong&gt;プロンプト:&lt;/strong&gt; Pythonコードを記述して、フォルダからすべての画像を読み取り、画像を白黒に変換し、透明背景を維持し、画像を保存するときに画像の品質を最適化し、ファイルサイズを削減し、同時にコンソールで表示し、前後のファイルサイズの比較を行います。&lt;/p&gt;
&lt;h2 id=&#34;例を挙げる&#34;&gt;例を挙げる
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 必要なライブラリをインポートする
import os
import PIL
from PIL import Image
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;例え話-1&#34;&gt;例え話
&lt;/h2&gt;&lt;h1 id=&#34;画像を白黒に変換し透明背景を維持し画像を保存しファイルサイズを返す関数を定義します&#34;&gt;画像を白黒に変換し、透明背景を維持し、画像を保存し、ファイルサイズを返す関数を定義します。
&lt;/h1&gt;&lt;p&gt;def convert_and_save(image_file):
# 画像を開く
image = Image.open(image_file)
# 画像のモードを取得し、RGBA モードの場合、透明背景があることを意味する
mode = image.mode
if mode == &amp;ldquo;RGBA&amp;rdquo;:
# 画像と同じサイズの白い背景画像を作成する
background = Image.new(&amp;ldquo;RGB&amp;rdquo;, image.size, (255, 255, 255))
# 元の画像を白い背景に貼り付け、透明ピクセルを無視する
background.paste(image, mask=image.split()[3])
# 合成された画像をグレースケールモードに変換する
gray_image = background.convert(&amp;ldquo;L&amp;rdquo;)
# グレースケール画像をRGBAモードに戻し、透明背景を保持する&lt;/p&gt;
&lt;h2 id=&#34;例えを挙げる&#34;&gt;例えを挙げる
&lt;/h2&gt;&lt;p&gt;gray_image = background.convert(&amp;ldquo;L&amp;rdquo;)
# 背景画像をグレースケールに変換し、透明背景を保持するためにRGBAモードに変換する
final_image = gray_image.convert(&amp;ldquo;RGBA&amp;rdquo;)
else:
# RGBAモードでない場合は、直接画像をグレースケールに変換する
final_image = image.convert(&amp;ldquo;L&amp;rdquo;)
# 元の画像のファイル名と拡張子を取得する
file_name, file_ext = os.path.splitext(image_file)
# 新しい画像のファイル名を定義し、&amp;quot;_bw&amp;quot;サフィックスを追加して白黒であることを示す
new_file_name = file_name + &amp;ldquo;_bw&amp;rdquo; + file_ext
# 新しい画像を保存し、品質を最適化してファイルサイズを削減する
final_image.save(new_file_name, optimize=True)
# 元の画像と新しい画像のファイルサイズを取得し、返す&lt;/p&gt;
&lt;h2 id=&#34;例を挙げる例を示す&#34;&gt;例を挙げる（例を示す）
&lt;/h2&gt;&lt;h1 id=&#34;新しい画像を保存し品質を最適化してファイルサイズを削減する&#34;&gt;新しい画像を保存し、品質を最適化してファイルサイズを削減する
&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;final_image.save(new_file_name, optimize=True)
# 元の画像と新しい画像のファイルサイズを取得し、返す
old_size = os.path.getsize(image_file)
new_size = os.path.getsize(new_file_name)
return old_size, new_size
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;例え話-2&#34;&gt;例え話
&lt;/h2&gt;&lt;h1 id=&#34;画像を保存するすべてのフォルダのパスを定義します&#34;&gt;画像を保存するすべてのフォルダのパスを定義します。
&lt;/h1&gt;&lt;p&gt;folder_path = &amp;ldquo;images&amp;rdquo;&lt;/p&gt;
&lt;h1 id=&#34;フォルダ内のすべてのファイルを確認します&#34;&gt;フォルダ内のすべてのファイルを確認します。
&lt;/h1&gt;&lt;p&gt;for file in os.listdir(folder_path):
# ファイルへの完全なパスを結合します。
file_path = os.path.join(folder_path, file)
# 画像ファイルの拡張子に基づいて、画像ファイルを判断します（必要に応じて拡張子を追加または変更できます）。
if file_path.endswith((&amp;quot;.png&amp;quot;, &amp;ldquo;.jpg&amp;rdquo;, &amp;ldquo;.jpeg&amp;rdquo;, &amp;ldquo;.gif&amp;rdquo;)):
# 画像を変換して保存し、ファイルサイズを取得する関数を呼び出します。
old_size, new_size = convert_and_save(file_path)
# 変換前のファイルと変換後のファイルサイズの比較をコンソールに出力します。
print(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)&lt;/p&gt;
&lt;h2 id=&#34;例え話-3&#34;&gt;例え話
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;AI&lt;/code&gt;は迅速に答えを提示し、見た目も美しく、使い勝手も問題ありませんでした。経験豊富なプログラムソースとしては、以下のコードが汎用性に欠け、本番環境へのデプロイも困難だと感じました：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;パラメータが固定されている&lt;/li&gt;
&lt;li&gt;ログファイルがなく、すべての情報がコンソールに出力されている&lt;/li&gt;
&lt;li&gt;画像処理タスクにはマルチスレッドモデルが適している&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;NewBing&lt;/code&gt;が登場し、プロンプトに基づいて問題を選択しました：「&lt;strong&gt;このコードの改善点はありますか？&lt;/strong&gt;」&lt;/p&gt;
&lt;p&gt;今回提示された回答は、正直に言って、予想を大幅に上回るものでした。一般的なプログラマが思いつくような最適化策を&lt;code&gt;AI&lt;/code&gt;が提案しました。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;このコードには、以下のような改善点がある可能性があります：

`argparse`ライブラリを使用して、コマンドライン引数からフォルダーパスと拡張子を指定できるようにすることで、コードにハードコーディングされたままでは無くなります。 ログ記録ライブラリを使用し、プログラムの実行状況をコンソールへの直接出力ではなく記録することが可能です。
try-except文を使用して、ファイルオープン失敗や画像変換失敗などの例外を捕捉し、適切な処理を行うことができます。
multiprocessingライブラリを使用して、複数のCPUコアを活用することで、画像の変換と保存プロセスを高速化できます。

（環境の違いを考慮し、マルチプロセッシングのサポートがない場合に備えて記述されています。）

## 例を挙げてみましょう

```shell
もちろん、コードの修正をお手伝いさせていただきます。argparse、logging、try-except文を追加しましたが、マルチプロセッシングライブラリは、あなたのコンピュータがマルチコア処理に対応しているかどうか不明なため追加していません。修正後のコードは以下のとおりです：
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;例を挙げる-1&#34;&gt;例を挙げる
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 必要なライブラリのインポート
import argparse
import logging
import multiprocessing
import os

from PIL import Image
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;例え話-4&#34;&gt;例え話
&lt;/h2&gt;&lt;h1 id=&#34;画像を白黒に変換し透明背景を維持し画像を保存しファイルサイズを返す関数を定義します-1&#34;&gt;画像を白黒に変換し、透明背景を維持し、画像を保存し、ファイルサイズを返す関数を定義します。
&lt;/h1&gt;&lt;p&gt;def convert_and_save(image_file):
# 画像を開く
try:
image = Image.open(image_file)
except Exception as e:
logging.error(f&amp;quot;&amp;rsquo;{image_file}&amp;rsquo; のオープンに失敗しました：{e}&amp;quot;)
return None, None
# 画像のモードを取得し、RGBA モードの場合、透明背景があることを意味します。
mode = image.mode
if mode == &amp;ldquo;RGBA&amp;rdquo;:
# 画像と同じサイズの白い背景画像を作成します。
background = Image.new(&amp;ldquo;RGB&amp;rdquo;, image.size, (255, 255, 255))
# 元の画像を白い背景に貼り付け、透明ピクセルを無視します。
background.paste(image, mask=image.split()[3])&lt;/p&gt;
&lt;h2 id=&#34;例えを挙げる-1&#34;&gt;例えを挙げる
&lt;/h2&gt;&lt;h1 id=&#34;元の画像を白色背景に貼り付け透明ピクセルを無視する&#34;&gt;元の画像を白色背景に貼り付け、透明ピクセルを無視する
&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;    background.paste(image, mask=image.split()[3])
    # 合成された画像にグレースケールモードに変換する
    gray_image = background.convert(&amp;quot;L&amp;quot;)
    # グレースケール画像をRGBAモードに戻し、透明背景を保持する
    final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
else:
    # RGBA モードでない場合は、直接画像にグレースケールモードで変換する
    final_image = image.convert(&amp;quot;L&amp;quot;)
# 元の画像のファイル名と拡張子を取得する
file_name, file_ext = os.path.splitext(image_file)
# 新しい画像のファイル名を定義し、_bw サフィックスを追加してモノクロであることを示す
new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
# 新しい画像を保存し、品質を最適化してファイルサイズを削減する
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;例を挙げる-2&#34;&gt;例を挙げる
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # 新しい画像を保存し、品質を最適化してファイルサイズを削減する
    try:
        final_image.save(new_file_name, optimize=True)
    except Exception as e:
        logging.error(f&amp;quot; {new_file_name} の保存に失敗しました：{e}&amp;quot;)
        return None, None
    # 元の画像と新しい画像のファイルサイズを取得し、返す
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return file_name, old_size, new_size
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;例を挙げる例を示す-1&#34;&gt;例を挙げる（例を示す）
&lt;/h2&gt;&lt;h1 id=&#34;コマンドライン引数を解析しフォルダパスと拡張子リストを返す関数を定義する&#34;&gt;コマンドライン引数を解析し、フォルダパスと拡張子リストを返す関数を定義する
&lt;/h1&gt;&lt;p&gt;def parse_args():
# パーサーオブジェクトを作成する
parser = argparse.ArgumentParser(description=&amp;ldquo;画像を白黒に変換し、品質を最適化する。&amp;rdquo;)
# 必須の位置引数として、フォルダパスを追加する
parser.add_argument(&amp;ldquo;folder_path&amp;rdquo;, help=&amp;ldquo;画像が含まれるフォルダのパス。&amp;rdquo;)
# オプションの引数として、拡張子リストを追加する（デフォルトは png, jpg, jpeg, gif）
parser.add_argument(&amp;quot;-e&amp;quot;, &amp;ldquo;&amp;ndash;extensions&amp;rdquo;, nargs=&amp;quot;+&amp;quot;, default=[&amp;quot;.png&amp;quot;, &amp;ldquo;.jpg&amp;rdquo;, &amp;ldquo;.jpeg&amp;rdquo;, &amp;ldquo;.gif&amp;rdquo;], help=&amp;ldquo;画像ファイルの拡張子。&amp;rdquo;)
# コマンドライン引数を解析し、結果オブジェクトを返す&lt;/p&gt;
&lt;h2 id=&#34;例を挙げる-3&#34;&gt;例を挙げる
&lt;/h2&gt;&lt;h1 id=&#34;コマンドライン引数を解析し結果オブジェクトを返す&#34;&gt;コマンドライン引数を解析し、結果オブジェクトを返す
&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;args = parser.parse_args()
return args.folder_path, args.extensions
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;例を挙げる-4&#34;&gt;例を挙げる
&lt;/h2&gt;&lt;h1 id=&#34;実行前に後のファイルサイズと実行後にファイルサイズを比較する関数を定義します&#34;&gt;実行前に後のファイルサイズと実行後にファイルサイズを比較する関数を定義します。
&lt;/h1&gt;&lt;p&gt;def print_result(result):
# 結果が空でない場合、変換と保存が成功したことを意味します。
if result:
# 結果をファイル名とファイルサイズのタプルにアンパックします。
if len(result) == 3:
file, old_size, new_size = result
# コンソールで最適化前のファイルサイズと実行後のファイルサイズを比較を表示します。
logging.info(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)
else:
logging.info(f&amp;quot;{result}&amp;quot;)&lt;/p&gt;
&lt;h2 id=&#34;例を挙げる-5&#34;&gt;例を挙げる
&lt;/h2&gt;&lt;h1 id=&#34;ロギングモジュールを設定しログをコンソールとファイルに出力しログレベルをinfoに設定する&#34;&gt;ロギングモジュールを設定し、ログをコンソールとファイルに出力し、ログレベルをINFOに設定する。
&lt;/h1&gt;&lt;p&gt;logging.basicConfig(level=logging.INFO,
format=&amp;quot;%(asctime)s %(levelname)s %(message)s&amp;quot;,
handlers=[logging.StreamHandler(),
logging.FileHandler(&amp;ldquo;log.txt&amp;rdquo;)])&lt;/p&gt;
&lt;h1 id=&#34;関数を呼び出してフォルダパスと拡張子リストを取得する&#34;&gt;関数を呼び出して、フォルダパスと拡張子リストを取得する。
&lt;/h1&gt;&lt;p&gt;folder_path, extensions = parse_args()&lt;/p&gt;
&lt;h2 id=&#34;例え話-5&#34;&gt;例え話
&lt;/h2&gt;&lt;h1 id=&#34;関数を呼び出してフォルダパスと拡張子のリストを取得する&#34;&gt;関数を呼び出して、フォルダパスと拡張子のリストを取得する
&lt;/h1&gt;&lt;p&gt;folder_path, extensions = parse_args()&lt;/p&gt;
&lt;p&gt;if &lt;strong&gt;name&lt;/strong&gt; == &amp;ldquo;&lt;strong&gt;main&lt;/strong&gt;&amp;rdquo;:
# Windows でこの関数が必要な理由は、Windows には fork() 関数がないため (これは完全に正確ではありません)。
# したがって、Windows では、fork() は新しいプロセスを作成することでシミュレートされます。
# この新しいプロセスで実行されるコードは、Linux 上では子プロセスで実行されるものです。
# これらのコードが技術的に無関係なプロセスで実行されるため、実行前にそこに渡す必要があります。
# その方法は、まずそれらをシリアライズし、元のプロセスからパイプを介して新しいプロセスに送信することです。
# また、この新しいプロセスはパイプを介して送信されたコードを実行するように通知され、&amp;ndash;multiprocessing-fork コマンドラインパラメータを渡すことで行われます。&lt;/p&gt;
&lt;h2 id=&#34;例えのために&#34;&gt;例えのために
&lt;/h2&gt;&lt;h1 id=&#34;複数のプロセスプールを作成しpcのコア数に基づいてプロセスを自動的に割り当てる&#34;&gt;複数のプロセスプールを作成し、PCのコア数に基づいてプロセスを自動的に割り当てる
&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;pool = multiprocessing.Pool()
# 空のリストを作成し、非同期タスクの結果オブジェクトを格納する
results = []
# フォルダー内のすべてのファイルに対して反復処理を行う
for file in os.listdir(folder_path):
    # ファイルパスを結合する
    file_path = os.path.join(folder_path, file)
    # 画像ファイルの拡張子を確認し、必要に応じて拡張子リストを変更する
    if any(file_path.endswith(ext) for ext in extensions):
        # 関数を呼び出して画像を変換および保存し、ファイルサイズを取得する。非同期モードで、メインプロセスをブロックしない
        result = pool.apply_async(convert_and_save, args=(file_path,), callback=print_result)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;例を挙げる-6&#34;&gt;例を挙げる
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;result = pool.apply_async(convert_and_save, args=(file_path,), callback=print_result)
            # 結果オブジェクトをリストに追加
            results.append((file, result))
    # 処理プールを閉じる（新しいタスクの受付を停止）
    pool.close()
    # すべてのタスクが完了するまで待機
    pool.join()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;終わりに&#34;&gt;終わりに
&lt;/h2&gt;&lt;p&gt;ローカル開発が &lt;code&gt;windows&lt;/code&gt; システムであるため、AI が最初に提示した回答には &lt;code&gt;main&lt;/code&gt; 関数も &lt;code&gt;multiprocessing.freeze_support&lt;/code&gt; も含まれておらず、エラーが発生しました。質問を重ねることでエラーの原因を特定し、コードを修正しました。&lt;/p&gt;
&lt;p&gt;かつて検索エンジンの技術を学ぶように、AI とコミュニケーションする上でも、適切な制約条件を与え、効率的に必要な回答を得るためのスキルを習得する必要があります。&lt;/p&gt;
&lt;p&gt;注意：&lt;strong&gt;もしあなたがプログラミング初心者であれば、提示されたコメントと合わせて理解できない点がある場合は、引き続き関連コードについて質問してください。&lt;/strong&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>AIによるプログラミング支援、生産性の進化</title>
        <link>https://ttf248.life/ja/p/ai-assisted-programming-productivity-evolution/</link>
        <pubDate>Tue, 28 Feb 2023 17:05:17 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ai-assisted-programming-productivity-evolution/</guid>
        <description>&lt;p&gt;GitHub Copilot のリリースからわずか 2 年しか経っていないのに、ChatGPT が登場し、裏にある原理をよく理解していない状態で、しばらく使ってみた。2 つのツールのサポートレベルは全く異なりだが、どちらも生産性を大幅に向上させた。
あまりにも複雑なことについては、AI ではまだできないだろう。なぜなら、彼らは論理がなく、パターンや形式固定されたもの、あるいは范式を確立しているものがだからだ。学習データは十分で、AI の効果は 9 分満点になる。&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;GitHub Copilot
&lt;/h2&gt;&lt;p&gt;リリース時に、公式サイトの紹介の &lt;code&gt;demo&lt;/code&gt; を見ると、あまり賢くなく、試用してみましたが、使い勝手が良くありませんでしたので、諦めました。
2022年以前に、暇つぶしで切り替えて新バージョンを体験したところ、かなり良くなっており、ただ国内の速度が少し遅いのは、ネットワークの問題である可能性が高いです。&lt;code&gt;Python&lt;/code&gt;のような言語では、コメントに基づいて書かれたコードもそれなりによくできており、自分で資料を探して書いていたよりもはるかに速かったです。&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;GitHub Copilot は、プログラマー、つまり開発者の視点から製品を設計しており、プログラミングを知っている必要がある。徐々にコメントを通じて AI を活用したプログラミングを支援してもらう。&lt;/p&gt;
&lt;p&gt;ChatGPT は次の段階に進み、&lt;strong&gt;専門知識のない人でもすぐに使いこなせるように&lt;/strong&gt;なった。対話形式でのチャットインターフェースであり、完全に質問や要求事項を提示し、理解できない場合はさらに質問することができる。 簡単な例を挙げます。品詞分割の概念は理解しているものの、どのようにエンコードするか分からないため、文字列の類似度を計算したいと考えています。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Python 品詞分割を用いて、「維天運通 LOGORY 和 合肥維天運通信息科技股份有限公司」という2つの文字列の類似度を計算します。比較する前に、文字列を統一的に処理し、英文は小文字に変換します。2番目の文字列の中に、1番目の文字列の先頭文字が見つかれば、2番目の文字列を1番目の文字列の長さ分切り捨てます。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;こんにちは、これはBingです。😊&lt;/p&gt;
&lt;p&gt;オンラインの情報123に基づくと、Python の品詞分割には jieba などのライブラリを使用できます。jieba ライブラリは、精密モード、全模式、検索エンジンモードの3種類の品詞分割をサポートしています。要件に応じて適切なモードを選択してください。 2つの文字列の類似度を比較するためには、まずそれらをトークン化し、その後、単語ベクトルや編集距離などの指標を計算する必要があります。NumPyまたはSciPyなどのライブラリを使用して、これらの数値演算を実行できます。&lt;/p&gt;
&lt;h2 id=&#34;chatgpt-1&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;文字列の統一的な処理、および英語を小文字に変換するには、Python の組み込み関数 &lt;code&gt;lower()&lt;/code&gt; を使用できます。
2 番目の文字列を抽出するには、Python のスライス演算子 &lt;code&gt;[ ]&lt;/code&gt; を使用します。
以下は 1 つの可能なコード例です：&lt;/p&gt;
&lt;h2 id=&#34;chatgpt-2&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import jieba
import numpy as np
from scipy.spatial.distance import cosine

# 定义两个字符串
str1 = &amp;quot;維天運通 LOGORY&amp;quot;
str2 = &amp;quot;合肥維天運通信息科技股份有限公司&amp;quot;

# 统一处理字符串，英文转换为小写
str1 = str1.lower()
str2 = str2.lower()

# 找到第二个字符串中第一个字符的位置
index = str2.find(str1[0])

# 如果找到了，截取第二个字符串
if index != -1:
    str2 = str2[index:index+len(str1)]

# 使用 jieba 库进行分词
words1 = list(jieba.cut(str1))
words2 = list(jieba.cut(str2))

# 计算两个字符串的词向量（以词频作为权重）
vector1 = np.zeros(len(words1))
vector2 = np.zeros(len(words1))
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;chatgpt-3&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;h1 id=&#34;2つの文字列の単語ベクトルを計算する-頻度を重みとして使用&#34;&gt;2つの文字列の単語ベクトルを計算する (頻度を重みとして使用)
&lt;/h1&gt;&lt;p&gt;vector1 = np.zeros(len(words1))
vector2 = np.zeros(len(words1))&lt;/p&gt;
&lt;p&gt;for i, word in enumerate(words1):
vector1[i] += 1  # 最初の文字列内の各単語の出現回数をカウント
if word in words2:
vector2[i] += 1  # 2番目の文字列内の各単語の出現回数をカウント&lt;/p&gt;
&lt;h1 id=&#34;2つの文字列の類似度を計算する-コサイン距離を指標として使用&#34;&gt;2つの文字列の類似度を計算する (コサイン距離を指標として使用)
&lt;/h1&gt;&lt;p&gt;similarity = 1 - cosine(vector1, vector2)&lt;/p&gt;
&lt;p&gt;print(&amp;ldquo;2つの文字列の類似度は：&amp;rdquo;, similarity)&lt;/p&gt;
&lt;h2 id=&#34;chatgpt-4&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;さらに踏み込んで、実行結果の問い合わせ、おめでとうございます。問題が見つかりました。結果はハッタリ（作り話）、コードを実行していません。しかし、素晴らしい結果を提供してくれます。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;栗子&#34;&gt;栗子
&lt;/h3&gt;&lt;p&gt;質問：SQL文で、製品コードテーブルから、製品コードが80000-89999のレコードを抽出するには&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;こんにちは、これはBingです。😊

検索結果12によると、BETWEEN演算子を使用して、指定された範囲内の値を選択できます。BETWEEN演算子は、開始値と終了値を両方含みます。

まず、クエリするテーブル名と列名を指定し、WHERE句でBETWEEN演算子と範囲値を指定する必要があります。

たとえば、製品コードテーブルから、製品コードが80000から89999のレコードを抽出するには、次のステートメントを使用できます。

SELECT * FROM product_code
WHERE code BETWEEN 80000 AND 89999;
ここで、*はすべての列を選択することを意味します3。
``` 製品コードは文字列であり、あなたのコードは間違っています。

### 栗子

```markdown
申し訳ありませんが、製品コードが文字列であることに気づいていませんでした。もしそうであれば、区間値の両側にシングルクォートを追加する必要があります。例：

SELECT * FROM product_code
WHERE code BETWEEN &#39;80000&#39; AND &#39;89999&#39;;
私の誤りをお許しください。🙏
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;おめでとうございます、それは間違えるでしょう。&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>

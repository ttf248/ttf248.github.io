<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Ai on 向叔の手帳</title>
        <link>https://ttf248.life/ja/tags/ai/</link>
        <description>Recent content in Ai on 向叔の手帳</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>ja</language>
        <lastBuildDate>Thu, 06 Nov 2025 01:40:10 +0800</lastBuildDate><atom:link href="https://ttf248.life/ja/tags/ai/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>コマンドラインベースのAIコーディングインタラクション</title>
        <link>https://ttf248.life/ja/p/command-line-ai-coding-interaction/</link>
        <pubDate>Wed, 05 Nov 2025 14:12:46 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/command-line-ai-coding-interaction/</guid>
        <description>&lt;p&gt;慣例のようにTraeを開き、コードを始める前に、通知欄にメッセージが届く。「claudeモデルが下ラインになったため使用できず、今後も回復する可能性は低い」と。公式からは補償プランが提供され、利用回数が300（1月まで）増加する。&lt;/p&gt;
&lt;p&gt;調べてみると、予想通り、Anthropic社はアメリカの要請により、国内企業へのclaudeシリーズモデルの使用を禁止している。TraeのDiscordコミュニティに潜入し、多くの人がclaudeモデルの下ラインについて不満を漏らし、大部分がclaudeを期待して利用していたためだ。claude 4.5モデルがtraeで同期されなかった時点で、この問題の兆候はすでに存在していた。&lt;/p&gt;
&lt;h2 id=&#34;試してみる&#34;&gt;試してみる
&lt;/h2&gt;&lt;p&gt;最後の1回、試してみることにした。他のモデルも体験してみた（OpenAIのgpt-3.5-turbo、gpt-4、GoogleのGemini Proなど）。
どう表現すればいいかわからないが、どれもあまり理想的ではなかった。Traeの海外チームがどのように開発したのかわからない。本来なら、こんなに大きな差はないはずだ。テストに使用したプロンプトは、以前使っていた小蓝书プロジェクトで、以前の記事にも書かれていたものだ。
加えて、Trae IDE自体に不満があったため、Traeチームにメールを送り、払い戻しの申請を行った。&lt;/p&gt;
&lt;h2 id=&#34;変更&#34;&gt;変更
&lt;/h2&gt;&lt;p&gt;誤っていただろうのは、Googleが最初にリリースしたターミナルインタラクティブAIプログラミングのことだ。IDEと比較して、日常的なスマートアシストは存在しないものの、より汎用性が高まっている。開発者は引き続き既存の開発環境を使用することができる。&lt;/p&gt;
&lt;p&gt;OpenAIとAnthropicの2社はそれぞれ、Claude Code、Codexを発表し、ツールとモデルが完全に固定されていない。設定ファイルを修正することで、他のモデルにも接続できる。&lt;/p&gt;
&lt;p&gt;Discordコミュニティでは、minimax M2やglm4といった国内のモデル（小蓝书プロジェクト）について言及があり、Minimax M2を試してみたところ、それなりに良かった。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;インストールには科学的なアクセスが必要で、異なるモデル間の切り替えについては、&lt;a class=&#34;link&#34; href=&#34;https://github.com/farion1231/cc-switch&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/farion1231/cc-switch&lt;/a&gt; を推奨します。&lt;/p&gt;
&lt;h2 id=&#34;claude-code&#34;&gt;claude code
&lt;/h2&gt;&lt;p&gt;Node.js に依存し、コマンド: npm install -g @anthropic-ai/claude-code&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;╭─── Claude Code v2.0.33 ────────────────────────────────────────────────────────────────────────────────╮
│                                    │ 開始方法のヒント                                                  │
│            ようこそ戻ってこられました！           │ /init を実行して、Claude の指示を含む CLAUDE.md ファイルを作成します。 │
│                                    │ ───────────────────────────────────────────────────────────────── │
│               ▐▛███▜▌              │ 最新アクティビティ                                                   │
│              ▝▜█████▛▘             │ 最新のアクティビティはありません                                                │
│                ▘▘ ▝▝               │                                                                   │
│                                    │                                                                   │
│   minimax-m2 · API 利用料金   │                                                                   │
│          F:\dev\notebook           │                                                                   │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────╯

─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
&amp;gt; &amp;quot;util logging.py を作成して...&amp;quot; を試してください
─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
  ！bash モードの場合は、入力フィールドをクリアするためにエスケープキーをダブルクリックします。
  / コマンドの実行      alt + m で自動的に編集を受け入れる       alt + v で画像を貼り付けます
  @ ファイルパスの表示     ctrl + o で詳細な出力を表示        # メモリ化するため
                        tab で思考を切り替える          ctrl + t でタスクを表示
                        backslash (\) + return (⏎) で
                        改行
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;codex&#34;&gt;Codex
&lt;/h2&gt;&lt;p&gt;未体験、参考資料：&lt;a class=&#34;link&#34; href=&#34;https://platform.minimaxi.com/docs/guides/text-ai-coding-tools#%E5%9C%A8-codex-cli-%E4%B8%AD%E4%BD%BF%E7%94%A8-minimax-m2&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://platform.minimaxi.com/docs/guides/text-ai-coding-tools#%E5%9C%A8-codex-cli-%E4%B8%AD%E4%BD%BF%E7%94%A8-minimax-m2&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>あらゆるAIの恩恵は、すでに影で価格が設定されていた。</title>
        <link>https://ttf248.life/ja/p/all-the-gifts-of-ai-have-already-been-marked-up-with-prices-in-the-shadows/</link>
        <pubDate>Fri, 10 Oct 2025 19:09:36 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/all-the-gifts-of-ai-have-already-been-marked-up-with-prices-in-the-shadows/</guid>
        <description>&lt;p&gt;記事の投稿頻度は、AIの使用に伴い著しく増加しています。私も記事内のタグで区別し、作者欄には大規模言語モデルの名前を記載する予定です。しかし問題は残っており、AIが生成した記事では、私の関与レベルは明らかに低下しています。多くの記事が半ヶ月ほど隔てられ、内容をほとんど忘れてしまいます。コーディングの際にも同様の状況が発生し、問題に遭遇したら、まずAIによる分析を思いつき、既存のものに基づいた問題解決やトラブルシューティングではなく、「怠惰」が顕著に向上しています。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;生成AIは業務効率を向上させる一方で、その「贈り物」には巨額な代償が伴います。北大研究チームが41万件の論文と縦断的な実験分析を通じて明らかにしたところ、AIは知識生産を加速させながらも、深刻な同質化を引き起こしています。ハーバード大学の研究では、AIが「資格偏向」をもたらし、初級職が7.7%減少するという結果を示しており、マタイ効果を悪化させています。個人的には、AIによる創造性の向上は一時的な「幻覚」に過ぎず、停止すると消え失せます。しかし、思想の同質化は持続的に存在し、「創造の傷痕」を生み出しています。&lt;/p&gt;
&lt;h2 id=&#34;現状&#34;&gt;現状
&lt;/h2&gt;&lt;p&gt;生成式AIは、あらゆる産業を再構築するだけでなく、人間の文章作成、認知、思考の根本的な方法も変えています。&lt;strong&gt;ChatGPT 3.5 の発表後、楽観的な期待が広まりました：「AI は労働力を均等化する」という予測です。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;2023 年、マサチューセッツ工科大学の経済学博士 2 人が『Science』誌に実証研究を発表し、この見通しを裏付けました。生成式 AI が低パフォーマンス従業員のパフォーマンスを大幅に向上させ、そのギャップを埋めることで不平等感を軽減する可能性があるというものです。&lt;/p&gt;
&lt;p&gt;『Science』誌の編集部は、こうまとめました。「スキルが劣る参加者は ChatGPT から最も利益を得ており、これは生産性の不平等を AI で削減するという政策にとって重要な示唆を与えています。」&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/all-the-gifts-of-ai-have-already-been-marked-up-with-prices-in-the-shadows/20251010191432.png&#34;
	width=&#34;1024&#34;
	height=&#34;905&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Science 誌&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;113&#34;
		data-flex-basis=&#34;271px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;しかしながら、&lt;strong&gt;2 年が経過した今、現実がこの理想的な経路を完全にたどっているとは限りません。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;2025 年、ハーバード大学の経済学博士 2 人は、2015 ～ 2025 年にかけて 620 万人以上、1.5 億回以上の採用・雇用データ分析を通じて、冷酷な真実を明らかにしました。&lt;strong&gt;生成式 AI は「資格偏重」の形で労働市場を再構築しているのです。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/all-the-gifts-of-ai-have-already-been-marked-up-with-prices-in-the-shadows/20251010191527.png&#34;
	width=&#34;866&#34;
	height=&#34;544&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;資格偏重&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;159&#34;
		data-flex-basis=&#34;382px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;数据显示、2015 ～ 2022 年にかけて、初級職と高級職の雇用成長曲線はほぼ一致していましたが、2023 年以降、両者で分岐が生じ始めました。高級職は引き続き上昇し続けましたが、初級職は方向転換して下降しました。&lt;/p&gt;
&lt;p&gt;AI を深く受け入れている企業の場合、その初級職の数は 6 四半期以内に約 7.7% 減少しましたが、高級職はほとんど影響を受けず、むしろわずかに増加しました。この現象の主な原因は採用の減少ではなく、大規模な解雇ではありませんでした。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI は、普恵的な平権をもたらすどころか、「强者更强」のマタイ効果をますます強調しています。&lt;/strong&gt; 携程 CEO の梁建章氏は、この論文について「AI は初級の知的労働者を代替し、若者の教育、結婚、出生、職業初期といった段階における困難を悪化させるだろう」と評価しました。&lt;/p&gt;
&lt;p&gt;労働市場の構造変化は氷山の一角に過ぎません。&lt;strong&gt;より深層的な問題が浮上してきます。AI が大規模に私たちのワークフローに組み込まれるとき、それは人間の創造性自体にどのような影響を与えるのでしょうか？ AI がもたらす効率性の向上は、個人の能力の内化でしょうか？ それは、私たちが見過ごしている方法で、あるいは「統一」することで、私たちの思想を形作ったり、「統一」したりしているのでしょうか？ 個体が AI に過度に依存した後、彼らの独立した、オリジナルの思考能力は強化されたのか、それとも無意識のうちに弱体化されたのか？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;最近、北京大学 李圭泉 教授の研究チームが、社会学のトップジャーナル Technology in Society に発表した論文は、この一連の重要な問題に対する正面からの回答です。&lt;/p&gt;
&lt;p&gt;研究の中心は 2 つの部分で構成されています。第一に、ChatGPT 3.5 のリリース前後の、全 21 科目の学術論文を分析する大規模な自然実験を通じて、AI が世界の知識生産に与える実際の影響を分析します。第二に、数か月続く縦断的な行動実験を通じて、ラボ環境で AI が個人の認知能力に及ぼす長期的な因果効果を探ります。&lt;/p&gt;
&lt;p&gt;研究チームは、ブレイクポイント回帰設計と機械学習などの技術を組み合わせて、生成式 AI が個人創造性と集団同質性に与える長期的かつ現実の影響を明らかにしました。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/all-the-gifts-of-ai-have-already-been-marked-up-with-prices-in-the-shadows/20251010191638.png&#34;
	width=&#34;1024&#34;
	height=&#34;747&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;ジャーナル&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;137&#34;
		data-flex-basis=&#34;328px&#34;
	
&gt;
このジャーナルは JCR 1区 top であり、影響因子 12.5 で、socialscience,Interdisciplinary 分類下 271本のジャーナル中ランキング第2&lt;/p&gt;
&lt;h2 id=&#34;41万論文の集団無意識&#34;&gt;41万論文の「集団無意識」
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;最恐ろしいのはノイズではなく、衆聞一斉であることだ。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;41万論文の集団無意識-1&#34;&gt;41万論文の「集団無意識」
&lt;/h2&gt;&lt;p&gt;この研究は大規模な自然実験でした。
研究チームは、Web of Scienceコアデータベースから、物理科学、生命科学・生物医学、応用科学、社会科学、芸術・人文など全部21分野の学術産出を抽出し、ChatGPT-3.5発表前の全419,344篇論文を約17,000名の研究者からのランダムサンプリングを通じて収集し、巨大なデータセットを作成することで、AIが世界の知識生産に与える真の影響を分析しました。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/all-the-gifts-of-ai-have-already-been-marked-up-with-prices-in-the-shadows/20251010191749.png&#34;
	width=&#34;1024&#34;
	height=&#34;493&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;大規模なデータセット&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;207&#34;
		data-flex-basis=&#34;498px&#34;
	
&gt;
生成AI発表前後の学術論文の同質性と創造性結果のイメージ図&lt;/p&gt;
&lt;p&gt;上記画像のように、2022年以前は世界の学術産出の創造性（赤/青線）と同質性（灰色線）が安定的に成長していました。しかし、ChatGPT3.5発表後、両者の傾斜が急激に上昇しました。
つまり、GPT3.5発表後、学界は知識産の創出（創造性）を著しく加速させる一方で、その内容の同質化もより速い速度で進み、生成AIが知識生産に対して持つ「両刃の剣」のような影響を明確に示すものでした。&lt;/p&gt;
&lt;p&gt;観察された変化がAIによって引き起こされたことを証明するため、研究チームは「断点回帰デザイン」（RDD）と呼ばれる因果推論手法を採用しました。&lt;/p&gt;
&lt;h3 id=&#34;方法&#34;&gt;方法
&lt;/h3&gt;&lt;p&gt;2022年12月ChatGPT-3.5のリリースを、天然の「時間断切」と捉えることができる。論文がその日付より前か後かで、個々の研究者にとって制御できない偶然要因（例えば査読期間）が存在し、これはほぼランダムに「実験群」（AIを使用できる機会があるグループ）と「対照群」（AIを使用できないグループ）に割り当てられたようなものである。&lt;/p&gt;
&lt;h3 id=&#34;信頼性の理由&#34;&gt;信頼性の理由
&lt;/h3&gt;&lt;p&gt;この「準確率」特性により、研究者は他の長期的な要因の干渉を効果的に排除し、AIがもたらす因果効果を正確に特定することができます。その方法論の厳密性を確保するため、チームは一連の統計的検定を実施し、学者が「切り替え点」の前後に大規模な「稿を捏造する」や「早期発刊する」などの戦略的な行動を行っていないことを確認しました。これにより、研究結果の信頼性が保証されます。&lt;/p&gt;
&lt;h3 id=&#34;創造性と同質性の指標を定量化するには&#34;&gt;「創造性」と「同質性」の指標を定量化するには？
&lt;/h3&gt;&lt;p&gt;因果関係が確認された後、研究チームは40以上の論文に対して、「創造性」と「同質性」という2つの次元で定量分析を実施しました。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;創造性&lt;/strong&gt;：論文発表の「数」と発表ジャーナルの「質」（JCR分区）を評価します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数：学者が発表した論文の総数。&lt;/li&gt;
&lt;li&gt;質：論文が発表されたジャーナルのJCR分区（JournalCitationReportsQuartiles）。これは、JCR（ジャーナル引用レポート・クォータイルズ）という権威あるジャーナル評価システムで、Q1は当該分野における影響力上位25%に位置するトップジャーナルを指し、Q4は末位の25%を指します。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;同質性&lt;/strong&gt;：内容類似度と言語スタイル類似度によって評価します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;内容類似度：SBERT（Sentence BERT）という深層学習モデルを用いて論文の要約を数値「ベクトル」に変換し、そのベクトル間の「コサイン類似度」を計算することで、核心的な意味合いにおける類似度を測ります。&lt;/li&gt;
&lt;li&gt;言語スタイル類似度：文字レベルでのマッチングアルゴリズムを用いて論文の要約から出現する短語や文型をスキャンし、それらの繰り返しをカウントすることで、文章スタイルの類似性を測定します。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;冷徹な両刃の剣より効率的しかしより単調&#34;&gt;冷徹な両刃の剣：より効率的、しかしより単調
&lt;/h3&gt;&lt;p&gt;如图所示のように、分析結果は明確に「両刃の剣」効果を明らかにする。
一方、AIの登場は学術産出における強力な「加速器」となったことは確かである。研究者の1人あたりの年平均発表論文数は0.9篇増加し、発表ジャーナルの質は平均6%向上した。この効果は特に技術や物理科学などの分野で顕著である。
しかしながら、効率の向上が思想と表現の多様性を犠牲にしている。データによると、論文の言語スタイル類似度は平均毎年驚異的な79%増加し、同時に論文の内容テーマも著しく同質化しており、特に物理科学、芸術、人文科学における同一化現象が最も深刻である。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;20251010192022.png&#34; &gt;断点回归结果图&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;北大研究チームによるこの大規模な自然実験は、私たちに現実世界の宏観的な証拠を提供する。生成式AIは学術産出における強力な「加速器」であり、学者たちがより迅速に論文を執筆し、より優れたジャーナルに発表するのを助ける。しかし、このような効率の向上は、思想と表現の多様性を犠牲にしている。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;世界の知識生産は、この「大交換」の中で、より効率的かつ「単調」になっているようだ。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;同時に、研究二でも、より深いレベルの問題が提起された：この宏観的なトレンドが、その場にいる個人にどのような意味を持つのか？AIが生み出す創造性の向上は、実際の個人能力の成長を意味するのだろうか？&lt;/p&gt;
&lt;p&gt;この問題を解決するために、研究チームは研究二で数ヶ月にわたる継続的な追跡調査を実施し、制御された実験環境においてAIが個人の認知能力に及ぼす長期的な因果効果を探求した。&lt;/p&gt;
&lt;h2 id=&#34;aiが生み出した創造性の傷跡&#34;&gt;AIが生み出した創造性の傷跡
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;思考が習慣に屈すると、創造性は失われてしまう。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;aiが生み出した創造性の傷跡-1&#34;&gt;AIが生み出した創造性の傷跡
&lt;/h2&gt;&lt;p&gt;実際には、すでに多くの研究所で、小規模なデータを用いた実証研究が、マクロデータが示唆するトレンドから異なる角度からその傾向を裏付けています。例えば、コーネル大学の研究では、AIライティングアシスタントが文化的独自性を犠牲にし、「西欧の規範」に従うような表現へと誘導するという傾向が見られました。また、サンタクララ大学の研究でも、ChatGPTを使用している個人は、その創造性が意味レベルでより類似していることが示唆されました。&lt;/p&gt;
&lt;p&gt;特に注目すべきは、マサチューセッツ工科大学の研究チームが脳波（EEG）技術を用いて、個人の脳活動を直接観察したことです。彼らは、ChatGPTを使用していた学生グループの脳活動レベルが、自分自身で考えるか、検索エンジンを使用するグループと比較して著しく低いことを発見しました。&lt;/p&gt;
&lt;p&gt;これらの研究は、AIが認知投入を減らし、多様性を犠牲にして効率を高めるという結論を導き出しています。&lt;/p&gt;
&lt;p&gt;しかし、ほとんどの研究は、AIの使用による即時の影響に焦点を当てており、AIが「離場」した後、その効果が持続するか、そしてその長期的な負の側面が軽減されるかについては、ほとんど探求されていません。&lt;/p&gt;
&lt;p&gt;北京大学はこの点において新たな試みを行いました。&lt;/p&gt;
&lt;p&gt;それは、7日間の実験中にAIの即時的な影響を観察するだけでなく、実験終了後の30日目と60日目の独立した追跡テストを通じて、AI依存によってもたらされる長期的な結果を体系的に検証することにも取り組んだのです。これにより、AIがもたらすのは、転移可能な「能力」なのか、それとも一時的で内化できない「幻影」なのかを真正に理解することが可能になりました。&lt;/p&gt;
&lt;p&gt;具体的には、北京大学の研究チームは、61名の大学生を2つのグループに無作為割り当てました。「AI実験群」（ChatGPT-4を使用可能）と「純粋な脳力対照群」。&lt;/p&gt;
&lt;p&gt;実験デザインには、3つの主要な段階が含まれていました。まず、すべての参加者が最初の日にAIを使用せず、創造力基線テストを実施しました。次に、2日から6日までの間、「AI実験群」はAIの支援を受けて毎日の創造力タスクを完了させ、「純粋な脳力対照群」はAIの支援なしでタスクを完了させました。最後に、そして最も重要なのは、7日目、30日目、および60日目に、すべての参加者がAIの支援なしに最終的な追跡テストを実施したことです。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/all-the-gifts-of-ai-have-already-been-marked-up-with-prices-in-the-shadows/20251010192137.png&#34;
	width=&#34;1024&#34;
	height=&#34;656&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;実験デザイン示意图&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;156&#34;
		data-flex-basis=&#34;374px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;研究者は、創造性を評価するために、複合的なタスクモードを採用し、複数の次元をカバーしました。これらのタスクには以下が含まれます：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;発散的思考テスト:&lt;/strong&gt; 従来の「代替用途タスク」（AUT）で、参加者が日常のアイテム（例えば、「ペン」）について可能な限り多くの新しい用途を思いつくように求められます。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;創造的な問題解決:&lt;/strong&gt; より現実世界のビジネスシナリオに基づいた課題で、例えば、「スマート自転車」のデザインにおける革新的な機能を考案するように求められます。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;集約的思考テスト:&lt;/strong&gt; 追跡段階に組み込まれた「遠距連想クイズ」（RAT）で、参加者が関連性のない3つの単語を同時に結びつける単語を見つけ出すように求められます。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;洞察力問題:&lt;/strong&gt; 「キャンドル問題」の古典的なもので、参加者が箱に入った金槌、一本のロウソク、そして火打ち石を使って、ロウソクを壁に固定し、かつロウがテーブルに落ちないようにする必要があります。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;評価の科学性を確保するために、研究者は分野における「ゴールドスタンダード」である専門家合意評価法（CAT）を採用しました。多位の専門家評委は、「双盲」条件下で、グループ分けや研究目的を全く知らない状態で、数千件の創造的なアウトプット（発散的思考タスクと複雑な問題解決策を含む）の新規性、実用性、柔軟性などの複数の次元について独立して評価しました。極めて高いデータの一貫性（評価者信度ICC &amp;gt; 0.90）が確保され、評価結果の科学性と公正性が保証されました。&lt;/p&gt;
&lt;p&gt;研究二では、同質性の測定方法として、研究一で採用された技術方法を完全に同一のものを使用し、2つの研究間の評価基準の一致性を確保しました。&lt;/p&gt;
&lt;p&gt;実験の結果は、明確な非対称性を示び露しました：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;創造性の向上は一時的で持続不可能である:&lt;/strong&gt; AIを使用していた期間（第2～6日） 停止使用AI 2か月後でも、「AI実験グループ」の出力内容は、意味レベルおよび言語スタイルにおいて、対照群と比較して依然として著しく高い類似性を示した。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;この縦断研究により、直接的な因果関係を示す証拠が得られ、AIが個人の創造性に及ぼす長期的な影響を実証した。AIが生み出すものは単なる内化できない「創造性の錯覚」に過ぎず、残された思考の同調は、長期間にわたって認知や表現習慣の中に残り続ける「創造的傷痕」となる可能性がある。&lt;/p&gt;
&lt;h2 id=&#34;もし世界に新しいアイデアがなくなったら&#34;&gt;もし世界に新しいアイデアがなくなったら
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;これは最良の時代であり、最悪の時代である。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;新しい創造性が世界にない場合&#34;&gt;新しい創造性が世界にない場合
&lt;/h2&gt;&lt;p&gt;北大が行ったこの研究の結論は、私たちが「挫折してAIを完全に放棄する」のではなく、AI時代においてAIを理解し対処するための意識的な努力を促すものである。長期的にAIに依存することで、個人の思考や認知習慣に及ぼされる深遠な影響を認識する必要があるという警告である。&lt;/p&gt;
&lt;p&gt;研究で明らかになった「同質化（Homogenization）」の傾向は、その根底には深い認知科学の原理が存在する。「AIの出力は、ユーザーに対して強力な「アンカー効果（Anchoring Effect）」を引き起こしやすく」、AIが迅速に「それなりによい」と思われる答えやフレームワークを生成すると、私たちの思考がその初期の提案に「固定化され」、その後の思考や創造性が大幅に逸脱することが難しくなる。それが集団レベルで思想の収束につながるのである。&lt;/p&gt;
&lt;p&gt;今年7月に黄仁勋氏がCNNのインタビューで述べた冷静な判断は、「世界に新しい創造性がない場合、AIが生み出す生産性の向上は失業へとつながる」というものだった。&lt;/p&gt;
&lt;p&gt;生成AIが継続的に使用されることで、インターネットの情報や人間の知識基盤がかつてない速度で同質化が進んでいる。北大的研究は、この傾向が実際に存在することを冷徹なデータによって証明している。社会が常に新しい創造性を生み出すことができれば、AIはより多様な雇用機会を生み出すことになる。しかし、単に既存のタスクを繰り返すだけでは、AIは数秒でそれを完了してしまうだろう。&lt;/p&gt;
&lt;p&gt;AIは創造性を増幅させるだけでなく、「アイデア枯渇（Mental Block）」した人々を排除する加速剤となる。&lt;/p&gt;
&lt;h2 id=&#34;ai時代における思考の鋭さの維持について&#34;&gt;AI時代における思考の鋭さの維持について
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;AIは私たちの仕事を軽減する一方で、深く考えることができる思考体系を構築し、AIとインタラクティブに連携することが重要です。解決したい問題をAIに記述するだけでなく、問題自体を推論し、AIの回答が正しいかどうか判断する必要があります。そのためには、弁証法的思考が必要です。—黄仁勋&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;ai時代における思考の鋭さの維持について-1&#34;&gt;AI時代における思考の鋭さの維持について
&lt;/h2&gt;&lt;p&gt;AI時代を生きる個人として、私たちはどのように向き合うべきか？AIの利便性を享受しながらも、創造性の荒廃を防ぐにはどうすればよいか？研究からの示唆に基づいて、以下に具体的な行動提案を示します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;AIを「思考のコーチ」と捉える&lt;/strong&gt;: 疲れることなく、無限の視点を提供してくれる「思考のコーチ」として活用する。アイデア出しや可能性の生成、固定観念への挑戦などに利用するが、最終的な選別、深化、意思決定、そして結果に対する責任は、依然として自分自身で行うべきだ。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;「認知摩擦」を意図的に作り出す&lt;/strong&gt;: 「アンカー効果」に対抗する最も有効な方法は、積極的に「認知摩擦」を生み出すことである。AIが最初に提示する答えに安易に同意せず、その論理的欠陥を探し出し、考慮されていない側面を质疑する。このような批判的思考の訓練こそが、私たちが独立した思考能力を維持するための鍵となる。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;「AIなしの時間」を設ける&lt;/strong&gt;: 筋肉が萎縮しないように定期的に運動するように、脳もAIのサポートなしに鍛える必要がある。週単位で「AIなしの時間」を設け、最も基本的な紙とペン、または空白のドキュメントを使って思考、計画、創作を行う。このような意図的な「認知断捨離」は、脳の中核的な創造性と推論能力が、安逸の中で退化することを防ぐのに役立つ。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>ByteDance AI エンコードの新基準 SOLO</title>
        <link>https://ttf248.life/ja/p/bytedance-ais-solo-encoding-new-paradigm/</link>
        <pubDate>Thu, 14 Aug 2025 21:49:06 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/bytedance-ais-solo-encoding-new-paradigm/</guid>
        <description>&lt;p&gt;以前使用していた製品は、コード開発を行う際には大差なく、しかしByteのSOLOは、コード開発において大きな違いが生じた。当初は招待コードを通じてベータ版に参加したが、現在はメールアドレスを提出し審査を待つ形式となり、審査に通れば利用できる。いつ申請を行ったのか記憶が曖昧なところだが、今日Traeから審査通過の通知を受け取った。&lt;/p&gt;
&lt;h2 id=&#34;字节soloの利点&#34;&gt;字节SOLOの利点
&lt;/h2&gt;&lt;p&gt;通常のプロジェクト開発の流れを参考に、UIデザイン、要件分析、機能設計、技術方案の実装を行い、最後にコードの開発を行うという流れを採用しています。全体的なインタラクションロジックは、初心者にとってより親切であり、複雑なプロジェクトの場合は、従来のパターンの方がより効果的です。AIは補助ツールとして、コードの修正と最適化を行います。&lt;/p&gt;
&lt;h2 id=&#34;港美股app開発&#34;&gt;港美股APP開発
&lt;/h2&gt;&lt;p&gt;はい、タイトルは私が書いたプロンプト文通りです。追加の説明はありません。SOLOモード下では、まず要求ドキュメントと技術アーキテクチャドキュメントが出力され、ユーザーが問題がないことを確認すると、コードの開発が行われます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/ai-coding-trae-solo/blob/master/.trae/documents/%E6%B8%AF%E7%BE%8E%E8%82%A1APP%E4%BA%A7%E5%93%81%E9%9C%80%E6%B1%82%E6%96%87%E6%A1%A3.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;要求ドキュメント&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/ai-coding-trae-solo/blob/master/.trae/documents/%E6%B8%AF%E7%BE%8E%E8%82%A1APP%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84%E6%96%87%E6%A1%A3.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;技術アーキテクチャドキュメント&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;どうすればいいかというと、設計が特別完璧ではないとしても、初稿として完全に使えるものです。私はUIのデザイン経験がないため、Figmaからデザインファイルをインポートする機能のテストを行っていません。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;コード構築中に、いくつかのドキュメントが見つかりました。SOLOモード下では、AIは存在している問題を自力で処理しようと試みます。例えば、データベースがローカルにある場合、データベースのフィールド設計を増やす必要があるため、最初に対応するスクリプトを生成し、次にjsスクリプトを実行してデータベーススクリプトを実行します。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;また、資料を見ながら見つからなかったポイントもありました。タスク分解機能については、港美股の頃の資料にスクリーンショットがありませんので、以前の漫画リーダープロジェクトを使用しました。バイトもお金持ちなので、一度のリクエストでたくさんのタスクを実行できますが、このシナリオは実際にはあまり多くなく、新しいプロジェクトでは大量のトークンを消費します。ユーザーが依存性を持つときこそ、ここで利益を得られるのです。
&lt;img src=&#34;https://ttf248.life/p/bytedance-ais-solo-encoding-new-paradigm/20250814215722.png&#34;
	width=&#34;571&#34;
	height=&#34;236&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;タスク分解機能&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;241&#34;
		data-flex-basis=&#34;580px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>日常のつぶやき</title>
        <link>https://ttf248.life/ja/p/daily-musings/</link>
        <pubDate>Fri, 01 Aug 2025 18:57:38 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/daily-musings/</guid>
        <description>&lt;p&gt;AI を過信しすぎると、何でも AI と考えすぎてしまうことがあります。新しい動向を学ぶ場合、検索エンジンとプロジェクトの公式ドキュメントの方が信頼性が高いです。&lt;/p&gt;
&lt;p&gt;香港株は下げ相場に遅れて参入し、回调に遭遇して日常的に無意味な操作を行い、利益はほぼ失われています。&lt;/p&gt;
&lt;h2 id=&#34;策略取引&#34;&gt;策略取引
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;単に稼ぐために実践する必要がある、というわけではなく、学習を通して自身の能力を高めたいと考えています。私はこれらのテクニカル指標を信用せず、むしろ国の運勢や大株主指数のインデックス投資を信じています。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;戦略取引&#34;&gt;戦略取引
&lt;/h2&gt;&lt;p&gt;先月のインスピレーションの一つで、AIが没収されたプロジェクトの一例を参考に、AIを使って実現しようと試みたところ問題が発生。本来はまず資料を集め、既存のプロジェクトがないか、彼らはどのようにして進めていたのかを確認すべきだった。以前は戦略取引を経験したことがなく、指標や市場データの処理など、全く触れたことがなかった。&lt;/p&gt;
&lt;p&gt;当初の計画は、完全に自分なりに想像したもので、AIとのコミュニケーションを通じてバックテストフレームワークを知り、GitHubでプロジェクトが活発であることを確認した。&lt;/p&gt;
&lt;p&gt;AIを使いすぎると、何でもAIを使って解決しようとするくなり、AIにも学習資料やアクティブなプロジェクト、そして完成度の高い公式ドキュメントを提供してもらうのが理想的だ。しかし、AIが出してくる学習案は現在のコードバージョンに追いつかない。&lt;/p&gt;
&lt;p&gt;プロジェクトの構造を調整する：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;データのダウンロード：ヤフー（Yahoo!）から、変動率のローソク足データを取得&lt;/li&gt;
&lt;li&gt;バックテストの公式ガイドに従い、基本的な使い方を学ぶ&lt;/li&gt;
&lt;li&gt;TA-Lib のインストールと使用、一般的な指標の計算、そしてバックテストでデータを表示&lt;/li&gt;
&lt;li&gt;アリペイ（Alipay）のような積立投資ロジックの実装。この戦略は長期的ETF積立投資に適している&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;香港株式取引&#34;&gt;香港株式取引
&lt;/h2&gt;&lt;p&gt;香港株式への参入は約2ヶ月、簡単な振り返りです。
美団の買い入れとその動機は、純資金流入を単純に見るとともに、美団近況を深く分析することなく、偶然にもデリバリー大战（デリバリー競争）に遭遇し、美団の株主となりました。小米も高位で買い入れたところ、機会を見つけて減塩（ポジションから利益確定して一部売却する）し、四期工場が落地（実際に稼働を開始した）したことで一波のチャンスがあったものの、それを継続するには忍耐が必要です。3年の時間ではほぼ終わります。
香港株式における新消費財、テクノロジー株の価格はすでに高水準であり、仮想通貨という概念も加わったため、テクノロジー株が下落した際に、長期的投資には不向きな頻繁な増配（ポジションに資金を追加する）を試みてしまい、今日なら一波賭けてみる、明日には下がって後悔してしまった。持続的に下落する市場に陥ると、簡単に巻き込まれてしまいます。
長期的投資としては、操作の頻度が過剰であり、週あたり2～3回程度が適切です。
上海総合指数は3600、国内の大盤に対して定投（積立投資）をほとんど行わず、この波を見逃してしまいました。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>最近の大規模言語モデルの利用経験について</title>
        <link>https://ttf248.life/ja/p/recent-usage-experiences-of-large-models/</link>
        <pubDate>Wed, 09 Jul 2025 21:09:01 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/recent-usage-experiences-of-large-models/</guid>
        <description>&lt;p&gt;現状では、どの大規模言語モデルも特によくとはなく、各社それぞれに得意な分野や活用シーンがあります。&lt;/p&gt;
&lt;h2 id=&#34;技術ドキュメント&#34;&gt;技術ドキュメント
&lt;/h2&gt;&lt;p&gt;コードの提供、または IT 技術に関する質問：ChatGPT と Gemini&lt;/p&gt;
&lt;h2 id=&#34;コーディング&#34;&gt;コーディング
&lt;/h2&gt;&lt;p&gt;要件を整理し、コードの修正を要求する：Claude&lt;/p&gt;
</description>
        </item>
        <item>
        <title>日々のたわごと</title>
        <link>https://ttf248.life/ja/p/daily-musings/</link>
        <pubDate>Thu, 19 Jun 2025 19:07:33 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/daily-musings/</guid>
        <description>&lt;p&gt;AIは日常の開発ワークフローに浸透しており、最近投資の方向転換があり、エクイティとETFへのシフトとなりました。&lt;/p&gt;
&lt;p&gt;オープンソースプロジェクト&lt;/p&gt;
&lt;h3 id=&#34;プロジェクト記録&#34;&gt;プロジェクト記録
&lt;/h3&gt;&lt;p&gt;先週、暇つぶしにGitHubバッジを取得するためにIssueモジュールを使い始めました。以前コードを書く際に、AIの変更内容を記録する場所を探していました。個別にドキュメントを作成するのは散らかってしまいがちでした。しかし、Issueモジュールを使用することで、バグ、機能、改善などのラベルで区別し、記録が明確かつ効率的にできるようになりました。将来使わない可能性もありますが、記録を残しておくことは蓄積にもなります。
&lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/comic-reader/issues?q=is%3Aissue&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Issueリストの確認&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;リリースノート&#34;&gt;リリースノート
&lt;/h3&gt;&lt;p&gt;リリース記録を記載します。最近の関連コミットを見つけ、すべてAI生成のコミット記録であるため、ウェブインターフェースから近隣のすべてのコミット記録をコピーし、それをAIに整理させることで、素晴らしいリリース記録を作成できます。
&lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/comic-reader/releases/tag/v1.9.0&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/comic-reader/releases/tag/v1.9.0&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;アクティビティ&#34;&gt;アクティビティ
&lt;/h3&gt;&lt;p&gt;GitHubの個人ページをきちんと整理したことで、見栄えが良くなり、結果的にコーディングへの積極性が高まりました。なぜなら、データ可視化によって、ある種のものは、非常に奇妙で、簡単なポジティブなフィードバックが、持続するためのモチベーションを生み出すことができるからです。&lt;/p&gt;
&lt;h3 id=&#34;trae&#34;&gt;Trae
&lt;/h3&gt;&lt;p&gt;有料で1ヶ月の体験版を購入しましたが、どう表現するか分かりません。VSCode内でもClaude4モデルを使用しており、バイト（ByteDance）のIDE体験の方が優れており、実戦的な効果も優れています。場合によっては、同じ問題に対してTraeがより良い回答を提示することもあります。今後、年額料金を購入しても良いでしょうか？現状の「適当に弄っている頻度」では、Traeの利用回数が足りなくなる可能性があります。杞憂（きゆう）して構いません。後で使い切ったら考えれば良いですし、バイトには他の有料プランがあり、より多くの呼び出し回数を購入できるかもしれません。
&lt;del&gt;簡単な小さな問題に対しては、マイクロソフトのものを使用しており、GitHub Copilotや各モデルも利用可能です。&lt;/del&gt;
計画は頓挫しました。GitHub Copilotも呼び出し回数に制限が加えられました。&lt;a class=&#34;link&#34; href=&#34;https://docs.github.com/zh/copilot/about-github-copilot/plans-for-github-copilot#models&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;618での制限に関する情報&lt;/a&gt;
現在の使用量を確認するには&lt;a class=&#34;link&#34; href=&#34;https://docs.github.com/zh/copilot/managing-copilot/understanding-and-managing-copilot-usage/monitoring-your-copilot-usage-and-entitlements#downloading-a-monthly-usage-report&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;こちら&lt;/a&gt;を参照してください。&lt;/p&gt;
&lt;h2 id=&#34;投資&#34;&gt;投資
&lt;/h2&gt;&lt;p&gt;結局、恒生通融通が開通して以来、香港株式市場で取引したことがなく、小米の新車発表を狙って少し買い増し、値上がりすれば売却し、値下がりすれば再び買い戻す、といった操作を何度か繰り返しましたが、新車の発売には至らず、株式でわずかな利益を得ることができました。&lt;/p&gt;
&lt;p&gt;この頃、恒生通の資金の流れを眺めるのが無意味ではなく、美团は資金の純流入であり、それに便乗して投資し、成功裏に株主となりました。しかし、全体的な資金の流れを見過ごし、国内からの買い入れ資金はその一部に過ぎず、香港市場には多くの外国資本も存在することに気づきました。今回、実際に試してみることで、ブルーチップ株を長期保有し、徐々に収益を増やす方法が有効であることを確認できました。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;ポジションのコントロールと損切りは、&lt;strong&gt;人の本性とは対照的なもの&lt;/strong&gt;です。焦らず、焦らず、急がないことが大切です。小米の新車が期待外れだった場合、どうやって売却するかという問題です。投資に対する認識はまだ十分ではなく、もっと本を読んだり、学んでいく必要があります。米連邦準備制度理事会（FRB）が利下げを示唆しないため、香港株式市場は一波の暴落し、建玉を入れるタイミングを遅らせることは適切ではありません。しかし、利下げというニュースが出た場合、香港株式市場は大暴騰することになります。これが投資であり、人間の本性を試すものです。
「&lt;strong&gt;常々口にする言葉：買うのは国の運だが、自分はそれを信じているとは言えない&lt;/strong&gt;」&lt;/p&gt;
&lt;p&gt;上記の国運の信仰を抛却して、**もう一つ重要なのは注意（注意力）**です。長期的な投資をするのであれば、頻繁にチャートを見ることは意味がありません。毎朝10分、取引終了後に10分ほどを目視で確認する程度で十分です。最終的に期待できる収益率はどれくらいでしょうか？明確な損切りポイントも設定されていません。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;市場が暴落した際に、腾讯は依然として魅力的な投資対象となり、資金が集まりました。&lt;/p&gt;
&lt;p&gt;| 00700 | 腾讯控股 | 498.600 | 80.08億 |&lt;/p&gt;
&lt;h2 id=&#34;投資-1&#34;&gt;投資
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;コード&lt;/th&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;最新価格&lt;/th&gt;
&lt;th&gt;取引量&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;03690&lt;/td&gt;
&lt;td&gt;美団-W&lt;/td&gt;
&lt;td&gt;128.100&lt;/td&gt;
&lt;td&gt;68.81億&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;投資-2&#34;&gt;投資
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;コード&lt;/th&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;最新価格&lt;/th&gt;
&lt;th&gt;取引量&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;09992&lt;/td&gt;
&lt;td&gt;泡盛マット&lt;/td&gt;
&lt;td&gt;247.200&lt;/td&gt;
&lt;td&gt;57億&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;投資-3&#34;&gt;投資
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;コード&lt;/th&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;最新価格&lt;/th&gt;
&lt;th&gt;取引量&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;09988&lt;/td&gt;
&lt;td&gt;アルバビバグループ-W&lt;/td&gt;
&lt;td&gt;109.800&lt;/td&gt;
&lt;td&gt;53.22億&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;投資-4&#34;&gt;投資
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;コード&lt;/th&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;最新価格&lt;/th&gt;
&lt;th&gt;取引量&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;01810&lt;/td&gt;
&lt;td&gt;小米グループ-W&lt;/td&gt;
&lt;td&gt;53.050&lt;/td&gt;
&lt;td&gt;41.05億&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
        </item>
        <item>
        <title>ブログ翻訳プロジェクトの雑感：文化伝達、AIプログラミング</title>
        <link>https://ttf248.life/ja/p/blog-translation-project-musings-cultural-transmission-ai-programming/</link>
        <pubDate>Mon, 02 Jun 2025 21:41:00 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/blog-translation-project-musings-cultural-transmission-ai-programming/</guid>
        <description>&lt;p&gt;文化伝播：意識形態的な影響、潜移漫歩。
AIプログラミング：ソフトウェア設計を行わないため、手戻りが多くなる。&lt;/p&gt;
&lt;h2 id=&#34;文化翻訳&#34;&gt;文化翻訳
&lt;/h2&gt;&lt;p&gt;当初のプロジェクトでは、英語、日本語、韓国語という3つの言語のみをサポートしていました。その後、「結局AI翻訳だから、色々な言語に対応した方が良いのではないか」と考え、フランス語、ロシア語、ヒンディー語を追加しました。その頃は問題に気づかず、プログラムが翻訳を実行する際に、過去のコードの問題により翻訳形式が正しくなく、保存された文章を再翻訳する必要がありました。&lt;/p&gt;
&lt;p&gt;統計的な時間経過の警告が表示され、すべての翻訳が完了するまでに約20時間がかかりました。これは、ローカルでデプロイされている大規模なモデルであるためです。不要な言語をいくつか削除し、翻訳時間を短縮することを考えました。フランス語、ロシア語、ヒンディー語を削除しました。その時、何かがおかしいことに気づきました。なぜ当初選択した言語（日本語、韓国語）が、私の選択になっているのでしょうか？&lt;/p&gt;
&lt;p&gt;世界人口の分布に基づいて見ると、これらの言語のユーザー層はそれほど多くありません。特に韓国語は、世界の利用人数は約8000万人に過ぎません。日本語はわずかに多い約1億2000万人です。一方、フランス語、ロシア語、ヒンディー語の利用人数はすべて1億人以上でした。&lt;/p&gt;
&lt;p&gt;その時、言語のユーザー層が、言語の使用人数によるものではなく、文化翻訳の影響によるものであることに気づきました。韓国と日本の文化は世界的に広範な影響力を持っており、特にアジア地域で顕著です。K-pop、アニメ、映画などの文化製品は大量のファンを引き付け、これらのファンは自然と関連する言語にも興味を持つようになりました。&lt;/p&gt;
&lt;p&gt;プロジェクトの成長を振り返ると、幼い頃によく日本のアニメや漫画を見ていましたし、大人になった今では多くの韓国映画やドラマを見ました。そのため、プロジェクトの設定時の初期言語を選択する際に、無意識のうちにこれらの馴染みのある言語を選択してしまいました。&lt;/p&gt;
&lt;h3 id=&#34;ソフトウェア設計とaiプログラミング&#34;&gt;ソフトウェア設計とAIプログラミング
&lt;/h3&gt;&lt;p&gt;翻訳助手は当初、単なるシンプルなツールに過ぎなかったが、Claude4のコーディング能力を体験してから徐々に機能が拡張され、文章翻訳、タグ翻訳などのモジュールが追加された。機能が増加するにつれて、コードの複雑さもそれに伴って上昇した。AIがコードをリファクタリングしてディレクトリ構造をより明確にしたことは確かだが、新機能の拡張やバグ修正時には、AI生成されたコードには繰り返し問題が発生することがある。&lt;/p&gt;
&lt;p&gt;AIはコード生成において、全体的な構造と設計理念に対する理解に欠けている。既存のコードに基づいて修正や拡張を行うことが多く、既存モジュールの有効な再利用をできていないため、コード冗長性が生じることがある。毎回、重複コードを手動で削除する必要があり、これは無意識のうちに開発コストを増加させている。&lt;/p&gt;
&lt;p&gt;さらに、AI生成されたコードは文法的に正しくても、論理と設計において問題がある場合がある。例えば、別のプロジェクトでプロンプトをわずかに調整しただけで、生成されるウェブページの構造が完全に異なり、一貫性がない。これは初期段階における合理的な設計の欠如、機能の追加が随意な積み重ねによるものであり、コード構造が混乱していることを反映している。&lt;/p&gt;
&lt;p&gt;これはまた、ソフトウェアエンジニアリングの核心的な経験は依然として無視できないことを私たちに思い出させる。適切な設計は返工を減らすだけでなく、コードの保守性と拡張性を向上させることができる。AIは強力なツールであるものの、システム設計に対する人間の深い理解と計画を代替することはできない。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>ブログ翻訳プロジェクトの雑感：歴史対話</title>
        <link>https://ttf248.life/ja/p/blog-translation-project-musings-historical-conversations/</link>
        <pubDate>Mon, 02 Jun 2025 21:16:24 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/blog-translation-project-musings-historical-conversations/</guid>
        <description>&lt;p&gt;ブログ翻訳プロジェクトは当初、複雑に設計されていた——まずMarkdown形式を解析し、プレースホルダーでコンテンツを保護し、最後に大規模言語モデルに送信する仕組みだった。これは完全に無駄であり、大規模言語モデル自体がMarkdownの文法を認識する能力を備えており、元のコンテンツを直接処理し、翻訳時にフォーマットを維持することができたからだ。&lt;/p&gt;
&lt;p&gt;私たちの仕事は、コードのデバッグから、大規模言語モデルの&lt;strong&gt;プロンプト&lt;/strong&gt;のデバッグへと変わった。
モデル：&lt;code&gt;google/gemma-3-4b&lt;/code&gt;
ハードウェア：&lt;code&gt;Nvidia 3060 12GB&lt;/code&gt;
そう、思考しないモデルを選んだ。思考するモデルは翻訳タスクを実行する際に効率が低く、4Bパラメータと12Bパラメータの効果を比較したところ、翻訳タスクにおいてはgemma3の4Bパラメータで十分だった。12Bパラメータは翻訳タスクにおいて明確な利点を持っていなかった。
12Bパラメータの速度：&lt;strong&gt;11.32 tok/sec&lt;/strong&gt;、4Bパラメータの速度：&lt;strong&gt;75.21 tok/sec&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;背景説明&#34;&gt;背景説明
&lt;/h2&gt;&lt;p&gt;システムに様々な条件制限を加えても、出力される翻訳結果には依然として問題が発生することがありました。具体的には、フォーマットの保護が不十分であったり、過剰な説明文が含まれていたりしました。役割定義時には、Markdown形式を保護し、翻訳結果のみを出力することを明示していたにも関わらず、最終的な翻訳は不安定でした。&lt;/p&gt;
&lt;p&gt;その時、以前漫画翻訳プロジェクトで大言語モデルを活用した経験が思い出されました。その時の翻訳精度は、私のものより良かったようです。コードやリクエストデータを確認したところ、漫画翻訳プロジェクトでは、毎回リクエストにコンテキスト（文脈）を付与していました。現在の翻訳内容に加え、過去の翻訳内容もまとめて送信していたのです。&lt;/p&gt;
&lt;p&gt;このメリットは何でしょうか？前後の翻訳の一貫性を高めるだけでなく、出力フォーマットの安定性を確保することにもつながったと考えられます。&lt;/p&gt;
&lt;h2 id=&#34;履歴対話の重要性&#34;&gt;履歴対話の重要性
&lt;/h2&gt;&lt;p&gt;AI 大規模モデル（GPT シリーズ、Claude、Gemini など）の普及に伴い、ますます多くの企業や開発者が API を通じてこれらのモデルにアクセスし、インテリジェントな顧客サポート、コンテンツ生成、コードアシスタントなどのアプリケーションを構築しています。しかし、多くの方は API への初期導入時に共通の問題に直面します：&lt;strong&gt;モデル出力が不整合で文脈理解が欠如しており、場合によっては質問の意図を誤解してしまう&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;この現象を引き起こす主要な原因の一つは——&lt;strong&gt;API リクエスト中に履歴対話の内容を含めないこと&lt;/strong&gt;です。&lt;/p&gt;
&lt;h2 id=&#34;履歴対話とは&#34;&gt;履歴対話とは？
&lt;/h2&gt;&lt;p&gt;履歴対話とは、一度の会話セッションにおいて、モデルとユーザー間の過去のやり取りの記録を指します。OpenAI の Chat Completions API（など、多くの大規模言語モデル API）では、開発者がリクエスト内で完全な &lt;code&gt;messages&lt;/code&gt; 配列を作成し、過去の会話をユーザーとアシスタントのメッセージが交互に並んだ形式で渡す必要があります。&lt;/p&gt;
&lt;h3 id=&#34;例文&#34;&gt;例文
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;model&amp;quot;: &amp;quot;gpt-4&amp;quot;,
  &amp;quot;messages&amp;quot;: [
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;退職の手紙を書いてください&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;assistant&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;かしこまりました。退職理由は何を書くようにしますか？&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;個人的なキャリアの追求をしたいと考えていると述べる&amp;quot;}
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;もし最後の文だけを送った場合：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;個人的なキャリアの追求をしたいと考えていると述べる&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;モデルは退職の手紙だと全く認識できず、文脈が理解されないため、出力品質は著しく低下します。&lt;/p&gt;
&lt;h2 id=&#34;歴史対話がなぜ重要なのか&#34;&gt;歴史対話がなぜ重要なのか？
&lt;/h2&gt;&lt;h3 id=&#34;1-文脈の構築と一貫性の向上&#34;&gt;1. &lt;strong&gt;文脈の構築と一貫性の向上&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;AIモデルは本質的に「コンテキスト駆動型」であり、過去の出来事を記憶することはできません。除非你&lt;strong&gt;明示的に伝える&lt;/strong&gt;のです。対話履歴を渡すことで、モデルはあなたの意図や話題の背景をより良く理解し、期待される出力を生成できます。&lt;/p&gt;
&lt;h3 id=&#34;2-誤解の低減&#34;&gt;2. &lt;strong&gt;誤解の低減&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;もしあなたがモデルに複数のステップで指示を実行させたい場合（例：文章作成、要約、コードデバッグ）、過去の履歴はモデルが徐々に理解を深め、途中で「逸脱」したり、重要な点を失ったりするのを防ぐのに役立ちます。&lt;/p&gt;
&lt;h3 id=&#34;3-実際の人間のような対話行動のシミュレーション&#34;&gt;3. &lt;strong&gt;実際の人間のような対話行動のシミュレーション&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;実用例として、カスタマーサポートシステム、教育アシスタント、健康相談などにおいて、ユーザーの質問は通常、段階的に展開され、一度に明確な表現で表明されることはありません。会話履歴を保持することで、AIが「記憶力のあるアシスタント」のように振る舞うことができます。&lt;/p&gt;
&lt;h2 id=&#34;api-中における会話履歴の正しい追加方法&#34;&gt;API 中における会話履歴の正しい追加方法
&lt;/h2&gt;&lt;p&gt;OpenAI の API を例に、以下の構造に従うことを推奨します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;messages = [
    {&amp;quot;role&amp;quot;: &amp;quot;system&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;あなたは専門的な法律アシスタントです&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;契約書の有効条件とは何ですか？&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;assistant&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;契約書が有効であるためには、以下の条件を満たす必要があります：……&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;口頭での合意は有効ですか？&amp;quot;}
]

response = openai.ChatCompletion.create(
    model=&amp;quot;gpt-4&amp;quot;,
    messages=messages
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注意点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;system&lt;/code&gt; メッセージを使用してモデルの動作とアイデンティティを設定します。&lt;/li&gt;
&lt;li&gt;最新の数回の重要な会話のみを保持し、毎回すべての履歴を送信する必要はありません（トークン制限を超えないように）。&lt;/li&gt;
&lt;li&gt;長いセッションでは、早期のコンテンツを切り捨てて、コア情報を要約し、トークンの消費を制御します。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;実践的推奨事項&#34;&gt;実践的推奨事項
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;対話状態管理&lt;/strong&gt;: バックエンドは、各ユーザーのセッション履歴（例: Redis、データベース）を記録するためのキャッシュメカニズムを設計する必要があります。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;長さ制限&lt;/strong&gt;: OpenAI GPT-4 のコンテキスト長は 128k tokens であり、Claude 3 は 200k～1M पर्यंत可能です。適切なトリミングが必要です。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;動的履歴の要約&lt;/strong&gt;: 履歴が長すぎる場合は、モデルを使用して古い会話を要約し、その結果を対話コンテキストに追加します。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;まとめ&#34;&gt;まとめ
&lt;/h2&gt;&lt;p&gt;AI 大規模モデルの能力は強力ですが、開発者に十分なコンテキスト情報を「与える」必要があります。API リクエストに過去の会話を追加することで、モデル出力の品質と一貫性を大幅に向上させるだけでなく、ユーザーエクスペリエンスをより自然で現実的な対話に近づけることができます。AI 顧客サービス、ライティングアシスタント、プログラミングアシスタント、教育アプリケーションなど、どのような分野でも無視できない最適化テクニックです。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>慢性疾患、華やかなりし世相に眼移り</title>
        <link>https://ttf248.life/ja/p/old-ailment-stunning-flowers/</link>
        <pubDate>Mon, 26 May 2025 23:54:12 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/old-ailment-stunning-flowers/</guid>
        <description>&lt;p&gt;長年にわたりバックエンド開発に注力してきましたが、最近は &lt;code&gt;AI&lt;/code&gt; プログラミングを試したり、少しフロントエンド関連のことも取り組むようになりました。しかし、この間の苦労の中で、自分には昔からある古傷—「繁華なものに目を奪われる」—に気づきました。&lt;code&gt;AI&lt;/code&gt; を使ってフロントエンドインターフェースを実現しようとするのですが、実際にはそのような試みが現在の仕事に大きな実用的な助けになりませんし、むしろ時間を浪費してしまいます。&lt;/p&gt;
&lt;h2 id=&#34;ai-の適用シナリオ&#34;&gt;AI の適用シナリオ
&lt;/h2&gt;&lt;p&gt;小規模なプロジェクトにおいては、AI ツールが大きな役割を果たすことができ、特に独立性が高く、システムとの結合度が低く、ビジネスロジックが単純な関数を作成する際に非常に役立ちます。これらのタスクは通常、明確な入力と出力があり、文脈依存が少ないため、現在の AI 支援プログラミングの能力範囲に最適です。&lt;/p&gt;
&lt;p&gt;しかしながら、複雑なシステムアーキテクチャや深いビジネスロジックに対処する場合、AI の限界が現れ始めます。それは、プロジェクトの実際のニーズから乖離した、見かけ上は合理的だが実際には不適切なコードを生成したり、デバッグが困難な潜在的な問題を導入したりする可能性があります。これらのシナリオにおいては、AI は補助ツールとして、完全なコード生成器に依存することなく使用されるべきです。生成されたコードは厳格なレビューとテストを受け、実際の要件を満たしていることを確認する必要があります。&lt;/p&gt;
&lt;h2 id=&#34;誤りと学習の代償&#34;&gt;誤りと学習の代償
&lt;/h2&gt;&lt;p&gt;AI を使ってフロントエンドコードを生成しようとした際、多くの課題に直面しました。フロントエンドは私の馴染みのない分野であるため、問題解決には時間と労力がかかりました。プロンプトを調整して AI にコードを書き直しても、どうしても低レベルのエラーが発生してしまうのです。このような試行錯誤は時間と労力を浪費するだけでなく、現在の私のエネルギーはバックエンドのビジネスロジックに集中すべきだと痛感させられました。&lt;/p&gt;
&lt;p&gt;週末に完成させたプロジェクトを振り返ってみると、バックエンド開発とユーザーインタラクションロジックに焦点を当て、コンソールから機能を実装することが、現状で最も効率的な選択であると確信します。より多くの時間とエネルギーが手に入ったら、フロントエンドの知識を体系的に学ぶ方が良いかもしれません。&lt;/p&gt;
&lt;h2 id=&#34;フロントエンド学習の計画&#34;&gt;フロントエンド学習の計画
&lt;/h2&gt;&lt;p&gt;フロントエンド技術スタックは複雑で多様であり、短期間で習得するのは現実的ではありません。まずは、Vue.jsやReact.jsなどのフレームワークを選択し、そのコアな概念と使用方法を深く学ぶことを計画しています。基礎知識を習得した後で、AIを活用してフロントエンドコードを生成することで、不慣れによる誤りや時間の浪費を防ぐことができます。&lt;/p&gt;
&lt;p&gt;まとめると、現在の段階ではバックエンド開発に重点を置き、着実にコアスキルを向上させることに注力します。その時が来るまで、フロントエンドとAIの組み合わせを探求することは控え、より大きな成果を得られる可能性があります。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Claude4のリリース、開発を試す：hugoタグ、超リンク翻訳アシスタント</title>
        <link>https://ttf248.life/ja/p/claude-4-release-hugo-tags-hyperlink-translation-assistant/</link>
        <pubDate>Sat, 24 May 2025 03:05:31 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/claude-4-release-hugo-tags-hyperlink-translation-assistant/</guid>
        <description>&lt;p&gt;本サイトはHugoで開発されていますが、筆者自身は常に中国語のタイトルを使用しており、その結果、生成される文章の超リンクが使いにくい状態でした。つまり、送信する際に、中国語の文字が超リンク内で%E4%BD%A0%E5%A5%BDのような形式にエスケープされてしまうため、見た目が良くありません。設定でslugを設定することで解決できますが、毎回手動で設定する必要があり、非常に面倒でした。
そこで、Claude4を使って翻訳アシスタントを開発し、中国語のタイトルを自動的に英語のslugに変換し、文章中に超リンクを追加することを試みました。これにより、手動での設定を回避できます。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Claude4はマジで最高！文脈理解能力が大幅に向上し、複雑なタスクの処理効率も飛躍的に向上しています。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;プロジェクトアドレス&#34;&gt;プロジェクトアドレス
&lt;/h2&gt;&lt;p&gt;国内プロジェクトアドレス：&lt;a class=&#34;link&#34; href=&#34;https://cnb.cool/ttf248/hugo-content-suite&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://cnb.cool/ttf248/hugo-content-suite&lt;/a&gt;
国外プロジェクトアドレス：&lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/hugo-content-suite&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/hugo-content-suite&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;コードの実装&#34;&gt;コードの実装
&lt;/h2&gt;&lt;p&gt;まず、実装の思路について説明します。すべての文章をスキャンし、タグ情報と記事タイトルを抽出した後、ローカルの大規模言語モデル（例：gemma-3-12b-it）を呼び出して翻訳します。&lt;/p&gt;
&lt;p&gt;実際の開発において、前世代の大規模言語モデルと比較して、&lt;code&gt;Claude4&lt;/code&gt; はいくつかの顕著な点を発揮しました。機能要件が多いため、&lt;code&gt;Claude4&lt;/code&gt; はインタラクティブメニューを自動的に設計し、さまざまな使用シナリオを考慮しました。例えば、タグ処理に関しては、&lt;code&gt;Claude4&lt;/code&gt; はタグの統計と分析だけでなく、分類統計もサポートし、さらに&lt;strong&gt;ラベルのない文章&lt;/strong&gt;を検出することも可能です。また、プレビュー機能やタグページ生成機能も提供しています。&lt;/p&gt;
&lt;p&gt;ローカルの大規模言語モデルとの連携、翻訳キャッシュの追加、大規模なコードのリファクタリングなど、&lt;code&gt;Claude4&lt;/code&gt; はすべて一度に完了し、ほとんど問題がありませんでした。プロジェクト規模は小さくても、多くの小さな機能を含んでいました。以前の開発プロセスでは、大規模言語モデルが前の内容を忘れてしまうことがよくありましたが、今回の &lt;code&gt;Claude4&lt;/code&gt; は非常に優れており、&lt;strong&gt;ほぼコンテキストを忘れることなく動作しました&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;要するに、スマート性が向上し、今後の開発には &lt;code&gt;Claude4&lt;/code&gt; をより多く使用し、日常的なコーディングの主力モデルとして活用していく予定です。&lt;/p&gt;
&lt;h2 id=&#34;翻訳キャッシュ&#34;&gt;翻訳キャッシュ
&lt;/h2&gt;&lt;p&gt;この注文に関する説明では、大規模モデルの呼び出し回数を減らすだけでなく、実際に12Bモデルをローカルで実行すると効率が非常に高く、時間ロスもありません。しかし、毎回大規模モデルを呼び出す場合は、やはり少し遅くなります。また、文章のリンクを固定するために、全量更新を実行した場合、文章のタイトルが長いため、稀に2回の翻訳結果が異なり、リンクが変わってしまうという状況が発生します。これは非常に困ります。&lt;/p&gt;
&lt;h2 id=&#34;機能最適化&#34;&gt;機能最適化
&lt;/h2&gt;&lt;p&gt;プロジェクト全体を &lt;code&gt;Claude4&lt;/code&gt; に引き渡して、最適化の余地を分析し、以下の提案を得ました：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;外部化の設定 - メンテナンス性と柔軟性を向上
構造化ログ - 問題のトラブルシューティングと監視が容易になる
パフォーマンスモニタリング - システムの状態を把握する
ユーザーエクスペリエンス - プログレスバーなどの視覚的なフィードバック
エラー処理 - より包括的な例外処理メカニズム
コード整理 - より明確なモジュール分割
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;コードをレビューしたところ、問題点は一切なく、例えば設定ファイルについては、元のコードから設定を変換し、デフォルト設定に変換した後、設定ファイルを読み込む際に、対応する設定ファイルが存在しない場合に自動的にデフォルト設定ファイルを生成することで、ユーザーの操作ミスを防いでいました。
要件：翻訳文の正体を翻訳する際に、翻訳効率を動的に計算し、残りの時間を予測して、関連情報をコンソールに出力しました。現在、文章の文字数を取得し、各行の翻訳時に現在の翻訳文字数、時間、100文字あたりの翻訳時間を適合計算しています。同時に、文章全体の翻訳残り時間を推定します。
コードが完了した後、新しい驚きを発見しました。翻訳効率の統計情報がリアルタイムで大量に表示されますが、無制限にスクロールダウンすることはありませんでした。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;原文を英語に翻訳中（合計 7163 文字）...
翻訳する必要がある行数が 53 行検出されました。
  [1/53] Stage1/6 [░░░░░░░░░░░░░░░░░░░░░░░░░] 1.9% 354 文字の翻訳...
    ✅ 完了 (3.1秒) | API呼び出し #1
    ✅ 完了 (1.5秒) | API呼び出し #2
    ✅ 完了 (0.9秒) | API呼び出し #3
    ✅ 完了 (0.2秒) | API呼び出し #4
    ✅ 完了 (1.0秒) | API呼び出し #5
    ✅ 完了 (1.0秒) | API呼び出し #6
    ✅ 完了 (0.2秒) | API呼び出し #7
    📊 進捗: 行の 13.2% (7/53) | 文字の 12.9% (925/7163) 114.6 文字/秒 📊
    ⚡ 効率：リアルタイム 76.4 | 平均 117.9 | 最近 109.0 | ステージ 113.6 文字/秒 📊
    🎯 正確度: 100.0% (7/7) | 残り: 46行 7 秒] 9.4% 110 文字の翻訳...
    ⏱️ 残りの推定時間: 55秒 | 予想完了時間: 00:10:19 8秒] 11.3% 114 文字の翻訳...
    💾 处理速度：3211.3 行/分钟 | 总用时：8秒] 13.2% 16 文字の翻訳...
  [8/53] Stage1/6 [███░░░░░░░░░░░░░░░░░░░░░░] 15.1% 166 文字の翻訳...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以前、プログラムを制御するコードはあまり書かれていませんでしたが、どのように実装されているのか知りたくて、コードを調べてみました。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;// キャッシュクリアと再表示（動的更新効果）
if translationCount &amp;gt; 1 {
   fmt.Print(&amp;quot;\033[6A\033[K&amp;quot;) // 上に 6 行移動し、内容をクリア
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;パフォーマンス統計メニュー&#34;&gt;パフォーマンス統計メニュー
&lt;/h3&gt;&lt;p&gt;新たに作成された&lt;strong&gt;パフォーマンス統計メニュー&lt;/strong&gt;は、私自身が設計したものでも、これほど完璧とは言えない。&lt;/p&gt;
&lt;p&gt;📊 パフォーマンス統計：
🔄 翻訳回数：360
⚡ キャッシュヒット率：1.4% (5/365)
⏱️ 平均翻訳時間：315.927234ms
📁 ファイル操作：73
❌ エラー回数：0&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;データマイニング&lt;/li&gt;
&lt;li&gt;ディープラーニング&lt;/li&gt;
&lt;li&gt;ニューラルネットワーク&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;=== ブログ管理ツール ===&lt;/p&gt;
&lt;p&gt;🚀 コア機能&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;全ブログの処理をワンクリックで実行 (完全なブログ処理フロー)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;📝 コンテンツ管理
2. タグページを生成
3. アーティクルスラッグを生成
4. 記事を多言語バージョンに翻訳&lt;/p&gt;
&lt;p&gt;💾 キャッシュ管理
5. キャッシュの状態を確認
6. 全量翻訳キャッシュの生成
7. 翻訳キャッシュをクリア&lt;/p&gt;
&lt;ol start=&#34;0&#34;&gt;
&lt;li&gt;プログラム終了&lt;/li&gt;
&lt;/ol&gt;</description>
        </item>
        <item>
        <title>AIを使いすぎると、後遺症のようなものがある。</title>
        <link>https://ttf248.life/ja/p/ai-overuse-side-effects/</link>
        <pubDate>Wed, 14 May 2025 19:39:50 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ai-overuse-side-effects/</guid>
        <description>&lt;p&gt;新しい「AI 灵感碰撞坊」を立ち上げたことで、様々なものが溢れてしまい、AIを使って記録したり、発信したりするものが増え続けていますが、静かに自分自身で考え込むようなものは減ってきているようです。今後はこの欄の出力をある程度コントロールし、月刊形式にまとめるのが良いかもしれません。毎月1本の内容を公開すればよいでしょう。&lt;/p&gt;
&lt;p&gt;これはまるで、一種の副作用のようなもの、あるいは後遺症と言えるかもしれません。効率は上がっていますが、思考の深さや幅は縮んでしまっているように感じます。&lt;/p&gt;
&lt;h2 id=&#34;効率向上否定できない&#34;&gt;効率向上：否定できない
&lt;/h2&gt;&lt;p&gt;以前、ブログのコーナー「魚の七秒鐘見聞」はあまりメンテナンスされていませんでした。いくつかの話題事件を放置し、インターネット検索や記録整理を行わずにいたためです。しかし、様々なAIツールが登場し、大枠を整理するだけで、AIが自動的に関連するイベントを検索・記録し、必要な文章を生成したり、簡単なフォーマット調整を行うことができます。&lt;/p&gt;
&lt;p&gt;これはまさに怠惰な人にとっての福音であり、効率は大幅に向上しました。さらには、執筆やコーディングにおいても同様です。以前はAPIインターフェースドキュメントの詳細な読み込みが必要でしたが、現在はAIがそれを代わりに行うため、非常に効率的です。APIの習得は「肉体労働」であり、「知的労働」ではありません。AIにこの部分を任せるのが最適です。&lt;/p&gt;
&lt;h2 id=&#34;垃圾コンテンツ&#34;&gt;垃圾コンテンツ
&lt;/h2&gt;&lt;p&gt;多くの稿子で、内容の質が低いと言わざるを得ません。読み応えがなく、煙火の息吹がないという点で、以前私が好まなかったスタイルです。まるで蝋を噛むようなものです。&lt;/p&gt;
&lt;p&gt;別の角度から言えば、AI生成コンテンツは、まさに流水線のようなもので、魂が欠けていると感じられます。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;新時代のインターネットゴミ&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;忘却性&#34;&gt;忘却性
&lt;/h2&gt;&lt;p&gt;このタイプの稿子は、読者の状況が不明確であり、時間が経つにつれて、私の記憶も曖昧になり、つい忘れかけてしまうことがあります。&lt;/p&gt;
&lt;p&gt;同様の問題は、コードを書く際にも発生します。コードの提交記録を振り返らずに、自分がどのように考え、なぜそう書いたのか全く思い出せないのです。特に、コードとAIが繰り返しコミュニケーションを通じて生成されたコードは、当初のアイデアとは大きく異なり、場合によっては全く異なるものになってしまうことがあります。&lt;/p&gt;
&lt;h2 id=&#34;検索&#34;&gt;検索
&lt;/h2&gt;&lt;p&gt;最近、Googleや百度を開く回数が明らかに減りました。多くの問題はAIを使って検索したり、インタラクティブな部分も検索結果も、従来の検索エンジンよりもずっと良いからです。
現在では、まだ生きているかどうか分からない&lt;code&gt;bing ai&lt;/code&gt;を追悼しましょう。これは大手企業の中で最初に公開された、インターネットに接続して検索できるAIツールです。
Googleの使用頻度が減り、&lt;code&gt;stackoverflow&lt;/code&gt;へのアクセス回数も減りました。多くの問題は直接AIに質問するだけで済みます。このサイトも時代の淘汰にさらされるでしょう。&lt;/p&gt;
&lt;h2 id=&#34;おわりに&#34;&gt;おわりに
&lt;/h2&gt;&lt;p&gt;筆記がメンテナンスしているブログですが、元々アクセス数は少なかったこともあり、現在はさらに期待していません。むしろ、自分宛の記録場所という性格になっています。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>コードを記述せず、カスタム株式選定モジュールを設計・開発する。</title>
        <link>https://ttf248.life/ja/p/design-develop-custom-stock-module-no-code/</link>
        <pubDate>Thu, 27 Feb 2025 23:20:39 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/design-develop-custom-stock-module-no-code/</guid>
        <description>&lt;p&gt;先月の当社では、cursorを試用しましたが、無料枠の制限により、複雑な機能開発は行わず、簡単なテストに留めました。その際に見つけたのは、Byte社も同様の製品を発表しており、両者は共通してClaude-3.5という大規模言語モデルを底で呼んでいる点でした。
Byte社の製品はTraeといい、最初にリリースされたmac版が今年2月にWindows版もリリースされました。大手企業のものは良いもので、無料でClaude-3.5を無制限に利用できるため、このモデルの性能は非常に優れています。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;最終的にはK線チャートの開発で詰まってしまいました。Reactの知識が全くない私には、直接的に大きなタスクであるK線チャートの開発を引き受けることはできません。より細かくタスクを分割し、開発を進めるためには、筆者がフロントエンドの基礎知識を追加し、タスクを分解する必要がありました。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;発見された問題点&#34;&gt;発見された問題点
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;外国製のAIモデルを使用していたため、Vue3 + Element-Plusの学習データが不足しており、Reactをフロントエンドフレームワークとして採用しました。&lt;/li&gt;
&lt;li&gt;偶発的な構文エラーが存在する可能性があり、手動での修正が必要です。&lt;/li&gt;
&lt;li&gt;一部の複雑な問題に対する解決策は、人的指導が必要となります。&lt;/li&gt;
&lt;li&gt;コード構造の最適化には、人的指導が必要です。&lt;/li&gt;
&lt;li&gt;最も時間がかかったのは、フロントエンドコードをコンテナにパッケージングすることでした。筆者は環境が全く理解されておらず、&lt;code&gt;.env.production&lt;/code&gt;や&lt;code&gt;tsconfig.json&lt;/code&gt;といった概念自体を知らなかったため、途中で助けを求める豆包（ネットでの質問サイトのユーザー）に頼らざるを得ませんでした。フロントエンドの開発 devモードとbuildモードでは、コードチェックや差異が大きく異なり、対応に苦慮しました。バックエンドのデータベースおよびサービスのコンテナスクリプトは、合計5分で完了しましたが。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AIは現状では開発効率を向上させる主な役割であり、基礎があることが最も重要です。AIがすべての問題を解決してくれるわけではありません。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;リポジトリアドレス&#34;&gt;リポジトリアドレス
&lt;/h2&gt;&lt;p&gt;タイトル通り、今回は手を動かさず、AIと雑談して、自選株モジュールを設計・開発してみます。最終的に何ができるのか試していきます。&lt;/p&gt;
&lt;p&gt;リポジトリアドレス：&lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/trae-demo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/trae-demo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;詳細な使用方法は、リポジトリのREADME.mdファイルをご覧ください。&lt;/p&gt;
&lt;p&gt;このリポジトリには多数の提出記録が含まれており、ほとんどが私とTraeとの会話記録、およびTraeの機能に対する私のテストです。対応する機能を実装するために人工干渉を行ったかどうかを備考に記載しています。&lt;/p&gt;
&lt;h2 id=&#34;プロンプト&#34;&gt;プロンプト
&lt;/h2&gt;&lt;p&gt;プロジェクトは、ゼロから作成するものですが、以下の内容がプロジェクトのプロンプトです：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;プロジェクトのプロトタイプ図に基づいて、以下の機能を開発してください：
    *   選別銘柄（ウォッチリスト）機能。契約新規追加、削除、修正、照会をサポートする必要があります。
    *   選別銘柄インターフェースは、基本的な市場データを表示する必要があります。
    *   複数の異なる市場の切り替えをサポートする必要があります。

    フロントエンド：React
    バックエンド：Golang Gin GORM
    データベース：PostgreSQL

    サーバーサイドには、クロスオリジンリクエストをサポートする必要があり、データの検証とエラー処理も考慮する必要があります。バックエンドサービスが利用できない場合、フロントエンドはアラートを表示する必要があります。

    バックエンドは、リクエストとレスポンスのログを表示し、フロントエンドも通信ログを出力して問題のトラブルシューティングに役立てます。
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;uiとインタラクションの最適化&#34;&gt;UIとインタラクションの最適化
&lt;/h2&gt;&lt;p&gt;フロントエンドインターフェースのデザインは完全にGrokに依存しています。まず、Trae内で成果物のプロトタイプを作成しましたが、美観が欠けていました。使用していたモデルはコード能力は非常に高いものの、他の能力は弱いため、Grokを使用してフロントエンドのUIを最適化する必要があります。&lt;/p&gt;
&lt;p&gt;現在のインターフェースのスクリーンショットを撮影し、それをGrokにアップロードして、UIを最適化するように指示します。これにより、一度に多くの最適化提案を受け取ることができ、それらを人工的に評価し、Traeにコピーして実行し、最適化の効果を確認できます。&lt;/p&gt;
&lt;h3 id=&#34;技術スタック&#34;&gt;技術スタック
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;フロントエンド：React + TypeScript&lt;/li&gt;
&lt;li&gt;バックエンド：Golang + Gin + GORM&lt;/li&gt;
&lt;li&gt;データベース：PostgreSQL 17&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;システムアーキテクチャ&#34;&gt;システムアーキテクチャ
&lt;/h2&gt;&lt;h2 id=&#34;バックエンドアーキテクチャ&#34;&gt;バックエンドアーキテクチャ
&lt;/h2&gt;&lt;p&gt;バックエンドは Golang の Gin フレームワークを用いて RESTful API を実装しており、主なモジュールには以下が含まれます。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;データベースモジュール&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;GORM を ORM 框架として使用&lt;/li&gt;
&lt;li&gt;環境変数でデータベース接続を設定可能&lt;/li&gt;
&lt;li&gt;自動的にデータベーススキーマのマイグレーションを実行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ルーティングモジュール&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;RESTful API 設計&lt;/li&gt;
&lt;li&gt;一貫したエラーハンドリングメカニズム&lt;/li&gt;
&lt;li&gt;内蔵されたリクエストログ記録&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;クロスオリジン処理&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;ローカル開発環境でのクロスオリジンをサポート&lt;/li&gt;
&lt;li&gt;設定可能な CORS ポリシー&lt;/li&gt;
&lt;li&gt;Cookie を使用したクロスオリジンをサポート&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;フロントエンドアーキテクチャ&#34;&gt;フロントエンドアーキテクチャ
&lt;/h2&gt;&lt;p&gt;フロントエンドはReact + TypeScriptで構築され、以下の機能を実装しています。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;株価リストの表示&lt;/li&gt;
&lt;li&gt;お気に入り銘柄の管理&lt;/li&gt;
&lt;li&gt;相場データ表示&lt;/li&gt;
&lt;li&gt;エラー通知メカニズム&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>AI開発2年：ドッカーのリリース前の状態に似ている</title>
        <link>https://ttf248.life/ja/p/ai-development-two-years-like-docker-pre-release/</link>
        <pubDate>Thu, 20 Feb 2025 18:16:37 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ai-development-two-years-like-docker-pre-release/</guid>
        <description>&lt;p&gt;人工知能（AI）は近年、技術分野で最も議論を呼ぶトピックの一つであり、特に過去2年間でその進歩は目覚ましいものがありました。深層学習、自然言語処理、コンピュータビジョン、自動化意思決定システムなど、AIの応用範囲は多岐にわたります。しかしながら、技術が着実に進化を続けているにもかかわらず、AIはDockerのリリース前のボトルネックに似た状況にあります――つまり、市場を本格的に引き出す「ゲームチェンジャー」となるような、決定的なアプリケーションが存在しないのです。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;プロンプト：記事を作成してください：AIは過去2年間で発展し、Dockerのリリース前のボトルネックのような状態になっています。既存技術に基づいて、完璧な実用例を作り出し、Dockerはあまり新しい技術を使用していませんが、全体的なソリューションが合理的に、運用および開発ワークフローを変革します。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;aiの現状技術は成熟しているが応用には突破が必要&#34;&gt;AIの現状：技術は成熟しているが、応用には突破が必要
&lt;/h2&gt;&lt;p&gt;技術的な側面から見ると、AIは過去2年間で相当な進歩を遂げました。OpenAIが発表したGPTシリーズモデルや、GoogleのBERT、DeepMindのAlphaシリーズなど、AIの処理能力は以前の予測を大幅に上回っています。特に自然言語処理分野では、GPT-4などのモデルが強力な生成能力に加え、理解と推論においても驚くべきパフォーマンスを示しています。&lt;/p&gt;
&lt;p&gt;しかしながら、技術革新は日進月歩であるにもかかわらず、AIの実用的な応用においてはいくつかの課題が残されています。Dockerのリリース前の状況に似ており、AIの潜在力は巨大ですが、現状では広く普及し、産業を変革するほどの「破壊的イノベーション」をもたらす主要なアプリケーションが登場していません。人々はAIの将来について議論していますが、必ずしも革命的な変化をもたらす直接的な応用シナリオを見つけるとは限りません。多くのAIアプリケーションはまだ初期段階の試みにとどまり、大部分はさらなる統合と最適化が必要です。&lt;/p&gt;
&lt;h2 id=&#34;dockerとaiの類似性技術は必ずしも革新ではなく解決策が重要&#34;&gt;DockerとAIの類似性：技術は必ずしも革新ではなく、解決策が重要
&lt;/h2&gt;&lt;p&gt;Dockerリリース前の歴史を振り返ると、技術環境とAIの現状には多くの類似点が見られることに気づきます。Dockerリリース前に、コンテナ技術自体が新しいものではありませんでした。初期のLXC（Linux Containers）や仮想化技術も、コンテナ化の基本的な能力を持っていました。しかし、Dockerは既存技術を巧みに統合・最適化することで、よりシンプルで直感的かつ効率的な解決策を提示しました。この解決策は、画期的な技術を導入したわけではありませんが、運用および開発プロセスにおける多くの課題を解決し、ソフトウェアのデプロイ、拡張、管理プロセスの大幅な簡素化を実現しました。&lt;/p&gt;
&lt;p&gt;同様に、AI分野も類似の状況に直面しています。現在のAI技術は、もはや「新鮮なもの」ではありませんが、大規模なアプリケーションを実現するためには、完璧な実行環境が必要であり、Dockerのように既存技術を統合・最適化して、合理的なアプリケーション解決策を形成することが重要です。AIのゲームチェンジャーとなるアプリケーションは、必ずしも新しい技術のブレークスルーに依存するのではなく、既存技術を組み合わせて、実際のビジネスにおける課題やニーズを解決することにある可能性があります。&lt;/p&gt;
&lt;h2 id=&#34;aiのdocker-momentドッカーmomentを見つける方法&#34;&gt;AIの「Docker Moment」（ドッカーMoment）を見つける方法
&lt;/h2&gt;&lt;p&gt;AI技術を広く普及させるためには、いくつかの側面から取り組む必要があります。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;実用シナリオの深掘り&lt;/strong&gt;
現在の多くのAIアプリケーションは実験的な性質が強く、大規模な実用化には至っていません。AI客服やレコメンデーションなどの分野は広く利用されていますが、その機能はまだ多くの場合、業界のボトルネックを突破していません。真のブレイクスルーは、従来のやり方に困っている業界から生まれる可能性があります。例えば、医療、製造業、物流などの分野では、AIがより効率的なデータ処理と予測分析を通じて、企業がこれらの複雑なシナリオで効率を高め、コストを削減するのを支援できます。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;製品化と使いやすさ&lt;/strong&gt;
Dockerのようにコンテナ化プロセスを簡素化し運用効率を向上させるのと同様に、AI製品の使いやすさは非常に重要です。AIの普及は技術の普及だけでなく、その製品化の普及でもあります。AIを日常業務フローに統合し、ユーザーが技術的な理解なしにこれらのツールを簡単に利用できるようにすることは、AIの実用化における重要なステップです。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;エコシステムの構築と標準化&lt;/strong&gt;
いかなる新技術も広く普及するためには、エコシステムの構築が不可欠です。Dockerが急速に台頭したのも、そのオープン性と互換性によるものであり、開発者がさまざまなクラウドプラットフォーム、ツール、サービスと簡単に連携できるようになったからです。同様に、AIの未来はエコシステムの構築に依存します。AIの標準化、モデルの共有、データのオープン、技術の統合可能性などが、AIが広範な産業応用を達成する上で重要な要素となります。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;結論aiの未来は可能性に満ちているが更なる完善な落とし所を必要とする&#34;&gt;結論：AIの未来は可能性に満ちているが、更なる完善な落とし所を必要とする
&lt;/h2&gt;&lt;p&gt;過去2年間にわたり、AI技術は目覚ましい進歩を遂げているものの、現状では「決定的な応用例」が存在しない段階にある。Dockerがリリース前のコンテナ化技術と同様に、AIには合理的な適用シナリオが必要であり、既存の技術とビジネスニーズを深く融合させることで初めて、大規模な応用と普及を実現できる。技術革新は確かに重要だが、業務プロセスを簡素化し、効率を高めるソリューションこそが、技術の普及と発展を促進するだろう。&lt;/p&gt;
&lt;p&gt;未来において、AIはDockerのように、画期的な技術的ブレークスルーではなく、既存技術を統合し、完璧な適用シナリオを構築することで、私たちの仕事や生活様式を変革していく可能性がある。&lt;/p&gt;</description>
        </item>
        <item>
        <title>ollama ローカル実行 deepseek-R1</title>
        <link>https://ttf248.life/ja/p/ollama-local-deployment-deepseek-r1/</link>
        <pubDate>Fri, 07 Feb 2025 22:41:02 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ollama-local-deployment-deepseek-r1/</guid>
        <description>&lt;p&gt;Ollamaは、大規模言語モデル（LLM）をローカルで実行およびデプロイすることを目的としたオープンソースのAIツールです。クラウドサービスへの依存なしに、開発者がローカルマシン上でGPTのようなモデルを使用するための簡単なかつ効率的な方法を提供することを目指しています。Ollamaは複数のモデルに対応し、パフォーマンスを最適化することで、リソースが限られたデバイスでもこれらのモデルをスムーズに実行できるように設計されています。&lt;/p&gt;
&lt;p&gt;Ollamaを使用すると、ユーザーはテキストベースのAIアプリケーションを利用でき、ローカルでデプロイされたモデルとインタラクトすることができ、データプライバシーやAPIの使用料金に関する懸念なく、自然言語処理や質問応答などのタスクを実行できます。コマンドラインインターフェース（CLI）を通じて異なるモデルを呼び出し、これらのタスクを実行できます。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ollamaは様々なモデルを試すのに適しており、Windows版のテストではハードウェアの性能を十分に発揮できなかった可能性があります。これはWindows版の問題かもしれません。Linux版の方が良い結果が得られる可能性があります。32bパラメータのモデルをデプロイし、メモリとGPU負荷が低い場合に、応答速度が遅いことが確認されました。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;ハードウェア概要&#34;&gt;ハードウェア概要
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;オペレーティングシステム: Windows 11&lt;/li&gt;
&lt;li&gt;CPU: i7-10700K&lt;/li&gt;
&lt;li&gt;メモリ: 40GB&lt;/li&gt;
&lt;li&gt;グラフィックカード: RTX 3060 12GB&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;環境準備&#34;&gt;環境準備
&lt;/h2&gt;&lt;p&gt;以下のシステム環境変数を設定し、後続の使用を容易にします：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_MODELS=E:\ollama&lt;/code&gt;&lt;/strong&gt;
この変数で Ollama モデルの保存場所を指定します。 &lt;code&gt;E:\ollama&lt;/code&gt; はフォルダパスであり、ダウンロードまたはデプロイしたローカルモデルファイルをすべてここに格納します。Ollama はこのパスに基づいてモデルをロードおよび使用します。モデルファイルの保存場所を変更する場合は、このパスを更新してください。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_HOST=127.0.0.1:8000&lt;/code&gt;&lt;/strong&gt;
Ollama サービスのホストとポートを設定します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;127.0.0.1&lt;/code&gt; はローカルアドレス（localhost）であり、Ollama サービスは本機からのリクエストのみを待ち受けます。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;8000&lt;/code&gt; は指定するポート番号であり、Ollama サービスが 8000 ポートでリクエストを受信および処理します。必要に応じてポート番号を変更できますが、他のアプリケーションで使用されていないことを確認してください。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_ORIGINS=*&lt;/code&gt;&lt;/strong&gt;
Ollama サービスへのアクセスを許可するオリジン（ソース）を制御します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;*&lt;/code&gt; はすべてのオリジン（つまり、すべてのドメインと IP アドレス）が Ollama サービスにアクセスできることを意味します。これは通常、開発およびデバッグ環境で使用されます。本番環境では、セキュリティを高めるために、特定のドメインまたは IP アドレスのみを許可するようにより厳格なオリジン制御を設定することが一般的です。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;deepseek-r1-モデルのデプロイ&#34;&gt;DeepSeek-R1 モデルのデプロイ
&lt;/h2&gt;&lt;p&gt;ollama のインストールは、初心者向けで簡単なため、詳細は省略します。
インストール後の検証：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core&amp;gt;ollama -v
ollama version is 0.5.11
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;モデルのデプロイについては、公式ウェブサイトのモデルページを参照し、対応するパラメータのモデルを選択してください: &lt;code&gt;ollama run deepseek-r1:14b&lt;/code&gt;
14b パラメータは会話コンテキストを効果的に記憶でき、より小さなパラメータバージョンではコンテキストを記憶できません。32b パラメータバージョンは、ローカルでのデプロイ時に非常に遅延するため、詳細なテストは行っていません。&lt;/p&gt;
&lt;h2 id=&#34;参考文献&#34;&gt;参考文献
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ollama.com/library/deepseek-r1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.ollama.com/library/deepseek-r1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/x18990027/article/details/145368094&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/x18990027/article/details/145368094&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Cursor AI プログラミング IDE のトライアル</title>
        <link>https://ttf248.life/ja/p/cursor-ai-programming-ide-trial/</link>
        <pubDate>Thu, 23 Jan 2025 19:30:13 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/cursor-ai-programming-ide-trial/</guid>
        <description>&lt;p&gt;一年又转眼即逝之际，在工作中最大的变化莫过于AI参与度明显提高。以往，不同开发语言之间切换，需要开发者熟悉各种语言的不同API接口，现在这些基础代码都可以通过AI生成代码了，对于开发者来说，无疑是一个巨大的福音。&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;23年の時点で、簡単な入門紹介を既に2本作成していましたが、今では25年となり、どう表現しようか… 顕著な進歩を感じ取ることはなく、自律的な認知能力を発展させ、タスクを合理的に分割できることなどが求められます。もちろん、最も重要なのはAIが生成したコードにバグが存在するかどうかを特定することです。&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;Github Copilot
&lt;/h2&gt;&lt;p&gt;いつの日か忘れましたが、シンガポールでサーバーがデプロイされているという情報を見つけました。国内では利用され、長期間のVPN接続も不要になりました。ただし、ログイン時にはVPN接続は必要ですが、そのVPN接続はログイン時のみ使用し、その後はオフにしておくことができます。&lt;/p&gt;
&lt;p&gt;日常的な使い道としてはGithub Copilotをより多く活用しています。この拡張機能は、VS CodeやVisual Studioで直接利用できます。2つのソフトウェア間の切り替えが不要です。ChatGPTと比較して、Github Copilotの方がプロジェクトのサポートが優れており、インタラクションもフレンドリーです。また、一部のローカルファイルをAIに「学習」させることで、生成されるコードがあなたのプロジェクトに合っているものになります。&lt;/p&gt;
&lt;h2 id=&#34;cursor-ai&#34;&gt;Cursor AI
&lt;/h2&gt;&lt;p&gt;最近、Cursor AI という新しいAIプログラミングIDEを見つけました。これはGithub Copilotをベースにしたもので、このIDEはよりスマートで、直接ファイルを作成するのを手伝ってくれます。&lt;/p&gt;
&lt;p&gt;簡単な使い方は試してみて、なかなか良いと感じましたが、既存プロジェクトの理解はまだ十分ではありません。ローカルプロジェクトのファイルが多い場合や、大規模なリファクタリング、最適化、調整を行う場合は、やはり&lt;strong&gt;開発者がタスクを分割して行う&lt;/strong&gt;必要があります。&lt;/p&gt;
&lt;p&gt;例として、curso のエンジンモードに切り替えて、以下の内容を入力してみましょう。「複数の異なるスタイルで切り替えられる個人用履歴書ウェブページの作成。個人情報をデータ表示のために埋めてください。」&lt;/p&gt;
&lt;p&gt;何度かやり取りするうちに、以下のようなウェブページが得られます。もちろん、このウェブページはかなりシンプルですが、初心者にとっては非常に良いでしょう。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;現在の登録ユーザーは、高度なAPIを150回無料で試用でき、有料ユーザーは5,000回まで制限されています。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;cursor-ai-1&#34;&gt;Cursor AI
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://cursor/index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;履歴書&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>AIプログラミングとタスク分解</title>
        <link>https://ttf248.life/ja/p/ai-programming-and-task-decomposition/</link>
        <pubDate>Fri, 22 Dec 2023 08:44:26 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ai-programming-and-task-decomposition/</guid>
        <description>&lt;p&gt;2年前、サイトにコード領域のコピー機能を追加するために、半日ほど試行錯誤した結果、レンダリング効果が少し不満だった。半ば無能なフロントエンド開発者として、改善することも思わなかった。動けばそれで十分だ、と割り切っていた。今年、&lt;code&gt;AI&lt;/code&gt;を使って小程序を開発し、フロントエンドの開発もより慣れてきた。そしてリファクタリングを行った（&lt;code&gt;AI&lt;/code&gt;が再設計）。&lt;/p&gt;
&lt;p&gt;悟り：タスク分解をして、多くの小さなタスクは&lt;code&gt;AI&lt;/code&gt;で開発すると自然にこなせる。すでに閉鎖された小程序において、&lt;code&gt;75%&lt;/code&gt;のコードを&lt;code&gt;AI&lt;/code&gt;が提供し、複数のタスクを分割して引き渡すことで、人工によってプロジェクトコードが&lt;code&gt;組み立て&lt;/code&gt;られた。&lt;/p&gt;
&lt;h2 id=&#34;前文&#34;&gt;前文
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://ttf248.github.io/post/2022/001/%E4%BB%A5%E4%B8%BA%E5%BE%88%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%8B%E6%83%85%E5%A2%9E%E5%8A%A0%E4%B8%80%E4%B8%AA%E4%BB%A3%E7%A0%81%E5%A4%8D%E5%88%B6%E6%8C%89%E9%92%AE/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;簡単なことだと考えたけど、コードのコピーボタンを追加する&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;promot&lt;/strong&gt;: クラス &amp;ldquo;highlight&amp;rdquo; を持つウェブページの要素のコンテナ内に、コードと JavaScript の CSS およびコードを記述して、テキストのコピー機能を実現するコピーボタンを追加します。&lt;/p&gt;
&lt;p&gt;最初のドラフトのコードは一見問題があり、基本的には使用可能なものを生成し、コピーされた内容が正しくなく、冗長な文字が含まれているため、最適化を再度誘導し、コアの色設計を指定し、エフェクトを含めるようにしました。&lt;/p&gt;
&lt;p&gt;お客様がボタンのサイズと色に関して特定の要件をお持ちであることを認識しており、これらの要件に合わせてスタイルのデザインを再構築できます。以下は、提供されたカラーパレットとボタンサイズの最適化を含むスタイルです。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.copy-btn {
  position: absolute;
  top: 2px; /* 位置調整 */
  right: 2px;
  padding: 3px 6px; /* サイズ縮小 */
  font-size: 12px; /* フォントサイズ縮小 */
  background-color: #8FD1E1; /* ボタンの背景色 */
  color: #272822; /* テキストの色 */
  border: 1px solid #272822; /* ボーダーの色 */
  border-radius: 3px; /* 角丸 */
  cursor: pointer;
  opacity: 0.7; /* デフォルトの不透明度 */
  transition: opacity 0.3s ease, background-color 0.3s ease; /* 平滑なトランジション効果 */
}

.copy-btn:hover {
  opacity: 1; /* マウスオーバー時に完全表示 */
  background-color: #A3D4E5; /* マウスオーバー時の背景色 */
}

.highlight {
  position: relative;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;このスタイルでは、ボタンのサイズとフォントサイズを小さくして、より洗練された外観にしています。また、ボタンはデフォルトで半透明になっており、マウスをホバーすると完全表示され、背景色がわずかに明るくなることで視覚的なフィードバックを提供します。これにより、お客様のカラー要件を満たしつつ、モダンでユーザーフレンドリーな特徴を備えたデザインを実現しています。&lt;/p&gt;
&lt;p&gt;以下はよりシンプルな JavaScript です。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-JavaScript&#34;&gt;document.addEventListener(&#39;DOMContentLoaded&#39;, function() {
  // すべての .highlight 要素を検索
  const highlights = document.querySelectorAll(&#39;.highlight&#39;);

  highlights.forEach(function(highlight) {
    // コピーボタンを作成
    const copyBtn = document.createElement(&#39;button&#39;);
    copyBtn.textContent = &#39;コピー&#39;;
    copyBtn.classList.add(&#39;copy-btn&#39;);

    // ボタンを各 .highlight 要素に追加
    highlight.appendChild(copyBtn);

    // クリックイベントリスナーを追加
    copyBtn.addEventListener(&#39;click&#39;, function() {
      // .highlight 内の最初の &amp;lt;code&amp;gt; 要素からコピーするコードを取得 (存在する場合)
      const code = highlight.querySelector(&#39;code&#39;) ? highlight.querySelector(&#39;code&#39;).textContent : &#39;&#39;;

      navigator.clipboard.writeText(code).then(() =&amp;gt; {
        // コピー成功メッセージを表示
        copyBtn.textContent = &#39;已コピー!&#39;;
        setTimeout(() =&amp;gt; {
          copyBtn.textContent = &#39;コピー&#39;;
        }, 2000);
      }).catch(err =&amp;gt; {
        console.error(&#39;コピー失敗: &#39;, err);
      });
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;終わりに&#34;&gt;終わりに
&lt;/h2&gt;&lt;p&gt;コード領域の右上隅に、トップエリアにコピーボタンを追加することを望んでいたが、フロントエンドに関する知識が不足しており、キーワードに基づいて機能を正確に記述することができなかったため、AIと何度もやり取りして期待に応えられなかった。&lt;/p&gt;
&lt;p&gt;しかし、時間の経過とともに、AIがプログラミング開発にどの程度の影響を与えるのかは分からない。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>プロンプトエンジニア</title>
        <link>https://ttf248.life/ja/p/prompt-engineer/</link>
        <pubDate>Sun, 26 Mar 2023 20:46:53 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/prompt-engineer/</guid>
        <description>&lt;p&gt;例として、かつて検索エンジンのテクニックを学んだように、私たちはまた、&lt;code&gt;AI&lt;/code&gt;とコミュニケーションするためのテクニックも習得する必要がある。合理的な制約条件を与え、効率的に必要な答えを得る方法を学ぶのだ。&lt;/p&gt;
&lt;p&gt;もし角度を変えて考えると、現在の&lt;code&gt;AI&lt;/code&gt;は記憶力に優れた小さな子供であり、完璧に暗記し、宿題をコピーできる能力を持っている。私たちがやるべきことは、&lt;code&gt;AI&lt;/code&gt;と正確かつ効果的にコミュニケーションする方法を学び、要求を正確に記述することで、&lt;code&gt;AI&lt;/code&gt;が期待される結果を生み出すのを助けることだ。&lt;/p&gt;
&lt;h2 id=&#34;科学普及&#34;&gt;科学普及
&lt;/h2&gt;&lt;p&gt;話題となっている&lt;code&gt;AI&lt;/code&gt;（人工知能）を具体的に言うと&lt;code&gt;Generative Pre-Training&lt;/code&gt;（生成事前学習）です。これはインターネット上で利用可能なデータを用いてテキスト生成を行う深層学習モデルであり、質問応答、テキスト要約生成、機械翻訳、分類、コード生成、対話型AIなど様々なタスクに用いられます。現在、GPT-1、GPT-2、GPT-3、GPT-4といった異なるバージョンのモデルが存在し、それぞれが前バージョンよりも規模が大きく、性能も向上しています。&lt;/p&gt;
&lt;h2 id=&#34;到底有没有智能&#34;&gt;到底有没有智能
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;類似度が高ければ高いほど、精度も高くなる&lt;/li&gt;
&lt;li&gt;基本的な、反復性の仕事は、特定の訓練を受けることで、人工の介入が不要になる
生成式AIとは、既存のテキスト、音声、画像などのデータを活用して新しいコンテンツを作成する技術である。テキスト生成、音声合成、画像生成、対話システムなど、様々なタスクに使用できる。生成式AIの論理性は、その学習データとモデル構造に依存する。一般的に、生成式AIは一定程度、文法、論理、常識に従うことができるが、誤りや偏見、または不真実を含むコンテンツを生成することもある。そのため、生成式AIの出力は人間の判断と検証が必要であり、盲目的に信頼したり使用したりすることはできない。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;プロンプトエンジニア&#34;&gt;プロンプトエンジニア
&lt;/h2&gt;&lt;p&gt;時間は流れの法則を変えない。人は潮流に適応することを学ぶ必要がある。AIを無智能で論理性に欠けるものと捉えがちだが、よく書けば使えないコードを生成することも少なくない。&lt;/p&gt;
&lt;p&gt;もし別の角度から考えると、現在のAIは記憶力に優れた幼い子供であり、丸暗記する能力を持っている。つまり、問題をコピーする能力があるのだ。私たちがやるべきことは、AIに対して適切で効果的かつ正確なコミュニケーションを学び、要求を明確に記述し、AIが期待される結果を生み出すのを支援することだ。&lt;/p&gt;
&lt;h2 id=&#34;対話モデル&#34;&gt;対話モデル
&lt;/h2&gt;&lt;p&gt;2年前、GitHub Copilotの発表は誰も予想していませんでした。その結果、OpenAIが横空に出現し、人類は大規模言語モデルの能力を認識するに至りました。&lt;/p&gt;
&lt;p&gt;コメントベースのプログラミングと対話ベースのプログラミングに基づき、インタラクティブなロジックは完全に異なり、対話のパターンは初心者ユーザーにとって親しみやすく、NewBingが各質問の後に提示するフォローアップのヒントは必須です。Microsoftは、AI知識ベースにあるより多くのコンテンツを取得するために、ユーザーを誘導しようとしています。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;データの前処理&lt;/li&gt;
&lt;li&gt;深層学習&lt;/li&gt;
&lt;li&gt;ニューラルネットワーク&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;栗子&#34;&gt;栗子
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 必要なライブラリをインポート
import argparse
import logging
import multiprocessing
import os

from PIL import Image


# 画像をグレースケールに変換し、透明背景を維持して画像を保存し、ファイルサイズを返す関数を定義します。
def convert_and_save(image_file):
    # 画像を開く
    try:
        image = Image.open(image_file)
    except Exception as e:
        logging.error(f&amp;quot;画像 {image_file} のオープンに失敗しました：{e}&amp;quot;)
        return None, None
    # 画像のモードを取得します。RGBA モードの場合、透明背景があります。
    mode = image.mode
    if mode == &amp;quot;RGBA&amp;quot;:
        # 画像と同じサイズの白い背景画像を生成します。
        background = Image.new(&amp;quot;RGB&amp;quot;, image.size, (255, 255, 255))
        # 元の画像に背景を貼り付け、透明ピクセルを無視します。
        background.paste(image, mask=image.split()[3])
        # 合成された画像をグレースケールモードに変換します。
        gray_image = background.convert(&amp;quot;L&amp;quot;)
        # グレースケール画像をRGBAモードに戻して透明背景を維持します。
        final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
    else:
        # RGBA モードでない場合は、画像が直接グレースケールモードに変換されます。
        final_image = image.convert(&amp;quot;L&amp;quot;)
    # 元の画像のファイル名と拡張子を取得します。
    file_name, file_ext = os.path.splitext(image_file)
    # 新しい画像のファイル名を定義し、_bw サフィックスを追加して黒白であることを示します。
    new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # 新しい画像を保存し、品質を最適化してファイルサイズを削減します。
    try:
        final_image.save(new_file_name, optimize=True)
    except Exception as e:
        logging.error(f&amp;quot;{new_file_name} の保存に失敗しました：{e}&amp;quot;)
        return None, None
    # 元の画像と新しい画像のファイルサイズを取得し、返します。
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return file_name, old_size, new_size

# コマンドライン引数を解析し、フォルダパスと拡張名リストを返す関数を定義します。
def parse_args():
    # 解析器オブジェクトを作成します。
    parser = argparse.ArgumentParser(description=&amp;quot;画像を黒白に変換し、品質を最適化します。&amp;quot;)
    # 位置パラメータを追加してフォルダパスを指定します。
    parser.add_argument(&amp;quot;folder_path&amp;quot;, help=&amp;quot;画像が含まれるフォルダーのパスです。&amp;quot;)
    # オプションパラメータを追加して拡張名リストを指定します。デフォルトは png, jpg, jpeg, gif です。
    parser.add_argument(&amp;quot;-e&amp;quot;, &amp;quot;--extensions&amp;quot;, nargs=&amp;quot;+&amp;quot;, default=[&amp;quot;.png&amp;quot;, &amp;quot;.jpg&amp;quot;, &amp;quot;.jpeg&amp;quot;, &amp;quot;.gif&amp;quot;], help=&amp;quot;画像ファイルの拡張子です。&amp;quot;)
    # コマンドライン引数を解析し、結果オブジェクトを返します。
    args = parser.parse_args()
    return args.folder_path, args.extensions

# 変換前後のファイルサイズの違いを出力する関数を定義します。
def print_result(result):
    # 結果が空でない場合、変換と保存が成功したことを示します。
    if result:
        # 結果をファイル名とファイルサイズのタプルに分解します。
        if len(result) == 3:
            file, old_size, new_size = result
            # コントロールパネルで変換前後のファイルサイズの違いを出力します。
            logging.info(f&amp;quot;{file}: {old_size} バイト -&amp;gt; {new_size} バイト&amp;quot;)
        else:
            # 結果を出力します。
            logging.info(f&amp;quot;{result}&amp;quot;)

# 日志記録器を設定し、ログをコンソールとファイルに出力し、ログレベルを INFO に設定します。
logging.basicConfig(level=logging.INFO,
                    format=&amp;quot;%(asctime)s %(levelname)s %(message)s&amp;quot;,
                    handlers=[logging.StreamHandler(),
                              logging.FileHandler(&amp;quot;log.txt&amp;quot;)])

# # 別のプロセスに、パイプを介して渡されたコードを実行するように通知されます。これは、`--multiprocessing-fork` コマンドライン引数を渡すことで行われます。
# `freeze_support()` 関数の実装を見ると、それが実行されているプロセスの確認と、パイプを介して渡されたコードの実行が必要かどうかを確認するタスクを実行します。
# `multiprocessing.freeze_support()`

# コア数に基づいてコンピューターに自動的にプロセスを割り当てるプロセスプールを作成します。
# プロセスプール = multiprocessing.Pool()
# 异步タスクの結果オブジェクトを格納するための空のリストを作成します。
# results = []
# フォルダー内のすべてのファイルに対して反復処理を行います。
# for file in os.listdir(folder_path):
#     # ファイルパスを結合します。
#     file_path = os.path.join(folder_path, file)
#     # 拡張子リストに基づいて画像ファイルを判断します。必要に応じて拡張子リストを変更できます。
#     if any(file_path.endswith(ext) for ext in extensions):
#         # 関数を呼び出して、画像を変換して保存し、ファイルサイズを取得します。パイプを介したコードの実行は、メインプロセスをブロックすることなく、非同期で行われます。
#         result = pool.apply_async(convert_and_save, args=(file_path,), callback=print_result)
#         # 結果オブジェクトをリストに追加します。
#         results.append((file, result))
# プロセスプールを閉じ、新しいタスクの受け入れをやめます。
# pool.close()
# すべてのタスクが完了するまで待ちます。
# pool.join()

## 終わりに

ローカル開発が `windows` システムであるため、AI が最初に提示した回答には `main` 関数も `multiprocessing.freeze_support` も含まれておらず、エラーが発生しました。質問を重ねることでエラーの原因を特定し、コードを修正しました。

かつて検索エンジンの技術を学ぶように、AI とコミュニケーションする上でも、適切な制約条件を与え、効率的に必要な回答を得るためのスキルを習得する必要があります。

注意：**もしあなたがプログラミング初心者であれば、提示されたコメントと合わせて理解できない点がある場合は、引き続き関連コードについて質問してください。**&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>AIによるプログラミング支援、生産性の進化</title>
        <link>https://ttf248.life/ja/p/ai-assisted-programming-productivity-evolution/</link>
        <pubDate>Tue, 28 Feb 2023 17:05:17 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ai-assisted-programming-productivity-evolution/</guid>
        <description>&lt;p&gt;GitHub Copilot のリリースからわずか 2 年しか経っていないのに、ChatGPT が登場し、裏にある原理をよく理解していない状態で、しばらく使ってみた。2 つのツールのサポートレベルは完全に異なり、どちらも生産性を大幅に向上させた。&lt;/p&gt;
&lt;p&gt;あまりにも複雑なことについては、AI ではまだできないだろう。なぜなら、彼らは論理がなく、パターンや形式固定されたもの、あるいは范式を定めているからだ。学習データは十分で、AI の効果は 9 分満点になる。&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;GitHub Copilot
&lt;/h2&gt;&lt;p&gt;リリース時に、公式サイトの紹介の &lt;code&gt;demo&lt;/code&gt; を見ると、あまり賢くなく、試用してみましたが、使い勝手が良くありませんでしたので、諦めました。
2022年以前に、暇つぶしで切り替えて新バージョンを体験したところ、かなり良くなっており、ただ国内の速度が少し遅いのは、ネットワークの問題である可能性が高いです。&lt;code&gt;Python&lt;/code&gt;のような言語では、コメントに基づいて書かれたコードもそれなりによくできており、自分で資料を探して書いていたよりもはるかに速かったです。&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;Github Copilot&lt;/code&gt;は、プログラマー、つまり開発者の視点から製品を設計しており、プログラミングの知識が必要であり、コメントを通じてAIによるコーディング支援を誘導していくものでした。
&lt;code&gt;ChatGPT&lt;/code&gt;は次の段階に進み、&lt;strong&gt;専門家でなくてもすぐに使いこなせるように設計されています&lt;/strong&gt;。対話形式でのチャットインターフェースにより、質問や要件の説明、理解できない場合は引き続き質問することができます。&lt;/p&gt;
&lt;p&gt;例えば、品詞分割の概念を知っているものの、コーディング方法がわからない状態で、文字列の類似度を計算したい場合を考えてみましょう。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Python 品詞分割 維天運通 LOGORY と 合肥維天運通情報科技股份有限公司 2 つの文字列の類似度を計算します。
比較前に、文字列を英語小文字に変換するなどして統一処理を行います。
2 番目の文字列の中に最初の文字列の最初の文字が見つかれば、2 番目の文字列を最初の文字列の長さと同じ長さで切り捨てます。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;こんにちは、これはBingです。😊
オンラインの情報123に基づき、Python の品詞分割には &lt;code&gt;jieba&lt;/code&gt; などのライブラリを使用できます。&lt;code&gt;jieba&lt;/code&gt; ライブラリは、精密モード、全模式、検索エンジンモードの 3 つの分詞モードをサポートしています。要件に応じて適切なモードを選択できます。
文字列の類似度を比較するには、まず文字列を品詞分割し、その後の単語ベクトルまたは編集距離などの指標を計算する必要があります。&lt;code&gt;numpy&lt;/code&gt; や &lt;code&gt;scipy&lt;/code&gt; などのライブラリを使用して数学演算を行うことができます。
文字列を統一的に処理するために、英語を小文字に変換するには、Python の組み込み関数 &lt;code&gt;lower()&lt;/code&gt; を使用できます。
2 番目の文字列を切り出すには、Python のスライス操作符 &lt;code&gt;[ ]&lt;/code&gt; を使用できます。&lt;/p&gt;
&lt;p&gt;以下は、その際のコード例です。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import jieba
import numpy as np
from scipy.spatial.distance import cosine

# 定義する 2 つの文字列
str1 = &amp;quot;維天運通 LOGORY&amp;quot;
str2 = &amp;quot;合肥維天運通情報科技股份有限公司&amp;quot;

# 統一処理：英語を小文字に変換
str1 = str1.lower()
str2 = str2.lower()

# 2 番目の文字列の中に最初の文字列の最初の文字が見つかる位置を探す
index = str2.find(str1[0])

# 見つかった場合、2 番目の文字列を切り出す
if index != -1:
    str2 = str2[index:index+len(str1)]

# jieba 库を使用して文字列を品詞分割する
words1 = list(jieba.cut(str1))
words2 = list(jieba.cut(str2))

# 2 つの文字列の単語ベクトル（頻度を重みとして使用）を計算する
vector1 = np.zeros(len(words1))
vector2 = np.zeros(len(words1))

for i, word in enumerate(words1):
    vector1[i] += 1 # 最初の文字列内の各単語の出現回数をカウント
    if word in words2:
        vector2[i] += 1 # 2 番目の文字列内の各単語の出現回数をカウント

# 2 つの文字列の類似度（余弦距離を指標として使用）を計算する
similarity = 1 - cosine(vector1, vector2)

print(&amp;quot;2 つの文字列の類似度は：&amp;quot;, similarity)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;さらに、結果を確認し、問題点を発見します。結果はランダムで、実際のコードを実行していませんが、良い結果を提供します。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;栗子&#34;&gt;栗子
&lt;/h3&gt;&lt;p&gt;質問：SQL文で、製品コードテーブルから、製品コードが80000～89999の範囲にあるレコードを抽出するには？&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;こんにちは、Bingです。😊

検索結果12によると、指定された範囲内の値を選択するために、BETWEEN演算子を使用できます。BETWEEN演算子は、開始値と終了値を両方含みます。

まず、クエリするテーブル名と列名を指定し、WHERE句でBETWEEN演算子と範囲値を指定する必要があります。

たとえば、製品コードが80000から89999の範囲にある製品コードテーブルからレコードを抽出するには、次のステートメントを使用できます。

SELECT * FROM product_code
WHERE code BETWEEN 80000 AND 89999;
ここで、*はすべての列3を選択します。特定の列（たとえば、製品名と価格）のみを選択する場合は、カンマで区切って指定できます。例えば：

SELECT name, price FROM product_code
WHERE code BETWEEN 80000 AND 89999;
これで役に立つことを願っています。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;さらに質問します。否定して：製品コードは文字列であり、あなたのコードは間違っています。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;申し訳ありませんが、製品コードが文字列であることに気づいていませんでした。もしそうであれば、範囲の値の前後にはシングルクォートを追加する必要があります。例えば：

SELECT * FROM product_code
WHERE code BETWEEN &#39;80000&#39; AND &#39;89999&#39;;
私の誤りを許してください。🙏
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;おめでとうございます。正しく認識します。&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Ai on 向叔の手帳</title>
        <link>https://ttf248.life/ja/tags/ai/</link>
        <description>Recent content in Ai on 向叔の手帳</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>ja</language>
        <lastBuildDate>Sun, 25 May 2025 14:10:37 +0800</lastBuildDate><atom:link href="https://ttf248.life/ja/tags/ai/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>クロード4リリース、試作：Hugoタグ、ハイパーリンク翻訳アシスタント</title>
        <link>https://ttf248.life/ja/p/claude-4-release-and-experimentation-hugo-tags-hyperlink-translation-assistant/</link>
        <pubDate>Sat, 24 May 2025 03:05:31 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/claude-4-release-and-experimentation-hugo-tags-hyperlink-translation-assistant/</guid>
        <description>&lt;p&gt;このサイトは hugo で開発されているのですが、筆者はいつも中国語のタイトルを使っているため、生成される記事のハイパーリンクが親しみやすくありません。つまり、発信したときに見栄えが悪く、中国語の文字がハイパーリンク内で %E4%BD%A0%E5%A5%BD のような形式に変換されてしまうのです。slug を設定すれば解決できるのですが、毎回手動で設定する必要があり、面倒です。&lt;/p&gt;
&lt;p&gt;それで、今日はClaude4を使って翻訳アシスタントを開発してみようと思います。中国語のタイトルを自動的に英語のスラッグに変換し、記事にハイパーリンクを追加することで、手動設定の手間を省きます。&lt;/p&gt;
&lt;p&gt;クロード4は素晴らしい、文脈理解能力と複雑なタスク処理の効率が大幅に向上している。&lt;/p&gt;
&lt;h2 id=&#34;プロジェクトの場所&#34;&gt;プロジェクトの場所
&lt;/h2&gt;&lt;p&gt;国内プロジェクトアドレス：&lt;a class=&#34;link&#34; href=&#34;https://cnb.cool/ttf248/hugo-slug-auto&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://cnb.cool/ttf248/hugo-slug-auto&lt;/a&gt;
海外プロジェクトの場所：&lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/hugo-slug-auto&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/hugo-slug-auto&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;コード実装&#34;&gt;コード実装
&lt;/h2&gt;&lt;p&gt;実装のアイデアですが、まず全ての記事をスキャンし、タグ情報と記事タイトルを抽出します。その後、ローカルの大規模言語モデル（gemma-3-12b-itなど）を用いて翻訳を行います。&lt;/p&gt;
&lt;p&gt;実際の開発において、以前の世代の大規模言語モデルと比較して、&lt;code&gt;Claude4&lt;/code&gt;はいくつかの顕著な特徴を示しています。機能要件が多いため、&lt;code&gt;Claude4&lt;/code&gt;はインタラクティブメニューを自動的に設計し、様々な使用シナリオを網羅的に考慮しています。例えば、タグ処理に関して、&lt;code&gt;Claude4&lt;/code&gt;はタグの統計と分析だけでなく、分類統計もサポートし、さらには&lt;strong&gt;未ラベルの記事&lt;/strong&gt;を検出することもできます。また、&lt;strong&gt;プレビュー&lt;/strong&gt;機能やタグページ生成機能も提供しています。&lt;/p&gt;
&lt;p&gt;ローカルモデルとの連携や翻訳キャッシュの追加、さらには広範囲にわたるコードのリファクタリングであっても、&lt;code&gt;Claude4&lt;/code&gt;は一度で完了し、ほとんど問題が発生しませんでした。プロジェクト規模は大きくありませんでしたが、多くの小機能が含まれていました。従来の大言語モデルでは開発中に以前の内容を忘れてしまうことがよくありましたが、今回の&lt;code&gt;Claude4&lt;/code&gt;は非常に優れたパフォーマンスを発揮し、&lt;strong&gt;コンテキストの忘れがほとんどありませんでした&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;要言すれば、知能が向上し、次はその後の準備として&lt;code&gt;Claude4&lt;/code&gt;に移行して、より多くの開発作業を行うことになります。日常のコーディングにおける主力モデルとして活用します。&lt;/p&gt;
&lt;h2 id=&#34;翻訳キャッシュ&#34;&gt;翻訳キャッシュ
&lt;/h2&gt;&lt;p&gt;この点を言えば、大規模言語モデルの呼び出し回数を減らすだけでなく、実際にローカルで12Bモデルを実行すると、効率は高く、作業を妨げることはありません。しかし、毎回大規模言語モデルを呼び出すと少し遅くなることがあります。次に、記事のリンクを固定するために、全量更新操作を行う際に、記事のタイトルが長い場合、時々、翻訳結果が2回で異なり、その結果、記事のリンクが変わってしまうという事態が発生することがあります。これは非常に困ったことです。&lt;/p&gt;
&lt;h2 id=&#34;機能改善&#34;&gt;機能改善
&lt;/h2&gt;&lt;p&gt;プロジェクト全体を&lt;code&gt;Claude4&lt;/code&gt;に投げ込み、最適化の余地を分析した結果、以下の提案が得られました。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;配置外置化 - 提高可维护性和灵活性
结构化日志 - 便于问题排查和监控
性能监控 - 了解系统运行状况
用户体验 - 进度条等视觉反馈
错误处理 - 更完善的异常处理机制
代码组织 - 更清晰的模块划分
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;コードを確認しました、全て問題ありません。例えば設定ファイルですが、以前のコードの設定をデフォルト設定に変換し、設定ファイルを読み込む際に、対応する設定ファイルがない場合、自動的にデフォルトの設定ファイルが生成されるため、ユーザーの誤った操作を防ぐことができます。&lt;/p&gt;
&lt;h3 id=&#34;性能統計メニュー&#34;&gt;性能統計メニュー
&lt;/h3&gt;&lt;p&gt;新たに導入された&lt;strong&gt;パフォーマンス統計メニュー&lt;/strong&gt;は、自分で設計してもここまで完璧にはならないだろう。&lt;/p&gt;
&lt;p&gt;パフォーマンス統計：
翻訳回数：360
キャッシュヒット率：1.4%（5/365）
平均翻訳時間：315.927234ms
ファイル操作：73
試行回数：0&lt;/p&gt;
&lt;h3 id=&#34;進捗状況表示&#34;&gt;進捗状況表示
&lt;/h3&gt;&lt;p&gt;新たに追加された&lt;strong&gt;プログレスバー表示&lt;/strong&gt;は、詳細な進捗状況、経過時間、および残り時間の推定値を示します。&lt;/p&gt;
&lt;p&gt;機能を選択してください（0-13）：10
翻訳目標を収集中です。
キャッシュファイルが読み込まれました。翻訳記録は0件です。&lt;/p&gt;
&lt;p&gt;翻訳キャッシュ統計:
タグ総数：229個
記事総数：131件
キャッシュ済み：0 個
360個&lt;/p&gt;
&lt;p&gt;確認しますか？ 全量翻訳キャッシュを生成しますか？ (y/n): y
🚀 全量翻訳キャッシュを生成しています…
キャッシュファイルが読み込まれました。翻訳記録は0件です。
翻訳をキャッシュから確認中…
🔄 新ラベルを360個翻訳する必要があります。
[░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 5/360 (1.4%) - 時間: 3秒 - 残り時間: 3分8秒💾 キャッシュファイル保存済み、翻訳記録5件を含む
[█░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 10/360 (2.8%) - 時間: 6秒 - 残り時間: 3分28秒💾 キャッシュファイル保存済み、翻訳記録10件を含む
[██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 15/360 (4.2%) - 時間: 9秒 - 残り時間: 3分30秒💾 キャッシュファイル保存済み、翻訳記録15件を含む
[██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 20/360 (5.6%) - 時間: 13秒 - 残り時間: 3分36秒💾 キャッシュファイル保存済み、翻訳記録20件を含む
[███░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 25/360 (6.9%) - 時間: 16秒 - 残り時間: 3分33秒💾 キャッシュファイル保存済み、25件の翻訳記録を含む
[████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 30/360 (8.3%) - 時間: 19秒 - 残り時間: 3分30秒💾 キャッシュファイル保存済み、30件の翻訳記録を含む
[████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 35/360 (9.7%) - 用时: 22s - 预计剩余: 3m25s💾 已保存缓存文件，包含 35 个翻译记录 [████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 35/360 (9.7%) - 経過時間: 22秒 - 残り時間見込み: 3分25秒💾 キャッシュファイル保存済み、翻訳記録35件を含む&lt;/p&gt;
&lt;hr&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;=== 博客标签管理工具 ===

📊 数据查看
  1. 标签统计与分析
  2. 分类统计
  3. 无标签文章

🏷️  标签页面管理
  4. 预览标签页面
  5. 生成标签页面

📝 文章Slug管理
  6. 预览文章Slug
  7. 生成文章Slug

💾 缓存管理
  8. 查看缓存状态
  9. 预览全量翻译缓存
 10. 生成全量翻译缓存
 11. 清空翻译缓存

🔧 系统工具
 12. 查看性能统计
 13. 重置性能统计

  0. 退出程序
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;hugoタグ自動化管理ツール&#34;&gt;Hugoタグ自動化管理ツール
&lt;/h1&gt;&lt;p&gt;🚀 Hugoブログ用に設計されたスマートなタグ管理ツール。AI翻訳、ローカルキャッシュ、そしてフレンドリーなインターフェースをサポートしています。&lt;/p&gt;
&lt;h2 id=&#34;-主要特長&#34;&gt;✨ 主要特長
&lt;/h2&gt;&lt;h3 id=&#34;-ai-翻訳&#34;&gt;🤖 AI 翻訳
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;LM StudioベースのローカルAIモデル翻訳&lt;/li&gt;
&lt;li&gt;中国語のタグが自動的にSEOに優しい英語のスラッグに変換されます。&lt;/li&gt;
&lt;li&gt;バッチ翻訳をサポートし、処理効率を高めます。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;スマートキャッシュシステム&#34;&gt;スマートキャッシュシステム
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;ローカルJSONキャッシュにより、重複翻訳を回避します。&lt;/li&gt;
&lt;li&gt;自動キャッシュ状態を検出し、API呼び出しを節約します。&lt;/li&gt;
&lt;li&gt;キャッシュ管理とクリア機能のサポート&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;フレンドリーなインターフェース&#34;&gt;フレンドリーなインターフェース
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;直感的コマンドラインメニューシステム&lt;/li&gt;
&lt;li&gt;カラー出力、鮮明で読みやすい。&lt;/li&gt;
&lt;li&gt;プレビュー機能、安全・信頼性があります。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;データ分析統計&#34;&gt;データ分析統計
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;タグ使用頻度分析&lt;/li&gt;
&lt;li&gt;分類統計と可視化&lt;/li&gt;
&lt;li&gt;タグなし記事検出&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;-すばやく始める&#34;&gt;🚀 すばやく始める
&lt;/h2&gt;&lt;h3 id=&#34;環境要件&#34;&gt;環境要件
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Go 1.21+&lt;/li&gt;
&lt;li&gt;LM Studio (オプション、AI翻訳用)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;インストールと実行&#34;&gt;インストールと実行
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 克隆项目
git clone https://github.com/ttf248/hugo-slug-auto.git
cd hugo-slug-auto

# 安装依赖
go mod tidy

# 运行工具
go run main.go [content目录路径]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;基本操作&#34;&gt;基本操作
&lt;/h3&gt;&lt;p&gt;タグ解析：ブログのタグ使用状況統計を確認
タグページを生成する：各タグごとに専用のページを作成する。
記事スラッグ管理：記事タイトルからSEOに優しいURLを生成する
キャッシュ管理：翻訳キャッシュの確認と管理&lt;/p&gt;
&lt;h2 id=&#34;プロジェクトアーキテクチャ&#34;&gt;プロジェクトアーキテクチャ
&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;hugo-slug-auto/
├── main.go              # 主程序入口
├── models/              # 数据模型
├── scanner/             # 文章扫描解析
├── stats/               # 统计分析
├── translator/          # AI翻译模块
├── generator/           # 内容生成器
├── display/             # 界面显示
└── docs/               # 详细文档
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;主な機能&#34;&gt;主な機能
&lt;/h2&gt;&lt;h3 id=&#34;タグ管理&#34;&gt;タグ管理
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;タグ統計分析&lt;/li&gt;
&lt;li&gt;自動生成ラベルページ&lt;/li&gt;
&lt;li&gt;一括翻訳処理&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;文書管理&#34;&gt;文書管理
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;📝 スラグ自動生成&lt;/li&gt;
&lt;li&gt;記事内容分析&lt;/li&gt;
&lt;li&gt;一括処理対応&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;スマート機能&#34;&gt;スマート機能
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;AI駆動の翻訳&lt;/li&gt;
&lt;li&gt;スマートキャッシュメカニズム&lt;/li&gt;
&lt;li&gt;正確なコンテンツ識別&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ドキュメントリンク&#34;&gt;ドキュメントリンク
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;インストール設定ガイド&lt;/li&gt;
&lt;li&gt;機能説明&lt;/li&gt;
&lt;li&gt;APIインターフェースドキュメント(docs/api.md)&lt;/li&gt;
&lt;li&gt;トラブルシューティング&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;貢献ガイド&#34;&gt;貢献ガイド
&lt;/h2&gt;&lt;p&gt;問題やプルリクエストの提出を歓迎します！詳細については、&lt;a class=&#34;link&#34; href=&#34;docs/contributing.md&#34; &gt;貢献ガイド&lt;/a&gt; をご確認ください。&lt;/p&gt;
&lt;h2 id=&#34;許可証&#34;&gt;許可証
&lt;/h2&gt;&lt;p&gt;MITライセンス - 詳細については&lt;a class=&#34;link&#34; href=&#34;LICENSE&#34; &gt;LICENSE&lt;/a&gt;ファイルをご参照ください。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;もしこのプロジェクトがあなたのお役に立てたなら、ぜひStarでサポートをお願いします！&lt;/p&gt;</description>
        </item>
        <item>
        <title>AIを使いすぎたせいか、少し後遺症が出ている。</title>
        <link>https://ttf248.life/ja/p/ai-overuse-side-effects/</link>
        <pubDate>Wed, 14 May 2025 19:39:50 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ai-overuse-side-effects/</guid>
        <description>&lt;p&gt;新しい&lt;code&gt;AI インスピレーションラボ&lt;/code&gt;を設立してから、色々なものの試しにAIで記録し、発表するものが増えたせいで、静まって自分自身で考える時間が減ってしまった。今後はこの欄の産出を少しコントロールして、月刊形式にするのが良いだろう。毎月1記事ずつ発表するのがいい。&lt;/p&gt;
&lt;p&gt;まるで何らかの後遺症や副作用のようで、効率は上がったものの、思考の深さと広がりが低下している。&lt;/p&gt;
&lt;h2 id=&#34;効率向上否定できない&#34;&gt;効率向上：否定できない
&lt;/h2&gt;&lt;p&gt;魚の七秒間の見聞 以前、この欄目はあまり維持されていませんでした。いくつかのホットな話題については、怠惰ゆえにインターネットで資料を検索したり、記録をまとめたりしませんでしたが、今では様々なAIツールがあるので、大まかなアウトラインを作成するだけで、AIが自動的に関連イベントを検索し記録し、必要な記事を生成してくれます。簡単なフォーマットの整理をして公開すれば良いのです。&lt;/p&gt;
&lt;p&gt;これはまさに怠け者の救いといったものだ、効率がかなり上がり、まるで労少なく成果を上げているかのようだ。&lt;/p&gt;
&lt;p&gt;原稿を書く作業を脇に置いてコードを書いている時の効率は、間違いなく向上しています。以前は詳細なAPIインターフェースドキュメントの説明を読む必要があった多くのコードの作成ですが、今はそれを直接スキップできます。このスキップは非常に重要です。APIへの慣れは「体力仕事」であり、「頭脳労働」ではありません。AIにこの部分を任せるのは、まさにそのものです。&lt;/p&gt;
&lt;h2 id=&#34;ゴミコンテンツ&#34;&gt;ゴミコンテンツ
&lt;/h2&gt;&lt;p&gt;たくさんの原稿があって、内容はあまり良くない。完全に否定できるわけではないけれど、読んでいてどうだろうか、生活感がないというか、昔から好かなかったスタイルで、味が無い感じだ。&lt;/p&gt;
&lt;p&gt;別の視点から言うと、AIが生成するコンテンツは、確かにベルトコンベアで大量生産されたようなもので、魂がないように見える。&lt;/p&gt;
&lt;p&gt;新時代のインターネットゴミ&lt;/p&gt;
&lt;h2 id=&#34;忘却性&#34;&gt;忘却性
&lt;/h2&gt;&lt;p&gt;この手の原稿は、すべてAI生成もので、読者の状況は不明ですが、時間が経つと、自分の記憶も曖昧になり、忘れそうになることがあります。&lt;/p&gt;
&lt;p&gt;似した問題は、コードを書いている時にも起こります。コードのコミット履歴を見ないと、自分が当時どう考えていたのか、なぜそう書いたのか全く分かりません。特に、コードが通るまでAIと何度もやり取りして生成されたコードは、当初の考え方とは大きく異なり、場合によっては全く違うものになります。&lt;/p&gt;
&lt;h2 id=&#34;検索&#34;&gt;検索
&lt;/h2&gt;&lt;p&gt;最近Googleや百度を開く回数が明らかに減った。多くの問題をAIで検索すると、インタラクションも検索結果も従来の検索エンジンよりずっと良い。&lt;/p&gt;
&lt;p&gt;今、生存しているかどうか分からない「빙 아이(bing ai)」に追悼の意を捧げましょう。大手企業の中で最初にリリースされ、インターネット検索が可能なAIツールです。&lt;/p&gt;
&lt;p&gt;グーグルを使う機会が減り、&lt;code&gt;stackoverflow&lt;/code&gt;へのアクセスも減った。多くの問題は直接AIに聞けるし、このサイトも時代に取り残されていくのだろう。&lt;/p&gt;
&lt;h2 id=&#34;結び&#34;&gt;結び
&lt;/h2&gt;&lt;p&gt;筆者が現在もメンテナンス中のブログですが、元々アクセス数はそれほど多くなかったし、今はさらに期待できません。むしろ、記録しておく場所という側面が強く、自分自身が見るためのものです。&lt;/p&gt;</description>
        </item>
        <item>
        <title>コードを書かずに、カスタム銘柄選択モジュールを設計・開発する。</title>
        <link>https://ttf248.life/ja/p/no-code-design-develop-custom-stock-module/</link>
        <pubDate>Thu, 27 Feb 2025 23:20:39 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/no-code-design-develop-custom-stock-module/</guid>
        <description>&lt;p&gt;先月、Cursor を試用しましたが、無料枠の制限により、複雑な機能開発は行わず、簡単なテストにとどまりました。その際、ByteDance も同様の商品をリリースしていることがわかり、両者とも基盤となる大規模言語モデルは Claude-3.5 でした。&lt;/p&gt;
&lt;p&gt;バイトのプロダクトTrae、まずMac版がリリースされ、今年の2月になってようやくWindows版もリリースされました。大手企業のものはやっぱり良いですね。無料で利用でき、お金を払わずにClaude-3.5を無制限に使えるので、このモデルの効果はなかなか良いです。&lt;/p&gt;
&lt;p&gt;最終、K線図の開発でつまずいてしまいました。私自身がreactの基礎をほとんど理解していないため、諦めざるを得ませんでした。開発を続けたいのであれば、筆者がフロントエンドの基礎知識を補強し、タスクをより細かく分割する必要があり、いきなり「K線図の開発」という大きなタスクを与えるべきではありません。&lt;/p&gt;
&lt;h2 id=&#34;発見された問題&#34;&gt;発見された問題
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;海外のAIモデルを使用するため、Vue3 + Element-Plus のトレーニングデータが不足しているため、React をフロントエンドフレームワークとして選択しました。&lt;/li&gt;
&lt;li&gt;文法的な誤りが偶発的に存在する可能性があり、手動での修正が必要です。&lt;/li&gt;
&lt;li&gt;複雑な問題の解決には、手動によるガイダンスが必要です。&lt;/li&gt;
&lt;li&gt;コード構造の最適化には人的指導が必要です。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最も時間がかかったのは、フロントエンドコードをコンテナにパッケージ化することです。筆者はゼロから始めたため、&lt;code&gt;.env.production&lt;/code&gt;や&lt;code&gt;tsconfig.json&lt;/code&gt;といった概念が全く理解できませんでした。途中で豆包（友人）に助けられたおかげで、ようやく対応するロジックを整理することができました。フロントエンドの開発におけるdevモードとbuildモードでは、コードのチェックに関して大きな違いがあります。バックエンドデータベースとサービスのコンテナスクリプトは、合わせて5分程度で終わりました。&lt;/p&gt;
&lt;p&gt;AIは現在、開発の効率を上げることに重点が置かれており、基礎があることが最も重要です。AIがすべての問題を解決するわけではありません。&lt;/p&gt;
&lt;h2 id=&#34;倉庫住所&#34;&gt;倉庫住所
&lt;/h2&gt;&lt;p&gt;タイトルが示すように、今回は書かずにAIと直接対話し、独自の株式モジュールを設計・開発します。最終的にどのような効果が得られるか見てみましょう。&lt;/p&gt;
&lt;p&gt;倉庫アドレス：&lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/trae-demo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/trae-demo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;詳細な使用方法は、倉庫のREADME.mdファイルを参照してください。&lt;/p&gt;
&lt;p&gt;倉庫には多くの提出記録が含まれており、そのほとんどが私とTraeとの会話記録、そして私がTraeのいくつかの機能に対して行ったテストです。それぞれの機能を達成するために手動介入を行ったかどうかを注記しています。&lt;/p&gt;
&lt;h2 id=&#34;prompt&#34;&gt;Prompt
&lt;/h2&gt;&lt;p&gt;プロジェクトはゼロから作成され、以下にプロンプトを示します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;基于项目原型图，开发功能：自选股，需要支持合约的新增、删除、修改、查询。自选股界面需要展示基础的行情数据。支持多个不同的市场切换。

前端：react
后端：golang gin gorm
数据库：PostgreSQL

服务端需要支持跨域请求，同时需要考虑数据的校验和错误处理，如果后端服务不可用，前端需要告警提示。

后端需要展示请求和应答的日志；前端也打印通讯的日志，方便排查问题。
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;ユーザーインターフェースとインタラクションの最適化&#34;&gt;ユーザーインターフェースとインタラクションの最適化
&lt;/h2&gt;&lt;p&gt;フロントエンドのインターフェースのデザインは完全にGrokに依存しており、まずTraeでプロダクトのプロトタイプを作成しましたが、美意識はありませんでした。使用しているモデルはコード生成能力は非常に高いですが、他の能力は弱いため、Grokを使ってフロントエンドUIを最適化する必要があります。&lt;/p&gt;
&lt;p&gt;現在のインターフェースのスクリーンショットを Grok にアップロードし、UI の最適化を依頼すると、一度に多くの改善提案が得られるかもしれない。私たちはそれらを評価し、Trae で実行して、最適化の効果を確認する。&lt;/p&gt;
&lt;h3 id=&#34;技術スタック&#34;&gt;技術スタック
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;フロントエンド：React + TypeScript&lt;/li&gt;
&lt;li&gt;バックエンド：Golang + Gin + GORM&lt;/li&gt;
&lt;li&gt;データベース：PostgreSQL 17&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;システムアーキテクチャ&#34;&gt;システムアーキテクチャ
&lt;/h2&gt;&lt;h2 id=&#34;バックエンドアーキテクチャ&#34;&gt;バックエンドアーキテクチャ
&lt;/h2&gt;&lt;p&gt;バックエンドはGolangのGinフレームワークでRESTful APIを実装しており、主なモジュールは以下の通りです。&lt;/p&gt;
&lt;p&gt;データベースモジュール&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GORM を ORM フレームワークとして使用する&lt;/li&gt;
&lt;li&gt;環境変数を設定してデータベース接続を構成する。&lt;/li&gt;
&lt;li&gt;自動的にデータベーステーブルを移行する&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ルーティングモジュール&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RESTful API 設計&lt;/li&gt;
&lt;li&gt;統一されたエラー処理メカニズム&lt;/li&gt;
&lt;li&gt;内蔵リクエストログ&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;越域処理&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ローカル開発環境でのクロスドメインをサポートする。&lt;/li&gt;
&lt;li&gt;設定可能なCORSポリシー&lt;/li&gt;
&lt;li&gt;Cookie のクロスドメインをサポート&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;フロントエンドアーキテクチャ&#34;&gt;フロントエンドアーキテクチャ
&lt;/h2&gt;&lt;p&gt;フロントエンドはReact + TypeScriptで構築されており、以下の機能を実装しています：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;株式リスト表示&lt;/li&gt;
&lt;li&gt;自主選択株式管理&lt;/li&gt;
&lt;li&gt;市場データ表示&lt;/li&gt;
&lt;li&gt;エラー通知メカニズム&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>AI開発2年：ドッカーがリリースされる前の状態に少し似ている。</title>
        <link>https://ttf248.life/ja/p/ai-development-two-years-docker-pre-release/</link>
        <pubDate>Thu, 20 Feb 2025 18:16:37 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ai-development-two-years-docker-pre-release/</guid>
        <description>&lt;p&gt;人工知能（AI）は近年、間違いなく技術分野で最も議論されている話題の一つであり、特に過去2年間のAI技術の急速な進歩が目覚ましいです。深層学習、自然言語処理、コンピュータビジョン、自動化された意思決定システムなど、AIの応用範囲は絶え間なく広がっています。しかしながら、技術的なブレークスルーが続いているにもかかわらず、AIはDockerがリリースされる前のボトルネックに似た状況に直面しており、市場を真に爆発させるような画期的なアプリケーションが不足しています。&lt;/p&gt;
&lt;p&gt;AIの発展も2年ほど経ち、Dockerがリリースされる前の状態に似ている。画期的なアプリケーションはまだなく、既存技術を基盤として、完璧な実用化シナリオを生み出す必要がある。Dockerのように、特に新しい技術を使わなくても良いのだが、全体的な方案が非常に合理的で、運用や開発のワークフローを変えるようなものだ。&lt;/p&gt;
&lt;h2 id=&#34;人工知能の開発状況技術は既に成熟しているが応用はまだブレークスルーが必要だ&#34;&gt;人工知能の開発状況：技術は既に成熟しているが、応用はまだブレークスルーが必要だ。
&lt;/h2&gt;&lt;p&gt;技術的な側面から見ると、AIは過去2年間でかなりの進歩を遂げています。OpenAIが発表したGPTシリーズモデルも、GoogleのBERTやDeepMindのAlphaシリーズも、AIの処理能力は以前の予想を大きく上回っています。特に自然言語処理分野においては、GPT-4などのモデルは強力な生成能力に加え、理解と推論においても驚くべきパフォーマンスを示しています。&lt;/p&gt;
&lt;p&gt;しかしながら、技術が日進月歩を遂げているにもかかわらず、AIの実際の応用においては一定の課題に直面している。Dockerがリリースされる前の状況と似ており、AIの潜在能力は大きいものの、現状では広く普及し、産業を変革する真に画期的なアプリケーションはまだ登場していない。多くの人々がAIの将来性について語っているが、革命的な変化をもたらす直接的な応用事例を見つけることは難しい。多くのAIアプリケーションは依然として初期段階にとどまっており、大部分はさらなる統合と最適化が必要である。&lt;/p&gt;
&lt;h2 id=&#34;dockerとaiの類似性技術そのものが革新ではない解決策が重要だ&#34;&gt;DockerとAIの類似性：技術そのものが革新ではない、解決策が重要だ。
&lt;/h2&gt;&lt;p&gt;もしDockerのリリース前の歴史を振り返れば、当時の技術環境とAIの現状には多くの類似点があることが容易にわかるでしょう。Dockerがリリースされる前は、コンテナ技術が新しいものではありませんでした。初期のLXC（Linux Containers）や仮想化技術もすでにコンテナ化の基本的な能力を備えていました。しかし、Dockerは既存技術を巧みに統合・最適化し、よりシンプルで直感的かつ効率的なソリューションを提案しました。このソリューションは画期的な技術を導入したものではありませんが、運用や開発プロセスにおける多くの課題を解決し、ソフトウェアのデプロイ、拡張、管理プロセスを大幅に簡素化しました。&lt;/p&gt;
&lt;p&gt;同様に、AI分野も類似の状況に直面している。現在のAI技術は「目新しさ」から離れたとはいえ、真に大規模な応用を実現するには、Dockerのように既存技術を統合・最適化し、合理的な応用シナリオを構築することが不可欠だ。AIの画期的な応用とは、必ずしも新たな技術革新に依存するものではなく、むしろ既存技術を統合して、実際のビジネスにおける課題やニーズを解決することにあるかもしれない。&lt;/p&gt;
&lt;h2 id=&#34;aiのdocker瞬間を見つけるにはどうすればよいか&#34;&gt;AIの「Docker瞬間」を見つけるにはどうすればよいか？
&lt;/h2&gt;&lt;p&gt;AI技術が真に広く応用されるためには、いくつかの側面から取り組む必要があります。&lt;/p&gt;
&lt;p&gt;現実的なシーンの深掘り
現在、多くのAIの応用事例は依然として実験的な性質が強く、大規模な実用化には至っていません。例えば、AIカスタマーサービスやスマートレコメンデーションといった分野では幅広い応用があるものの、その機能にはまだ多くの制約があり、業界のボトルネックを突破できていません。真のブレークスルーは、従来の方法に悩まされてきた医療、製造業、物流といった業界から生まれるかもしれません。AIは、より効率的なデータ処理や予測分析を通じて、これらの複雑な状況下で企業の効率向上とコスト削減に貢献できるでしょう。&lt;/p&gt;
&lt;p&gt;製品化とユーザビリティ
Dockerのようにコンテナ化プロセスを簡略化することで運用効率を高めるように、AIプロダクトの使いやすさも同様に重要です。AIの普及は技術の普及であると同時に、製品化の普及でもあります。AIを日常業務フローに統合し、ユーザーが深い技術的理解なしにこれらのツールを簡単に使えるようにすることは、AIを実用化するための重要な一歩です。&lt;/p&gt;
&lt;p&gt;生態建設と標準化
いかなる新技術の広範な応用も、エコシステムの構築なしには成り立ちません。Dockerが急速に台頭できたのは、そのオープン性と互換性のおかげで、開発者が様々なクラウドプラットフォーム、ツール、サービスとの連携を容易に行えるようになったからです。同様に、AIの未来もエコシステムの構築にかかっています。AIの標準化、モデルの共有、データの公開、そして技術の統合性は、AIが広範な業界応用を形成できるかどうかを左右するでしょう。&lt;/p&gt;
&lt;h2 id=&#34;結論aiの未来は多くの可能性を秘めているがより完善した着地点が必要である&#34;&gt;結論：AIの未来は多くの可能性を秘めているが、より完善した着地点が必要である。
&lt;/h2&gt;&lt;p&gt;AI技術はここ2年間で目覚ましい進歩を遂げたものの、現状では「決定版のアプリケーション」とは言えない段階です。Dockerがリリースされる前のコンテナ化技術と同様に、AIも合理的な応用シナリオを持ち、既存技術とビジネスニーズを深く融合することで初めて、大規模な導入と普及を実現できます。技術革新は確かに重要ですが、プロセスを簡素化し効率を高めるソリューションの方が、技術の普及と発展をより促進します。&lt;/p&gt;
&lt;p&gt;未来、AIはDockerのように、画期的な技術革新ではなく、既存の技術を統合することで完璧なアプリケーションシーンを作り出し、最終的に私たちの仕事や生活のやり方を変えるかもしれません。&lt;/p&gt;</description>
        </item>
        <item>
        <title>ローカルにdeepseek-R1をデプロイ</title>
        <link>https://ttf248.life/ja/p/ollama-local-deployment-deepseek-r1/</link>
        <pubDate>Fri, 07 Feb 2025 22:41:02 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ollama-local-deployment-deepseek-r1/</guid>
        <description>&lt;p&gt;Ollamaは、ユーザーがローカルで大規模言語モデル（LLM）を実行およびデプロイできるようにすることを目的としたオープンソースのAIツールです。開発者がクラウドサービスに依存することなく、GPTのようなモデルをローカルマシン上で利用できる、便利で効率的な方法を提供することを目指しています。Ollamaは複数のモデルをサポートしており、パフォーマンスの最適化に重点を置いており、リソースが限られたデバイスでもこれらのモデルをスムーズに実行できるようにします。&lt;/p&gt;
&lt;p&gt;Ollama を使用すれば、ユーザーはテキストベースの AI アプリケーションを利用でき、データプライバシーを気にすることなく、また高額な API 利用料金を心配することなく、ローカルにデプロイされたモデルと対話することができます。コマンドラインインターフェース（CLI）を通じて様々なモデルを呼び出し、自然言語処理や質問応答などのタスクを実行できます。&lt;/p&gt;
&lt;p&gt;Ollamaは様々なモデルを試すのに適していますが、Windows版をテストしたところ、ハードウェアの性能を十分に発揮できないようです。原因はWindows版にあるのかもしれません。Linux版の方が良いかもしれません。32bパラメータのモデルをデプロイした場合、メモリやGPUの負荷が低いにも関わらず、応答速度が非常に遅いです。&lt;/p&gt;
&lt;h2 id=&#34;ハードウェア概要&#34;&gt;ハードウェア概要
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;オペレーティングシステム：win11&lt;/li&gt;
&lt;li&gt;CPU：i7-10700K&lt;/li&gt;
&lt;li&gt;メモリ：40GB&lt;/li&gt;
&lt;li&gt;グラフィックボード：RTX 3060 12GB&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;環境準備&#34;&gt;環境準備
&lt;/h2&gt;&lt;p&gt;新たにシステム環境変数を追加し、今後の利用を容易にします。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_MODELS=E:\ollama&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
この変数は、Ollamaモデルの保存パスを指定します。&lt;code&gt;E:\ollama&lt;/code&gt; はフォルダパスで、すべてのローカルモデルファイルがそのディレクトリに格納されていることを示しています。Ollamaは、このパスに基づいてダウンロードまたはデプロイした言語モデルをロードして使用します。モデルファイルを別の場所に保存したい場合は、このパスを変更するだけです。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_HOST=127.0.0.1:8000&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
この環境変数は、Ollama サービスのホストとポートを設定します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;127.0.0.1&lt;/code&gt; はローカルアドレス（localhost）であり、Ollama サービスはローカルからのリクエストのみをリッスンします。&lt;/li&gt;
&lt;li&gt;8000は指定されたポート番号で、Ollamaサービスが8000ポートでリクエストを待機し処理することを示します。必要に応じてポート番号を変更できますが、そのポートが他のアプリケーションによって使用されていないことを確認してください。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_ORIGINS=*&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
この環境変数は、Ollama サービスにアクセスできるリクエストのソースを制御します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;*&lt;/code&gt; は、Ollama サービスへのアクセスを任意のソース（すべてのドメインと IP アドレス）から許可することを意味します。これは通常、開発およびデバッグ環境で使用されます。本番環境では、セキュリティを高めるために、特定のドメインまたは IP からのみアクセスできるように、より厳格なソースの制御を指定することが一般的です。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;deepseek-r1モデルのデプロイ&#34;&gt;DeepSeek-R1モデルのデプロイ
&lt;/h2&gt;&lt;p&gt;Ollamaのインストールは簡単で、ここでは詳細を説明しません。&lt;/p&gt;
&lt;p&gt;インストール後の検証：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core&amp;gt;ollama -v
ollama version is 0.5.11
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;モデルのデプロイについては、公式ウェブサイトのモデルページを参照し、対応するパラメータを持つモデルを選択してください。例：&lt;code&gt;ollama run deepseek-r1:14b&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;14bパラメータは会話のコンテキストを効果的に記憶できますが、より小さいパラメータバージョンではそれができません。32bパラメータバージョンについては、ローカルでのデプロイが非常に遅く、さらなるテストは行っていません。&lt;/p&gt;
&lt;h2 id=&#34;参照資料&#34;&gt;参照資料
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ollama.com/library/deepseek-r1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.ollama.com/library/deepseek-r1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/x18990027/article/details/145368094&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/x18990027/article/details/145368094&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>ディープシーク、旧正節前の急成長、NVIDIA株の大幅下落：背景にある機関投資家の動きと大規模言語モデルの推論チェーン</title>
        <link>https://ttf248.life/ja/p/deepseek-chinese-new-year-nvidia-stock-drop-institutional-operations-large-language-model-chain/</link>
        <pubDate>Fri, 07 Feb 2025 20:36:05 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/deepseek-chinese-new-year-nvidia-stock-drop-institutional-operations-large-language-model-chain/</guid>
        <description>&lt;p&gt;旧正年の前夜、DeepSeekは一躍注目を集め、数日の間にソーシャルメディアで広く話題となった。この突如の爆発的な人気は驚くべきものであり、市場に連鎖反応を引き起こした。一方、NVIDIA株は暴落し、多くの投資家がその見通しを疑念視している。一部機関は、この期間中に大規模な空売りを行っており、まるで全てが「精心策划（じょうみけんさ）」された状況を示唆しているかのようだ。&lt;/p&gt;
&lt;h3 id=&#34;ディープシークの急上昇短時間で注目を集める&#34;&gt;ディープシークの急上昇：短時間で注目を集める
&lt;/h3&gt;&lt;p&gt;DeepSeekは、AIをベースとしたツールであり、特に自然言語処理（NLP）や画像生成分野での応用において、深層学習モデルの最適化に焦点を当てています。旧正月の数日前、このプロジェクトは突然、多くの投資家や技術者の注目を集めました。その背後にあるチームの実績と、提示された技術成果により、多くの人々がこのプロジェクトに強い関心を持つようになりました。開発者コミュニティにおいてもソーシャルメディアプラットフォームにおいても、DeepSeekに関する議論は、ほぼテクノロジー業界の話題を占めています。&lt;/p&gt;
&lt;p&gt;しかし、DeepSeekの突如たる爆発的な人気は偶然ではない。分析の結果、多くの人がこの背後に何らかの機関の操作が関与しているのではないかと疑い始めている。特にその人気に火がついた後、NVIDIA株価が著しい下落を見せていることから、明らかに何らかの要因がこの変化を促していることが見て取れる。&lt;/p&gt;
&lt;h3 id=&#34;エヌビディア株急落空売り操作の黒幕&#34;&gt;エヌビディア株急落：空売り操作の黒幕
&lt;/h3&gt;&lt;p&gt;NVIDIAは、世界をリードするグラフィックス処理ユニット（GPU）メーカーであり、長らく大規模モデルやAIコンピューティングの主要なハードウェアサプライヤーです。AI市場の急速な発展に伴い、NVIDIA株は長期的に好調でしたが、投資家の人気を集めていました。しかし、DeepSeekの人気急上昇と市場からのその技術への高い注目により、NVIDIA株は暴落しました。&lt;/p&gt;
&lt;p&gt;この現象の背景には、機関投資家の空売り戦略が関わっているかもしれません。ここ数年、AI技術の普及に伴い、NVIDIAの株価は大きく押し上げられ、多くの投資家が同社の株価に過大評価のリスクを感じていました。特にDeepSeekのような技術が爆発的に広まった後、一部の機関はNVIDIAの株式を空売りすることで、大きな利益を得た可能性があります。正確な市場機会の捉え方とDeepSeekの影響力に関する予測により、これらの機関は成功裏に利益を上げました。&lt;/p&gt;
&lt;h3 id=&#34;大規模言語モデルの思考チェーンの探求結果からプロセスへ&#34;&gt;大規模言語モデルの思考チェーンの探求：「結果」から「プロセス」へ
&lt;/h3&gt;&lt;p&gt;伝統的な人工知能の応用において、多くの専門家や投資家はAIモデルの「結果」——生成された画像やテキストといった直接的な成果物——に多くの中目を向けてきました。しかしながら、DeepSeekに関連する議論の中で、より多くの人々が、大規模言語モデル（LLM）の背後にある思考連鎖こそが、より注目すべき核心的内容であることに気づき始めています。これまで、私たちは単にモデルの出力結果しか見ることができませんでしたが、今や、その背後にある論理、アルゴリズム、そしてこれらの要素を調整してモデルのパフォーマンスを最適化する方法を理解することが求められています。&lt;/p&gt;
&lt;p&gt;この思考様式の転換は、AI研究と応用に対する深い考察と言えるでしょう。単純なブラックボックス操作から、モデル内部の動作メカニズムを真に理解することへの転換は、多くの技術者や投資家が人工知能の将来的な発展方向を改めて見直すきっかけとなりました。DeepSeek の人気は、まさにこの思考回路の画期的な応用であり、人々は最終的な出力結果だけでなく、モデル全体の構築と最適化プロセスに関心を向け始めています。&lt;/p&gt;
&lt;h3 id=&#34;まとめ&#34;&gt;まとめ
&lt;/h3&gt;&lt;p&gt;DeepSeekの突然の爆発的な人気、NVIDIA株式の大幅下落、そして市場背景にある機関投資家の空売り操作、これら全てには巧妙に仕組まれた陰謀があるように思われます。大規模言語モデルの思考チェーンに対する深い理解を通して見ると、AI技術の応用は単なる表面現象の積み重ねではなく、モデル内部の論理を深く掘り下げて最適化することです。技術が進歩するにつれて、今後DeepSeekのような革新的なツールがさらに多く登場し、AI研究と応用の発展をより高いレベルへと押し進めることが予想されます。&lt;/p&gt;
&lt;p&gt;この現象は、AI技術の莫大な可能性を私たちに見せてくれるだけでなく、その背景にあるビジネスの駆け引きや資本運用のことを考えさせるものとなりました。今後の市場動向が、技術と資本の対立をめぐる継続的な注目点となるでしょう。&lt;/p&gt;</description>
        </item>
        <item>
        <title>カーサーAI プログラミングIDE 体験</title>
        <link>https://ttf248.life/ja/p/cursor-ai-programming-ide-trial/</link>
        <pubDate>Thu, 23 Jan 2025 19:30:13 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/cursor-ai-programming-ide-trial/</guid>
        <description>&lt;p&gt;気がつけばまた一年が過ぎた。仕事における最大の変化は、やはりAIの関与が顕著に高まっていることだ。これまで、開発言語間の切り替えには、開発者が様々な言語の異なるAPIインターフェースを理解する必要があったが、今ではこれらの基礎コードもAIによって生成できるようになった。これは開発者にとって大きな福音と言えるだろう。&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;23年頃に簡単な入門紹介を2つほどやったことがあったのに、気がつけばもう25年も経っている。どう言えばいいのか分からないが、目に見えるような進歩は感じられない。自分の認知を確立し、タスクを合理的に分割できるようになる必要がある。もちろん、最も重要なのはAI生成コードにバグがないかどうかを見抜くことだ。&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;Github copilot
&lt;/h2&gt;&lt;p&gt;いつになったか覚えていないが、資料を見たところシンガポールにサーバーが設置され、国内で利用できるようになったらしい。これにより、もう長期間VPNを使わなくてもよくなった。もちろん、ログイン時にはまだVPNが必要だが、ログインが終われば閉じるだけで良い。&lt;/p&gt;
&lt;p&gt;普段使いとしては、やはり Github Copilot の方が多いです。このプラグインは、VS Code や Visual Studio で直接使えるので、2つのソフトウェア間を切り替える必要がありません。ChatGPT と比較すると、Github Copilot はプロジェクトのサポートがより良く、インタラクションも友好的です。さらに、ローカルファイルの一部を選択して AI に「訓練」させることができ、その結果生成されるコードはあなたのプロジェクトに合致しやすくなります。&lt;/p&gt;
&lt;h2 id=&#34;cursor-ai&#34;&gt;Cursor AI
&lt;/h2&gt;&lt;p&gt;最近新しいAIプログラミングIDE、Cursor AIを見ました。このIDEはGithub Copilotをベースにしていますが、さらにスマートで、ファイルを作成してくれます。&lt;/p&gt;
&lt;p&gt;軽く使ってみましたが、なかなか良い感じです。ただ、既存プロジェクトの理解はまだ足りません。ローカルプロジェクトファイルが多い場合や、大規模なリファクタリングや最適化調整を行う場合は、やはり&lt;strong&gt;開発者がタスクを分割する必要&lt;/strong&gt;があります。&lt;/p&gt;
&lt;p&gt;curso のプロジェクトモードに切り替えて、次のような内容を入力してください：新しい個人履歴ウェブページの作成、複数の異なるスタイルへの切り替えをサポートし、データ表示のためにいくつかの個人情報を入力してください。&lt;/p&gt;
&lt;p&gt;何度か試行錯誤すると、次のようなウェブページを入手できます。もちろん、このウェブページはまだシンプルなものですが、初心者にとっては良いでしょう。&lt;/p&gt;
&lt;p&gt;現在登録ユーザーは、高機能APIを150回無料で試用できます。有料ユーザーは、高機能APIの利用が5000回に制限されます。&lt;/p&gt;
&lt;p&gt;履歴書&lt;/p&gt;</description>
        </item>
        <item>
        <title>AIプログラミングとタスク分解</title>
        <link>https://ttf248.life/ja/p/ai-programming-and-task-decomposition/</link>
        <pubDate>Fri, 22 Dec 2023 08:44:26 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ai-programming-and-task-decomposition/</guid>
        <description>&lt;p&gt;2年前にサイトに追加したコード領域のコピー機能ですが、あれから半日ほど格闘した結果、最終的なレンダリングの効果は少し期待外れでした。半熟前開発者だったため、改善しようともせず、動けば良いと思っていました。今年は&lt;code&gt;AI&lt;/code&gt;で小程序を開発し、フロントエンドの開発にもより慣れたので、一新（AIによる再設計）。&lt;/p&gt;
&lt;p&gt;悟道：タスクを分解して、多くの小さなタスクに分けました。AIで開発するのはまだスムーズです。すでに閉鎖された小程序ですが、75%のコードはAIによって提供され、複数のタスクに分割して割り当て、人工でプロジェクトコードを組み立てています。&lt;/p&gt;
&lt;h2 id=&#34;前文&#34;&gt;前文
&lt;/h2&gt;&lt;p&gt;簡単なことだと思っていることを、コードコピーボタンを追加する。&lt;/p&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文
&lt;/h2&gt;&lt;p&gt;CSSとJavaScriptのコードを設計し、class=&amp;ldquo;highlight&amp;rdquo; のウェブ要素を見つけて、その要素のコンテナ内にコピーボタンを追加して、コードをコピーする機能を実現してください。&lt;/p&gt;
&lt;p&gt;最初のドラフトのコードを見ると問題があり、再生成したところ、ほぼ使えるようになったが、コピーされた内容に誤りがあり、重複するテキストも含まれている。再度最適化を促し、手動で主要なカラーデザインを指定し、どのようなエフェクトが含まれるかを指示した。&lt;/p&gt;
&lt;p&gt;ボタンのサイズと色に関して特定の要件があることを承知いたしました。これらの要件に合わせて、ボタンのスタイルを再設計できます。以下に、ご提供いただいたカラースキームを含め、ボタンのサイズを最適化した調整後のCSSスタイルを示します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.copy-btn {
  position: absolute;
  top: 2px; /* 调整位置 */
  right: 2px;
  padding: 3px 6px; /* 缩小尺寸 */
  font-size: 12px; /* 减小字体大小 */
  background-color: #8FD1E1; /* 按钮背景色 */
  color: #272822; /* 文字颜色 */
  border: 1px solid #272822; /* 边框颜色 */
  border-radius: 3px; /* 圆角 */
  cursor: pointer;
  opacity: 0.7; /* 默认半透明 */
  transition: opacity 0.3s ease, background-color 0.3s ease; /* 平滑过渡效果 */
}

.copy-btn:hover {
  opacity: 1; /* 鼠标悬停时不透明 */
  background-color: #A3D4E5; /* 鼠标悬停时的背景色 */
}

.highlight {
  position: relative;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;このスタイルでは、ボタンのサイズとフォントサイズを小さくし、より洗練された印象にしました。同時に、ボタンのデフォルト状態は半透明で、マウスがボタンの上にかかると不透明になり、背景色が少し明るくなることで視覚的なフィードバックを提供します。このようなデザインは、お客様の色に関する要件を満たしつつ、モダンさと使いやすさを維持しています。&lt;/p&gt;
&lt;p&gt;対応する簡単な &lt;code&gt;JavaScript&lt;/code&gt; を提供しました。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-JavaScript&#34;&gt;document.addEventListener(&#39;DOMContentLoaded&#39;, function() {
  // 查找所有 .highlight 元素
  const highlights = document.querySelectorAll(&#39;.highlight&#39;);

  highlights.forEach(function(highlight) {
    // 创建复制按钮
    const copyBtn = document.createElement(&#39;button&#39;);
    copyBtn.textContent = &#39;复制&#39;;
    copyBtn.classList.add(&#39;copy-btn&#39;);

    // 将按钮添加到每个 .highlight 元素中
    highlight.appendChild(copyBtn);

    // 添加点击事件监听器
    copyBtn.addEventListener(&#39;click&#39;, function() {
      // 假设 .highlight 下的第一个 &amp;lt;code&amp;gt; 元素包含要复制的代码
      const code = highlight.querySelector(&#39;code&#39;) ? highlight.querySelector(&#39;code&#39;).textContent : &#39;&#39;;

      navigator.clipboard.writeText(code).then(() =&amp;gt; {
        // 显示复制成功信息
        copyBtn.textContent = &#39;已复制!&#39;;
        setTimeout(() =&amp;gt; {
          copyBtn.textContent = &#39;复制&#39;;
        }, 2000);
      }).catch(err =&amp;gt; {
        console.error(&#39;复制失败: &#39;, err);
      });
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;あとがき&#34;&gt;あとがき
&lt;/h2&gt;&lt;p&gt;コピーボタンをコード領域の右上隅、または上部に新たに追加することを期待していたのですが、フロントエンドについて十分な知識がないため、キーワードに基づいて機能を正確に説明できず、AI と何度かやり取りしても、期待通りの結果が得られませんでした。&lt;/p&gt;
&lt;p&gt;時間が経つにつれて、AIがプログラミング開発にどれほどの影響を与えるか分かりません。&lt;/p&gt;</description>
        </item>
        <item>
        <title>プロンプトエンジニア</title>
        <link>https://ttf248.life/ja/p/prompt-engineer/</link>
        <pubDate>Sun, 26 Mar 2023 20:46:53 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/prompt-engineer/</guid>
        <description>&lt;p&gt;かつて検索エンジンのテクニックを学ぶように、私たちもAIとコミュニケーションをとるためのテクニックを学び、合理的で十分な制約を与え、必要な答えを効率的に得る必要があります。&lt;/p&gt;
&lt;p&gt;もし別の角度から考えると、現在のAIは記憶力の良い子供のようなもので、一度見たものはすべて覚える能力があり、宿題を写すような能力があります。私たちがやるべきことは、AIと正しく効果的にコミュニケーションを取り、ニーズを正確に記述し、AIが期待される結果を生み出すのを助けることです。&lt;/p&gt;
&lt;h2 id=&#34;科学普及&#34;&gt;科学普及
&lt;/h2&gt;&lt;p&gt;火が出天际の&lt;code&gt;AI&lt;/code&gt;、正確に言うと&lt;code&gt;Generative Pre-Training（生成事前学習）&lt;/code&gt;です。直訳すると生成的な事前訓練となります。これは、インターネットで利用可能なデータでトレーニングされたテキスト生成深層学習モデルであり、質問応答、テキスト要約生成、機械翻訳、分類、コード生成、対話AIなどのタスクに使用されます。現在ではGPT-1、GPT-2、GPT-3、GPT-4など、さまざまなバージョンのモデルが存在し、各バージョンは前のバージョンよりも大きく、強力です。&lt;/p&gt;
&lt;h2 id=&#34;結局知能は存在するのか&#34;&gt;結局、知能は存在するのか。
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;類似度が十分高いほど、精度も上がる。&lt;/li&gt;
&lt;li&gt;基本的な、反復的な作業は、特定の訓練を経れば、もはや手作業の介在は不要となる。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;生成AIとは、既存のテキスト、音声、画像などのデータを利用して新しいコンテンツを作成する技術です。テキスト生成、音声合成、画像生成、対話システムなど、さまざまなタスクに使用できます。生成AIの論理性は、トレーニングデータとモデル構造に依存します。一般的に、生成AIは文法、論理、常識をある程度遵守できますが、誤り、偏見、または虚偽の内容を生み出す可能性もあります。したがって、生成AIの出力には人間の判断と検証が必要であり、盲目的に信じたり使用したりすることはできません。&lt;/p&gt;
&lt;h2 id=&#34;プロンプトエンジニア&#34;&gt;プロンプトエンジニア
&lt;/h2&gt;&lt;p&gt;時の流れは二度と戻らない、人は時代の流れに適応する必要がある。あなたはAIが賢くないとか、論理的ではないとか考えるかもしれない。それは、しばしば役に立たないコードを生成するからだ。&lt;/p&gt;
&lt;p&gt;もし別の角度から考えると、現在のAIは記憶力の良い子供のようなもので、一度見たものはすべて覚える能力があり、宿題を写すような能力があります。私たちがやるべきことは、AIと正しく効果的にコミュニケーションを取り、ニーズを正確に説明し、AIが期待される結果を生み出すのを助けることです。&lt;/p&gt;
&lt;h2 id=&#34;対話モード&#34;&gt;対話モード
&lt;/h2&gt;&lt;p&gt;2 年前 Github Copilot が発表されたとき、誰しも 2 年後に OpenAI が突如として現れ、人間が大規模言語モデルの能力に気づくとは思いもしなかった。&lt;/p&gt;
&lt;p&gt;アノテーションベースのプログラミングと対話型プログラミングに基づく場合、インタラクションロジックは完全に異なり、対話形式は初心者ユーザーにとってフレンドリーな体験を提供します。この点において、NewBingが各質問の後で提示する追質問の提案は言及せざるを得ません。これは、Microsoftがユーザーを誘導し、AIナレッジベースからより多くの情報を取得しようとする試みです。&lt;/p&gt;
&lt;h2 id=&#34;例えば&#34;&gt;例えば
&lt;/h2&gt;&lt;p&gt;長時間の新幹線の移動中、コーディングは良い選択肢だ。データ通信量が限られているので、画像を数枚処理し、画像素材を入手した。ソフトウェアをダウンロードして画像を処理するのは少し贅沢すぎるし、ネットワーク環境もそれを許さない。&lt;/p&gt;
&lt;p&gt;要件：一連の画像素材があり、それらは透明な背景を持つものとします。これらの画像をミニプログラムのナビゲーションバーに使用し、選択された状態はカラー表示、未選択の状態は白黒表示にしたいと考えています。素材自体はすべてカラーなので、事前に処理する必要があります。&lt;/p&gt;
&lt;p&gt;フォルダ内のすべての画像を読み込み、画像を白黒に変換し、透明な背景を維持し、画像の品質を最適化してファイルサイズを縮小しながら画像を保存するPythonコードを作成してください。コンソールには、最適化前のファイルサイズと最適化後のファイルサイズの比較を表示します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 导入必要的库
import os
import PIL
from PIL import Image

# 定义一个函数，将图片转换成黑白，维持透明背景，保存图片，并返回文件体积
def convert_and_save(image_file):
    # 打开图片
    image = Image.open(image_file)
    # 获取图片的模式，如果是 RGBA 模式，说明有透明背景
    mode = image.mode
    if mode == &amp;quot;RGBA&amp;quot;:
        # 创建一个和图片大小一致的白色背景图片
        background = Image.new(&amp;quot;RGB&amp;quot;, image.size, (255, 255, 255))
        # 将原图片粘贴到白色背景上，忽略透明像素
        background.paste(image, mask=image.split()[3])
        # 将合成的图片转换成灰度模式
        gray_image = background.convert(&amp;quot;L&amp;quot;)
        # 将灰度图片再转换成 RGBA 模式，以便保留透明背景
        final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
    else:
        # 如果不是 RGBA 模式，直接将图片转换成灰度模式
        final_image = image.convert(&amp;quot;L&amp;quot;)
    # 获取原图片的文件名和扩展名
    file_name, file_ext = os.path.splitext(image_file)
    # 定义新图片的文件名，添加 _bw 后缀表示黑白
    new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # 保存新图片，并优化质量，减少文件体积
    final_image.save(new_file_name, optimize=True)
    # 获取原图片和新图片的文件体积，并返回
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return old_size, new_size

# 定义一个文件夹路径，存放所有的图片
folder_path = &amp;quot;images&amp;quot;
# 遍历文件夹中的所有文件
for file in os.listdir(folder_path):
    # 拼接完整的文件路径
    file_path = os.path.join(folder_path, file)
    # 判断是否是图片文件，根据扩展名判断，可以根据需要添加或修改扩展名
    if file_path.endswith((&amp;quot;.png&amp;quot;, &amp;quot;.jpg&amp;quot;, &amp;quot;.jpeg&amp;quot;, &amp;quot;.gif&amp;quot;)):
        # 调用函数，转换并保存图片，并获取文件体积
        old_size, new_size = convert_and_save(file_path)
        # 在控制台展示优化前后的文件体积大小对比
        print(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;AIはすぐに答えを出力し、見た目も良く問題なく動作するものの、経験豊富なプログラマーなら、下記のコードが十分に汎用的ではなく、本番環境にデプロイするには向いていないと感じるだろう。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;パラメータが固定されました。&lt;/li&gt;
&lt;li&gt;ログファイルはなく、情報はすべてコンソールに出力されています。&lt;/li&gt;
&lt;li&gt;画像の処理タスクは、マルチスレッドモデルに適しています。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ニュービングが登場し、プロンプトに従って質問を選びました。&lt;strong&gt;このコードには改善できる点はありますか？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;今回いただいた回答は、正直言って、完全に予想を上回っています。一般的なプログラマーが思いつくような最適化策に対して、AI が対応する提案を出してくるほどです。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;这段代码可能还有一些可以改进的地方，比如：

可以使用 argparse 库，让用户可以通过命令行参数指定文件夹路径和扩展名，而不是写死在代码里。
可以使用 logging 库，记录程序的运行情况，而不是直接打印到控制台。
可以使用 try-except 语句，捕获可能出现的异常，比如文件打开失败，图片转换失败等，并做相应的处理。
可以使用 multiprocessing 库，利用多核处理器，加速图片的转换和保存过程。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;非常にフレンドリーな対応で、デプロイ環境の違いを考慮し、マルチプロセスをサポートしていないことを許可します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;当然，我很乐意帮你修改一下代码。我尝试添加了 argparse, logging 和 try-except 语句，但没有添加 multiprocessing 库，因为我不确定你的电脑是否支持多核处理。修改后的代码如下：
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 导入必要的库
import argparse
import logging
import multiprocessing
import os

from PIL import Image


# 定义一个函数，将图片转换成黑白，维持透明背景，保存图片，并返回文件体积
def convert_and_save(image_file):
    # 打开图片
    try:
        image = Image.open(image_file)
    except Exception as e:
        logging.error(f&amp;quot;Failed to open {image_file}: {e}&amp;quot;)
        return None, None
    # 获取图片的模式，如果是 RGBA 模式，说明有透明背景
    mode = image.mode
    if mode == &amp;quot;RGBA&amp;quot;:
        # 创建一个和图片大小一致的白色背景图片
        background = Image.new(&amp;quot;RGB&amp;quot;, image.size, (255, 255, 255))
        # 将原图片粘贴到白色背景上，忽略透明像素
        background.paste(image, mask=image.split()[3])
        # 将合成的图片转换成灰度模式
        gray_image = background.convert(&amp;quot;L&amp;quot;)
        # 将灰度图片再转换成 RGBA 模式，以便保留透明背景
        final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
    else:
        # 如果不是 RGBA 模式，直接将图片转换成灰度模式
        final_image = image.convert(&amp;quot;L&amp;quot;)
    # 获取原图片的文件名和扩展名
    file_name, file_ext = os.path.splitext(image_file)
    # 定义新图片的文件名，添加 _bw 后缀表示黑白
    new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # 保存新图片，并优化质量，减少文件体积
    try:
        final_image.save(new_file_name, optimize=True)
    except Exception as e:
        logging.error(f&amp;quot;Failed to save {new_file_name}: {e}&amp;quot;)
        return None, None
    # 获取原图片和新图片的文件体积，并返回
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return file_name, old_size, new_size

# 定义一个函数，解析命令行参数，并返回文件夹路径和扩展名列表
def parse_args():
    # 创建一个解析器对象
    parser = argparse.ArgumentParser(description=&amp;quot;Convert images to black and white and optimize quality.&amp;quot;)
    # 添加一个必选的位置参数，表示文件夹路径
    parser.add_argument(&amp;quot;folder_path&amp;quot;, help=&amp;quot;The path of the folder that contains the images.&amp;quot;)
    # 添加一个可选的参数，表示扩展名列表，默认为 png, jpg, jpeg 和 gif
    parser.add_argument(&amp;quot;-e&amp;quot;, &amp;quot;--extensions&amp;quot;, nargs=&amp;quot;+&amp;quot;, default=[&amp;quot;.png&amp;quot;, &amp;quot;.jpg&amp;quot;, &amp;quot;.jpeg&amp;quot;, &amp;quot;.gif&amp;quot;], help=&amp;quot;The extensions of the image files.&amp;quot;)
    # 解析命令行参数，并返回结果对象
    args = parser.parse_args()
    return args.folder_path, args.extensions

# 定义一个函数，打印优化前后的文件体积大小对比
def print_result(result):
    # 如果结果不为空，说明转换和保存成功
    if result:
        # 解包结果为文件名和文件体积元组
        if len(result) == 3:
            file, old_size, new_size = result
            # 在控制台展示优化前后的文件体积大小对比
            logging.info(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)
        else:
            logging.info(f&amp;quot;{result}&amp;quot;)

# 配置日志记录器，将日志输出到控制台和文件中，设置日志等级为 INFO
logging.basicConfig(level=logging.INFO,
                    format=&amp;quot;%(asctime)s %(levelname)s %(message)s&amp;quot;,
                    handlers=[logging.StreamHandler(),
                              logging.FileHandler(&amp;quot;log.txt&amp;quot;)])

# 调用函数，获取文件夹路径和扩展名列表
folder_path, extensions = parse_args()

if __name__ == &amp;quot;__main__&amp;quot;:
    # Windows 需要这个函数的原因是 Windows 缺乏 fork() 函数（这不完全正确）。
    # 因此，在 Windows 上，fork() 是通过创建一个新的进程来模拟的，这个新的进程中运行的代码，在 Linux 上是在子进程中运行的。
    # 由于这些代码要在技术上无关的进程中运行，所以它必须在运行之前被传递到那里。
    # 传递的方式是先将它们序列化，然后通过管道从原始进程发送到新的进程。
    # 另外，这个新的进程被通知它必须运行通过管道传递的代码，通过向它传递 --multiprocessing-fork 命令行参数。
    # 如果你看一下 freeze_support() 函数的实现，它的任务是检查它运行在哪个进程中，是否应该运行通过管道传递的代码
    multiprocessing.freeze_support()

    # 创建一个进程池，根据电脑的核心数自动分配进程
    pool = multiprocessing.Pool()
    # 创建一个空列表，用于存放异步任务的结果对象
    results = []
    # 遍历文件夹中的所有文件
    for file in os.listdir(folder_path):
        # 拼接完整的文件路径
        file_path = os.path.join(folder_path, file)
        # 判断是否是图片文件，根据扩展名判断，可以根据需要修改扩展名列表
        if any(file_path.endswith(ext) for ext in extensions):
            # 调用函数，转换并保存图片，并获取文件体积，使用异步方式，不阻塞主进程
            result = pool.apply_async(convert_and_save, args=(file_path,), callback=print_result)
            # 将结果对象添加到列表中
            results.append((file, result))
    # 关闭进程池，不再接受新的任务
    pool.close()
    # 等待所有的任务完成
    pool.join()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;あとがき&#34;&gt;あとがき
&lt;/h2&gt;&lt;p&gt;ローカル開発環境が&lt;code&gt;Windows&lt;/code&gt;システムであるため、&lt;code&gt;AI&lt;/code&gt;が最初に提示した回答には&lt;code&gt;main&lt;/code&gt;関数も&lt;code&gt;multiprocessing.freeze_support&lt;/code&gt;も含まれていませんでした。質問への対応でエラーが発生し、それによってコードを修正しました。&lt;/p&gt;
&lt;p&gt;かつて検索エンジンのテクニックを学ぶように、私たちもAIとコミュニケーションをとるためのテクニックを学び、合理的で十分な制約を与え、必要な答えを効率的に得る必要があります。&lt;/p&gt;
&lt;p&gt;注意：プログラミング初心者の方で、与えられたコメントに基づいて理解できない部分があれば、関連コードについてさらに質問してください。&lt;/p&gt;</description>
        </item>
        <item>
        <title>AI支援によるプログラミング、生産性の進化</title>
        <link>https://ttf248.life/ja/p/ai-assisted-programming-productivity-evolution/</link>
        <pubDate>Tue, 28 Feb 2023 17:05:17 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ai-assisted-programming-productivity-evolution/</guid>
        <description>&lt;p&gt;GitHub Copilotのリリースから2年も経っていないうちに、ChatGPTが登場しました。その裏側の仕組みはよく分かりませんが、しばらく使っています。この二つのツールは補助的な面で全く異なりながらも、いずれも生産性を大きく向上させています。&lt;/p&gt;
&lt;p&gt;あまりに複雑なことは、AIではまだできません。結局のところ、彼らには論理がないからです。パターンが決まっていることや、固定されたパラダイムのようなことに対しては、学習データが十分であれば、AIの効果は9割程度期待できます。&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;github copilot
&lt;/h2&gt;&lt;p&gt;公開されたとき、公式サイトのデモを見て、あまり賢そうではないし、試してみたけれど使い勝手が悪く、諦めた。&lt;/p&gt;
&lt;p&gt;2022年以前、暇な時に新しいバージョンを試してみたら、すでに効果はかなり良いです。ただ、国内の速度が少し遅いので、おそらくネットワークの問題でしょう。&lt;code&gt;Python&lt;/code&gt;のような言語で、コメントを参照して書かれたコードはなかなか良く、自分で資料を探して書くよりもずっと速いです。&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;GitHub Copilotはまだ、プログラマー、つまり開発の視点から製品を設計している段階で、プログラミングの方法を知り、徐々にコメントを通じてAIによる補助的なプログラミングを促す必要があります。&lt;/p&gt;
&lt;p&gt;ChatGPT が次のレベルに進化し、&lt;strong&gt;素人でもすぐに使いこなせる&lt;/strong&gt;ようになりました。 会話形式のインタラクティブなデザインなので、どんな質問や要望でも気軽に投げかけられ、わからないことがあれば、遠慮なく追加で質問できます。&lt;/p&gt;
&lt;p&gt;単純な例として、トークン化の概念は知っているけれど、どのようにコーディングすればいいのかわからない。文字列の類似度を計算したいと考えている場合：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Python 分词计算 維天運通 LOGORY 和 合肥維天運通信息科技股份有限公司 两个字符串的相似度；
比较前，统一处理字符串，英文转换为小写；
第二个字符中如果能找到第一个字符的首字符，将第二个字符串截位，截位的长度为第一个字符串的长度
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;こんにちは、これはBingです。😊&lt;/p&gt;
&lt;p&gt;オンラインの情報によると123、Pythonの形態素解析には、jiebaライブラリを使用できます。jiebaライブラリは、厳密モード、フルモード、そして検索エンジンモードという3つの形態素解析モードをサポートしています。ニーズに合わせて適切なモードを選択してください。&lt;/p&gt;
&lt;p&gt;文字列の類似度を比較するためには、まず文字列をトークン化し、次に単語ベクトルや編集距離などの指標を計算する必要があります。numpy や scipy などのライブラリを使用して数学演算を行うことができます。&lt;/p&gt;
&lt;p&gt;文字列を統一的に処理するために、英字を小文字に変換するには、Python の組み込み関数lower()を使用できます。&lt;/p&gt;
&lt;p&gt;2番目の文字列を切り出すには、Pythonのスライス演算子[]を使用できます。&lt;/p&gt;
&lt;p&gt;以下はサンプルコードです。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import jieba
import numpy as np
from scipy.spatial.distance import cosine

# 定义两个字符串
str1 = &amp;quot;維天運通 LOGORY&amp;quot;
str2 = &amp;quot;合肥維天運通信息科技股份有限公司&amp;quot;

# 统一处理字符串，英文转换为小写
str1 = str1.lower()
str2 = str2.lower()

# 找到第二个字符串中第一个字符的位置
index = str2.find(str1[0])

# 如果找到了，截取第二个字符串
if index != -1:
    str2 = str2[index:index+len(str1)]

# 使用 jieba 库进行分词
words1 = list(jieba.cut(str1))
words2 = list(jieba.cut(str2))

# 计算两个字符串的词向量（以词频作为权重）
vector1 = np.zeros(len(words1))
vector2 = np.zeros(len(words1))

for i, word in enumerate(words1):
    vector1[i] += 1 # 统计第一个字符串中每个词出现的次数
    if word in words2:
        vector2[i] += 1 # 统计第二个字符串中每个词出现的次数

# 计算两个字符串的相似度（以余弦距离作为指标）
similarity = 1 - cosine(vector1, vector2)

print(&amp;quot;两个字符串的相似度是：&amp;quot;, similarity)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;さらに進めて、実行結果について問い合わせたところ、問題が見つかりました。結果はでっち上げられており、実際にはコードが実行されていないようですが、なかなか良い結果を返してきます。&lt;/p&gt;
&lt;h3 id=&#34;くり&#34;&gt;くり
&lt;/h3&gt;&lt;p&gt;質問：SQL文で、製品コード表から、製品コードが80000～89999の範囲にあるレコードを抽出するにはどうすればよいでしょうか。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;你好，这是 Bing。😊

根据搜索结果12，你可以使用 SQL BETWEEN 运算符来选择给定区间内的值。BETWEEN 运算符包含了开始和结束的值。

你需要先指定要查询的表名和列名，然后在 WHERE 子句中使用 BETWEEN 运算符和区间值。

例如，如果你要查询产品代码表中，产品代码在 80000 到 89999 之间的记录，你可以使用以下语句：

SELECT * FROM product_code
WHERE code BETWEEN 80000 AND 89999;
这里，* 表示选择所有列3。如果你只想选择特定的列，比如产品名称和价格，你可以用逗号分隔它们，如下：

SELECT name, price FROM product_code
WHERE code BETWEEN 80000 AND 89999;
希望这能帮助到你。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;引き続き質問し、否定してください。製品コードは文字列です。あなたのコードが間違っています。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;抱歉，我没有注意到产品代码是字符串。如果是这样的话，你需要在区间值两边加上单引号，如下：

SELECT * FROM product_code
WHERE code BETWEEN &#39;80000&#39; AND &#39;89999&#39;;
请原谅我的错误。🙏
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;おめでとうございます、間違えるでしょう。&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

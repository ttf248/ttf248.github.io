<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Ai on 向叔の手帳</title>
        <link>https://ttf248.life/ja/tags/ai/</link>
        <description>Recent content in Ai on 向叔の手帳</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>ja</language>
        <lastBuildDate>Mon, 02 Jun 2025 21:59:58 +0800</lastBuildDate><atom:link href="https://ttf248.life/ja/tags/ai/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>ブログ翻訳プロジェクトの雑感：文化伝達、AIプログラミング</title>
        <link>https://ttf248.life/ja/p/blog-translation-project-musings-cultural-transmission-ai-programming/</link>
        <pubDate>Mon, 02 Jun 2025 21:41:00 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/blog-translation-project-musings-cultural-transmission-ai-programming/</guid>
        <description>&lt;p&gt;文化伝播：意識形態的な影響、潜移漫歩。
AIプログラミング：ソフトウェア設計を行わないため、手戻りが多くなる。&lt;/p&gt;
&lt;h2 id=&#34;文化翻訳&#34;&gt;文化翻訳
&lt;/h2&gt;&lt;p&gt;当初のプロジェクトでは、英語、日本語、韓国語という3つの言語のみをサポートしていました。その後、「結局AI翻訳だから、色々な言語に対応した方が良いのではないか」と考え、フランス語、ロシア語、ヒンディー語を追加しました。その頃は問題に気づかず、プログラムが翻訳を実行する際に、過去のコードの問題により翻訳形式が正しくなく、保存された文章を再翻訳する必要がありました。&lt;/p&gt;
&lt;p&gt;統計的な時間経過の警告が表示され、すべての翻訳が完了するまでに約20時間がかかりました。これは、ローカルでデプロイされている大規模なモデルであるためです。不要な言語をいくつか削除し、翻訳時間を短縮することを考えました。フランス語、ロシア語、ヒンディー語を削除しました。その時、何かがおかしいことに気づきました。なぜ当初選択した言語（日本語、韓国語）が、私の選択になっているのでしょうか？&lt;/p&gt;
&lt;p&gt;世界人口の分布に基づいて見ると、これらの言語のユーザー層はそれほど多くありません。特に韓国語は、世界の利用人数は約8000万人に過ぎません。日本語はわずかに多い約1億2000万人です。一方、フランス語、ロシア語、ヒンディー語の利用人数はすべて1億人以上でした。&lt;/p&gt;
&lt;p&gt;その時、言語のユーザー層が、言語の使用人数によるものではなく、文化翻訳の影響によるものであることに気づきました。韓国と日本の文化は世界的に広範な影響力を持っており、特にアジア地域で顕著です。K-pop、アニメ、映画などの文化製品は大量のファンを引き付け、これらのファンは自然と関連する言語にも興味を持つようになりました。&lt;/p&gt;
&lt;p&gt;プロジェクトの成長を振り返ると、幼い頃によく日本のアニメや漫画を見ていましたし、大人になった今では多くの韓国映画やドラマを見ました。そのため、プロジェクトの設定時の初期言語を選択する際に、無意識のうちにこれらの馴染みのある言語を選択してしまいました。&lt;/p&gt;
&lt;h3 id=&#34;ソフトウェア設計とaiプログラミング&#34;&gt;ソフトウェア設計とAIプログラミング
&lt;/h3&gt;&lt;p&gt;翻訳助手は当初、単なるシンプルなツールに過ぎなかったが、Claude4のコーディング能力を体験してから徐々に機能が拡張され、文章翻訳、タグ翻訳などのモジュールが追加された。機能が増加するにつれて、コードの複雑さもそれに伴って上昇した。AIがコードをリファクタリングしてディレクトリ構造をより明確にしたことは確かだが、新機能の拡張やバグ修正時には、AI生成されたコードには繰り返し問題が発生することがある。&lt;/p&gt;
&lt;p&gt;AIはコード生成において、全体的な構造と設計理念に対する理解に欠けている。既存のコードに基づいて修正や拡張を行うことが多く、既存モジュールの有効な再利用をできていないため、コード冗長性が生じることがある。毎回、重複コードを手動で削除する必要があり、これは無意識のうちに開発コストを増加させている。&lt;/p&gt;
&lt;p&gt;さらに、AI生成されたコードは文法的に正しくても、論理と設計において問題がある場合がある。例えば、別のプロジェクトでプロンプトをわずかに調整しただけで、生成されるウェブページの構造が完全に異なり、一貫性がない。これは初期段階における合理的な設計の欠如、機能の追加が随意な積み重ねによるものであり、コード構造が混乱していることを反映している。&lt;/p&gt;
&lt;p&gt;これはまた、ソフトウェアエンジニアリングの核心的な経験は依然として無視できないことを私たちに思い出させる。適切な設計は返工を減らすだけでなく、コードの保守性と拡張性を向上させることができる。AIは強力なツールであるものの、システム設計に対する人間の深い理解と計画を代替することはできない。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>ブログ翻訳プロジェクトの雑感：歴史対話</title>
        <link>https://ttf248.life/ja/p/blog-translation-project-musings-historical-conversations/</link>
        <pubDate>Mon, 02 Jun 2025 21:16:24 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/blog-translation-project-musings-historical-conversations/</guid>
        <description>&lt;p&gt;ブログ翻訳プロジェクトは当初、複雑に設計されていた——まずMarkdown形式を解析し、プレースホルダーでコンテンツを保護し、最後に大規模言語モデルに送信する仕組みだった。これは完全に無駄であり、大規模言語モデル自体がMarkdownの文法を認識する能力を備えており、元のコンテンツを直接処理し、翻訳時にフォーマットを維持することができたからだ。&lt;/p&gt;
&lt;p&gt;私たちの仕事は、コードのデバッグから、大規模言語モデルの&lt;strong&gt;プロンプト&lt;/strong&gt;のデバッグへと変わった。
モデル：&lt;code&gt;google/gemma-3-4b&lt;/code&gt;
ハードウェア：&lt;code&gt;Nvidia 3060 12GB&lt;/code&gt;
そう、思考しないモデルを選んだ。思考するモデルは翻訳タスクを実行する際に効率が低く、4Bパラメータと12Bパラメータの効果を比較したところ、翻訳タスクにおいてはgemma3の4Bパラメータで十分だった。12Bパラメータは翻訳タスクにおいて明確な利点を持っていなかった。
12Bパラメータの速度：&lt;strong&gt;11.32 tok/sec&lt;/strong&gt;、4Bパラメータの速度：&lt;strong&gt;75.21 tok/sec&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;背景説明&#34;&gt;背景説明
&lt;/h2&gt;&lt;p&gt;システムに様々な条件制限を加えても、出力される翻訳結果には依然として問題が発生することがありました。具体的には、フォーマットの保護が不十分であったり、過剰な説明文が含まれていたりしました。役割定義時には、Markdown形式を保護し、翻訳結果のみを出力することを明示していたにも関わらず、最終的な翻訳は不安定でした。&lt;/p&gt;
&lt;p&gt;その時、以前漫画翻訳プロジェクトで大言語モデルを活用した経験が思い出されました。その時の翻訳精度は、私のものより良かったようです。コードやリクエストデータを確認したところ、漫画翻訳プロジェクトでは、毎回リクエストにコンテキスト（文脈）を付与していました。現在の翻訳内容に加え、過去の翻訳内容もまとめて送信していたのです。&lt;/p&gt;
&lt;p&gt;このメリットは何でしょうか？前後の翻訳の一貫性を高めるだけでなく、出力フォーマットの安定性を確保することにもつながったと考えられます。&lt;/p&gt;
&lt;h2 id=&#34;履歴対話の重要性&#34;&gt;履歴対話の重要性
&lt;/h2&gt;&lt;p&gt;AI 大規模モデル（GPT シリーズ、Claude、Gemini など）の普及に伴い、ますます多くの企業や開発者が API を通じてこれらのモデルにアクセスし、インテリジェントな顧客サポート、コンテンツ生成、コードアシスタントなどのアプリケーションを構築しています。しかし、多くの方は API への初期導入時に共通の問題に直面します：&lt;strong&gt;モデル出力が不整合で文脈理解が欠如しており、場合によっては質問の意図を誤解してしまう&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;この現象を引き起こす主要な原因の一つは——&lt;strong&gt;API リクエスト中に履歴対話の内容を含めないこと&lt;/strong&gt;です。&lt;/p&gt;
&lt;h2 id=&#34;履歴対話とは&#34;&gt;履歴対話とは？
&lt;/h2&gt;&lt;p&gt;履歴対話とは、一度の会話セッションにおいて、モデルとユーザー間の過去のやり取りの記録を指します。OpenAI の Chat Completions API（など、多くの大規模言語モデル API）では、開発者がリクエスト内で完全な &lt;code&gt;messages&lt;/code&gt; 配列を作成し、過去の会話をユーザーとアシスタントのメッセージが交互に並んだ形式で渡す必要があります。&lt;/p&gt;
&lt;h3 id=&#34;例文&#34;&gt;例文
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;model&amp;quot;: &amp;quot;gpt-4&amp;quot;,
  &amp;quot;messages&amp;quot;: [
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;退職の手紙を書いてください&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;assistant&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;かしこまりました。退職理由は何を書くようにしますか？&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;個人的なキャリアの追求をしたいと考えていると述べる&amp;quot;}
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;もし最後の文だけを送った場合：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;個人的なキャリアの追求をしたいと考えていると述べる&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;モデルは退職の手紙だと全く認識できず、文脈が理解されないため、出力品質は著しく低下します。&lt;/p&gt;
&lt;h2 id=&#34;歴史対話がなぜ重要なのか&#34;&gt;歴史対話がなぜ重要なのか？
&lt;/h2&gt;&lt;h3 id=&#34;1-文脈の構築と一貫性の向上&#34;&gt;1. &lt;strong&gt;文脈の構築と一貫性の向上&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;AIモデルは本質的に「コンテキスト駆動型」であり、過去の出来事を記憶することはできません。除非你&lt;strong&gt;明示的に伝える&lt;/strong&gt;のです。対話履歴を渡すことで、モデルはあなたの意図や話題の背景をより良く理解し、期待される出力を生成できます。&lt;/p&gt;
&lt;h3 id=&#34;2-誤解の低減&#34;&gt;2. &lt;strong&gt;誤解の低減&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;もしあなたがモデルに複数のステップで指示を実行させたい場合（例：文章作成、要約、コードデバッグ）、過去の履歴はモデルが徐々に理解を深め、途中で「逸脱」したり、重要な点を失ったりするのを防ぐのに役立ちます。&lt;/p&gt;
&lt;h3 id=&#34;3-実際の人間のような対話行動のシミュレーション&#34;&gt;3. &lt;strong&gt;実際の人間のような対話行動のシミュレーション&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;実用例として、カスタマーサポートシステム、教育アシスタント、健康相談などにおいて、ユーザーの質問は通常、段階的に展開され、一度に明確な表現で表明されることはありません。会話履歴を保持することで、AIが「記憶力のあるアシスタント」のように振る舞うことができます。&lt;/p&gt;
&lt;h2 id=&#34;api-中における会話履歴の正しい追加方法&#34;&gt;API 中における会話履歴の正しい追加方法
&lt;/h2&gt;&lt;p&gt;OpenAI の API を例に、以下の構造に従うことを推奨します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;messages = [
    {&amp;quot;role&amp;quot;: &amp;quot;system&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;あなたは専門的な法律アシスタントです&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;契約書の有効条件とは何ですか？&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;assistant&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;契約書が有効であるためには、以下の条件を満たす必要があります：……&amp;quot;},
    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;口頭での合意は有効ですか？&amp;quot;}
]

response = openai.ChatCompletion.create(
    model=&amp;quot;gpt-4&amp;quot;,
    messages=messages
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注意点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;system&lt;/code&gt; メッセージを使用してモデルの動作とアイデンティティを設定します。&lt;/li&gt;
&lt;li&gt;最新の数回の重要な会話のみを保持し、毎回すべての履歴を送信する必要はありません（トークン制限を超えないように）。&lt;/li&gt;
&lt;li&gt;長いセッションでは、早期のコンテンツを切り捨てて、コア情報を要約し、トークンの消費を制御します。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;実践的推奨事項&#34;&gt;実践的推奨事項
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;対話状態管理&lt;/strong&gt;: バックエンドは、各ユーザーのセッション履歴（例: Redis、データベース）を記録するためのキャッシュメカニズムを設計する必要があります。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;長さ制限&lt;/strong&gt;: OpenAI GPT-4 のコンテキスト長は 128k tokens であり、Claude 3 は 200k～1M पर्यंत可能です。適切なトリミングが必要です。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;動的履歴の要約&lt;/strong&gt;: 履歴が長すぎる場合は、モデルを使用して古い会話を要約し、その結果を対話コンテキストに追加します。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;まとめ&#34;&gt;まとめ
&lt;/h2&gt;&lt;p&gt;AI 大規模モデルの能力は強力ですが、開発者に十分なコンテキスト情報を「与える」必要があります。API リクエストに過去の会話を追加することで、モデル出力の品質と一貫性を大幅に向上させるだけでなく、ユーザーエクスペリエンスをより自然で現実的な対話に近づけることができます。AI 顧客サービス、ライティングアシスタント、プログラミングアシスタント、教育アプリケーションなど、どのような分野でも無視できない最適化テクニックです。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>慢性疾患、華やかなりし世相に眼移り</title>
        <link>https://ttf248.life/ja/p/old-ailment-stunning-flowers/</link>
        <pubDate>Mon, 26 May 2025 23:54:12 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/old-ailment-stunning-flowers/</guid>
        <description>&lt;p&gt;長年にわたりバックエンド開発に注力してきましたが、最近は &lt;code&gt;AI&lt;/code&gt; プログラミングを試したり、少しフロントエンド関連のことも取り組むようになりました。しかし、この間の苦労の中で、自分には昔からある古傷—「繁華なものに目を奪われる」—に気づきました。&lt;code&gt;AI&lt;/code&gt; を使ってフロントエンドインターフェースを実現しようとするのですが、実際にはそのような試みが現在の仕事に大きな実用的な助けになりませんし、むしろ時間を浪費してしまいます。&lt;/p&gt;
&lt;h2 id=&#34;ai-の適用シナリオ&#34;&gt;AI の適用シナリオ
&lt;/h2&gt;&lt;p&gt;小規模なプロジェクトにおいては、AI ツールが大きな役割を果たすことができ、特に独立性が高く、システムとの結合度が低く、ビジネスロジックが単純な関数を作成する際に非常に役立ちます。これらのタスクは通常、明確な入力と出力があり、文脈依存が少ないため、現在の AI 支援プログラミングの能力範囲に最適です。&lt;/p&gt;
&lt;p&gt;しかしながら、複雑なシステムアーキテクチャや深いビジネスロジックに対処する場合、AI の限界が現れ始めます。それは、プロジェクトの実際のニーズから乖離した、見かけ上は合理的だが実際には不適切なコードを生成したり、デバッグが困難な潜在的な問題を導入したりする可能性があります。これらのシナリオにおいては、AI は補助ツールとして、完全なコード生成器に依存することなく使用されるべきです。生成されたコードは厳格なレビューとテストを受け、実際の要件を満たしていることを確認する必要があります。&lt;/p&gt;
&lt;h2 id=&#34;誤りと学習の代償&#34;&gt;誤りと学習の代償
&lt;/h2&gt;&lt;p&gt;AI を使ってフロントエンドコードを生成しようとした際、多くの課題に直面しました。フロントエンドは私の馴染みのない分野であるため、問題解決には時間と労力がかかりました。プロンプトを調整して AI にコードを書き直しても、どうしても低レベルのエラーが発生してしまうのです。このような試行錯誤は時間と労力を浪費するだけでなく、現在の私のエネルギーはバックエンドのビジネスロジックに集中すべきだと痛感させられました。&lt;/p&gt;
&lt;p&gt;週末に完成させたプロジェクトを振り返ってみると、バックエンド開発とユーザーインタラクションロジックに焦点を当て、コンソールから機能を実装することが、現状で最も効率的な選択であると確信します。より多くの時間とエネルギーが手に入ったら、フロントエンドの知識を体系的に学ぶ方が良いかもしれません。&lt;/p&gt;
&lt;h2 id=&#34;フロントエンド学習の計画&#34;&gt;フロントエンド学習の計画
&lt;/h2&gt;&lt;p&gt;フロントエンド技術スタックは複雑で多様であり、短期間で習得するのは現実的ではありません。まずは、Vue.jsやReact.jsなどのフレームワークを選択し、そのコアな概念と使用方法を深く学ぶことを計画しています。基礎知識を習得した後で、AIを活用してフロントエンドコードを生成することで、不慣れによる誤りや時間の浪費を防ぐことができます。&lt;/p&gt;
&lt;p&gt;まとめると、現在の段階ではバックエンド開発に重点を置き、着実にコアスキルを向上させることに注力します。その時が来るまで、フロントエンドとAIの組み合わせを探求することは控え、より大きな成果を得られる可能性があります。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Claude4のリリース、開発を試す：hugoタグ、超リンク翻訳アシスタント</title>
        <link>https://ttf248.life/ja/p/claude-4-release-hugo-tags-hyperlink-translation-assistant/</link>
        <pubDate>Sat, 24 May 2025 03:05:31 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/claude-4-release-hugo-tags-hyperlink-translation-assistant/</guid>
        <description>&lt;p&gt;本サイトはHugoで開発されていますが、筆者自身は常に中国語のタイトルを使用しており、その結果、生成される文章の超リンクが使いにくい状態でした。つまり、送信する際に、中国語の文字が超リンク内で%E4%BD%A0%E5%A5%BDのような形式にエスケープされてしまうため、見た目が良くありません。設定でslugを設定することで解決できますが、毎回手動で設定する必要があり、非常に面倒でした。
そこで、Claude4を使って翻訳アシスタントを開発し、中国語のタイトルを自動的に英語のslugに変換し、文章中に超リンクを追加することを試みました。これにより、手動での設定を回避できます。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Claude4はマジで最高！文脈理解能力が大幅に向上し、複雑なタスクの処理効率も飛躍的に向上しています。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;プロジェクトアドレス&#34;&gt;プロジェクトアドレス
&lt;/h2&gt;&lt;p&gt;国内プロジェクトアドレス：&lt;a class=&#34;link&#34; href=&#34;https://cnb.cool/ttf248/hugo-content-suite&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://cnb.cool/ttf248/hugo-content-suite&lt;/a&gt;
国外プロジェクトアドレス：&lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/hugo-content-suite&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/hugo-content-suite&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;コードの実装&#34;&gt;コードの実装
&lt;/h2&gt;&lt;p&gt;まず、実装の思路について説明します。すべての文章をスキャンし、タグ情報と記事タイトルを抽出した後、ローカルの大規模言語モデル（例：gemma-3-12b-it）を呼び出して翻訳します。&lt;/p&gt;
&lt;p&gt;実際の開発において、前世代の大規模言語モデルと比較して、&lt;code&gt;Claude4&lt;/code&gt; はいくつかの顕著な点を発揮しました。機能要件が多いため、&lt;code&gt;Claude4&lt;/code&gt; はインタラクティブメニューを自動的に設計し、さまざまな使用シナリオを考慮しました。例えば、タグ処理に関しては、&lt;code&gt;Claude4&lt;/code&gt; はタグの統計と分析だけでなく、分類統計もサポートし、さらに&lt;strong&gt;ラベルのない文章&lt;/strong&gt;を検出することも可能です。また、プレビュー機能やタグページ生成機能も提供しています。&lt;/p&gt;
&lt;p&gt;ローカルの大規模言語モデルとの連携、翻訳キャッシュの追加、大規模なコードのリファクタリングなど、&lt;code&gt;Claude4&lt;/code&gt; はすべて一度に完了し、ほとんど問題がありませんでした。プロジェクト規模は小さくても、多くの小さな機能を含んでいました。以前の開発プロセスでは、大規模言語モデルが前の内容を忘れてしまうことがよくありましたが、今回の &lt;code&gt;Claude4&lt;/code&gt; は非常に優れており、&lt;strong&gt;ほぼコンテキストを忘れることなく動作しました&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;要するに、スマート性が向上し、今後の開発には &lt;code&gt;Claude4&lt;/code&gt; をより多く使用し、日常的なコーディングの主力モデルとして活用していく予定です。&lt;/p&gt;
&lt;h2 id=&#34;翻訳キャッシュ&#34;&gt;翻訳キャッシュ
&lt;/h2&gt;&lt;p&gt;この注文に関する説明では、大規模モデルの呼び出し回数を減らすだけでなく、実際に12Bモデルをローカルで実行すると効率が非常に高く、時間ロスもありません。しかし、毎回大規模モデルを呼び出す場合は、やはり少し遅くなります。また、文章のリンクを固定するために、全量更新を実行した場合、文章のタイトルが長いため、稀に2回の翻訳結果が異なり、リンクが変わってしまうという状況が発生します。これは非常に困ります。&lt;/p&gt;
&lt;h2 id=&#34;機能最適化&#34;&gt;機能最適化
&lt;/h2&gt;&lt;p&gt;プロジェクト全体を &lt;code&gt;Claude4&lt;/code&gt; に引き渡して、最適化の余地を分析し、以下の提案を得ました：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;外部化の設定 - メンテナンス性と柔軟性を向上
構造化ログ - 問題のトラブルシューティングと監視が容易になる
パフォーマンスモニタリング - システムの状態を把握する
ユーザーエクスペリエンス - プログレスバーなどの視覚的なフィードバック
エラー処理 - より包括的な例外処理メカニズム
コード整理 - より明確なモジュール分割
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;コードをレビューしたところ、問題点は一切なく、例えば設定ファイルについては、元のコードから設定を変換し、デフォルト設定に変換した後、設定ファイルを読み込む際に、対応する設定ファイルが存在しない場合に自動的にデフォルト設定ファイルを生成することで、ユーザーの操作ミスを防いでいました。
要件：翻訳文の正体を翻訳する際に、翻訳効率を動的に計算し、残りの時間を予測して、関連情報をコンソールに出力しました。現在、文章の文字数を取得し、各行の翻訳時に現在の翻訳文字数、時間、100文字あたりの翻訳時間を適合計算しています。同時に、文章全体の翻訳残り時間を推定します。
コードが完了した後、新しい驚きを発見しました。翻訳効率の統計情報がリアルタイムで大量に表示されますが、無制限にスクロールダウンすることはありませんでした。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;原文を英語に翻訳中（合計 7163 文字）...
翻訳する必要がある行数が 53 行検出されました。
  [1/53] Stage1/6 [░░░░░░░░░░░░░░░░░░░░░░░░░] 1.9% 354 文字の翻訳...
    ✅ 完了 (3.1秒) | API呼び出し #1
    ✅ 完了 (1.5秒) | API呼び出し #2
    ✅ 完了 (0.9秒) | API呼び出し #3
    ✅ 完了 (0.2秒) | API呼び出し #4
    ✅ 完了 (1.0秒) | API呼び出し #5
    ✅ 完了 (1.0秒) | API呼び出し #6
    ✅ 完了 (0.2秒) | API呼び出し #7
    📊 進捗: 行の 13.2% (7/53) | 文字の 12.9% (925/7163) 114.6 文字/秒 📊
    ⚡ 効率：リアルタイム 76.4 | 平均 117.9 | 最近 109.0 | ステージ 113.6 文字/秒 📊
    🎯 正確度: 100.0% (7/7) | 残り: 46行 7 秒] 9.4% 110 文字の翻訳...
    ⏱️ 残りの推定時間: 55秒 | 予想完了時間: 00:10:19 8秒] 11.3% 114 文字の翻訳...
    💾 处理速度：3211.3 行/分钟 | 总用时：8秒] 13.2% 16 文字の翻訳...
  [8/53] Stage1/6 [███░░░░░░░░░░░░░░░░░░░░░░] 15.1% 166 文字の翻訳...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以前、プログラムを制御するコードはあまり書かれていませんでしたが、どのように実装されているのか知りたくて、コードを調べてみました。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;// キャッシュクリアと再表示（動的更新効果）
if translationCount &amp;gt; 1 {
   fmt.Print(&amp;quot;\033[6A\033[K&amp;quot;) // 上に 6 行移動し、内容をクリア
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;パフォーマンス統計メニュー&#34;&gt;パフォーマンス統計メニュー
&lt;/h3&gt;&lt;p&gt;新たに作成された&lt;strong&gt;パフォーマンス統計メニュー&lt;/strong&gt;は、私自身が設計したものでも、これほど完璧とは言えない。&lt;/p&gt;
&lt;p&gt;📊 パフォーマンス統計：
🔄 翻訳回数：360
⚡ キャッシュヒット率：1.4% (5/365)
⏱️ 平均翻訳時間：315.927234ms
📁 ファイル操作：73
❌ エラー回数：0&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;データマイニング&lt;/li&gt;
&lt;li&gt;ディープラーニング&lt;/li&gt;
&lt;li&gt;ニューラルネットワーク&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;=== ブログ管理ツール ===&lt;/p&gt;
&lt;p&gt;🚀 コア機能&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;全ブログの処理をワンクリックで実行 (完全なブログ処理フロー)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;📝 コンテンツ管理
2. タグページを生成
3. アーティクルスラッグを生成
4. 記事を多言語バージョンに翻訳&lt;/p&gt;
&lt;p&gt;💾 キャッシュ管理
5. キャッシュの状態を確認
6. 全量翻訳キャッシュの生成
7. 翻訳キャッシュをクリア&lt;/p&gt;
&lt;ol start=&#34;0&#34;&gt;
&lt;li&gt;プログラム終了&lt;/li&gt;
&lt;/ol&gt;</description>
        </item>
        <item>
        <title>AIを使いすぎると、後遺症のようなものがある。</title>
        <link>https://ttf248.life/ja/p/ai-overuse-side-effects/</link>
        <pubDate>Wed, 14 May 2025 19:39:50 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ai-overuse-side-effects/</guid>
        <description>&lt;p&gt;新しい「AI 灵感碰撞坊」を立ち上げたことで、様々なものが溢れてしまい、AIを使って記録したり、発信したりするものが増え続けていますが、静かに自分自身で考え込むようなものは減ってきているようです。今後はこの欄の出力をある程度コントロールし、月刊形式にまとめるのが良いかもしれません。毎月1本の内容を公開すればよいでしょう。&lt;/p&gt;
&lt;p&gt;これはまるで、一種の副作用のようなもの、あるいは後遺症と言えるかもしれません。効率は上がっていますが、思考の深さや幅は縮んでしまっているように感じます。&lt;/p&gt;
&lt;h2 id=&#34;効率向上否定できない&#34;&gt;効率向上：否定できない
&lt;/h2&gt;&lt;p&gt;以前、ブログのコーナー「魚の七秒鐘見聞」はあまりメンテナンスされていませんでした。いくつかの話題事件を放置し、インターネット検索や記録整理を行わずにいたためです。しかし、様々なAIツールが登場し、大枠を整理するだけで、AIが自動的に関連するイベントを検索・記録し、必要な文章を生成したり、簡単なフォーマット調整を行うことができます。&lt;/p&gt;
&lt;p&gt;これはまさに怠惰な人にとっての福音であり、効率は大幅に向上しました。さらには、執筆やコーディングにおいても同様です。以前はAPIインターフェースドキュメントの詳細な読み込みが必要でしたが、現在はAIがそれを代わりに行うため、非常に効率的です。APIの習得は「肉体労働」であり、「知的労働」ではありません。AIにこの部分を任せるのが最適です。&lt;/p&gt;
&lt;h2 id=&#34;垃圾コンテンツ&#34;&gt;垃圾コンテンツ
&lt;/h2&gt;&lt;p&gt;多くの稿子で、内容の質が低いと言わざるを得ません。読み応えがなく、煙火の息吹がないという点で、以前私が好まなかったスタイルです。まるで蝋を噛むようなものです。&lt;/p&gt;
&lt;p&gt;別の角度から言えば、AI生成コンテンツは、まさに流水線のようなもので、魂が欠けていると感じられます。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;新時代のインターネットゴミ&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;忘却性&#34;&gt;忘却性
&lt;/h2&gt;&lt;p&gt;このタイプの稿子は、読者の状況が不明確であり、時間が経つにつれて、私の記憶も曖昧になり、つい忘れかけてしまうことがあります。&lt;/p&gt;
&lt;p&gt;同様の問題は、コードを書く際にも発生します。コードの提交記録を振り返らずに、自分がどのように考え、なぜそう書いたのか全く思い出せないのです。特に、コードとAIが繰り返しコミュニケーションを通じて生成されたコードは、当初のアイデアとは大きく異なり、場合によっては全く異なるものになってしまうことがあります。&lt;/p&gt;
&lt;h2 id=&#34;検索&#34;&gt;検索
&lt;/h2&gt;&lt;p&gt;最近、Googleや百度を開く回数が明らかに減りました。多くの問題はAIを使って検索したり、インタラクティブな部分も検索結果も、従来の検索エンジンよりもずっと良いからです。
現在では、まだ生きているかどうか分からない&lt;code&gt;bing ai&lt;/code&gt;を追悼しましょう。これは大手企業の中で最初に公開された、インターネットに接続して検索できるAIツールです。
Googleの使用頻度が減り、&lt;code&gt;stackoverflow&lt;/code&gt;へのアクセス回数も減りました。多くの問題は直接AIに質問するだけで済みます。このサイトも時代の淘汰にさらされるでしょう。&lt;/p&gt;
&lt;h2 id=&#34;おわりに&#34;&gt;おわりに
&lt;/h2&gt;&lt;p&gt;筆記がメンテナンスしているブログですが、元々アクセス数は少なかったこともあり、現在はさらに期待していません。むしろ、自分宛の記録場所という性格になっています。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>コードを記述せず、カスタム株式選定モジュールを設計・開発する。</title>
        <link>https://ttf248.life/ja/p/design-develop-custom-stock-module-no-code/</link>
        <pubDate>Thu, 27 Feb 2025 23:20:39 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/design-develop-custom-stock-module-no-code/</guid>
        <description>&lt;p&gt;先月の当社では、cursorを試用しましたが、無料枠の制限により、複雑な機能開発は行わず、簡単なテストに留めました。その際に見つけたのは、Byte社も同様の製品を発表しており、両者は共通してClaude-3.5という大規模言語モデルを底で呼んでいる点でした。
Byte社の製品はTraeといい、最初にリリースされたmac版が今年2月にWindows版もリリースされました。大手企業のものは良いもので、無料でClaude-3.5を無制限に利用できるため、このモデルの性能は非常に優れています。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;最終的にはK線チャートの開発で詰まってしまいました。Reactの知識が全くない私には、直接的に大きなタスクであるK線チャートの開発を引き受けることはできません。より細かくタスクを分割し、開発を進めるためには、筆者がフロントエンドの基礎知識を追加し、タスクを分解する必要がありました。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;発見された問題点&#34;&gt;発見された問題点
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;外国製のAIモデルを使用していたため、Vue3 + Element-Plusの学習データが不足しており、Reactをフロントエンドフレームワークとして採用しました。&lt;/li&gt;
&lt;li&gt;偶発的な構文エラーが存在する可能性があり、手動での修正が必要です。&lt;/li&gt;
&lt;li&gt;一部の複雑な問題に対する解決策は、人的指導が必要となります。&lt;/li&gt;
&lt;li&gt;コード構造の最適化には、人的指導が必要です。&lt;/li&gt;
&lt;li&gt;最も時間がかかったのは、フロントエンドコードをコンテナにパッケージングすることでした。筆者は環境が全く理解されておらず、&lt;code&gt;.env.production&lt;/code&gt;や&lt;code&gt;tsconfig.json&lt;/code&gt;といった概念自体を知らなかったため、途中で助けを求める豆包（ネットでの質問サイトのユーザー）に頼らざるを得ませんでした。フロントエンドの開発 devモードとbuildモードでは、コードチェックや差異が大きく異なり、対応に苦慮しました。バックエンドのデータベースおよびサービスのコンテナスクリプトは、合計5分で完了しましたが。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AIは現状では開発効率を向上させる主な役割であり、基礎があることが最も重要です。AIがすべての問題を解決してくれるわけではありません。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;リポジトリアドレス&#34;&gt;リポジトリアドレス
&lt;/h2&gt;&lt;p&gt;タイトル通り、今回は手を動かさず、AIと雑談して、自選株モジュールを設計・開発してみます。最終的に何ができるのか試していきます。&lt;/p&gt;
&lt;p&gt;リポジトリアドレス：&lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/trae-demo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/trae-demo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;詳細な使用方法は、リポジトリのREADME.mdファイルをご覧ください。&lt;/p&gt;
&lt;p&gt;このリポジトリには多数の提出記録が含まれており、ほとんどが私とTraeとの会話記録、およびTraeの機能に対する私のテストです。対応する機能を実装するために人工干渉を行ったかどうかを備考に記載しています。&lt;/p&gt;
&lt;h2 id=&#34;プロンプト&#34;&gt;プロンプト
&lt;/h2&gt;&lt;p&gt;プロジェクトは、ゼロから作成するものですが、以下の内容がプロジェクトのプロンプトです：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;プロジェクトのプロトタイプ図に基づいて、以下の機能を開発してください：
    *   選別銘柄（ウォッチリスト）機能。契約新規追加、削除、修正、照会をサポートする必要があります。
    *   選別銘柄インターフェースは、基本的な市場データを表示する必要があります。
    *   複数の異なる市場の切り替えをサポートする必要があります。

    フロントエンド：React
    バックエンド：Golang Gin GORM
    データベース：PostgreSQL

    サーバーサイドには、クロスオリジンリクエストをサポートする必要があり、データの検証とエラー処理も考慮する必要があります。バックエンドサービスが利用できない場合、フロントエンドはアラートを表示する必要があります。

    バックエンドは、リクエストとレスポンスのログを表示し、フロントエンドも通信ログを出力して問題のトラブルシューティングに役立てます。
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;uiとインタラクションの最適化&#34;&gt;UIとインタラクションの最適化
&lt;/h2&gt;&lt;p&gt;フロントエンドインターフェースのデザインは完全にGrokに依存しています。まず、Trae内で成果物のプロトタイプを作成しましたが、美観が欠けていました。使用していたモデルはコード能力は非常に高いものの、他の能力は弱いため、Grokを使用してフロントエンドのUIを最適化する必要があります。&lt;/p&gt;
&lt;p&gt;現在のインターフェースのスクリーンショットを撮影し、それをGrokにアップロードして、UIを最適化するように指示します。これにより、一度に多くの最適化提案を受け取ることができ、それらを人工的に評価し、Traeにコピーして実行し、最適化の効果を確認できます。&lt;/p&gt;
&lt;h3 id=&#34;技術スタック&#34;&gt;技術スタック
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;フロントエンド：React + TypeScript&lt;/li&gt;
&lt;li&gt;バックエンド：Golang + Gin + GORM&lt;/li&gt;
&lt;li&gt;データベース：PostgreSQL 17&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;システムアーキテクチャ&#34;&gt;システムアーキテクチャ
&lt;/h2&gt;&lt;h2 id=&#34;バックエンドアーキテクチャ&#34;&gt;バックエンドアーキテクチャ
&lt;/h2&gt;&lt;p&gt;バックエンドは Golang の Gin フレームワークを用いて RESTful API を実装しており、主なモジュールには以下が含まれます。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;データベースモジュール&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;GORM を ORM 框架として使用&lt;/li&gt;
&lt;li&gt;環境変数でデータベース接続を設定可能&lt;/li&gt;
&lt;li&gt;自動的にデータベーススキーマのマイグレーションを実行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ルーティングモジュール&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;RESTful API 設計&lt;/li&gt;
&lt;li&gt;一貫したエラーハンドリングメカニズム&lt;/li&gt;
&lt;li&gt;内蔵されたリクエストログ記録&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;クロスオリジン処理&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;ローカル開発環境でのクロスオリジンをサポート&lt;/li&gt;
&lt;li&gt;設定可能な CORS ポリシー&lt;/li&gt;
&lt;li&gt;Cookie を使用したクロスオリジンをサポート&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;フロントエンドアーキテクチャ&#34;&gt;フロントエンドアーキテクチャ
&lt;/h2&gt;&lt;p&gt;フロントエンドはReact + TypeScriptで構築され、以下の機能を実装しています。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;株価リストの表示&lt;/li&gt;
&lt;li&gt;お気に入り銘柄の管理&lt;/li&gt;
&lt;li&gt;相場データ表示&lt;/li&gt;
&lt;li&gt;エラー通知メカニズム&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>AI開発2年：ドッカーのリリース前の状態に似ている</title>
        <link>https://ttf248.life/ja/p/ai-development-two-years-like-docker-pre-release/</link>
        <pubDate>Thu, 20 Feb 2025 18:16:37 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ai-development-two-years-like-docker-pre-release/</guid>
        <description>&lt;p&gt;人工知能（AI）は近年、技術分野で最も議論を呼ぶトピックの一つであり、特に過去2年間でその進歩は目覚ましいものがありました。深層学習、自然言語処理、コンピュータビジョン、自動化意思決定システムなど、AIの応用範囲は多岐にわたります。しかしながら、技術が着実に進化を続けているにもかかわらず、AIはDockerのリリース前のボトルネックに似た状況にあります――つまり、市場を本格的に引き出す「ゲームチェンジャー」となるような、決定的なアプリケーションが存在しないのです。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;プロンプト：記事を作成してください：AIは過去2年間で発展し、Dockerのリリース前のボトルネックのような状態になっています。既存技術に基づいて、完璧な実用例を作り出し、Dockerはあまり新しい技術を使用していませんが、全体的なソリューションが合理的に、運用および開発ワークフローを変革します。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;aiの現状技術は成熟しているが応用には突破が必要&#34;&gt;AIの現状：技術は成熟しているが、応用には突破が必要
&lt;/h2&gt;&lt;p&gt;技術的な側面から見ると、AIは過去2年間で相当な進歩を遂げました。OpenAIが発表したGPTシリーズモデルや、GoogleのBERT、DeepMindのAlphaシリーズなど、AIの処理能力は以前の予測を大幅に上回っています。特に自然言語処理分野では、GPT-4などのモデルが強力な生成能力に加え、理解と推論においても驚くべきパフォーマンスを示しています。&lt;/p&gt;
&lt;p&gt;しかしながら、技術革新は日進月歩であるにもかかわらず、AIの実用的な応用においてはいくつかの課題が残されています。Dockerのリリース前の状況に似ており、AIの潜在力は巨大ですが、現状では広く普及し、産業を変革するほどの「破壊的イノベーション」をもたらす主要なアプリケーションが登場していません。人々はAIの将来について議論していますが、必ずしも革命的な変化をもたらす直接的な応用シナリオを見つけるとは限りません。多くのAIアプリケーションはまだ初期段階の試みにとどまり、大部分はさらなる統合と最適化が必要です。&lt;/p&gt;
&lt;h2 id=&#34;dockerとaiの類似性技術は必ずしも革新ではなく解決策が重要&#34;&gt;DockerとAIの類似性：技術は必ずしも革新ではなく、解決策が重要
&lt;/h2&gt;&lt;p&gt;Dockerリリース前の歴史を振り返ると、技術環境とAIの現状には多くの類似点が見られることに気づきます。Dockerリリース前に、コンテナ技術自体が新しいものではありませんでした。初期のLXC（Linux Containers）や仮想化技術も、コンテナ化の基本的な能力を持っていました。しかし、Dockerは既存技術を巧みに統合・最適化することで、よりシンプルで直感的かつ効率的な解決策を提示しました。この解決策は、画期的な技術を導入したわけではありませんが、運用および開発プロセスにおける多くの課題を解決し、ソフトウェアのデプロイ、拡張、管理プロセスの大幅な簡素化を実現しました。&lt;/p&gt;
&lt;p&gt;同様に、AI分野も類似の状況に直面しています。現在のAI技術は、もはや「新鮮なもの」ではありませんが、大規模なアプリケーションを実現するためには、完璧な実行環境が必要であり、Dockerのように既存技術を統合・最適化して、合理的なアプリケーション解決策を形成することが重要です。AIのゲームチェンジャーとなるアプリケーションは、必ずしも新しい技術のブレークスルーに依存するのではなく、既存技術を組み合わせて、実際のビジネスにおける課題やニーズを解決することにある可能性があります。&lt;/p&gt;
&lt;h2 id=&#34;aiのdocker-momentドッカーmomentを見つける方法&#34;&gt;AIの「Docker Moment」（ドッカーMoment）を見つける方法
&lt;/h2&gt;&lt;p&gt;AI技術を広く普及させるためには、いくつかの側面から取り組む必要があります。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;実用シナリオの深掘り&lt;/strong&gt;
現在の多くのAIアプリケーションは実験的な性質が強く、大規模な実用化には至っていません。AI客服やレコメンデーションなどの分野は広く利用されていますが、その機能はまだ多くの場合、業界のボトルネックを突破していません。真のブレイクスルーは、従来のやり方に困っている業界から生まれる可能性があります。例えば、医療、製造業、物流などの分野では、AIがより効率的なデータ処理と予測分析を通じて、企業がこれらの複雑なシナリオで効率を高め、コストを削減するのを支援できます。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;製品化と使いやすさ&lt;/strong&gt;
Dockerのようにコンテナ化プロセスを簡素化し運用効率を向上させるのと同様に、AI製品の使いやすさは非常に重要です。AIの普及は技術の普及だけでなく、その製品化の普及でもあります。AIを日常業務フローに統合し、ユーザーが技術的な理解なしにこれらのツールを簡単に利用できるようにすることは、AIの実用化における重要なステップです。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;エコシステムの構築と標準化&lt;/strong&gt;
いかなる新技術も広く普及するためには、エコシステムの構築が不可欠です。Dockerが急速に台頭したのも、そのオープン性と互換性によるものであり、開発者がさまざまなクラウドプラットフォーム、ツール、サービスと簡単に連携できるようになったからです。同様に、AIの未来はエコシステムの構築に依存します。AIの標準化、モデルの共有、データのオープン、技術の統合可能性などが、AIが広範な産業応用を達成する上で重要な要素となります。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;結論aiの未来は可能性に満ちているが更なる完善な落とし所を必要とする&#34;&gt;結論：AIの未来は可能性に満ちているが、更なる完善な落とし所を必要とする
&lt;/h2&gt;&lt;p&gt;過去2年間にわたり、AI技術は目覚ましい進歩を遂げているものの、現状では「決定的な応用例」が存在しない段階にある。Dockerがリリース前のコンテナ化技術と同様に、AIには合理的な適用シナリオが必要であり、既存の技術とビジネスニーズを深く融合させることで初めて、大規模な応用と普及を実現できる。技術革新は確かに重要だが、業務プロセスを簡素化し、効率を高めるソリューションこそが、技術の普及と発展を促進するだろう。&lt;/p&gt;
&lt;p&gt;未来において、AIはDockerのように、画期的な技術的ブレークスルーではなく、既存技術を統合し、完璧な適用シナリオを構築することで、私たちの仕事や生活様式を変革していく可能性がある。&lt;/p&gt;</description>
        </item>
        <item>
        <title>ollama ローカル実行 deepseek-R1</title>
        <link>https://ttf248.life/ja/p/ollama-local-deployment-deepseek-r1/</link>
        <pubDate>Fri, 07 Feb 2025 22:41:02 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ollama-local-deployment-deepseek-r1/</guid>
        <description>&lt;p&gt;Ollamaは、大規模言語モデル（LLM）をローカルで実行およびデプロイすることを目的としたオープンソースのAIツールです。クラウドサービスへの依存なしに、開発者がローカルマシン上でGPTのようなモデルを使用するための簡単なかつ効率的な方法を提供することを目指しています。Ollamaは複数のモデルに対応し、パフォーマンスを最適化することで、リソースが限られたデバイスでもこれらのモデルをスムーズに実行できるように設計されています。&lt;/p&gt;
&lt;p&gt;Ollamaを使用すると、ユーザーはテキストベースのAIアプリケーションを利用でき、ローカルでデプロイされたモデルとインタラクトすることができ、データプライバシーやAPIの使用料金に関する懸念なく、自然言語処理や質問応答などのタスクを実行できます。コマンドラインインターフェース（CLI）を通じて異なるモデルを呼び出し、これらのタスクを実行できます。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ollamaは様々なモデルを試すのに適しており、Windows版のテストではハードウェアの性能を十分に発揮できなかった可能性があります。これはWindows版の問題かもしれません。Linux版の方が良い結果が得られる可能性があります。32bパラメータのモデルをデプロイし、メモリとGPU負荷が低い場合に、応答速度が遅いことが確認されました。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;ハードウェア概要&#34;&gt;ハードウェア概要
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;オペレーティングシステム: Windows 11&lt;/li&gt;
&lt;li&gt;CPU: i7-10700K&lt;/li&gt;
&lt;li&gt;メモリ: 40GB&lt;/li&gt;
&lt;li&gt;グラフィックカード: RTX 3060 12GB&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;環境準備&#34;&gt;環境準備
&lt;/h2&gt;&lt;p&gt;以下のシステム環境変数を設定し、後続の使用を容易にします：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_MODELS=E:\ollama&lt;/code&gt;&lt;/strong&gt;
この変数で Ollama モデルの保存場所を指定します。 &lt;code&gt;E:\ollama&lt;/code&gt; はフォルダパスであり、ダウンロードまたはデプロイしたローカルモデルファイルをすべてここに格納します。Ollama はこのパスに基づいてモデルをロードおよび使用します。モデルファイルの保存場所を変更する場合は、このパスを更新してください。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_HOST=127.0.0.1:8000&lt;/code&gt;&lt;/strong&gt;
Ollama サービスのホストとポートを設定します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;127.0.0.1&lt;/code&gt; はローカルアドレス（localhost）であり、Ollama サービスは本機からのリクエストのみを待ち受けます。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;8000&lt;/code&gt; は指定するポート番号であり、Ollama サービスが 8000 ポートでリクエストを受信および処理します。必要に応じてポート番号を変更できますが、他のアプリケーションで使用されていないことを確認してください。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_ORIGINS=*&lt;/code&gt;&lt;/strong&gt;
Ollama サービスへのアクセスを許可するオリジン（ソース）を制御します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;*&lt;/code&gt; はすべてのオリジン（つまり、すべてのドメインと IP アドレス）が Ollama サービスにアクセスできることを意味します。これは通常、開発およびデバッグ環境で使用されます。本番環境では、セキュリティを高めるために、特定のドメインまたは IP アドレスのみを許可するようにより厳格なオリジン制御を設定することが一般的です。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;deepseek-r1-モデルのデプロイ&#34;&gt;DeepSeek-R1 モデルのデプロイ
&lt;/h2&gt;&lt;p&gt;ollama のインストールは、初心者向けで簡単なため、詳細は省略します。
インストール後の検証：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core&amp;gt;ollama -v
ollama version is 0.5.11
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;モデルのデプロイについては、公式ウェブサイトのモデルページを参照し、対応するパラメータのモデルを選択してください: &lt;code&gt;ollama run deepseek-r1:14b&lt;/code&gt;
14b パラメータは会話コンテキストを効果的に記憶でき、より小さなパラメータバージョンではコンテキストを記憶できません。32b パラメータバージョンは、ローカルでのデプロイ時に非常に遅延するため、詳細なテストは行っていません。&lt;/p&gt;
&lt;h2 id=&#34;参考文献&#34;&gt;参考文献
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ollama.com/library/deepseek-r1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.ollama.com/library/deepseek-r1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/x18990027/article/details/145368094&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/x18990027/article/details/145368094&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>DeepSeek（ディープシーク）が旧正月前に急激に人気を博し、NVIDIAの株価が暴落した：その裏にある機関投資家の動きと大規模言語モデルの思考連鎖</title>
        <link>https://ttf248.life/ja/p/deepseek-explodes-before-chinese-new-year-nvidia-stock-plummets-behind-the-scenes-and-large-language-model-reasoning/</link>
        <pubDate>Fri, 07 Feb 2025 20:36:05 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/deepseek-explodes-before-chinese-new-year-nvidia-stock-plummets-behind-the-scenes-and-large-language-model-reasoning/</guid>
        <description>&lt;p&gt;旧正月前夕，DeepSeek 一度成为热门话题，短短几天内便在社交媒体上引起了广泛关注。这种突然的爆火，不仅让人惊讶，还带动了市场的连锁反应。与此同时，英伟达的股票却迎来了暴跌，许多投资者对其前景产生了疑虑，部分机构在此期间进行了大规模的做空操作，似乎一切都指向了一个“精心策划”的局面。&lt;/p&gt;
&lt;h3 id=&#34;deepseek-の爆発的な人気短期間で急速に注目を集める&#34;&gt;&lt;strong&gt;DeepSeek の爆発的な人気：短期間で急速に注目を集める&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;DeepSeek は、AI を活用したツールであり、特に自然言語処理（NLP）および画像生成分野における深層学習モデルの最適化に焦点を当てています。旧正月前の数日間、このプロジェクトは投資家や技術者から急増するほどの関心を集めました。その背後にあるチームのパフォーマンスと、提示された技術成果が多くの人々を強く惹きつけました。開発者コミュニティやソーシャルメディアプラットフォームにおいて、DeepSeek に関する議論が技術界全体のあらゆる話題を占めています。&lt;/p&gt;
&lt;p&gt;しかし、DeepSeek の突然爆発的な人気は偶然ではありません。分析の結果、その裏には何らかの組織による操作があったのではないかという疑念が広まりました。特に爆発的な人気が出た後、NVIDIA の株価に顕著な下落が見られ、何らかの要因がこの変化を推進していることが明らかになりました。&lt;/p&gt;
&lt;h3 id=&#34;nvidia-株価暴落ショート売り戦略の裏黒幕&#34;&gt;&lt;strong&gt;NVIDIA 株価暴落：ショート売り戦略の裏黒幕&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;NVIDIA（英伟達），全球领先的圖形處理单元（GPU）制造商であり、多くの大規模言語モデルやAI計算における重要なハードウェアプロバイダーとして長年存在してきた。AI市場の急速な発展に伴い、NVIDIA の株価は長期にわたり堅調で、多くの投資家の注目を集めていた。しかし、DeepSeek の爆発的な人気と市場におけるその技術への高い関心により、NVIDIA 株は急落した。&lt;/p&gt;
&lt;p&gt;この現象の裏には、機関投資家によるショート売り戦略が隠されている可能性がある。過去数年間、AI 技術の普及に伴い、NVIDIA の株価は過度に高騰しており、多くの投資家がその株価に過剰な期待を抱いていた。特に DeepSeek などの技術が爆発的に人気を集めた後、一部の機関投資家は NVIDIA の株式をショートすることで、かなりの利益を得た可能性がある。正確な市場タイミングを捉え、DeepSeek の影響力を予測することによって、これらの機関投資家は成功裏に利益を上げることができた。&lt;/p&gt;
&lt;h3 id=&#34;大規模言語モデルの思考連鎖への接触結果からプロセスへ&#34;&gt;&lt;strong&gt;大規模言語モデルの思考連鎖への接触：結果からプロセスへ&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;従来の人工知能アプリケーションにおいて、多くの実務者や投資家は、AI モデルの「結果」—生成された画像、テキストなどの直接的なアウトプットに多く注目してきました。一方、DeepSeekに関連する議論の中で、ますます多くの人が、大規模言語モデルの背後に隠された思考連鎖こそがより注目すべき核心の内容であることに気づき始めています。これまで、私たちはモデルが出力する結果しか見ることができませんでしたが、今では、その背後にある論理、アルゴリズム、そしてこれらの要素を調整することでモデルのパフォーマンスを最適化する方法を理解する必要があります。&lt;/p&gt;
&lt;p&gt;この思考様式の転換は、AI 研究およびアプリケーションに対する深い考察であることを意味します。単純なブラックボックス操作から、モデル内部の動作メカニズムを真正に理解することへと移行することは、多くの技術者や投資家が人工知能の将来的な発展方向を再考するきっかけとなっています。DeepSeek の爆発的な人気は、まさにこの思考連鎖の画期的な応用であり、人々がモデル全体の構築と最適化プロセスに注目し始め、最終的なアウトプットの結果だけに焦点を当てるのではなく、ということです。&lt;/p&gt;
&lt;h3 id=&#34;まとめ&#34;&gt;&lt;strong&gt;まとめ&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;DeepSeekの突然的な爆発、NVIDIA株の大暴落、そして市場の裏で機関投資家がショートしたという事実は、すべてが緻密に設計された罠であるかのようだ。大規模言語モデルの思考連鎖を深く理解することで、AI技術の応用は表面的な現象の積み重ねではなく、モデル内部ロジックの深い掘り起こしと最適化であることを認識できる。技術の進歩とともに、今後もDeepSeekのような革新的なツールが登場し、AI研究および応用がより高度なレベルへと発展していく可能性がある。&lt;/p&gt;
&lt;p&gt;この現象は、AI技術の巨大な潜在能力を私たちに示唆すると同時に、技術背後にあるビジネスの駆け引きと資本の動きについても考えさせ始めるきっかけとなった。今後の市場の動向は、技術と資本の博弈という継続的な焦点となるだろう。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Cursor AI プログラミング IDE のトライアル</title>
        <link>https://ttf248.life/ja/p/cursor-ai-programming-ide-trial/</link>
        <pubDate>Thu, 23 Jan 2025 19:30:13 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/cursor-ai-programming-ide-trial/</guid>
        <description>&lt;p&gt;一年又转眼即逝之际，在工作中最大的变化莫过于AI参与度明显提高。以往，不同开发语言之间切换，需要开发者熟悉各种语言的不同API接口，现在这些基础代码都可以通过AI生成代码了，对于开发者来说，无疑是一个巨大的福音。&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;23年の時点で、簡単な入門紹介を既に2本作成していましたが、今では25年となり、どう表現しようか… 顕著な進歩を感じ取ることはなく、自律的な認知能力を発展させ、タスクを合理的に分割できることなどが求められます。もちろん、最も重要なのはAIが生成したコードにバグが存在するかどうかを特定することです。&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;Github Copilot
&lt;/h2&gt;&lt;p&gt;いつの日か忘れましたが、シンガポールでサーバーがデプロイされているという情報を見つけました。国内では利用され、長期間のVPN接続も不要になりました。ただし、ログイン時にはVPN接続は必要ですが、そのVPN接続はログイン時のみ使用し、その後はオフにしておくことができます。&lt;/p&gt;
&lt;p&gt;日常的な使い道としてはGithub Copilotをより多く活用しています。この拡張機能は、VS CodeやVisual Studioで直接利用できます。2つのソフトウェア間の切り替えが不要です。ChatGPTと比較して、Github Copilotの方がプロジェクトのサポートが優れており、インタラクションもフレンドリーです。また、一部のローカルファイルをAIに「学習」させることで、生成されるコードがあなたのプロジェクトに合っているものになります。&lt;/p&gt;
&lt;h2 id=&#34;cursor-ai&#34;&gt;Cursor AI
&lt;/h2&gt;&lt;p&gt;最近、Cursor AI という新しいAIプログラミングIDEを見つけました。これはGithub Copilotをベースにしたもので、このIDEはよりスマートで、直接ファイルを作成するのを手伝ってくれます。&lt;/p&gt;
&lt;p&gt;簡単な使い方は試してみて、なかなか良いと感じましたが、既存プロジェクトの理解はまだ十分ではありません。ローカルプロジェクトのファイルが多い場合や、大規模なリファクタリング、最適化、調整を行う場合は、やはり&lt;strong&gt;開発者がタスクを分割して行う&lt;/strong&gt;必要があります。&lt;/p&gt;
&lt;p&gt;例として、curso のエンジンモードに切り替えて、以下の内容を入力してみましょう。「複数の異なるスタイルで切り替えられる個人用履歴書ウェブページの作成。個人情報をデータ表示のために埋めてください。」&lt;/p&gt;
&lt;p&gt;何度かやり取りするうちに、以下のようなウェブページが得られます。もちろん、このウェブページはかなりシンプルですが、初心者にとっては非常に良いでしょう。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;現在の登録ユーザーは、高度なAPIを150回無料で試用でき、有料ユーザーは5,000回まで制限されています。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;cursor-ai-1&#34;&gt;Cursor AI
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://cursor/index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;履歴書&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>AIプログラミングとタスク分解</title>
        <link>https://ttf248.life/ja/p/ai-programming-and-task-decomposition/</link>
        <pubDate>Fri, 22 Dec 2023 08:44:26 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ai-programming-and-task-decomposition/</guid>
        <description>&lt;p&gt;2年前、サイトにコード領域のコピー機能を追加するために、半日ほど試行錯誤した結果、レンダリング効果が少し不満だった。半ば無能なフロントエンド開発者として、改善することも思わなかった。動けばそれで十分だ、と割り切っていた。今年、&lt;code&gt;AI&lt;/code&gt;を使って小程序を開発し、フロントエンドの開発もより慣れてきた。そしてリファクタリングを行った（&lt;code&gt;AI&lt;/code&gt;が再設計）。&lt;/p&gt;
&lt;p&gt;悟り：タスク分解をして、多くの小さなタスクは&lt;code&gt;AI&lt;/code&gt;で開発すると自然にこなせる。すでに閉鎖された小程序において、&lt;code&gt;75%&lt;/code&gt;のコードを&lt;code&gt;AI&lt;/code&gt;が提供し、複数のタスクを分割して引き渡すことで、人工によってプロジェクトコードが&lt;code&gt;組み立て&lt;/code&gt;られた。&lt;/p&gt;
&lt;h2 id=&#34;前文&#34;&gt;前文
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://ttf248.github.io/post/2022/001/%E4%BB%A5%E4%B8%BA%E5%BE%88%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%8B%E6%83%85%E5%A2%9E%E5%8A%A0%E4%B8%80%E4%B8%AA%E4%BB%A3%E7%A0%81%E5%A4%8D%E5%88%B6%E6%8C%89%E9%92%AE/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;簡単なことだと考えたけど、コードのコピーボタンを追加する&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;promot&lt;/strong&gt;: クラス &amp;ldquo;highlight&amp;rdquo; を持つウェブページの要素のコンテナ内に、コードと JavaScript の CSS およびコードを記述して、テキストのコピー機能を実現するコピーボタンを追加します。&lt;/p&gt;
&lt;p&gt;最初のドラフトのコードは一見問題があり、基本的には使用可能なものを生成し、コピーされた内容が正しくなく、冗長な文字が含まれているため、最適化を再度誘導し、コアの色設計を指定し、エフェクトを含めるようにしました。&lt;/p&gt;
&lt;p&gt;お客様がボタンのサイズと色に関して特定の要件をお持ちであることを認識しており、これらの要件に合わせてスタイルのデザインを再構築できます。以下は、提供されたカラーパレットとボタンサイズの最適化を含むスタイルです。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.copy-btn {
  position: absolute;
  top: 2px; /* 位置調整 */
  right: 2px;
  padding: 3px 6px; /* サイズ縮小 */
  font-size: 12px; /* フォントサイズ縮小 */
  background-color: #8FD1E1; /* ボタンの背景色 */
  color: #272822; /* テキストの色 */
  border: 1px solid #272822; /* ボーダーの色 */
  border-radius: 3px; /* 角丸 */
  cursor: pointer;
  opacity: 0.7; /* デフォルトの不透明度 */
  transition: opacity 0.3s ease, background-color 0.3s ease; /* 平滑なトランジション効果 */
}

.copy-btn:hover {
  opacity: 1; /* マウスオーバー時に完全表示 */
  background-color: #A3D4E5; /* マウスオーバー時の背景色 */
}

.highlight {
  position: relative;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;このスタイルでは、ボタンのサイズとフォントサイズを小さくして、より洗練された外観にしています。また、ボタンはデフォルトで半透明になっており、マウスをホバーすると完全表示され、背景色がわずかに明るくなることで視覚的なフィードバックを提供します。これにより、お客様のカラー要件を満たしつつ、モダンでユーザーフレンドリーな特徴を備えたデザインを実現しています。&lt;/p&gt;
&lt;p&gt;以下はよりシンプルな JavaScript です。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-JavaScript&#34;&gt;document.addEventListener(&#39;DOMContentLoaded&#39;, function() {
  // すべての .highlight 要素を検索
  const highlights = document.querySelectorAll(&#39;.highlight&#39;);

  highlights.forEach(function(highlight) {
    // コピーボタンを作成
    const copyBtn = document.createElement(&#39;button&#39;);
    copyBtn.textContent = &#39;コピー&#39;;
    copyBtn.classList.add(&#39;copy-btn&#39;);

    // ボタンを各 .highlight 要素に追加
    highlight.appendChild(copyBtn);

    // クリックイベントリスナーを追加
    copyBtn.addEventListener(&#39;click&#39;, function() {
      // .highlight 内の最初の &amp;lt;code&amp;gt; 要素からコピーするコードを取得 (存在する場合)
      const code = highlight.querySelector(&#39;code&#39;) ? highlight.querySelector(&#39;code&#39;).textContent : &#39;&#39;;

      navigator.clipboard.writeText(code).then(() =&amp;gt; {
        // コピー成功メッセージを表示
        copyBtn.textContent = &#39;已コピー!&#39;;
        setTimeout(() =&amp;gt; {
          copyBtn.textContent = &#39;コピー&#39;;
        }, 2000);
      }).catch(err =&amp;gt; {
        console.error(&#39;コピー失敗: &#39;, err);
      });
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;終わりに&#34;&gt;終わりに
&lt;/h2&gt;&lt;p&gt;コード領域の右上隅に、トップエリアにコピーボタンを追加することを望んでいたが、フロントエンドに関する知識が不足しており、キーワードに基づいて機能を正確に記述することができなかったため、AIと何度もやり取りして期待に応えられなかった。&lt;/p&gt;
&lt;p&gt;しかし、時間の経過とともに、AIがプログラミング開発にどの程度の影響を与えるのかは分からない。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>プロンプトエンジニア</title>
        <link>https://ttf248.life/ja/p/prompt-engineer/</link>
        <pubDate>Sun, 26 Mar 2023 20:46:53 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/prompt-engineer/</guid>
        <description>&lt;p&gt;例として、かつて検索エンジンのテクニックを学んだように、私たちはまた、&lt;code&gt;AI&lt;/code&gt;とコミュニケーションするためのテクニックも習得する必要がある。合理的な制約条件を与え、効率的に必要な答えを得る方法を学ぶのだ。&lt;/p&gt;
&lt;p&gt;もし角度を変えて考えると、現在の&lt;code&gt;AI&lt;/code&gt;は記憶力に優れた小さな子供であり、完璧に暗記し、宿題をコピーできる能力を持っている。私たちがやるべきことは、&lt;code&gt;AI&lt;/code&gt;と正確かつ効果的にコミュニケーションする方法を学び、要求を正確に記述することで、&lt;code&gt;AI&lt;/code&gt;が期待される結果を生み出すのを助けることだ。&lt;/p&gt;
&lt;h2 id=&#34;科学普及&#34;&gt;科学普及
&lt;/h2&gt;&lt;p&gt;話題となっている&lt;code&gt;AI&lt;/code&gt;（人工知能）を具体的に言うと&lt;code&gt;Generative Pre-Training&lt;/code&gt;（生成事前学習）です。これはインターネット上で利用可能なデータを用いてテキスト生成を行う深層学習モデルであり、質問応答、テキスト要約生成、機械翻訳、分類、コード生成、対話型AIなど様々なタスクに用いられます。現在、GPT-1、GPT-2、GPT-3、GPT-4といった異なるバージョンのモデルが存在し、それぞれが前バージョンよりも規模が大きく、性能も向上しています。&lt;/p&gt;
&lt;h2 id=&#34;到底有没有智能&#34;&gt;到底有没有智能
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;類似度が高ければ高いほど、精度も高くなる&lt;/li&gt;
&lt;li&gt;基本的な、反復性の仕事は、特定の訓練を受けることで、人工の介入が不要になる
生成式AIとは、既存のテキスト、音声、画像などのデータを活用して新しいコンテンツを作成する技術である。テキスト生成、音声合成、画像生成、対話システムなど、様々なタスクに使用できる。生成式AIの論理性は、その学習データとモデル構造に依存する。一般的に、生成式AIは一定程度、文法、論理、常識に従うことができるが、誤りや偏見、または不真実を含むコンテンツを生成することもある。そのため、生成式AIの出力は人間の判断と検証が必要であり、盲目的に信頼したり使用したりすることはできない。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;プロンプトエンジニア&#34;&gt;プロンプトエンジニア
&lt;/h2&gt;&lt;p&gt;時間は流れの法則を変えない。人は潮流に適応することを学ぶ必要がある。AIを無智能で論理性に欠けるものと捉えがちだが、よく書けば使えないコードを生成することも少なくない。&lt;/p&gt;
&lt;p&gt;もし別の角度から考えると、現在のAIは記憶力に優れた幼い子供であり、丸暗記する能力を持っている。つまり、問題をコピーする能力があるのだ。私たちがやるべきことは、AIに対して適切で効果的かつ正確なコミュニケーションを学び、要求を明確に記述し、AIが期待される結果を生み出すのを支援することだ。&lt;/p&gt;
&lt;h2 id=&#34;対話モデル&#34;&gt;対話モデル
&lt;/h2&gt;&lt;p&gt;2年前、GitHub Copilotの発表は誰も予想していませんでした。その結果、OpenAIが横空に出現し、人類は大規模言語モデルの能力を認識するに至りました。&lt;/p&gt;
&lt;p&gt;コメントベースのプログラミングと対話ベースのプログラミングに基づき、インタラクティブなロジックは完全に異なり、対話のパターンは初心者ユーザーにとって親しみやすく、NewBingが各質問の後に提示するフォローアップのヒントは必須です。Microsoftは、AI知識ベースにあるより多くのコンテンツを取得するために、ユーザーを誘導しようとしています。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;データの前処理&lt;/li&gt;
&lt;li&gt;深層学習&lt;/li&gt;
&lt;li&gt;ニューラルネットワーク&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;栗子&#34;&gt;栗子
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 必要なライブラリをインポート
import argparse
import logging
import multiprocessing
import os

from PIL import Image


# 画像をグレースケールに変換し、透明背景を維持して画像を保存し、ファイルサイズを返す関数を定義します。
def convert_and_save(image_file):
    # 画像を開く
    try:
        image = Image.open(image_file)
    except Exception as e:
        logging.error(f&amp;quot;画像 {image_file} のオープンに失敗しました：{e}&amp;quot;)
        return None, None
    # 画像のモードを取得します。RGBA モードの場合、透明背景があります。
    mode = image.mode
    if mode == &amp;quot;RGBA&amp;quot;:
        # 画像と同じサイズの白い背景画像を生成します。
        background = Image.new(&amp;quot;RGB&amp;quot;, image.size, (255, 255, 255))
        # 元の画像に背景を貼り付け、透明ピクセルを無視します。
        background.paste(image, mask=image.split()[3])
        # 合成された画像をグレースケールモードに変換します。
        gray_image = background.convert(&amp;quot;L&amp;quot;)
        # グレースケール画像をRGBAモードに戻して透明背景を維持します。
        final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
    else:
        # RGBA モードでない場合は、画像が直接グレースケールモードに変換されます。
        final_image = image.convert(&amp;quot;L&amp;quot;)
    # 元の画像のファイル名と拡張子を取得します。
    file_name, file_ext = os.path.splitext(image_file)
    # 新しい画像のファイル名を定義し、_bw サフィックスを追加して黒白であることを示します。
    new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # 新しい画像を保存し、品質を最適化してファイルサイズを削減します。
    try:
        final_image.save(new_file_name, optimize=True)
    except Exception as e:
        logging.error(f&amp;quot;{new_file_name} の保存に失敗しました：{e}&amp;quot;)
        return None, None
    # 元の画像と新しい画像のファイルサイズを取得し、返します。
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return file_name, old_size, new_size

# コマンドライン引数を解析し、フォルダパスと拡張名リストを返す関数を定義します。
def parse_args():
    # 解析器オブジェクトを作成します。
    parser = argparse.ArgumentParser(description=&amp;quot;画像を黒白に変換し、品質を最適化します。&amp;quot;)
    # 位置パラメータを追加してフォルダパスを指定します。
    parser.add_argument(&amp;quot;folder_path&amp;quot;, help=&amp;quot;画像が含まれるフォルダーのパスです。&amp;quot;)
    # オプションパラメータを追加して拡張名リストを指定します。デフォルトは png, jpg, jpeg, gif です。
    parser.add_argument(&amp;quot;-e&amp;quot;, &amp;quot;--extensions&amp;quot;, nargs=&amp;quot;+&amp;quot;, default=[&amp;quot;.png&amp;quot;, &amp;quot;.jpg&amp;quot;, &amp;quot;.jpeg&amp;quot;, &amp;quot;.gif&amp;quot;], help=&amp;quot;画像ファイルの拡張子です。&amp;quot;)
    # コマンドライン引数を解析し、結果オブジェクトを返します。
    args = parser.parse_args()
    return args.folder_path, args.extensions

# 変換前後のファイルサイズの違いを出力する関数を定義します。
def print_result(result):
    # 結果が空でない場合、変換と保存が成功したことを示します。
    if result:
        # 結果をファイル名とファイルサイズのタプルに分解します。
        if len(result) == 3:
            file, old_size, new_size = result
            # コントロールパネルで変換前後のファイルサイズの違いを出力します。
            logging.info(f&amp;quot;{file}: {old_size} バイト -&amp;gt; {new_size} バイト&amp;quot;)
        else:
            # 結果を出力します。
            logging.info(f&amp;quot;{result}&amp;quot;)

# 日志記録器を設定し、ログをコンソールとファイルに出力し、ログレベルを INFO に設定します。
logging.basicConfig(level=logging.INFO,
                    format=&amp;quot;%(asctime)s %(levelname)s %(message)s&amp;quot;,
                    handlers=[logging.StreamHandler(),
                              logging.FileHandler(&amp;quot;log.txt&amp;quot;)])

# # 別のプロセスに、パイプを介して渡されたコードを実行するように通知されます。これは、`--multiprocessing-fork` コマンドライン引数を渡すことで行われます。
# `freeze_support()` 関数の実装を見ると、それが実行されているプロセスの確認と、パイプを介して渡されたコードの実行が必要かどうかを確認するタスクを実行します。
# `multiprocessing.freeze_support()`

# コア数に基づいてコンピューターに自動的にプロセスを割り当てるプロセスプールを作成します。
# プロセスプール = multiprocessing.Pool()
# 异步タスクの結果オブジェクトを格納するための空のリストを作成します。
# results = []
# フォルダー内のすべてのファイルに対して反復処理を行います。
# for file in os.listdir(folder_path):
#     # ファイルパスを結合します。
#     file_path = os.path.join(folder_path, file)
#     # 拡張子リストに基づいて画像ファイルを判断します。必要に応じて拡張子リストを変更できます。
#     if any(file_path.endswith(ext) for ext in extensions):
#         # 関数を呼び出して、画像を変換して保存し、ファイルサイズを取得します。パイプを介したコードの実行は、メインプロセスをブロックすることなく、非同期で行われます。
#         result = pool.apply_async(convert_and_save, args=(file_path,), callback=print_result)
#         # 結果オブジェクトをリストに追加します。
#         results.append((file, result))
# プロセスプールを閉じ、新しいタスクの受け入れをやめます。
# pool.close()
# すべてのタスクが完了するまで待ちます。
# pool.join()

## 終わりに

ローカル開発が `windows` システムであるため、AI が最初に提示した回答には `main` 関数も `multiprocessing.freeze_support` も含まれておらず、エラーが発生しました。質問を重ねることでエラーの原因を特定し、コードを修正しました。

かつて検索エンジンの技術を学ぶように、AI とコミュニケーションする上でも、適切な制約条件を与え、効率的に必要な回答を得るためのスキルを習得する必要があります。

注意：**もしあなたがプログラミング初心者であれば、提示されたコメントと合わせて理解できない点がある場合は、引き続き関連コードについて質問してください。**&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>AIによるプログラミング支援、生産性の進化</title>
        <link>https://ttf248.life/ja/p/ai-assisted-programming-productivity-evolution/</link>
        <pubDate>Tue, 28 Feb 2023 17:05:17 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ai-assisted-programming-productivity-evolution/</guid>
        <description>&lt;p&gt;GitHub Copilot のリリースからわずか 2 年しか経っていないのに、ChatGPT が登場し、裏にある原理をよく理解していない状態で、しばらく使ってみた。2 つのツールのサポートレベルは完全に異なり、どちらも生産性を大幅に向上させた。&lt;/p&gt;
&lt;p&gt;あまりにも複雑なことについては、AI ではまだできないだろう。なぜなら、彼らは論理がなく、パターンや形式固定されたもの、あるいは范式を定めているからだ。学習データは十分で、AI の効果は 9 分満点になる。&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;GitHub Copilot
&lt;/h2&gt;&lt;p&gt;リリース時に、公式サイトの紹介の &lt;code&gt;demo&lt;/code&gt; を見ると、あまり賢くなく、試用してみましたが、使い勝手が良くありませんでしたので、諦めました。
2022年以前に、暇つぶしで切り替えて新バージョンを体験したところ、かなり良くなっており、ただ国内の速度が少し遅いのは、ネットワークの問題である可能性が高いです。&lt;code&gt;Python&lt;/code&gt;のような言語では、コメントに基づいて書かれたコードもそれなりによくできており、自分で資料を探して書いていたよりもはるかに速かったです。&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;Github Copilot&lt;/code&gt;は、プログラマー、つまり開発者の視点から製品を設計しており、プログラミングの知識が必要であり、コメントを通じてAIによるコーディング支援を誘導していくものでした。
&lt;code&gt;ChatGPT&lt;/code&gt;は次の段階に進み、&lt;strong&gt;専門家でなくてもすぐに使いこなせるように設計されています&lt;/strong&gt;。対話形式でのチャットインターフェースにより、質問や要件の説明、理解できない場合は引き続き質問することができます。&lt;/p&gt;
&lt;p&gt;例えば、品詞分割の概念を知っているものの、コーディング方法がわからない状態で、文字列の類似度を計算したい場合を考えてみましょう。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Python 品詞分割 維天運通 LOGORY と 合肥維天運通情報科技股份有限公司 2 つの文字列の類似度を計算します。
比較前に、文字列を英語小文字に変換するなどして統一処理を行います。
2 番目の文字列の中に最初の文字列の最初の文字が見つかれば、2 番目の文字列を最初の文字列の長さと同じ長さで切り捨てます。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;こんにちは、これはBingです。😊
オンラインの情報123に基づき、Python の品詞分割には &lt;code&gt;jieba&lt;/code&gt; などのライブラリを使用できます。&lt;code&gt;jieba&lt;/code&gt; ライブラリは、精密モード、全模式、検索エンジンモードの 3 つの分詞モードをサポートしています。要件に応じて適切なモードを選択できます。
文字列の類似度を比較するには、まず文字列を品詞分割し、その後の単語ベクトルまたは編集距離などの指標を計算する必要があります。&lt;code&gt;numpy&lt;/code&gt; や &lt;code&gt;scipy&lt;/code&gt; などのライブラリを使用して数学演算を行うことができます。
文字列を統一的に処理するために、英語を小文字に変換するには、Python の組み込み関数 &lt;code&gt;lower()&lt;/code&gt; を使用できます。
2 番目の文字列を切り出すには、Python のスライス操作符 &lt;code&gt;[ ]&lt;/code&gt; を使用できます。&lt;/p&gt;
&lt;p&gt;以下は、その際のコード例です。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import jieba
import numpy as np
from scipy.spatial.distance import cosine

# 定義する 2 つの文字列
str1 = &amp;quot;維天運通 LOGORY&amp;quot;
str2 = &amp;quot;合肥維天運通情報科技股份有限公司&amp;quot;

# 統一処理：英語を小文字に変換
str1 = str1.lower()
str2 = str2.lower()

# 2 番目の文字列の中に最初の文字列の最初の文字が見つかる位置を探す
index = str2.find(str1[0])

# 見つかった場合、2 番目の文字列を切り出す
if index != -1:
    str2 = str2[index:index+len(str1)]

# jieba 库を使用して文字列を品詞分割する
words1 = list(jieba.cut(str1))
words2 = list(jieba.cut(str2))

# 2 つの文字列の単語ベクトル（頻度を重みとして使用）を計算する
vector1 = np.zeros(len(words1))
vector2 = np.zeros(len(words1))

for i, word in enumerate(words1):
    vector1[i] += 1 # 最初の文字列内の各単語の出現回数をカウント
    if word in words2:
        vector2[i] += 1 # 2 番目の文字列内の各単語の出現回数をカウント

# 2 つの文字列の類似度（余弦距離を指標として使用）を計算する
similarity = 1 - cosine(vector1, vector2)

print(&amp;quot;2 つの文字列の類似度は：&amp;quot;, similarity)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;さらに、結果を確認し、問題点を発見します。結果はランダムで、実際のコードを実行していませんが、良い結果を提供します。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;栗子&#34;&gt;栗子
&lt;/h3&gt;&lt;p&gt;質問：SQL文で、製品コードテーブルから、製品コードが80000～89999の範囲にあるレコードを抽出するには？&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;こんにちは、Bingです。😊

検索結果12によると、指定された範囲内の値を選択するために、BETWEEN演算子を使用できます。BETWEEN演算子は、開始値と終了値を両方含みます。

まず、クエリするテーブル名と列名を指定し、WHERE句でBETWEEN演算子と範囲値を指定する必要があります。

たとえば、製品コードが80000から89999の範囲にある製品コードテーブルからレコードを抽出するには、次のステートメントを使用できます。

SELECT * FROM product_code
WHERE code BETWEEN 80000 AND 89999;
ここで、*はすべての列3を選択します。特定の列（たとえば、製品名と価格）のみを選択する場合は、カンマで区切って指定できます。例えば：

SELECT name, price FROM product_code
WHERE code BETWEEN 80000 AND 89999;
これで役に立つことを願っています。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;さらに質問します。否定して：製品コードは文字列であり、あなたのコードは間違っています。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;申し訳ありませんが、製品コードが文字列であることに気づいていませんでした。もしそうであれば、範囲の値の前後にはシングルクォートを追加する必要があります。例えば：

SELECT * FROM product_code
WHERE code BETWEEN &#39;80000&#39; AND &#39;89999&#39;;
私の誤りを許してください。🙏
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;おめでとうございます。正しく認識します。&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>

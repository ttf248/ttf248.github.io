<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>AI on 向叔の手帳</title>
        <link>https://blog.ttf248.life/ja/tags/ai/</link>
        <description>Recent content in AI on 向叔の手帳</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>ja</language>
        <lastBuildDate>Wed, 28 May 2025 09:47:38 +0800</lastBuildDate><atom:link href="https://blog.ttf248.life/ja/tags/ai/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>古い弱点、花の華やかさに目が奪われる。</title>
        <link>https://blog.ttf248.life/ja/p/old-ailment-stunning-flowers/</link>
        <pubDate>Mon, 26 May 2025 23:54:12 +0800</pubDate>
        
        <guid>https://blog.ttf248.life/ja/p/old-ailment-stunning-flowers/</guid>
        <description>&lt;p&gt;長年バックエンド開発に注力してきましたが、最近、フロントエンドインターフェースを実現するために &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; 编程，并涉足了一些前端相关的内容。然而，在这段折腾的过程中，我逐渐意识到自己又陷入了一个老毛病——繁花迷人眼。总想着用 &lt;strong&gt;INLINE_CODE_1&lt;/strong&gt; を試み始めましたが、実際には、そのような試みは現在の仕事にほとんど役立たず、むしろ気を散らすだけでした。&lt;/p&gt;
&lt;h2 id=&#34;aiの適用シーン&#34;&gt;AIの適用シーン
&lt;/h2&gt;&lt;p&gt;小規模プロジェクトにおいて、AIツールは特に大きな効果を発揮します。独立性が高く、システムとの結合度が低く、ビジネスロジックが単純な関数を記述する際には、いっそうその手腕が光ります。これらのタスクは通常、明確な入力と出力があり、コンテキスト依存性が少ないため、現在のAIによるプログラミング支援の能力範囲に最適です。&lt;/p&gt;
&lt;p&gt;しかし、複雑なシステムアーキテクチャや高度なビジネスロジックに直面すると、AIの限界が徐々に明らかになる。一見妥当に見えるが、実際にはプロジェクトの真のニーズからかけ離れたコードを生成したり、原因究明が困難な潜在的な問題を導入したりする可能性がある。そのような状況では、AIは完全なコードジェネレーターとしてではなく、むしろ補助ツールとして活用すべきである。生成されたコードについては厳格なレビューとテストを行い、実際の要件を満たしていることを確認する必要がある。&lt;/p&gt;
&lt;h2 id=&#34;間違いと学習の代償&#34;&gt;間違いと学習の代償
&lt;/h2&gt;&lt;p&gt;AIによるフロントエンドコード生成を試みる中で、多くの課題に直面しました。フロントエンドは得意分野ではないため、問題の特定には時間と労力がかかります。プロンプトを調整してAIにコードを書き直しても、初級的なエラーを避けることは難しいです。この繰り返しの試行錯誤は時間を浪費するだけでなく、現在のリソースを慣れない領域での模索ではなく、バックエンドのビジネスロジックに集中すべきだと気づかされました。&lt;/p&gt;
&lt;p&gt;週末に完了したプロジェクトを振り返ると、バックエンド開発とユーザーインタラクションロジックに集中し、コンソールで機能を実装することが現時点で最も効率的な選択だと確信する。より多くの時間とエネルギーがある時に、フロントエンドの知識を体系的に学ぶ方が良い戦略かもしれない。&lt;/p&gt;
&lt;h2 id=&#34;フロントエンド学習計画&#34;&gt;フロントエンド学習計画
&lt;/h2&gt;&lt;p&gt;フロントエンド技術のスタックは複雑で多様なため、すぐに習得することは現実的ではありません。まずは Vue.js や React.js のようなフレームワークを一つ選び、そのコアコンセプトと使い方を深く学習する予定です。基礎知識に慣れてからこそ、AI を活用してフロントエンドコードを生成することで初めて、不慣れによるエラーや時間浪費を効果的に回避できます。&lt;/p&gt;
&lt;p&gt;結局、現段階ではバックエンド開発に重点を置き、着実にコアスキルを向上させることが重要だ。時機が整ったら、フロントエンドとAIの組み合わせを探求するのも良いかもしれないし、より大きな成果が得られるかもしれない。&lt;/p&gt;</description>
        </item>
        <item>
        <title>AIを使いすぎたせいか、少し後遺症が出ている。</title>
        <link>https://blog.ttf248.life/ja/p/ai-overuse-side-effects/</link>
        <pubDate>Wed, 14 May 2025 19:39:50 +0800</pubDate>
        
        <guid>https://blog.ttf248.life/ja/p/ai-overuse-side-effects/</guid>
        <description>&lt;p&gt;新しい___INLINE_CODE_0__ができて以来、色々なものの試しにAIで記録し発信するものが増えたため、静まって自分自身で考える時間が増えていない。今後はこの欄の産出を少しコントロールし、月刊形式にまとめるのが良いだろう。毎月一記事の発行で十分である。&lt;/p&gt;
&lt;p&gt;まるで何らかの後遺症や副作用のようで、効率は上がったものの、思考の深さと広がりが低下している。&lt;/p&gt;
&lt;h2 id=&#34;効率向上否定できない&#34;&gt;効率向上：否定できない
&lt;/h2&gt;&lt;p&gt;以前はあまりメンテナンスしていなかったこのコーナーだが、時事問題に対しては面倒がらずにインターネットで情報を検索し、記録としてまとめなかった。しかし今では様々なAIツールがあり、アウトラインを作成するだけで、AIが自動的に関連イベントを検索・記録し、必要な記事を生成してくれる。簡単なフォーマット調整をして公開すれば良い。&lt;/p&gt;
&lt;p&gt;まるで怠け者の救いもの、効率が大幅に上がり、まさに少ない労力で大きな成果だ。&lt;/p&gt;
&lt;p&gt;コーディングに集中すると、執筆作業を脇に置いた時と比べて、効率が確実に向上します。以前はAPIインターフェースドキュメントを詳細に読む必要があったコードの記述も、今は直接スキップできることが多くなり、そのスキップは非常に重要です。APIへの習熟は&lt;code&gt;体力劳动&lt;/code&gt;，而不是&lt;code&gt;脑力劳动&lt;/code&gt;であり、AIにこの部分を任せるのがちょうど良いです。&lt;/p&gt;
&lt;h2 id=&#34;ゴミ情報&#34;&gt;ゴミ情報
&lt;/h2&gt;&lt;p&gt;多くの原稿だが、内容はそれほど良くなく、完全に無価値というわけではないものの、どこか活気が感じられず、以前から好まない傾向のある、味が無いような内容だ。&lt;/p&gt;
&lt;p&gt;別の視点で見ると、AIが生成したコンテンツは確かに、まるでベルトコンベアで大量生産されたようなもので、魂がないように感じる。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;新しい時代のインターネットゴミ&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;忘却性&#34;&gt;忘却性
&lt;/h2&gt;&lt;p&gt;この手の原稿は、すべてAI生成で、読者の状況も不明なため、時間が経つと私の記憶も曖昧になり、忘れそうになる。&lt;/p&gt;
&lt;p&gt;類似の問題は、コードを書く時にも起こる。コードのコミット履歴を見ないと、自分が当時どう考えていたのか、なぜそう書いたのか全く分からない。特に、コードが通るまでAIと何度もやり取りして生成されたコードは、当初の考え方と大きく異なったり、全く違うものだったりする。&lt;/p&gt;
&lt;h2 id=&#34;検索&#34;&gt;検索
&lt;/h2&gt;&lt;p&gt;最近、Googleや百度を開く回数が明らかに減った。多くの問題をAIで検索すると、インタラクションも検索結果も、従来の検索エンジンよりもずっと良い。&lt;/p&gt;
&lt;p&gt;現在、生存しているかどうか定かではない__INLINE_CODE_0__に追悼を捧げましょう。これは大手企業で最初にリリースされた、インターネット検索が可能なAIツールです。&lt;/p&gt;
&lt;p&gt;グーグルを使う人が減り、アクセス数も減っている。多くの質問はAIに直接聞けるし、このサイトも時代に取り残されていくだろう。&lt;/p&gt;
&lt;h2 id=&#34;結びに&#34;&gt;結びに
&lt;/h2&gt;&lt;p&gt;ブログは現在もメンテナンス中で、以前からアクセス数は少なかったのですが、今はさらに期待できません。むしろ、自分用の記録として、自分自身に見るための場所です。&lt;/p&gt;</description>
        </item>
        <item>
        <title>コードを書かずに、カスタム銘柄選択モジュールを設計・開発する。</title>
        <link>https://blog.ttf248.life/ja/p/no-code-design-develop-custom-stock-module/</link>
        <pubDate>Thu, 27 Feb 2025 23:20:39 +0800</pubDate>
        
        <guid>https://blog.ttf248.life/ja/p/no-code-design-develop-custom-stock-module/</guid>
        <description>&lt;p&gt;先月、Cursor を試用しましたが、無料枠の制限により、複雑な機能開発は行わず、簡単なテストにとどまりました。その際、ByteDance も同様の商品をリリースしていることがわかり、両者とも基盤となる大規模言語モデルは Claude-3.5 です。&lt;/p&gt;
&lt;p&gt;バイトのプロダクトTrae、まずMac版が先行してリリースされ、今年の2月になってようやくWindows版も登場しました。大手企業のものはやはり良いですね。無料で利用でき、お金を払わずにClaude-3.5を無制限に使えるのは素晴らしいです。このモデルの効果はなかなか良いです。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;結局、K線図の開発でつまずいてしまいました。Reactの知識がほとんどないため、諦めざるを得ませんでした。開発を続けたい場合は、筆者がフロントエンドの基礎知識を補強し、タスクをより細かく分割する必要があります。いきなり「K線図の開発」という大きな課題を与えるのではなくです。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;発見された問題&#34;&gt;発見された問題
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;海外のAIモデルを利用するため、Vue3 + Element-Plus の学習データが不足しているため、React をフロントエンドフレームワークとして採用しました。&lt;/li&gt;
&lt;li&gt;可能性はありますが、文法的な誤りが発生する可能性があり、手動での修正が必要です。&lt;/li&gt;
&lt;li&gt;複雑な問題の解決には、手動での指示が必要です。&lt;/li&gt;
&lt;li&gt;コード構造の最適化には人的指導が必要です。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最も時間がかかったのは、フロントエンドコードをコンテナにパッケージ化することです。筆者は全くの初心者__INLINE_CODE_0__ __INLINE_CODE_1__で、概念がありませんでした。途中で助けを借りたおかげで、ようやく対応するロジックを理解することができました。フロントエンドの開発環境（devモード）とビルドモードでは、コードのチェックに関して大きな違いがあります。バックエンドデータベースとサービスのコンテナスクリプトは、合わせて5分で終わりました。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI 目前更多的提高开发的效率，你有基础是最好的，并不是 AI 会帮你解决所有的问题&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;倉庫住所&#34;&gt;倉庫住所
&lt;/h2&gt;&lt;p&gt;タイトル通り、今回は書かずにAIと直接対話し、独自の株式モジュールを設計・開発します。最終的に何ができるか見てみましょう。&lt;/p&gt;
&lt;p&gt;倉庫住所：&lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/trae-demo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/trae-demo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;詳細な使用方法は、リポジトリのREADME.mdファイルを参照してください。&lt;/p&gt;
&lt;p&gt;倉庫には多くの提出記録が含まれており、そのほとんどが私とTraeとの会話記録、そして私がTraeのいくつかの機能をテストした記録です。それぞれの機能を実現するために手動介入を行ったかどうかを注記しています。&lt;/p&gt;
&lt;h2 id=&#34;prompt&#34;&gt;Prompt
&lt;/h2&gt;&lt;p&gt;プロジェクトはゼロから作成され、以下にプロンプトを示します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;基于项目原型图，开发功能：自选股，需要支持合约的新增、删除、修改、查询。自选股界面需要展示基础的行情数据。支持多个不同的市场切换。

前端：react
后端：golang gin gorm
数据库：PostgreSQL

服务端需要支持跨域请求，同时需要考虑数据的校验和错误处理，如果后端服务不可用，前端需要告警提示。

后端需要展示请求和应答的日志；前端也打印通讯的日志，方便排查问题。
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;ユーザーインターフェースとインタラクションの最適化&#34;&gt;ユーザーインターフェースとインタラクションの最適化
&lt;/h2&gt;&lt;p&gt;フロントエンドの設計は完全にGrokに依存しており、まずTraeでプロダクトの原型を作成しましたが、デザイン性は欠けていました。使用しているモデルはコード生成能力は高いものの、他の能力が弱いので、Grokを使ってフロントエンドUIを最適化する必要があります。&lt;/p&gt;
&lt;p&gt;現在のインターフェースのスクリーンショットをGrokにアップロードし、UI最適化のアドバイスをもらう。その中から手動で評価したものをTaeにコピーして実行し、効果を確認する。&lt;/p&gt;
&lt;h3 id=&#34;技術スタック&#34;&gt;技術スタック
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;フロントエンド：React + TypeScript&lt;/li&gt;
&lt;li&gt;バックエンド：Golang + Gin + GORM&lt;/li&gt;
&lt;li&gt;データベース：PostgreSQL 17&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;システムアーキテクチャ&#34;&gt;システムアーキテクチャ
&lt;/h2&gt;&lt;h2 id=&#34;バックエンドアーキテクチャ&#34;&gt;バックエンドアーキテクチャ
&lt;/h2&gt;&lt;p&gt;バックエンドはGolangのGinフレームワークでRESTful APIを実装しており、主なモジュールは以下の通りです。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;申し訳ありませんが、翻訳する中国語のテキストが提供されていません。テキストを提供してください。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;GORM を ORM フレームワークとして使用する。&lt;/li&gt;
&lt;li&gt;環境変数でデータベース接続を設定することを推奨します。&lt;/li&gt;
&lt;li&gt;自動データベーステーブル移行&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;申し訳ありませんが、翻訳する中国語のテキストが提供されていません。テキストを提供してください。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;RESTful API 設計&lt;/li&gt;
&lt;li&gt;統一されたエラー処理メカニズム&lt;/li&gt;
&lt;li&gt;内蔵リクエストログ&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;申し訳ありませんが、翻訳する中国語のテキストが提供されていません。テキストを提供してください。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;ローカル開発環境でのクロスドメインをサポート&lt;/li&gt;
&lt;li&gt;設定可能なCORSポリシー&lt;/li&gt;
&lt;li&gt;Cookie 跨ドメイン対応&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;フロントエンドアーキテクチャ&#34;&gt;フロントエンドアーキテクチャ
&lt;/h2&gt;&lt;p&gt;React + TypeScript を使用して構築され、以下の機能を実装しています：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;株式リスト表示&lt;/li&gt;
&lt;li&gt;銘柄選択管理&lt;/li&gt;
&lt;li&gt;市場データ表示&lt;/li&gt;
&lt;li&gt;エラー通知メカニズム&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>AI 開発二年：ドッカーリリース前の状態に似ている。</title>
        <link>https://blog.ttf248.life/ja/p/ai-development-two-years-docker-pre-release/</link>
        <pubDate>Thu, 20 Feb 2025 18:16:37 +0800</pubDate>
        
        <guid>https://blog.ttf248.life/ja/p/ai-development-two-years-docker-pre-release/</guid>
        <description>&lt;p&gt;人工知能（AI）は近年、技術分野で最も議論されている話題の一つであり、特に過去2年間でAI技術は急速な進歩を遂げました。深層学習、自然言語処理、コンピュータビジョン、自動化意思決定システムなど、AIの応用範囲は広がり続けています。しかしながら、技術が不断に突破口を開いても、AIはDockerリリース前のボトルネックと同様に、市場を真に引き金となるような画期的なアプリケーションが不足しているという課題を抱えています。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;AIの発展も2年ほど経ち、Dockerがリリースされる前のような状況で、現状では決定的なキラーアプリケーションは存在しない。しかし、既存技術を基盤として、完璧な実用化シナリオを作り出すことができれば、Dockerのように、必ずしも新しい技術に頼る必要はなくとも、運用や開発のワークフローを変革するような、合理的な全体像が実現するだろう。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;aiの現状技術は成熟しているが応用はまだブレークスルーが必要&#34;&gt;AIの現状：技術は成熟しているが、応用はまだブレークスルーが必要。
&lt;/h2&gt;&lt;p&gt;技術的な側面から見ると、AIは過去2年間で著しい進歩を遂げています。OpenAIのGPTシリーズやGoogleのBERT、DeepMindのAlphaシリーズなど、AIの処理能力は以前の予想を大きく上回っています。特に自然言語処理分野においては、GPT-4などのモデルが強力な生成能力に加え、理解と推論においても驚くべきパフォーマンスを示しています。&lt;/p&gt;
&lt;p&gt;しかしながら、技術は日進月歩とは言えども、AIの現実的な応用には一定の課題が残る。Dockerリリース前の状況に似ており、AIの潜在能力は大きいものの、広範な普及や産業を変革する真に画期的なアプリケーションはまだ登場していない。多くの人がAIの将来性について語っているが、革命的な変化をもたらす直接的な応用事例を見つけるのは容易ではない。多くのAIアプリケーションは依然として初期段階にとどまっており、大部分はさらなる統合と最適化が必要である。&lt;/p&gt;
&lt;h2 id=&#34;dockerとaiの類似点技術そのものではなく解決策が重要&#34;&gt;DockerとAIの類似点：技術そのものではなく、解決策が重要
&lt;/h2&gt;&lt;p&gt;もしDockerリリース前の歴史を振り返れば、当時の技術環境とAIの現状には多くの類似点が見て取れることに気づくでしょう。Dockerが登場する以前から、コンテナ技術は決して新しいものではありませんでした。LXC（Linux Containers）や仮想化技術など、すでにコンテナ化に必要な基本的な機能は存在していました。しかし、Dockerは既存技術を巧みに統合・最適化し、よりシンプルで直感的かつ効率的なソリューションを提示しました。画期的な技術ではありませんでしたが、運用や開発プロセスにおける多くの課題を解決し、ソフトウェアのデプロイ、拡張、管理プロセスを大幅に簡素化しました。&lt;/p&gt;
&lt;p&gt;同様に、AI分野も類似の状況に直面している。「目新しさ」は薄れたものの、現在のAI技術が真に大規模な応用を実現するには、Dockerのように既存技術を統合・最適化し、合理的な応用プランを構築する必要がある。画期的なAIアプリケーションとは、必ずしも新しい技術革新に依存するものではなく、むしろ既存技術を統合して、実際のビジネスにおける課題やニーズを解決することにあるかもしれない。&lt;/p&gt;
&lt;h2 id=&#34;aiのdocker瞬間はどう見つけるか&#34;&gt;AIの「Docker瞬間」は、どう見つけるか？
&lt;/h2&gt;&lt;p&gt;AI技術が真に広く普及するためには、いくつかの側面から取り組む必要があります。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;申し訳ありませんが、翻訳する中国語のテキストが提供されていません。テキストを提供してください。
現在多くのAIの応用事例は実験的な性質が強く、大規模な実用化には至っていません。例えば、AIカスタマーサービスやスマートレコメンデーションといった分野では幅広い応用があるものの、機能には依然として多くの制約があり、業界のボトルネックを突破できていません。真のブレークスルーは、従来の方法に悩まされてきた医療、製造業、物流などの業界から生まれるかもしれません。AIは、より効率的なデータ処理や予測分析を通じて、これらの複雑な状況下で企業の効率向上とコスト削減に貢献できるでしょう。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;申し訳ありませんが、翻訳する中国語のテキストが提供されていません。テキストを提供してください。
Dockerのように、コンテナ化プロセスを簡略化して運用効率を高めるように、AIプロダクトの使いやすさも同様に重要です。AIの普及は技術の普及であると同時に、製品化の普及でもあります。AIを日常業務に統合し、ユーザーが深い技術理解なしにこれらのツールを簡単に使えるようにすることが、AIを実用化するための重要な一歩です。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;申し訳ありませんが、翻訳する中国語のテキストが提供されていません。テキストを提供してください。
新しい技術の広範な応用は、エコシステムの構築なしには成り立ちません。Dockerが急速に台頭できたのは、そのオープン性と互換性のおかげで、開発者が様々なクラウドプラットフォーム、ツール、サービスとの連携を容易にできたからです。同様に、AIの未来もエコシステム構築にかかっています。AIの標準化、モデルの共有、データの公開、そして技術の統合性は、AIが広範な産業応用を形成するかどうかを左右します。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;結論aiの未来は可能性に満ちているがより完善した着地点が必要である&#34;&gt;結論：AIの未来は可能性に満ちているが、より完善した着地点が必要である。
&lt;/h2&gt;&lt;p&gt;AI技術はここ2年で目覚ましい進歩を遂げたものの、現状では「決定版アプリケーション」とは言えない段階です。Dockerの登場以前のコンテナ化技術と同様に、AIも現実的な応用シナリオを見出し、既存技術とビジネスニーズを深く融合させることで初めて大規模な展開と普及を実現できます。技術革新は重要ですが、プロセスを簡素化し効率を高めるソリューションこそが、技術の普及と発展を促進します。&lt;/p&gt;
&lt;p&gt;未来、AIはDockerのように、画期的な技術革新ではなく、既存技術の統合によって完璧なアプリケーションシーンを構築し、最終的に私たちの仕事や生活様式を変える可能性がある。&lt;/p&gt;</description>
        </item>
        <item>
        <title>ローカルにDeepSeek-R1をデプロイ</title>
        <link>https://blog.ttf248.life/ja/p/ollama-local-deployment-deepseek-r1/</link>
        <pubDate>Fri, 07 Feb 2025 22:41:02 +0800</pubDate>
        
        <guid>https://blog.ttf248.life/ja/p/ollama-local-deployment-deepseek-r1/</guid>
        <description>&lt;p&gt;Ollamaは、ユーザーがローカルで大規模言語モデル（LLM）を実行・デプロイできるように設計されたオープンソースのAIツールです。クラウドサービスに依存することなく、GPTのようなモデルをローカルマシン上で利用するための、便利で効率的な方法を提供し、様々なモデルに対応しています。また、パフォーマンスの最適化に重点を置いており、リソースが限られたデバイスでもスムーズに動作するようにしています。&lt;/p&gt;
&lt;p&gt;Ollama を使用すれば、ユーザーはテキストベースのAIアプリケーションを利用でき、データプライバシーや高額なAPI利用料金を心配することなく、ローカルにデプロイされたモデルと対話できます。様々なモデルをコマンドラインインターフェース（CLI）から呼び出し、自然言語処理や質問応答などのタスクを実行できます。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Ollamaは様々なモデルの試用に向いていますが、Windows版をテストしたところ、ハードウェアの性能を十分に発揮できませんでした。原因はWindows版にあるのかもしれません。Linux版の方が良いかもしれません。32bパラメータのモデルをデプロイしても、メモリやGPUの負荷が低いにも関わらず、応答速度が非常に遅いです。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;ハードウェア概要&#34;&gt;ハードウェア概要
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;OS：Win11&lt;/li&gt;
&lt;li&gt;CPU：i7-10700K&lt;/li&gt;
&lt;li&gt;メモリ：40GB&lt;/li&gt;
&lt;li&gt;グラフィックボード：RTX 3060 12GB&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;環境準備&#34;&gt;環境準備
&lt;/h2&gt;&lt;p&gt;新たにシステム環境変数を追加し、今後の利用を容易にします。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_MODELS=E:\ollama&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
この変数は、Ollamaモデルの保存パスを指定します。&lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; はフォルダパスであり、すべてのローカルモデルファイルがそのディレクトリに格納されます。Ollamaは、このパスに基づいてダウンロードまたはデプロイした言語モデルを読み込み使用します。モデルファイルを別の場所に保存する場合は、このパスを変更するだけです。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_HOST=127.0.0.1:8000&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
この環境変数は、Ollama サービスが利用するホストとポートを設定します。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; はローカルアドレス（localhost）を意味し、Ollama サービスはローカルからのリクエストのみを待ち受けます。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; は、指定されたポート番号で、Ollamaサービスが8000ポートでリクエストを待機し処理することを示します。必要に応じてポート番号を変更できますが、そのポートが他のアプリケーションによって使用されていないことを確認してください。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_ORIGINS=*&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
この環境変数は、Ollama サービスにアクセスできるリクエストのソースを制御します。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;あらゆるソース（すべてのドメインとIPアドレス）からのアクセスを許可します。これは通常、開発およびデバッグ環境で使用され、本番環境ではセキュリティを高めるために、特定のドメインまたはIPのみがサービスにアクセスできるように制限することが一般的です。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;deepseek-r1-モデルのデプロイ&#34;&gt;DeepSeek-R1 モデルのデプロイ
&lt;/h2&gt;&lt;p&gt;インストールは簡単ですので、詳細は割愛します。&lt;/p&gt;
&lt;p&gt;インストール後の検証：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core&amp;gt;ollama -v
ollama version is 0.5.11
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;モデルのデプロイについては、公式ウェブサイトのモデルページを参照し、対応するパラメータを持つモデルを選択してください。&lt;/p&gt;
&lt;p&gt;14bパラメータは会話コンテキストを効果的に記憶できるが、より小さいパラメータのバージョンでは記憶できない。32bパラメータ版はローカル環境での動作が重く、さらなるテストは実施していない。&lt;/p&gt;
&lt;h2 id=&#34;参照資料&#34;&gt;参照資料
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ollama.com/library/deepseek-r1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.ollama.com/library/deepseek-r1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/x18990027/article/details/145368094&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/x18990027/article/details/145368094&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>ディープシーク、春節前に急成長、NVIDIA株が暴落：背景にある機関投資家の動きと大規模言語モデルの推論チェーン</title>
        <link>https://blog.ttf248.life/ja/p/deepseek-chinese-new-year-nvidia-stock-drop-institutional-operations-large-language-model-chain/</link>
        <pubDate>Fri, 07 Feb 2025 20:36:05 +0800</pubDate>
        
        <guid>https://blog.ttf248.life/ja/p/deepseek-chinese-new-year-nvidia-stock-drop-institutional-operations-large-language-model-chain/</guid>
        <description>&lt;p&gt;旧正月前夜、DeepSeekが一度話題の中心となり、数日のうちにSNSで広く注目を集めました。この突如の急上昇は驚くべきものであり、市場に連鎖的な反応を引き起こしました。一方、NVIDIA株は暴落し、多くの投資家がその見通しを疑心暗鬼に陥りました。一部機関は期間中に大規模な空売りを行い、まるで全てが「周到に計画された」状況を示唆しているかのようでした。&lt;/p&gt;
&lt;h3 id=&#34;申し訳ありませんが翻訳する中国語のテキストが提供されていませんテキストを提供してください&#34;&gt;申し訳ありませんが、翻訳する中国語のテキストが提供されていません。テキストを提供してください。
&lt;/h3&gt;&lt;p&gt;DeepSeekは、深層学習モデルの最適化に特化したAIツールであり、特に自然言語処理（NLP）や画像生成分野での応用を重視しています。旧正月の数日前、このプロジェクトは突如として多くの投資家や技術者の注目を集めました。その開発チームの実績と技術成果が、多くの人々から強い関心を引き起こしました。開発者コミュニティはもちろんのこと、ソーシャルメディアプラットフォームにおいても、DeepSeekに関する議論が技術界の話題を席巻しています。&lt;/p&gt;
&lt;p&gt;しかし、DeepSeekの突如たる爆発的な人気は偶然ではない。分析の結果、多くの人が背後に何らかの組織の操作が関与しているのではないかと疑い始めている。特に、その人気に沸騰した後、NVIDIA株価が著しい下落を見せていることから、明らかに何らかの要因がこの変化を促していることが見て取れる。&lt;/p&gt;
&lt;h3 id=&#34;申し訳ありませんが翻訳する中国語のテキストが提供されていませんテキストを提供してください-1&#34;&gt;申し訳ありませんが、翻訳する中国語のテキストが提供されていません。テキストを提供してください。
&lt;/h3&gt;&lt;p&gt;NVIDIAは、世界をリードするGPUメーカーであり、長らく大規模モデルやAI計算の主要なハードウェアサプライヤーとして機能してきました。AI市場の急速な成長とともに、同社の株価は長期的に好調で、多くの投資家の注目を集めていましたが、DeepSeekの急上昇と市場からの高い関心により、NVIDIA株は暴落しました。&lt;/p&gt;
&lt;p&gt;この現象の背景には、機関投資家の空売り戦略が関わっているかもしれない。近年、AI技術の普及に伴い、NVIDIA株価は大きく上昇し、多くの投資家が過剰なバブルのリスクを感じ始めていた。特にDeepSeekのような技術が爆発的に広まった後、一部の機関はNVIDIA株を空売りすることで、大きな利益を得た可能性がある。正確な市場タイミングの把握とDeepSeekの影響力への予測により、彼らは成功裏に利益を上げた。&lt;/p&gt;
&lt;h3 id=&#34;申し訳ありませんが翻訳する中国語のテキストが提供されていませんテキストを提供してください-2&#34;&gt;申し訳ありませんが、翻訳する中国語のテキストが提供されていません。テキストを提供してください。
&lt;/h3&gt;&lt;p&gt;伝統的なAI応用では、多くの専門家や投資家は生成された画像やテキストといったAIモデルの「結果」に注目していましたが、DeepSeekに関連する議論の中で、より多くの人々が、大規模言語モデル（LLM）背後にある推論連鎖こそが、より注力すべき核心的内容であることに気づき始めています。これまで私たちはモデルの出力結果しか見ることができませんでしたが、今やその背後にあるロジック、アルゴリズムを理解し、これらの要素を調整してモデルのパフォーマンスを最適化することが求められています。&lt;/p&gt;
&lt;p&gt;この思考様式の転換は、AI研究と応用に対する深い考察と言えるでしょう。単純なブラックボックス操作から、モデル内部の動作メカニズムを真に理解することへの転換は、多くの技術者や投資家が人工知能の将来的な発展方向を改めて見直すきっかけとなりました。DeepSeek の人気は、まさにこの思考の突破口であり、人々は最終的な出力結果だけでなく、モデル全体の構築と最適化プロセスに関心を向けるようになりました。&lt;/p&gt;
&lt;h3 id=&#34;申し訳ありませんが翻訳する中国語のテキストが提供されていませんテキストを提供してください-3&#34;&gt;申し訳ありませんが、翻訳する中国語のテキストが提供されていません。テキストを提供してください。
&lt;/h3&gt;&lt;p&gt;DeepSeekの急激な人気、NVIDIA株式の大幅下落、そして市場背景にある機関投資家の空売り操作。これらはすべて、巧妙に仕組まれた陰謀なのかもしれません。大規模言語モデルの思考回路を深く理解することで、AI技術の応用は単なる表面的な積み重ねではなく、モデル内部の論理を探求し最適化することであることが分かります。技術の進歩に伴い、今後DeepSeekのような革新的なツールがさらに多く登場し、AI研究と応用の発展を新たな高みに導くことが期待されます。&lt;/p&gt;
&lt;p&gt;この現象は、AI技術の巨大な可能性を私たちに見せてくれるだけでなく、その背景にあるビジネス対立や資本運用のあり方を考えさせるものとなりました。今後の市場動向は、技術と資本との駆け引きの継続的な注目点となるでしょう。&lt;/p&gt;</description>
        </item>
        <item>
        <title>Cursor AI プログラミングIDE 体験版</title>
        <link>https://blog.ttf248.life/ja/p/cursor-ai-programming-ide-trial/</link>
        <pubDate>Thu, 23 Jan 2025 19:30:13 +0800</pubDate>
        
        <guid>https://blog.ttf248.life/ja/p/cursor-ai-programming-ide-trial/</guid>
        <description>&lt;p&gt;あっという間に一年が過ぎ、仕事において最も大きな変化は、やはりAIの関与が顕著に高まっていることだ。これまで、開発言語間の切り替えには、それぞれの言語特有のAPIインターフェースを理解する必要があったが、今ではこれらの基礎コードもAIによって生成されるようになった。これは開発者にとって非常にありがたいことだ。&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;23年にも簡単な入門記事を2つほど書いた頃から、気がつけばもう25年。目に見えるような進歩は感じられず、自分自身の理解を確立し、タスクを適切に分割でき、何よりもAI生成コードのバグを見抜くことが重要だ。&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;Github copilot
&lt;/h2&gt;&lt;p&gt;いつだったか覚えていないが、シンガポールにサーバーを設置したという資料を見た。これにより、ローカルで利用でき、それ以来、長期間VPNを使用する必要はなくなった。ログイン時のみVPNが必要だが、ログイン後であれば閉じることもできる。&lt;/p&gt;
&lt;p&gt;普段使いでは、より多くの場合は Github Copilot を使っています。このプラグインは、VS Code や Visual Studio で直接使用でき、2つのソフトウェア間での切り替えが不要です。ChatGPT と比較して、Github Copilot の方がプロジェクトのサポートが充実しており、操作性も優れています。さらに、ローカルファイルの一部を &lt;strong&gt;“训练”AI&lt;/strong&gt; として提供することで、プロジェクトに合ったコードを生成できます。&lt;/p&gt;
&lt;h2 id=&#34;cursor-ai&#34;&gt;Cursor AI
&lt;/h2&gt;&lt;p&gt;最近、新しいAIプログラミングIDEのCursor AIを見ました。このIDEはGithub Copilotをベースにしていますが、さらにスマートで、ファイル作成も支援してくれます。&lt;/p&gt;
&lt;p&gt;軽く使ってみたところ、まだ悪くない感じだが、既存プロジェクトの理解はまだ足りない。ローカルプロジェクトファイルが多い場合や、大規模なリファクタリング・最適化調整には、やはり&lt;strong&gt;开发者拆分任务&lt;/strong&gt;が必要だ。&lt;/p&gt;
&lt;p&gt;curso のプロジェクトに切り替えて、以下の内容を入力してください：個人用履歴書ウェブページの作成、複数の異なるスタイルへの切り替えをサポートし、データ表示用の個人情報を忘れずに埋めてください。&lt;/p&gt;
&lt;p&gt;何度か試行錯誤をすれば、次のようなウェブページを入手できます。もちろん、このウェブページはまだシンプルですが、初心者には良いでしょう。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;現在、新規登録ユーザーは高機能APIを150回無料で試用できます。有料ユーザーは高機能APIの利用回数が5000回に制限されます。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;申し訳ありませんが、翻訳する中国語のテキストが提供されていません。テキストを提供していただければ、日本語に翻訳します。&lt;/p&gt;</description>
        </item>
        <item>
        <title>AIプログラミングとタスク分解</title>
        <link>https://blog.ttf248.life/ja/p/ai-programming-and-task-decomposition/</link>
        <pubDate>Fri, 22 Dec 2023 08:44:26 +0800</pubDate>
        
        <guid>https://blog.ttf248.life/ja/p/ai-programming-and-task-decomposition/</guid>
        <description>&lt;p&gt;2年前にサイトに追加したコード領域のコピー機能の開発で、あれほど手間取ったのに、最終的な表示は少し期待外れだった。半熟前任開発者として、動けば良いやと諦め、そのままにしてきた。今年は__INLINE_CODE_0__で小程序を開発し、フロントエンド開発にも慣れたので、改めて（AIによる再設計）。&lt;/p&gt;
&lt;p&gt;悟道：任務分解され、多くの小任務が __INLINE_CODE_0__开发起来还是顺手的。已经倒闭的小程序，__INLINE_CODE_1__BOLD_5&lt;code&gt;AI&lt;/code&gt;提供，拆解了多个任务交付，人工进行项目代码的&lt;code&gt;组装&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&#34;前文&#34;&gt;前文
&lt;/h2&gt;&lt;p&gt;申し訳ありませんが、翻訳する中国語のテキストが提供されていません。テキストを提供していただければ、日本語に翻訳します。&lt;/p&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文
&lt;/h2&gt;&lt;p&gt;CSSとJavaScriptのコードを設計し、class=&amp;ldquo;highlight&amp;rdquo; のウェブ要素を特定。その要素のコンテナ内にコピーボタンを追加し、コードをコピーする機能を実装する。&lt;/p&gt;
&lt;p&gt;最初の草稿のコードには問題があり、再生成した草稿はほぼ使用可能だが、コピー元の内容が正しくなく、重複するテキストが含まれている。再度最適化を促し、手動で主要なカラーデザインと適用されるエフェクトを指定する必要がある。&lt;/p&gt;
&lt;p&gt;ボタンのサイズと色に関して特定の要件があるとのこと、承知いたしました。これらの要件に合わせてボタンのデザインを再設計できます。以下に、ご提示いただいたカラースキームを取り入れ、ボタンのサイズを最適化した調整後のCSSスタイルを示します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.copy-btn {
  position: absolute;
  top: 2px; /* 调整位置 */
  right: 2px;
  padding: 3px 6px; /* 缩小尺寸 */
  font-size: 12px; /* 减小字体大小 */
  background-color: #8FD1E1; /* 按钮背景色 */
  color: #272822; /* 文字颜色 */
  border: 1px solid #272822; /* 边框颜色 */
  border-radius: 3px; /* 圆角 */
  cursor: pointer;
  opacity: 0.7; /* 默认半透明 */
  transition: opacity 0.3s ease, background-color 0.3s ease; /* 平滑过渡效果 */
}

.copy-btn:hover {
  opacity: 1; /* 鼠标悬停时不透明 */
  background-color: #A3D4E5; /* 鼠标悬停时的背景色 */
}

.highlight {
  position: relative;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;このスタイルでは、ボタンのサイズとフォントサイズを小さくし、より洗練された印象にしました。また、ボタンのデフォルト状態は半透明で、マウスオーバー時に不透明になり、背景色がわずかに明るくなることで視覚的なフィードバックを提供します。このようなデザインは、お客様の色に関する要件を満たしつつ、モダンさとユーザビリティを維持しています。&lt;/p&gt;
&lt;p&gt;対応する、より簡単なものを提示しました。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-JavaScript&#34;&gt;document.addEventListener(&#39;DOMContentLoaded&#39;, function() {
  // 查找所有 .highlight 元素
  const highlights = document.querySelectorAll(&#39;.highlight&#39;);

  highlights.forEach(function(highlight) {
    // 创建复制按钮
    const copyBtn = document.createElement(&#39;button&#39;);
    copyBtn.textContent = &#39;复制&#39;;
    copyBtn.classList.add(&#39;copy-btn&#39;);

    // 将按钮添加到每个 .highlight 元素中
    highlight.appendChild(copyBtn);

    // 添加点击事件监听器
    copyBtn.addEventListener(&#39;click&#39;, function() {
      // 假设 .highlight 下的第一个 &amp;lt;code&amp;gt; 元素包含要复制的代码
      const code = highlight.querySelector(&#39;code&#39;) ? highlight.querySelector(&#39;code&#39;).textContent : &#39;&#39;;

      navigator.clipboard.writeText(code).then(() =&amp;gt; {
        // 显示复制成功信息
        copyBtn.textContent = &#39;已复制!&#39;;
        setTimeout(() =&amp;gt; {
          copyBtn.textContent = &#39;复制&#39;;
        }, 2000);
      }).catch(err =&amp;gt; {
        console.error(&#39;复制失败: &#39;, err);
      });
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;追記&#34;&gt;追記
&lt;/h2&gt;&lt;p&gt;コード領域の右上、上部にコピーボタンを追加することを期待していたのですが、フロントエンドについて十分な理解がないため、キーワードで正確に機能を説明できず、&lt;code&gt;AI&lt;/code&gt; と何度かやり取りしても、期待通りの結果が得られませんでした。&lt;/p&gt;
&lt;p&gt;時間の経過とともに、&lt;code&gt;AI&lt;/code&gt;がプログラミングにどの程度影響を与えるか、まだわからない。&lt;/p&gt;</description>
        </item>
        <item>
        <title>プロンプトエンジニア</title>
        <link>https://blog.ttf248.life/ja/p/prompt-engineer/</link>
        <pubDate>Sun, 26 Mar 2023 20:46:53 +0800</pubDate>
        
        <guid>https://blog.ttf248.life/ja/p/prompt-engineer/</guid>
        <description>&lt;p&gt;まるで昔に検索エンジンのテクニックを学ぶように、私たちも&lt;code&gt;AI&lt;/code&gt;とのコミュニケーションのコツを学び、合理的かつ十分な条件を設定し、必要な答えを効率的に得る必要がある。&lt;/p&gt;
&lt;p&gt;もし別の視点から考えてみたら、現在の強調表示は期待通りの結果を生むでしょう。&lt;/p&gt;
&lt;h2 id=&#34;科学解説&#34;&gt;科学解説
&lt;/h2&gt;&lt;p&gt;火出天际的&lt;code&gt;AI&lt;/code&gt;BOLD_2&lt;code&gt;Generative Pre-Training&lt;/code&gt;とは、直訳すると生成事前学習です。これは、インターネットで利用可能なデータで訓練されたテキスト生成深層学習モデルであり、質問応答、テキスト要約の生成、機械翻訳、分類、コード生成、対話AIなどのタスクに使用されます。現在ではGPT-1、GPT-2、GPT-3、GPT-4など、さまざまなバージョンのモデルが存在し、各バージョンは前のバージョンよりも大きく、強力です。&lt;/p&gt;
&lt;h2 id=&#34;結局知能は存在するのか&#34;&gt;結局、知能は存在するのか。
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;類似度が十分高いほど、精度も上がる。&lt;/li&gt;
&lt;li&gt;基本的な、反復作業は、特定の訓練を経れば、これ以上の人的介入は不要となる。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;生成AIとは、既存のテキスト、音声、画像などのデータを利用して新しいコンテンツを生成する技術です。テキスト生成、音声合成、画像生成、対話システムなど、様々なタスクに利用できます。生成AIの論理性は、学習データとモデル構造に依存します。一般的に、生成AIは文法、論理、常識をある程度遵守できますが、誤りや偏見、虚偽の内容を生み出す可能性もあります。そのため、生成AIの出力には人間の判断と検証が必要であり、盲目的に信じたり使用したりすることはできません。&lt;/p&gt;
&lt;h2 id=&#34;プロンプトエンジニア&#34;&gt;プロンプトエンジニア
&lt;/h2&gt;&lt;p&gt;時間が流れ去ることはないから、人は時代の流れに適応する必要がある。あなたはそれを__INLINE_CODE_0__を非論理的だと考えられるかもしれないし、役に立たないコードを生成することがよくある。&lt;/p&gt;
&lt;p&gt;もし別の視点から考えてみたら、現在の強調表示は期待通りの結果を生むでしょう。&lt;/p&gt;
&lt;h2 id=&#34;会話モード&#34;&gt;会話モード
&lt;/h2&gt;&lt;p&gt;2年前に、大胆に登場し、人類は大規模言語モデルの能力を認識した。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;基于注释的编程&lt;/strong&gt;と&lt;strong&gt;基于对话的编程&lt;/strong&gt;に基づき、インタラクションの論理は完全に異なり、会話のパターンも、初心者ユーザーにとって使いやすい体験を提供します。ここに必ず&lt;code&gt;NewBing&lt;/code&gt;在每个问题之后，给出的追问提示，微软在尝试引导用户，获取&lt;code&gt;AI&lt;/code&gt;知識ベース内の、より多くのコンテンツについて言及する必要があります。&lt;/p&gt;
&lt;h2 id=&#34;例えば&#34;&gt;例えば
&lt;/h2&gt;&lt;p&gt;高速鉄道の移動時間は長く、コーディングは良い選択だ。データ通信量が限られているので、画像を数枚処理し、画像素材を入手したが、ソフトウェアをダウンロードして画像を処理するのは少し贅沢すぎるし、ネットワーク環境もそれを許さない。&lt;/p&gt;
&lt;p&gt;画像素材がいくつかあり、それらは透明な背景の画像で、ミニプログラムのナビゲーションバーに使用されます。選択された状態はカラー、未選択の状態は白黒です。素材自体はカラーなので、前処理が必要です。&lt;/p&gt;
&lt;p&gt;フォルダ内のすべての画像を読み込み、モノクロに変換し、透明な背景を維持した上で、品質を最適化してファイルサイズを縮小した画像を保存するPythonコードを作成してください。また、コンソールには変換前のファイルサイズと変換後のファイルサイズの比較を表示してください。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 导入必要的库
import os
import PIL
from PIL import Image

# 定义一个函数，将图片转换成黑白，维持透明背景，保存图片，并返回文件体积
def convert_and_save(image_file):
    # 打开图片
    image = Image.open(image_file)
    # 获取图片的模式，如果是 RGBA 模式，说明有透明背景
    mode = image.mode
    if mode == &amp;quot;RGBA&amp;quot;:
        # 创建一个和图片大小一致的白色背景图片
        background = Image.new(&amp;quot;RGB&amp;quot;, image.size, (255, 255, 255))
        # 将原图片粘贴到白色背景上，忽略透明像素
        background.paste(image, mask=image.split()[3])
        # 将合成的图片转换成灰度模式
        gray_image = background.convert(&amp;quot;L&amp;quot;)
        # 将灰度图片再转换成 RGBA 模式，以便保留透明背景
        final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
    else:
        # 如果不是 RGBA 模式，直接将图片转换成灰度模式
        final_image = image.convert(&amp;quot;L&amp;quot;)
    # 获取原图片的文件名和扩展名
    file_name, file_ext = os.path.splitext(image_file)
    # 定义新图片的文件名，添加 _bw 后缀表示黑白
    new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # 保存新图片，并优化质量，减少文件体积
    final_image.save(new_file_name, optimize=True)
    # 获取原图片和新图片的文件体积，并返回
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return old_size, new_size

# 定义一个文件夹路径，存放所有的图片
folder_path = &amp;quot;images&amp;quot;
# 遍历文件夹中的所有文件
for file in os.listdir(folder_path):
    # 拼接完整的文件路径
    file_path = os.path.join(folder_path, file)
    # 判断是否是图片文件，根据扩展名判断，可以根据需要添加或修改扩展名
    if file_path.endswith((&amp;quot;.png&amp;quot;, &amp;quot;.jpg&amp;quot;, &amp;quot;.jpeg&amp;quot;, &amp;quot;.gif&amp;quot;)):
        # 调用函数，转换并保存图片，并获取文件体积
        old_size, new_size = convert_and_save(file_path)
        # 在控制台展示优化前后的文件体积大小对比
        print(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;すぐに回答しましたが、見た目は良く、問題なく動作します。経験豊富なプログラマーなら、下記のコードが汎用的ではなく、本番環境には向かないと感じるでしょう。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;パラメータが固定されました。&lt;/li&gt;
&lt;li&gt;ログファイルはなく、情報はコンソールに出力されています。&lt;/li&gt;
&lt;li&gt;画像処理のタスクは、マルチスレッドモデルに適しています。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;このコードの改善点はありますか？&lt;/p&gt;
&lt;p&gt;今回提示された回答は、正直言って期待を遥かに上回っています。一般的なプログラマーが思いつくような最適化策についても、それぞれ対応する提案が示されています。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;这段代码可能还有一些可以改进的地方，比如：

可以使用 argparse 库，让用户可以通过命令行参数指定文件夹路径和扩展名，而不是写死在代码里。
可以使用 logging 库，记录程序的运行情况，而不是直接打印到控制台。
可以使用 try-except 语句，捕获可能出现的异常，比如文件打开失败，图片转换失败等，并做相应的处理。
可以使用 multiprocessing 库，利用多核处理器，加速图片的转换和保存过程。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;非常にフレンドリーな対応で、デプロイ環境の違いを考慮し、マルチプロセス非対応を許可しています。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;当然，我很乐意帮你修改一下代码。我尝试添加了 argparse, logging 和 try-except 语句，但没有添加 multiprocessing 库，因为我不确定你的电脑是否支持多核处理。修改后的代码如下：
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 导入必要的库
import argparse
import logging
import multiprocessing
import os

from PIL import Image


# 定义一个函数，将图片转换成黑白，维持透明背景，保存图片，并返回文件体积
def convert_and_save(image_file):
    # 打开图片
    try:
        image = Image.open(image_file)
    except Exception as e:
        logging.error(f&amp;quot;Failed to open {image_file}: {e}&amp;quot;)
        return None, None
    # 获取图片的模式，如果是 RGBA 模式，说明有透明背景
    mode = image.mode
    if mode == &amp;quot;RGBA&amp;quot;:
        # 创建一个和图片大小一致的白色背景图片
        background = Image.new(&amp;quot;RGB&amp;quot;, image.size, (255, 255, 255))
        # 将原图片粘贴到白色背景上，忽略透明像素
        background.paste(image, mask=image.split()[3])
        # 将合成的图片转换成灰度模式
        gray_image = background.convert(&amp;quot;L&amp;quot;)
        # 将灰度图片再转换成 RGBA 模式，以便保留透明背景
        final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
    else:
        # 如果不是 RGBA 模式，直接将图片转换成灰度模式
        final_image = image.convert(&amp;quot;L&amp;quot;)
    # 获取原图片的文件名和扩展名
    file_name, file_ext = os.path.splitext(image_file)
    # 定义新图片的文件名，添加 _bw 后缀表示黑白
    new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # 保存新图片，并优化质量，减少文件体积
    try:
        final_image.save(new_file_name, optimize=True)
    except Exception as e:
        logging.error(f&amp;quot;Failed to save {new_file_name}: {e}&amp;quot;)
        return None, None
    # 获取原图片和新图片的文件体积，并返回
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return file_name, old_size, new_size

# 定义一个函数，解析命令行参数，并返回文件夹路径和扩展名列表
def parse_args():
    # 创建一个解析器对象
    parser = argparse.ArgumentParser(description=&amp;quot;Convert images to black and white and optimize quality.&amp;quot;)
    # 添加一个必选的位置参数，表示文件夹路径
    parser.add_argument(&amp;quot;folder_path&amp;quot;, help=&amp;quot;The path of the folder that contains the images.&amp;quot;)
    # 添加一个可选的参数，表示扩展名列表，默认为 png, jpg, jpeg 和 gif
    parser.add_argument(&amp;quot;-e&amp;quot;, &amp;quot;--extensions&amp;quot;, nargs=&amp;quot;+&amp;quot;, default=[&amp;quot;.png&amp;quot;, &amp;quot;.jpg&amp;quot;, &amp;quot;.jpeg&amp;quot;, &amp;quot;.gif&amp;quot;], help=&amp;quot;The extensions of the image files.&amp;quot;)
    # 解析命令行参数，并返回结果对象
    args = parser.parse_args()
    return args.folder_path, args.extensions

# 定义一个函数，打印优化前后的文件体积大小对比
def print_result(result):
    # 如果结果不为空，说明转换和保存成功
    if result:
        # 解包结果为文件名和文件体积元组
        if len(result) == 3:
            file, old_size, new_size = result
            # 在控制台展示优化前后的文件体积大小对比
            logging.info(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)
        else:
            logging.info(f&amp;quot;{result}&amp;quot;)

# 配置日志记录器，将日志输出到控制台和文件中，设置日志等级为 INFO
logging.basicConfig(level=logging.INFO,
                    format=&amp;quot;%(asctime)s %(levelname)s %(message)s&amp;quot;,
                    handlers=[logging.StreamHandler(),
                              logging.FileHandler(&amp;quot;log.txt&amp;quot;)])

# 调用函数，获取文件夹路径和扩展名列表
folder_path, extensions = parse_args()

if __name__ == &amp;quot;__main__&amp;quot;:
    # Windows 需要这个函数的原因是 Windows 缺乏 fork() 函数（这不完全正确）。
    # 因此，在 Windows 上，fork() 是通过创建一个新的进程来模拟的，这个新的进程中运行的代码，在 Linux 上是在子进程中运行的。
    # 由于这些代码要在技术上无关的进程中运行，所以它必须在运行之前被传递到那里。
    # 传递的方式是先将它们序列化，然后通过管道从原始进程发送到新的进程。
    # 另外，这个新的进程被通知它必须运行通过管道传递的代码，通过向它传递 --multiprocessing-fork 命令行参数。
    # 如果你看一下 freeze_support() 函数的实现，它的任务是检查它运行在哪个进程中，是否应该运行通过管道传递的代码
    multiprocessing.freeze_support()

    # 创建一个进程池，根据电脑的核心数自动分配进程
    pool = multiprocessing.Pool()
    # 创建一个空列表，用于存放异步任务的结果对象
    results = []
    # 遍历文件夹中的所有文件
    for file in os.listdir(folder_path):
        # 拼接完整的文件路径
        file_path = os.path.join(folder_path, file)
        # 判断是否是图片文件，根据扩展名判断，可以根据需要修改扩展名列表
        if any(file_path.endswith(ext) for ext in extensions):
            # 调用函数，转换并保存图片，并获取文件体积，使用异步方式，不阻塞主进程
            result = pool.apply_async(convert_and_save, args=(file_path,), callback=print_result)
            # 将结果对象添加到列表中
            results.append((file, result))
    # 关闭进程池，不再接受新的任务
    pool.close()
    # 等待所有的任务完成
    pool.join()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;追記&#34;&gt;追記
&lt;/h2&gt;&lt;p&gt;ローカル開発で__BOLD_4&lt;code&gt;windows&lt;/code&gt;第一次给出的答案，并没有加上&lt;code&gt;AI&lt;/code&gt;BOLD_6&lt;code&gt;main&lt;/code&gt;第一次给出的答案，并没有加上&lt;code&gt;multiprocessing.freeze_support&lt;/code&gt;が発生し、エラー追跡によりコードを修正しました。&lt;/p&gt;
&lt;p&gt;まるで昔に検索エンジンのテクニックを学ぶように、私たちも__INLINE_CODE_0__とのコミュニケーションのコツを学び、合理的かつ十分な条件を設定し、必要な答えを効率的に得る必要がある。&lt;/p&gt;
&lt;p&gt;注意：&lt;/p&gt;</description>
        </item>
        <item>
        <title>AI支援によるプログラミング、生産性の進化</title>
        <link>https://blog.ttf248.life/ja/p/ai-assisted-programming-productivity-evolution/</link>
        <pubDate>Tue, 28 Feb 2023 17:05:17 +0800</pubDate>
        
        <guid>https://blog.ttf248.life/ja/p/ai-assisted-programming-productivity-evolution/</guid>
        <description>&lt;p&gt;&lt;strong&gt;斜体_3&lt;/strong&gt;**太字_2__斜体_4__が登場しました。仕組みはよく分かりませんが、しばらく使っています。両方のツールは生産性を大幅に向上させますが、サポートの面では全く異なります。&lt;/p&gt;
&lt;p&gt;複雑なことについては、効果はせいぜい9割程度だ。&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;github copilot
&lt;/h2&gt;&lt;p&gt;公開時に公式サイトの説明を拝見しましたが、あまり賢そうではありませんでした。試してみたものの、使い勝手が悪く、諦めました。&lt;/p&gt;
&lt;p&gt;2022年前、暇な時に新バージョンを試してみたら、すでに効果はなかなか良い。ただ、国内の速度が少し遅いのは、大概ネットワークの問題だろう。__INLINE_CODE_0__のような言語で、コメントを参照して書かれたコードはなかなか良く、自分で資料を探して書くよりもずっと速い。&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;まだプログラマー、つまり開発の視点から製品を設計している段階です。プログラミングの方法を理解し、コメントを通じてAIによる補助的なプログラミングを徐々に誘導する必要があります。&lt;/p&gt;
&lt;p&gt;専門家でなくてもすぐに使い始められる**。対話形式のチャットインターフェースなので、質問や要望を自由に伝えられます。分からないことがあれば、遠慮なく質問してください。&lt;/p&gt;
&lt;p&gt;単純な例で言うと、トークン化の概念は理解しているが、どのようにコーディングするか分からない。文字列の類似度を計算したい。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Python 分词计算 維天運通 LOGORY 和 合肥維天運通信息科技股份有限公司 两个字符串的相似度；
比较前，统一处理字符串，英文转换为小写；
第二个字符中如果能找到第一个字符的首字符，将第二个字符串截位，截位的长度为第一个字符串的长度
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;こんにちは、これはBingです。😊&lt;/p&gt;
&lt;p&gt;オンラインの情報によると123、Pythonの形態素解析には、jiebaライブラリを使用できます。jiebaライブラリは、厳密モード、全文モード、そして検索エンジンモードという3つの分かち込みモードをサポートしています。ニーズに合わせて適切なモードを選択してください。&lt;/p&gt;
&lt;p&gt;文字列の類似度を比較するためには、まず単語分割を行い、次に単語ベクトルや編集距離などの指標を計算する必要があります。numpy や scipy などのライブラリを使用して数学演算を行うことができます。&lt;/p&gt;
&lt;p&gt;文字列を統一的に処理するために、英字を小文字に変換するには、Pythonの組み込み関数lower()を使用できます。&lt;/p&gt;
&lt;p&gt;2番目の文字列を抽出するには、Pythonのスライス演算子[]を使用できます。&lt;/p&gt;
&lt;p&gt;以下はサンプルコードです。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import jieba
import numpy as np
from scipy.spatial.distance import cosine

# 定义两个字符串
str1 = &amp;quot;維天運通 LOGORY&amp;quot;
str2 = &amp;quot;合肥維天運通信息科技股份有限公司&amp;quot;

# 统一处理字符串，英文转换为小写
str1 = str1.lower()
str2 = str2.lower()

# 找到第二个字符串中第一个字符的位置
index = str2.find(str1[0])

# 如果找到了，截取第二个字符串
if index != -1:
    str2 = str2[index:index+len(str1)]

# 使用 jieba 库进行分词
words1 = list(jieba.cut(str1))
words2 = list(jieba.cut(str2))

# 计算两个字符串的词向量（以词频作为权重）
vector1 = np.zeros(len(words1))
vector2 = np.zeros(len(words1))

for i, word in enumerate(words1):
    vector1[i] += 1 # 统计第一个字符串中每个词出现的次数
    if word in words2:
        vector2[i] += 1 # 统计第二个字符串中每个词出现的次数

# 计算两个字符串的相似度（以余弦距离作为指标）
similarity = 1 - cosine(vector1, vector2)

print(&amp;quot;两个字符串的相似度是：&amp;quot;, similarity)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;申し訳ありませんが、翻訳する中国語のテキストが提供されていません。テキストを提供してください。&lt;/p&gt;
&lt;h3 id=&#34;栗&#34;&gt;栗
&lt;/h3&gt;&lt;p&gt;SQL文で、製品コード表から、製品コードが80000～89999の範囲にあるレコードを抽出してください。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;你好，这是 Bing。😊

根据搜索结果12，你可以使用 SQL BETWEEN 运算符来选择给定区间内的值。BETWEEN 运算符包含了开始和结束的值。

你需要先指定要查询的表名和列名，然后在 WHERE 子句中使用 BETWEEN 运算符和区间值。

例如，如果你要查询产品代码表中，产品代码在 80000 到 89999 之间的记录，你可以使用以下语句：

SELECT * FROM product_code
WHERE code BETWEEN 80000 AND 89999;
这里，* 表示选择所有列3。如果你只想选择特定的列，比如产品名称和价格，你可以用逗号分隔它们，如下：

SELECT name, price FROM product_code
WHERE code BETWEEN 80000 AND 89999;
希望这能帮助到你。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;引き続き質問し、否定してください。製品コードは文字列です。あなたのコードが間違っています。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;抱歉，我没有注意到产品代码是字符串。如果是这样的话，你需要在区间值两边加上单引号，如下：

SELECT * FROM product_code
WHERE code BETWEEN &#39;80000&#39; AND &#39;89999&#39;;
请原谅我的错误。🙏
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;おめでとうございます、間違えるでしょう。&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

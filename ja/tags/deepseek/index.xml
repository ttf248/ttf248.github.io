<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Deepseek on 向叔の手帳</title>
        <link>https://ttf248.life/ja/tags/deepseek/</link>
        <description>Recent content in Deepseek on 向叔の手帳</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>ja</language>
        <lastBuildDate>Mon, 02 Jun 2025 19:00:25 +0800</lastBuildDate><atom:link href="https://ttf248.life/ja/tags/deepseek/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>ollama ローカル実行 deepseek-R1</title>
        <link>https://ttf248.life/ja/p/ollama-local-deployment-deepseek-r1/</link>
        <pubDate>Fri, 07 Feb 2025 22:41:02 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ollama-local-deployment-deepseek-r1/</guid>
        <description>&lt;p&gt;Ollamaは、大規模言語モデル (LLM) をローカルで実行およびデプロイできるように設計されたオープンソースのAIツールです。クラウドサービスへの依存を減らし、開発者がローカルマシン上でGPTのようなモデルを使用するための便利な効率的な方法を提供することを目的としています。Ollamaは複数のモデルをサポートし、パフォーマンスを最適化することに重点を置いており、リソースが限られたデバイスでもこれらのモデルをスムーズに実行できるようにします。&lt;/p&gt;
&lt;p&gt;Ollamaを通じて、テキストベースのAIアプリケーションを使用でき、ローカルでデプロイされたモデルとインタラクションできます。データプライバシーやAPIの使用料金に関する懸念なくです。コマンドラインインターフェース (CLI) を使用してさまざまなモデルを呼び出し、自然言語処理、質問応答などのタスクを実行できます。 &amp;gt; ollama は様々なモデルを試すのに適しており、Windows 版でテストしたところ、ハードウェアの性能を十分に発揮することができませんでした。これは Windows 版の問題である可能性があり、Linux 版の方が良いかもしれません。32b パラメータのモデルをデプロイする際、メモリや GPU の負荷が低い状況でも、応答速度が遅い。&lt;/p&gt;
&lt;h2 id=&#34;ハードウェア概要&#34;&gt;ハードウェア概要
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;オペレーティングシステム: Windows 11&lt;/li&gt;
&lt;li&gt;CPU: i7-10700K&lt;/li&gt;
&lt;li&gt;メモリ: 40GB&lt;/li&gt;
&lt;li&gt;グラフィックカード: RTX 3060 12GB&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;環境準備&#34;&gt;環境準備
&lt;/h2&gt;&lt;p&gt;以下のシステム環境変数を設定し、後続の使用を容易にします：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_MODELS=E:\ollama&lt;/code&gt;&lt;/strong&gt;
この変数で Ollama モデルの保存パスを指定します。 &lt;code&gt;E:\ollama&lt;/code&gt; はフォルダパスであり、ダウンロードまたはデプロイしたローカルモデルファイルをすべてここに格納します。Ollama はこのパスに基づいてモデルをロードおよび使用します。モデルファイルの場所を変更する場合は、このパスを更新してください。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_HOST=127.0.0.1:8000&lt;/code&gt;&lt;/strong&gt;
この環境変数は Ollama サービスのホストとポートを設定します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;127.0.0.1&lt;/code&gt; はローカルアドレス（localhost）であり、Ollama サービスは本機からのリクエストのみを待ち受けます。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;8000&lt;/code&gt; は指定するポート番号であり、Ollama サービスが 8000 ポートでリクエストを受信および処理します。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;環境準備-1&#34;&gt;環境準備
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_ORIGINS=*&lt;/code&gt;&lt;/strong&gt;
この環境変数によって、Ollama サービスにアクセスできるリクエストのソースを制御します。
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;*&lt;/code&gt; はすべてのソース（つまり、すべてのドメインと IP アドレス）が Ollama サービスにアクセスできるようにすることを意味します。これは通常、開発およびデバッグ環境で使用され、本番環境では、セキュリティを高めるために特定のドメインまたは IP アドレスのみがサービスへのアクセスを許可するようにより厳格なソース制御を指定することが一般的です。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;deepseek-r1-モデルのデプロイ&#34;&gt;DeepSeek-R1 モデルのデプロイ
&lt;/h2&gt;&lt;p&gt;ollama のインストールは、初心者向けで簡単なため、詳細は省略します。
インストール後の検証：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core&amp;gt;ollama -v
ollama version is 0.5.11
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;モデルのデプロイについては、公式ウェブサイトのモデルページを参照し、対応するパラメータのモデルを選択してください: &lt;code&gt;ollama run deepseek-r1:14b&lt;/code&gt;
14b パラメータは会話コンテキストを効果的に記憶でき、より小さなパラメータバージョンではコンテキストを記憶できません。32b パラメータバージョンは、ローカルでのデプロイ時に非常に遅延するため、詳細なテストは行っていません。&lt;/p&gt;
&lt;h2 id=&#34;参考文献&#34;&gt;参考文献
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ollama.com/library/deepseek-r1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.ollama.com/library/deepseek-r1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/x18990027/article/details/145368094&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/x18990027/article/details/145368094&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>DeepSeek（ディープシーク）が旧正月前に急激に人気を博し、NVIDIAの株価が暴落した：その裏にある機関投資家の動きと大規模言語モデルの思考連鎖</title>
        <link>https://ttf248.life/ja/p/deepseek-explodes-before-chinese-new-year-nvidia-stock-plummets-behind-the-scenes-and-large-language-model-reasoning/</link>
        <pubDate>Fri, 07 Feb 2025 20:36:05 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/deepseek-explodes-before-chinese-new-year-nvidia-stock-plummets-behind-the-scenes-and-large-language-model-reasoning/</guid>
        <description>&lt;p&gt;旧正月前夕，DeepSeek 一度成为热门话题，短短几天内便在社交媒体上引起了广泛关注。这种突然的爆火，不仅让人惊讶，还带动了市场的连锁反应。与此同时，英伟达的股票却迎来了暴跌，许多投资者对其前景产生了疑虑，部分机构在此期间进行了大规模的做空操作，似乎一切都指向了一个“精心策划”的局面。&lt;/p&gt;
&lt;h3 id=&#34;deepseek-の爆発的な人気短期間で急速に注目を集める&#34;&gt;&lt;strong&gt;DeepSeek の爆発的な人気：短期間で急速に注目を集める&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;DeepSeek は、AI を活用したツールであり、特に自然言語処理（NLP）および画像生成分野における深層学習モデルの最適化に焦点を当てています。旧正月前の数日間、このプロジェクトは投資家や技術者から急増するほどの関心を集めました。その背後にあるチームのパフォーマンスと展示された技術成果が、多くの人々を強く惹きつけました。開発者コミュニティやソーシャルメディアプラットフォームにおいて、DeepSeek に関する議論は技術界全体のあらゆる話題を占めています。&lt;/p&gt;
&lt;p&gt;しかし、DeepSeek の突然爆発的な人気は偶然ではありませんでした。分析の結果、何らかの組織による操作の可能性が疑われるようになり始めました。&lt;/p&gt;
&lt;h3 id=&#34;nvidia-株価暴落ショート売り戦略の裏黒幕&#34;&gt;&lt;strong&gt;NVIDIA 株価暴落：ショート売り戦略の裏黒幕&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;NVIDIA（エヌビディア）、世界をリードするグラフィックス処理ユニット（GPU）メーカーは、長年にわたり、多くの大規模言語モデルやAI計算における重要なハードウェアサプライヤーとして存在感を示してきました。AI市場の急速な発展に伴い、NVIDIA の株価は長期にわたって堅調で、投資家の注目を集めてきました。しかし、DeepSeek の爆発的な人気と市場におけるその技術への高い関心により、NVIDIA の株価は急落しました。
この現象の裏には、機関投資家によるショート売り戦略が潜んでいる可能性があります。過去数年間、AI 技術の普及に伴い、NVIDIA の株価は過度に高騰しており、多くの投資家がその株価に過剰な期待を抱いていると認識していました。特に DeepSeek などの技術が爆発的に人気を集めた後、一部の機関投資家が NVIDIA の株式をショートすることで、かなりの利益を得た可能性があります。&lt;/p&gt;
&lt;h3 id=&#34;大規模言語モデルの推論チェーンへの接触結果からプロセスへ&#34;&gt;&lt;strong&gt;大規模言語モデルの推論チェーンへの接触：結果からプロセスへ&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;従来の人工知能アプリケーションにおいて、多くの実務者や投資家は、AI モデルの「結果」—生成された画像、テキストなどの直接的なアウトプットに多く注目してきました。一方、DeepSeekに関連する議論の中で、ますます多くの人が、大規模言語モデルの背後に隠された推論チェーンこそがより注目すべき核心内容であることに気づき始めています。これまで、私たちはモデルが出力した結果しか見ることができませんでしたが、今では、その背後にあるロジック、アルゴリズム、そしてこれらの要素を調整することでモデルのパフォーマンスを最適化する方法を理解する必要があります。&lt;/p&gt;
&lt;p&gt;この思考様式の転換は、AI 研究およびアプリケーションに対する深い考察であることを意味します。 単純なブラックボックス操作から、モデル内部の動作メカニズムを真正に理解する変革へと移行し、多くの技術者や投資家が人工知能の将来的な発展方向を再考し始めた。DeepSeek の爆発的な人気は、まさにこの思考連鎖の画期的な応用であり、人々が単なる最終的な出力結果ではなく、全体のモデル構築と最適化プロセスに注目し始めるきっかけとなった。&lt;/p&gt;
&lt;h3 id=&#34;まとめ&#34;&gt;&lt;strong&gt;まとめ&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;DeepSeekの突然的な爆発、英偉達株の大暴落、そして市場の裏で機関がショートしたという事実は、すべてが緻密に設計された罠であるかのようだ。大規模言語モデルの思考連鎖を深く理解することで、AI技術の応用は表面的な現象の積み重ねではなく、モデル内部ロジックの深い掘り起こしと最適化であることを認識できる。技術の進歩とともに、今後もDeepSeekのような革新的なツールが登場し、AI研究・応用がより高度なレベルへと発展していく可能性がある。&lt;/p&gt;
&lt;p&gt;この現象は、AI技術の巨大な潜在能力を私たちに示すだけでなく、技術背後にあるビジネスの駆け引きや資本の動きについても考えさせ始めるきっかけとなった。今後の市場の動向は、技術と資本の博弈という継続的な焦点となるだろう。&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>

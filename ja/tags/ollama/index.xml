<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Ollama on 向叔の手帳</title>
        <link>https://ttf248.life/ja/tags/ollama/</link>
        <description>Recent content in Ollama on 向叔の手帳</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>ja</language>
        <lastBuildDate>Mon, 02 Jun 2025 19:00:25 +0800</lastBuildDate><atom:link href="https://ttf248.life/ja/tags/ollama/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>ollama ローカル実行 deepseek-R1</title>
        <link>https://ttf248.life/ja/p/ollama-local-deployment-deepseek-r1/</link>
        <pubDate>Fri, 07 Feb 2025 22:41:02 +0800</pubDate>
        
        <guid>https://ttf248.life/ja/p/ollama-local-deployment-deepseek-r1/</guid>
        <description>&lt;p&gt;Ollamaは、大規模言語モデル (LLM) をローカルで実行およびデプロイできるように設計されたオープンソースのAIツールです。クラウドサービスへの依存を減らし、開発者がローカルマシン上でGPTのようなモデルを使用するための便利な効率的な方法を提供することを目的としています。Ollamaは複数のモデルをサポートし、パフォーマンスを最適化することに重点を置いており、リソースが限られたデバイスでもこれらのモデルをスムーズに実行できるようにします。&lt;/p&gt;
&lt;p&gt;Ollamaを通じて、テキストベースのAIアプリケーションを使用でき、ローカルでデプロイされたモデルとインタラクションできます。データプライバシーやAPIの使用料金に関する懸念なくです。コマンドラインインターフェース (CLI) を使用してさまざまなモデルを呼び出し、自然言語処理、質問応答などのタスクを実行できます。 &amp;gt; ollama は様々なモデルを試すのに適しており、Windows 版でテストしたところ、ハードウェアの性能を十分に発揮することができませんでした。これは Windows 版の問題である可能性があり、Linux 版の方が良いかもしれません。32b パラメータのモデルをデプロイする際、メモリや GPU の負荷が低い状況でも、応答速度が遅い。&lt;/p&gt;
&lt;h2 id=&#34;ハードウェア概要&#34;&gt;ハードウェア概要
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;オペレーティングシステム: Windows 11&lt;/li&gt;
&lt;li&gt;CPU: i7-10700K&lt;/li&gt;
&lt;li&gt;メモリ: 40GB&lt;/li&gt;
&lt;li&gt;グラフィックカード: RTX 3060 12GB&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;環境準備&#34;&gt;環境準備
&lt;/h2&gt;&lt;p&gt;以下のシステム環境変数を設定し、後続の使用を容易にします：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_MODELS=E:\ollama&lt;/code&gt;&lt;/strong&gt;
この変数で Ollama モデルの保存パスを指定します。 &lt;code&gt;E:\ollama&lt;/code&gt; はフォルダパスであり、ダウンロードまたはデプロイしたローカルモデルファイルをすべてここに格納します。Ollama はこのパスに基づいてモデルをロードおよび使用します。モデルファイルの場所を変更する場合は、このパスを更新してください。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_HOST=127.0.0.1:8000&lt;/code&gt;&lt;/strong&gt;
この環境変数は Ollama サービスのホストとポートを設定します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;127.0.0.1&lt;/code&gt; はローカルアドレス（localhost）であり、Ollama サービスは本機からのリクエストのみを待ち受けます。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;8000&lt;/code&gt; は指定するポート番号であり、Ollama サービスが 8000 ポートでリクエストを受信および処理します。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;環境準備-1&#34;&gt;環境準備
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_ORIGINS=*&lt;/code&gt;&lt;/strong&gt;
この環境変数によって、Ollama サービスにアクセスできるリクエストのソースを制御します。
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;*&lt;/code&gt; はすべてのソース（つまり、すべてのドメインと IP アドレス）が Ollama サービスにアクセスできるようにすることを意味します。これは通常、開発およびデバッグ環境で使用され、本番環境では、セキュリティを高めるために特定のドメインまたは IP アドレスのみがサービスへのアクセスを許可するようにより厳格なソース制御を指定することが一般的です。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;deepseek-r1-モデルのデプロイ&#34;&gt;DeepSeek-R1 モデルのデプロイ
&lt;/h2&gt;&lt;p&gt;ollama のインストールは、初心者向けで簡単なため、詳細は省略します。
インストール後の検証：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core&amp;gt;ollama -v
ollama version is 0.5.11
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;モデルのデプロイについては、公式ウェブサイトのモデルページを参照し、対応するパラメータのモデルを選択してください: &lt;code&gt;ollama run deepseek-r1:14b&lt;/code&gt;
14b パラメータは会話コンテキストを効果的に記憶でき、より小さなパラメータバージョンではコンテキストを記憶できません。32b パラメータバージョンは、ローカルでのデプロイ時に非常に遅延するため、詳細なテストは行っていません。&lt;/p&gt;
&lt;h2 id=&#34;参考文献&#34;&gt;参考文献
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ollama.com/library/deepseek-r1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.ollama.com/library/deepseek-r1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/x18990027/article/details/145368094&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/x18990027/article/details/145368094&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        
    </channel>
</rss>

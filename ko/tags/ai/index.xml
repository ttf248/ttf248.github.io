<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Ai on 향숙의 수첩</title>
        <link>https://ttf248.life/ko/tags/ai/</link>
        <description>Recent content in Ai on 향숙의 수첩</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>ko</language>
        <lastBuildDate>Mon, 26 May 2025 00:49:57 +0800</lastBuildDate><atom:link href="https://ttf248.life/ko/tags/ai/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>클로드4 출시, Hugo 태그 및 하이퍼링크 번역 도우미 개발 시도</title>
        <link>https://ttf248.life/ko/p/claude-4-release-and-experimentation-hugo-tags-hyperlink-translation-assistant/</link>
        <pubDate>Sat, 24 May 2025 03:05:31 +0800</pubDate>
        
        <guid>https://ttf248.life/ko/p/claude-4-release-and-experimentation-hugo-tags-hyperlink-translation-assistant/</guid>
        <description>&lt;p&gt;이 사이트는 hugo 기반이지만, 글 제목을 항상 중국어로 사용했기 때문에 생성되는 기사 링크가 친절하지 않습니다. 쉽게 말해서, 공유할 때 보기 좋지 않고, 중국어 문자가 링크에서 %E4%BD%A0%E5%A5%BD 와 같은 형태로 변환되기 때문입니다. 슬러그를 설정하여 해결할 수 있지만, 매번 수동으로 설정해야 해서 번거롭습니다.&lt;/p&gt;
&lt;p&gt;그래서 오늘 클로드4를 활용하여 중국어 제목을 영어 슬러그로 자동 변환하고, 기사에 하이퍼링크를 추가하는 번역 도우미를 개발해 보았습니다. 이렇게 하면 수동 설정의 번거로움을 피할 수 있습니다.&lt;/p&gt;
&lt;p&gt;클로드4는 정말 좋네요, 문맥 이해 능력과 복잡한 작업 처리 효율이 크게 향상되었습니다&lt;/p&gt;
&lt;p&gt;프로젝트 주소&lt;/p&gt;
&lt;p&gt;국내 프로젝트 주소: &lt;a class=&#34;link&#34; href=&#34;https://cnb.cool/ttf248/hugo-content-suite&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://cnb.cool/ttf248/hugo-content-suite&lt;/a&gt;
해외 프로젝트 주소: &lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/hugo-content-suite&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/hugo-content-suite&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;코드 구현&lt;/p&gt;
&lt;p&gt;먼저 구현 아이디어부터 설명드리자면, 모든 문서를 스캔하여 태그 정보와 문서 제목을 추출한 다음, 로컬 모델(예: gemma-3-12b-it)을 호출하여 번역합니다&lt;/p&gt;
&lt;p&gt;실제 개발에서 &lt;code&gt;Claude4&lt;/code&gt;는 이전 세대 대규모 언어 모델과 비교하여 몇 가지 뚜렷한 특징을 보여줍니다. 다양한 기능 요구 사항으로 인해 &lt;code&gt;Claude4&lt;/code&gt;는 자동 인터랙티브 메뉴를 설계하고, 모든 사용 시나리오를 포괄적으로 고려했습니다. 예를 들어, 태그 처리 측면에서 &lt;code&gt;Claude4&lt;/code&gt;는 태그의 통계 및 분석은 물론 분류 통계까지 지원하며, 심지어 &lt;strong&gt;비표시된 문서&lt;/strong&gt;도 감지할 수 있습니다. 또한 &lt;strong&gt;미리 보기&lt;/strong&gt;와 태그 페이지 생성 기능도 제공합니다.&lt;/p&gt;
&lt;p&gt;로컬 모델 연동, 번역 캐시 추가, 대규모 코드 리팩토링 등 무엇이든 한 번에 처리하며 거의 문제 없이 완료됩니다. 프로젝트 규모는 크지 않지만 다양한 기능들을 포함하고 있었는데, 기존의 거대 언어 모델들이 개발 과정에서 앞뒤 맥락을 잊는 경우가 많았지만 이번 &lt;code&gt;Claude4&lt;/code&gt;는 &lt;strong&gt;거의 맥락을 잊지 않았습니다.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;간단히 말해서, 지능이 향상되었고, 이후 개발 작업은 주력 모델로 일상 코딩에 활용하기 위해 &lt;code&gt;Claude4&lt;/code&gt;로 전환할 준비를 하고 있습니다&lt;/p&gt;
&lt;p&gt;번역 캐시&lt;/p&gt;
&lt;p&gt;이 점은 단독으로 볼 때, 거대 모델 호출 횟수를 줄이는 것 외에도 실제 로컬에서 12B 모델을 실행하면 효율이 괜찮고 업무를 방해하지 않지만, 매번 거대 모델을 호출해야 하면 조금 느려지는 경향이 있습니다. 또한, 기사의 연결을 고정하기 위해 전체 업데이트 작업을 수행할 때 기사 제목이 길면 가끔씩 두 번 번역된 결과가 달라져서 기사 링크가 변경되는 상황이 발생하는데, 이 부분은 상당히 난감합니다.&lt;/p&gt;
&lt;p&gt;기능 개선&lt;/p&gt;
&lt;p&gt;전체 프로젝트를 &lt;code&gt;클로드4&lt;/code&gt;에 맡겨 분석 및 최적화 공간을 확인한 결과, 다음과 같은 제안을 받았습니다&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;配置外置化 - 提高可维护性和灵活性
结构化日志 - 便于问题排查和监控
性能监控 - 了解系统运行状况
用户体验 - 进度条等视觉反馈
错误处理 - 更完善的异常处理机制
代码组织 - 更清晰的模块划分
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;코드 검토 결과, 문제 없습니다. 예를 들어 설정 파일의 경우, 기존 코드 설정을 기본 설정으로 변환하고, 설정 파일을 읽을 때 해당 파일이 없으면 자동으로 생성하여 사용자 실수로 인한 오류를 방지합니다.&lt;/p&gt;
&lt;h3 id=&#34;heading&#34;&gt;
&lt;/h3&gt;&lt;p&gt;요구 사항: 본문 번역 시 현재 번역 효율을 동적으로 계산하고, 남은 시간을 예측하여 콘솔에 관련 정보를 출력합니다. 현재 획득한 문서의 문자 수, 각 행 번역 시 현재 번역된 문자 수, 시간, 100자당 예상 번역 시간 등을 계산하며, 문서의 남은 번역 예상 시간도 함께 계산합니다.&lt;/p&gt;
&lt;p&gt;코드는 마무리했는데, 결과가 만족스럽지 않아 AI에게 새로운 디자인 방안을 제시하도록 했어:&lt;/p&gt;
&lt;p&gt;다양한 효율성 계산 방식 제공: 실시간 효율, 평균 효율, 슬라이딩 윈도우 효율
표시 방식 개선: 진행률 표시줄, 단계별 통계, 동적 새로 고침
더 유용한 지표 추가: API 호출 횟수, 성공률 등&lt;/p&gt;
&lt;p&gt;코드 완성 후 새로운 깜짝 놀랄 일이 발견되었는데, 번역 효율 통계 정보가 실시간으로 화면을 채우지만 맹목적으로 아래로 스크롤되지는 않는다&lt;/p&gt;
&lt;p&gt;번역 전문을 영어로 번역 중입니다 (총 7163자)
53행이 번역 필요로 감지됨
[1/53] Stage1/6 [░░░░░░░░░░░░░░░░░░░░░░░░░] 1.9% 번역 354자..
✅ 완료 (3.1초) | API 호출 #1
✅ 완료 (1.5초) | API 호출 #2
완료 (0.9초) | API 호출 #3
완료 (0.2초) | API 호출 #4
완료 (1.0초) | API 호출 #5
완료 (1.0초) | API 호출 #6
완료 (0.2초) | API 호출 #7
📊 진행률: 행 13.2% (7/53) | 문자 12.9% (925/7163) 114.6자/초 📊
⚡ 효율성: 실시간 76.4 | 평균 117.9 | 최근 109.0 | 단계별 113.6 자/초 📊
성공률: 100.0% (7/7) | 남은 항목: 46행 7초] 9.4% 번역 110자..
예상 남은 시간: 55초 | 완료 예상: 00:10:19 8초] 11.3% 번역 114자…
처리 속도: 3211.3 행/분 | 총 소요 시간: 8초] 13.2% 번역 16 문자..
[8/53] Stage1/6 [███░░░░░░░░░░░░░░░░░░░░░░] 15.1% 번역 166자..&lt;/p&gt;
&lt;p&gt;이전에는 제어 프로그램 코드를 많이 작성해보지 않아서 어떻게 구현되었는지 궁금해서 코드를 살펴봤다&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;// 清屏并重新显示 (动态刷新效果)
if translationCount &amp;gt; 1 {
   fmt.Print(&amp;quot;\033[6A\033[K&amp;quot;) // 上移6行并清除
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;성능 통계 메뉴&lt;/p&gt;
&lt;p&gt;새로 추가된 &lt;strong&gt;성능 통계 메뉴&lt;/strong&gt;는 제가 직접 디자인했는데, 이렇게 완벽하게 만들 수 있을 줄은 몰랐습니다&lt;/p&gt;
&lt;p&gt;성능 통계:
번역 횟수: 360
⚡ 캐시 적중률: 1.4% (5/365)
평균 번역 시간: 315.927234ms
파일 작업: 73
오류 횟수: 0&lt;/p&gt;
&lt;p&gt;진행률 표시&lt;/p&gt;
&lt;p&gt;새로운 &lt;strong&gt;진행률 표시&lt;/strong&gt;, 상세한 진행 상황, 경과 시간, 남은 예상 시간&lt;/p&gt;
&lt;p&gt;기능 선택 (0-13): 10
번역 목표를 수집 중입니다…
📄 캐시 파일이 로드되었습니다. 번역 기록 0개 포함&lt;/p&gt;
&lt;p&gt;번역 캐시 통계:
🏷️ 총 태그 수: 229개
📝 총 기사 수: 131건
✅ 캐시됨: 0개
🔄 번역 필요: 360개&lt;/p&gt;
&lt;p&gt;전체 번역 캐시 생성 확인하시겠습니까? (y/n): y
🚀 전체 번역 캐시 생성 중…
📄 캐시 파일이 로드되었습니다. 번역 기록 0개 포함
검색 중인 번역을 캐시에서 확인 중…
새로운 태그 360개 번역 필요
[░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 5/360 (1.4%) - 소요시간: 3초 - 예상 남은 시간: 3분 8초💾 캐시 파일 저장, 번역 기록 5개 포함
[█░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 10/360 (2.8%) - 소요시간: 6초 - 예상 남은 시간: 3분 28초💾 캐시 파일 저장, 번역 기록 10개 포함
[██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 15/360 (4.2%) - 소요시간: 9초 - 예상 남은 시간: 3분 30초💾 캐시 파일 저장 완료, 번역 기록 15개 포함
[██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 20/360 (5.6%) - 소요시간: 13초 - 예상 남은 시간: 3분 36초💾 캐시 파일 저장 완료, 번역 기록 20개 포함
[███░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 25/360 (6.9%) - 소요시간: 16초 - 예상 남은 시간: 3분 33초💾 캐시 파일 저장 완료, 번역 기록 25개 포함
[████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 30/360 (8.3%) - 소요시간: 19초 - 예상 남은 시간: 3분 30초💾 캐시 파일 저장 완료, 번역 기록 30개 포함
[████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 35/360 (9.7%) - 용량: 22s - 예상 남은 시간: 3분 25초💾 캐시 파일 저장 완료, 번역 기록 35개 포함&lt;/p&gt;
&lt;hr&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;=== Hugo 博客管理工具 ===

🚀 核心功能
  1. 一键处理全部 (完整博客处理流程)

📝 内容管理
  2. 生成标签页面
  3. 生成文章Slug
  4. 翻译文章为多语言版本

💾 缓存管理
  5. 查看缓存状态
  6. 生成全量翻译缓存
  7. 清空翻译缓存

  0. 退出程序
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>인공지능을 너무 많이 쓰니 약간의 후유증이 있네요</title>
        <link>https://ttf248.life/ko/p/ai-overuse-side-effects/</link>
        <pubDate>Wed, 14 May 2025 19:39:50 +0800</pubDate>
        
        <guid>https://ttf248.life/ko/p/ai-overuse-side-effects/</guid>
        <description>&lt;p&gt;새로운 &lt;code&gt;AI 영감 교류 공간&lt;/code&gt;을 만들고 나서, 별의별 것들을 AI로 기록하고 게시하는 데 신경 쓰느라 정작 스스로 생각하는 시간은 줄어들었습니다. 앞으로는 이 栏目的 생산량을 조금 조절해서 월간 형태로 통합하는 것이 좋겠습니다. 매달 한 편씩 발행하면 괜찮을 것 같습니다.&lt;/p&gt;
&lt;p&gt;이것은 일종의 후유증과 같거나, 부작용이라고 할 수 있는데, 효율은 높아졌지만 사고의 깊이와 넓이는 얕아졌다&lt;/p&gt;
&lt;h2 id=&#34;효율성-향상-부정할-수-없다&#34;&gt;효율성 향상: 부정할 수 없다
&lt;/h2&gt;&lt;p&gt;물고기의 7초 기록들 이전에는 이 코너를 잘 관리하지 않았습니다. 몇몇 주요 사건에 대해서는 게으름 때문에 인터넷에서 자료를 검색하거나 기록을 정리하지 않았습니다. 하지만 이제 다양한 AI 도구가 생기면서 개요만 작성하면 AI가 자동으로 관련 사건을 검색하고 기록하여 필요한 기사를 생성해 줍니다. 간단히 형식을 정리해서 게시하면 됩니다.&lt;/p&gt;
&lt;p&gt;이것은 마치 게으름뱅이를 위한 구원처럼, 효율이 상당히 높아졌고 심지어는 노력의 절반으로 결과를 두 배로 얻을 수 있을 정도입니다&lt;/p&gt;
&lt;p&gt;초안 작성은 잠시 미뤄두고 코딩을 할 때 효율이 눈에 띄게 향상된다. 이전에는 API 인터페이스 문서 설명을 자세히 읽어야 했는데, 이제는 이 단계를 건너뛸 수 있다. 이러한 단계 건너뛰기는 매우 유용하며, API 숙지는 &amp;lsquo;체력 노동&amp;rsquo;이지 &amp;lsquo;두뇌 노동&amp;rsquo;이 아니다. AI가 이 부분을 처리하는 것은 딱 맞다.&lt;/p&gt;
&lt;h2 id=&#34;쓰레기-내용&#34;&gt;쓰레기 내용
&lt;/h2&gt;&lt;p&gt;많은 원고들이 있는데, 내용 품질이 높지 않다. 완전히 엉망인 것은 아니지만, 읽으면 활력이 없고, 예전에 내가 싫어했던 스타일이다. 밋밋하고 재미없다.&lt;/p&gt;
&lt;p&gt;또 다른 관점에서 보면, AI가 생성한 콘텐츠는 어느 정도 컨베이어 벨트에서 생산된 것처럼 느껴지고 영혼이 부족합니다&lt;/p&gt;
&lt;p&gt;새 시대의 인터넷 쓰레기&lt;/p&gt;
&lt;h2 id=&#34;망각성&#34;&gt;망각성
&lt;/h2&gt;&lt;p&gt;이런 종류의 초고는 AI가 생성한 것이고, 독자의 상황은 파악하기 어렵지만 시간이 지나면 제 기억조차 흐릿해지거나 잊혀질 수도 있습니다&lt;/p&gt;
&lt;p&gt;비슷한 문제가 코드를 작성할 때도 발생하는데, 코드 제출 기록을 확인하지 않으면 당시 내가 어떻게 생각했는지, 왜 이렇게 썼는지 전혀 알 수 없다. 특히 코드가 AI와 반복적으로 소통하여 최종적으로 생성된 코드는 처음의 생각과 크게 달라서 심지어 완전히 다른 경우도 있다.&lt;/p&gt;
&lt;h2 id=&#34;검색&#34;&gt;검색
&lt;/h2&gt;&lt;p&gt;최근에 구글이나 바이두를 열어보는 횟수가 눈에 띄게 줄었다. 많은 문제를 AI로 검색하면, 상호작용도 좋고 검색 결과도 전통적인 검색 엔진보다 훨씬 낫다.&lt;/p&gt;
&lt;p&gt;지금은 살아있는지 알 수 없는 &lt;code&gt;빙 아이(Bing AI)&lt;/code&gt;를 기리며, 대기업 중에서 가장 먼저 출시되어 인터넷 검색 기능을 제공했던 AI 도구입니다&lt;/p&gt;
&lt;p&gt;구글을 잘 안 쓰게 됐고, &lt;code&gt;stackoverflow&lt;/code&gt; 방문 횟수도 줄어들었어. 많은 문제를 AI에 바로 물어볼 수 있어서 이 사이트는 점점 시대의 흐름 속에서 사라질 것 같아.&lt;/p&gt;
&lt;h2 id=&#34;마무리&#34;&gt;마무리
&lt;/h2&gt;&lt;p&gt;제가 아직 관리 중인 블로그인데, 원래 방문자 수가 많지 않았고 지금은 더 기대하기 어렵습니다. 주로 기록하는 곳이고, 제 자신을 위해 쓰는 것입니다.&lt;/p&gt;</description>
        </item>
        <item>
        <title>코딩 없이 맞춤 주식 모듈 설계 개발</title>
        <link>https://ttf248.life/ko/p/no-code-design-develop-custom-stock-module/</link>
        <pubDate>Thu, 27 Feb 2025 23:20:39 +0800</pubDate>
        
        <guid>https://ttf248.life/ko/p/no-code-design-develop-custom-stock-module/</guid>
        <description>&lt;p&gt;지난달에 커서를 시험 사용해 봤는데, 무료 한도 제한 때문에 복잡한 기능 개발은 하지 않고 간단히 테스트만 했습니다. 그때쯔음에 바이트(Byte)도 유사한 제품을 출시했고, 두 제품 모두 기반으로 하는 대규모 언어 모델이 Claude-3.5였습니다.&lt;/p&gt;
&lt;p&gt;바이트의 제품인 트레이인데, 먼저 맥 버전으로 출시했고, 올해 2월에 드디어 윈도우 버전이 나왔어. 대기업 제품은 역시 좋지, 무료로 사용할 수 있고 돈을 내지 않아도 무제한으로 Claude-3.5를 사용할 수 있는데, 이 모델의 성능은 아주 괜찮아.&lt;/p&gt;
&lt;p&gt;최종적으로 K라인 차트 개발에 막혀버렸습니다. 개인적으로 React에 대한 기본 지식이 부족하여 포기할 수밖에 없었습니다. 계속 개발하려면 저자가 프론트엔드 기초 지식을 보충하고, “K라인 차트 개발”과 같이 큰 작업을 바로 주지 않고 더 세분화된 작은 작업으로 나누어야 합니다.&lt;/p&gt;
&lt;h2 id=&#34;발견된-문제&#34;&gt;발견된 문제
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;해외 AI 모델 사용으로 인해 Vue3 + Element-Plus의 학습 데이터가 부족하여, 프론트엔드 프레임워크로 React를 선택했습니다&lt;/li&gt;
&lt;li&gt;문법 오류가 발생할 수 있으므로, 사람이 직접 수정해야 합니다&lt;/li&gt;
&lt;li&gt;일부 복잡한 문제 해결에는 사람의 지침이 필요합니다&lt;/li&gt;
&lt;li&gt;코드 구조 최적화는 수동 지침이 필요합니다&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;가장 시간이 오래 걸린 부분은 프론트엔드 코드를 컨테이너에 패키징하는 것이었는데, 작성자가 기초 지식이 전혀 없어서 &lt;code&gt;.env.production&lt;/code&gt; &lt;code&gt;tsconfig.json&lt;/code&gt; 같은 개념도 전혀 알지 못했습니다. 중간에 도움을 받은 덕분에 겨우 논리를 파악할 수 있었습니다. 프론트엔드 개발의 dev 모드와 build 모드는 코드 검사에서 큰 차이가 있습니다. 백엔드 데이터베이스 및 서비스 컨테이너 스크립트는 총 5분 만에 처리했습니다.&lt;/p&gt;
&lt;p&gt;AI는 현재 개발 효율성을 높이는 데 더 중점을 두고 있으며, 기본기가 가장 중요하며 AI가 모든 문제를 해결해 주는 것은 아닙니다&lt;/p&gt;
&lt;h2 id=&#34;창고-주소&#34;&gt;창고 주소
&lt;/h2&gt;&lt;p&gt;제목에서 언급했듯이, 이번에는 코딩하지 않고 AI와 직접 대화하며 자체 선택 주식 모듈을 설계하고 개발해 보겠습니다. 최종적으로 어떤 결과물이 나올지 지켜보죠.&lt;/p&gt;
&lt;p&gt;저장소 주소: &lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/trae-demo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/trae-demo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;자세한 사용 방법은 창고의 README.md 파일을 참조하십시오&lt;/p&gt;
&lt;p&gt;창고에는 많은 제출 기록이 포함되어 있는데, 대부분은 저와 Trae의 대화 기록과 제가 Trae의 몇몇 기능들을 테스트한 내용이며, 해당 기능을 구현하기 위해 수동 개입이 이루어졌는지에 대한 메모가 달려 있습니다&lt;/p&gt;
&lt;h2 id=&#34;prompt&#34;&gt;Prompt
&lt;/h2&gt;&lt;p&gt;프로젝트는 처음부터 시작되었으며, 프로젝트 프롬프트는 다음과 같습니다&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;基于项目原型图，开发功能：自选股，需要支持合约的新增、删除、修改、查询。自选股界面需要展示基础的行情数据。支持多个不同的市场切换。

前端：react
后端：golang gin gorm
数据库：PostgreSQL

服务端需要支持跨域请求，同时需要考虑数据的校验和错误处理，如果后端服务不可用，前端需要告警提示。

后端需要展示请求和应答的日志；前端也打印通讯的日志，方便排查问题。
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;ui-및-상호작용-최적화&#34;&gt;UI 및 상호작용 최적화
&lt;/h2&gt;&lt;p&gt;프론트엔드 인터페이스 디자인은 완전히 Grok에 의존하고 있으며, 우리는 먼저 Trae에서 제품의 초기 형태를 만들었지만 심미적인 부분은 부족했습니다. 사용한 모델은 코드 능력은 강력하지만 다른 기능은 상대적으로 약하기 때문에 Grok을 사용하여 프론트엔드의 UI를 최적화해야 합니다.&lt;/p&gt;
&lt;p&gt;현재 인터페이스의 스크린샷을 찍어 Grok에 업로드한 다음, Grok이 우리 UI를 최적화하도록 하고, 여러 가지 최적화 제안을 한 번에 받은 뒤, 저희가 수동으로 평가하고 Trae에서 실행하여 최적화 효과를 관찰합니다&lt;/p&gt;
&lt;h3 id=&#34;기술-스택&#34;&gt;기술 스택
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;프론트엔드: React + TypeScript&lt;/li&gt;
&lt;li&gt;백엔드: Golang + Gin + GORM&lt;/li&gt;
&lt;li&gt;데이터베이스: PostgreSQL 17&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;시스템-아키텍처&#34;&gt;시스템 아키텍처
&lt;/h2&gt;&lt;h2 id=&#34;백엔드-아키텍처&#34;&gt;백엔드 아키텍처
&lt;/h2&gt;&lt;p&gt;백엔드는 Golang의 Gin 프레임워크로 구현된 RESTful API이며, 주요 모듈은 다음과 같습니다:&lt;/p&gt;
&lt;p&gt;데이터베이스 모듈&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GORM을 ORM 프레임워크로 사용하세요&lt;/li&gt;
&lt;li&gt;환경 변수를 통해 데이터베이스 연결을 구성할 수 있습니다&lt;/li&gt;
&lt;li&gt;자동으로 데이터베이스 테이블 마이그레이션 수행&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;라우팅 모듈&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RESTful API 설계&lt;/li&gt;
&lt;li&gt;통일된 오류 처리 메커니즘&lt;/li&gt;
&lt;li&gt;내장 요청 로깅&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;영역 간 처리&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;로컬 개발 환경 간의 교차 도메인 접근을 지원합니다&lt;/li&gt;
&lt;li&gt;구성 가능한 CORS 정책&lt;/li&gt;
&lt;li&gt;쿠키 크로스 도메인 지원&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;프론트엔드-아키텍처&#34;&gt;프론트엔드 아키텍처
&lt;/h2&gt;&lt;p&gt;프론트엔드는 React + TypeScript로 구축되었으며, 다음과 같은 기능을 구현했습니다:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;주식 목록 표시&lt;/li&gt;
&lt;li&gt;자선주 관리&lt;/li&gt;
&lt;li&gt;시장 데이터 표시&lt;/li&gt;
&lt;li&gt;오류 표시 메커니즘&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>AI 개발 2년: 도커 출시 전과 비슷한 상태</title>
        <link>https://ttf248.life/ko/p/ai-development-two-years-docker-pre-release/</link>
        <pubDate>Thu, 20 Feb 2025 18:16:37 +0800</pubDate>
        
        <guid>https://ttf248.life/ko/p/ai-development-two-years-docker-pre-release/</guid>
        <description>&lt;p&gt;인공지능(AI)은 최근 몇 년간 기술 분야에서 가장 핫한 논제 중 하나이며, 특히 지난 2년 동안 AI 기술이 비약적으로 발전했습니다. 심층 학습, 자연어 처리는 물론 컴퓨터 비전, 자동화 의사 결정 시스템까지, AI의 적용 사례가 끊임없이 등장하고 있습니다. 하지만 기술이 계속해서 도약을 이루고 있음에도 불구하고, AI는 Docker 출시 이전과 유사한 병목 현상에 직면해 있는데, 이는 시장을 진정으로 폭발시킬 만한 &amp;lsquo;경험 있는 애플리케이션&amp;rsquo;이 부족하기 때문입니다.&lt;/p&gt;
&lt;p&gt;AI가 발전한 지 2년 정도 되었는데, Docker가 처음 공개되기 전과 비슷한 상황입니다. 아직 게임 체인저와 같은 Killer App이 없고, 현재 기술을 기반으로 완벽한 적용 사례를 만들어내야 합니다. Docker는 새로운 기술을 많이 사용하지 않았지만, 전체적인 솔루션이 매우 합리적이었고 운영 및 개발 업무의 워크플로우를 변화시켰습니다.&lt;/p&gt;
&lt;h2 id=&#34;인공지능-발전-현황-기술은-이미-성숙했지만-적용은-아직-돌파구를-찾아야-한다&#34;&gt;인공지능 발전 현황: 기술은 이미 성숙했지만, 적용은 아직 돌파구를 찾아야 한다
&lt;/h2&gt;&lt;p&gt;기술적인 측면에서 볼 때, AI는 지난 2년 동안 상당한 발전을 이루었습니다. OpenAI의 GPT 시리즈 모델이든, Google의 BERT, DeepMind의 Alpha 시리즈든, AI의 처리 능력은 이전 예상보다 훨씬 뛰어넘었습니다. 특히 자연어 처리 분야에서 GPT-4와 같은 모델은 강력한 생성 능력을 갖추는 것은 물론 이해력과 추론 능력에서도 놀라운 성과를 보여주고 있습니다.&lt;/p&gt;
&lt;p&gt;하지만, 기술이 비약적으로 발전하고 있음에도 불구하고 AI의 실제 적용은 일정한 어려움에 직면해 있습니다. Docker 출시 이전과 비슷하게, AI의 잠재력은 매우 크지만 아직 널리 보급되어 산업을 변화시킬 수 있는 진정한 &amp;lsquo;게임 체인저&amp;rsquo; 애플리케이션은 나타나지 않았습니다. 많은 사람들이 AI의 전망에 대해 이야기하지만, 직접적인 혁신적 변화를 가져올 수 있는 적용 사례를 찾기는 어려울 것입니다. 많은 AI 애플리케이션이 여전히 초기 단계에 머물러 있으며, 대부분 추가 통합 및 최적화가 필요합니다.&lt;/p&gt;
&lt;h2 id=&#34;도커와-ai의-유사성-기술-자체가-혁신이-아니라-솔루션이-핵심이다&#34;&gt;도커와 AI의 유사성: 기술 자체가 혁신이 아니라, 솔루션이 핵심이다
&lt;/h2&gt;&lt;p&gt;만약 Docker 출시 이전의 역사를 되돌아보면, 당시 기술 환경과 AI의 발전 현황 사이에 많은 유사점을 발견하기 어렵지 않습니다. Docker가 출시되기 전, 컨테이너 기술은 새로운 것이 아니었고, 초기 LXC(Linux Containers)와 가상화 기술들은 이미 컨테이너화의 기본적인 능력을 갖추고 있었습니다. 하지만 Docker는 기존 기술을 교묘하게 통합하고 최적화하여 더욱 간단하고 직관적이며 효율적인 솔루션을 제시했습니다. 이 솔루션은 획기적인 기술을 도입하지 않았지만, 운영 및 개발 과정에서 많은 어려움을 해결하고 소프트웨어의 배포, 확장 및 관리 프로세스를 크게 단순화했습니다.&lt;/p&gt;
&lt;p&gt;동일하게도 AI 분야 또한 유사한 상황에 직면해 있습니다. 현재의 AI 기술은 더 이상 “새로운 물건”이 아니지만, 진정으로 대규모 적용을 달성하기 위해서는 Docker처럼 기존 기술을 융합하고 최적화하여 합리적인 애플리케이션 방안을 형성하는 완벽한 실행 사례가 여전히 필요합니다. AI의 핵심 애플리케이션은 새로운 기술 돌파구에 의존하기보다는 기존 기술을 통합하여 실제 비즈니스에서 발생하는 문제점과 요구사항을 해결하는 데 달려 있을 수 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;ai의-도커-순간은-어떻게-찾아야-할까요&#34;&gt;AI의 “도커 순간”은 어떻게 찾아야 할까요?
&lt;/h2&gt;&lt;p&gt;AI 기술이 진정으로 널리 활용되려면 몇 가지 측면에서 노력해야 합니다&lt;/p&gt;
&lt;p&gt;실제 상황에 대한 심층적인 분석
현재 많은 AI의 적용 사례는 아직 실험적인 성격이 강하고 대규모로 실제 적용되지는 못하고 있습니다. 예를 들어, AI 고객 서비스나 지능형 추천과 같은 분야는 널리 사용되고 있지만 기능에 여러 가지 한계가 있으며 업계의 난관을 돌파하지 못했습니다. 진정한 도약은 전통적인 방법으로 오랫동안 어려움을 겪어왔던 의료, 제조업, 물류와 같은 산업에서 발생할 수 있습니다. AI는 더욱 효율적인 데이터 처리 및 예측 분석을 통해 기업이 이러한 복잡한 시나리오에서 효율성을 높이고 비용을 절감하도록 도울 수 있습니다.&lt;/p&gt;
&lt;p&gt;제품화 및 사용 편의성
Docker와 같이 컨테이너화 프로세스를 간소화하여 운영 효율성을 높이는 것처럼, AI 제품의 사용 편의성 또한 매우 중요합니다. AI의 보급은 기술의 보급일 뿐만 아니라, 제품화된 AI의 보급입니다. AI를 일상적인 워크플로우에 통합하고, 사용자가 심도 있는 기술 이해 없이도 이러한 도구를 쉽게 사용할 수 있도록 하는 것이 AI 상용화를 위한 중요한 단계입니다.&lt;/p&gt;
&lt;p&gt;생태 건설과 표준화
어떤 새로운 기술이라도 널리 사용되기 위해서는 생태계 구축이 필수적입니다. Docker가 빠르게 성장할 수 있었던 이유는 바로 개방성과 호환성 덕분이었으며, 개발자들이 다양한 클라우드 플랫폼, 도구 및 서비스와 쉽게 연동할 수 있도록 해주었기 때문입니다. 마찬가지로 AI의 미래 또한 생태계 구축에 달려 있습니다. AI의 표준화, 모델 공유, 데이터 개방, 그리고 기술의 통합성은 AI가 광범위한 산업적 활용을 이룰 수 있는지 여부에 영향을 미칠 것입니다.&lt;/p&gt;
&lt;h2 id=&#34;결론적으로-ai의-미래는-가능성으로-가득-차-있지만-더욱-완벽한-해결책이-필요합니다&#34;&gt;결론적으로, AI의 미래는 가능성으로 가득 차 있지만, 더욱 완벽한 해결책이 필요합니다
&lt;/h2&gt;&lt;p&gt;비록 AI 기술이 지난 2년간 상당한 진전을 이루었지만, 현재는 아직 “획기적인 응용 분야가 없는” 단계에 머물러 있습니다. Docker 출시 전의 컨테이너화 기술과 마찬가지로, AI 역시 합리적인 적용 시나리오를 통해 기존 기술을 비즈니스 요구사항과 심층적으로 융합해야 진정으로 대규모 적용 및 보급이 가능합니다. 기술 혁신은 물론 중요하지만, 프로세스를 간소화하고 효율성을 높이는 솔루션이야말로 기술의 보급과 발전을 더욱 촉진할 수 있습니다.&lt;/p&gt;
&lt;p&gt;미래에는 AI가 Docker처럼 획기적인 기술 돌파구가 아닌 기존 기술을 통합하여 완벽한 애플리케이션 시나리오를 구축함으로써, 결국 우리의 업무와 생활 방식을 바꿀 수 있습니다&lt;/p&gt;</description>
        </item>
        <item>
        <title>올라마에 deepseek-R1 로컬 배포</title>
        <link>https://ttf248.life/ko/p/ollama-local-deployment-deepseek-r1/</link>
        <pubDate>Fri, 07 Feb 2025 22:41:02 +0800</pubDate>
        
        <guid>https://ttf248.life/ko/p/ollama-local-deployment-deepseek-r1/</guid>
        <description>&lt;p&gt;Ollama는 사용자가 로컬에서 대규모 언어 모델(LLM)을 실행하고 배포할 수 있도록 하는 오픈 소스 AI 도구입니다. 이 도구의 목표는 개발자가 클라우드 서비스에 의존하지 않고도 GPT와 같은 모델을 로컬 머신에서 편리하고 효율적으로 사용할 수 있는 방법을 제공하는 것입니다. Ollama는 다양한 모델을 지원하며 성능 최적화에 중점을 두어 리소스가 제한된 장치에서도 이러한 모델을 원활하게 실행할 수 있도록 합니다.&lt;/p&gt;
&lt;p&gt;올라마를 통해 사용자는 텍스트 기반의 AI 애플리케이션을 사용할 수 있으며, 데이터 개인 정보나 높은 API 사용 비용 걱정 없이 로컬에 배포된 모델과 상호 작용할 수 있습니다. 다양한 모델을 명령줄 인터페이스(CLI)를 통해 호출하여 자연어 처리, 질의 응답 등의 작업을 수행할 수 있습니다.&lt;/p&gt;
&lt;p&gt;올라마는 다양한 모델을 시험해 보기에 적합하지만, 윈도우 버전으로 테스트해 보니 하드웨어 성능을 충분히 활용하지 못하는 듯합니다. 아마 윈도우 버전 때문일 수도 있고, 리눅스 버전이 더 나을 수도 있습니다. 32b 파라미터 모델을 배포했을 때 메모리나 그래픽 카드 사용량이 높지 않음에도 불구하고 응답 속도가 매우 느립니다.&lt;/p&gt;
&lt;h2 id=&#34;하드웨어-개요&#34;&gt;하드웨어 개요
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;운영체제: win11&lt;/li&gt;
&lt;li&gt;CPU：i7-10700K&lt;/li&gt;
&lt;li&gt;메모리: 40GB&lt;/li&gt;
&lt;li&gt;그래픽 카드: RTX 3060 12GB&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;환경-준비&#34;&gt;환경 준비
&lt;/h2&gt;&lt;p&gt;새로운 시스템 환경 변수를 추가하여 향후 사용을 용이하게 합니다&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_MODELS=E:\ollama&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
이 변수는 Ollama 모델이 저장될 경로를 지정합니다. &lt;code&gt;E:\ollama&lt;/code&gt;는 모든 로컬 모델 파일이 해당 디렉터리에 저장되어 있음을 나타내는 폴더 경로입니다. Ollama는 이 경로를 기준으로 다운로드하거나 배포한 언어 모델을 로드하고 사용합니다. 모델 파일을 다른 위치에 저장하려면 이 경로만 변경하면 됩니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_HOST=127.0.0.1:8000&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
이 환경 변수는 Ollama 서비스의 호스트와 포트를 설정합니다&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;127.0.0.1&lt;/code&gt;은 로컬 주소(localhost)이며, Ollama 서비스는 로컬에서 온 요청만 수신합니다&lt;/li&gt;
&lt;li&gt;8000은 지정된 포트 번호이며, Ollama 서비스가 8000번 포트에서 요청을 기다리고 처리할 것임을 나타냅니다. 필요에 따라 포트 번호를 변경할 수 있지만, 해당 포트가 다른 애플리케이션에서 사용 중인지 확인해야 합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_ORIGINS=*&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
이 환경 변수는 Ollama 서비스에 접근할 수 있는 요청의 출처를 제어합니다&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;*&lt;/code&gt;는 모든 소스(즉, 모든 도메인 및 IP 주소)에서 Ollama 서비스에 액세스할 수 있도록 허용합니다. 이는 일반적으로 개발 및 디버깅 환경에서 사용되며, 프로덕션 환경에서는 더 엄격한 소스 제어를 지정하여 특정 도메인 또는 IP만 서비스를 액세스하도록 제한하여 보안을 강화하는 것이 일반적입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;딥시크-r1-모델-배포&#34;&gt;딥시크-R1 모델 배포
&lt;/h2&gt;&lt;p&gt;올라마 설치는 간단하니 자세한 설명은 생략하겠습니다&lt;/p&gt;
&lt;p&gt;설치 후 검증:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core&amp;gt;ollama -v
ollama version is 0.5.11
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;모델 배포는 공식 모델 페이지를 참조하여 해당 매개변수가 있는 모델을 선택합니다: &lt;code&gt;ollama run deepseek-r1:14b&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;14b 파라미터는 대화 컨텍스트를 효과적으로 기억할 수 있지만, 더 작은 파라미터 버전은 그렇지 못합니다. 32b 파라미터 버전은 로컬에서 실행하면 매우 느려서 더 이상 테스트하지 않았습니다.&lt;/p&gt;
&lt;h2 id=&#34;참고-자료&#34;&gt;참고 자료
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ollama.com/library/deepseek-r1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.ollama.com/library/deepseek-r1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/x18990027/article/details/145368094&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/x18990027/article/details/145368094&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>딥시크 스프링 페스티벌 전 갑작스러운 인기, 엔비디아 주식 급락: 뒤에 숨은 기관의 움직임과 거대 모델 사고 체인</title>
        <link>https://ttf248.life/ko/p/deepseek-chinese-new-year-nvidia-stock-drop-institutional-operations-large-language-model-chain/</link>
        <pubDate>Fri, 07 Feb 2025 20:36:05 +0800</pubDate>
        
        <guid>https://ttf248.life/ko/p/deepseek-chinese-new-year-nvidia-stock-drop-institutional-operations-large-language-model-chain/</guid>
        <description>&lt;p&gt;설 명절 직전, DeepSeek가 한 번의 화제로 주목받기 시작하며 며칠 만에 소셜 미디어에서 광범위한 관심을 끌었습니다. 이러한 갑작스러운 인기 폭발은 놀라울 뿐만 아니라 시장 전체에 연쇄적인 영향을 미쳤습니다. 동시에 엔비디아 주가는 급락했고, 많은 투자자들이 그 전망에 대해 의문을 품기 시작했으며, 일부 기관들은 이 기간 동안 대규모의 공매도 포지션을 취했습니다. 모든 상황이 마치 “계획된” 것처럼 보였습니다.&lt;/p&gt;
&lt;h3 id=&#34;딥시크의-폭발적인-인기-짧은-시간-내에-빠르게-주목받음&#34;&gt;딥시크의 폭발적인 인기: 짧은 시간 내에 빠르게 주목받음
&lt;/h3&gt;&lt;p&gt;DeepSeek는 AI 기반 도구로, 특히 자연어 처리(NLP) 및 이미지 생성 분야에서 딥 러닝 모델 최적화에 중점을 두고 있습니다. 설 명절 직전 며칠 동안 이 프로젝트는 갑자기 많은 투자자와 기술 전문가들의 관심을 받기 시작했습니다. 그 뒤에 있는 팀의 성과와 시연된 기술적 결과물은 많은 사람들에게 이 프로젝트에 대한 강한 관심을 불러일으켰습니다. 개발자 커뮤니티나 소셜 미디어 플랫폼에서든, DeepSeek에 대한 논의는 거의 기술계의 모든 화제를 장악했습니다.&lt;/p&gt;
&lt;p&gt;하지만 DeepSeek의 갑작스러운 인기 폭발은 우연이 아니다. 분석 결과, 많은 사람들이 이 뒤에 특정 기관의 개입이 있을 가능성을 의심하기 시작했다. 특히 인기가 폭발한 이후 엔비디아 주가가 뚜렷하게 하락했는데, 분명 어떤 요인들이 이러한 변화를 촉진하고 있는 것으로 보인다.&lt;/p&gt;
&lt;h3 id=&#34;엔비디아-주가-폭락-공매도-작전의-배후-세력&#34;&gt;엔비디아 주가 폭락: 공매도 작전의 배후 세력
&lt;/h3&gt;&lt;p&gt;엔비디아는 그래픽 처리 장치(GPU) 제조업체로서, 수많은 거대 모델과 AI 컴퓨팅의 핵심 하드웨어 공급업체였습니다. AI 시장이 빠르게 발전하면서 엔비디아 주식은 오랫동안 강세를 보였고 심지어 많은 투자자들의 선호 대상이 되기도 했습니다. 하지만 DeepSeek의 폭발적인 인기와 시장의 기술에 대한 높은 관심으로 인해 엔비디아 주가는 급락했습니다.&lt;/p&gt;
&lt;p&gt;이 현상 뒤에는 기관 투자자의 공매도 전략이 관련되어 있을 수도 있습니다. 지난 몇 년간 AI 기술의 보급과 함께 엔비디아 주가는 크게 상승했고, 많은 투자자들은 그 주가가 과도하게 부풀려졌다고 생각하기 시작했습니다. 특히 DeepSeek와 같은 기술이 폭발적으로 인기를 얻은 이후, 일부 기관들은 엔비디아 주식을 공매도하여 상당한 이익을 얻었을 가능성이 있습니다. 정확한 시장 시기 포착과 DeepSeek의 영향력에 대한 예측을 통해 이러한 기관들은 성공적으로 이익을 얻었습니다.&lt;/p&gt;
&lt;h3 id=&#34;대규모-모델-사고-체인의-접촉-결과에서-과정으로&#34;&gt;대규모 모델 사고 체인의 접촉: “결과”에서 “과정”으로
&lt;/h3&gt;&lt;p&gt;전통적인 인공지능 응용 분야에서 많은 실무자와 투자자들은 AI 모델의 “결과” — 예를 들어 생성된 이미지, 텍스트와 같은 직접적인 산출물에 더 많은 관심을 기울였습니다. 하지만 DeepSeek 관련 논의에서는 점점 더 많은 사람들이 대형 모델 뒤에 숨겨진 사고 과정이 더욱 주목할 가치가 있는 핵심 내용이라는 것을 깨닫기 시작했습니다. 과거에는 모델 출력 결과만 볼 수 있었지만, 이제는 그 뒤에 숨겨진 논리, 알고리즘과 이러한 요소를 조정하여 모델의 성능을 최적화하는 방법을 이해해야 합니다.&lt;/p&gt;
&lt;p&gt;이러한 사고방식의 전환은 AI 연구와 응용에 대한 심층적인 고찰인 동시에, 단순한 블랙박스 조작에서 모델 내부 작동 메커니즘을 진정으로 이해하는 것으로의 변화는 많은 기술 전문가와 투자자들이 인공지능의 미래 발전 방향을 다시 한번 검토하게 만들었습니다. DeepSeek의 인기 폭발은 바로 이러한 사고방식의 획기적인 응용이며, 사람들은 이제 최종 출력 결과뿐만 아니라 전체 모델 구축 및 최적화 과정에 주목하기 시작했습니다.&lt;/p&gt;
&lt;h3 id=&#34;요약&#34;&gt;요약
&lt;/h3&gt;&lt;p&gt;딥시크의 갑작스러운 인기, 엔비디아 주식의 폭락, 그리고 시장 뒤에 숨은 기관의 공매도 세력, 이 모든 현상 뒤에는 치밀하게 설계된 음모가 있는 듯합니다. 거대 언어 모델 사고 체인에 대한 깊이 있는 이해를 통해 AI 기술의 적용은 단순한 표면적 현상의 조합이 아니라 모델 내부 로직에 대한 심층적인 탐구와 최적화임을 알 수 있습니다. 기술 발전과 함께 앞으로 딥시크와 같은 혁신적인 도구가 더 많이 등장하여 AI 연구 및 응용을 더욱 높은 수준으로 발전시키는 것을 목격할 수도 있을 것입니다.&lt;/p&gt;
&lt;p&gt;이러한 현상은 인공지능 기술의 엄청난 잠재력을 보여주는 동시에, 기술 뒤에 숨겨진 상업적 경쟁과 자본 운용에 대해 생각하게 합니다. 앞으로 시장 추세는 기술과 자본 간의 경쟁이 지속적으로 초점이 될 것입니다.&lt;/p&gt;</description>
        </item>
        <item>
        <title>커서 AI 프로그래밍 IDE 체험</title>
        <link>https://ttf248.life/ko/p/cursor-ai-programming-ide-trial/</link>
        <pubDate>Thu, 23 Jan 2025 19:30:13 +0800</pubDate>
        
        <guid>https://ttf248.life/ko/p/cursor-ai-programming-ide-trial/</guid>
        <description>&lt;p&gt;번뜩이는 사이 또 일 년이 지나갔다. 업무적으로 가장 큰 변화는 인공지능의 참여도가 눈에 띄게 높아진 것인데, 이전에는 다양한 개발 언어 간 전환 시 개발자가 익숙해해야 할 여러 언어들의 다른 API 인터페이스들이 있었지만, 이제 이러한 기본적인 코드들은 AI를 통해 생성할 수 있게 되었다. 이는 개발자들에게 큰 행운이다.&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;23년도에 간단한 입문 소개 두 편을 다룬 적이 있었는데, 눈 깜짝할 사이에 25년이 벌써 왔네요. 어떻게 말해야 할지 모르겠지만, 뚜렷한 발전은 없는 것 같아요. 아직은 자신만의 인식을 가지고 합리적으로 작업을 분할할 수 있어야 하고, 무엇보다 중요한 것은 AI가 생성한 코드에 버그가 있는지 식별하는 것입니다.&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;Github copilot
&lt;/h2&gt;&lt;p&gt;어느 날인지 잊혀졌는데, 자료를 보니 싱가포르에 서버를 구축했고, 이제 국내에서 사용할 수 있어서 더 이상 오랫동안 VPN을 사용할 필요가 없어. 물론 로그인할 때는 아직 VPN이 필요하지만, 이 VPN은 로그인할 때만 잠깐 사용하면 되고 그 후에는 종료해도 돼.&lt;/p&gt;
&lt;p&gt;일상적으로 더 많이 사용하는 것은 Github Copilot 플러그인인데, 이 플러그인은 vscode나 visual studio에서 바로 사용할 수 있습니다. 두 프로그램 사이를 전환할 필요가 없습니다. ChatGPT에 비해 Github Copilot이 프로젝트 지원이 더 좋고, 상호작용도 더 친절하며, 일부 로컬 파일을 선택하여 AI를 **“훈련”**시킬 수 있어 생성되는 코드가 프로젝트에 더 잘 맞습니다.&lt;/p&gt;
&lt;h2 id=&#34;cursor-ai&#34;&gt;Cursor AI
&lt;/h2&gt;&lt;p&gt;최근에 새로운 AI 프로그래밍 IDE인 Cursor AI를 보았는데, 이 IDE는 Github Copilot을 기반으로 하고 있지만, 더 똑똑하고 파일을 직접 생성해 줄 수 있습니다&lt;/p&gt;
&lt;p&gt;간단히 사용해 봤는데 괜찮은 것 같긴 하지만, 현재 프로젝트에 대한 이해는 아직 부족하고, 로컬 프로젝트 파일이 많을 때는 큰 규모의 리팩토링이나 최적화 조정은 여전히 &lt;strong&gt;개발자가 작업을 분할해야 한다&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;예시 하나를 덧붙입니다: curso의 엔지니어링 모드로 전환하여 다음 내용을 입력하세요: 새로운 개인 이력서 웹페이지를 생성하고, 여러 가지 다른 스타일로 전환할 수 있도록 지원하며, 데이터 표시를 위해 몇몇 개인 정보를 채워 넣으세요&lt;/p&gt;
&lt;p&gt;몇 번이고 &lt;strong&gt;두었다 떼었다&lt;/strong&gt; 하는 과정을 거치면 다음과 같은 웹페이지를 얻을 수 있습니다. 물론 이 웹페이지는 비교적 간단하지만, 초보자에게는 아주 괜찮은 시작입니다.&lt;/p&gt;
&lt;p&gt;현재 등록 사용자는 고급 API를 150회 무료로 체험해 볼 수 있으며, 유료 사용자는 고급 API 사용이 5000회로 제한됩니다&lt;/p&gt;
&lt;p&gt;개인 이력서&lt;/p&gt;</description>
        </item>
        <item>
        <title>AI 프로그래밍 및 작업 분할</title>
        <link>https://ttf248.life/ko/p/ai-programming-and-task-decomposition/</link>
        <pubDate>Fri, 22 Dec 2023 08:44:26 +0800</pubDate>
        
        <guid>https://ttf248.life/ko/p/ai-programming-and-task-decomposition/</guid>
        <description>&lt;p&gt;2년 전 사이트에 코드 영역 복사 기능을 추가했는데, 여러 날을 끙끙거린 끝에 최종 렌더링 효과가 만족스럽지 않았습니다. 반쪽짜리 프론트엔드 개발자였기 때문에 개선하려 하지는 않고 그냥 사용했습니다. 올해 &lt;code&gt;AI&lt;/code&gt;로 미니 프로그램을 개발하면서 프론트엔드 개발에도 더 익숙해졌고, 그래서 다시 한번 (AI 재설계) 리팩토링을 했습니다.&lt;/p&gt;
&lt;p&gt;깨달음: 과제를 분해하니 작은 작업들이 많아져서, AI 개발에 적합하네요. 이미 폐쇄된 앱인데 75%의 코드를 AI가 제공했고, 여러 개의 작업으로 분할하여 배포했으며, 사람이 프로젝트 코드 조립을 담당했습니다.&lt;/p&gt;
&lt;h2 id=&#34;전문&#34;&gt;전문
&lt;/h2&gt;&lt;p&gt;간단하다고 생각했던 일이지만, 코드 복사 버튼을 추가하면 됩니다&lt;/p&gt;
&lt;h2 id=&#34;본문&#34;&gt;본문
&lt;/h2&gt;&lt;p&gt;CSS와 JavaScript 코드를 설계하여 class=&amp;ldquo;highlight&amp;quot;인 웹 요소의 컨테이너 내에 복사 버튼을 추가하고, 코드 복사 기능을 구현합니다&lt;/p&gt;
&lt;p&gt;제공된 첫 번째 초안 코드에는 문제가 있는 듯 보입니다. 다시 생성한 초안은 기본적으로 사용 가능하지만, 복사된 내용이 정확하지 않고 불필요한 텍스트가 포함되어 있습니다. 핵심 색상 디자인과 어떤 효과를 포함할지 수동으로 지정하여 추가 최적화를 유도했습니다.&lt;/p&gt;
&lt;p&gt;버튼의 크기와 색상에 대한 특정 요구 사항이 있다는 것을 파악했습니다. 귀하의 요구 사항에 맞게 버튼 스타일을 다시 디자인할 수 있습니다. 다음은 제공하신 색상 구성표를 포함하고 버튼 크기를 최적화한 조정된 CSS 스타일입니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.copy-btn {
  position: absolute;
  top: 2px; /* 调整位置 */
  right: 2px;
  padding: 3px 6px; /* 缩小尺寸 */
  font-size: 12px; /* 减小字体大小 */
  background-color: #8FD1E1; /* 按钮背景色 */
  color: #272822; /* 文字颜色 */
  border: 1px solid #272822; /* 边框颜色 */
  border-radius: 3px; /* 圆角 */
  cursor: pointer;
  opacity: 0.7; /* 默认半透明 */
  transition: opacity 0.3s ease, background-color 0.3s ease; /* 平滑过渡效果 */
}

.copy-btn:hover {
  opacity: 1; /* 鼠标悬停时不透明 */
  background-color: #A3D4E5; /* 鼠标悬停时的背景色 */
}

.highlight {
  position: relative;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이 스타일에서 저는 버튼 크기와 글꼴 크기를 줄여 더욱 세련되게 만들었습니다. 동시에 버튼의 기본 상태는 반투명하며, 마우스가 버튼 위에 올라갈 때 불투명해지고 배경색이 약간 밝아져 시각적인 피드백을 제공합니다. 이러한 디자인은 귀하의 색상 요구 사항을 충족하면서도 현대적이고 사용자 친화적인 특징을 유지합니다.&lt;/p&gt;
&lt;p&gt;해당하는 더 간단한 &lt;code&gt;JavaScript&lt;/code&gt;를 제공합니다&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-JavaScript&#34;&gt;document.addEventListener(&#39;DOMContentLoaded&#39;, function() {
  // 查找所有 .highlight 元素
  const highlights = document.querySelectorAll(&#39;.highlight&#39;);

  highlights.forEach(function(highlight) {
    // 创建复制按钮
    const copyBtn = document.createElement(&#39;button&#39;);
    copyBtn.textContent = &#39;复制&#39;;
    copyBtn.classList.add(&#39;copy-btn&#39;);

    // 将按钮添加到每个 .highlight 元素中
    highlight.appendChild(copyBtn);

    // 添加点击事件监听器
    copyBtn.addEventListener(&#39;click&#39;, function() {
      // 假设 .highlight 下的第一个 &amp;lt;code&amp;gt; 元素包含要复制的代码
      const code = highlight.querySelector(&#39;code&#39;) ? highlight.querySelector(&#39;code&#39;).textContent : &#39;&#39;;

      navigator.clipboard.writeText(code).then(() =&amp;gt; {
        // 显示复制成功信息
        copyBtn.textContent = &#39;已复制!&#39;;
        setTimeout(() =&amp;gt; {
          copyBtn.textContent = &#39;复制&#39;;
        }, 2000);
      }).catch(err =&amp;gt; {
        console.error(&#39;复制失败: &#39;, err);
      });
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;사후기&#34;&gt;사후기
&lt;/h2&gt;&lt;p&gt;비록 코드 영역의 오른쪽 상단에 복사 버튼을 추가하는 것을 더 기대했지만, 프론트엔드에 대한 이해 부족으로 기능이 정확하게 설명되지 않았고, AI와 몇 번이고 반복했음에도 예상한 결과를 얻지 못했습니다&lt;/p&gt;
&lt;p&gt;시간이 지나면서 AI가 프로그램 개발에 얼마나 큰 영향을 미칠지 모르겠다&lt;/p&gt;</description>
        </item>
        <item>
        <title>프롬프트 엔지니어</title>
        <link>https://ttf248.life/ko/p/prompt-engineer/</link>
        <pubDate>Sun, 26 Mar 2023 20:46:53 +0800</pubDate>
        
        <guid>https://ttf248.life/ko/p/prompt-engineer/</guid>
        <description>&lt;p&gt;과거 검색 엔진 사용법을 배우던 것처럼, 우리도 AI와 소통하는 방법, 즉 합리적이고 충분한 조건을 제시하여 필요한 답변을 효율적으로 얻는 방법을 배워야 합니다&lt;/p&gt;
&lt;p&gt;만약 다른 각도에서 생각해 보면, 현재의 AI는 기억력이 아주 좋은 어린이에 해당합니다. 그는 눈에 보이는 것을 모두 외울 수 있고, 베끼기 능력이 있습니다. 우리가 해야 할 일은 AI와 어떻게 정확하고 효과적으로 소통하며, 요구사항을 정밀하게 묘사하여 AI가 예상되는 결과를 생성하도록 돕는 것입니다.&lt;/p&gt;
&lt;h2 id=&#34;과학-대중화&#34;&gt;과학 대중화
&lt;/h2&gt;&lt;p&gt;AI라고 불리는, 정확히 말하면 &lt;code&gt;Generative Pre-Training&lt;/code&gt;은 직역하면 생성적 사전 훈련입니다. 이는 인터넷에서 사용 가능한 데이터로 학습된 텍스트 생성 심층 학습 모델이며, 질의 응답, 텍스트 요약 생성, 기계 번역, 분류, 코드 생성 및 대화형 AI와 같은 작업에 사용됩니다. 현재 GPT-1, GPT-2, GPT-3 및 GPT-4 등 다양한 버전의 모델이 있으며, 각 버전은 이전 버전에 비해 더 크고 강력합니다.&lt;/p&gt;
&lt;h2 id=&#34;정말-인공지능이-있을까&#34;&gt;정말 인공지능이 있을까
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;유사도가 충분히 높으면 정확도 또한 높아집니다&lt;/li&gt;
&lt;li&gt;기본적이고 반복적인 업무는 특정 훈련을 거치면 더 이상 인공의 개입이 필요하지 않다&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;생성형 AI는 기존의 텍스트, 오디오, 이미지 등 데이터를 활용하여 새로운 콘텐츠를 생성하는 기술입니다. 텍스트 생성, 음성 합성, 이미지 생성, 대화 시스템 등 다양한 작업에 사용될 수 있습니다. 생성형 AI의 논리성은 학습 데이터와 모델 구조에 따라 달라집니다. 일반적으로 생성형 AI는 문법, 논리 및 상식에 어느 정도 따르지만 오류, 편향 또는 부정확한 내용을 포함할 수도 있습니다. 따라서 생성형 AI의 출력은 인간의 판단과 검증이 필요하며 맹목적으로 믿거나 사용할 수 없습니다.&lt;/p&gt;
&lt;h2 id=&#34;프롬프트-엔지니어&#34;&gt;프롬프트 엔지니어
&lt;/h2&gt;&lt;p&gt;시간의 흐름은 거슬러갈 수 없고, 사람은 변화하는 흐름에 적응해야 합니다. AI가 똑똑하지 않다고 생각할 수도 있고, 논리성이 없다고 생각할 수도 있습니다. 코드를 작성해도 제대로 작동하지 않는 경우가 많습니다.&lt;/p&gt;
&lt;p&gt;만약 다른 각도에서 생각해 보면, 현재의 AI는 기억력이 아주 좋은 어린이에 해당합니다. 그는 눈에 보이는 것을 모두 외울 수 있고, 베끼기 능력이 있습니다. 우리가 해야 할 일은 AI와 어떻게 정확하고 효과적으로 소통하며, 요구사항을 정밀하게 묘사하여 AI가 예상되는 결과를 생성하도록 돕는 것입니다.&lt;/p&gt;
&lt;h2 id=&#34;대화-모드&#34;&gt;대화 모드
&lt;/h2&gt;&lt;p&gt;2년 전 &lt;code&gt;Github Copilot&lt;/code&gt;이 출시되었을 때, 2년 후 &lt;code&gt;OpenAI&lt;/code&gt;가 갑자기 등장하여 인간의 인지 능력을 크게 확장시키는 대규모 언어 모델의 가능성을 보여줄 거라고는 아무도 예상하지 못했습니다&lt;/p&gt;
&lt;p&gt;주석 기반 프로그래밍과 대화 기반 프로그래밍은 상호 작용 방식이 완전히 다르며, 대화의 패턴은 초보 사용자에게 친숙한 경험을 제공합니다. 여기서 &lt;code&gt;NewBing&lt;/code&gt;이 각 질문마다 제시하는 후속 질문 제안을 언급하지 않을 수 없는데, 이는 마이크로소프트가 사용자를 유도하여 AI 지식 데이터베이스에서 더 많은 정보를 얻으려고 시도하고 있는 것입니다.&lt;/p&gt;
&lt;h2 id=&#34;예시로-말하자면&#34;&gt;예시로 말하자면
&lt;/h2&gt;&lt;p&gt;고속철도 여행 시간은 길고, 코딩이 좋은 선택이다. 데이터 사용량이 제한적인 상황에서 몇 장의 사진을 처리하고 이미지 자료를 얻었지만, 소프트웨어를 다운로드하여 사진을 처리하는 것은 조금 사치스럽고 네트워크 환경도 허락하지 않는다.&lt;/p&gt;
&lt;p&gt;요구 사항은 다음과 같습니다. 투명 배경이 있는 이미지 자료가 여러 벌 있는데, 이것들을 앱의 내비게이션 바에 사용하려고 합니다. 선택된 상태는 컬러로, 선택되지 않은 상태는 흑백으로 하고, 원본 이미지는 모두 컬러입니다. 따라서 사전 처리 작업이 필요합니다.&lt;/p&gt;
&lt;p&gt;폴더에서 모든 이미지를 읽어와서, 이미지를 흑백으로 변환하고 투명 배경을 유지하며, 이미지 저장 시 품질을 최적화하여 파일 크기를 줄이고, 콘솔에 최적화 전후 파일 크기 비교를 표시하는 파이썬 코드를 작성하세요&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 导入必要的库
import os
import PIL
from PIL import Image

# 定义一个函数，将图片转换成黑白，维持透明背景，保存图片，并返回文件体积
def convert_and_save(image_file):
    # 打开图片
    image = Image.open(image_file)
    # 获取图片的模式，如果是 RGBA 模式，说明有透明背景
    mode = image.mode
    if mode == &amp;quot;RGBA&amp;quot;:
        # 创建一个和图片大小一致的白色背景图片
        background = Image.new(&amp;quot;RGB&amp;quot;, image.size, (255, 255, 255))
        # 将原图片粘贴到白色背景上，忽略透明像素
        background.paste(image, mask=image.split()[3])
        # 将合成的图片转换成灰度模式
        gray_image = background.convert(&amp;quot;L&amp;quot;)
        # 将灰度图片再转换成 RGBA 模式，以便保留透明背景
        final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
    else:
        # 如果不是 RGBA 模式，直接将图片转换成灰度模式
        final_image = image.convert(&amp;quot;L&amp;quot;)
    # 获取原图片的文件名和扩展名
    file_name, file_ext = os.path.splitext(image_file)
    # 定义新图片的文件名，添加 _bw 后缀表示黑白
    new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # 保存新图片，并优化质量，减少文件体积
    final_image.save(new_file_name, optimize=True)
    # 获取原图片和新图片的文件体积，并返回
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return old_size, new_size

# 定义一个文件夹路径，存放所有的图片
folder_path = &amp;quot;images&amp;quot;
# 遍历文件夹中的所有文件
for file in os.listdir(folder_path):
    # 拼接完整的文件路径
    file_path = os.path.join(folder_path, file)
    # 判断是否是图片文件，根据扩展名判断，可以根据需要添加或修改扩展名
    if file_path.endswith((&amp;quot;.png&amp;quot;, &amp;quot;.jpg&amp;quot;, &amp;quot;.jpeg&amp;quot;, &amp;quot;.gif&amp;quot;)):
        # 调用函数，转换并保存图片，并获取文件体积
        old_size, new_size = convert_and_save(file_path)
        # 在控制台展示优化前后的文件体积大小对比
        print(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;AI가 빠르게 답을 내놓았는데, 보기에 좋고 사용하기에도 괜찮은데, 경험이 많은 프로그래머라면 아래 코드가 충분히 일반적이지 않다고 느낄 것이고, 생산 환경에 적용하기도 어렵다고 생각할 것입니다&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;매개변수가 고정되었습니다&lt;/li&gt;
&lt;li&gt;로그 파일이 없고, 정보는 모두 콘솔에 출력됩니다&lt;/li&gt;
&lt;li&gt;이미지 처리는 다중 스레드 모델에 적합합니다&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;뉴빙이 등장하여 프롬프트에 따라 질문을 선택했습니다: &lt;strong&gt;이 코드의 개선할 부분이 있나요?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;제공된 답변은 솔직히 기대 이상이었고, 일반 프로그래머가 생각할 수 있는 최적화 방안에 대해 AI가 해당하는 제안을 제시했습니다&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;这段代码可能还有一些可以改进的地方，比如：

可以使用 argparse 库，让用户可以通过命令行参数指定文件夹路径和扩展名，而不是写死在代码里。
可以使用 logging 库，记录程序的运行情况，而不是直接打印到控制台。
可以使用 try-except 语句，捕获可能出现的异常，比如文件打开失败，图片转换失败等，并做相应的处理。
可以使用 multiprocessing 库，利用多核处理器，加速图片的转换和保存过程。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;매우 친절한 응답입니다. 배포 환경의 차이를 고려하여 다중 프로세스를 지원하지 않아도 괜찮습니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;当然，我很乐意帮你修改一下代码。我尝试添加了 argparse, logging 和 try-except 语句，但没有添加 multiprocessing 库，因为我不确定你的电脑是否支持多核处理。修改后的代码如下：
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 导入必要的库
import argparse
import logging
import multiprocessing
import os

from PIL import Image


# 定义一个函数，将图片转换成黑白，维持透明背景，保存图片，并返回文件体积
def convert_and_save(image_file):
    # 打开图片
    try:
        image = Image.open(image_file)
    except Exception as e:
        logging.error(f&amp;quot;Failed to open {image_file}: {e}&amp;quot;)
        return None, None
    # 获取图片的模式，如果是 RGBA 模式，说明有透明背景
    mode = image.mode
    if mode == &amp;quot;RGBA&amp;quot;:
        # 创建一个和图片大小一致的白色背景图片
        background = Image.new(&amp;quot;RGB&amp;quot;, image.size, (255, 255, 255))
        # 将原图片粘贴到白色背景上，忽略透明像素
        background.paste(image, mask=image.split()[3])
        # 将合成的图片转换成灰度模式
        gray_image = background.convert(&amp;quot;L&amp;quot;)
        # 将灰度图片再转换成 RGBA 模式，以便保留透明背景
        final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
    else:
        # 如果不是 RGBA 模式，直接将图片转换成灰度模式
        final_image = image.convert(&amp;quot;L&amp;quot;)
    # 获取原图片的文件名和扩展名
    file_name, file_ext = os.path.splitext(image_file)
    # 定义新图片的文件名，添加 _bw 后缀表示黑白
    new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # 保存新图片，并优化质量，减少文件体积
    try:
        final_image.save(new_file_name, optimize=True)
    except Exception as e:
        logging.error(f&amp;quot;Failed to save {new_file_name}: {e}&amp;quot;)
        return None, None
    # 获取原图片和新图片的文件体积，并返回
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return file_name, old_size, new_size

# 定义一个函数，解析命令行参数，并返回文件夹路径和扩展名列表
def parse_args():
    # 创建一个解析器对象
    parser = argparse.ArgumentParser(description=&amp;quot;Convert images to black and white and optimize quality.&amp;quot;)
    # 添加一个必选的位置参数，表示文件夹路径
    parser.add_argument(&amp;quot;folder_path&amp;quot;, help=&amp;quot;The path of the folder that contains the images.&amp;quot;)
    # 添加一个可选的参数，表示扩展名列表，默认为 png, jpg, jpeg 和 gif
    parser.add_argument(&amp;quot;-e&amp;quot;, &amp;quot;--extensions&amp;quot;, nargs=&amp;quot;+&amp;quot;, default=[&amp;quot;.png&amp;quot;, &amp;quot;.jpg&amp;quot;, &amp;quot;.jpeg&amp;quot;, &amp;quot;.gif&amp;quot;], help=&amp;quot;The extensions of the image files.&amp;quot;)
    # 解析命令行参数，并返回结果对象
    args = parser.parse_args()
    return args.folder_path, args.extensions

# 定义一个函数，打印优化前后的文件体积大小对比
def print_result(result):
    # 如果结果不为空，说明转换和保存成功
    if result:
        # 解包结果为文件名和文件体积元组
        if len(result) == 3:
            file, old_size, new_size = result
            # 在控制台展示优化前后的文件体积大小对比
            logging.info(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)
        else:
            logging.info(f&amp;quot;{result}&amp;quot;)

# 配置日志记录器，将日志输出到控制台和文件中，设置日志等级为 INFO
logging.basicConfig(level=logging.INFO,
                    format=&amp;quot;%(asctime)s %(levelname)s %(message)s&amp;quot;,
                    handlers=[logging.StreamHandler(),
                              logging.FileHandler(&amp;quot;log.txt&amp;quot;)])

# 调用函数，获取文件夹路径和扩展名列表
folder_path, extensions = parse_args()

if __name__ == &amp;quot;__main__&amp;quot;:
    # Windows 需要这个函数的原因是 Windows 缺乏 fork() 函数（这不完全正确）。
    # 因此，在 Windows 上，fork() 是通过创建一个新的进程来模拟的，这个新的进程中运行的代码，在 Linux 上是在子进程中运行的。
    # 由于这些代码要在技术上无关的进程中运行，所以它必须在运行之前被传递到那里。
    # 传递的方式是先将它们序列化，然后通过管道从原始进程发送到新的进程。
    # 另外，这个新的进程被通知它必须运行通过管道传递的代码，通过向它传递 --multiprocessing-fork 命令行参数。
    # 如果你看一下 freeze_support() 函数的实现，它的任务是检查它运行在哪个进程中，是否应该运行通过管道传递的代码
    multiprocessing.freeze_support()

    # 创建一个进程池，根据电脑的核心数自动分配进程
    pool = multiprocessing.Pool()
    # 创建一个空列表，用于存放异步任务的结果对象
    results = []
    # 遍历文件夹中的所有文件
    for file in os.listdir(folder_path):
        # 拼接完整的文件路径
        file_path = os.path.join(folder_path, file)
        # 判断是否是图片文件，根据扩展名判断，可以根据需要修改扩展名列表
        if any(file_path.endswith(ext) for ext in extensions):
            # 调用函数，转换并保存图片，并获取文件体积，使用异步方式，不阻塞主进程
            result = pool.apply_async(convert_and_save, args=(file_path,), callback=print_result)
            # 将结果对象添加到列表中
            results.append((file, result))
    # 关闭进程池，不再接受新的任务
    pool.close()
    # 等待所有的任务完成
    pool.join()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;사후기&#34;&gt;사후기
&lt;/h2&gt;&lt;p&gt;로컬 개발 환경이 &lt;code&gt;windows&lt;/code&gt; 시스템이기 때문에, &lt;code&gt;AI&lt;/code&gt;가 처음 제시한 답변에는 &lt;code&gt;main&lt;/code&gt; 함수와 &lt;code&gt;multiprocessing.freeze_support&lt;/code&gt;가 포함되지 않았습니다. 질문을 통해 발생한 오류를 해결하여 코드를 수정했습니다.&lt;/p&gt;
&lt;p&gt;과거 검색 엔진 사용법을 배우던 것처럼, AI와 소통하는 방법도 배워야 합니다. 합리적이고 충분한 조건을 제시하여 필요한 답변을 효율적으로 얻어야 합니다.&lt;/p&gt;
&lt;p&gt;주의: &lt;strong&gt;만약 여러분이 프로그래밍 초보이고 주어진 주석을 바탕으로도 이해가 안 되는 부분이 있다면 관련 코드에 대해 계속 질문해도 좋습니다.&lt;/strong&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>AI 지원 프로그래밍, 생산성 진화</title>
        <link>https://ttf248.life/ko/p/ai-assisted-programming-productivity-evolution/</link>
        <pubDate>Tue, 28 Feb 2023 17:05:17 +0800</pubDate>
        
        <guid>https://ttf248.life/ko/p/ai-assisted-programming-productivity-evolution/</guid>
        <description>&lt;p&gt;깃허브 코파일럿이 출시된 지 2년도 채 되지 않았는데, 챗GPT가 등장했네요. 작동 원리는 잘 모르겠지만, 둘 다 한동안 사용하고 있습니다. 두 도구는 보조 기능에서 완전히 다르지만, 생산성 향상에 큰 도움이 됩니다.&lt;/p&gt;
&lt;p&gt;너무 복잡한 일은 아직 AI가 해내지 못합니다. 결국 그들은 논리가 없고, 패턴이 있거나 패러다임이 고정된 일은 훈련 데이터가 충분하면 AI의 효과는 90%까지 도달할 수 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;github copilot
&lt;/h2&gt;&lt;p&gt;발표할 때, 공식 홈페이지의 소개 &lt;code&gt;demo&lt;/code&gt;를 보고 보니까 그렇게 똑똑해 보이지 않았고, 사용해 봤는데 잘 안 돼서 포기했다&lt;/p&gt;
&lt;p&gt;2022년 이전에는, 시간 날 때마다 새로운 버전으로 바꿔서 사용해 보는데, 효과는 꽤 괜찮은 편이야. 다만 국내 속도가 좀 느린 것 같아. 네트워크 문제일 확률이 높지. &lt;code&gt;Python&lt;/code&gt; 같은 언어는 주석을 보고 코드를 짜면, 제가 자료를 찾아 직접 작성하는 것보다 훨씬 빠르더라고요.&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;깃허브 코파일럿은 아직 프로그래머, 즉 개발의 관점에서 제품을 설계하고 있으며, 프로그래밍 방법을 이해해야 하고, 점차 주석을 통해 AI를 보조 프로그래밍하도록 유도해야 합니다&lt;/p&gt;
&lt;p&gt;ChatGPT가 다음 단계로 진화하여 &lt;strong&gt;전문가가 아닌 일반인도 빠르게 익힐 수 있게 되었습니다&lt;/strong&gt;. 대화형 챗 인터페이스 덕분에 질문하고, 요구사항을 설명하며, 이해가 안 되는 부분은 계속해서 질문할 수 있습니다.&lt;/p&gt;
&lt;p&gt;간단한 예시로, 토큰화 개념은 알지만 코딩하는 방법은 모르고 문자열의 유사도를 계산하고 싶습니다&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Python 分词计算 維天運通 LOGORY 和 合肥維天運通信息科技股份有限公司 两个字符串的相似度；
比较前，统一处理字符串，英文转换为小写；
第二个字符中如果能找到第一个字符的首字符，将第二个字符串截位，截位的长度为第一个字符串的长度
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;안녕하세요, 빙입니다. 😊&lt;/p&gt;
&lt;p&gt;온라인 정보에 따르면 123, Python 토큰화 계산은 jieba 라이브러리를 사용하여 구현할 수 있습니다. jieba 라이브러리는 정확 모드, 전체 모드 및 검색 엔진 모드의 세 가지 토큰화 모드를 지원합니다. 필요에 따라 적절한 모드를 선택할 수 있습니다.&lt;/p&gt;
&lt;p&gt;두 문자열의 유사도를 비교하려면 먼저 토큰화한 다음 단어 벡터 또는 편집 거리와 같은 지표를 계산해야 합니다. 수학 연산에는 numpy나 scipy 등의 라이브러리를 사용할 수 있습니다.&lt;/p&gt;
&lt;p&gt;문자열을 일관되게 처리하기 위해 영문자를 소문자로 변환하려면 Python의 내장 함수 lower()를 사용할 수 있습니다&lt;/p&gt;
&lt;p&gt;두 번째 문자열을 추출하려면 Python의 슬라이스 연산자 []를 사용할 수 있습니다&lt;/p&gt;
&lt;p&gt;다음은 가능한 코드 예제입니다&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import jieba
import numpy as np
from scipy.spatial.distance import cosine

# 定义两个字符串
str1 = &amp;quot;維天運通 LOGORY&amp;quot;
str2 = &amp;quot;合肥維天運通信息科技股份有限公司&amp;quot;

# 统一处理字符串，英文转换为小写
str1 = str1.lower()
str2 = str2.lower()

# 找到第二个字符串中第一个字符的位置
index = str2.find(str1[0])

# 如果找到了，截取第二个字符串
if index != -1:
    str2 = str2[index:index+len(str1)]

# 使用 jieba 库进行分词
words1 = list(jieba.cut(str1))
words2 = list(jieba.cut(str2))

# 计算两个字符串的词向量（以词频作为权重）
vector1 = np.zeros(len(words1))
vector2 = np.zeros(len(words1))

for i, word in enumerate(words1):
    vector1[i] += 1 # 统计第一个字符串中每个词出现的次数
    if word in words2:
        vector2[i] += 1 # 统计第二个字符串中每个词出现的次数

# 计算两个字符串的相似度（以余弦距离作为指标）
similarity = 1 - cosine(vector1, vector2)

print(&amp;quot;两个字符串的相似度是：&amp;quot;, similarity)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;더 나아가서, 실행 결과를 문의했더니, 당신을 축하하며 문제점을 발견했습니다. 결과는 날조된 것이고, 실제 코드를 실행하지 않고도 괜찮은 결과를 보여줍니다.&lt;/p&gt;
&lt;h3 id=&#34;밤&#34;&gt;밤
&lt;/h3&gt;&lt;p&gt;SQL 쿼리, 제품 코드 테이블에서 제품 코드가 80000부터 89999 사이인 레코드를 찾아주세요&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;你好，这是 Bing。😊

根据搜索结果12，你可以使用 SQL BETWEEN 运算符来选择给定区间内的值。BETWEEN 运算符包含了开始和结束的值。

你需要先指定要查询的表名和列名，然后在 WHERE 子句中使用 BETWEEN 运算符和区间值。

例如，如果你要查询产品代码表中，产品代码在 80000 到 89999 之间的记录，你可以使用以下语句：

SELECT * FROM product_code
WHERE code BETWEEN 80000 AND 89999;
这里，* 表示选择所有列3。如果你只想选择特定的列，比如产品名称和价格，你可以用逗号分隔它们，如下：

SELECT name, price FROM product_code
WHERE code BETWEEN 80000 AND 89999;
希望这能帮助到你。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;계속 질문하고 반박하세요: 제품 코드는 문자열인데, 당신의 코드가 잘못되었습니다&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;抱歉，我没有注意到产品代码是字符串。如果是这样的话，你需要在区间值两边加上单引号，如下：

SELECT * FROM product_code
WHERE code BETWEEN &#39;80000&#39; AND &#39;89999&#39;;
请原谅我的错误。🙏
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;축하해요, 틀릴 거예요&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

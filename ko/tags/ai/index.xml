<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>AI on 향숙의 수첩</title>
        <link>https://ttf248.life/ko/tags/ai/</link>
        <description>Recent content in AI on 향숙의 수첩</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>ko</language>
        <lastBuildDate>Wed, 28 May 2025 09:47:38 +0800</lastBuildDate><atom:link href="https://ttf248.life/ko/tags/ai/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>오래된 습관, 화려함에 눈이 멀다</title>
        <link>https://ttf248.life/ko/p/old-ailment-stunning-flowers/</link>
        <pubDate>Mon, 26 May 2025 23:54:12 +0800</pubDate>
        
        <guid>https://ttf248.life/ko/p/old-ailment-stunning-flowers/</guid>
        <description>&lt;p&gt;수년간 백엔드 개발에 집중해 왔는데, 최근 프론트엔드 인터페이스를 구현하기 위해 &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; 编程，并涉足了一些前端相关的内容。然而，在这段折腾的过程中，我逐渐意识到自己又陷入了一个老毛病——繁花迷人眼。总想着用 __INLINE_CODE_1__을 시도하기 시작했으나, 실제로는 현재 업무에 큰 도움이 되지 않고 오히려 에너지를 분산시키는 것 같습니다&lt;/p&gt;
&lt;h2 id=&#34;ai-적용-사례&#34;&gt;AI 적용 사례
&lt;/h2&gt;&lt;p&gt;소규모 프로젝트에서는 특히 독립성이 강하고 시스템과의 연계가 낮으며 비즈니스 로직이 간단한 함수를 작성할 때, AI 도구가 큰 역할을 할 수 있습니다. 이러한 작업은 일반적으로 명확한 입력과 출력을 가지며 컨텍스트 의존성이 적어 현재 AI 지원 프로그래밍의 역량 범위에 매우 적합합니다.&lt;/p&gt;
&lt;p&gt;그러나 복잡한 시스템 아키텍처나 심층적인 비즈니스 로직에 직면하면 AI의 한계가 점차 드러난다. AI는 겉으로는 합리적이지만 실제로는 프로젝트의 요구사항과 동떨어진 코드를 생성하거나, 해결하기 어려운 잠재적인 문제를 유발할 수도 있다. 이러한 상황에서는 AI를 완전한 코드 생성 도구로 의존하기보다는 보조 도구로 활용하는 것이 적절하다. 생성된 코드는 엄격하게 검토하고 테스트하여 실제 요구사항을 충족하는지 확인해야 한다.&lt;/p&gt;
&lt;h2 id=&#34;실패와-학습의-대가&#34;&gt;실패와 학습의 대가
&lt;/h2&gt;&lt;p&gt;AI를 활용하여 프론트엔드 코드를 생성하려 시도하는 과정에서 여러 어려움에 직면했습니다. 프론트엔드는 제가 익숙한 분야가 아니기 때문에 문제 해결 과정이 시간과 노력이 많이 소요됩니다. 프롬프트를 조정하여 AI가 코드를 재작성해도 초보적인 오류를 피하기 어렵습니다. 이러한 반복적인 시도는 시간을 낭비할 뿐만 아니라, 현재 제 에너지를 익숙하지 않은 분야에서 헤매는 대신 백엔드 비즈니스 로직에 집중하는 것이 더 중요함을 깨닫게 했습니다.&lt;/p&gt;
&lt;p&gt;주말에 완료한 그 프로젝트를 돌이켜보면, 백엔드 개발과 사용자 인터랙션 로직에 집중하고 콘솔을 통해 기능을 구현하는 것이 현재 가장 효율적인 선택이라는 확신이 듭니다. 더 많은 시간과 에너지가 있을 때 시스템적으로 프론트엔드 지식을 학습하는 것이 더 나은 전략일 수도 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;프론트엔드-학습-계획&#34;&gt;프론트엔드 학습 계획
&lt;/h2&gt;&lt;p&gt;프론트엔드 기술 스택이 복잡하고 다양해서 빠르게 익히는 것은 현실적이지 않습니다. 그래서 Vue.js나 React.js와 같이 하나의 프레임워크를 선택하여 핵심 개념과 사용법을 깊이 있게 학습할 계획입니다. 기초 지식을 숙지한 후에야 AI를 활용하여 프론트엔드 코드를 생성하면, 미숙함으로 인한 오류와 시간 낭비를 효과적으로 막을 수 있습니다.&lt;/p&gt;
&lt;p&gt;결국, 현재 단계에서는 백엔드 개발에 집중하며 핵심 역량을 꾸준히 강화하는 것이 중요합니다. 시기가 되면 프론트엔드와 AI의 결합을 탐색하면 더 큰 성과를 얻을 수 있을 것입니다.&lt;/p&gt;</description>
        </item>
        <item>
        <title>클로드4 출시, hugo 태그 및 하이퍼링크 번역 도우미 개발 시도</title>
        <link>https://ttf248.life/ko/p/claude-4-release-and-experimentation-hugo-tags-hyperlink-translation-assistant/</link>
        <pubDate>Sat, 24 May 2025 03:05:31 +0800</pubDate>
        
        <guid>https://ttf248.life/ko/p/claude-4-release-and-experimentation-hugo-tags-hyperlink-translation-assistant/</guid>
        <description>&lt;p&gt;이 사이트는 hugo 기반이지만, 글 제목을 항상 중국어로 사용했기 때문에 생성되는 기사 링크가 친절하지 않습니다. 쉽게 말해서, 공유할 때 보기 좋지 않고, 중국어 문자가 링크에서 %E4%BD%A0%E5%A5%BD 와 같은 형태로 변환되기 때문입니다. 슬러그를 설정하여 해결할 수 있지만, 매번 수동으로 설정해야 해서 번거롭습니다.&lt;/p&gt;
&lt;p&gt;그래서 오늘 클로드4를 활용해 중국어 제목을 영어 슬러그로 자동 변환하고, 기사에 하이퍼링크를 추가하는 번역 도우미를 개발해 보았습니다. 이렇게 하면 수동 설정의 번거로움을 피할 수 있습니다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;클로드4는 정말 좋네요, 문맥 이해 능력과 복잡한 작업 처리 효율이 크게 향상되었습니다&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;프로젝트-주소&#34;&gt;프로젝트 주소
&lt;/h2&gt;&lt;p&gt;국내 프로젝트 주소: &lt;a class=&#34;link&#34; href=&#34;https://cnb.cool/ttf248/hugo-content-suite&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://cnb.cool/ttf248/hugo-content-suite&lt;/a&gt;
해외 프로젝트 주소: &lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/hugo-content-suite&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/hugo-content-suite&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;코드-구현&#34;&gt;코드 구현
&lt;/h2&gt;&lt;p&gt;먼저 구현 아이디어부터 설명드리자면, 모든 문서를 스캔하여 태그 정보와 문서 제목을 추출한 다음, 로컬의 대형 모델(예: gemma-3-12b-it)을 사용하여 번역합니다&lt;/p&gt;
&lt;p&gt;실제 개발에서, 이전 세대 대규모 모델과 비교하여 &lt;code&gt;Claude4&lt;/code&gt; 展现了几个显著的亮点。由于功能需求较多，&lt;code&gt;Claude4&lt;/code&gt; 自动设计了交互式菜单，全面考虑了各种使用场景。例如，在标签处理方面，&lt;strong&gt;INLINE_CODE_2&lt;/strong&gt; 不仅支持标签的统计与分析，还包括分类统计，甚至能够检测** 태그 없는 문서 &lt;strong&gt;。此外，它还提供了&lt;/strong&gt; 미리 보기 및 생성 기능&lt;/p&gt;
&lt;p&gt;어떤 로컬 모델과 연결하든, 새로운 번역 캐시를 추가하든, 아니면 광범위한 코드 리팩토링을 하든, &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; 都一次性完成，几乎没有出现任何问题。尽管项目规模不大，但包含了许多小功能。以往在开发过程中，大模型经常会遗忘前面的内容，而这次的 &lt;strong&gt;INLINE_CODE_1&lt;/strong&gt; 表现非常出色，**거의 문맥을 잃는 경우가 발생하지 않습니다&lt;/p&gt;
&lt;p&gt;간단히 말해서, 지능이 향상되었고, 이후 개발 작업의 주력 모델로 사용하기 위해 __INLINE_CODE_0__으로 전환할 준비를 하고 있습니다&lt;/p&gt;
&lt;h2 id=&#34;번역-캐시&#34;&gt;번역 캐시
&lt;/h2&gt;&lt;p&gt;이 점은 단독으로 볼 때, 거대 모델 호출 횟수를 줄이는 것 외에도 실제 로컬에서 12B 모델을 실행하면 효율이 괜찮고 업무를 방해하지 않지만, 매번 거대 모델을 호출해야 하면 약간 느려지는 경향이 있습니다. 또한, 기사의 연결을 고정하기 위해 전체 업데이트 작업을 수행할 때 기사 제목이 길면 가끔씩 두 번 번역된 결과가 달라져서 기사 링크가 바뀌는 경우가 있는데, 이 부분은 상당히 난감합니다.&lt;/p&gt;
&lt;h2 id=&#34;기능-개선&#34;&gt;기능 개선
&lt;/h2&gt;&lt;p&gt;전체 프로젝트를 __INLINE_CODE_0__에게 맡기고 분석 및 최적화 여지를 확인한 결과, 다음과 같은 제안을 받았습니다&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;配置外置化 - 提高可维护性和灵活性
结构化日志 - 便于问题排查和监控
性能监控 - 了解系统运行状况
用户体验 - 进度条等视觉反馈
错误处理 - 更完善的异常处理机制
代码组织 - 更清晰的模块划分
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;코드 검토 결과, 문제 없습니다. 예를 들어 설정 파일의 경우, 기존 코드 설정을 기본 설정으로 변환하고, 설정 파일을 읽을 때 해당 파일이 없으면 자동으로 생성하여 사용자 실수로 인한 오류를 방지합니다.&lt;/p&gt;
&lt;h3 id=&#34;heading&#34;&gt;
&lt;/h3&gt;&lt;p&gt;요구 사항: 본문 번역 시 현재 번역 효율을 동적으로 계산하고, 남은 시간을 예측하여 콘솔에 관련 정보를 출력합니다. 현재 획득한 문서의 문자 수, 각 행 번역 시 현재 번역된 문자 수, 시간, 100자당 예상 번역 시간 등을 계산하며, 문서의 남은 번역 예상 시간도 함께 계산합니다.&lt;/p&gt;
&lt;p&gt;코드는 마무리했는데, 결과가 만족스럽지 않아서 AI에게 새로운 디자인 방안을 제시하도록 했어:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;다양한 효율성 계산 방식 제공: 실시간 효율, 평균 효율, 슬라이딩 윈도우 효율&lt;/li&gt;
&lt;li&gt;표시 방식 개선: 진행률 표시줄, 단계별 통계, 동적 새로 고침&lt;/li&gt;
&lt;li&gt;더 유용한 지표 추가: API 호출 횟수, 성공률 등&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;코드 완성 후 새로운 깜짝 놀랄 일이 발견되었는데, 번역 효율 통계 정보가 실시간으로 화면을 채우지만 맹목적으로 아래로 스크롤되지는 않는다&lt;/p&gt;
&lt;p&gt;번역 전문을 영어로 번역 중입니다(총 7163자)
53행이 번역 필요로 감지됨
[1/53] Stage1/6 [░░░░░░░░░░░░░░░░░░░░░░░░░] 1.9% 번역 354자.
✅ 완료 (3.1초) | API 호출 #1
✅ 완료 (1.5초) | API 호출 #2
완료 (0.9초) | API 호출 #3
완료 (0.2초) | API 호출 #4
완료 (1.0초) | API 호출 #5
완료 (1.0초) | API 호출 #6
완료 (0.2초) | API 호출 #7
📊 진행률: 행 13.2% (7/53) | 문자 12.9% (925/7163) 114.6자/초 📊
⚡ 효율성: 실시간 76.4 | 평균 117.9 | 최근 109.0 | 단계별 113.6 자/초 📊
성공률: 100.0% (7/7) | 남은 항목: 46행, 7초] 9.4% 번역 110자.
예상 남은 시간: 55초 | 완료 예상: 00:10:19 8초] 11.3% 번역 114자…
처리 속도: 3211.3 행/분 | 총 소요 시간: 8초] 13.2% 번역 16 문자.
[8/53] Stage1/6 [███░░░░░░░░░░░░░░░░░░░░░░] 15.1% 번역 166자.&lt;/p&gt;
&lt;p&gt;이전에는 제어 프로그램 코드를 많이 작성해보지 않아서 어떻게 구현되었는지 궁금해서 코드 확인해 보았다&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;// 清屏并重新显示 (动态刷新效果)
if translationCount &amp;gt; 1 {
   fmt.Print(&amp;quot;\033[6A\033[K&amp;quot;) // 上移6行并清除
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;성능-통계-메뉴&#34;&gt;성능 통계 메뉴
&lt;/h3&gt;&lt;p&gt;새로 추가된 &lt;strong&gt;性能统计菜单&lt;/strong&gt;, 제가 직접 디자인해도 이렇게 완벽하게 만들 수 있을지 모르겠네요&lt;/p&gt;
&lt;p&gt;성능 통계:
번역 횟수: 360
⚡ 캐시 적중률: 1.4% (5/365)
평균 번역 시간: 315.927234ms
파일 작업: 73
오류 횟수: 0&lt;/p&gt;
&lt;h3 id=&#34;진행률-표시&#34;&gt;진행률 표시
&lt;/h3&gt;&lt;p&gt;새로운 &lt;strong&gt;进度条显示&lt;/strong&gt;, 상세한 진행 상황, 소요 시간, 남은 시간 예측&lt;/p&gt;
&lt;p&gt;기능 선택 (0-13): 10
번역 목표를 수집 중입니다…
📄 캐시 파일이 로드되었습니다. 번역 기록 0개 포함&lt;/p&gt;
&lt;p&gt;번역 캐시 통계:
🏷️ 총 태그 수: 229개
📝 총 기사 수: 131건
✅ 캐시됨: 0개
🔄 번역 필요: 360개&lt;/p&gt;
&lt;p&gt;전체 번역 캐시 생성 확인하시겠습니까? (y/n): y
🚀 전체 번역 캐시 생성 중…
📄 캐시 파일이 로드되었습니다. 번역 기록 0개 포함
검색 중인 번역 확인 중…
새로운 태그 360개 번역 필요
[░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 5/360 (1.4%) - 소요시간: 3초 - 예상 남은 시간: 3분 8초💾 캐시 파일 저장 완료, 번역 기록 5개 포함
[█░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 10/360 (2.8%) - 소요시간: 6초 - 예상 남은 시간: 3분 28초💾 캐시 파일 저장, 번역 기록 10개 포함
[██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 15/360 (4.2%) - 소요시간: 9초 - 예상 남은 시간: 3분 30초💾 캐시 파일 저장 완료, 번역 기록 15개 포함
[██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 20/360 (5.6%) - 소요시간: 13초 - 예상 남은 시간: 3분 36초💾 캐시 파일 저장 완료, 번역 기록 20개 포함
[███░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 25/360 (6.9%) - 소요시간: 16초 - 예상 남은 시간: 3분 33초💾 캐시 파일 저장 완료, 번역 기록 25개 포함
[████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 30/360 (8.3%) - 소요시간: 19초 - 예상 남은 시간: 3분 30초💾 캐시 파일 저장 완료, 번역 기록 30개 포함
[████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 35/360 (9.7%) - 용량: 22s - 예상 남은 시간: 3분 25초💾 캐시 파일 저장 완료, 번역 기록 35개 포함&lt;/p&gt;
&lt;hr&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;=== Hugo 博客管理工具 ===

🚀 核心功能
  1. 一键处理全部 (完整博客处理流程)

📝 内容管理
  2. 生成标签页面
  3. 生成文章Slug
  4. 翻译文章为多语言版本

💾 缓存管理
  5. 查看缓存状态
  6. 生成全量翻译缓存
  7. 清空翻译缓存

  0. 退出程序
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>AI를 너무 많이 쓰니, 약간의 후유증이 있네요</title>
        <link>https://ttf248.life/ko/p/ai-overuse-side-effects/</link>
        <pubDate>Wed, 14 May 2025 19:39:50 +0800</pubDate>
        
        <guid>https://ttf248.life/ko/p/ai-overuse-side-effects/</guid>
        <description>&lt;p&gt;새로운 __INLINE_CODE_0__이 생긴 이후로, 별 볼 일 없는 것들을 AI로 기록하고 게시하는 데 많은 노력을 쏟고 있는데, 정적이고 스스로 생각하는 시간은 점점 줄어들고 있습니다. 앞으로 이 항목의 생산을 조금 통제하고 월간 형태로 통합하는 것이 좋겠습니다. 매달 한 편씩 발행하면 될 것 같습니다.&lt;/p&gt;
&lt;p&gt;이것은 일종의 후유증과 같거나, 부작용이라고 할 수 있는데, 효율은 높아졌지만 사고의 깊이와 넓이는 얕아졌다&lt;/p&gt;
&lt;h2 id=&#34;효율성-향상-부정할-수-없다&#34;&gt;효율성 향상: 부정할 수 없다
&lt;/h2&gt;&lt;p&gt;__INLINE_CODE_0__예전에는 이 코너를 잘 관리하지 않았습니다. 몇몇 주요 이슈에 대해서는 게으름 때문에 인터넷에서 자료를 검색하고 정리하는 일은 하지 않았죠. 요즘은 다양한 AI 도구가 생겨서 개요만 작성하면, AI가 자동으로 관련 정보를 검색하고 기록하여 필요한 글을 생성해 줍니다. 간단히 서식을 정리해서 게시하면 됩니다.&lt;/p&gt;
&lt;p&gt;이것은 게으름뱅이를 위한 구세주와도 같아서, 효율이 눈에 띄게 높아졌고, 노력의 절반으로 두 배의 효과를 보는 것 같습니다&lt;/p&gt;
&lt;p&gt;스크립트 작성은 잠시 접어두고 코딩할 때 효율이 눈에 띄게 올라갔다. 이전에는 API 인터페이스 문서 설명을 자세히 읽어야 했는데, 이제는 그냥 넘어가도 되는데, 이런 점화는 상당히 유용하다. API 숙지는 __INLINE_CODE_0__BOLD_2&lt;code&gt;脑力劳动&lt;/code&gt;의 영역이고, AI가 이 부분을 처리하기에 딱 좋다.&lt;/p&gt;
&lt;h2 id=&#34;쓰레기-내용&#34;&gt;쓰레기 내용
&lt;/h2&gt;&lt;p&gt;많은 원고들이 있는데, 내용 품질이 높지 않아. 완전히 엉망인 것은 아니지만, 읽으면 활력이 없고, 예전부터 싫어했던 스타일이야. 밋밋하고 재미없어.&lt;/p&gt;
&lt;p&gt;AI가 생성한 콘텐츠는, 바꿔 말하면, 마치 조립 라인에서 나온 것처럼 영혼이 부족하다고 할 수 있습니다&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;새 시대의 인터넷 쓰레기&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;망각성&#34;&gt;망각성
&lt;/h2&gt;&lt;p&gt;이런 종류의 초고는 AI가 생성한 것이고, 독자 상황은 파악하기 어렵지만, 시간이 지나면 제 기억조차 흐릿해지거나 잊혀질 수도 있습니다&lt;/p&gt;
&lt;p&gt;비슷한 문제가 코딩할 때도 발생하는데, 코드 커밋 기록을 확인하지 않으면 당시 어떻게 생각했는지, 왜 그렇게 썼는지 전혀 알 수 없다. 특히 코드 검토와 AI와의 반복적인 소통 끝에 생성된 코드는 처음의 생각과 크게 달라서 심지어 완전히 다른 경우도 있다.&lt;/p&gt;
&lt;h2 id=&#34;검색&#34;&gt;검색
&lt;/h2&gt;&lt;p&gt;최근에 구글이나 바이두를 열어보는 횟수가 눈에 띄게 줄었다. AI로 검색하면 상호작용도 좋고 검색 결과도 전통적인 검색 엔진보다 훨씬 낫다.&lt;/p&gt;
&lt;p&gt;지금은 생존 여부가 불분명한 __INLINE_CODE_0__에게 경의를 표하며, 대기업 내에서 가장 먼저 출시된 인터넷 검색 기능이 탑재된 AI 도구입니다&lt;/p&gt;
&lt;p&gt;구글을 잘 안 쓰게 됐고, &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; 접속 횟수도 줄어들었어. 많은 문제를 AI에 바로 물어볼 수 있어서 이 사이트는 점점 시대에 뒤쳐질 것 같아.&lt;/p&gt;
&lt;h2 id=&#34;마무리&#34;&gt;마무리
&lt;/h2&gt;&lt;p&gt;제가 관리 중인 블로그는 원래 방문자 수가 많지 않았고, 지금은 더 기대하기 어렵습니다. 주로 기록하는 곳이며, 제 자신을 위해 쓰는 것입니다.&lt;/p&gt;</description>
        </item>
        <item>
        <title>코딩 없이 맞춤 주식 모듈 설계 개발</title>
        <link>https://ttf248.life/ko/p/no-code-design-develop-custom-stock-module/</link>
        <pubDate>Thu, 27 Feb 2025 23:20:39 +0800</pubDate>
        
        <guid>https://ttf248.life/ko/p/no-code-design-develop-custom-stock-module/</guid>
        <description>&lt;p&gt;지난달에 커서를 시험 사용해 봤는데, 무료 한도 때문에 복잡한 기능 개발은 못 하고 간단히 테스트만 했습니다. 그때쯔음에 바이트(Byte)도 유사한 제품을 출시했고, 두 제품 모두 Claude-3.5를 기반으로 하고 있습니다.&lt;/p&gt;
&lt;p&gt;바이트의 제품인 Trae가 먼저 Mac 버전으로 출시되었고, 올해 2월에 드디어 Windows 버전이 나왔다. 대기업 제품은 역시 좋아서, 무료로 사용할 수 있고 돈을 낼 필요 없이 Claude-3.5를 무제한으로 사용할 수 있다. 이 모델 성능은 아주 괜찮다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;결국 K라인 차트 개발에 막혀서, 본인은 React를 거의 모르는 관계로 포기해야 했습니다. 계속 개발하려면 저자가 프론트엔드 기초 지식을 보충하고, “K라인 차트 개발”과 같이 큰 덩어리의 과제를 바로 주지 않고 더 세분화된 작은 단위로 나누어야 합니다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;발견된-문제&#34;&gt;발견된 문제
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;해외 AI 모델 사용으로 인해 Vue3 + Element-Plus의 학습 데이터가 부족하여, 프론트엔드 프레임워크로 React를 선택했습니다&lt;/li&gt;
&lt;li&gt;일부 문법 오류가 발생할 수 있으며, 사람이 직접 수정해야 합니다&lt;/li&gt;
&lt;li&gt;일부 복잡한 문제 해결에는 인공 지침이 필요합니다&lt;/li&gt;
&lt;li&gt;코드 구조 최적화는 수동 지침이 필요합니다&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;가장 시간이 오래 걸린 부분은 프론트엔드 코드를 컨테이너에 패키징하는 것이었는데, 저의 __INLINE_CODE_0__BOLD_2&lt;code&gt;tsconfig.json&lt;/code&gt; 지식 부족으로 전혀 감이 잡히지 않았습니다. 중간에 도움을 받아야 겨우 로직을 파악할 수 있었습니다. 프론트엔드 개발의 dev 모드와 build 모드는 코드 검사에서 큰 차이가 있습니다. 백엔드 데이터베이스 및 서비스 컨테이너 스크립트는 총 5분 만에 처리했습니다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI 目前更多的提高开发的效率，你有基础是最好的，并不是 AI 会帮你解决所有的问题&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;창고-주소&#34;&gt;창고 주소
&lt;/h2&gt;&lt;p&gt;제목에서 언급했듯이, 이번에는 코딩을 하지 않고 AI와 직접 대화하며 자체 선택 주식 모듈을 설계하고 개발해 봅니다. 최종 결과물이 어떻게 나올지 보겠습니다.&lt;/p&gt;
&lt;p&gt;창고 주소: &lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/trae-demo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/trae-demo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;자세한 사용 방법은 저장소의 README.md 파일을 참조하세요&lt;/p&gt;
&lt;p&gt;창고에는 많은 제출 기록이 포함되어 있는데, 대부분은 저와 트레이의 대화 기록과 제가 트레이의 몇몇 기능들을 테스트한 내용이며, 해당 기능을 구현하기 위해 수동 개입이 있었는지 여부를 메모해 두었습니다&lt;/p&gt;
&lt;h2 id=&#34;prompt&#34;&gt;Prompt
&lt;/h2&gt;&lt;p&gt;프로젝트는 처음부터 시작되었으며, 아래는 프로젝트 프롬프트입니다:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;基于项目原型图，开发功能：自选股，需要支持合约的新增、删除、修改、查询。自选股界面需要展示基础的行情数据。支持多个不同的市场切换。

前端：react
后端：golang gin gorm
数据库：PostgreSQL

服务端需要支持跨域请求，同时需要考虑数据的校验和错误处理，如果后端服务不可用，前端需要告警提示。

后端需要展示请求和应答的日志；前端也打印通讯的日志，方便排查问题。
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;ui-및-상호작용-최적화&#34;&gt;UI 및 상호작용 최적화
&lt;/h2&gt;&lt;p&gt;프론트엔드 디자인은 Grok에 완전히 의존하며, 우리는 먼저 Trae에서 제품의 초기 형태를 만들었지만 심미적인 부분은 부족했습니다. 사용한 모델은 코드 능력은 뛰어나지만 다른 기능이 상대적으로 약하기 때문에 Grok을 사용하여 프론트엔드 UI를 최적화해야 합니다.&lt;/p&gt;
&lt;p&gt;현재 인터페이스 스크린샷을 찍어 Grok에 업로드한 후, UI 최적화를 요청하면 여러 건의 제안을 받을 수 있습니다. 저희는 이를 검토하고 Trae에서 실행하여 최적화 효과를 확인합니다.&lt;/p&gt;
&lt;h3 id=&#34;기술-스택&#34;&gt;기술 스택
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;프론트엔드: React + TypeScript&lt;/li&gt;
&lt;li&gt;백엔드: Golang + Gin + GORM&lt;/li&gt;
&lt;li&gt;데이터베이스: PostgreSQL 17&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;시스템-아키텍처&#34;&gt;시스템 아키텍처
&lt;/h2&gt;&lt;h2 id=&#34;백엔드-아키텍처&#34;&gt;백엔드 아키텍처
&lt;/h2&gt;&lt;p&gt;백엔드는 Golang의 Gin 프레임워크로 구현된 RESTful API이며, 주요 모듈은 다음과 같습니다:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;数据库模块&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;GORM을 ORM 프레임워크로 사용&lt;/li&gt;
&lt;li&gt;환경 변수를 통해 데이터베이스 연결을 구성할 수 있습니다&lt;/li&gt;
&lt;li&gt;자동으로 데이터베이스 테이블 마이그레이션&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;路由模块&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;RESTful API 설계&lt;/li&gt;
&lt;li&gt;통일된 오류 처리 메커니즘&lt;/li&gt;
&lt;li&gt;내장 요청 로깅&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;跨域处理&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;로컬 개발 환경 간의 교차 도메인 접근을 지원합니다&lt;/li&gt;
&lt;li&gt;구성 가능한 CORS 정책&lt;/li&gt;
&lt;li&gt;쿠키 크로스 도메인 지원&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;프론트엔드-아키텍처&#34;&gt;프론트엔드 아키텍처
&lt;/h2&gt;&lt;p&gt;리액트(React) + 타입스크립트(TypeScript)로 구축하여 다음과 같은 기능을 구현했습니다:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;주식 목록 표시&lt;/li&gt;
&lt;li&gt;자선주 관리&lt;/li&gt;
&lt;li&gt;시장 데이터 표시&lt;/li&gt;
&lt;li&gt;오류 표시 메커니즘&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>AI 발전 2년: 도커 출시 전과 비슷한 상황</title>
        <link>https://ttf248.life/ko/p/ai-development-two-years-docker-pre-release/</link>
        <pubDate>Thu, 20 Feb 2025 18:16:37 +0800</pubDate>
        
        <guid>https://ttf248.life/ko/p/ai-development-two-years-docker-pre-release/</guid>
        <description>&lt;p&gt;최근 몇 년간 인공지능(AI)은 기술 분야에서 가장 활발하게 논의되는 주제 중 하나이며, 특히 지난 2년간 AI 기술이 비약적으로 발전했습니다. 심층 학습, 자연어 처리, 컴퓨터 비전, 자동화 의사 결정 시스템 등 AI 적용 사례는 끊임없이 등장하고 있습니다. 하지만 기술적 진보에도 불구하고 AI는 Docker 출시 이전과 유사한 병목 현상에 직면해 있는데, 시장을 폭발적으로 성장시킬 만한 &amp;lsquo;경험 있는 애플리케이션&amp;rsquo;이 부족하기 때문입니다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;AI 발전 두 해, 도커 출시 전과 비슷한 상황입니다. 아직 게임 체인저와 같은 Killer 앱이 없고, 현재 기술 기반으로 완벽한 활용 사례를 만들어내야 합니다. 도커는 획기적인 신기술을 많이 사용하지 않았지만, 전체 솔루션이 매우 합리적이었고 운영 및 개발 업무 흐름을 변화시켰습니다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;인공지능-발전-현황-기술은-성숙했지만-적용은-아직-돌파구를-찾아야-한다&#34;&gt;인공지능 발전 현황: 기술은 성숙했지만, 적용은 아직 돌파구를 찾아야 한다
&lt;/h2&gt;&lt;p&gt;기술적인 측면에서 볼 때, AI는 지난 2년간 상당한 발전을 이루었습니다. OpenAI의 GPT 시리즈 모델이나 Google의 BERT, DeepMind의 Alpha 시리즈처럼 AI의 처리 능력은 이전 예상보다 훨씬 뛰어넘었습니다. 특히 자연어 처리 분야에서 GPT-4와 같은 모델들은 강력한 생성 능력을 갖추는 것은 물론 이해와 추론에서도 놀라운 성능을 보여주고 있습니다.&lt;/p&gt;
&lt;p&gt;그럼에도 불구하고, 기술이 비약적으로 발전했음에도 불구하고 AI의 실제 적용은 여전히 어려움을 겪고 있습니다. Docker 출시 이전과 마찬가지로 AI의 잠재력은 크지만 아직 광범위하게 보급되어 산업을 변화시킬 만한 혁신적인 killer application은 나타나지 않았습니다. 많은 사람들이 AI의 전망에 대해 이야기하지만, 직접적으로 혁명적인 변화를 가져올 수 있는 애플리케이션 시나리오를 찾기는 쉽지 않습니다. 현재 많은 AI 애플리케이션은 초기 단계에 머물러 있으며, 대부분 추가 통합 및 최적화가 필요합니다.&lt;/p&gt;
&lt;h2 id=&#34;도커와-ai의-유사성-기술-자체가-혁신이-아니라-솔루션이-핵심이다&#34;&gt;도커와 AI의 유사성: 기술 자체가 혁신이 아니라, 솔루션이 핵심이다
&lt;/h2&gt;&lt;p&gt;만약 Docker 출시 이전의 역사를 되돌아보면, 당시 기술 환경과 AI 발전 현황 사이에 많은 유사점을 발견할 수 있습니다. Docker가 등장하기 전, 컨테이너 기술은 이미 새로운 것이 아니었습니다. 초기 LXC(Linux Containers)나 가상화 기술들은 이미 컨테이너화의 기본적인 기능을 갖추고 있었습니다. 하지만 Docker는 기존 기술을 능숙하게 통합하고 최적화하여 더욱 간단하고 직관적이며 효율적인 솔루션을 제시했습니다. 이 솔루션은 획기적인 기술을 도입한 것은 아니지만, 운영 및 개발 과정에서 많은 어려움을 해결하고 소프트웨어 배포, 확장 및 관리 프로세스를 크게 단순화했습니다.&lt;/p&gt;
&lt;p&gt;동일하게도 AI 분야 또한 유사한 상황에 직면해 있습니다. 현재의 AI 기술은 더 이상 “새로운 물건”이 아니지만, 진정으로 대규모 적용을 달성하기 위해서는 Docker처럼 기존 기술을 융합하고 최적화하여 합리적인 애플리케이션 방안을 형성하는 완벽한 실행 사례가 필요합니다. AI의 핵심 애플리케이션은 새로운 기술 혁신에 의존하기보다는 기존 기술을 통합하여 실제 비즈니스에서 발생하는 문제점과 요구사항을 해결하는 데 달려 있을 수 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;ai의-도커-순간은-어떻게-찾아낼-수-있을까&#34;&gt;AI의 “도커 순간”은 어떻게 찾아낼 수 있을까?
&lt;/h2&gt;&lt;p&gt;AI 기술이 진정으로 널리 활용되려면 여러 측면에서 노력해야 합니다&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;实际场景的深度挖掘&lt;/strong&gt;
현재 많은 AI 활용 사례는 아직 실험적인 성격이 강하고 대규모로 실제 적용되지는 못하고 있습니다. 예를 들어, AI 고객 상담이나 지능형 추천과 같은 분야는 널리 사용되고 있지만 기능에 여러 제약이 있어 산업의 난관을 돌파하지 못했습니다. 진정한 도약은 전통적인 방법으로 오랫동안 어려움을 겪어왔던 의료, 제조업, 물류와 같은 분야에서 발생할 수 있으며, AI는 더욱 효율적인 데이터 처리 및 예측 분석을 통해 기업이 이러한 복잡한 환경에서 효율성을 높이고 비용을 절감하도록 도울 수 있습니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;产品化与易用性&lt;/strong&gt;
Docker와 같이 컨테이너화 프로세스를 간소화하여 운영 효율성을 높이는 것처럼, AI 제품의 사용 편의성 또한 매우 중요합니다. AI 보급은 기술 보급일 뿐만 아니라 제품화된 보급입니다. AI를 일상 업무 흐름에 통합하고, 사용자가 심도 있는 기술 이해 없이도 쉽게 이러한 도구를 활용할 수 있도록 하는 것이 AI 상용화의 중요한 단계입니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;生态建设与标准化&lt;/strong&gt;
어떤 새로운 기술이든 널리 활용되려면 생태계 구축이 필수적이다. Docker가 빠르게 성장한 이유는 바로 개방성과 호환성 덕분인데, 개발자들이 다양한 클라우드 플랫폼, 도구 및 서비스와 쉽게 연동할 수 있도록 했기 때문이다. 마찬가지로 AI의 미래 또한 생태계 구축에 달려있다. AI의 표준화, 모델 공유, 데이터 개방, 기술 통합성은 AI가 광범위한 산업 분야에 적용될 수 있는지 여부를 결정하는 중요한 요소이다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;결론적으로-ai의-미래는-가능성으로-가득하지만-더욱-완벽한-해결책이-필요합니다&#34;&gt;결론적으로, AI의 미래는 가능성으로 가득하지만, 더욱 완벽한 해결책이 필요합니다
&lt;/h2&gt;&lt;p&gt;비록 AI 기술이 지난 2년간 상당한 발전을 이루었지만, 아직은 “획기적인 응용 분야는 없는” 단계에 머물러 있습니다. Docker 출시 전의 컨테이너화 기술과 마찬가지로, AI 역시 합리적인 활용 사례를 통해 기존 기술을 비즈니스 요구와 심층적으로 통합해야 진정한 대규모 적용 및 보급이 가능합니다. 기술 혁신은 물론 중요하지만, 프로세스를 간소화하고 효율성을 높이는 솔루션이 기술의 보급과 발전을 더욱 촉진할 수 있습니다.&lt;/p&gt;
&lt;p&gt;미래에 AI는 Docker처럼 획기적인 기술 돌파구보다는 기존 기술을 통합하여 완벽한 활용 사례를 구축함으로써, 우리의 업무와 생활 방식을 바꿀 수 있을 것이다&lt;/p&gt;</description>
        </item>
        <item>
        <title>올라마에 deepseek-R1 로컬 배포</title>
        <link>https://ttf248.life/ko/p/ollama-local-deployment-deepseek-r1/</link>
        <pubDate>Fri, 07 Feb 2025 22:41:02 +0800</pubDate>
        
        <guid>https://ttf248.life/ko/p/ollama-local-deployment-deepseek-r1/</guid>
        <description>&lt;p&gt;Ollama는 사용자가 로컬에서 대규모 언어 모델(LLM)을 실행하고 배포할 수 있도록 하는 오픈 소스 AI 도구입니다. 개발자가 클라우드 서비스에 의존하지 않고도 GPT와 같은 모델을 로컬 머신에서 편리하고 효율적으로 사용할 수 있도록 지원하며, 다양한 모델을 지원하고 성능 최적화에 중점을 두어 리소스가 제한적인 장치에서도 원활하게 실행될 수 있도록 합니다.&lt;/p&gt;
&lt;p&gt;올라마를 통해 사용자는 텍스트 기반 AI 애플리케이션을 활용하고, 데이터 프라이버시나 높은 API 사용 비용 걱정 없이 로컬에 배포된 모델과 상호 작용할 수 있습니다. 다양한 모델을 명령줄 인터페이스(CLI)를 통해 호출하여 자연어 처리, 질의응답 등의 작업을 수행할 수 있습니다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;올라마는 다양한 모델을 시험해 보기에 적합하지만, 윈도우 버전은 하드웨어 성능을 충분히 활용하지 못하는 듯합니다. 리눅스 버전이 더 나을 수도 있습니다. 32B 파라미터 모델을 배포했을 때 메모리나 GPU 사용량이 높지 않음에도 응답 속도가 매우 느립니다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;하드웨어-개요&#34;&gt;하드웨어 개요
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;운영체제: win11&lt;/li&gt;
&lt;li&gt;CPU：i7-10700K&lt;/li&gt;
&lt;li&gt;메모리: 40GB&lt;/li&gt;
&lt;li&gt;그래픽 카드: RTX 3060 12GB&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;환경-준비&#34;&gt;환경 준비
&lt;/h2&gt;&lt;p&gt;새로운 시스템 환경 변수를 추가하여 향후 사용을 용이하게 합니다&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_MODELS=E:\ollama&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
이 변수는 Ollama 모델이 저장될 경로를 지정합니다. __INLINE_CODE_0__은 모든 로컬 모델 파일이 저장되는 폴더 경로입니다. Ollama는 이 경로를 기준으로 다운로드하거나 배포한 언어 모델을 로드하고 사용합니다. 모델 파일을 다른 위치에 저장하려면 이 경로를 변경하면 됩니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_HOST=127.0.0.1:8000&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
이 환경 변수는 Ollama 서비스의 호스트와 포트를 설정합니다&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;__INLINE_CODE_0__은 로컬 주소(localhost)이며, Ollama 서비스가 로컬 요청만 수신하도록 합니다&lt;/li&gt;
&lt;li&gt;__INLINE_CODE_0__은 지정된 포트 번호이며, Ollama 서비스가 8000번 포트에서 요청을 대기하고 처리할 것임을 나타냅니다. 필요에 따라 포트 번호를 변경할 수 있지만, 해당 포트가 다른 애플리케이션에 의해 사용되지 않는지 확인해야 합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_ORIGINS=*&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
이 환경 변수는 Ollama 서비스에 접근할 수 있는 요청의 출처를 제어합니다&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; 모든 소스(모든 도메인 및 IP 주소)에서 Ollama 서비스에 접근할 수 있도록 허용합니다. 이는 일반적으로 개발 및 디버깅 환경에서 사용되며, 프로덕션 환경에서는 보안 강화를 위해 특정 도메인 또는 IP만 접근하도록 제한하는 것이 일반적입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;딥시크-r1-모델-배포&#34;&gt;딥시크-R1 모델 배포
&lt;/h2&gt;&lt;p&gt;설치는 간단하니 생략합니다&lt;/p&gt;
&lt;p&gt;설치 후 검증:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core&amp;gt;ollama -v
ollama version is 0.5.11
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;모델 배포는 공식 모델 페이지에서 해당 매개변수의 모델을 선택하세요: &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;14B 파라미터는 대화 맥락을 효과적으로 기억할 수 있지만, 더 작은 파라미터 버전은 그렇지 못합니다. 32B 파라미터 버전은 로컬 배포 시 버벅거림이 심해 더 이상 테스트하지 않았습니다.&lt;/p&gt;
&lt;h2 id=&#34;참고-자료&#34;&gt;참고 자료
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ollama.com/library/deepseek-r1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.ollama.com/library/deepseek-r1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/x18990027/article/details/145368094&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/x18990027/article/details/145368094&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>딥시크, 설날 직전 갑작스러운 인기와 엔비디아 주가 폭락: 배후의 기관 투자 및 거대 모델 사고 체인</title>
        <link>https://ttf248.life/ko/p/deepseek-chinese-new-year-nvidia-stock-drop-institutional-operations-large-language-model-chain/</link>
        <pubDate>Fri, 07 Feb 2025 20:36:05 +0800</pubDate>
        
        <guid>https://ttf248.life/ko/p/deepseek-chinese-new-year-nvidia-stock-drop-institutional-operations-large-language-model-chain/</guid>
        <description>&lt;p&gt;설 명절 직전, DeepSeek가 한 번의 화제로 주목받으며 며칠 만에 소셜 미디어에서 광범위한 관심을 모았습니다. 이러한 갑작스러운 인기에는 놀라움이 더해진 것은 물론 시장 전체에 연쇄적인 영향을 미쳤습니다. 동시에 엔비디아 주가는 폭락했고, 많은 투자자들이 그 전망에 의문을 제기하며 일부 기관은 대규모 공매도 거래를 진행했습니다. 이 모든 상황은 마치 “계획된” 것처럼 보였습니다.&lt;/p&gt;
&lt;h3 id=&#34;deepseek-的爆火短时间内迅速成为焦点&#34;&gt;&lt;strong&gt;DeepSeek 的爆火：短时间内迅速成为焦点&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;DeepSeek는 AI 기반 도구로, 특히 자연어 처리(NLP) 및 이미지 생성 분야에서 딥러닝 모델 최적화에 집중합니다. 설 명절 직전 이 프로젝트는 갑자기 많은 투자자와 기술 전문가들의 관심을 받기 시작했습니다. 팀의 성과와 시연된 기술적 결과물은 많은 사람들에게 강한 관심을 불러일으켰고, 개발자 커뮤니티나 소셜 미디어 플랫폼에서 DeepSeek에 대한 논의가 기술계 전반의 주요 화두를 차지하고 있습니다.&lt;/p&gt;
&lt;p&gt;그러나 DeepSeek의 갑작스러운 인기 폭발은 우연이 아니다. 분석 결과, 많은 사람들이 이 뒤에 특정 기관의 개입이 있을 가능성을 의심하기 시작했다. 특히 인기가 폭발한 이후 엔비디아 주가가 뚜렷하게 하락했는데, 분명 어떤 요인이 이러한 변화를 촉진하고 있는 것으로 보인다.&lt;/p&gt;
&lt;h3 id=&#34;英伟达股票暴跌做空操作的幕后推手&#34;&gt;&lt;strong&gt;英伟达股票暴跌：做空操作的幕后推手&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;엔비디아는 그래픽 처리 장치(GPU) 제조업체로서, 대규모 모델 및 AI 컴퓨팅의 핵심 하드웨어 공급업체였으며, AI 시장의 급성장과 함께 주가가 꾸준히 상승하여 많은 투자자들의 선호 대상이 되었습니다. 하지만 DeepSeek의 인기에 힘입어 시장의 기술적 관심이 높아지면서 엔비디아 주가는 급락했습니다.&lt;/p&gt;
&lt;p&gt;이러한 현상 이면에는 기관 투자자의 공매도 전략이 관련되었을 수도 있습니다. 지난 몇 년간 AI 기술의 보급과 함께 엔비디아 주가는 크게 상승했고, 많은 투자자들은 그 주가가 과도하게 부풀려졌다고 판단했습니다. 특히 DeepSeek와 같은 기술이 폭발적으로 인기를 얻은 이후, 일부 기관들은 엔비디아 주식을 공매도하여 상당한 이익을 얻었을 가능성이 있습니다. 정확한 시장 상황 파악과 DeepSeek의 영향력에 대한 예측을 통해 이러한 기관들은 성공적으로 이익을 창출했습니다.&lt;/p&gt;
&lt;h3 id=&#34;大模型思维链的接触从结果到过程&#34;&gt;&lt;strong&gt;大模型思维链的接触：从“结果”到“过程”&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;전통적인 인공지능 응용 분야에서 많은 실무자와 투자자들은 생성된 이미지나 텍스트와 같은 AI 모델의 “결과”에 더 집중해 왔습니다. 하지만 DeepSeek 관련 논의에서는 점점 더 많은 사람들이 대규모 모델 뒤에 숨겨진 사고 과정이 더욱 주목할 가치가 있는 핵심 내용이라는 것을 깨닫기 시작했습니다. 과거에는 모델 출력 결과만 볼 수 있었지만, 이제는 그 이면에 숨겨진 논리, 알고리즘을 이해하고 이러한 요소를 조정하여 모델 성능을 최적화하는 것이 더 중요합니다.&lt;/p&gt;
&lt;p&gt;이러한 사고방식의 전환은 AI 연구와 활용에 대한 깊이 있는 고찰이며, 단순한 블랙박스 조작에서 모델 내부 작동 메커니즘을 진정으로 이해하는 변화로 이어지면서 많은 기술 전문가와 투자자들이 인공지능의 미래 발전 방향을 재검토하기 시작했습니다. DeepSeek의 인기 폭발은 바로 이러한 사고방식의 획기적인 응용이며, 사람들은 최종 결과물뿐만 아니라 전체 모델 구축 및 최적화 과정에 주목하기 시작했습니다.&lt;/p&gt;
&lt;h3 id=&#34;总结&#34;&gt;&lt;strong&gt;总结&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;딥시크의 갑작스러운 인기, 엔비디아 주가의 폭락, 그리고 시장 뒤편의 기관의 공매도 작전, 이 모든 현상 뒤에는 치밀하게 설계된 음모가 있는 듯합니다. 거대 언어 모델 사고 체인에 대한 깊이 있는 이해를 통해 AI 기술의 적용은 단순한 표면 현상의 조합이 아니라 모델 내부 로직에 대한 심층적인 탐구와 최적화임을 알 수 있습니다. 기술 발전과 함께 앞으로 딥시크와 같은 혁신적인 도구가 더 많이 등장하여 AI 연구 및 응용을 더욱 높은 수준으로 이끌어갈 것으로 예상됩니다.&lt;/p&gt;
&lt;p&gt;이러한 현상은 AI 기술의 엄청난 잠재력을 보여줄 뿐만 아니라, 기술 뒤에 숨겨진 사업 경쟁과 자본 운용에 대해 생각하게 합니다. 앞으로 시장 추세는 기술과 자본 간의 경쟁이 지속적으로 초점이 될 것입니다.&lt;/p&gt;</description>
        </item>
        <item>
        <title>커서 AI 프로그래밍 IDE 체험</title>
        <link>https://ttf248.life/ko/p/cursor-ai-programming-ide-trial/</link>
        <pubDate>Thu, 23 Jan 2025 19:30:13 +0800</pubDate>
        
        <guid>https://ttf248.life/ko/p/cursor-ai-programming-ide-trial/</guid>
        <description>&lt;p&gt;번뜩하니 또 일 년이 지났습니다. 업무적으로 가장 큰 변화는 AI의 참여도가 눈에 띄게 높아진 것인데, 이전에는 개발 언어 간 전환 시 각 언어별 다양한 API 인터페이스를 익혀야 했지만, 이제 이러한 기본 코드는 AI가 생성해 주니 개발자에게는 정말 큰 축복입니다.&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;23년 초에 간단한 입문 소개 두 편을 다루었었는데, 눈 깜짝할 사이에 25년이 벌써 왔네요. 어떻게 말해야 할지 모르겠지만, 뚜렷한 발전은 없는 것 같아요. 여전히 자신만의 인식을 갖고 합리적으로 작업을 분할할 수 있어야 하고, 무엇보다 중요한 것은 AI가 생성한 코드에 버그가 있는지 식별하는 것입니다.&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;Github copilot
&lt;/h2&gt;&lt;p&gt;날짜가 언제인지 잊어버렸는데, 자료를 보니 싱가포르에 서버를 구축했고 국내에서 사용할 수 있게 되었다. 더 이상 장기간으로 VPN을 사용할 필요는 없지만, 로그인할 때는 여전히 VPN이 필요하다. 하지만 이 VPN은 로그인할 때만 사용하면 되고 그 후에는 종료할 수 있다.&lt;/p&gt;
&lt;p&gt;일상적으로 더 많이 사용하는 것은 Github Copilot 플러그인인데, 이 플러그인은 VS Code, Visual Studio에서 바로 사용할 수 있습니다. 두 프로그램 사이를 전환할 필요가 없습니다. ChatGPT에 비해 Github Copilot이 프로젝트 지원이 더 좋고, 상호작용도 더 친절하며, 일부 로컬 파일을 선택하여 &lt;strong&gt;“训练”AI&lt;/strong&gt; 투입하면 해당 프로젝트에 더 적합한 코드를 생성합니다.&lt;/p&gt;
&lt;h2 id=&#34;cursor-ai&#34;&gt;Cursor AI
&lt;/h2&gt;&lt;p&gt;최근에 새로운 AI 프로그래밍 IDE인 Cursor AI를 보았는데, 이 IDE는 Github Copilot 기반이지만 더 똑똑하고 파일을 직접 생성해 준다&lt;/p&gt;
&lt;p&gt;간단히 사용해 봤는데 괜찮은 것 같긴 하지만, 현재 프로젝트에 대한 이해는 아직 부족하고, 로컬 프로젝트 파일이 많을 때는 큰 규모의 리팩토링 및 최적화 조정에는 여전히 &lt;strong&gt;开发者拆分任务&lt;/strong&gt;가 필요하다&lt;/p&gt;
&lt;p&gt;curso 프로젝트의 엔지니어 모드로 전환하여 &amp;ldquo;새로운 개인 이력서 웹페이지 생성&amp;quot;이라는 내용을 입력하고, 다양한 스타일 전환을 지원하며, 데이터 표시를 위해 개인 정보를 채워 넣으세요&lt;/p&gt;
&lt;p&gt;몇 번이고 반복하다 보면 다음과 같은 웹페이지를 얻을 수 있습니다. 물론 이 페이지는 비교적 간단하지만, 초보자에게는 꽤 괜찮은 시작입니다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;현재 등록 사용자는 고급 API를 150회 무료로 체험할 수 있으며, 유료 사용자는 고급 API 사용이 5000회로 제한됩니다&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;죄송합니다, 번역할 중국어 텍스트가 제공되지 않았습니다. 텍스트를 제공해 주시면 번역해 드리겠습니다.&lt;/p&gt;</description>
        </item>
        <item>
        <title>AI 프로그래밍 및 작업 분할</title>
        <link>https://ttf248.life/ko/p/ai-programming-and-task-decomposition/</link>
        <pubDate>Fri, 22 Dec 2023 08:44:26 +0800</pubDate>
        
        <guid>https://ttf248.life/ko/p/ai-programming-and-task-decomposition/</guid>
        <description>&lt;p&gt;2년 전 사이트에 코드 영역 복사 기능을 추가하려고 했는데, 반쯤 날로 붙들여 놓은 듯했고, 렌더링 효과도 만족스럽지 않았습니다. 반쪽짜리 프론트엔드 개발자였으니 개선할 생각도 없이 그냥 쓰고 있었는데, 올해 __INLINE_CODE_0__으로 미니 프로그램을 개발하면서 프론트엔드 개발에 더 익숙해졌고, AI를 활용하여 다시 디자인했습니다.&lt;/p&gt;
&lt;p&gt;깨달음: 임무 분해, 여러 소임들, &lt;em&gt;이탤릭 강조&lt;/em&gt; 굵게 표시_ 또 다른 소임들_&lt;/p&gt;
&lt;h2 id=&#34;전문&#34;&gt;전문
&lt;/h2&gt;&lt;p&gt;죄송합니다, 번역할 중국어 텍스트가 제공되지 않았습니다. 텍스트를 제공해 주시면 번역해 드리겠습니다.&lt;/p&gt;
&lt;h2 id=&#34;본문&#34;&gt;본문
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;promot&lt;/strong&gt;: CSS 및 JavaScript 코드를 설계하여, 클래스가 &amp;ldquo;highlight&amp;quot;인 웹 요소의 컨테이너 내에 복사 버튼을 추가하고 코드 복사 기능을 구현합니다&lt;/p&gt;
&lt;p&gt;제공된 첫 번째 초안 코드에는 문제가 있어 보입니다. 다시 생성한 두 번째 초안은 기본적으로 사용 가능하지만, 복사된 내용이 정확하지 않고 불필요한 텍스트가 있습니다. 핵심 색상 디자인과 포함될 효과를 지정하여 추가 최적화를 유도합니다.&lt;/p&gt;
&lt;p&gt;버튼 크기 및 색상에 대한 특정 요구 사항을 파악했습니다. 이러한 요구 사항에 맞게 버튼 스타일을 재설계할 수 있으며, 제공해주신 색상 구성표를 포함하고 버튼 크기를 최적화한 CSS 스타일이 아래와 같습니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.copy-btn {
  position: absolute;
  top: 2px; /* 调整位置 */
  right: 2px;
  padding: 3px 6px; /* 缩小尺寸 */
  font-size: 12px; /* 减小字体大小 */
  background-color: #8FD1E1; /* 按钮背景色 */
  color: #272822; /* 文字颜色 */
  border: 1px solid #272822; /* 边框颜色 */
  border-radius: 3px; /* 圆角 */
  cursor: pointer;
  opacity: 0.7; /* 默认半透明 */
  transition: opacity 0.3s ease, background-color 0.3s ease; /* 平滑过渡效果 */
}

.copy-btn:hover {
  opacity: 1; /* 鼠标悬停时不透明 */
  background-color: #A3D4E5; /* 鼠标悬停时的背景色 */
}

.highlight {
  position: relative;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이 스타일에서 버튼 크기와 글꼴 크기를 줄여 더욱 세련되게 만들었습니다. 또한, 버튼의 기본 상태는 반투명하며, 마우스가 올라오면 불투명해지고 배경색이 약간 밝아져 시각적인 피드백을 제공합니다. 이러한 디자인은 귀하의 색상 요구 사항을 충족하면서도 현대적이고 사용자 친화적인 특징을 유지합니다.&lt;/p&gt;
&lt;p&gt;해당하는 더 간단한 ____이 제공되었습니다&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-JavaScript&#34;&gt;document.addEventListener(&#39;DOMContentLoaded&#39;, function() {
  // 查找所有 .highlight 元素
  const highlights = document.querySelectorAll(&#39;.highlight&#39;);

  highlights.forEach(function(highlight) {
    // 创建复制按钮
    const copyBtn = document.createElement(&#39;button&#39;);
    copyBtn.textContent = &#39;复制&#39;;
    copyBtn.classList.add(&#39;copy-btn&#39;);

    // 将按钮添加到每个 .highlight 元素中
    highlight.appendChild(copyBtn);

    // 添加点击事件监听器
    copyBtn.addEventListener(&#39;click&#39;, function() {
      // 假设 .highlight 下的第一个 &amp;lt;code&amp;gt; 元素包含要复制的代码
      const code = highlight.querySelector(&#39;code&#39;) ? highlight.querySelector(&#39;code&#39;).textContent : &#39;&#39;;

      navigator.clipboard.writeText(code).then(() =&amp;gt; {
        // 显示复制成功信息
        copyBtn.textContent = &#39;已复制!&#39;;
        setTimeout(() =&amp;gt; {
          copyBtn.textContent = &#39;复制&#39;;
        }, 2000);
      }).catch(err =&amp;gt; {
        console.error(&#39;复制失败: &#39;, err);
      });
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;사후기&#34;&gt;사후기
&lt;/h2&gt;&lt;p&gt;비록 코드 영역 오른쪽 상단에 복사 버튼을 추가하기를 더 바라지만, 프론트엔드에 대한 이해 부족으로 정확한 기능 설명을 위한 키워드를 제시하지 못했고, __INLINE_CODE_0__과 여러 차례 시도했음에도 기대했던 결과를 얻지 못했습니다&lt;/p&gt;
&lt;p&gt;시간이 지남에 따라 &lt;code&gt;AI&lt;/code&gt;이 프로그램 개발에 얼마나 영향을 미칠지 모르겠다&lt;/p&gt;</description>
        </item>
        <item>
        <title>프롬프트 엔지니어</title>
        <link>https://ttf248.life/ko/p/prompt-engineer/</link>
        <pubDate>Sun, 26 Mar 2023 20:46:53 +0800</pubDate>
        
        <guid>https://ttf248.life/ko/p/prompt-engineer/</guid>
        <description>&lt;p&gt;마치 과거 검색 엔진 사용법을 배운 것처럼, 우리는 __INLINE_CODE_0__과 소통하는 방법, 합리적이고 충분한 조건을 제시하여 필요한 답변을 효율적으로 얻는 방법을 배워야 합니다&lt;/p&gt;
&lt;p&gt;만약 다른 각도에서 접근해 본다면, 현재의 __INLINE_CODE_0__属于一个记忆力很好的小孩子，它拥有过目不忘的能力，有抄作业的能力。我们需要做的是学会如何正确、有效的和__INLINE_CODE_1__沟通，精准的描述需求，帮助__INLINE_CODE_2__이 예상하는 결과를 낼 수 있을 것이다&lt;/p&gt;
&lt;h2 id=&#34;과학-대중화&#34;&gt;과학 대중화
&lt;/h2&gt;&lt;p&gt;발사되는 듯 하늘을 찌르는 &lt;code&gt;AI&lt;/code&gt;确切的说__INLINE_CODE_1__은 직역하면 생성적 사전 훈련이다. 이는 인터넷에서 구할 수 있는 데이터로 학습된 텍스트 생성 심층 학습 모델이며, 질의응답, 텍스트 요약 생성, 기계 번역, 분류, 코드 생성 및 대화형 AI와 같은 작업에 사용된다. 현재 GPT-1, GPT-2, GPT-3 및 GPT-4 등 다양한 버전의 모델이 있으며, 각 버전은 이전 버전에 비해 더 크고 강력하다.&lt;/p&gt;
&lt;h2 id=&#34;정말-인공지능이-있을까&#34;&gt;정말 인공지능이 있을까?
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;유사도가 높을수록 정확도 또한 높아진다&lt;/li&gt;
&lt;li&gt;기본적이고 반복적인 업무는 특정 훈련을 거치면 더 이상 인공의 개입이 필요하지 않다&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;생성형 AI는 기존의 텍스트, 오디오, 이미지 등 데이터를 활용하여 새로운 콘텐츠를 생성하는 기술입니다. 텍스트 생성, 음성 합성, 이미지 생성, 대화 시스템 등 다양한 작업에 사용될 수 있습니다. 생성형 AI의 논리성은 학습 데이터와 모델 구조에 따라 달라지며, 일반적으로 문법, 논리 및 상식을 어느 정도 따르지만 오류, 편향 또는 부정확한 내용을 포함할 수도 있습니다. 따라서 생성형 AI의 출력은 인간의 판단과 검증이 필요하며 맹목적으로 믿거나 사용할 수 없습니다.&lt;/p&gt;
&lt;h2 id=&#34;프롬프트-엔지니어&#34;&gt;프롬프트 엔지니어
&lt;/h2&gt;&lt;p&gt;시간의 흐름은 거슬러갈 수 없고, 사람은 변화에 적응해야 합니다. 당신이 __INLINE_CODE_0__을 비효율적이고 논리성이 없다고 생각할 수도 있습니다. 그것은 종종 쓸모없는 코드를 생성합니다.&lt;/p&gt;
&lt;p&gt;만약 다른 각도에서 접근해 본다면, 현재의 &lt;code&gt;AI&lt;/code&gt;属于一个记忆力很好的小孩子，它拥有过目不忘的能力，有抄作业的能力。我们需要做的是学会如何正确、有效的和&lt;code&gt;AI&lt;/code&gt;沟通，精准的描述需求，帮助&lt;code&gt;AI&lt;/code&gt;이 예상하는 결과를 낼 수 있을 것이다&lt;/p&gt;
&lt;h2 id=&#34;대화-모드&#34;&gt;대화 모드
&lt;/h2&gt;&lt;p&gt;두 해 전 __发布，谁也想不到两年后，__INLINE_CODE_0__이 __INLINE_CODE_1__과 함께 등장하여 인간에게 거대 언어 모델의 능력을 각인시켰다&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;基于注释的编程&lt;/strong&gt;와 &lt;strong&gt;基于对话的编程&lt;/strong&gt;를 기반으로, 상호 작용 방식이 완전히 다르며, 대화 모드는 초보 사용자에게 친숙한 경험을 제공합니다. 여기서는 반드시 &lt;code&gt;NewBing&lt;/code&gt;BOLD_4&lt;code&gt;AI&lt;/code&gt; 지식 데이터베이스 내 더 많은 내용을 언급해야 합니다.&lt;/p&gt;
&lt;h2 id=&#34;예시로-말하자면&#34;&gt;예시로 말하자면
&lt;/h2&gt;&lt;p&gt;고속철도 여행 시간은 길지만, 코딩이 좋은 선택이다. 데이터 사용량이 제한적인 상황에서 몇 장의 사진을 처리하고 이미지 자료를 얻었더니, 사진 편집 프로그램을 다운로드하여 처리하는 것은 다소 사치스럽고 네트워크 환경도 허락하지 않는다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;需求&lt;/strong&gt;: 이미지 자료 모음이 있는데, 투명 배경으로 되어 있고, 앱의 내비게이션 바에 사용하기 위한 것입니다. 선택된 상태는 컬러이고, 선택되지 않은 상태는 흑백입니다. 자료들은 모두 컬러로 되어 있으므로, 사전 처리 과정이 필요합니다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Prompt&lt;/strong&gt;: 폴더 내 모든 이미지를 읽어와서 흑백으로 변환하고, 투명 배경을 유지하며, 이미지 품질을 최적화하여 파일 크기를 줄인 후 저장하는 Python 코드를 작성하세요. 콘솔에 최적 전후 파일 크기 비교를 표시합니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 导入必要的库
import os
import PIL
from PIL import Image

# 定义一个函数，将图片转换成黑白，维持透明背景，保存图片，并返回文件体积
def convert_and_save(image_file):
    # 打开图片
    image = Image.open(image_file)
    # 获取图片的模式，如果是 RGBA 模式，说明有透明背景
    mode = image.mode
    if mode == &amp;quot;RGBA&amp;quot;:
        # 创建一个和图片大小一致的白色背景图片
        background = Image.new(&amp;quot;RGB&amp;quot;, image.size, (255, 255, 255))
        # 将原图片粘贴到白色背景上，忽略透明像素
        background.paste(image, mask=image.split()[3])
        # 将合成的图片转换成灰度模式
        gray_image = background.convert(&amp;quot;L&amp;quot;)
        # 将灰度图片再转换成 RGBA 模式，以便保留透明背景
        final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
    else:
        # 如果不是 RGBA 模式，直接将图片转换成灰度模式
        final_image = image.convert(&amp;quot;L&amp;quot;)
    # 获取原图片的文件名和扩展名
    file_name, file_ext = os.path.splitext(image_file)
    # 定义新图片的文件名，添加 _bw 后缀表示黑白
    new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # 保存新图片，并优化质量，减少文件体积
    final_image.save(new_file_name, optimize=True)
    # 获取原图片和新图片的文件体积，并返回
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return old_size, new_size

# 定义一个文件夹路径，存放所有的图片
folder_path = &amp;quot;images&amp;quot;
# 遍历文件夹中的所有文件
for file in os.listdir(folder_path):
    # 拼接完整的文件路径
    file_path = os.path.join(folder_path, file)
    # 判断是否是图片文件，根据扩展名判断，可以根据需要添加或修改扩展名
    if file_path.endswith((&amp;quot;.png&amp;quot;, &amp;quot;.jpg&amp;quot;, &amp;quot;.jpeg&amp;quot;, &amp;quot;.gif&amp;quot;)):
        # 调用函数，转换并保存图片，并获取文件体积
        old_size, new_size = convert_and_save(file_path)
        # 在控制台展示优化前后的文件体积大小对比
        print(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;빠르게 답을 내놓았지만, 보기에는 괜찮고 사용에도 문제는 없으나, 경험이 많은 프로그래머라면 아래 코드가 충분히 일반적이지 않으며 프로덕션 환경에 적용하기 어렵다고 느낄 것이다&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;매개변수 고정됨&lt;/li&gt;
&lt;li&gt;로그 파일이 없고, 정보는 모두 콘솔에 출력됩니다&lt;/li&gt;
&lt;li&gt;이미지 처리는 멀티스레드 모델에 적합합니다&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;이 코드 개선할 부분 있을까요?&lt;/p&gt;
&lt;p&gt;제공된 답변은 솔직히 기대 이상이었고, 일반 프로그래머가 생각할 수 있는 최적화 방안에 대한 구체적인 제안들이 모두 포함되어 있습니다&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;这段代码可能还有一些可以改进的地方，比如：

可以使用 argparse 库，让用户可以通过命令行参数指定文件夹路径和扩展名，而不是写死在代码里。
可以使用 logging 库，记录程序的运行情况，而不是直接打印到控制台。
可以使用 try-except 语句，捕获可能出现的异常，比如文件打开失败，图片转换失败等，并做相应的处理。
可以使用 multiprocessing 库，利用多核处理器，加速图片的转换和保存过程。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;매우 친절한 응답입니다. 배포 환경의 차이를 고려하여 다중 프로세스를 지원하지 않아도 괜찮습니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;当然，我很乐意帮你修改一下代码。我尝试添加了 argparse, logging 和 try-except 语句，但没有添加 multiprocessing 库，因为我不确定你的电脑是否支持多核处理。修改后的代码如下：
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 导入必要的库
import argparse
import logging
import multiprocessing
import os

from PIL import Image


# 定义一个函数，将图片转换成黑白，维持透明背景，保存图片，并返回文件体积
def convert_and_save(image_file):
    # 打开图片
    try:
        image = Image.open(image_file)
    except Exception as e:
        logging.error(f&amp;quot;Failed to open {image_file}: {e}&amp;quot;)
        return None, None
    # 获取图片的模式，如果是 RGBA 模式，说明有透明背景
    mode = image.mode
    if mode == &amp;quot;RGBA&amp;quot;:
        # 创建一个和图片大小一致的白色背景图片
        background = Image.new(&amp;quot;RGB&amp;quot;, image.size, (255, 255, 255))
        # 将原图片粘贴到白色背景上，忽略透明像素
        background.paste(image, mask=image.split()[3])
        # 将合成的图片转换成灰度模式
        gray_image = background.convert(&amp;quot;L&amp;quot;)
        # 将灰度图片再转换成 RGBA 模式，以便保留透明背景
        final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
    else:
        # 如果不是 RGBA 模式，直接将图片转换成灰度模式
        final_image = image.convert(&amp;quot;L&amp;quot;)
    # 获取原图片的文件名和扩展名
    file_name, file_ext = os.path.splitext(image_file)
    # 定义新图片的文件名，添加 _bw 后缀表示黑白
    new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # 保存新图片，并优化质量，减少文件体积
    try:
        final_image.save(new_file_name, optimize=True)
    except Exception as e:
        logging.error(f&amp;quot;Failed to save {new_file_name}: {e}&amp;quot;)
        return None, None
    # 获取原图片和新图片的文件体积，并返回
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return file_name, old_size, new_size

# 定义一个函数，解析命令行参数，并返回文件夹路径和扩展名列表
def parse_args():
    # 创建一个解析器对象
    parser = argparse.ArgumentParser(description=&amp;quot;Convert images to black and white and optimize quality.&amp;quot;)
    # 添加一个必选的位置参数，表示文件夹路径
    parser.add_argument(&amp;quot;folder_path&amp;quot;, help=&amp;quot;The path of the folder that contains the images.&amp;quot;)
    # 添加一个可选的参数，表示扩展名列表，默认为 png, jpg, jpeg 和 gif
    parser.add_argument(&amp;quot;-e&amp;quot;, &amp;quot;--extensions&amp;quot;, nargs=&amp;quot;+&amp;quot;, default=[&amp;quot;.png&amp;quot;, &amp;quot;.jpg&amp;quot;, &amp;quot;.jpeg&amp;quot;, &amp;quot;.gif&amp;quot;], help=&amp;quot;The extensions of the image files.&amp;quot;)
    # 解析命令行参数，并返回结果对象
    args = parser.parse_args()
    return args.folder_path, args.extensions

# 定义一个函数，打印优化前后的文件体积大小对比
def print_result(result):
    # 如果结果不为空，说明转换和保存成功
    if result:
        # 解包结果为文件名和文件体积元组
        if len(result) == 3:
            file, old_size, new_size = result
            # 在控制台展示优化前后的文件体积大小对比
            logging.info(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)
        else:
            logging.info(f&amp;quot;{result}&amp;quot;)

# 配置日志记录器，将日志输出到控制台和文件中，设置日志等级为 INFO
logging.basicConfig(level=logging.INFO,
                    format=&amp;quot;%(asctime)s %(levelname)s %(message)s&amp;quot;,
                    handlers=[logging.StreamHandler(),
                              logging.FileHandler(&amp;quot;log.txt&amp;quot;)])

# 调用函数，获取文件夹路径和扩展名列表
folder_path, extensions = parse_args()

if __name__ == &amp;quot;__main__&amp;quot;:
    # Windows 需要这个函数的原因是 Windows 缺乏 fork() 函数（这不完全正确）。
    # 因此，在 Windows 上，fork() 是通过创建一个新的进程来模拟的，这个新的进程中运行的代码，在 Linux 上是在子进程中运行的。
    # 由于这些代码要在技术上无关的进程中运行，所以它必须在运行之前被传递到那里。
    # 传递的方式是先将它们序列化，然后通过管道从原始进程发送到新的进程。
    # 另外，这个新的进程被通知它必须运行通过管道传递的代码，通过向它传递 --multiprocessing-fork 命令行参数。
    # 如果你看一下 freeze_support() 函数的实现，它的任务是检查它运行在哪个进程中，是否应该运行通过管道传递的代码
    multiprocessing.freeze_support()

    # 创建一个进程池，根据电脑的核心数自动分配进程
    pool = multiprocessing.Pool()
    # 创建一个空列表，用于存放异步任务的结果对象
    results = []
    # 遍历文件夹中的所有文件
    for file in os.listdir(folder_path):
        # 拼接完整的文件路径
        file_path = os.path.join(folder_path, file)
        # 判断是否是图片文件，根据扩展名判断，可以根据需要修改扩展名列表
        if any(file_path.endswith(ext) for ext in extensions):
            # 调用函数，转换并保存图片，并获取文件体积，使用异步方式，不阻塞主进程
            result = pool.apply_async(convert_and_save, args=(file_path,), callback=print_result)
            # 将结果对象添加到列表中
            results.append((file, result))
    # 关闭进程池，不再接受新的任务
    pool.close()
    # 等待所有的任务完成
    pool.join()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;사후기&#34;&gt;사후기
&lt;/h2&gt;&lt;p&gt;로컬 개발 중 __系统，__INLINE_CODE_0__第一次给出的答案，并没有加上__INLINE_CODE_1__函数，也没有__INLINE_CODE_2__BOLD_5&lt;code&gt;multiprocessing.freeze_support&lt;/code&gt; 오류가 발생하여, 질문을 통해 오류를 추적하고 코드를 수정했습니다&lt;/p&gt;
&lt;p&gt;마치 과거 검색 엔진 사용법을 배운 것처럼, 우리는 __INLINE_CODE_0__과 소통하는 방법, 합리적이고 충분한 조건을 제시하여 필요한 답변을 효율적으로 얻는 방법을 배워야 합니다&lt;/p&gt;
&lt;p&gt;주의:&lt;/p&gt;</description>
        </item>
        <item>
        <title>AI 지원 프로그래밍, 생산성 진화</title>
        <link>https://ttf248.life/ko/p/ai-assisted-programming-productivity-evolution/</link>
        <pubDate>Tue, 28 Feb 2023 17:05:17 +0800</pubDate>
        
        <guid>https://ttf248.life/ko/p/ai-assisted-programming-productivity-evolution/</guid>
        <description>&lt;p&gt;&lt;code&gt;GitHub Copilot&lt;/code&gt;BOLD_2&lt;code&gt;ChatGPT&lt;/code&gt;이 세상에 나왔는데, 작동 원리는 잘 모르지만 한동안 사용했다. 두 도구는 생산성 향상에 있어 완전히 다른 수준의 도움을 주지만, 모두 큰 효과를 발휘한다.&lt;/p&gt;
&lt;p&gt;너무 복잡한 일은, ⁠_강조_⁠의 효과는 아홉할 정도일 뿐이다&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;github copilot
&lt;/h2&gt;&lt;p&gt;발표할 때, 홈페이지 소개__INLINE_CODE_0__를 보니 그렇게 똑똑해 보이지 않았고, 사용해 봤는데 잘 안 돼서 포기했다&lt;/p&gt;
&lt;p&gt;2022년 이전에는, 시간 날 때마다 새로운 버전으로 바꿔서 사용해 보는데, 효과는 꽤 괜찮은 편이다. 다만 국내 속도가 좀 느린데, 아마 네트워크 문제인 것 같다. &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; 같은 언어로 작성된 코드는 주석을 참고해서 따라 하면 나보다 자료를 찾아 직접 짜는 것보다 훨씬 빠르다.&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;여전히 프로그래머, 즉 개발 관점에서 제품을 설계하고 있으며, 프로그래밍 방법을 이해해야 하고, 주석을 통해 AI 지원 프로그래밍을 점진적으로 유도해야 합니다&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; 走到了下一个层面，**외지인도 빠르게 시작할 수 있습니다. 대화형 챗 인터페이스로 설계되어, 질문하고 요구사항을 설명하며, 이해가 안 되는 부분은 계속 질문할 수 있습니다.&lt;/p&gt;
&lt;p&gt;간단한 예시로, 토큰화 개념은 알지만 코딩 방법은 모르고 문자열 유사도를 계산하고 싶습니다&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Python 分词计算 維天運通 LOGORY 和 合肥維天運通信息科技股份有限公司 两个字符串的相似度；
比较前，统一处理字符串，英文转换为小写；
第二个字符中如果能找到第一个字符的首字符，将第二个字符串截位，截位的长度为第一个字符串的长度
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;안녕하세요, 빙입니다. 😊&lt;/p&gt;
&lt;p&gt;온라인 정보에 따르면 123, Python 분단 계산은 jieba 라이브러리를 사용하여 구현할 수 있습니다. jieba 라이브러리는 정확 모드, 전체 모드 및 검색 엔진 모드의 세 가지 분단 모드를 지원합니다. 필요에 따라 적절한 모드를 선택할 수 있습니다.&lt;/p&gt;
&lt;p&gt;두 문자열의 유사도를 비교하려면 먼저 토큰화한 다음 단어 벡터 또는 편집 거리 등의 지표를 계산해야 합니다. 수학 연산에는 numpy나 scipy 같은 라이브러리를 사용할 수 있습니다.&lt;/p&gt;
&lt;p&gt;문자열을 일관되게 처리하기 위해 영문자를 소문자로 변환하려면 Python의 내장 함수 lower()를 사용할 수 있습니다&lt;/p&gt;
&lt;p&gt;두 번째 문자열을 추출하려면 Python의 슬라이스 연산자 []를 사용할 수 있습니다&lt;/p&gt;
&lt;p&gt;다음은 가능한 코드 예제입니다:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import jieba
import numpy as np
from scipy.spatial.distance import cosine

# 定义两个字符串
str1 = &amp;quot;維天運通 LOGORY&amp;quot;
str2 = &amp;quot;合肥維天運通信息科技股份有限公司&amp;quot;

# 统一处理字符串，英文转换为小写
str1 = str1.lower()
str2 = str2.lower()

# 找到第二个字符串中第一个字符的位置
index = str2.find(str1[0])

# 如果找到了，截取第二个字符串
if index != -1:
    str2 = str2[index:index+len(str1)]

# 使用 jieba 库进行分词
words1 = list(jieba.cut(str1))
words2 = list(jieba.cut(str2))

# 计算两个字符串的词向量（以词频作为权重）
vector1 = np.zeros(len(words1))
vector2 = np.zeros(len(words1))

for i, word in enumerate(words1):
    vector1[i] += 1 # 统计第一个字符串中每个词出现的次数
    if word in words2:
        vector2[i] += 1 # 统计第二个字符串中每个词出现的次数

# 计算两个字符串的相似度（以余弦距离作为指标）
similarity = 1 - cosine(vector1, vector2)

print(&amp;quot;两个字符串的相似度是：&amp;quot;, similarity)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;更进一步，咨询运行的结果，恭喜你，发现问题了，结果是瞎编的，它并没有实际运行代码，但是会给你一个不错的结果&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;밤&#34;&gt;밤
&lt;/h3&gt;&lt;p&gt;SQL 쿼리, 제품 코드 테이블에서 제품 코드 범위가 80000부터 89999까지인 레코드 검색&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;你好，这是 Bing。😊

根据搜索结果12，你可以使用 SQL BETWEEN 运算符来选择给定区间内的值。BETWEEN 运算符包含了开始和结束的值。

你需要先指定要查询的表名和列名，然后在 WHERE 子句中使用 BETWEEN 运算符和区间值。

例如，如果你要查询产品代码表中，产品代码在 80000 到 89999 之间的记录，你可以使用以下语句：

SELECT * FROM product_code
WHERE code BETWEEN 80000 AND 89999;
这里，* 表示选择所有列3。如果你只想选择特定的列，比如产品名称和价格，你可以用逗号分隔它们，如下：

SELECT name, price FROM product_code
WHERE code BETWEEN 80000 AND 89999;
希望这能帮助到你。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;계속 질문하고 반박하세요: 제품 코드는 문자열이고, 당신의 코드가 잘못되었습니다&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;抱歉，我没有注意到产品代码是字符串。如果是这样的话，你需要在区间值两边加上单引号，如下：

SELECT * FROM product_code
WHERE code BETWEEN &#39;80000&#39; AND &#39;89999&#39;;
请原谅我的错误。🙏
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;축하해요, 틀릴 거예요&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

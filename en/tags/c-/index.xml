<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>C&#43;&#43; on Uncle Xiang&#39;s Notebook</title>
        <link>https://ttf248.life/en/tags/c-/</link>
        <description>Recent content in C&#43;&#43; on Uncle Xiang&#39;s Notebook</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Mon, 02 Jun 2025 07:41:32 +0800</lastBuildDate><atom:link href="https://ttf248.life/en/tags/c-/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>C&#43;&#43; Bitwise Operations Fundamentals: Bitwise Extraction and Flag Setting</title>
        <link>https://ttf248.life/en/p/cpp-bitwise-operations-basics-flags/</link>
        <pubDate>Fri, 17 Jan 2025 02:23:56 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-bitwise-operations-basics-flags/</guid>
        <description>&lt;p&gt;In actual C++ development, bitwise operations are a common technique, especially when dealing with system states, flags, or control bits. Bitwise operations can provide highly efficient solutions. This article will illustrate how to use bitwise operations to retrieve and set specific flags through an example.&lt;/p&gt;
&lt;h3 id=&#34;bitwise-operations-fundamentals&#34;&gt;Bitwise Operations Fundamentals
&lt;/h3&gt;&lt;p&gt;In computers, data is stored in binary bits (0 and 1). Bitwise operations are operations performed on these binary bits. C++ provides several commonly used bitwise operators:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Bitwise AND (&amp;amp;)&lt;/strong&gt;: Used to check if a particular bit is set to 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise OR (|)&lt;/strong&gt;: Used to set a particular bit to 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise XOR (^)&lt;/strong&gt;: Used to flip a particular bit.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise NOT (~)&lt;/strong&gt;: Inverts all the bits.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Left Shift (&amp;laquo;)&lt;/strong&gt;: Shifts all the bits to the left by a specified number of positions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Right Shift (&amp;raquo;)&lt;/strong&gt;: Shifts all the bits to the right by a specified number of positions.
In this example, we need to perform a series of bitwise operations on an &lt;code&gt;unsigned short&lt;/code&gt; variable &lt;code&gt;wInfo&lt;/code&gt; to represent different states using various flags.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;requirement-analysis&#34;&gt;Requirement Analysis
&lt;/h3&gt;&lt;p&gt;Based on the description, we have a 16-bit flag to represent different states. These states are represented by various binary bits, with each binary bit corresponding to a specific meaning. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;bit0&lt;/strong&gt;: Failure status&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bit1&lt;/strong&gt;: Compression status&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bit2&lt;/strong&gt;: Incremental status&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bit3&lt;/strong&gt;: Presence of subsequent packets&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bit5&lt;/strong&gt;: Normal request or cancellation&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;using-bitwise-operations&#34;&gt;Using Bitwise Operations
&lt;/h3&gt;&lt;p&gt;We will use bitwise operations to set and retrieve these flags. Specifically:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Bitwise AND:&lt;/strong&gt; Retrieve the value of a particular bit (0 or 1).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise OR:&lt;/strong&gt; Set a particular bit to 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise XOR:&lt;/strong&gt; Set a particular bit to 0.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We first define an &lt;code&gt;unsigned short&lt;/code&gt; type variable &lt;code&gt;wInfo&lt;/code&gt; to store these flags. Then, we use bitwise operations to check and set the corresponding flags.&lt;/p&gt;
&lt;h3 id=&#34;c-example-code&#34;&gt;C++ Example Code
&lt;/h3&gt;&lt;p&gt;Execute the code, recommended for old friends: &lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;code-explanation&#34;&gt;Code Explanation
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Flag Definition&lt;/strong&gt;: Use shift operations (&lt;code&gt;1 &amp;lt;&amp;lt; n&lt;/code&gt;) to define each flag bit. For example, &lt;code&gt;1 &amp;lt;&amp;lt; 0&lt;/code&gt; corresponds to &lt;code&gt;bit0&lt;/code&gt;, &lt;code&gt;1 &amp;lt;&amp;lt; 1&lt;/code&gt; corresponds to &lt;code&gt;bit1&lt;/code&gt;, and so on. This way, we allocate a unique binary position for each flag.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Check a Bit&lt;/strong&gt;: The &lt;code&gt;isBitSet&lt;/code&gt; function uses the bitwise AND operation (&lt;code&gt;wInfo &amp;amp; bitMask&lt;/code&gt;) to check if a specific flag is set to 1. If the bit is 1, the function returns &lt;code&gt;true&lt;/code&gt;, otherwise it returns &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Set a Bit&lt;/strong&gt;: The &lt;code&gt;setBit&lt;/code&gt; function uses the bitwise OR operation (&lt;code&gt;wInfo |= bitMask&lt;/code&gt;) to set a specific flag bit to 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clear a Bit&lt;/strong&gt;: The &lt;code&gt;clearBit&lt;/code&gt; function uses the bitwise AND operation (&lt;code&gt;wInfo &amp;amp;= ~bitMask&lt;/code&gt;) to clear a specific flag bit to 0.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary
&lt;/h3&gt;&lt;p&gt;Through bitwise operations, we can efficiently handle multiple state flags. This technique is particularly useful in practical development. For example, in embedded development, network protocols, and system status management scenarios, bit flags are often used to represent multiple binary states, saving space and improving efficiency.&lt;/p&gt;
&lt;p&gt;We hope this blog post helps you understand how to use bitwise operations in C++ to perform bitwise selection and setting, and mastering these skills is very helpful for writing efficient and maintainable code!&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Deeply understand GCC, GLIBC, and C&#43;&#43; program compatibility issues</title>
        <link>https://ttf248.life/en/p/deep-understanding-gcc-glibc-cpp-compatibility-issues/</link>
        <pubDate>Mon, 06 Jan 2025 19:51:16 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/deep-understanding-gcc-glibc-cpp-compatibility-issues/</guid>
        <description>&lt;p&gt;In the C++ development field, GCC and GLIBC are two indispensable key elements, and compatibility issues after program release often trouble developers. This article will delve into their essence, explore the root causes of compatibility problems, and investigate coping strategies.&lt;/p&gt;
&lt;h2 id=&#34;i-gcc-a-powerful-compiler-cornerstone&#34;&gt;I. GCC: A Powerful Compiler Cornerstone
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Definition and Function&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;GCC, or GNU Compiler Collection, is a suite of open-source compilers developed by the GNU project. It’s far from a typical compiler; it supports a wide range of programming languages including C, C++, Objective - C, Fortran, Ada, and Go, providing a one-stop solution for cross-language development.&lt;/li&gt;
&lt;li&gt;Taking C++ as an example, when we write a source file containing complex features like classes, templates, and function overloading, GCC can translate the advanced C++ code into low-level machine instructions that can be understood and executed by the system. This process involves multiple fine-grained stages such as lexical analysis, syntax analysis, semantic analysis, optimization, and code generation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;i-gcc-a-powerful-compiler-foundation&#34;&gt;I. GCC: A Powerful Compiler Foundation
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Compilation Process Details&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Preprocessing Stage:&lt;/strong&gt; GCC first performs preprocessing operations on the source file. During this stage, it handles all preprocessor directives starting with &lt;code&gt;#&lt;/code&gt;, such as &lt;code&gt;#include&lt;/code&gt; instructions. These instructions embed the entire content of specified header files (e.g., &lt;code&gt;&amp;lt;iostream&amp;gt;&lt;/code&gt; for C++ input/output stream operations) into the corresponding locations in the source file, allowing programs to use functions, classes, and other resources declared in those headers; macro definitions using &lt;code&gt;#define&lt;/code&gt; are also expanded and replaced during this stage, such as &lt;code&gt;#define PI 3.14159&lt;/code&gt;.  Every occurrence of &lt;code&gt;PI&lt;/code&gt; in the source file is then replaced with &lt;code&gt;3.14159&lt;/code&gt;. After preprocessing, the source file undergoes an initial &amp;ldquo;expansion.&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compilation Stage:&lt;/strong&gt; The preprocessed file enters the compilation stage, where GCC converts the source file into assembly language code based on the C++ language standard. It carefully checks the code structure, ensuring that class inheritance and polymorphism implementations are correct, as well as that function call parameters match. Upon detecting errors that violate the grammatical semantics, it immediately reports them and terminates the compilation process. For example, if the parameter list in a function declaration does not match its definition, GCC will accurately pinpoint the issue.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-gcc-a-powerful-compiler-cornerstone-1&#34;&gt;I. GCC: A Powerful Compiler Cornerstone
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Assembly Stage:&lt;/strong&gt; The assembler converts the assembly code generated in the previous step into machine code, producing object files with a &lt;code&gt;.o&lt;/code&gt; extension. These object files contain binary instructions that can be directly executed by the machine, but they cannot run independently because a complete program is typically composed of multiple modules, and function and variable references between these modules have not yet been resolved.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Linking Stage:&lt;/strong&gt; This is the final sprint to generate an executable file. The linker integrates multiple object files as well as required libraries (static or dynamic) together. For example, when using container classes from the C++ Standard Template Library, linking requires finding the corresponding library implementation code to ensure that the program can correctly call functions of objects like &lt;code&gt;vector&lt;/code&gt; and &lt;code&gt;list&lt;/code&gt; at runtime, ultimately generating a complete executable program.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ii-glibc-the-backbone-of-c-program-execution&#34;&gt;II. GLIBC: The Backbone of C++ Program Execution
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Nature and Function&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;GLIBC, or the GNU C Library, is a concrete implementation of the C standard library within the GNU ecosystem. Although its name emphasizes C, C++ programs heavily rely on it as well, because C++ inherits its foundational elements. It provides a vast array of basic functions, such as those for memory management – &lt;code&gt;malloc&lt;/code&gt; (dynamic memory allocation) and &lt;code&gt;free&lt;/code&gt; (memory deallocation) – which are indispensable when creating dynamic arrays and objects in C++, as well as string manipulation functions like &lt;code&gt;strcpy&lt;/code&gt; (string copy) and &lt;code&gt;strcat&lt;/code&gt; (string concatenation). Even though C++ has a more advanced &lt;code&gt;string&lt;/code&gt; class, these functions are still frequently used at the underlying level when interacting with C code or striving for extreme performance, as well as in early C++ development and scenarios where simplicity is paramount.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;ii-glibc-the-backbone-of-c-program-execution-1&#34;&gt;II. GLIBC: The Backbone of C++ Program Execution
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Collaboration with the Operating System&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;GLIBC acts as a crucial bridge between the operating system and applications. In Linux systems, when a C++ program initiates a system call – such as opening a file (using the &lt;code&gt;open&lt;/code&gt; function, which relies on GLIBC’s implementation), GLIBC encapsulates the program&amp;rsquo;s request in a manner conforming to the operating system kernel’s specifications and passes it to the kernel for processing. Upon completion by the kernel, GLIBC returns the results to the application. This allows applications to utilize various system resources – such as file systems, networks, and process management – without needing to delve into the complex details of the underlying system call interfaces.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;iii-compatibility-issues-after-c-program-deployment-an-analysis&#34;&gt;III. Compatibility Issues After C++ Program Deployment: An Analysis
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Compatibility Dilemmas Triggered by Differences in GLIBC Version&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Different Linux distributions often feature different versions of GLIBC. When a C++ program is compiled in a newer GLIBC environment, it may unknowingly utilize certain new function features or rely on optimized function implementations introduced in that version. For example, a newer GLIBC version has improved the memory allocation algorithm; the program frequently utilizes this new algorithm to enhance performance during runtime. Once this program is deployed on a lower-version GLIBC system, it may encounter issues such as failing to find the corresponding function (because the older version did not introduce it) or abnormal function behavior (the old implementation logic differs from the new one), leading to program crashes or incorrect results.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;iii-compatibility-issues-after-c-program-publishing-an-analysis&#34;&gt;III. Compatibility Issues After C++ Program Publishing: An Analysis
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Compatibility Risks Due to Compiler Differences&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Even when using the same GCC compiler, differences between different versions of GCC in terms of code generation, standard library support, and implementation details for C++ features can lead to compatibility issues. Newer GCC versions may have full support for the latest C++ standards (such as new feature modules in C++20 like coroutines), and if a program uses these advanced features and is compiled under an older GCC version, the compiler will error out due to its inability to recognize these new syntax structures. Even without syntax errors, different GCC versions have different optimization strategies, which can lead to significant differences in machine code generated in terms of execution efficiency and memory usage. In performance-critical scenarios, this can cause programs to behave differently in different environments. - &lt;strong&gt;Challenges Posed by Architectural Differences&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;C++ programs may need to run on different hardware system architectures, such as x86, ARM, and PowerPC. These architectures have unique instruction sets, memory layouts, and data alignment requirements. For example, a structure data layout that runs correctly on an x86 architecture might cause memory access exceptions on an ARM architecture due to differing alignment rules, leading to program errors. Furthermore, GCC generates significantly different machine code when compiling for various architectures; if the program contains hardcoded architectural-specific instructions or assumptions, it will inevitably fail during cross-architecture execution.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;four-strategies-for-addressing-compatibility-issues&#34;&gt;Four. Strategies for Addressing Compatibility Issues
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Utilization of Static Link Libraries&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Consider using static link libraries, packaging the code of libraries that your program depends on (such as GLIBC) directly into the executable file. This eliminates the need for the target system’s specific GLIBC version at runtime, effectively preventing issues caused by GLIBC version mismatches. However, static linking will significantly increase the size of the executable file, requiring a trade-off in resource-constrained scenarios.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Containerized Deployment&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Leveraging containerization technologies like Docker, encapsulate your C++ program and its required runtime environment (including specific versions of GCC, GLIBC, etc.) within an independent container. Regardless of the underlying operating system to which it is deployed, the container maintains consistency with the development environment, ensuring that the program runs as expected and greatly simplifies cross-environment deployment complexity. - &lt;strong&gt;Compatibility Testing and Continuous Integration&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Establish a comprehensive compatibility testing system, covering different GLIBC versions, GCC versions, and common system architectures. During the software development process, use continuous integration tools to perform automated testing on multiple environments regularly. Once compatibility issues are identified, they are promptly fixed, eliminating potential problems at their earliest stages and ensuring stability after program deployment.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;four-strategies-for-addressing-compatibility-issues-1&#34;&gt;Four. Strategies for Addressing Compatibility Issues
&lt;/h2&gt;&lt;p&gt;As a summary, a deep understanding of the workings of GCC and GLIBC, accurately identifying the root causes of C++ compatibility issues, and flexibly applying appropriate strategies are essential skills for every C++ developer to build robust, cross-platform applications. Only in this way can our C++ works run smoothly within diverse technological ecosystems.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Linux backend services handling large volumes of string data – performance is slow.</title>
        <link>https://ttf248.life/en/p/linux-backend-slow-string-processing/</link>
        <pubDate>Wed, 13 Nov 2024 19:42:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-backend-slow-string-processing/</guid>
        <description>&lt;p&gt;In the history of C++ development projects, we utilized a custom protocol for communication, which employed a two-dimensional array pattern. When processing large volumes of data, the protocol required iterating through the arrays and performing serialization operations to generate logs. Due to its low efficiency, this resulted in noticeable lag or stuttering within the system under heavy load, as reported by the business departments.&lt;/p&gt;
&lt;h2 id=&#34;problem-identification&#34;&gt;Problem Identification
&lt;/h2&gt;&lt;p&gt;When troubleshooting the issue, we first performed a performance analysis of the system and found that CPU utilization increased significantly when processing large amounts of data, and system response times became longer. Through analyzing the system logs, we identified numerous serialization operations, which were inefficient when handling two-dimensional arrays, leading to a decline in system performance.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;pstack&lt;/code&gt; tool captured thread information for the service, pinpointing that the log threads spent most of their time processing string concatenation.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is today&amp;rsquo;s focus: different accumulation methods have significant efficiency differences. Historically, the code used the &lt;code&gt;+&lt;/code&gt; operator, which frequently creates temporary objects and is very inefficient. You know it’s bad, but you don’t know &lt;em&gt;how&lt;/em&gt; bad it is.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;demo-verification&#34;&gt;Demo Verification
&lt;/h2&gt;&lt;p&gt;Based on the project code, we extracted the business logic and wrote a simple demo to verify the efficiency issues of string concatenation. We compiled and ran it in &lt;code&gt;Release&lt;/code&gt; mode using the &lt;code&gt;vs2022&lt;/code&gt; compiler under &lt;code&gt;windows&lt;/code&gt; and the &lt;code&gt;gcc8.5&lt;/code&gt; compiler under &lt;code&gt;linux&lt;/code&gt;, comparing the efficiencies.&lt;/p&gt;
&lt;h3 id=&#34;key-points-explanation&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;p&gt;The project utilized Method Four, and before obtaining test data, the reader should consider which method is most efficient and which is least efficient. I was quite surprised by the results.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Method 1 (&lt;code&gt;+=&lt;/code&gt; Concatenation)&lt;/strong&gt;: Directly concatenates each field using &lt;code&gt;+=&lt;/code&gt; to a string.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 2 (&lt;code&gt;std::ostringstream&lt;/code&gt; Concatenation)&lt;/strong&gt;: Uses a stream (&lt;code&gt;std::ostringstream&lt;/code&gt;) to concatenate fields, which is more efficient, especially when dealing with large amounts of data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 3 (Pre-allocated &lt;code&gt;+=&lt;/code&gt; Concatenation)&lt;/strong&gt;: Pre-allocates enough memory for the string using &lt;code&gt;reserve&lt;/code&gt; to reduce the overhead of memory reallocation and improve performance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 4 (&lt;code&gt;bodys = bodys + body + &amp;quot;\n&amp;quot;&lt;/code&gt;)&lt;/strong&gt;: Each concatenation creates a new temporary string object, leading to performance degradation, especially with large-scale concatenations due to the allocation and copying of a new memory space each time.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Referring to the results, we can see that this method was selected as the least efficient.&lt;/p&gt;
&lt;p&gt;Furthermore, let&amp;rsquo;s analyze the optimization efficiency of different platform compilers – Microsoft’s &lt;code&gt;visual studio&lt;/code&gt; remains consistently excellent, with high string optimization efficiency, while the &lt;code&gt;gcc&lt;/code&gt; compiler lags somewhat in this regard.&lt;/p&gt;
&lt;h3 id=&#34;key-points-explanation-1&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;The code executes on different machines, and the two datasets do not have a direct comparison; instead, differences can be compared between various splicing methods.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;complete-code&#34;&gt;Complete Code
&lt;/h2&gt;</description>
        </item>
        <item>
        <title>C&#43;&#43; Lambda Expression Parameter Lifetimes</title>
        <link>https://ttf248.life/en/p/cpp-lambda-parameter-lifetime/</link>
        <pubDate>Wed, 13 Nov 2024 19:23:02 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-lambda-parameter-lifetime/</guid>
        <description>&lt;p&gt;In C++, lambda expressions are a convenient way to create anonymous functions that can capture external variables and use them within their bodies. This makes lambdas a flexible programming tool. However, the lifetime of parameters in a lambda expression is an aspect that requires careful attention, especially when capturing and passing parameters.&lt;/p&gt;
&lt;h3 id=&#34;1-lambda-expression-parameter-lifetime&#34;&gt;1. Lambda Expression Parameter Lifetime
&lt;/h3&gt;&lt;p&gt;The lifetime of parameters in a lambda expression is typically the same as that of other C++ functions. Parameters exist while the function is being called, and their lifetime ends when the function call terminates. However, due to the possibility of lambdas capturing external variables, the parameter&amp;rsquo;s lifetime is also affected by how it’s captured.&lt;/p&gt;
&lt;h3 id=&#34;2-capturing-the-relationship-with-parameter-lifecycles&#34;&gt;2. Capturing the Relationship with Parameter Lifecycles
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;#### 2.1 Capturing External Variables

C++ lambda expressions allow external variables to be captured in two ways:

- **Capture by Value:** When capturing by value, the value of the external variable is copied into the lambda, and the lifetime of the copy is controlled by the lifetime of the lambda.
- **Capture by Reference:** When capturing by reference, a reference to the external variable is retained, and the lambda&#39;s reference points to the original external variable. The lifetime depends on the external variable.

For captured variables, the lifetimes are as follows:

- **Capture by Value:** When capturing, the value of the external variable is copied into the lambda; when the lambda’s lifetime ends, the copy is destroyed.
- **Capture by Reference:** The lambda holds a reference to the external variable, and **the external variable must be valid before it is used within the lambda, otherwise undefined behavior results.**
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;22-lambda-parameters&#34;&gt;2.2 Lambda Parameters
&lt;/h4&gt;&lt;p&gt;Lambda parameters are similar to regular function parameters; their lifetime is limited to the lambda function body. That is, lambda parameters are created when the lambda is called and their lifetime ends when the lambda call completes.
In this example, &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; are the parameters of the lambda expression, they are created when the lambda is called and destroyed when the lambda executes.&lt;/p&gt;
&lt;h3 id=&#34;3-lifecycle-issues-when-capturing-external-variables&#34;&gt;3. Lifecycle Issues When Capturing External Variables
&lt;/h3&gt;&lt;h4 id=&#34;31-whether-captured-variables-are-valid-outside-lambda&#34;&gt;3.1 Whether Captured Variables Are Valid Outside Lambda
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Value Capture:&lt;/strong&gt; Even if the external variable is destroyed after the lambda call, the lambda internally holds a copy of the external variable. Therefore, the copy within the lambda can be safely used even if the external variable no longer exists.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reference Capture:&lt;/strong&gt; If the captured variable is a reference to the external variable, the lambda&amp;rsquo;s access to that reference depends on the lifecycle of the external variable. If the external variable is destroyed before the lambda executes, a dangling reference issue will occur, leading to undefined behavior.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;It’s important to ensure that the external variables are valid when the lambda executes if the execution order of the lambda is not deterministic.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>Upgrading the GCC version caused program crashes: hidden issues due to code non-compliance.</title>
        <link>https://ttf248.life/en/p/upgrade-gcc-version-causes-program-crash-code-irregularities/</link>
        <pubDate>Sun, 10 Mar 2024 23:19:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/upgrade-gcc-version-causes-program-crash-code-irregularities/</guid>
        <description>&lt;p&gt;In the same business code scenario, the program compiled and ran normally in a CentOS 7 environment. However, when switching to CentOS 8 and using an updated version of GCC for compilation, the program crashed. It’s worth noting that the issue only occurs in &lt;strong&gt;Release mode&lt;/strong&gt;, while &lt;strong&gt;Debug mode&lt;/strong&gt; does not exhibit any problems. This is the first time we&amp;rsquo;ve encountered a situation like this; after three days of investigation, we finally identified the root cause.&lt;/p&gt;
&lt;h3 id=&#34;problem-identification&#34;&gt;Problem Identification
&lt;/h3&gt;&lt;p&gt;After investigation, the root cause of the issue was &lt;strong&gt;the function lacked a return value&lt;/strong&gt;. In Release mode, new versions of GCC perform more optimizations, which caused an unknown logic to occur within the function that originally did not have an explicit return value during execution, leading to a crash. Our conclusion is that &lt;strong&gt;compiler warnings should not be ignored, especially in legacy projects where some warnings may be dismissed, but it’s also important to avoid suppressing all warnings.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;environment-details&#34;&gt;Environment Details
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CentOS 7 GCC Version:&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CentOS 8 GCC Version:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;crash-phenomena&#34;&gt;Crash Phenomena
&lt;/h3&gt;&lt;p&gt;When analyzing the stack trace of a program crash, the following stack information was observed:
This stack doesn&amp;rsquo;t appear intuitive; the crash function’s stack information displays as a ‘??’, which makes troubleshooting the issue even more complex.&lt;/p&gt;
&lt;h3 id=&#34;code-example&#34;&gt;Code Example
&lt;/h3&gt;&lt;p&gt;To better understand the issue, here is a minimal code example that reproduces the crash:
The &lt;code&gt;test()&lt;/code&gt; function in this code clearly does not explicitly return a value, and its return type is &lt;code&gt;int&lt;/code&gt;. According to the C++ standard, when a function is declared as an &lt;code&gt;int&lt;/code&gt; type, it must have a return value, otherwise it may lead to undefined behavior.&lt;/p&gt;
&lt;h3 id=&#34;compilation-warnings&#34;&gt;Compilation Warnings
&lt;/h3&gt;&lt;p&gt;In our project, the CMake script suppresses many compiler warnings, including the following:&lt;/p&gt;
&lt;p&gt;This warning indicates that the &lt;code&gt;test()&lt;/code&gt; function does not return a value, which is the root cause of the problem. Newer versions of GCC (such as 8.5.0) may perform unstable optimizations on this undefined behavior when optimizing code, potentially leading to program crashes.&lt;/p&gt;
&lt;h3 id=&#34;assembly-code-differences&#34;&gt;Assembly Code Differences
&lt;/h3&gt;&lt;p&gt;To explain the differences in GCC compiler optimization behavior, we compared assembly code generated by different versions of GCC:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GCC 4.8.5 Generated Assembly Code:&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The assembly code is relatively verbose and includes logic for handling standard output streams (such as &lt;code&gt;std::cout&lt;/code&gt;). This indicates that the compiler performed more conservative optimizations, not optimizing excessively for the missing return value issue in the &lt;code&gt;test()&lt;/code&gt; function, possibly to avoid a crash.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GCC 8.5.0 Generated Assembly Code:&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The new version of GCC performed more optimizations, reducing the code volume. However, this optimization may have resulted in undefined behavior when executing a function without a return value, leading to program crashes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h3&gt;&lt;p&gt;Through this troubleshooting process, we deeply realized that in C++, &lt;strong&gt;function return values must be explicit&lt;/strong&gt;, especially when functions are declared as &lt;code&gt;int&lt;/code&gt;, a return value must be provided. When upgrading from older versions of compilers to newer GCC versions, more optimization and stricter warning mechanisms may arise. Therefore, we recommend not suppressing all warnings during compilation, but rather selectively addressing them, particularly common issues such as function return values and type matching.
Ultimately, by adding a return value to the &lt;code&gt;test()&lt;/code&gt; function, the problem was resolved, and the program returned to normal operation.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>C&#43;&#43; Programming Traps: A Detailed Explanation of Program Crashes Caused by Improper Use of `std::map`</title>
        <link>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</link>
        <pubDate>Sun, 10 Mar 2024 22:03:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</guid>
        <description>e&gt;
&lt;h2 id=&#34;body&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;In the C++ standard library, &lt;code&gt;std::map&lt;/code&gt; is an associative container that stores elements in ascending order based on their keys (key), and provides efficient keyword lookup functionality. However, novice developers sometimes find themselves in trouble due to a misunderstanding of the behavior of the square bracket operator &lt;code&gt;[]&lt;/code&gt; within &lt;code&gt;std::map&lt;/code&gt;. In fact, when using &lt;code&gt;[]&lt;/code&gt; to access a non-existent key, &lt;code&gt;std::map&lt;/code&gt; inserts a new key-value pair, and the default constructor will be used to initialize the value type associated with that key.&lt;/p&gt;
&lt;p&gt;Although this code does not directly cause the program to crash, this implicit insertion behavior can lead to unexpected side effects in certain situations, such as resource leaks or changes inconsistent with expectations. Worse still, concurrent access to uninitialized memory regions in a multithreaded environment can even cause the program to crash. To prevent such issues, it is recommended to use the &lt;code&gt;std::map::find()&lt;/code&gt; or &lt;code&gt;std::map::count()&lt;/code&gt; methods to check if a key exists, or to explicitly insert elements using the &lt;code&gt;std::map::insert()&lt;/code&gt; method.&lt;/p&gt;
&lt;p&gt;If the map container internally stores objects of pointer types, the automatic insertion behavior will save an uninitialized pointer, and any call to this pointer will cause the program to crash.&lt;/p&gt;</description>
        </item>
        <item>
        <title>C&#43;&#43; Function Call Latency</title>
        <link>https://ttf248.life/en/p/cpp-function-call-timing/</link>
        <pubDate>Wed, 24 Jan 2024 14:11:33 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-function-call-timing/</guid>
        <description>&lt;p&gt;Designed a行情 SDK, implementing different callback function implementations, and performed an extensive test. Recently I&amp;rsquo;ve been looking into C++ function programming, where functions have become first-class citizens, flowing within the program internally – what’s the difference in performance?&lt;/p&gt;
&lt;p&gt;Previous article link: &lt;a class=&#34;link&#34; href=&#34;https://ttf248.life/en/p/compiler-callback-function-performance-testing/&#34; &gt;Compiler, Callback Functions, Performance Testing&lt;/a&gt;
&lt;code&gt;leimao&lt;/code&gt;大佬 also did similar tests, so I borrowed their code.&lt;/p&gt;
&lt;h2 id=&#34;main-content&#34;&gt;Main Content
&lt;/h2&gt;&lt;p&gt;The execution platform remains our old friend, &lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leimao.github.io/blog/CPP-Function-Call-Performance/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://leimao.github.io/blog/CPP-Function-Call-Performance/&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>C11: sleep for vs yield</title>
        <link>https://ttf248.life/en/p/c11-sleep-for-vs-yield/</link>
        <pubDate>Tue, 20 Sep 2022 20:54:51 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/c11-sleep-for-vs-yield/</guid>
        <description>&lt;p&gt;While reviewing the code, &lt;code&gt;std::this_thread::yield()&lt;/code&gt; suddenly popped into my view, a syntax sugar from &lt;code&gt;C11&lt;/code&gt; that I’d used quite a bit, but hadn&amp;rsquo;t noticed before.&lt;/p&gt;
&lt;p&gt;I didn&amp;rsquo;t consult the manual; first, I thought it had something to do with asynchronous operations – the word was used in the coroutine implementation of the Boost library.  Clearly, it wasn’t related to coroutines; it’s about controlling logic within a regular thread.&lt;/p&gt;
&lt;h2 id=&#34;documentation&#34;&gt;Documentation
&lt;/h2&gt;&lt;h3 id=&#34;yield&#34;&gt;yield
&lt;/h3&gt;&lt;p&gt;The accuracy of this function depends on the implementation, particularly the OS scheduler mechanism and system state used. For example, the First-Come, First-Served (FCFS) real-time scheduler (Linux’s SCHED_FIFO) will suspend the current thread and place it at the end of the queue for other threads with the same priority that are ready to run (and has no effect if there are no other threads with the same priority).&lt;/p&gt;
&lt;h3 id=&#34;sleep_for&#34;&gt;sleep_for
&lt;/h3&gt;&lt;p&gt;Blocks the current thread&amp;rsquo;s execution for at least the specified &lt;code&gt;sleep_duration&lt;/code&gt;.
This function may block longer than &lt;code&gt;sleep_duration&lt;/code&gt; due to scheduling or resource contention delays.
The standard library recommends measuring durations using a monotonic clock. If implementing with system time instead, the wait time may be sensitive to clock adjustments.&lt;/p&gt;
&lt;h3 id=&#34;analysis&#34;&gt;Analysis
&lt;/h3&gt;&lt;p&gt;Both functions are designed to release the current thread and its associated resources, with the actual effect depending on the platform. I’m still a bit unclear at this point, so let&amp;rsquo;s run the code to see the execution results.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ThinkPad laptop (Visual Studio Community 2022), Tencent Cloud S2 Standard Server (gcc8.5)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;analysis-1&#34;&gt;Analysis
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Execution Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First/us&lt;/th&gt;
&lt;th&gt;Second/us&lt;/th&gt;
&lt;th&gt;Third/us&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h3 id=&#34;analysis-2&#34;&gt;Analysis
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Execution Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First Time / us&lt;/th&gt;
&lt;th&gt;Second Time / us&lt;/th&gt;
&lt;th&gt;Third Time / us&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h3 id=&#34;analysis-3&#34;&gt;Analysis
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Execution Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First/us&lt;/th&gt;
&lt;th&gt;Second/us&lt;/th&gt;
&lt;th&gt;Third/us&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h3 id=&#34;analysis-4&#34;&gt;Analysis
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Execution Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First/us&lt;/th&gt;
&lt;th&gt;Second/us&lt;/th&gt;
&lt;th&gt;Third/us&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h3 id=&#34;analysis-5&#34;&gt;Analysis
&lt;/h3&gt;&lt;p&gt;From the running results, it’s not difficult to understand that due to differences in operating system implementations, the stability of high-precision sleep varies greatly. If you want high-precision sleep, using &lt;code&gt;yield&lt;/code&gt; is more appropriate.&lt;/p&gt;
&lt;p&gt;When the time precision is increased to &lt;code&gt;ms&lt;/code&gt;, the difference between them is no longer significant.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Why Do We Need to Learn a New Language?</title>
        <link>https://ttf248.life/en/p/why-learn-a-new-language/</link>
        <pubDate>Thu, 04 Aug 2022 11:27:30 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/why-learn-a-new-language/</guid>
        <description>&lt;p&gt;Starting from my academic years, I’ve been working with &lt;code&gt;C++&lt;/code&gt; for over ten years. So, why do I need to learn other programming languages?&lt;/p&gt;
&lt;p&gt;Work experience: Lacking experience in elegant module design, &lt;code&gt;C++&lt;/code&gt; syntax is freeform. Learning other languages helps me guide the development of more elegant designs.&lt;/p&gt;
&lt;p&gt;I often use them when writing some tools. The design principles for low-level libraries and business modules are also becoming clearer.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Standard Library Container Memory Allocators: allocator</title>
        <link>https://ttf248.life/en/p/standard-library-container-memory-allocator/</link>
        <pubDate>Mon, 30 Dec 2019 13:26:19 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/standard-library-container-memory-allocator/</guid>
        <description>&lt;p&gt;A custom allocator can improve performance, increase memory utilization efficiency, and address the issue of frequent, small memory allocations.&lt;/p&gt;
&lt;h4 id=&#34;antecedent&#34;&gt;Antecedent
&lt;/h4&gt;&lt;p&gt;Recently, I&amp;rsquo;ve been working on the development of network data packets, requiring frequent allocation and release of small blocks of memory. Initially, I considered using a memory pool, reviewing several existing ones and discovering this:
&lt;a class=&#34;link&#34; href=&#34;https://github.com/cacay/MemoryPool&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/cacay/MemoryPool&lt;/a&gt;
When looking at the interface, I was quite puzzled by how the memory pool&amp;rsquo;s implementation was a bit strange. The &lt;code&gt;MemoryPool&lt;/code&gt; implementation logic involves allocating fixed-size memory spaces. Having reviewed Boost’s memory pool interface, it provides a template that is instantiated when used. Fortunately, this library already had an article describing it, mentioning the concept of ‘allocator’.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;#### [wiki](https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_(C%2B%2B))

In C++ programming, an allocator is a key component of the C++ standard library. The C++ library defines various data structures commonly referred to as &amp;quot;containers&amp;quot; (such as linked lists, sets, etc.). A common feature of these containers is that their size can be changed at runtime; therefore, dynamic memory allocation becomes necessary to achieve this. The allocator is used to handle container requests for memory allocation and deallocation. In other words, the allocator encapsulates the low-level details of memory management for standard template library (STL) containers. By default, the C++ standard library uses its built-in generic allocator; however, programmers can customize allocators to replace it as needed.
``` The allocator was originally invented by Alexander Stepanov as part of the C++ Standard Template Library (STL) as a way to “make the library more flexible and independent of the underlying data model,” allowing programmers to use custom pointer and reference types within the library. However, when the STL was incorporated into the C++ standard, the C++ standards committee realized that full abstraction of the data model would lead to unacceptable performance penalties. To compromise, restrictions on allocators in the standard became much stricter, and as a result, the degree to which allocators can be customized is now greatly limited compared to Stepanov’s original vision.

```markdown
#### [wiki](https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_(C%2B%2B))
Although customization of the allocator is limited, it is still often necessary to use a custom allocator in many cases, typically for encapsulating access methods to different types of memory spaces (such as shared memory and reclaimed memory), or for improving performance when using memory pools. In addition, from the perspective of memory usage and execution time, introducing a dedicated allocator for programs that frequently perform small amounts of memory allocation will also benefit.
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;usage-requirementshttpszhwikipediaorgwikie58886e9858de599a8_c2b2b&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Usage Requirements&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;Defining custom allocators primarily aims to improve performance. Utilizing a dedicated custom allocator can enhance program performance, or improve memory usage efficiency, or both [4][8]. The default allocator uses the &lt;code&gt;new&lt;/code&gt; operator to allocate storage [Reference 5], which often leverages the C language heap allocation function (malloc()) [9]. Because heap allocation functions are typically optimized for infrequent large memory allocations, the default allocator generally performs well when allocating memory for containers that require a single large memory allocation, such as vectors and doubly-ended queues [8]. However, when using the default allocator to allocate memory for associative containers with linked lists or bidirectional linked lists – which frequently require allocating small amounts of memory – performance is typically very low [4][9].&lt;/p&gt;
&lt;h4 id=&#34;usage-requirementshttpsenwikipediaorgwikimemory_pool_c2b2b&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Memory_pool_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Usage Requirements&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;In short, this section (…)(like) is a “I Have a Dream” speech for the allocator. Before the dream comes true, programmers concerned with portability will be limited to (using) stateless custom allocators.
—Scott Meyers, &lt;em&gt;Effective STL&lt;/em&gt;
Given this, in this case, memory pools are often used to address frequent, small allocations [8]. Unlike the default “on-demand allocation” method, when using a memory pool allocator, the program pre-allocates large blocks of memory (referred to as the “memory pool”) upfront.  Then, when requesting memory, the custom allocator simply returns a pointer to an available block within the pool. Unlike object deconstruction, no actual memory is released; instead, the release is deferred until the lifecycle of the memory pool ends [Note 1][8].&lt;/p&gt;
&lt;h4 id=&#34;usage-requirementshttpszhwikipediaorgwikie58886e9858de599a8_c2b2b-1&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Usage Requirements&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;On the topic of &amp;ldquo;Custom Allocators,&amp;rdquo; numerous C++ experts and authors have participated in discussions, such as Scott Meyers&amp;rsquo; &lt;em&gt;Effective STL&lt;/em&gt; and Andrei Alexandrescu’s &lt;em&gt;Modern C++ Design&lt;/em&gt;, which both mention it. Meyers observed that if one requires all instances of a particular type &lt;code&gt;T&lt;/code&gt;’s allocator to be equal, then the portable allocator instance must not contain state. Although the C++ standard encourages library implementers to support stateful allocators [Ref 4], Meyers called this paragraph “(seemingly) a wonderful idea,” but it is almost empty rhetoric, and considered the allocator restrictions “too strict” [4]. For example, STL’s list allows the splice method, meaning a node from one list object A can be directly inserted into another list object B. This requires that the memory allocated by A’s allocator is released by B’s allocator, thereby deducing that A and B’s allocator instances must be equal. Meyer’s conclusion is that allocators should be defined as types using static methods. For example, according to the C++ standard, an allocator must provide a class template other that implements the rebind method.&lt;/p&gt;
&lt;h4 id=&#34;usage-requirementshttpszhwikipediaorgwikie58886e9858de599a8_c2b2b-2&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Usage Requirements&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;Additionally, in &lt;em&gt;The C++ Programming Language&lt;/em&gt; by Bjarne Stroustrup, he states “&amp;lsquo;strict allocation to avoid different information for each object,&amp;rsquo; this is clearly not a problem’ (roughly), and points out that most allocators don&amp;rsquo;t need state, or even perform better when there is no state. He proposes three use cases for custom allocators: pool-based allocator, shared memory allocator, and garbage collector, and demonstrates an implementation of an allocator which utilizes an internal memory pool to quickly allocate/deallocate small amounts of memory. However, he also notes that such optimization may already be present in the sample allocator he provides [3].
Another use for custom allocators is debugging memory-related errors [10]. To achieve this, you can write a memory allocator that allocates additional memory when allocating, and uses it to store debugging information. This allocator not only ensures that memory is allocated/deallocated by the same type of allocator, but also provides some protection against cache overflows [11].&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>

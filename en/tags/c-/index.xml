<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>C&#43;&#43; on Uncle Xiang&#39;s Notebook</title>
        <link>https://ttf248.life/en/tags/c-/</link>
        <description>Recent content in C&#43;&#43; on Uncle Xiang&#39;s Notebook</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Wed, 28 May 2025 09:47:38 +0800</lastBuildDate><atom:link href="https://ttf248.life/en/tags/c-/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>C&#43;&#43; Bitwise Operations Fundamentals: Bit Extraction and Flag Setting</title>
        <link>https://ttf248.life/en/p/cpp-bitwise-operations-basics-flags/</link>
        <pubDate>Fri, 17 Jan 2025 02:23:56 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-bitwise-operations-basics-flags/</guid>
        <description>&lt;p&gt;In practical C++ development, bitwise operations are a common technique, particularly when handling system states, flags, or control bits. This article will explain how to use bitwise operations to get and set specific flag bits through an example.&lt;/p&gt;
&lt;h3 id=&#34;basic-operating-concepts&#34;&gt;Basic operating concepts
&lt;/h3&gt;&lt;p&gt;In computers, data is stored as binary digits (bits) of 0 and 1. Bitwise operations are operations performed on these bits. C++ has several common bitwise operators:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Checks if a bit is 1&lt;/li&gt;
&lt;li&gt;Sets a specific bit to 1&lt;/li&gt;
&lt;li&gt;Used to invert a bit&lt;/li&gt;
&lt;li&gt;Reverse all bits&lt;/li&gt;
&lt;li&gt;Shift all bits several positions to the left&lt;/li&gt;
&lt;li&gt;Shift all bits right by several positions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this case, we need to perform a series of bit operations on a &lt;strong&gt;bold&lt;/strong&gt; &lt;em&gt;italicized&lt;/em&gt; value to represent different states using various flag bits&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;flowchart LR
    A[原始数值: 00010000] --&amp;gt; B[左移: 00010000 &amp;lt;&amp;lt; 1]
    B --&amp;gt; C[结果: 00100000]
    C --&amp;gt; D[右移: 00100000 &amp;gt;&amp;gt; 1]
    D --&amp;gt; E[结果: 00010000]

    subgraph 左移操作
        direction LR
        A --&amp;gt; B --&amp;gt; C
    end

    subgraph 右移操作
        direction LR
        C --&amp;gt; D --&amp;gt; E
    end
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;requirements-analysis&#34;&gt;Requirements Analysis
&lt;/h3&gt;&lt;p&gt;According to the description in the question, we have a 16-bit flag used to represent different states. These states are represented by various binary bits, each corresponding to a specific meaning. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Whether it failed&lt;/li&gt;
&lt;li&gt;Is it compressed?&lt;/li&gt;
&lt;li&gt;Incremental?&lt;/li&gt;
&lt;li&gt;Is there a follow-up package?&lt;/li&gt;
&lt;li&gt;Normal request or logout&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;implement-using-bitwise-operations&#34;&gt;Implement using bitwise operations
&lt;/h3&gt;&lt;p&gt;We will use bit operations to set and get these flag bits. Specifically:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Get the value of a single bit (0 or 1)&lt;/li&gt;
&lt;li&gt;Set a bit to 1&lt;/li&gt;
&lt;li&gt;Set a bit to 0&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We first define a flag to store these flags. Then, we use bit operations to check and set the corresponding flags.&lt;/p&gt;
&lt;h3 id=&#34;c-example-code&#34;&gt;C++ example code
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;bitset&amp;gt;

// 定义标志位常量
const unsigned short BIT_0_FAIL = 1 &amp;lt;&amp;lt; 0;    // bit0 是否失败
const unsigned short BIT_1_COMPRESSED = 1 &amp;lt;&amp;lt; 1; // bit1 是否压缩
const unsigned short BIT_2_INCREMENT = 1 &amp;lt;&amp;lt; 2;  // bit2 是否增量
const unsigned short BIT_3_HAS_MORE = 1 &amp;lt;&amp;lt; 3;   // bit3 是否有后续包
const unsigned short BIT_5_CANCEL = 1 &amp;lt;&amp;lt; 5;     // bit5 正常请求(0)或注销(1)

// 检查某一位是否为1
bool isBitSet(unsigned short wInfo, unsigned short bitMask) {
    return (wInfo &amp;amp; bitMask) != 0;
}

// 设置某一位为1
void setBit(unsigned short&amp;amp; wInfo, unsigned short bitMask) {
    wInfo |= bitMask;
}

// 清除某一位（设置为0）
void clearBit(unsigned short&amp;amp; wInfo, unsigned short bitMask) {
    wInfo &amp;amp;= ~bitMask;
}

int main() {
    // 假设wInfo的初始值为0
    unsigned short wInfo = 0;

    // 设置bit0（失败标志）
    setBit(wInfo, BIT_0_FAIL);
    
    // 设置bit1（压缩标志）
    setBit(wInfo, BIT_1_COMPRESSED);
    
    // 打印wInfo的二进制值
    std::cout &amp;lt;&amp;lt; &amp;quot;wInfo (in binary): &amp;quot; &amp;lt;&amp;lt; std::bitset&amp;lt;16&amp;gt;(wInfo) &amp;lt;&amp;lt; std::endl;

    // 检查各个标志位
    std::cout &amp;lt;&amp;lt; &amp;quot;bit0 (是否失败): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_0_FAIL) ? &amp;quot;是&amp;quot; : &amp;quot;否&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit1 (是否压缩): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_1_COMPRESSED) ? &amp;quot;是&amp;quot; : &amp;quot;否&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit2 (是否增量): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_2_INCREMENT) ? &amp;quot;是&amp;quot; : &amp;quot;否&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit3 (是否有后续包): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_3_HAS_MORE) ? &amp;quot;是&amp;quot; : &amp;quot;否&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit5 (是否注销): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_5_CANCEL) ? &amp;quot;是&amp;quot; : &amp;quot;否&amp;quot;) &amp;lt;&amp;lt; std::endl;

    // 清除bit1（压缩标志）
    clearBit(wInfo, BIT_1_COMPRESSED);
    
    // 打印更新后的wInfo
    std::cout &amp;lt;&amp;lt; &amp;quot;Updated wInfo (in binary): &amp;quot; &amp;lt;&amp;lt; std::bitset&amp;lt;16&amp;gt;(wInfo) &amp;lt;&amp;lt; std::endl;

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Run code, recommended by an old friend: &lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;wInfo (in binary): 0000000000000011
bit0 (是否失败): 是
bit1 (是否压缩): 是
bit2 (是否增量): 否
bit3 (是否有后续包): 否
bit5 (是否注销): 否
Updated wInfo (in binary): 0000000000000001
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;code-explanation&#34;&gt;Code explanation
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Using bitwise operations (shifting, ANDing, ORing, XORing, etc.), we assign each flag a unique binary position&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The bolded and italicized elements are not part of the translation. Here&amp;rsquo;s the translation: It is a matter of great importance.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set the specific flag bit to 1&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To set a specific flag bit to 0&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary
&lt;/h3&gt;&lt;p&gt;Bit manipulation allows for efficient handling of multiple status flags. This technique is particularly useful in practical development, such as embedded systems, network protocols, and system state management, where bit flags are often used to represent multiple binary states, saving space and improving efficiency.&lt;/p&gt;
&lt;p&gt;This blog post aims to help you understand how to use bitwise operations in C++ for bit manipulation and setting. Mastering these skills is very helpful for writing efficient and maintainable code!&lt;/p&gt;</description>
        </item>
        <item>
        <title>Understanding GCC, GLIBC, and C&#43;&#43; Program Compatibility Issues</title>
        <link>https://ttf248.life/en/p/deep-understanding-gcc-glibc-cpp-compatibility-issues/</link>
        <pubDate>Mon, 06 Jan 2025 19:51:16 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/deep-understanding-gcc-glibc-cpp-compatibility-issues/</guid>
        <description>&lt;p&gt;In C++ development, GCC and GLIBC are essential components, and compatibility issues after program release often trouble developers. This article will delve into their nature, explore the root causes of compatibility problems, and discuss corresponding solutions.&lt;/p&gt;
&lt;h2 id=&#34;i-gcc-a-powerful-compiler-foundation&#34;&gt;I. GCC: A Powerful Compiler Foundation
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;GCC, the GNU Compiler Collection, is an open-source compiler suite developed by the GNU project. It&amp;rsquo;s far more than a typical compiler; it supports numerous mainstream languages including C, C++, Objective-C, Fortran, Ada, and Go, providing a one-stop solution for cross-language development.&lt;/li&gt;
&lt;li&gt;Taking C++ as an example, when we write a source file containing complex features such as classes, templates, and function overloading, GCC can convert the high-level C++ code into instruction sequences that the underlying machine can understand and execute, based on C++&amp;rsquo;s strict syntax and semantic rules. This process involves multiple fine-grained stages including lexical analysis, syntactic analysis, semantic analysis, optimization, and code generation.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;GCC first preprocesses the source file. During this process, it handles all directives, and after preprocessing, the source file is initially expanded.&lt;/li&gt;
&lt;li&gt;After preprocessing, the file enters the compilation stage. GCC, based on the C++ language standard, converts the source file into assembly code. It carefully checks the code structure, ensuring correct class inheritance, polymorphism implementation, and function call parameter matching. If any errors violating syntax or semantics are detected, it will promptly report them and terminate the compilation process. For example, if there is a mismatch between the function declaration and definition&amp;rsquo;s parameter list, GCC will precisely indicate the issue.&lt;/li&gt;
&lt;li&gt;The assembler converts the assembly code generated in the previous step into machine code, producing a target file with a &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; extension. These target files contain binary instructions that can be directly executed by the machine, but they cannot run independently because a complete program typically consists of multiple modules with unresolved function and variable references.&lt;/li&gt;
&lt;li&gt;This is the final sprint to generate an executable file. The linker integrates multiple object files and required library files (static or dynamic libraries). For example, when using container classes from the C++ Standard Template Library, the linker needs to find the corresponding library implementation code to ensure that functions like __INLINE_CODE_0__BOLD_3&lt;code&gt;list&lt;/code&gt; can be correctly called at runtime, ultimately generating a complete executable program.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ii-glibc-the-backbone-behind-c-program-execution&#34;&gt;II. GLIBC: The Backbone Behind C++ Program Execution
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;GLIBC, or the GNU C Library, is a specific implementation of the C standard library within the GNU ecosystem. Although its name highlights C, C++ programs are equally reliant on it, as C++ inherits much from C&amp;rsquo;s foundation. It provides a vast array of fundamental functions, such as those for memory management, and frequently appears in early C++ development and scenarios demanding high performance and conciseness.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;GLIBC acts as a crucial bridge between the operating system and applications. In Linux systems, when a C++ program makes a system call—for example, to open a file (using a function that relies on GLIBC implementation)—GLIBC encapsulates the program&amp;rsquo;s request in the manner specified by the operating system kernel, passes it to the kernel, and returns the result to the application after the kernel has processed it. This allows applications to use various system resources—such as file systems, networks, and process management—without needing to understand the complex details of the underlying system call interfaces.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;compatibility-issues-after-c-program-release&#34;&gt;Compatibility Issues After C++ Program Release
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Different Linux distributions often use different versions of GLIBC. When a C++ program is compiled in a high-version GLIBC environment, it may inadvertently utilize new functions or rely on optimized implementations introduced in that version. For example, newer GLIBC versions improve memory allocation algorithms, and programs frequently leverage these improvements for performance gains. If such a program is ported to a system with an older GLIBC version, it may encounter missing function errors (because the function wasn&amp;rsquo;t introduced in the older version) or abnormal function behavior (due to discrepancies between old and new implementations), leading to crashes or incorrect results.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Even when using the same GCC compiler, different versions exhibit variations in code generation, standard library support, and implementation details of C++ features. Newer GCC versions may offer complete support for the latest C++ standards (e.g., modules and coroutines in C++20). Compiling programs utilizing these advanced features with older GCC versions can result in errors due to unrecognized syntax; even without syntactic errors, differing optimization strategies across GCC versions can lead to significantly different machine code performance—affecting execution efficiency and memory usage—potentially causing vastly different behavior in demanding scenarios.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;C++ programs may need to run on different hardware architectures, such as x86, ARM, and PowerPC. These architectures have their own unique instruction sets, memory layouts, and data alignment requirements. For example, a structure&amp;rsquo;s data storage layout that runs correctly on the x86 architecture can cause abnormal memory access and program errors on the ARM architecture due to different alignment rules. Furthermore, GCC generates significantly different machine code when compiling for different architectures; if the program contains hardcoded architecture-specific instructions or assumptions, cross-architecture runtime failures are inevitable.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;strategies-for-addressing-compatibility-issues&#34;&gt;Strategies for Addressing Compatibility Issues
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Consider using a static library, which packages the program&amp;rsquo;s dependencies (e.g., GLIBC) directly into the executable file. This eliminates runtime dependency on specific GLIBC versions, effectively preventing issues caused by version mismatches. However, static linking significantly increases the executable size and requires weighing the pros and cons in scenarios with limited storage resources.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;By leveraging containerization technologies like Docker, the C++ program and its required runtime environment (including specific versions of GCC, GLIBC, etc.) are encapsulated within a standalone container. This ensures consistent execution environments regardless of the underlying operating system, simplifying cross-environment deployment significantly.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Establish a comprehensive compatibility testing system covering various GLIBC versions, GCC versions, and common system architectures. Through continuous integration tools, conduct regular automated testing in multiple environments during development. Address any compatibility issues promptly to eliminate potential risks early on and ensure stability upon release.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thoroughly understanding the workings of GCC and GLIBC, accurately identifying the root causes of C++ compatibility issues, and skillfully applying solutions are essential skills for every C++ developer aiming to build robust, cross-platform applications. Only then can our C++ works navigate diverse technical ecosystems smoothly.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Slow efficiency when processing large string data in Linux backend services</title>
        <link>https://ttf248.life/en/p/linux-backend-slow-string-processing/</link>
        <pubDate>Wed, 13 Nov 2024 19:42:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-backend-slow-string-processing/</guid>
        <description>&lt;p&gt;In past C++ development projects, we used a custom protocol for communication that employed a two-dimensional array structure. Due to inefficient traversal and serialization of this array when handling large amounts of data, the system experienced noticeable lag under high load, prompting feedback from the business department regarding these slowdowns.&lt;/p&gt;
&lt;h2 id=&#34;issue-identification&#34;&gt;Issue identification
&lt;/h2&gt;&lt;p&gt;During troubleshooting, we first performed a performance analysis of the system. We found that CPU usage increased significantly and response times lengthened when processing large amounts of data. Analyzing system logs revealed numerous serialization operations, which were inefficient when handling two-dimensional arrays, leading to decreased system performance.&lt;/p&gt;
&lt;p&gt;The tool&amp;rsquo;s thread analysis revealed that the logging thread spends most of its time string concatenation&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The key takeaway today is that different accumulation methods have vastly different efficiencies. Legacy code used the &lt;code&gt;__INLINE_CODE_0&lt;/code&gt; operator, which frequently creates temporary objects and is very inefficient—the kind of inefficiency you know is bad but don&amp;rsquo;t realize just how bad it is.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;demo-verification&#34;&gt;Demo verification
&lt;/h2&gt;&lt;p&gt;We extracted the business logic based on the project code and created a simple demo to verify the efficiency of string concatenation. We compared the efficiency while compiling and running it in &lt;code&gt;windows&lt;/code&gt; 下的 &lt;code&gt;vs2022&lt;/code&gt; 编译器，&lt;strong&gt;INLINE_CODE_2&lt;/strong&gt; 下的 &lt;strong&gt;INLINE_CODE_3&lt;/strong&gt; 编译器，&lt;strong&gt;INLINE_CODE_4&lt;/strong&gt; mode.&lt;/p&gt;
&lt;h3 id=&#34;key-points&#34;&gt;Key points
&lt;/h3&gt;&lt;p&gt;The project uses method four. Before receiving the test data, readers can first consider which approach is most efficient and which is least efficient. I was still surprised by the results.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Concatenate each field directly into a string&lt;/li&gt;
&lt;li&gt;Using streams (concatenating) to join each field is more efficient, especially when dealing with large amounts of data&lt;/li&gt;
&lt;li&gt;Pre-allocating sufficient memory for strings reduces the overhead of memory reallocation, thereby improving performance&lt;/li&gt;
&lt;li&gt;Creating a new temporary string object for each concatenation degrades performance, especially during large-scale concatenations, as it involves repeated memory allocation and copying&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Based on the results, the project selected the least efficient method&lt;/p&gt;
&lt;p&gt;Furthermore, let&amp;rsquo;s analyze the optimization efficiency of different platforms&amp;rsquo; compilers. Microsoft&amp;rsquo;s compiler falls short in this regard.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Running the code on different machines makes direct comparison of the data meaningless; instead, compare the differences between different concatenation methods&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;windows 平台下的 vs2022 编译器

----------------------------------------
Data Generation Time: 0.054 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.053 seconds.
+ ostringstream Data merging took: 0.054 seconds.
+ Pre-reserved Data merging took: 0.045 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 16.108 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;linux 平台下的 gcc8.5 编译器
----------------------------------------
Data Generation Time: 0.108 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.100 seconds.
+ ostringstream Data merging took: 0.083 seconds.
+ Pre-reserved Data merging took: 0.057 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 29.298 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code&#34;&gt;Complete code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;random&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;sstream&amp;gt;
#include &amp;lt;iomanip&amp;gt;

typedef std::vector&amp;lt;std::string&amp;gt; DataRow;
typedef std::vector&amp;lt;DataRow&amp;gt; DataGroup;

struct ResponsePackage
{
    std::string ErrorInfo;
    DataRow Head;
    std::string ClientId;
    std::string UUID;
    std::string MsgID;
    std::string SessionID;
    std::string ExtraInfo1;
    std::string ExtraInfo2;
    DataGroup DataBody;
};

// Generate specified length of random string
std::string generateRandomString(size_t length)
{
    const char charset[] = &amp;quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&amp;quot;;
    const size_t max_index = sizeof(charset) - 1;
    std::string random_string;
    random_string.reserve(length);

    std::random_device rd;
    std::mt19937 generator(rd());
    std::uniform_int_distribution&amp;lt;&amp;gt; distribution(0, max_index);

    for (size_t i = 0; i &amp;lt; length; ++i)
    {
        random_string += charset[distribution(generator)];
    }

    return random_string;
}

void create_large_string()
{
    // Example request package with 50 fields
    ResponsePackage requestPackage;

    requestPackage.Head = {
        &amp;quot;Field1&amp;quot;, &amp;quot;Field2&amp;quot;, &amp;quot;Field3&amp;quot;, &amp;quot;Field4&amp;quot;, &amp;quot;Field5&amp;quot;,
        &amp;quot;Field6&amp;quot;, &amp;quot;Field7&amp;quot;, &amp;quot;Field8&amp;quot;, &amp;quot;Field9&amp;quot;, &amp;quot;Field10&amp;quot;,
        &amp;quot;Field11&amp;quot;, &amp;quot;Field12&amp;quot;, &amp;quot;Field13&amp;quot;, &amp;quot;Field14&amp;quot;, &amp;quot;Field15&amp;quot;,
        &amp;quot;Field16&amp;quot;, &amp;quot;Field17&amp;quot;, &amp;quot;Field18&amp;quot;, &amp;quot;Field19&amp;quot;, &amp;quot;Field20&amp;quot;,
        &amp;quot;Field21&amp;quot;, &amp;quot;Field22&amp;quot;, &amp;quot;Field23&amp;quot;, &amp;quot;Field24&amp;quot;, &amp;quot;Field25&amp;quot;,
        &amp;quot;Field26&amp;quot;, &amp;quot;Field27&amp;quot;, &amp;quot;Field28&amp;quot;, &amp;quot;Field29&amp;quot;, &amp;quot;Field30&amp;quot;,
        &amp;quot;Field31&amp;quot;, &amp;quot;Field32&amp;quot;, &amp;quot;Field33&amp;quot;, &amp;quot;Field34&amp;quot;, &amp;quot;Field35&amp;quot;,
        &amp;quot;Field36&amp;quot;, &amp;quot;Field37&amp;quot;, &amp;quot;Field38&amp;quot;, &amp;quot;Field39&amp;quot;, &amp;quot;Field40&amp;quot;,
        &amp;quot;Field41&amp;quot;, &amp;quot;Field42&amp;quot;, &amp;quot;Field43&amp;quot;, &amp;quot;Field44&amp;quot;, &amp;quot;Field45&amp;quot;,
        &amp;quot;Field46&amp;quot;, &amp;quot;Field47&amp;quot;, &amp;quot;Field48&amp;quot;, &amp;quot;Field49&amp;quot;, &amp;quot;Field50&amp;quot;
    };

    requestPackage.ClientId = &amp;quot;ClientID&amp;quot;;
    requestPackage.UUID = &amp;quot;UUID&amp;quot;;
    requestPackage.MsgID = &amp;quot;MsgID&amp;quot;;
    requestPackage.SessionID = &amp;quot;SessionID&amp;quot;;
    requestPackage.ExtraInfo1 = &amp;quot;ExtraInfo1&amp;quot;;
    requestPackage.ExtraInfo2 = &amp;quot;ExtraInfo2&amp;quot;;

    // Start timing for data generation
    auto start_gen = std::chrono::high_resolution_clock::now();

    // Generate 10,000 rows of data, each with 50 fields
    for (size_t i = 0; i &amp;lt; 10000; ++i)
    {
        DataRow dataRow(50, &amp;quot;This is a test string&amp;quot;);
        requestPackage.DataBody.push_back(dataRow);
    }

    // End timing for data generation
    auto end_gen = std::chrono::high_resolution_clock::now();
    std::chrono::duration&amp;lt;double&amp;gt; duration_gen = end_gen - start_gen;

    // Display result generation time
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Generation Time: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_gen.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    // Data merging using different methods
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Performance:\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    {
        // Method 1: Using &#39;+=&#39; string concatenation
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys(&amp;quot;&amp;quot;);
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (+=) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 2: Using ostringstream
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::ostringstream bodys;
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::ostringstream body;
            body &amp;lt;&amp;lt; &amp;quot;This is a test string&amp;quot;;
            for (auto&amp;amp; item : vec)
            {
                body &amp;lt;&amp;lt; item &amp;lt;&amp;lt; &amp;quot; &amp;quot;;
            }
            bodys &amp;lt;&amp;lt; body.str() &amp;lt;&amp;lt; &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ ostringstream Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 3: Pre-allocated memory
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys;
        bodys.reserve(1000 * 50 * 20); // Pre-allocate enough memory
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            body.reserve(50 * 20); // Pre-allocate memory for each row
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Pre-reserved Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 4: Using &#39;bodys = bodys + body + &amp;quot;\n&amp;quot;&#39;
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys(&amp;quot;&amp;quot;);
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            for (auto&amp;amp; item : vec)
            {
                body = body + item + &amp;quot; &amp;quot;; // Note the use of &#39;body = body + item&#39;
            }
            bodys = bodys + body + &amp;quot;\n&amp;quot;; // Again, using &#39;bodys = bodys + body&#39;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (bodys = bodys + body + \&amp;quot;\\n\&amp;quot;) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Complete.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;
}

int main()
{
    try
    {
        create_large_string();
    }
    catch (const std::exception&amp;amp; e)
    {
        std::cerr &amp;lt;&amp;lt; &amp;quot;Caught exception: &amp;quot; &amp;lt;&amp;lt; e.what() &amp;lt;&amp;lt; std::endl;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\nProgram finished.\n&amp;quot;;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Lambda expression parameter lifetime in C&#43;&#43;</title>
        <link>https://ttf248.life/en/p/cpp-lambda-parameter-lifetime/</link>
        <pubDate>Wed, 13 Nov 2024 19:23:02 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-lambda-parameter-lifetime/</guid>
        <description>&lt;p&gt;In C++, lambda expressions are convenient anonymous functions that can capture external variables and use them internally. This makes lambdas a flexible programming tool. However, the lifecycle of lambda expression parameters is an aspect requiring special attention, particularly when capturing and passing arguments.&lt;/p&gt;
&lt;h3 id=&#34;lambda-expression-parameter-lifecycle&#34;&gt;Lambda expression parameter lifecycle
&lt;/h3&gt;&lt;p&gt;The lifetime of lambda expression parameters generally mirrors that of other C++ functions. Parameters exist during the function call and end when the call completes. However, due to potential capture of external variables, parameter lifetimes can also be affected by the capturing method.&lt;/p&gt;
&lt;h3 id=&#34;the-relationship-between-capture-and-parameter-lifecycle&#34;&gt;The relationship between capture and parameter lifecycle
&lt;/h3&gt;&lt;h4 id=&#34;capturing-external-variables&#34;&gt;Capturing External Variables
&lt;/h4&gt;&lt;p&gt;C++ lambda expressions allow capturing external variables in two ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;By value capture, the values of external variables are copied into the lambda, and the lifecycle of these copies is controlled by the lambda&amp;rsquo;s lifecycle&lt;/li&gt;
&lt;li&gt;Through capturing references, external variable references are preserved; lambda&amp;rsquo;s references point to the original external variables, and their lifecycle depends on the external variables&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int x = 10;
auto lambda_by_value = [x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };  // 捕获x的副本
auto lambda_by_reference = [&amp;amp;x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };  // 捕获x的引用

lambda_by_value();  // 打印10
lambda_by_reference();  // 打印10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The lifecycle of captured variables is as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When a variable is captured, its value is copied into the lambda; when the lambda&amp;rsquo;s lifecycle ends, this copy is destroyed&lt;/li&gt;
&lt;li&gt;Lambda functions hold references to external variables&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;lambda-parameters&#34;&gt;Lambda Parameters
&lt;/h4&gt;&lt;p&gt;Lambda parameters are similar to regular function parameters, with a lifecycle limited to the lambda function body. They are created upon lambda invocation and terminate when the invocation is complete.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;auto lambda = [](int a, int b) {
    std::cout &amp;lt;&amp;lt; a + b &amp;lt;&amp;lt; std::endl;
};
lambda(5, 10);  // a和b在这里是lambda的参数
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, &lt;code&gt;a&lt;/code&gt;BOLD_2&lt;code&gt;b&lt;/code&gt; are the parameters of the lambda expression; they are created when the lambda is called and destroyed after it finishes executing&lt;/p&gt;
&lt;h3 id=&#34;lifecycle-issues-when-capturing-external-variables&#34;&gt;Lifecycle issues when capturing external variables
&lt;/h3&gt;&lt;h4 id=&#34;whether-captured-variables-are-valid-outside-of-the-lambda&#34;&gt;Whether captured variables are valid outside of the lambda
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Even if external variables are destroyed after a lambda call, the lambda internally still holds a copy of those variables. Therefore, the internal copy can be used safely, even if the external variables no longer exist.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int x = 10;
auto lambda = [x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };
x = 20;  // x 在lambda调用后修改
lambda();  // 打印10，捕获的是x的副本
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;If a lambda captures a reference to an external variable, access to that reference within the lambda depends on the lifetime of the external variable. If the external variable is destroyed before the lambda executes, it can lead to a dangling reference and undefined behavior.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int x = 10;
auto lambda = [&amp;amp;x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };
x = 20;  // x 在lambda调用前修改
lambda();  // 打印20，捕获的是x的引用
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;It&amp;rsquo;s crucial to ensure that captured external variables remain valid when the lambda is executed if the order of execution for lambdas is uncertain&lt;/p&gt;
&lt;/blockquote&gt;</description>
        </item>
        <item>
        <title>Upgrading GCC version leads to program crashes: Hidden dangers of non-compliant code</title>
        <link>https://ttf248.life/en/p/upgrade-gcc-version-causes-program-crash-code-irregularities/</link>
        <pubDate>Sun, 10 Mar 2024 23:19:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/upgrade-gcc-version-causes-program-crash-code-irregularities/</guid>
        <description>&lt;p&gt;The program compiled and ran normally in the CentOS 7 environment, but crashed when switched to CentOS 8 and compiled with a newer version of GCC. Notably, this issue only occurred under &lt;strong&gt;Release 模式&lt;/strong&gt;, while &lt;strong&gt;Debug 模式&lt;/strong&gt; was unaffected. This was the first time we encountered such a situation, and after three days of troubleshooting, we finally found the root cause.&lt;/p&gt;
&lt;h3 id=&#34;issue-identification&#34;&gt;Issue identification
&lt;/h3&gt;&lt;p&gt;The root cause of the problem lies in &lt;strong&gt;函数缺少返回值&lt;/strong&gt;. The increased optimization performed by newer versions of GCC in Release mode has introduced unknown logic into functions without explicit return values, leading to crashes. Our conclusion is that &lt;strong&gt;编译器的警告不容忽视，尤其是在老项目中，部分警告可能被无视，但也应当避免屏蔽所有警告&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;environmental-description&#34;&gt;Environmental Description
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39)
Copyright © 2015 Free Software Foundation, Inc.
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-21)
Copyright (C) 2018 Free Software Foundation, Inc.
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;crash-phenomenon&#34;&gt;Crash phenomenon
&lt;/h3&gt;&lt;p&gt;When analyzing the program crash stack, we observed the following stack information:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[New LWP 1385902]
[Thread debugging using libthread_db enabled]
Using host libthread_db library &amp;quot;/lib64/libthread_db.so.1&amp;quot;.
Core was generated by `./pstack_main`.
Program terminated with signal SIGSEGV, Segmentation fault.
#0  0x00007ffe894b4420 in ?? ()
(gdb) bt
#0  0x00007ffe894b4420 in ?? ()
#1  0x00000000004008e9 in main ()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This stack trace isn&amp;rsquo;t intuitive; the crash information shows as a &lt;code&gt;__INLINE_CODE_0&lt;/code&gt;, making debugging more difficult&lt;/p&gt;
&lt;h3 id=&#34;code-example&#34;&gt;Code example
&lt;/h3&gt;&lt;p&gt;To better understand the issue, here&amp;rsquo;s a minimal code example to reproduce the crash:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;map&amp;gt;

int test() {
    std::cout &amp;lt;&amp;lt; &amp;quot;1&amp;quot; &amp;lt;&amp;lt; std::endl;
}

int main() {
    test();
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When a ``test()&lt;code&gt; 函数显然没有显式返回一个值，而它的返回类型是 __INLINE_CODE_1__。根据 C++ 规范，当一个函数声明为 __INLINE_CODE_2__&lt;/code&gt; type is used, it must have a return value; otherwise, undefined behavior may occur&lt;/p&gt;
&lt;h3 id=&#34;compilation-warning&#34;&gt;Compilation warning
&lt;/h3&gt;&lt;p&gt;In our project, CMake scripts suppress many compile-time warnings, including the following message:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;/root/pstack/main.cpp: In function ‘int test()’:
/root/pstack/main.cpp:7:1: warning: no return statement in function returning non-void [-Wreturn-type]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This warning indicates that the &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; function has no return value, which is the root of the problem. High-version GCC (such as 8.5.0) may perform unstable optimizations on this undefined behavior during code optimization, leading to program crashes.&lt;/p&gt;
&lt;h3 id=&#34;assembly-code-differences&#34;&gt;Assembly code differences
&lt;/h3&gt;&lt;p&gt;To explain the differences in GCC compiler optimization behavior, we compared assembly code generated by different versions of GCC&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The assembly code is lengthy and includes excessive optimizations for issues like the missing return value in functions such as __INLINE_CODE_0__BOLD_2&lt;code&gt;test()&lt;/code&gt;, which may have prevented a crash&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The new version of GCC includes more optimizations that reduce code size. However, these optimizations can lead to undefined behavior when executing functions lacking return values, potentially causing program crashes.&lt;/p&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h3&gt;&lt;p&gt;This troubleshooting has highlighted the importance of carefully addressing warnings in C++, particularly when functions are declared inline. It&amp;rsquo;s crucial to selectively handle these warnings, especially those related to function return values and type matching, rather than suppressing them all.&lt;/p&gt;
&lt;p&gt;The issue was resolved by adding a return value to the &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; function, and the program returned to normal operation&lt;/p&gt;</description>
        </item>
        <item>
        <title>Traps in C&#43;&#43; Programming: Detailed Explanation of Program Crashes Due to Misusing `std::map`</title>
        <link>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</link>
        <pubDate>Sun, 10 Mar 2024 22:03:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</guid>
        <description>&lt;p&gt;This article aims to reveal how improper use of C++ containers can lead to program crashes. Attempting to access a non-existent key using the bracket operator automatically adds an empty element. We will analyze this misunderstanding and demonstrate its potential risks with example code.&lt;/p&gt;
&lt;p&gt;Storing simple values is fine, but problems arise when storing pointers. Since a pointer is an address, if it&amp;rsquo;s not initialized, the address is undefined, which can lead to program crashes.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;In the C++ standard library, &lt;code&gt;_ITERATOR_categories&lt;/code&gt; inserts a new key-value pair, and the default constructor will be used to initialize the value type corresponding to that key&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;map&amp;gt;

int main() {
    std::map&amp;lt;std::string, int&amp;gt; myMap;
    
    // 错误的用法：假设这里试图访问一个不存在的键并认为会得到0
    std::cout &amp;lt;&amp;lt; &amp;quot;Value for &#39;nonexistent_key&#39;: &amp;quot; &amp;lt;&amp;lt; myMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;

    // 实际上，上述行代码创建了一个新的键值对，其中值被默认初始化为int的默认值（通常是0）
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;While this code doesn&amp;rsquo;t directly cause the program to crash, such implicit insertion behavior can potentially lead to unexpected side effects in certain situations, like resource leaks or state changes that don&amp;rsquo;t meet expectations. Worse still, concurrent access to uninitialized memory regions in a multithreaded environment could even trigger a program crash.&lt;/p&gt;
&lt;p&gt;To prevent such issues, it is recommended to explicitly insert elements using ____&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;std::map&amp;lt;std::string, int&amp;gt; safeMap;
if (safeMap.count(&amp;quot;nonexistent_key&amp;quot;) == 0) {
    std::cout &amp;lt;&amp;lt; &amp;quot;Key does not exist.&amp;quot; &amp;lt;&amp;lt; std::endl;
} else {
    std::cout &amp;lt;&amp;lt; &amp;quot;Value for existing key: &amp;quot; &amp;lt;&amp;lt; safeMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;
}

// 或者明确插入一个键值对，指定初始值
safeMap.insert({ &amp;quot;new_key&amp;quot;, 0 });
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the objects stored in a &lt;code&gt;map&lt;/code&gt; container are of pointer type, the automatic insertion behavior will save an uninitialized pointer, and any operation on this pointer will lead to program crashes&lt;/p&gt;</description>
        </item>
        <item>
        <title>C&#43;&#43; function call time cost</title>
        <link>https://ttf248.life/en/p/cpp-function-call-timing/</link>
        <pubDate>Wed, 24 Jan 2024 14:11:33 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-function-call-timing/</guid>
        <description>&lt;p&gt;We conducted a time-consuming test of the design quote SDK, implementing different callback function approaches. Recently I&amp;rsquo;ve been looking at C++ functional programming – what performance differences arise when functions become first-class citizens and circulate within a program?&lt;/p&gt;
&lt;p&gt;Previous article link:&lt;/p&gt;
&lt;p&gt;The expert also did similar testing and borrowed the code&lt;/p&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;The execution platform remains our old friend, [link placeholder]&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;cassert&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;functional&amp;gt;
#include &amp;lt;iostream&amp;gt;
#include &amp;lt;vector&amp;gt;

int add_one(int input) { return input + 1; }

bool validate_vector_add_one(std::vector&amp;lt;int&amp;gt; const&amp;amp; input_vector,
                             std::vector&amp;lt;int&amp;gt; const&amp;amp; output_vector)
{
    bool is_valid{true};
    for (size_t i{0}; i &amp;lt; input_vector.size(); ++i)
    {
        if (output_vector.at(i) != input_vector.at(i) + 1)
        {
            is_valid = false;
            break;
        }
    }
    return is_valid;
}

void reset_vector(std::vector&amp;lt;int&amp;gt;&amp;amp; input_vector)
{
    for (size_t i{0}; i &amp;lt; input_vector.size(); ++i)
    {
        input_vector.at(i) = 0;
    }
}

template &amp;lt;typename T, typename Func&amp;gt;
void unitary_function_pass_by_lambda_function(T&amp;amp; output, T const&amp;amp; input,
                                              Func const func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_std_function_value(T&amp;amp; output, T const&amp;amp; input,
                                                 std::function&amp;lt;T(T)&amp;gt; const func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_std_function_reference(
    T&amp;amp; output, T const&amp;amp; input, std::function&amp;lt;T(T)&amp;gt; const&amp;amp; func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_function_pointer(T&amp;amp; output, T const&amp;amp; input,
                                               T (*func)(T))
{
    output = func(input);
}

int main()
{
    // Set floating point format std::cout with 3 decimal places.
    std::cout.precision(3);

    size_t const num_elements{10000000};
    std::vector&amp;lt;int&amp;gt; input_vector(num_elements, 0);
    std::vector&amp;lt;int&amp;gt; output_vector(num_elements, 0);

    auto const lambda_function_add_one{[](int const&amp;amp; input) -&amp;gt; int
                                       { return input + 1; }};
    std::function&amp;lt;int(int)&amp;gt; const std_function_add_one{lambda_function_add_one};

    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a function pointer: &amp;quot; &amp;lt;&amp;lt; sizeof(&amp;amp;add_one)
              &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a std::function pointer: &amp;quot;
              &amp;lt;&amp;lt; sizeof(&amp;amp;std_function_add_one) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a std::function: &amp;quot; &amp;lt;&amp;lt; sizeof(std_function_add_one)
              &amp;lt;&amp;lt; std::endl;

    // Call function frequently in a vanilla way.
    // The compiler knows what function to call at compile time and can optimize
    // the code.
    // This is the best performance we could get.
    std::chrono::steady_clock::time_point const time_start_vanilla{
        std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        output_vector.at(i) = add_one(input_vector.at(i));
    }
    std::chrono::steady_clock::time_point const time_end_vanilla{
        std::chrono::steady_clock::now()};
    auto const time_elapsed_vanilla{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(time_end_vanilla -
                                                             time_start_vanilla)
            .count()};
    float const latency_vanilla{time_elapsed_vanilla /
                                static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass Vanilla: &amp;quot; &amp;lt;&amp;lt; latency_vanilla &amp;lt;&amp;lt; &amp;quot; ns&amp;quot;
              &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // Sometimes, we don&#39;t know what function to call at compile time.
    // We can use std::function to pass a function as an argument.
    // In this case, we pass the std::function by value.
    // Because the size of a std::function is 32 bytes, passing by value
    // results in a lot of copying and bad performance.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_std_function_value{std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_std_function_value(
            output_vector.at(i), input_vector.at(i), std_function_add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_std_function_value{std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_std_function_value{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_std_function_value -
            time_start_pass_by_std_function_value)
            .count()};
    float const latency_pass_by_std_function_value{
        time_elapsed_pass_by_std_function_value /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Std Function Value: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_std_function_value &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // Instead of passing the std::function by value, we can pass it by
    // reference (pointer). In this case, object copying is eliminated. The
    // performance is better than passing the std::function by value. However,
    // the performance is still not as good as the vanilla way.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_std_function_reference{
            std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_std_function_reference(
            output_vector.at(i), input_vector.at(i), std_function_add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_std_function_reference{
            std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_std_function_reference{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_std_function_reference -
            time_start_pass_by_std_function_reference)
            .count()};
    float const latency_pass_by_std_function_reference{
        time_elapsed_pass_by_std_function_reference /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Std Function Reference: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_std_function_reference &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // std::function is a general purpose wrapper for function pointers,
    // callable objects, and lambda functions. Because it&#39;s general purpose,
    // it&#39;s not as efficient as a function pointer. In this case, we pass a
    // function pointer to a function. The performance is better than passing
    // the std::function by reference.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_function_pointer{std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_function_pointer(output_vector.at(i),
                                                  input_vector.at(i), &amp;amp;add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_function_pointer{std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_function_pointer{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_function_pointer -
            time_start_pass_by_function_pointer)
            .count()};
    float const latency_pass_by_function_pointer{
        time_elapsed_pass_by_function_pointer /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Function Pointer: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_function_pointer &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // We can also pass a lambda function to a function.
    // The compiler knows what function to call at compile time and can optimize
    // the code. The performance is also better than passing the std::function
    // by reference.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_lambda_function{std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_lambda_function(
            output_vector.at(i), input_vector.at(i), lambda_function_add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_lambda_function{std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_lambda_function{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_lambda_function -
            time_start_pass_by_lambda_function)
            .count()};
    float const latency_pass_by_lambda_function{
        time_elapsed_pass_by_lambda_function /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Lambda Function: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_lambda_function &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 组里常规也就开启 O2 优化，编译选用了 gcc13，不同版本的 gcc 性能耗时略有不同，版本越高 lambda 效果越好
The size of a function pointer: 8
The size of a std::function pointer: 8
The size of a std::function: 32
Latency Pass Vanilla: 0.418 ns
Latency Pass By Std Function Value: 3.47 ns
Latency Pass By Std Function Reference: 1.36 ns
Latency Pass By Function Pointer: 0.396 ns
Latency Pass By Lambda Function: 0.44 ns
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leimao.github.io/blog/CPP-Function-Call-Performance/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://leimao.github.io/blog/CPP-Function-Call-Performance/&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>C11: sleep for vs yield</title>
        <link>https://ttf248.life/en/p/c11-sleep-for-vs-yield/</link>
        <pubDate>Tue, 20 Sep 2022 20:54:51 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/c11-sleep-for-vs-yield/</guid>
        <description>&lt;p&gt;It was the first time I saw this, and I hadn&amp;rsquo;t noticed it before&lt;/p&gt;
&lt;p&gt;Without checking the manual, my first thought was whether it&amp;rsquo;s related to asynchronicity. The term __INLINE_CODE_0__appears in the Boost library&amp;rsquo;s coroutine implementation, but it certainly isn&amp;rsquo;t related to coroutines here; the control logic is likely related to ordinary threads.&lt;/p&gt;
&lt;h2 id=&#34;document&#34;&gt;Document
&lt;/h2&gt;&lt;h3 id=&#34;yield&#34;&gt;yield
&lt;/h3&gt;&lt;p&gt;The accuracy of this function depends on the implementation, particularly the OS scheduler mechanism and system state. For example, a first-in, first-out real-time scheduler (such as Linux&amp;rsquo;s SCHED_FIFO) will suspend the current thread and place it at the tail of the queue of threads with the same priority (and yield has no effect if there are no other threads at that priority).&lt;/p&gt;
&lt;h3 id=&#34;sleep_for&#34;&gt;sleep_for
&lt;/h3&gt;&lt;p&gt;Blocks the current thread&amp;rsquo;s execution for at least the specified sleep_duration
This function may block for longer than sleep_duration due to scheduling or resource contention
The standard library recommends measuring duration using a stable clock. If implemented with system time, wait times may also be sensitive to clock adjustments.&lt;/p&gt;
&lt;h3 id=&#34;analysis&#34;&gt;Analysis
&lt;/h3&gt;&lt;p&gt;Both functions release the current thread, and their effects depend on the platform. Still a bit unclear here; let&amp;rsquo;s run the code to see the execution results.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ThinkPad laptop (Visual Studio Community 2022), Tencent Cloud S2 standard server (gcc8.5)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Runtime Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First/μs&lt;/th&gt;
&lt;th&gt;Second/μs&lt;/th&gt;
&lt;th&gt;Third/μs&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Windows&lt;/td&gt;
&lt;td&gt;sleep_for&lt;/td&gt;
&lt;td&gt;9872&lt;/td&gt;
&lt;td&gt;1884&lt;/td&gt;
&lt;td&gt;11302&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Windows&lt;/td&gt;
&lt;td&gt;yield&lt;/td&gt;
&lt;td&gt;119&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Linux&lt;/td&gt;
&lt;td&gt;sleep_for&lt;/td&gt;
&lt;td&gt;171&lt;/td&gt;
&lt;td&gt;168&lt;/td&gt;
&lt;td&gt;167&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Linux&lt;/td&gt;
&lt;td&gt;yield&lt;/td&gt;
&lt;td&gt;101&lt;/td&gt;
&lt;td&gt;102&lt;/td&gt;
&lt;td&gt;101&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Given the operating system implementation, &lt;strong&gt;INLINE_CODE_0__稳定性差异巨大，如果想要高精度的休眠，使用__INLINE_CODE_1&lt;/strong&gt; is more suitable for high-precision sleep&lt;/p&gt;
&lt;p&gt;The difference is not significant when time accuracy is improved to &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;thread&amp;gt;
 
// 建议其他线程运行一小段时间的“忙睡眠”
void little_sleep(std::chrono::microseconds us)
{
    auto start = std::chrono::high_resolution_clock::now();
    auto end = start + us;
    do {
        std::this_thread::yield();
    } while (std::chrono::high_resolution_clock::now() &amp;lt; end);
}
 
int main()
{
    auto start = std::chrono::high_resolution_clock::now();
 
    little_sleep(std::chrono::microseconds(100));
    std::this_thread::sleep_for(std::chrono::microseconds(100));
 
    auto elapsed = std::chrono::high_resolution_clock::now() - start;
    std::cout &amp;lt;&amp;lt; &amp;quot;waited for &amp;quot;
              &amp;lt;&amp;lt; std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(elapsed).count()
              &amp;lt;&amp;lt; &amp;quot; microseconds\n&amp;quot;;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Why learn a new language?</title>
        <link>https://ttf248.life/en/p/why-learn-a-new-language/</link>
        <pubDate>Thu, 04 Aug 2022 11:27:30 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/why-learn-a-new-language/</guid>
        <description>&lt;p&gt;Why learn other programming languages after more than ten years of experience with [this/it]?&lt;/p&gt;
&lt;p&gt;Lack of experience in elegant module design, grammar is flexible, and learning other languages can guide the creation of more elegant designs&lt;/p&gt;
&lt;p&gt;I often find myself using these tools when writing code&lt;/p&gt;
&lt;p&gt;Whether it&amp;rsquo;s the underlying library design or the business module implementation, the design principles are consistent&lt;/p&gt;</description>
        </item>
        <item>
        <title>Allocator for standard library containers</title>
        <link>https://ttf248.life/en/p/standard-library-container-memory-allocator/</link>
        <pubDate>Mon, 30 Dec 2019 13:26:19 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/standard-library-container-memory-allocator/</guid>
        <description>&lt;p&gt;Custom allocators can improve performance, enhance memory efficiency, and address issues with frequent small memory allocations&lt;/p&gt;
&lt;h4 id=&#34;cause&#34;&gt;Cause
&lt;/h4&gt;&lt;p&gt;Recently, I&amp;rsquo;ve been working on network packet development, which requires frequent allocation and release of small memory blocks. I initially considered using a memory pool but examined existing implementations and found this&amp;hellip;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/cacay/MemoryPool&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/cacay/MemoryPool&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Seeing the interface, I was quite puzzled by this memory pool&amp;rsquo;s implementation—the concept of &lt;code&gt;MemoryPool&lt;/code&gt;的实现逻辑，是在申请固定大小的内存空间。看过boost的内存池接口，提供的是一个模板，用的时候进行实例化。正巧这个库已经有文章进行过介绍，提到了__INLINE_CODE_1&lt;/p&gt;
&lt;h4 id=&#34;wikihttpszhwikipediaorgwikie58886e9858de599a8_c2b2b&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;wiki&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;In C++ programming, an allocator is a crucial component of the C++ standard library. Containers (such as linked lists and sets) are data structures defined in the C++ library that share a common characteristic: their size can change at runtime. Dynamic memory allocation is essential to achieve this, and allocators handle memory allocation and deallocation requests for containers. In other words, an allocator encapsulates the low-level details of memory management for Standard Template Library (STL) containers. By default, the C++ standard library uses its own generic allocator, but programmers can also customize their own allocators as needed.&lt;/p&gt;
&lt;p&gt;The allocator was originally invented by Alexander Stepanov as part of the C++ Standard Template Library (STL) with the goal of creating a way to make the library more flexible and independent of the underlying data model, allowing programmers to utilize custom pointer and reference types within the library. However, when incorporating the STL into the C++ standard, the C++ standards committee realized that complete abstraction of the data model would result in unacceptable performance losses. As a compromise, restrictions on allocators were tightened in the standard. Consequently, the current standard describes allocators with significantly less customization than Stepanov originally envisioned.&lt;/p&gt;
&lt;p&gt;While customization of allocators is limited, custom allocators are often necessary to manage access to different memory spaces (such as shared and recycled memory) or to improve performance when using memory pools. Furthermore, in programs with frequent small allocations, introducing a specialized allocator can yield significant benefits in terms of memory footprint and runtime.&lt;/p&gt;
&lt;h4 id=&#34;please-provide-the-chinese-text-you-want-me-to-translate-i-am-ready-when-you-are-just-paste-the-text-after-使用需求httpszhwikipediaorgwikie58886e9858de599a8_c2b2b&#34;&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text after &amp;ldquo;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;使用需求&lt;/a&gt;.
&lt;/h4&gt;&lt;p&gt;One primary reason for defining custom allocators is to improve performance. Utilizing a dedicated custom allocator can enhance program performance, increase memory efficiency, or both [4][8]. The default allocator uses the &lt;code&gt;new&lt;/code&gt; operator to allocate storage space [Reference 5], often implemented using C&amp;rsquo;s heap allocation functions (malloc()) [9]. While the default allocator generally performs well when allocating memory for containers requiring large, infrequent allocations (e.g., vectors, double-ended queues) [8], it can be inefficient when used with containers that require frequent small allocations (e.g., associative containers and doubly linked lists) [4][9]. Furthermore, malloc()-based default allocators suffer from issues such as poor locality of reference [4] and potential memory fragmentation [4][9].&lt;/p&gt;
&lt;p&gt;In short, this section is like a &amp;ldquo;I Have a Dream&amp;rdquo; speech for the standard&amp;rsquo;s approach to allocators. Before that dream comes true, programmers concerned with portability will limit themselves to stateless custom allocators.
Scott Meyers, &lt;em&gt;Effective STL&lt;/em&gt;
Given this situation, memory pool allocators are often used to address frequent small allocations [8]. Unlike the default &amp;ldquo;on-demand&amp;rdquo; allocation approach, with a memory pool allocator, the program pre-allocates a large block of memory (the “memory pool”), and the custom allocator simply returns a pointer to memory within the pool when an allocation is requested; no actual deallocation is performed during object destruction but is deferred until the end of the memory pool&amp;rsquo;s lifecycle [Note 1] [8].&lt;/p&gt;
&lt;p&gt;The topic of &amp;ldquo;custom allocators&amp;rdquo; has been extensively discussed by C++ experts and authors, such as Scott Meyers&amp;rsquo; &amp;ldquo;Effective STL&amp;rdquo; and Andrei Alexandrescu&amp;rsquo;s &amp;ldquo;Modern C++ Design.&amp;rdquo; Meyers observed that if all instances of an allocator for a given type T must be equal, then portable allocator instances must not contain state. While the C++ standard encourages library implementers to support allocators with state [reference 4], Meyers calls this related passage a “seemingly wonderful idea” but almost empty rhetoric, and considers the restriction on allocators &amp;ldquo;too strict&amp;rdquo; [4]. For example, STL&amp;rsquo;s list allows the splice method, where nodes of one list object A can be directly moved into another list object B, requiring that the memory allocated by A’s allocator can be released by B’s allocator, thus inferring that the allocator instances of A and B must be equal. Meyers concludes that allocators are best defined as types using static methods. For example, according to the C++ standard, an allocator must provide an other class template that implements the rebind method.&lt;/p&gt;
&lt;p&gt;Additionally, in &amp;ldquo;The C++ Programming Language,&amp;rdquo; Bjarne Stroustrup argues that “strictly limiting the allocator to avoid object information differences” is not a significant issue (in essence), and notes that many allocators do not require state; performance can even be better without it. He proposes three use cases for custom allocators: memory pool allocators, shared-memory allocators, and garbage collection allocators, and demonstrates an implementation utilizing an internal memory pool for rapid allocation/deallocation of small amounts of memory. However, he also mentions that such optimization may already be achieved in the example allocator he provides [3].&lt;/p&gt;
&lt;p&gt;Another use of custom allocators is debugging memory-related errors [10]. This can be achieved by writing an allocator that allocates extra memory during allocation to store debug information. Such an allocator not only ensures that memory is allocated/deallocated by the same type of allocator, but also helps protect the program from buffer overflows [11].&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>C&#43;&#43; on Uncle Xiang&#39;s Notebook</title>
        <link>https://ttf248.life/en/tags/c-/</link>
        <description>Recent content in C&#43;&#43; on Uncle Xiang&#39;s Notebook</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Wed, 11 Jun 2025 00:28:57 +0800</lastBuildDate><atom:link href="https://ttf248.life/en/tags/c-/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Memory Layout and Binary Compatibility</title>
        <link>https://ttf248.life/en/p/memory-layout-and-binary-compatibility/</link>
        <pubDate>Tue, 10 Jun 2025 18:53:02 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/memory-layout-and-binary-compatibility/</guid>
        <description>&lt;p&gt;C++ service crashed. The service depends on a static library for compilation.
The static library made modifications, adding members to the header file and re-publishing the binary static library file.
The service relies on the new binary library file, compiles and runs normally, but then crashes. The crash point appears fine, similar to the crashes caused by compiler upgrades – undefined behavior, an untrustworthy stack trace.
Updating the service’s dependent header files allows it to mutate correctly, and running also works normally.
A detailed explanation is needed, involving computer science knowledge, I suspect it&amp;rsquo;s related to memory layout, with examples for a thorough explanation.&lt;/p&gt;
&lt;p&gt;This is a typical crash caused by mismatches between static library header files and binary library files. It’s indeed related to memory layout. Here’s a detailed explanation:&lt;/p&gt;
&lt;h2 id=&#34;problem-analysis&#34;&gt;Problem Analysis
&lt;/h2&gt;&lt;p&gt;Static libraries’ header files define the structure of classes (including member variables and methods), while their binary files contain the implementation code. During compilation, the compiler generates code based on the class definitions in the header files, including memory layout and access patterns. If the header file and the static library&amp;rsquo;s binary file are not compatible, it can lead to undefined behavior at runtime.&lt;/p&gt;
&lt;h2 id=&#34;key-concepts&#34;&gt;Key Concepts
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Memory Layout:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In C++, the layout of class member variables in memory is determined by the compiler based on the header file definition.&lt;/li&gt;
&lt;li&gt;If a header file adds member variables, the memory layout of the class will change. For example, adding a new member variable may increase the size ( &lt;code&gt;sizeof&lt;/code&gt; ) of the class or change the offset of the member variables.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Binary Compatibility:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Static library binary files are generated based on the header files. If a service is compiled using older header files and links to a new static library binary at runtime, the service&amp;rsquo;s code will access class member variables according to the old memory layout, while the implementation code of the static library operates on the new memory layout. This inconsistency leads to undefined behavior.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Undefined Behavior:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Undefined behavior may manifest as crashes, incorrect stack traces, or even abnormal program execution results. This is because when the program accesses memory, it may access an incorrect address or an uninitialized region.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;examples&#34;&gt;Examples
&lt;/h2&gt;&lt;p&gt;Let&amp;rsquo;s consider a static library whose header file originally defined the following class:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;class MyClass {
public:
    int a;
    void func();
};
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The binary file of the static library is compiled based on this definition.
Later, the header file was modified to:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;class MyClass {
public:
    int a;
    int b;  // Added member variable
    void func();
};
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A new static library binary file is compiled based on the modified header file.
If the service compiles using the old header file, the following problems may occur:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Inconsistent Memory Layout:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;The service assumes that &lt;code&gt;MyClass&lt;/code&gt;&amp;rsquo;s size is &lt;code&gt;sizeof(int)&lt;/code&gt;, while the static library assumes it’s &lt;code&gt;sizeof(int) * 2&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;When accessing members of the &lt;code&gt;MyClass&lt;/code&gt; object, the service may access an incorrect memory address.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method Call Issues:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;If the implementation code in the static library depends on the new member variable (e.g., &lt;code&gt;b&lt;/code&gt;), and the service&amp;rsquo;s code does not correctly initialize &lt;code&gt;b&lt;/code&gt;, a crash may occur at runtime.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;solutions&#34;&gt;Solutions
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Maintain Consistency Between Header Files and Binary Files:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;During service compilation, ensure you are using header files that match the binary file of the static library.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Avoid Incompatible Modifications to Binaries:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;When modifying class definitions, try to avoid directly adding member variables; instead, use inheritance or other methods.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Recompile All Dependent Components:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;When a static library is modified, recompile all services that depend on it to ensure consistency between the header files and binary files.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary
&lt;/h2&gt;&lt;p&gt;The root cause of this issue is inconsistency between the header file and binary file, leading to errors in memory layout. The C++ compiler generates code based on the header file during compilation, while runtime behavior depends on the binary file. If these two don&amp;rsquo;t match, it results in undefined behavior. Ensuring consistency between the header file and binary file can prevent similar problems.&lt;/p&gt;</description>
        </item>
        <item>
        <title>C&#43;&#43; Bitwise Operations Fundamentals: Bitwise Extraction and Flag Setting</title>
        <link>https://ttf248.life/en/p/cpp-bitwise-operations-flags/</link>
        <pubDate>Fri, 17 Jan 2025 02:23:56 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-bitwise-operations-flags/</guid>
        <description>&lt;p&gt;In actual C++ development, bitwise operations are a common technique, especially when dealing with system states, flags, or control bits. Bitwise operations can provide very efficient solutions. This article will illustrate how to use bitwise operations to retrieve and set specific flags through an example.&lt;/p&gt;
&lt;h3 id=&#34;bitwise-operations-fundamentals&#34;&gt;Bitwise Operations Fundamentals
&lt;/h3&gt;&lt;p&gt;In computers, data is stored in binary bits (0 and 1). Bitwise operations are operations performed on these binary bits. C++ provides several commonly used bitwise operators:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Bitwise AND (&amp;amp;)&lt;/strong&gt;: Used to check if a particular bit is set to 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise OR (|)&lt;/strong&gt;: Used to set a particular bit to 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise XOR (^)&lt;/strong&gt;: Used to flip a particular bit.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise NOT (~)&lt;/strong&gt;: Inverts all the bits.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Left Shift (&amp;laquo;)&lt;/strong&gt;: Shifts all bits to the left by a specified number of positions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Right Shift (&amp;raquo;)&lt;/strong&gt;: Shifts all bits to the right by a specified number of positions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this example, we need to perform a series of bitwise operations on an &lt;code&gt;unsigned short&lt;/code&gt; variable &lt;code&gt;wInfo&lt;/code&gt; to represent different states using various flags.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;flowchart LR
    A[Original Value: 00010000] --&amp;gt; B[Left Shift: 00010000 &amp;lt;&amp;lt; 1]
    B --&amp;gt; C[Result: 00100000]
    C --&amp;gt; D[Right Shift: 00100000 &amp;gt;&amp;gt; 1]
    D --&amp;gt; E[Result: 00010000]

    subgraph Left Shift Operation
        direction LR
        A --&amp;gt; B --&amp;gt; C
    end

    subgraph Right Shift Operation
        direction LR
        C --&amp;gt; D --&amp;gt; E
    end
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;requirement-analysis&#34;&gt;Requirement Analysis
&lt;/h3&gt;&lt;p&gt;Based on the description, we have a 16-bit flag to represent different states. These states are represented by various binary bits, with each binary bit corresponding to a specific meaning. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;bit0&lt;/strong&gt;: Failure status&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bit1&lt;/strong&gt;: Compression status&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bit2&lt;/strong&gt;: Incremental status&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bit3&lt;/strong&gt;: Presence of subsequent packets&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bit5&lt;/strong&gt;: Normal request or cancellation&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;using-bitwise-operations&#34;&gt;Using Bitwise Operations
&lt;/h3&gt;&lt;p&gt;We will use bitwise operations to set and retrieve these flags. Specifically:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Bitwise AND:&lt;/strong&gt; Retrieve the value of a particular bit (0 or 1).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise OR:&lt;/strong&gt; Set a particular bit to 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise XOR:&lt;/strong&gt; Set a particular bit to 0.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We first define an &lt;code&gt;unsigned short&lt;/code&gt; type variable &lt;code&gt;wInfo&lt;/code&gt; to store these flags. Then, we use bitwise operations to check and set the corresponding flags.&lt;/p&gt;
&lt;h3 id=&#34;c-example-code&#34;&gt;C++ Example Code
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;bitset&amp;gt;

// Define flag constants
const unsigned short BIT_0_FAIL = 1 &amp;lt;&amp;lt; 0;    // bit0 failed?
const unsigned short BIT_1_COMPRESSED = 1 &amp;lt;&amp;lt; 1; // bit1 compressed?
const unsigned short BIT_2_INCREMENT = 1 &amp;lt;&amp;lt; 2;  // bit2 incremented?
const unsigned short BIT_3_HAS_MORE = 1 &amp;lt;&amp;lt; 3;   // bit3 has more packets?
const unsigned short BIT_5_CANCEL = 1 &amp;lt;&amp;lt; 5;     // bit5 normal request(0) or cancel(1)

// Check if a bit is set
bool isBitSet(unsigned short wInfo, unsigned short bitMask) {
    return (wInfo &amp;amp; bitMask) != 0;
}

// Set a bit to 1
void setBit(unsigned short&amp;amp; wInfo, unsigned short bitMask) {
    wInfo |= bitMask;
}

// Clear a bit (set it to 0)
void clearBit(unsigned short&amp;amp; wInfo, unsigned short bitMask) {
    wInfo &amp;amp;= ~bitMask;
}

int main() {
    // Assume wInfo&#39;s initial value is 0
    unsigned short wInfo = 0;

    // Set bit0 (failure flag)
    setBit(wInfo, BIT_0_FAIL);
    
    // Set bit1 (compressed flag)
    setBit(wInfo, BIT_1_COMPRESSED);
    
    // Print wInfo&#39;s binary value
    std::cout &amp;lt;&amp;lt; &amp;quot;wInfo (in binary): &amp;quot; &amp;lt;&amp;lt; std::bitset&amp;lt;16&amp;gt;(wInfo) &amp;lt;&amp;lt; std::endl;

    // Check each flag
    std::cout &amp;lt;&amp;lt; &amp;quot;bit0 (failed?): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_0_FAIL) ? &amp;quot;yes&amp;quot; : &amp;quot;no&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit1 (compressed?): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_1_COMPRESSED) ? &amp;quot;yes&amp;quot; : &amp;quot;no&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit2 (incremented?): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_2_INCREMENT) ? &amp;quot;yes&amp;quot; : &amp;quot;no&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit3 (has more packets?): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_3_HAS_MORE) ? &amp;quot;yes&amp;quot; : &amp;quot;no&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit5 (canceled?): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_5_CANCEL) ? &amp;quot;yes&amp;quot; : &amp;quot;no&amp;quot;) &amp;lt;&amp;lt; std::endl;

    // Clear bit1 (compressed flag)
    clearBit(wInfo, BIT_1_COMPRESSED);
    
    // Print the updated wInfo
    std::cout &amp;lt;&amp;lt; &amp;quot;Updated wInfo (in binary): &amp;quot; &amp;lt;&amp;lt; std::bitset&amp;lt;16&amp;gt;(wInfo) &amp;lt;&amp;lt; std::endl;

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Run the code, recommended for old friends: &lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;wInfo (in binary): 0000000000000001
bit0 (failed?): yes
bit1 (compressed?): no
bit2 (incremented?): no
bit3 (has more packets?): no
bit5 (canceled?): no
Updated wInfo (in binary): 0000000000000000
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;code-explanation&#34;&gt;Code Explanation
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Flag Definition&lt;/strong&gt;: Use shift operations (&lt;code&gt;1 &amp;lt;&amp;lt; n&lt;/code&gt;) to define each flag bit. For example, &lt;code&gt;1 &amp;lt;&amp;lt; 0&lt;/code&gt; corresponds to &lt;code&gt;bit0&lt;/code&gt;, &lt;code&gt;1 &amp;lt;&amp;lt; 1&lt;/code&gt; corresponds to &lt;code&gt;bit1&lt;/code&gt;, and so on. This way, we allocate a unique binary position for each flag.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Check a Bit&lt;/strong&gt;: The &lt;code&gt;isBitSet&lt;/code&gt; function uses the bitwise AND operation (&lt;code&gt;wInfo &amp;amp; bitMask&lt;/code&gt;) to check if a specific flag is set to 1. If the bit is 1, the function returns &lt;code&gt;true&lt;/code&gt;, otherwise it returns &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Set a Bit&lt;/strong&gt;: The &lt;code&gt;setBit&lt;/code&gt; function uses the bitwise OR operation (&lt;code&gt;wInfo |= bitMask&lt;/code&gt;) to set a specific flag bit to 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clear a Bit&lt;/strong&gt;: The &lt;code&gt;clearBit&lt;/code&gt; function uses the bitwise AND operation (&lt;code&gt;wInfo &amp;amp;= ~bitMask&lt;/code&gt;) to clear a specific flag bit to 0.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary
&lt;/h3&gt;&lt;p&gt;Through bitwise operations, we can efficiently handle multiple state flags. This technique is particularly useful in practical development. For example, in embedded development, network protocols, and system status management scenarios, bit flags are often used to represent multiple binary states, saving space and improving efficiency.&lt;/p&gt;
&lt;p&gt;We hope this blog post helps you understand how to use bitwise operations in C++ to perform bitwise selection and setting, and mastering these skills is very helpful for writing efficient and maintainable code!&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Linux backend services handling large volumes of string data – performance is slow.</title>
        <link>https://ttf248.life/en/p/linux-backend-slow-string-processing/</link>
        <pubDate>Wed, 13 Nov 2024 19:42:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-backend-slow-string-processing/</guid>
        <description>&lt;p&gt;In the history of C++ development projects, we utilized a custom protocol for communication, which employed a two-dimensional array pattern. When processing large volumes of data, the protocol required iterating through the arrays and performing serialization operations to generate logs. Due to its low efficiency, this resulted in noticeable lag or stuttering within the system under heavy load, as reported by the business departments.&lt;/p&gt;
&lt;h2 id=&#34;problem-identification&#34;&gt;Problem Identification
&lt;/h2&gt;&lt;p&gt;When troubleshooting the issue, we first performed a performance analysis of the system and discovered that CPU utilization increased significantly when processing large amounts of data, and system response times became longer. By analyzing the system logs, we identified numerous serialization operations, which were inefficient when handling two-dimensional arrays, leading to a decline in system performance.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;pstack&lt;/code&gt; tool captured thread information for the service, pinpointing that the log threads spent most of their time processing string concatenation.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is today’s focus: different accumulation methods have significant efficiency differences. Historically, the code used the &lt;code&gt;+&lt;/code&gt; operator, which frequently creates temporary objects and is very inefficient. You know it&amp;rsquo;s bad, but you don&amp;rsquo;t know &lt;em&gt;how&lt;/em&gt; bad it is.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;demo-verification&#34;&gt;Demo Verification
&lt;/h2&gt;&lt;p&gt;Based on the project code, we extracted the business logic and wrote a simple demo to verify the efficiency issues of string concatenation. We compiled and ran it in &lt;code&gt;Release&lt;/code&gt; mode using the &lt;code&gt;vs2022&lt;/code&gt; compiler under &lt;code&gt;windows&lt;/code&gt; and the &lt;code&gt;gcc8.5&lt;/code&gt; compiler under &lt;code&gt;linux&lt;/code&gt;, comparing the efficiencies.&lt;/p&gt;
&lt;h3 id=&#34;key-point-explanation&#34;&gt;Key Point Explanation
&lt;/h3&gt;&lt;p&gt;The project utilized Method Four, and before obtaining test data, readers were encouraged to consider which method was most efficient and which was least efficient. I was quite surprised by the results.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Method 1 (&lt;code&gt;+=&lt;/code&gt; Concatenation)&lt;/strong&gt;: Directly concatenates each field using &lt;code&gt;+=&lt;/code&gt; into a string.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 2 (&lt;code&gt;std::ostringstream&lt;/code&gt; Concatenation)&lt;/strong&gt;: Uses a stream (&lt;code&gt;std::ostringstream&lt;/code&gt;) to concatenate fields, which is more efficient, especially when dealing with large amounts of data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 3 (Pre-allocated Memory &lt;code&gt;+=&lt;/code&gt; Concatenation)&lt;/strong&gt;: Pre-allocates enough memory for the string using &lt;code&gt;reserve&lt;/code&gt;, reducing the overhead of memory reallocation and improving performance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 4 (&lt;code&gt;bodys = bodys + body + &amp;quot;\n&amp;quot;&lt;/code&gt;)&lt;/strong&gt;: Creates a new temporary string object each time it concatenates, leading to decreased performance, particularly when dealing with large-scale concatenation due to repeated memory allocation and copying.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Referring to the results, we can see that the project inadvertently selected the least efficient method.&lt;/p&gt;
&lt;p&gt;Furthermore, let&amp;rsquo;s analyze the optimization efficiency of different platforms and compilers. Microsoft’s &lt;code&gt;visual studio&lt;/code&gt; consistently performs excellently in terms of string optimization, while the &lt;code&gt;gcc&lt;/code&gt; compiler has somewhat lower optimization efficiency in this area.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When running the code on different machines, direct comparison between the two datasets is meaningless; instead, we can compare the differences between the various concatenation methods.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;key-points-explanation&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Windows platform under VS2022 compiler

----------------------------------------
Data Generation Time: 0.054 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.053 seconds.
+ ostringstream Data merging took: 0.054 seconds.
+ Pre-reserved Data merging took: 0.045 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 16.108 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Linux platform under gcc8.5 compiler
----------------------------------------
Data Generation Time: 0.108 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.100 seconds.
+ ostringstream Data merging took: 0.083 seconds.
+ Pre-reserved Data merging took: 0.057 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 29.298 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;random&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;sstream&amp;gt;
#include &amp;lt;iomanip&amp;gt;

typedef std::vector&amp;lt;std::string&amp;gt; DataRow;
typedef std::vector&amp;lt;DataRow&amp;gt; DataGroup;

struct ResponsePackage
{
    std::string ErrorInfo;
    DataRow Head;
    std::string ClientId;
    std::string UUID;
    std::string MsgID;
    std::string SessionID;
    std::string ExtraInfo1;
    std::string ExtraInfo2;
    DataGroup DataBody;
};

// Generate specified length of random string
std::string generateRandomString(size_t length)
{
    const char charset[] = &amp;quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&amp;quot;;
    const size_t max_index = sizeof(charset) - 1;
    std::string random_string;
    random_string.reserve(length);

    std::random_device rd;
    std::mt19937 generator(rd());
    std::uniform_int_distribution&amp;lt;&amp;gt; distribution(0, max_index);

    for (size_t i = 0; i &amp;lt; length; ++i)
    {
        random_string += charset[distribution(generator)];
    }

    return random_string;
}

void create_large_string()
{
    // Example request package with 50 fields
    ResponsePackage requestPackage;

    requestPackage.Head = {
        &amp;quot;Field1&amp;quot;, &amp;quot;Field2&amp;quot;, &amp;quot;Field3&amp;quot;, &amp;quot;Field4&amp;quot;, &amp;quot;Field5&amp;quot;,
        &amp;quot;Field6&amp;quot;, &amp;quot;Field7&amp;quot;, &amp;quot;Field8&amp;quot;, &amp;quot;Field9&amp;quot;, &amp;quot;Field10&amp;quot;,
        &amp;quot;Field11&amp;quot;, &amp;quot;Field12&amp;quot;, &amp;quot;Field13&amp;quot;, &amp;quot;Field14&amp;quot;, &amp;quot;Field15&amp;quot;,
        &amp;quot;Field16&amp;quot;, &amp;quot;Field17&amp;quot;, &amp;quot;Field18&amp;quot;, &amp;quot;Field19&amp;quot;, &amp;quot;Field20&amp;quot;,
        &amp;quot;Field21&amp;quot;, &amp;quot;Field22&amp;quot;, &amp;quot;Field23&amp;quot;, &amp;quot;Field24&amp;quot;, &amp;quot;Field25&amp;quot;,
        &amp;quot;Field26&amp;quot;, &amp;quot;Field27&amp;quot;, &amp;quot;Field28&amp;quot;, &amp;quot;Field29&amp;quot;, &amp;quot;Field30&amp;quot;,
        &amp;quot;Field31&amp;quot;, &amp;quot;Field32&amp;quot;, &amp;quot;Field33&amp;quot;, &amp;quot;Field34&amp;quot;, &amp;quot;Field35&amp;quot;,
        &amp;quot;Field36&amp;quot;, &amp;quot;Field37&amp;quot;, &amp;quot;Field38&amp;quot;, &amp;quot;Field39&amp;quot;, &amp;quot;Field40&amp;quot;,
        &amp;quot;Field41&amp;quot;, &amp;quot;Field42&amp;quot;, &amp;quot;Field43&amp;quot;, &amp;quot;Field44&amp;quot;, &amp;quot;Field45&amp;quot;,
        &amp;quot;Field46&amp;quot;, &amp;quot;Field47&amp;quot;, &amp;quot;Field48&amp;quot;, &amp;quot;Field49&amp;quot;, &amp;quot;Field50&amp;quot;
    };

    requestPackage.ClientId = &amp;quot;ClientID&amp;quot;;
    requestPackage.UUID = &amp;quot;UUID&amp;quot;;
    requestPackage.MsgID = &amp;quot;MsgID&amp;quot;;
    requestPackage.SessionID = &amp;quot;SessionID&amp;quot;;
    requestPackage.ExtraInfo1 = &amp;quot;ExtraInfo1&amp;quot;;
    requestPackage.ExtraInfo2 = &amp;quot;ExtraInfo2&amp;quot;;

    // Start timing for data generation
    auto start_gen = std::chrono::high_resolution_clock::now();

    // Generate 10,000 rows of data, each with 50 fields
    for (size_t i = 0; i &amp;lt; 10000; ++i)
    {
        DataRow dataRow(50, &amp;quot;This is a test string&amp;quot;);
        requestPackage.DataBody.push_back(dataRow);
    }

    // End timing for data generation
    auto end_gen = std::chrono::high_resolution_clock::now();
    std::chrono::duration&amp;lt;double&amp;gt; duration_gen = end_gen - start_gen;

    // Display result generation time
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Generation Time: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_gen.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    // Data merging using different methods
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Performance:\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    {
        // Method 1: Using &#39;+=&#39; string concatenation
        auto start_merge = std::chrono::high_resolution_

```markdown
## Complete Code
{
        // Method 2: Using ostringstream
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::ostringstream bodys;
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::ostringstream body;
            body &amp;lt;&amp;lt; &amp;quot;This is a test string&amp;quot;;
            for (auto&amp;amp; item : vec)
            {
                body &amp;lt;&amp;lt; item &amp;lt;&amp;lt; &amp;quot; &amp;quot;;
            }
            bodys &amp;lt;&amp;lt; body.str() &amp;lt;&amp;lt; &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ ostringstream Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 3: Pre-allocated memory
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys;
        bodys.reserve(1000 * 50 * 20); // Pre-allocate enough memory
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            body.reserve(50 * 20); // Pre-allocate memory for each row
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Pre-reserved Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 4: Using &#39;bodys = bodys + body + &amp;quot;\n&amp;quot;&#39;
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys(&amp;quot;&amp;quot;);
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            for (auto&amp;amp; item : vec)
            {
                body = body + item + &amp;quot; &amp;quot;; // Note the use of &#39;body = body + item&#39;
            }
            bodys = bodys + body + &amp;quot;\n&amp;quot;; // Again, using &#39;bodys = bodys + body&#39;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (bodys = bodys + body + \&amp;quot;\\n\&amp;quot;) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Complete.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;
}

int main()
{
    try
    {
        create_large_string();
    }
    catch (const std::exception&amp;amp; e)
    {
        std::cerr &amp;lt;&amp;lt; &amp;quot;Caught exception: &amp;quot; &amp;lt;&amp;lt; e.what() &amp;lt;&amp;lt; std::endl;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\nProgram finished.\n&amp;quot;;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>C&#43;&#43; Lambda Expression Parameter Lifetimes</title>
        <link>https://ttf248.life/en/p/cpp-lambda-parameter-lifetime/</link>
        <pubDate>Wed, 13 Nov 2024 19:23:02 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-lambda-parameter-lifetime/</guid>
        <description>&lt;p&gt;In C++, lambda expressions are a convenient way to create anonymous functions that can capture external variables and use them within their bodies. This makes lambdas a flexible programming tool. However, the lifetime of parameters in a lambda expression is an aspect that requires careful attention, especially when capturing and passing parameters.&lt;/p&gt;
&lt;h3 id=&#34;1-lambda-expression-parameter-lifetime&#34;&gt;1. Lambda Expression Parameter Lifetime
&lt;/h3&gt;&lt;p&gt;The lifetime of parameters in a lambda expression is typically the same as that of other C++ functions. Parameters exist while the function is being called, and their lifetime ends when the function call terminates. However, due to the possibility of lambdas capturing external variables, the parameter&amp;rsquo;s lifetime is also affected by how it’s captured.&lt;/p&gt;
&lt;h3 id=&#34;2-capturing-the-relationship-with-parameter-lifecycles&#34;&gt;2. Capturing the Relationship with Parameter Lifecycles
&lt;/h3&gt;&lt;h4 id=&#34;21-capturing-external-variables&#34;&gt;2.1 Capturing External Variables
&lt;/h4&gt;&lt;p&gt;C++ lambda expressions allow capturing external variables in two ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Capture by Value:&lt;/strong&gt; When capturing by value, the value of the external variable is copied into the lambda&amp;rsquo;s internal scope. The lifetime of this copy is controlled by the lambda’s own lifetime.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Capture by Reference:&lt;/strong&gt; When capturing by reference, a reference to the external variable is retained. The lambda’s reference points to the original external variable, and its lifetime depends on the external variable’s lifetime.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int x = 10;
auto lambda_by_value = [x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };  // Captures a copy of x
auto lambda_by_reference = [&amp;amp;x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };  // Captures a reference to x

lambda_by_value();  // Prints 10
lambda_by_reference();  // Prints 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For captured variables, the lifetimes are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Capture by Value:&lt;/strong&gt; When capturing, the external variable’s value is copied into the lambda, and the copy is destroyed when the lambda’s lifetime ends.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Capture by Reference:&lt;/strong&gt; The lambda holds a reference to the external variable; &lt;strong&gt;the external variable must be valid at the time the lambda is used, or undefined behavior results.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;22-lambda-parameters&#34;&gt;2.2 Lambda Parameters
&lt;/h4&gt;&lt;p&gt;Lambda parameters are similar to regular function parameters; their lifetime is limited to the lambda function body. That is, lambda parameters are created when the lambda is called and their lifetime ends when the lambda call finishes.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;auto lambda = [](int a, int b) {
    std::cout &amp;lt;&amp;lt; a + b &amp;lt;&amp;lt; std::endl;
};
lambda(5, 10);  // a and b are the parameters of the lambda here
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; are the parameters of the lambda expression, they are created when the lambda is called and destroyed after the lambda executes.&lt;/p&gt;
&lt;h3 id=&#34;3-lifecycle-issues-when-capturing-external-variables&#34;&gt;3. Lifecycle Issues When Capturing External Variables
&lt;/h3&gt;&lt;h4 id=&#34;31-whether-captured-variables-can-be-effective-outside-lambda&#34;&gt;3.1 Whether Captured Variables Can Be Effective Outside Lambda
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Value Capture&lt;/strong&gt;: Even if the external variable is destroyed after the lambda call, the lambda internally still holds a copy of the external variable. Therefore, the copy within the lambda can be safely used even if the external variable no longer exists.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int x = 10;
auto lambda = [x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };
x = 20;  // x is modified after the lambda call
lambda();  // Prints 10, captures a copy of x
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Reference Capture&lt;/strong&gt;: If the external variable is captured by reference, the lambda&amp;rsquo;s access to this reference depends on the lifetime of the external variable. If the external variable is destroyed before the lambda executes, a dangling reference issue will occur, leading to undefined behavior.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int x = 10;
auto lambda = [&amp;amp;x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };
x = 20;  // x is modified before the lambda call
lambda();  // Prints 20, captures a reference to x
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;It&amp;rsquo;s important to ensure that the external variable is valid when the lambda executes if the execution order of the lambda is uncertain.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>Upgrading the GCC version caused program crashes: hidden issues due to code non-compliance.</title>
        <link>https://ttf248.life/en/p/gcc-upgrade-causes-program-crash-code-irregularities/</link>
        <pubDate>Sun, 10 Mar 2024 23:19:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/gcc-upgrade-causes-program-crash-code-irregularities/</guid>
        <description>&lt;p&gt;In the same business code scenario, the program compiled and ran normally in a CentOS 7 environment. However, when switching to CentOS 8 and using an updated version of GCC for compilation, the program crashed. It’s worth noting that the issue only occurs in &lt;strong&gt;Release mode&lt;/strong&gt;, while &lt;strong&gt;Debug mode&lt;/strong&gt; does not exhibit any problems. This is the first time we&amp;rsquo;ve encountered a situation like this; after three days of investigation, we finally identified the root cause.&lt;/p&gt;
&lt;h3 id=&#34;problem-identification&#34;&gt;Problem Identification
&lt;/h3&gt;&lt;p&gt;After investigation, the root cause of the issue was &lt;strong&gt;the function lacked a return value&lt;/strong&gt;. In Release mode, new versions of GCC perform more optimizations, which caused an unknown logic to occur within the function that originally did not have an explicit return value during execution, ultimately triggering a crash. Our conclusion is that &lt;strong&gt;compiler warnings should not be ignored, especially in legacy projects where some warnings may be dismissed, but it’s also important to avoid suppressing all warnings.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;environment-details&#34;&gt;Environment Details
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CentOS 7 GCC Version:&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CentOS 8 GCC Version:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;crash-phenomena&#34;&gt;Crash Phenomena
&lt;/h3&gt;&lt;p&gt;When analyzing the stack information for program crashes, we observed the following stack details:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[New LWP 1385902]
[Thread debugging using libthread_db enabled]
Using host libthread_db library &amp;quot;/lib64/libthread_db.so.1&amp;quot;.
Core was generated by `./pstack_main`.
Program terminated with signal SIGSEGV, Segmentation fault.
#0  0x00007ffe894b4420 in ?? ()
(gdb) bt
#0  0x00007ffe894b4420 in ?? ()
#1  0x00000000004008e9 in main ()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This stack doesn&amp;rsquo;t appear intuitive; the crash function’s stack information shows a &lt;code&gt;??&lt;/code&gt;, which makes troubleshooting even more complex.&lt;/p&gt;
&lt;h3 id=&#34;code-example&#34;&gt;Code Example
&lt;/h3&gt;&lt;p&gt;To better understand the issue, here is a minimal code example that reproduces the crash:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;map&amp;gt;

int test() {
    std::cout &amp;lt;&amp;lt; &amp;quot;1&amp;quot; &amp;lt;&amp;lt; std::endl;
}

int main() {
    test();
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;test()&lt;/code&gt; function in this code clearly does not explicitly return a value, and its return type is &lt;code&gt;int&lt;/code&gt;. According to the C++ standard, when a function is declared as an &lt;code&gt;int&lt;/code&gt; type, it must have a return value, otherwise it may lead to undefined behavior.&lt;/p&gt;
&lt;h3 id=&#34;compilation-warning&#34;&gt;Compilation Warning
&lt;/h3&gt;&lt;p&gt;In our project, the CMake script suppresses many compile-time warnings, including the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;/root/pstack/main.cpp: In function ‘int test()’:
/root/pstack/main.cpp:7:1: warning: no return statement in function returning non-void [-Wreturn-type]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This warning indicates that the &lt;code&gt;test()&lt;/code&gt; function does not return a value, which is the root cause of the problem. Newer versions of GCC (such as 8.5.0) may make unstable optimizations with this undefined behavior when optimizing code, potentially leading to program crashes.&lt;/p&gt;
&lt;h3 id=&#34;assembly-code-differences&#34;&gt;Assembly Code Differences
&lt;/h3&gt;&lt;p&gt;To explain the differences in GCC compiler optimization behavior, we compared assembly code generated by different versions of GCC:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GCC 4.8.5 Generated Assembly Code:&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The assembly code is relatively verbose and includes handling logic for standard output streams (such as &lt;code&gt;std::cout&lt;/code&gt;). This indicates that the compiler performed more conservative optimizations, not optimizing excessively for the missing return value issue in the &lt;code&gt;test()&lt;/code&gt; function, possibly to avoid a crash.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GCC 8.5.0 Generated Assembly Code:&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The new version of GCC performed more optimizations, reducing the code volume. However, this optimization may have resulted in unpredictable behavior when executing functions without returning values, leading to program crashes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h3&gt;&lt;p&gt;Through this troubleshooting process, we deeply realized that in C++, &lt;strong&gt;function return values must be explicit&lt;/strong&gt;, particularly when a function is declared as &lt;code&gt;int&lt;/code&gt;, a return value must be provided. When upgrading from older versions of compilers to newer versions of GCC, more optimization and stricter warning mechanisms may be encountered. Therefore, we recommend not &lt;strong&gt;disabling all warnings&lt;/strong&gt; during compilation, but rather selectively addressing them, especially common issues such as function return values and type matching.
Ultimately, by adding a return value to the &lt;code&gt;test()&lt;/code&gt; function, the problem was resolved, and the program returned to normal operation.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>C&#43;&#43; Programming Traps: A Detailed Explanation of Program Crashes Caused by Improper Use of `std::map`</title>
        <link>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</link>
        <pubDate>Sun, 10 Mar 2024 22:03:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</guid>
        <description>e&gt;
&lt;h2 id=&#34;text&#34;&gt;Text
&lt;/h2&gt;&lt;p&gt;In the C++ standard library, &lt;code&gt;std::map&lt;/code&gt; is an associative container that stores elements in ascending order of keys (key) and provides efficient keyword lookup functionality. However, novice developers sometimes fall into trouble because they misunderstand the behavior of the square bracket operator &lt;code&gt;[]&lt;/code&gt; in &lt;code&gt;std::map&lt;/code&gt;. In fact, when using &lt;code&gt;[]&lt;/code&gt; to access a non-existent key, &lt;code&gt;std::map&lt;/code&gt; inserts a new key-value pair, and the default constructor will be used to initialize the value type corresponding to that key.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;map&amp;gt;

int main() {
    std::map&amp;lt;std::string, int&amp;gt; myMap;

    // Incorrect usage: assuming here that we are trying to access a non-existent key and assume it will return 0
    std::cout &amp;lt;&amp;lt; &amp;quot;Value for &#39;nonexistent_key&#39;: &amp;quot; &amp;lt;&amp;lt; myMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;

    // In fact, the above line of code creates a new key-value pair, where the value is initialized by the default constructor of int (usually 0)
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Although the above code does not directly cause the program to crash, this implicit insertion behavior can lead to unexpected side effects in some cases, such as resource leaks or changes that do not meet expectations. Worse still, in a multithreaded environment, concurrent access to uninitialized memory areas may even cause the program to crash.&lt;/p&gt;
&lt;p&gt;To prevent these problems, it is recommended to use &lt;code&gt;std::map::find()&lt;/code&gt; or &lt;code&gt;std::map::count()&lt;/code&gt; methods to check if the key exists, or explicitly insert elements using &lt;code&gt;std::map::insert()&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;std::map&amp;lt;std::string, int&amp;gt; safeMap;
if (safeMap.count(&amp;quot;nonexistent_key&amp;quot;) == 0) {
    std::cout &amp;lt;&amp;lt; &amp;quot;Key does not exist.&amp;quot; &amp;lt;&amp;lt; std::endl;
} else {
    std::cout &amp;lt;&amp;lt; &amp;quot;Value for existing key: &amp;quot; &amp;lt;&amp;lt; safeMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;
}

// Or explicitly insert a key-value pair, specifying the initial value
safeMap.insert({ &amp;quot;new_key&amp;quot;, 0 });
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the map container stores objects of pointer type, the implicit insertion behavior will save an uninitialized pointer, and any operation on this pointer will cause the program to crash.&lt;/p&gt;</description>
        </item>
        <item>
        <title>C&#43;&#43; Function Call Latency</title>
        <link>https://ttf248.life/en/p/cpp-function-call-timing/</link>
        <pubDate>Wed, 24 Jan 2024 14:11:33 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-function-call-timing/</guid>
        <description>&lt;p&gt;Designed a行情 SDK, implementing different callback function implementations, and performed an extensive test. Recently I’ve been looking into C++ function programming, where functions have become first-class citizens, flowing within the program internally – what&amp;rsquo;s the difference in performance?&lt;/p&gt;
&lt;p&gt;Previous article link: &lt;a class=&#34;link&#34; href=&#34;https://ttf248.life/en/p/compiler-callback-performance-testing/&#34; &gt;Compiler, Callback Functions, Performance Testing&lt;/a&gt;
&lt;code&gt;leimao&lt;/code&gt;大佬 also did similar tests, so I borrowed their code.&lt;/p&gt;
&lt;h2 id=&#34;main-content&#34;&gt;Main Content
&lt;/h2&gt;&lt;p&gt;The execution platform remains our old friend, &lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;cassert&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;functional&amp;gt;
#include &amp;lt;iostream&amp;gt;
#include &amp;lt;vector&amp;gt;

int add_one(int input) { return input + 1; }

bool validate_vector_add_one(std::vector&amp;lt;int&amp;gt; const&amp;amp; input_vector,
                             std::vector&amp;lt;int&amp;gt; const&amp;amp; output_vector)
{
    bool is_valid{true};
    for (size_t i{0}; i &amp;lt; input_vector.size(); ++i)
    {
        if (output_vector.at(i) != input_vector.at(i) + 1)
        {
            is_valid = false;
            break;
        }
    }
    return is_valid;
}

void reset_vector(std::vector&amp;lt;int&amp;gt;&amp;amp; input_vector)
{
    for (size_t i{0}; i &amp;lt; input_vector.size(); ++i)
    {
        input_vector.at(i) = 0;
    }
}

template &amp;lt;typename T, typename Func&amp;gt;
void unitary_function_pass_by_lambda_function(T&amp;amp; output, T const&amp;amp; input,
                                              Func const func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_std_function_value(T&amp;amp; output, T const&amp;amp; input,
                                                 std::function&amp;lt;T(T)&amp;gt; const func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_std_function_reference(
    T&amp;amp; output, T const&amp;amp; input, std::function&amp;lt;T(T)&amp;gt; const&amp;amp; func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_function_pointer(T&amp;amp; output, T const&amp;amp; input,
                                               T (*func)(T))
{
    output = func(input);
}

int main()
{
    // Set floating point format std::cout with 3 decimal places.
    std::cout.precision(3);

    size_t const num_elements{10000000};
    std::vector&amp;lt;int&amp;gt; input_vector(num_elements, 0);
    std::vector&amp;lt;int&amp;gt; output_vector(num_elements, 0);

    auto const lambda_function_add_one{[](int const&amp;amp; input) -&amp;gt; int
                                       { return input + 1; }};
    std::function&amp;lt;int(int)&amp;gt; const std_function_add_one{lambda_function_add_one};

    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a function pointer: &amp;quot; &amp;lt;&amp;lt; sizeof(&amp;amp;add_one)
              &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a std::function pointer: &amp;quot;
              &amp;lt;&amp;lt; sizeof(&amp;amp;std_function_add_one) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a std::function: &amp;quot; &amp;lt;&amp;lt; sizeof(std_function_add_one)
              &amp;lt;&amp;lt; std::endl;

    // Call function frequently in a vanilla way.
    // The compiler knows what function to call at compile time and can optimize
    // the code.
    // This is the best performance we could get.
    std::chrono::steady_clock::time_point const time_start_vanilla{
        std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        output_vector.at(i) = add_one(input_vector.at(i));
    }
    std::chrono::steady_clock::time_point const time_end_vanilla{
        std::chrono::steady_clock::now()};
    auto const time_elapsed_vanilla{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(time_end_vanilla -
                                                             time_start_vanilla)
            .count()};
    float const latency_vanilla{time_elapsed_vanilla /
                                static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass Vanilla: &amp;quot; &amp;lt;&amp;lt; latency_vanilla &amp;lt;&amp;lt; &amp;quot; ns&amp;quot;
              &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector

```markdown
## Text
// Sometimes, we don&#39;t know what function to call at compile time.
// We can use `std::function` to pass a function as an argument.
// In this case, we pass the `std::function` by value.
// Because the size of a `std::function` is 32 bytes, passing by value
// results in a lot of copying and bad performance.
std::chrono::steady_clock::time_point const
    time_start_pass_by_std_function_value{std::chrono::steady_clock::now()};
for (size_t i{0}; i &amp;lt; num_elements; ++i)
{
    unitary_function_pass_by_std_function_value(
        output_vector.at(i), input_vector.at(i), std_function_add_one);
}
std::chrono::steady_clock::time_point const
    time_end_pass_by_std_function_value{std::chrono::steady_clock::now()};
auto const time_elapsed_pass_by_std_function_value{
    std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
        time_end_pass_by_std_function_value -
        time_start_pass_by_std_function_value)
        .count()};
float const latency_pass_by_std_function_value{
    time_elapsed_pass_by_std_function_value /
    static_cast&amp;lt;float&amp;gt;(num_elements)};
std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Std Function Value: &amp;quot;
          &amp;lt;&amp;lt; latency_pass_by_std_function_value &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
assert(validate_vector_add_one(input_vector, output_vector));
reset_vector(output_vector);

// Instead of passing the `std::function` by value, we can pass it by
// reference (pointer). In this case, object copying is eliminated. The
// performance is better than passing the `std::function` by value. However,
// the performance is still not as good as the vanilla way.
std::chrono::steady_clock::time_point const
    time_start_pass_by_std_function_reference{
        std::chrono::steady_clock::now()};
for (size_t i{0}; i &amp;lt; num_elements; ++i)
{
    unitary_function_pass_by_std_function_reference(
        output_vector.at(i), input_vector.at(i), std_function_add_one);
}
std::chrono::steady_clock::time_point const
    time_end_pass_by_std_function_reference{
        std::chrono::steady_clock::now()};
auto const time_elapsed_pass_by_std_function_reference{
    std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
        time_end_pass_by_std_function_reference -
        time_start_pass_by_std_function_reference)
        .count()};
float const latency_pass_by_std_function_reference{
    time_elapsed_pass_by_std_function_reference /
    static_cast&amp;lt;float&amp;gt;(num_elements)};
std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Std Function Reference: &amp;quot;
          &amp;lt;&amp;lt; latency_pass_by_std_function_reference &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
assert(validate_vector_add_one(input_vector, output_vector));
reset_vector(output_vector);
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Text

// `std::function` is a general-purpose wrapper for function pointers,
// callable objects, and lambda functions. Because it&#39;s general purpose,
// it&#39;s not as efficient as a function pointer. In this case, we pass a
// function pointer to a function. The performance is better than passing
// the `std::function` by reference.
std::chrono::steady_clock::time_point const
    time_start_pass_by_function_pointer{std::chrono::steady_clock::now()};
for (size_t i{0}; i &amp;lt; num_elements; ++i)
{
    unitary_function_pass_by_function_pointer(output_vector.at(i),
                                                  input_vector.at(i), &amp;amp;add_one);
}
std::chrono::steady_clock::time_point const
    time_end_pass_by_function_pointer{std::chrono::steady_clock::now()};
auto const time_elapsed_pass_by_function_pointer{
    std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
        std::chrono::steady_clock::now() -
        time_start_pass_by_function_pointer)
        .count()};
float const latency_pass_by_function_pointer{
    time_elapsed_pass_by_function_pointer /
    static_cast&amp;lt;float&amp;gt;(num_elements)};
std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Function Pointer: &amp;quot;
          &amp;lt;&amp;lt; latency_pass_by_function_pointer &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
assert(validate_vector_add_one(input_vector, output_vector));
reset_vector(output_vector);

// We can also pass a lambda function to a function.
// The compiler knows what function to call at compile time and can optimize
// the code. The performance is also better than passing the `std::function`
// by reference.
std::chrono::steady_clock::time_point const
    time_start_pass_by_lambda_function{std::chrono::steady_clock::now()};
for (size_t i{0}; i &amp;lt; num_elements; ++i)
{
    unitary_function_pass_by_lambda_function(
        output_vector.at(i), input_vector.at(i), lambda_function_add_one);
}
std::chrono::steady_clock::time_point const
    time_end_pass_by_lambda_function{std::chrono::steady_clock::now()};
auto const time_elapsed_pass_by_lambda_function{
    std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
        std::chrono::steady_clock::now() -
        time_start_pass_by_lambda_function)
        .count()};
float const latency_pass_by_lambda_function{
    time_elapsed_pass_by_lambda_function /
    static_cast&amp;lt;float&amp;gt;(num_elements)};
std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Lambda Function: &amp;quot;
          &amp;lt;&amp;lt; latency_pass_by_lambda_function &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
assert(validate_vector_add_one(input_vector, output_vector));
reset_vector(output_vector);
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;body&#34;&gt;Body
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# The default optimization for the team is to enable O2, and the compiler selected was gcc13. Performance and execution times vary slightly between different versions of gcc, with higher versions resulting in better lambda performance.
# Function pointer size: 8
# std::function pointer size: 8
# std::function size: 32
# Vanilla Pass Latency: 0.418 ns
# Latency Pass By Std Function Value: 3.47 ns
# Latency Pass By Std Function Reference: 1.36 ns
# Latency Pass By Function Pointer: 0.396 ns
# Latency Pass By Lambda Function: 0.44 ns
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leimao.github.io/blog/CPP-Function-Call-Performance/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://leimao.github.io/blog/CPP-Function-Call-Performance/&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>C11: sleep for vs yield</title>
        <link>https://ttf248.life/en/p/c11-sleep-for-vs-yield/</link>
        <pubDate>Tue, 20 Sep 2022 20:54:51 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/c11-sleep-for-vs-yield/</guid>
        <description>&lt;p&gt;While reviewing the code, &lt;code&gt;std::this_thread::yield()&lt;/code&gt; suddenly popped into my view, a syntax sugar from &lt;code&gt;C11&lt;/code&gt; that I’d used quite a bit, but hadn&amp;rsquo;t noticed before.&lt;/p&gt;
&lt;p&gt;I didn’t consult the manual; first, I thought it had something to do with asynchronous operations – the word was used in the coroutine implementation of the Boost library.  Clearly, it wasn’t related to coroutines; it’s about controlling logic within a regular thread.&lt;/p&gt;
&lt;h2 id=&#34;documentation&#34;&gt;Documentation
&lt;/h2&gt;&lt;h3 id=&#34;yield&#34;&gt;yield
&lt;/h3&gt;&lt;p&gt;The accuracy of this function depends on the implementation, particularly the OS scheduler mechanism and system state used. For example, the First-Come, First-Served (FCFS) real-time scheduler (Linux’s SCHED_FIFO) will suspend the current thread and place it at the end of the queue for other threads with the same priority that are ready to run (and has no effect if there are no other threads with the same priority).&lt;/p&gt;
&lt;h3 id=&#34;sleep_for&#34;&gt;sleep_for
&lt;/h3&gt;&lt;p&gt;Blocks the current thread&amp;rsquo;s execution for at least the specified &lt;code&gt;sleep_duration&lt;/code&gt;.
This function may block longer than &lt;code&gt;sleep_duration&lt;/code&gt; due to scheduling or resource contention delays.
The standard library recommends measuring durations using a monotonic clock. If implementing with system time instead, waiting times may be sensitive to clock adjustments.&lt;/p&gt;
&lt;h3 id=&#34;analysis&#34;&gt;Analysis
&lt;/h3&gt;&lt;p&gt;Both functions are designed to release the current thread and its associated resources, with the actual effect depending on the platform. I’m still a bit unclear at this point, so let&amp;rsquo;s run the code to see the execution results.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ThinkPad laptop (Visual Studio Community 2022), Tencent Cloud S2 Standard Server (gcc8.5)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;analysis-1&#34;&gt;Analysis
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Execution Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First/us&lt;/th&gt;
&lt;th&gt;Second/us&lt;/th&gt;
&lt;th&gt;Third/us&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h3 id=&#34;analysis-2&#34;&gt;Analysis
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Execution Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First Time / us&lt;/th&gt;
&lt;th&gt;Second Time / us&lt;/th&gt;
&lt;th&gt;Third Time / us&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h3 id=&#34;analysis-3&#34;&gt;Analysis
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Execution Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First/us&lt;/th&gt;
&lt;th&gt;Second/us&lt;/th&gt;
&lt;th&gt;Third/us&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h3 id=&#34;analysis-4&#34;&gt;Analysis
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Execution Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First/us&lt;/th&gt;
&lt;th&gt;Second/us&lt;/th&gt;
&lt;th&gt;Third/us&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h3 id=&#34;analysis-5&#34;&gt;Analysis
&lt;/h3&gt;&lt;p&gt;From the results, it’s clear that due to differences in operating system implementations, the stability of high-precision sleep varies greatly. If you want high-precision sleep, using &lt;code&gt;yield&lt;/code&gt; is more appropriate.&lt;/p&gt;
&lt;p&gt;When the time precision is increased to &lt;code&gt;ms&lt;/code&gt;, the difference between the two methods is not significant.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Why Do We Need to Learn a New Language?</title>
        <link>https://ttf248.life/en/p/why-learn-a-new-language/</link>
        <pubDate>Thu, 04 Aug 2022 11:27:30 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/why-learn-a-new-language/</guid>
        <description>&lt;p&gt;Starting from my academic years, I’ve been working with &lt;code&gt;C++&lt;/code&gt; for over ten years. So, why do I need to learn other programming languages?&lt;/p&gt;
&lt;p&gt;Work experience: Lacking experience in elegant module design, &lt;code&gt;C++&lt;/code&gt; syntax is freeform. Learning other languages helps me guide the development of more elegant designs.&lt;/p&gt;
&lt;p&gt;I often use them when writing some tools. The design principles for low-level libraries and business modules are also becoming clearer.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Standard Library Container Memory Allocators: allocator</title>
        <link>https://ttf248.life/en/p/standard-library-container-memory-allocator/</link>
        <pubDate>Mon, 30 Dec 2019 13:26:19 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/standard-library-container-memory-allocator/</guid>
        <description>&lt;p&gt;A custom allocator can improve performance, increase memory utilization efficiency, and address the issue of frequent, small memory allocations.&lt;/p&gt;
&lt;h4 id=&#34;antecedent&#34;&gt;Antecedent
&lt;/h4&gt;&lt;p&gt;Recently, I&amp;rsquo;ve been working on the development of network data packets, requiring frequent allocation and release of small blocks of memory. Initially, I considered using a memory pool, reviewing several existing ones and discovering this:
&lt;a class=&#34;link&#34; href=&#34;https://github.com/cacay/MemoryPool&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/cacay/MemoryPool&lt;/a&gt;
When looking at the interface, I was quite puzzled by how the memory pool&amp;rsquo;s implementation was a bit strange. The &lt;code&gt;MemoryPool&lt;/code&gt; implementation logic involves allocating fixed-size memory blocks. Having reviewed Boost’s memory pool interface, it provides a template that is instantiated when used. Fortunately, this library already had an article describing it, mentioning the concept of an ‘allocator’.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;#### [wiki](https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_(C%2B%2B))

In C++ programming, an allocator is a key component of the C++ standard library. The C++ standard library defines various data structures commonly referred to as &amp;quot;containers&amp;quot; (such as linked lists, sets, etc.). A common feature of these containers is that their size can be changed at runtime; therefore, dynamic memory allocation becomes necessary to achieve this. The allocator is used to handle memory allocation and deallocation requests made by the containers. In other words, the allocator encapsulates the low-level details of memory management for Standard Template Library (STL) containers. By default, the C++ standard library uses its built-in generic allocator, but programmers can customize allocators to replace it as needed.

The allocator was originally invented by Alexander Stepanov as part of the C++ Standard Template Library (STL), with the intention of creating a mechanism that would &amp;quot;make the library more flexible and allow independent use of low-level data models,&amp;quot; and enable programmers to utilize custom pointer and reference types within the library; however, when the STL was incorporated into the C++ standard, the C++ standards committee realized that complete abstraction of the data model would result in unacceptable performance penalties. To compromise, restrictions on the allocator were made more stringent, and compared to Stepanov&#39;s original vision, the degree to which the current standard describes allocators is greatly limited.

Although customization of the allocator is somewhat restricted, it is still needed in many cases, typically for encapsulating access to different types of memory spaces (such as shared memory and reclaimed memory), or for improving performance when using a memory pool for memory allocation. In addition, from the perspective of memory usage and execution time, in programs that frequently perform small amounts of memory allocation, introducing a dedicated allocator can also yield benefits.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;- Data Mining
- Deep Learning
- Neural Network

#### [Usage Requirements](https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_(C%2B%2B))

The primary reason for defining custom allocators is to improve performance. Utilizing a dedicated custom allocator can increase program performance, or improve memory usage efficiency, or both [4][8]. The default allocator uses the `new` operator to allocate storage [Reference 5], which is often implemented using the C language heap allocation function (malloc()) [9]. Because heap allocation functions are optimized for occasional large memory allocations, the default allocator generally works well when allocating memory for containers that require a single large memory allocation at once, such as vectors and doubly-ended queues [8]. However, for associative containers and linked lists that frequently allocate small amounts of memory, using the default allocator typically results in low efficiency [4][9]. In addition, the malloc()-based default allocator also has many problems, such as poor reference locality [4], and may cause memory fragmentation [4][9].

In short, this section (…)(like) is a “Dream” speech for this standard regarding allocators. Before dreams come true, programmers concerned with portability will be limited to using stateless custom allocators.
— Scott Meyers, *Effective STL*

Given this, in this situation, people often use memory pool-based allocators to solve the problem of frequent small allocations [8]. Unlike the default “on-demand” allocation method, when using a memory pool-based allocator, the program pre-allocates large blocks of memory (i.e., &amp;quot;memory pool&amp;quot;) and then the custom allocator simply returns a pointer to an available memory location in the pool to the requester. When objects are destructed, it does not actually deallocate memory; instead, it is deferred until the lifetime of the memory pool ends [Note 1][8].

In the topic of “custom allocators,” many C++ experts and authors have participated in discussions, such as Scott Meyers’s *Effective STL* and Andrej Alexandrescu’s *Modern C++ Design*, which mention it. Meyers realized that if an allocator instance is required to be equal for a specific type T, the portable allocator instance must not contain state. Although the C++ standard encourages library implementers to support stateful allocators [Reference 4], Meyers said that this paragraph is “(seemingly) a wonderful view,” but it’s almost nonsense, and he considered the restrictions on allocators “too strict” [4]. For example, the list in STL allows the `splice` method, which means a node in one list object A can be directly moved into another list object B, which requires that the memory allocated by A&#39;s allocator be released by B&#39;s allocator, thus deducing that the allocator instances of A and B must be equal. Meyers’s conclusion is that allocators should be defined as types using static methods. For example, according to the C++ standard, the allocator must provide a `rebind` method other class template.

Furthermore, in *C++ Programming Language*, Bjørn Strubø suggests “‘restricting the allocator to avoid different information for each object’ is obviously not a problem” (roughly), and points out that most allocators do not need state, or even perform better without state. He proposed three use cases for custom allocators: memory pool-type allocators, shared memory-type allocators, and garbage collection-type allocators, and demonstrated an implementation of an allocator using an internal memory pool to quickly allocate/deallocate small amounts of memory [3]. However, he also mentioned that such optimization may already be implemented in the sample allocator he provided.

Another use for custom allocators is to debug memory-related errors [10]. To do this, you can write an allocator that allocates extra memory when allocating and stores debugging information. This type of allocator not only ensures that memory is allocated/deallocated by the same type of allocator, but also can protect the program to some extent from cache overflows [11].
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        
    </channel>
</rss>

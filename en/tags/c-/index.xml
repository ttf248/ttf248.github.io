<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>C&#43;&#43; on Uncle Xiang&#39;s Notebook</title>
        <link>https://ttf248.life/en/tags/c-/</link>
        <description>Recent content in C&#43;&#43; on Uncle Xiang&#39;s Notebook</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Mon, 02 Jun 2025 19:00:25 +0800</lastBuildDate><atom:link href="https://ttf248.life/en/tags/c-/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>C&#43;&#43; Bitwise Operations Fundamentals: Bitwise Extraction and Flag Setting</title>
        <link>https://ttf248.life/en/p/cpp-bitwise-operations-flags/</link>
        <pubDate>Fri, 17 Jan 2025 02:23:56 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-bitwise-operations-flags/</guid>
        <description>&lt;p&gt;In actual C++ development, bitwise operations are a common technique, especially when dealing with system states, flags, or control bits. Bitwise operations can provide very efficient solutions. This article will illustrate how to use bitwise operations to retrieve and set specific flags through an example.&lt;/p&gt;
&lt;h3 id=&#34;bitwise-operations-fundamentals&#34;&gt;Bitwise Operations Fundamentals
&lt;/h3&gt;&lt;p&gt;In computers, data is stored in binary bits (0 and 1). Bitwise operations are operations performed on these binary bits. C++ provides several commonly used bitwise operators:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Bitwise AND (&amp;amp;)&lt;/strong&gt;: Used to check if a particular bit is set to 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise OR (|)&lt;/strong&gt;: Used to set a particular bit to 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise XOR (^)&lt;/strong&gt;: Used to flip a particular bit.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise NOT (~)&lt;/strong&gt;: Inverts all the bits.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Left Shift (&amp;laquo;)&lt;/strong&gt;: Shifts all bits to the left by a specified number of positions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Right Shift (&amp;raquo;)&lt;/strong&gt;: Shifts all bits to the right by a specified number of positions.
In this example, we need to perform a series of bitwise operations on an &lt;code&gt;unsigned short&lt;/code&gt; variable &lt;code&gt;wInfo&lt;/code&gt; to represent different states using various flags.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bitwise-operations-fundamentals-1&#34;&gt;Bitwise Operations Fundamentals
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;flowchart LR
    A[Original Value: 00010000] --&amp;gt; B[Left Shift: 00010000 &amp;lt;&amp;lt; 1]
    B --&amp;gt; C[Result: 00100000]
    C --&amp;gt; D[Right Shift: 00100000 &amp;gt;&amp;gt; 1]
    D --&amp;gt; E[Result: 00010000]

    subgraph Left Shift Operation
        direction LR
        A --&amp;gt; B --&amp;gt; C
    end

    subgraph Right Shift Operation
        direction LR
        C --&amp;gt; D --&amp;gt; E
    end
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;requirement-analysis&#34;&gt;Requirement Analysis
&lt;/h3&gt;&lt;p&gt;Based on the description, we have a 16-bit flag to represent different states. These states are represented by various binary bits, with each binary bit corresponding to a specific meaning. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;bit0&lt;/strong&gt;: Failure status&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bit1&lt;/strong&gt;: Compression status&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bit2&lt;/strong&gt;: Incremental status&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bit3&lt;/strong&gt;: Presence of subsequent packets&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bit5&lt;/strong&gt;: Normal request or cancellation&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;using-bitwise-operations&#34;&gt;Using Bitwise Operations
&lt;/h3&gt;&lt;p&gt;We will use bitwise operations to set and retrieve these flags. Specifically:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Bitwise AND:&lt;/strong&gt; Retrieve the value of a particular bit (0 or 1).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise OR:&lt;/strong&gt; Set a particular bit to 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise XOR:&lt;/strong&gt; Set a particular bit to 0.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We first define an &lt;code&gt;unsigned short&lt;/code&gt; type variable &lt;code&gt;wInfo&lt;/code&gt; to store these flags. Then, we use bitwise operations to check and set the corresponding flags.&lt;/p&gt;
&lt;h3 id=&#34;c-example-code&#34;&gt;C++ Example Code
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;bitset&amp;gt;

// Define flag constants
const unsigned short BIT_0_FAIL = 1 &amp;lt;&amp;lt; 0;    // Bit0 failed?
const unsigned short BIT_1_COMPRESSED = 1 &amp;lt;&amp;lt; 1; // Bit1 compressed?
const unsigned short BIT_2_INCREMENT = 1 &amp;lt;&amp;lt; 2;  // Bit2 incremented?
const unsigned short BIT_3_HAS_MORE = 1 &amp;lt;&amp;lt; 3;   // Bit3 has more packets?
const unsigned short BIT_5_CANCEL = 1 &amp;lt;&amp;lt; 5;     // Bit5 normal request (0) or cancellation (1)

// Check if a bit is set
bool isBitSet(unsigned short wInfo, unsigned short bitMask) {
    return (wInfo &amp;amp; bitMask) != 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;### C++ Example Code
// Set a bit to 1
void setBit(unsigned short&amp;amp; wInfo, unsigned short bitMask) {
    wInfo |= bitMask;
}

// Clear a bit (set it to 0)
void clearBit(unsigned short&amp;amp; wInfo, unsigned short bitMask) {
    wInfo &amp;amp;= ~bitMask;
}

int main() {
    // Assume wInfo&#39;s initial value is 0
    unsigned short wInfo = 0;

    // Set bit0 (failure flag)
    setBit(wInfo, BIT_0_FAIL);

    // Set bit1 (compressed flag)
    setBit(wInfo, BIT_1_COMPRESSED);

    // Print wInfo&#39;s binary value
    std::cout &amp;lt;&amp;lt; &amp;quot;wInfo (in binary): &amp;quot; &amp;lt;&amp;lt; std::bitset&amp;lt;16&amp;gt;(wInfo) &amp;lt;&amp;lt; std::endl;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;c-example-code-1&#34;&gt;C++ Example Code
&lt;/h3&gt;&lt;p&gt;// Check the various flags
std::cout &amp;laquo; &amp;ldquo;bit0 (failure flag): &amp;quot; &amp;laquo; (isBitSet(wInfo, BIT_0_FAIL) ? &amp;ldquo;yes&amp;rdquo; : &amp;ldquo;no&amp;rdquo;) &amp;laquo; std::endl;
std::cout &amp;laquo; &amp;ldquo;bit1 (compression flag): &amp;quot; &amp;laquo; (isBitSet(wInfo, BIT_1_COMPRESSED) ? &amp;ldquo;yes&amp;rdquo; : &amp;ldquo;no&amp;rdquo;) &amp;laquo; std::endl;
std::cout &amp;laquo; &amp;ldquo;bit2 (incremental flag): &amp;quot; &amp;laquo; (isBitSet(wInfo, BIT_2_INCREMENT) ? &amp;ldquo;yes&amp;rdquo; : &amp;ldquo;no&amp;rdquo;) &amp;laquo; std::endl;
std::cout &amp;laquo; &amp;ldquo;bit3 (more packets flag): &amp;quot; &amp;laquo; (isBitSet(wInfo, BIT_3_HAS_MORE) ? &amp;ldquo;yes&amp;rdquo; : &amp;ldquo;no&amp;rdquo;) &amp;laquo; std::endl;
std::cout &amp;laquo; &amp;ldquo;bit5 (cancel flag): &amp;quot; &amp;laquo; (isBitSet(wInfo, BIT_5_CANCEL) ? &amp;ldquo;yes&amp;rdquo; : &amp;ldquo;no&amp;rdquo;) &amp;laquo; std::endl;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;### C++ Example Code
// Clear bit 1 (compression flag)
    clearBit(wInfo, BIT_1_COMPRESSED);

    // Print the updated wInfo
    std::cout &amp;lt;&amp;lt; &amp;quot;Updated wInfo (in binary): &amp;quot; &amp;lt;&amp;lt; std::bitset&amp;lt;16&amp;gt;(wInfo) &amp;lt;&amp;lt; std::endl;

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;c-example-code-2&#34;&gt;C++ Example Code
&lt;/h3&gt;&lt;p&gt;Execute the code, recommended for old friends: &lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;wInfo (in binary): 0000000000000011
bit0 (failure flag): Yes
bit1 (compression flag): Yes
bit2 (incremental flag): No
bit3 (has subsequent package flag): No
bit5 (log out flag): No
Updated wInfo (in binary): 0000000000000001
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;code-explanation&#34;&gt;Code Explanation
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Flag Definition&lt;/strong&gt;: Use shift operations (&lt;code&gt;1 &amp;lt;&amp;lt; n&lt;/code&gt;) to define each flag bit. For example, &lt;code&gt;1 &amp;lt;&amp;lt; 0&lt;/code&gt; corresponds to &lt;code&gt;bit0&lt;/code&gt;, &lt;code&gt;1 &amp;lt;&amp;lt; 1&lt;/code&gt; corresponds to &lt;code&gt;bit1&lt;/code&gt;, and so on. This way, we allocate a unique binary position for each flag.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Check a Bit&lt;/strong&gt;: The &lt;code&gt;isBitSet&lt;/code&gt; function uses the bitwise AND operation (&lt;code&gt;wInfo &amp;amp; bitMask&lt;/code&gt;) to check if a specific flag is set to 1. If the bit is 1, the function returns &lt;code&gt;true&lt;/code&gt;, otherwise it returns &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Set a Bit&lt;/strong&gt;: The &lt;code&gt;setBit&lt;/code&gt; function uses the bitwise OR operation (&lt;code&gt;wInfo |= bitMask&lt;/code&gt;) to set a specific flag bit to 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clear a Bit&lt;/strong&gt;: The &lt;code&gt;clearBit&lt;/code&gt; function uses the bitwise AND operation (&lt;code&gt;wInfo &amp;amp;= ~bitMask&lt;/code&gt;) to clear a specific flag bit to 0.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary
&lt;/h3&gt;&lt;p&gt;Through bitwise operations, we can efficiently handle multiple state flags. This technique is particularly useful in practical development. For example, in embedded development, network protocols, and system status management scenarios, bit flags are often used to represent multiple binary states, saving space and improving efficiency.&lt;/p&gt;
&lt;p&gt;We hope this blog post helps you understand how to use bitwise operations in C++ to perform bitwise selection and setting, and mastering these skills is very helpful for writing efficient and maintainable code!&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Deeply understand GCC, GLIBC, and C&#43;&#43; program compatibility issues</title>
        <link>https://ttf248.life/en/p/gcc-glibc-cpp-compatibility/</link>
        <pubDate>Mon, 06 Jan 2025 19:51:16 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/gcc-glibc-cpp-compatibility/</guid>
        <description>&lt;p&gt;In the C++ development field, GCC and GLIBC are two indispensable key elements, and compatibility issues after program release often trouble developers. This article will delve into their essence, explore the root causes of compatibility problems, and investigate coping strategies.&lt;/p&gt;
&lt;h2 id=&#34;i-gcc-a-powerful-compiler-cornerstone&#34;&gt;I. GCC: A Powerful Compiler Cornerstone
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Definition and Function&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;GCC, or GNU Compiler Collection, is a suite of open-source compilers developed by the GNU project. It’s far from a typical compiler; it supports a wide range of programming languages including C, C++, Objective - C, Fortran, Ada, and Go, providing a one-stop solution for cross-language development.&lt;/li&gt;
&lt;li&gt;Taking C++ as an example, when we write a source file containing complex features like classes, templates, and function overloading, GCC can translate the advanced C++ code into low-level machine instructions that can be understood and executed by the system. This process involves multiple fine-grained stages such as lexical analysis, syntax analysis, semantic analysis, optimization, and code generation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;i-gcc-a-powerful-compiler-foundation&#34;&gt;I. GCC: A Powerful Compiler Foundation
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Compilation Process Details&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Preprocessing Stage:&lt;/strong&gt; GCC first performs preprocessing operations on the source file. During this stage, it handles all preprocessor directives starting with &lt;code&gt;#&lt;/code&gt;, such as &lt;code&gt;#include&lt;/code&gt; instructions. These instructions embed the entire contents of specified header files (e.g., &lt;code&gt;&amp;lt;iostream&amp;gt;&lt;/code&gt; for C++ input/output stream operations) into the corresponding locations in the source file, allowing the program to use functions, classes, and other resources declared in those headers; &lt;code&gt;#define&lt;/code&gt; directives defining macros are also expanded and replaced during this stage, such as &lt;code&gt;#define PI 3.14159&lt;/code&gt;.  Every occurrence of &lt;code&gt;PI&lt;/code&gt; in the source file is replaced with &lt;code&gt;3.14159&lt;/code&gt;. After preprocessing, the source file undergoes an initial &amp;ldquo;expansion.&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compilation Stage:&lt;/strong&gt; The preprocessed file enters the compilation phase, where GCC converts the source file into assembly language code based on the C++ language standard. It carefully checks the code structure, ensuring that class inheritance and polymorphism implementations are correct, as well as that function call parameters match. Upon detecting errors that violate the grammatical semantics, it immediately reports them and terminates the compilation process. For example, if the parameter list in a function declaration does not match its definition, GCC will accurately pinpoint the issue.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-gcc-a-powerful-compiler-cornerstone-1&#34;&gt;I. GCC: A Powerful Compiler Cornerstone
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Assembly Stage:&lt;/strong&gt; The assembler converts the assembly code generated in the previous step into machine code, producing object files with a &lt;code&gt;.o&lt;/code&gt; extension. These object files contain binary instructions that can be directly executed by the machine, but they cannot run independently because a complete program is typically composed of multiple modules, and function and variable references between these modules have not yet been resolved.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Linking Stage:&lt;/strong&gt; This is the final sprint to generate an executable file. The linker integrates multiple object files as well as required libraries (static or dynamic) together. For example, when using container classes from the C++ Standard Template Library, linking requires finding the corresponding library implementation code to ensure that the program can correctly call functions of objects like &lt;code&gt;vector&lt;/code&gt; and &lt;code&gt;list&lt;/code&gt; at runtime, ultimately generating a complete executable program.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ii-glibc-the-backbone-of-c-program-execution&#34;&gt;II. GLIBC: The Backbone of C++ Program Execution
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Nature and Function&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;GLIBC, or the GNU C Library, is a concrete implementation of the C standard library within the GNU ecosystem. Although its name emphasizes C, C++ programs heavily rely on it as well, because C++ inherits its foundational elements. It provides a vast array of basic functions, such as those for memory management – &lt;code&gt;malloc&lt;/code&gt; (dynamic memory allocation) and &lt;code&gt;free&lt;/code&gt; (memory deallocation) – which are indispensable when creating dynamic arrays and objects in C++, as well as string manipulation functions like &lt;code&gt;strcpy&lt;/code&gt; (string copy) and &lt;code&gt;strcat&lt;/code&gt; (string concatenation). Even though C++ has a more advanced &lt;code&gt;string&lt;/code&gt; class, these functions are still frequently used at the underlying level when interacting with C code or pursuing extreme performance, as well as in early C++ development and scenarios where simplicity is paramount.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;ii-glibc-the-backbone-of-c-program-execution-1&#34;&gt;II. GLIBC: The Backbone of C++ Program Execution
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Collaboration with the Operating System&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;GLIBC acts as a crucial bridge between the operating system and applications. In Linux systems, when a C++ program initiates a system call – such as opening a file (using the &lt;code&gt;open&lt;/code&gt; function, which relies on GLIBC’s implementation), GLIBC encapsulates the program&amp;rsquo;s request in a manner conforming to the operating system kernel’s specifications and passes it to the kernel for processing. Upon completion by the kernel, GLIBC returns the results to the application. This allows applications to utilize various system resources – such as file systems, networks, and process management – without needing to delve into the complex details of the underlying system call interfaces.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;iii-compatibility-issues-after-c-program-deployment-analysis&#34;&gt;III. Compatibility Issues After C++ Program Deployment Analysis
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Compatibility Dilemmas Triggered by Differences in GLIBC Version&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Different Linux distributions often utilize different versions of GLIBC. When a C++ program is compiled in a newer GLIBC environment, it may unknowingly use certain new function features or rely on optimized function implementations introduced in that version. For example, the new GLIBC version has improved memory allocation algorithms; the program frequently utilizes this new algorithm to enhance performance at runtime. Once this program is deployed on a lower-version GLIBC system, it may encounter issues such as failing to find the corresponding function (because the older version did not introduce it) or abnormal function behavior (the old version’s implementation logic differs from the new one), leading to program crashes or incorrect results.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;iii-compatibility-issues-after-c-program-publishing-an-analysis&#34;&gt;III. Compatibility Issues After C++ Program Publishing: An Analysis
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Compatibility Risks Due to Compiler Differences&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Even when using the same GCC compiler, different versions of GCC differ in code generation, standard library support, and implementation details for C++ features. Newer GCC versions may have full support for the latest C++ standards (such as new feature modules in C++20 like coroutines), and if a program uses these advanced features and is compiled under an older GCC version, the compiler will error out due to its inability to recognize these new syntax structures. Even without syntax errors, different GCC versions have different optimization strategies, which can lead to significant differences in machine code generated in terms of execution efficiency and memory usage. In performance-critical scenarios, this can cause programs to behave differently in different environments. - &lt;strong&gt;Challenges Posed by Architectural Differences&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;C++ programs may need to run on different hardware system architectures, such as x86, ARM, and PowerPC. These architectures have unique instruction sets, memory layouts, and data alignment requirements. For example, a structure data layout that runs correctly on an x86 architecture might cause memory access exceptions on an ARM architecture due to differing alignment rules, leading to program errors. Furthermore, GCC generates significantly different machine code when compiling for various architectures; if the program contains hardcoded architectural-specific instructions or assumptions, it will inevitably fail during cross-architecture execution.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;four-strategies-for-addressing-compatibility-issues&#34;&gt;Four. Strategies for Addressing Compatibility Issues
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Utilization of Static Link Libraries&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Consider using static link libraries, packaging the code of libraries that your program depends on (such as GLIBC) directly into the executable file. This eliminates the need for the target system’s specific GLIBC version at runtime, effectively preventing issues caused by GLIBC version mismatches. However, static linking will significantly increase the size of the executable file, requiring a trade-off in resource-constrained scenarios.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Containerized Deployment&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Leveraging containerization technologies like Docker, encapsulate your C++ program and its required runtime environment (including specific versions of GCC, GLIBC, etc.) within an independent container. Regardless of the underlying operating system to which it is deployed, the container maintains consistency with the development environment, ensuring the program runs as expected and greatly simplifies cross-environment deployment complexity. - &lt;strong&gt;Compatibility Testing and Continuous Integration&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Establish a comprehensive compatibility testing system, covering different GLIBC versions, GCC versions, and common system architectures. During the software development process, use continuous integration tools to perform automated testing on various environments regularly. Once compatibility issues are identified, they are promptly fixed, eliminating potential problems at their earliest stages and ensuring stability after program deployment.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;four-strategies-for-addressing-compatibility-issues-1&#34;&gt;Four. Strategies for Addressing Compatibility Issues
&lt;/h2&gt;&lt;p&gt;As a summary, a deep understanding of the workings of GCC and GLIBC, accurately identifying the root causes of C++ compatibility issues, and flexibly applying appropriate strategies are essential skills for every C++ developer to build robust, cross-platform applications. Only in this way can our C++ works run smoothly within diverse technological ecosystems.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Linux backend services handling large volumes of string data – performance is slow.</title>
        <link>https://ttf248.life/en/p/linux-backend-slow-string-processing/</link>
        <pubDate>Wed, 13 Nov 2024 19:42:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-backend-slow-string-processing/</guid>
        <description>&lt;p&gt;In the history of C++ development projects, we utilized a custom protocol for communication, which employed a two-dimensional array pattern. When processing large volumes of data, the protocol required iterating through the arrays and performing serialization operations to generate logs. Due to its low efficiency, this resulted in noticeable lag or stuttering within the system under heavy load, as reported by the business department.&lt;/p&gt;
&lt;h2 id=&#34;problem-identification&#34;&gt;Problem Identification
&lt;/h2&gt;&lt;p&gt;When troubleshooting the issue, we first performed a performance analysis of the system and discovered that CPU utilization increased significantly when processing large amounts of data, and system response times became longer. By analyzing the system logs, we identified numerous serialization operations, which were inefficient when handling two-dimensional arrays, leading to a decline in system performance.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;pstack&lt;/code&gt; tool captured thread information for the service, pinpointing that the log threads spent most of their time processing string concatenation.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is today’s focus: different accumulation methods have significant efficiency differences. Historically, the code used the &lt;code&gt;+&lt;/code&gt; operator, which frequently creates temporary objects and is very inefficient. You know it&amp;rsquo;s bad, but you don&amp;rsquo;t know &lt;em&gt;how&lt;/em&gt; bad it is.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;demo-verification&#34;&gt;Demo Verification
&lt;/h2&gt;&lt;p&gt;Based on the project code, we extracted the business logic and wrote a simple demo to verify the efficiency issues of string concatenation. We compiled and ran it in &lt;code&gt;Release&lt;/code&gt; mode using the &lt;code&gt;vs2022&lt;/code&gt; compiler under &lt;code&gt;windows&lt;/code&gt; and the &lt;code&gt;gcc8.5&lt;/code&gt; compiler under &lt;code&gt;linux&lt;/code&gt;, comparing the efficiencies.&lt;/p&gt;
&lt;h3 id=&#34;key-points-explanation&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;p&gt;The project utilized Method Four, and before obtaining test data, readers should consider which method is most efficient and which is least efficient. I was quite surprised by the results.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Method 1 (&lt;code&gt;+=&lt;/code&gt; Concatenation)&lt;/strong&gt;: Directly concatenates each field using &lt;code&gt;+=&lt;/code&gt; to a string.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 2 (&lt;code&gt;std::ostringstream&lt;/code&gt; Concatenation)&lt;/strong&gt;: Uses a stream (&lt;code&gt;std::ostringstream&lt;/code&gt;) to concatenate each field, which is more efficient, especially when dealing with large amounts of data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 3 (Pre-allocated Memory &lt;code&gt;+=&lt;/code&gt; Concatenation)&lt;/strong&gt;: Pre-allocates enough memory for the string using &lt;code&gt;reserve&lt;/code&gt; to reduce the overhead of memory reallocation and improve performance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 4 (&lt;code&gt;bodys = bodys + body + &amp;quot;\n&amp;quot;&lt;/code&gt;)&lt;/strong&gt;: Each concatenation creates a new temporary string object, leading to performance degradation, especially with large-scale concatenations due to the allocation and copying of a new memory space each time.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Referring to the results, we can see that this method was selected as the least efficient.&lt;/p&gt;
&lt;p&gt;Furthermore, let&amp;rsquo;s analyze the optimization efficiency of different platform compilers – Microsoft’s &lt;code&gt;visual studio&lt;/code&gt; remains consistently excellent, with high string optimization efficiency, while the &lt;code&gt;gcc&lt;/code&gt; compiler lags somewhat in this regard.&lt;/p&gt;
&lt;h3 id=&#34;key-points-explanation-1&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;The code executes on different machines, and the two datasets do not have a direct comparison; instead, differences can be compared between various splicing methods.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;key-points-explanation-2&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Windows platform under Visual Studio 2022 compiler

----------------------------------------
Data Generation Time: 0.054 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.053 seconds.
+ ostringstream Data merging took: 0.054 seconds.
+ Pre-reserved Data merging took: 0.045 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 16.108 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;key-points-explanation-3&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Linux platform under GCC 8.5 compiler
----------------------------------------
Data Generation Time: 0.108 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.100 seconds.
+ ostringstream Data merging took: 0.083 seconds.
+ Pre-reserved Data merging took: 0.057 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 29.298 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;random&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;sstream&amp;gt;
#include &amp;lt;iomanip&amp;gt;

typedef std::vector&amp;lt;std::string&amp;gt; DataRow;
typedef std::vector&amp;lt;DataRow&amp;gt; DataGroup;

struct ResponsePackage
{
    std::string ErrorInfo;
    DataRow Head;
    std::string ClientId;
    std::string UUID;
    std::string MsgID;
    std::string SessionID;
    std::string ExtraInfo1;
    std::string ExtraInfo2;
    DataGroup DataBody;
};
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-1&#34;&gt;Complete Code
&lt;/h2&gt;&lt;p&gt;// Generate specified length of random string
std::string generateRandomString(size_t length)
{
const char charset[] = &amp;ldquo;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&amp;rdquo;;
const size_t max_index = sizeof(charset) - 1;
std::string random_string;
random_string.reserve(length);&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;std::random_device rd;
std::mt19937 generator(rd());
std::uniform_int_distribution&amp;lt;&amp;gt; distribution(0, max_index);
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-2&#34;&gt;Complete Code
&lt;/h2&gt;&lt;p&gt;for (size_t i = 0; i &amp;lt; length; ++i)
{
random_string += charset[distribution(generator)];
}&lt;/p&gt;
&lt;p&gt;return random_string;
}&lt;/p&gt;
&lt;p&gt;void create_large_string()
{
// Example request package with 50 fields
ResponsePackage requestPackage;&lt;/p&gt;
&lt;h2 id=&#34;complete-code-3&#34;&gt;Complete Code
&lt;/h2&gt;&lt;p&gt;requestPackage.Head = {
&amp;ldquo;Field1&amp;rdquo;, &amp;ldquo;Field2&amp;rdquo;, &amp;ldquo;Field3&amp;rdquo;, &amp;ldquo;Field4&amp;rdquo;, &amp;ldquo;Field5&amp;rdquo;,
&amp;ldquo;Field6&amp;rdquo;, &amp;ldquo;Field7&amp;rdquo;, &amp;ldquo;Field8&amp;rdquo;, &amp;ldquo;Field9&amp;rdquo;, &amp;ldquo;Field10&amp;rdquo;,
&amp;ldquo;Field11&amp;rdquo;, &amp;ldquo;Field12&amp;rdquo;, &amp;ldquo;Field13&amp;rdquo;, &amp;ldquo;Field14&amp;rdquo;, &amp;ldquo;Field15&amp;rdquo;,
&amp;ldquo;Field16&amp;rdquo;, &amp;ldquo;Field17&amp;rdquo;, &amp;ldquo;Field18&amp;rdquo;, &amp;ldquo;Field19&amp;rdquo;, &amp;ldquo;Field20&amp;rdquo;,
&amp;ldquo;Field21&amp;rdquo;, &amp;ldquo;Field22&amp;rdquo;, &amp;ldquo;Field23&amp;rdquo;, &amp;ldquo;Field24&amp;rdquo;, &amp;ldquo;Field25&amp;rdquo;,
&amp;ldquo;Field26&amp;rdquo;, &amp;ldquo;Field27&amp;rdquo;, &amp;ldquo;Field28&amp;rdquo;, &amp;ldquo;Field29&amp;rdquo;, &amp;ldquo;Field30&amp;rdquo;,
&amp;ldquo;Field31&amp;rdquo;, &amp;ldquo;Field32&amp;rdquo;, &amp;ldquo;Field33&amp;rdquo;, &amp;ldquo;Field34&amp;rdquo;, &amp;ldquo;Field35&amp;rdquo;
};&lt;/p&gt;
&lt;h2 id=&#34;complete-code-4&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;Field31&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field32&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field33&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field34&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field35&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field36&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field37&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field38&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field39&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field40&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field41&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field42&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field43&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field44&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field45&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field46&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field47&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field48&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field49&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field50&amp;quot;: &amp;quot;&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-5&#34;&gt;Complete Code
&lt;/h2&gt;&lt;p&gt;requestPackage.ClientId = &amp;ldquo;ClientID&amp;rdquo;;
requestPackage.UUID = &amp;ldquo;UUID&amp;rdquo;;
requestPackage.MsgID = &amp;ldquo;MsgID&amp;rdquo;;
requestPackage.SessionID = &amp;ldquo;SessionID&amp;rdquo;;
requestPackage.ExtraInfo1 = &amp;ldquo;ExtraInfo1&amp;rdquo;;
requestPackage.ExtraInfo2 = &amp;ldquo;ExtraInfo2&amp;rdquo;;&lt;/p&gt;
&lt;p&gt;// Start timing for data generation
auto start_gen = std::chrono::high_resolution_clock::now();&lt;/p&gt;
&lt;h2 id=&#34;complete-code-6&#34;&gt;Complete Code
&lt;/h2&gt;&lt;p&gt;// Generate 10,000 rows of data, each with 50 fields
for (size_t i = 0; i &amp;lt; 10000; ++i)
{
DataRow dataRow(50, &amp;ldquo;This is a test string&amp;rdquo;);
requestPackage.DataBody.push_back(dataRow);
}&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// End timing for data generation
auto end_gen = std::chrono::high_resolution_clock::now();
std::chrono::duration&amp;lt;double&amp;gt; duration_gen = end_gen - start_gen;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code
// Display result generation time
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Generation Time: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_gen.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    // Data merging using different methods
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Performance:\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-7&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Method 1: Using &#39;+=&#39; string concatenation
auto start_merge = std::chrono::high_resolution_clock::now();
std::string bodys(&amp;quot;&amp;quot;);
for (auto&amp;amp; vec : requestPackage.DataBody)
{
    std::string body(&amp;quot;This is a test string&amp;quot;);
    for (auto&amp;amp; item : vec)
    {
        body += item + &amp;quot; &amp;quot;;
    }
    bodys += body + &amp;quot;\n&amp;quot;;
}
auto end_merge = std::chrono::high_resolution_clock::now();
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code
}
    auto end_merge = std::chrono::high_resolution_clock::now();
    std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
    std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (+=) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-8&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Method 2: Using ostringstream
auto start_merge = std::chrono::high_resolution_clock::now();
std::ostringstream bodys;
for (auto&amp;amp; vec : requestPackage.DataBody)
{
    std::ostringstream body;
    body &amp;lt;&amp;lt; &amp;quot;This is a test string&amp;quot;;
    for (auto&amp;amp; item : vec)
    {
        body &amp;lt;&amp;lt; item &amp;lt;&amp;lt; &amp;quot; &amp;quot;;
    }
    bodys &amp;lt;&amp;lt; body.str() &amp;lt;&amp;lt; &amp;quot;\n&amp;quot;;
}
auto end_merge = std::chrono::high_resolution_clock::now();
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code
}
    auto end_merge = std::chrono::high_resolution_clock::now();
    std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
    std::cout &amp;lt;&amp;lt; &amp;quot;+ ostringstream Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code
{
        // Method 3: Pre-allocated memory
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys;
        bodys.reserve(1000 * 50 * 20); // Pre-allocate enough memory
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            body.reserve(50 * 20); // Pre-allocate memory for each row
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code

for (auto&amp;amp; item : vec) {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Pre-reserved Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-9&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;// Method 4: Using &#39;bodys = bodys + body + &amp;quot;\n&amp;quot;&#39;
auto start_merge = std::chrono::high_resolution_clock::now();
std::string bodys(&amp;quot;&amp;quot;);
for (auto&amp;amp; vec : requestPackage.DataBody)
{
    std::string body(&amp;quot;This is a test string&amp;quot;);
    for (auto&amp;amp; item : vec)
    {
        body = body + item + &amp;quot; &amp;quot;; // Note the use of &#39;body = body + item&#39;
    }
    bodys = bodys + body + &amp;quot;\n&amp;quot;; // Again, using &#39;bodys = bodys + body&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code

```cpp
        auto start_merge = std::chrono::high_resolution_clock::now();
        bodys = bodys + body + &amp;quot;\n&amp;quot;; // Again, using &#39;bodys = bodys + body&#39;
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (bodys = bodys + body + \&amp;quot;\\n\&amp;quot;) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-10&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Complete.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;
}

int main()
{
    try
    {
        create_large_string();
    }
    catch (const std::exception&amp;amp; e)
    {
        std::cerr &amp;lt;&amp;lt; &amp;quot;Caught exception: &amp;quot; &amp;lt;&amp;lt; e.what() &amp;lt;&amp;lt; std::endl;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\nProgram finished.\n&amp;quot;;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>C&#43;&#43; Lambda Expression Parameter Lifetimes</title>
        <link>https://ttf248.life/en/p/cpp-lambda-parameter-lifetime/</link>
        <pubDate>Wed, 13 Nov 2024 19:23:02 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-lambda-parameter-lifetime/</guid>
        <description>&lt;p&gt;In C++, lambda expressions are a convenient way to create anonymous functions that can capture external variables and use them within their bodies. This makes lambdas a flexible programming tool. However, the lifetime of parameters in a lambda expression is an aspect that requires particular attention, especially when capturing and passing parameters.&lt;/p&gt;
&lt;h3 id=&#34;1-lambda-expression-parameter-lifetime&#34;&gt;1. Lambda Expression Parameter Lifetime
&lt;/h3&gt;&lt;p&gt;The lifetime of parameters in a lambda expression is typically the same as that of other C++ functions. Parameters exist while the function is called, and their lifetime ends when the function call terminates. However, due to the possibility of lambdas capturing external variables, the parameter&amp;rsquo;s lifetime is also affected by how it’s captured.&lt;/p&gt;
&lt;h3 id=&#34;2-capturing-the-relationship-with-parameter-lifecycles&#34;&gt;2. Capturing the Relationship with Parameter Lifecycles
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;#### 2.1 Capturing External Variables

C++ lambda expressions allow external variables to be captured in two ways:

- **Capture by Value:** When capturing by value, the value of the external variable is copied into the lambda, and the lifetime of the copy is controlled by the lifetime of the lambda.
- **Capture by Reference:** When capturing by reference, a reference to the external variable is retained, and the lambda&#39;s reference points to the original external variable. The lifetime depends on the lifetime of the external variable.
``` ```cpp
int x = 10;
auto lambda_by_value = [x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };  // Captures a copy of x
auto lambda_by_reference = [&amp;amp;x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };  // Captures a reference to x

lambda_by_value();  // Prints 10
lambda_by_reference();  // Prints 10

For the captured variables, their lifetimes are as follows:
- **Capture by value**: When the lambda is created, a copy of the external variable x is made and stored within the lambda. When the lambda&#39;s lifetime ends, this copied value is destroyed.
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;21-capture-external-variables&#34;&gt;2.1 Capture External Variables
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;By Reference Capture:&lt;/strong&gt; The lambda holds a reference to the external variable, &lt;strong&gt;the external variable must be valid before it is used within the lambda, otherwise undefined behavior will occur.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;22-lambda-parameters&#34;&gt;2.2 Lambda Parameters
&lt;/h4&gt;&lt;p&gt;Lambda parameters are similar to regular function parameters; their lifetime is limited to the lambda function body. That is, lambda parameters are created when the lambda is called and their lifetime ends when the lambda call completes.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;auto lambda = [](int a, int b) {
    std::cout &amp;lt;&amp;lt; a + b &amp;lt;&amp;lt; std::endl;
};
lambda(5, 10);  // a and b are the parameters of the lambda here
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; are the parameters of the lambda expression, they are created when the lambda is called and destroyed after the lambda executes.&lt;/p&gt;
&lt;h3 id=&#34;3-lifecycle-issues-when-capturing-external-variables&#34;&gt;3. Lifecycle Issues When Capturing External Variables
&lt;/h3&gt;&lt;h4 id=&#34;31-whether-captured-variables-are-valid-outside-lambda&#34;&gt;3.1 Whether Captured Variables Are Valid Outside Lambda
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Value Capture&lt;/strong&gt;: Even if the external variable is destroyed after the lambda call, the lambda internally holds a copy of the external variable. Therefore, the copy within the lambda can be used safely, even if the external variable no longer exists.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int x = 10;
auto lambda = [x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };
x = 20;  // x is modified after the lambda call
lambda();  // Prints 10, captures a copy of x
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Reference Capture&lt;/strong&gt;: If the external variable is captured by reference, the lambda&amp;rsquo;s access to that reference depends on the lifetime of the external variable. If the external variable is destroyed before the lambda executes, it results in a dangling reference problem and undefined behavior. ```cpp
int x = 10;
auto lambda = &lt;a class=&#34;link&#34; href=&#34;&#34; &gt;&amp;amp;x&lt;/a&gt; { std::cout &amp;laquo; x &amp;laquo; std::endl; };
x = 20;  // x is modified before lambda execution
lambda();  // Prints 20, captures a reference to x&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;
&amp;gt; If the execution order of the lambda is uncertain, it&#39;s crucial to ensure that any external variables captured within the lambda are still valid when the lambda executes.&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Upgrading the GCC version caused program crashes: hidden issues due to code non-compliance.</title>
        <link>https://ttf248.life/en/p/gcc-upgrade-causes-program-crash-code-irregularities/</link>
        <pubDate>Sun, 10 Mar 2024 23:19:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/gcc-upgrade-causes-program-crash-code-irregularities/</guid>
        <description>&lt;p&gt;In the same business code scenario, the program compiled and ran normally in a CentOS 7 environment. However, when switching to CentOS 8 and using an updated version of GCC for compilation, the program crashed. It’s worth noting that the issue only occurs in &lt;strong&gt;Release mode&lt;/strong&gt;, while &lt;strong&gt;Debug mode&lt;/strong&gt; does not exhibit any problems. This is the first time we&amp;rsquo;ve encountered a situation like this; after three days of investigation, we finally identified the root cause.&lt;/p&gt;
&lt;h3 id=&#34;problem-identification&#34;&gt;Problem Identification
&lt;/h3&gt;&lt;p&gt;After investigation, the root cause of the issue was &lt;strong&gt;the function lacking a return value&lt;/strong&gt;. In Release mode, new versions of GCC perform more optimizations, which caused an unknown logic to occur within the function that originally did not have an explicit return value during execution, ultimately triggering a crash. Our conclusion is that &lt;strong&gt;compiler warnings should not be ignored, especially in legacy projects where some warnings may be dismissed, but it’s also important to avoid suppressing all warnings.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;environment-details&#34;&gt;Environment Details
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CentOS 7 GCC Version:&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CentOS 8 GCC Version:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;crash-phenomena&#34;&gt;Crash Phenomena
&lt;/h3&gt;&lt;p&gt;When analyzing the stack information for program crashes, we observed the following stack details:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[New LWP 1385902]
[Thread debugging using libthread_db enabled]
Using host libthread_db library &amp;quot;/lib64/libthread_db.so.1&amp;quot;.
Core was generated by `./pstack_main`.
Program terminated with signal SIGSEGV, Segmentation fault.
#0  0x00007ffe894b4420 in ?? ()
(gdb) bt
#0  0x00007ffe894b4420 in ?? ()
#1  0x00000000004008e9 in main ()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This stack doesn&amp;rsquo;t appear intuitive; the crash function’s stack information shows a &lt;code&gt;??&lt;/code&gt;, which makes troubleshooting even more complex.&lt;/p&gt;
&lt;h3 id=&#34;code-example&#34;&gt;Code Example
&lt;/h3&gt;&lt;p&gt;To better understand the issue, here’s a minimal code example that reproduces the crash:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;map&amp;gt;

int test() {
    std::cout &amp;lt;&amp;lt; &amp;quot;1&amp;quot; &amp;lt;&amp;lt; std::endl;
}

int main() {
    test();
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;test()&lt;/code&gt; function in this code clearly doesn&amp;rsquo;t explicitly return a value, and its return type is &lt;code&gt;int&lt;/code&gt;. According to the C++ standard, when a function is declared as an &lt;code&gt;int&lt;/code&gt; type, it must have a return value, otherwise it may lead to undefined behavior.&lt;/p&gt;
&lt;h3 id=&#34;compilation-warning&#34;&gt;Compilation Warning
&lt;/h3&gt;&lt;p&gt;In our project, the CMake script suppresses many compile-time warnings, including the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;/root/pstack/main.cpp: In function ‘int test()’:
/root/pstack/main.cpp:7:1: warning: no return statement in function returning non-void [-Wreturn-type]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This warning indicates that the &lt;code&gt;test()&lt;/code&gt; function does not return a value, which is the root cause of the problem. Newer versions of GCC (such as 8.5.0) may make unstable optimizations with this undefined behavior when optimizing code, potentially leading to program crashes.&lt;/p&gt;
&lt;h3 id=&#34;assembly-code-differences&#34;&gt;Assembly Code Differences
&lt;/h3&gt;&lt;p&gt;To explain the differences in GCC compiler optimization behavior, we compared assembly code generated by different versions of GCC:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GCC 4.8.5 Generated Assembly Code:&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The assembly code is relatively verbose and includes handling logic for standard output streams (such as &lt;code&gt;std::cout&lt;/code&gt;). This indicates that the compiler performed more conservative optimizations, not optimizing excessively for the missing return value issue in the &lt;code&gt;test()&lt;/code&gt; function, possibly to avoid a crash.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GCC 8.5.0 Generated Assembly Code:&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The new version of GCC performed more optimizations, reducing the code volume. However, this optimization may have resulted in undefined behavior when calling functions without returning values, leading to program crashes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h3&gt;&lt;p&gt;Through this troubleshooting process, we deeply realized that in C++, &lt;strong&gt;function return values must be explicit&lt;/strong&gt;, especially when a function is declared as &lt;code&gt;int&lt;/code&gt;, a return value must be provided. When upgrading from older versions of compilers to newer versions of GCC, more optimization and stricter warning mechanisms may be encountered. Therefore, we recommend not suppressing all warnings during compilation, but rather selectively addressing them, particularly common issues such as function return values and type matching.
Ultimately, by adding a return value to the &lt;code&gt;test()&lt;/code&gt; function, the problem was resolved, and the program returned to normal operation.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>C&#43;&#43; Programming Traps: A Detailed Explanation of Program Crashes Caused by Improper Use of `std::map`</title>
        <link>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</link>
        <pubDate>Sun, 10 Mar 2024 22:03:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</guid>
        <description>e&gt;
&lt;h2 id=&#34;body&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;In the C++ standard library, &lt;code&gt;std::map&lt;/code&gt; is an associative container that stores elements in ascending order based on their keys (key), and provides efficient keyword lookup functionality. However, novice developers sometimes find themselves in trouble due to a misunderstanding of the behavior of the square bracket operator &lt;code&gt;[]&lt;/code&gt; within &lt;code&gt;std::map&lt;/code&gt;. In fact, when using &lt;code&gt;[]&lt;/code&gt; to access a non-existent key, &lt;code&gt;std::map&lt;/code&gt; inserts a new key-value pair, and the default constructor will be used to initialize the value type associated with that key. ```cpp
#include &lt;iostream&gt;
#include &lt;map&gt;&lt;/p&gt;
&lt;p&gt;int main() {
std::map&amp;lt;std::string, int&amp;gt; myMap;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Incorrect usage: Assuming this attempts to access a non-existent key and will return 0
std::cout &amp;lt;&amp;lt; &amp;quot;Value for &#39;nonexistent_key&#39;: &amp;quot; &amp;lt;&amp;lt; myMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;

// In reality, the above line of code creates a new key-value pair, where the value is initialized to the default value for an int (usually 0)
return 0;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-##&#34;&gt;In the C++ standard library, `std::map` is an associative container that stores elements in ascending order based on their keys (key), and provides efficient keyword lookup functionality. However, novice developers sometimes find themselves in trouble due to a misunderstanding of the behavior of the square bracket operator `[]` within `std::map`. In fact, when using `[]` to access a non-existent key, `std::map` inserts a new key-value pair, and the default constructor will be used to initialize the value type associated with that key.

## Text
Although this code does not directly cause the program to crash, this implicit insertion behavior can lead to unexpected side effects in some cases, such as resource leaks or changes in state that are not expected. Worse still, concurrent access to uninitialized memory regions in a multithreaded environment can even cause the program to crash.

To prevent these issues, it is recommended to use the `std::map::find()` or `std::map::count()` methods to check if a key exists, or to utilize the `std::map::insert()` method to explicitly insert elements:

```cpp
std::map&amp;lt;std::string, int&amp;gt; safeMap;
if (safeMap.count(&amp;quot;nonexistent_key&amp;quot;) == 0) {
    std::cout &amp;lt;&amp;lt; &amp;quot;Key does not exist.&amp;quot; &amp;lt;&amp;lt; std::endl;
} else {
    std::cout &amp;lt;&amp;lt; &amp;quot;Value for existing key: &amp;quot; &amp;lt;&amp;lt; safeMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;
}

// Or explicitly insert a key-value pair, specifying the initial value
safeMap. ## Text
Although the code does not directly cause a program crash, this implicit insertion behavior can lead to unexpected side effects in some cases, such as resource leaks or changes in state that are not expected. Worse still, concurrent access to uninitialized memory regions in a multithreaded environment can even cause a program to crash.

To prevent these issues, it is recommended to use the `std::map::find()` or `std::map::count()` methods to check if a key exists, or to utilize the `std::map::insert()` method to explicitly insert elements:

```cpp
std::map&amp;lt;std::string, int&amp;gt; safeMap;
if (safeMap.count(&amp;quot;nonexistent_key&amp;quot;) == 0) {
    std::cout &amp;lt;&amp;lt; &amp;quot;Key does not exist.&amp;quot; &amp;lt;&amp;lt; std::endl;
} else {
    std::cout &amp;lt;&amp;lt; &amp;quot;Value for existing key: &amp;quot; &amp;lt;&amp;lt; safeMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;
}

// Or explicitly insert a key-value pair, specifying the initial value
safeMap.

## Text
If the objects stored within the map container are pointer types, the automatic insertion behavior will save an uninitialized pointer, and any call to this pointer will cause the program to crash.&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>C&#43;&#43; Function Call Latency</title>
        <link>https://ttf248.life/en/p/cpp-function-call-timing/</link>
        <pubDate>Wed, 24 Jan 2024 14:11:33 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-function-call-timing/</guid>
        <description>&lt;p&gt;Designed a行情 SDK, implementing different callback function implementations, and performed an extensive test. Recently I’ve been looking into C++ function programming, where functions have become first-class citizens, flowing within the program internally – what are the differences in performance?&lt;/p&gt;
&lt;p&gt;Previous article link: &lt;a class=&#34;link&#34; href=&#34;https://ttf248.life/en/p/compiler-callback-performance-testing/&#34; &gt;Compiler, Callback Functions, Performance Testing&lt;/a&gt;
&lt;code&gt;leimao&lt;/code&gt;大佬 also did similar tests, so I borrowed their code.&lt;/p&gt;
&lt;h2 id=&#34;main-content&#34;&gt;Main Content
&lt;/h2&gt;&lt;p&gt;The execution platform remains our old friend, &lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;content&#34;&gt;Content
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;cassert&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;functional&amp;gt;
#include &amp;lt;iostream&amp;gt;
#include &amp;lt;vector&amp;gt;

int add_one(int input) { return input + 1; }
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;body&#34;&gt;Body
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;int add_one(int input) { return input + 1; }

bool validate_vector_add_one(std::vector&amp;lt;int&amp;gt; const&amp;amp; input_vector,
                             std::vector&amp;lt;int&amp;gt; const&amp;amp; output_vector)
{
    bool is_valid{true};
    for (size_t i{0}; i &amp;lt; input_vector.size(); ++i)
    {
        if (output_vector.at(i) != input_vector.at(i) + 1)
        {
            is_valid = false;
            break;
        }
    }
    return is_valid;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Main Content
```cpp
void reset_vector(std::vector&amp;lt;int&amp;gt;&amp;amp; input_vector)
{
    for (size_t i{0}; i &amp;lt; input_vector.size(); ++i)
    {
        input_vector.at(i) = 0;
    }
}

template &amp;lt;typename T, typename Func&amp;gt;
void unitary_function_pass_by_lambda_function(T&amp;amp; output, T const&amp;amp; input,
                                              Func const func)
{
    output = func(input);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Body
template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_std_function_value(T&amp;amp; output, T const&amp;amp; input,
                                                 std::function&amp;lt;T(T)&amp;gt; const func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_std_function_reference(
    T&amp;amp; output, T const&amp;amp; input, std::function&amp;lt;T(T)&amp;gt; const&amp;amp; func)
{
    output = func(input);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;body-1&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;template &lt;typename T&gt;
void unitary_function_pass_by_function_pointer(T&amp;amp; output, T const&amp;amp; input,
T (*func)(T))
{
output = func(input);
}&lt;/p&gt;
&lt;p&gt;int main()
{
// Set floating point format std::cout with 3 decimal places.
std::cout.precision(3);&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;size_t const num_elements{10000000};
std::vector&amp;lt;int&amp;gt; input_vector(num_elements, 0);
std::vector&amp;lt;int&amp;gt; output_vector(num_elements, 0);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;h2 id=&#34;text&#34;&gt;Text
&lt;/h2&gt;&lt;p&gt;auto const lambda_function_add_one{[](int const&amp;amp; input) -&amp;gt; int
{ return input + 1; }};
std::function&amp;lt;int(int)&amp;gt; const std_function_add_one{lambda_function_add_one};&lt;/p&gt;
&lt;h2 id=&#34;body-2&#34;&gt;Body
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;std::cout &amp;lt;&amp;lt; &amp;quot;The size of a function pointer: &amp;quot; &amp;lt;&amp;lt; sizeof(&amp;amp;add_one)
              &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a std::function pointer: &amp;quot;
              &amp;lt;&amp;lt; sizeof(&amp;amp;std_function_add_one) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a std::function: &amp;quot; &amp;lt;&amp;lt; sizeof(std_function_add_one)
              &amp;lt;&amp;lt; std::endl;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;body-3&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;// Call function frequently in a vanilla way.
// The compiler knows what function to call at compile time and can optimize
// the code.
// This is the best performance we could get.
std::chrono::steady_clock::time_point const time_start_vanilla{
std::chrono::steady_clock::now()};
for (size_t i{0}; i &amp;lt; num_elements; ++i)
{
output_vector.at(i) = add_one(input_vector.at(i));
}
std::chrono::steady_clock::time_point const time_end_vanilla{&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Body
}
    std::chrono::steady_clock::time_point const time_end_vanilla{
        std::chrono::steady_clock::now()};
    auto const time_elapsed_vanilla{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(time_end_vanilla -
                                                             time_start_vanilla)
            .count()};
    float const latency_vanilla{time_elapsed_vanilla /
                                static_cast&amp;lt;float&amp;gt;(num_elements)};
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;text-1&#34;&gt;Text
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;static_cast&amp;lt;float&amp;gt;(num_elements)}; std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass Vanilla: &amp;quot; &amp;lt;&amp;lt; latency_vanilla &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl; assert(validate_vector_add_one(input_vector, output_vector)); reset_vector(output_vector);&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;body-4&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;// Sometimes, we don&amp;rsquo;t know what function to call at compile time.
// We can use std::function to pass a function as an argument.
// In this case, we pass the std::function by value.
// Because the size of a std::function is 32 bytes, passing by value
// results in a lot of copying and bad performance.
std::chrono::steady_clock::time_point const
time_start_pass_by_std_function_value{std::chrono::steady_clock::now()};
for (size_t i{0}; i &amp;lt; num_elements; ++i)&lt;/p&gt;
&lt;h2 id=&#34;body-5&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;for (size_t i{0}; i &amp;lt; num_elements; ++i)
{
unitary_function_pass_by_std_function_value(
output_vector.at(i), input_vector.at(i), std_function_add_one);
}
std::chrono::steady_clock::time_point const
time_end_pass_by_std_function_value{std::chrono::steady_clock::now()};
auto const time_elapsed_pass_by_std_function_value{
std::chrono::duration_cast&lt;a class=&#34;link&#34; href=&#34;std::chrono::nanoseconds&#34; &gt;std::chrono::nanoseconds&lt;/a&gt;(
time_end_pass_by_std_function_value -&lt;/p&gt;
&lt;h2 id=&#34;text-2&#34;&gt;Text
&lt;/h2&gt;&lt;p&gt;time_end_pass_by_std_function_value -
time_start_pass_by_std_function_value)
.count()};
float const latency_pass_by_std_function_value{
time_elapsed_pass_by_std_function_value /
static_cast&lt;float&gt;(num_elements)};
std::cout &amp;laquo; &amp;ldquo;Latency Pass By Std Function Value: &amp;quot;
&amp;laquo; latency_pass_by_std_function_value &amp;laquo; &amp;quot; ns&amp;rdquo; &amp;laquo; std::endl;
assert(validate_vector_add_one(input_vector, output_vector));
reset_vector(output_vector);&lt;/p&gt;
&lt;h2 id=&#34;body-6&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;// Instead of passing the std::function by value, we can pass it by
// reference (pointer). In this case, object copying is eliminated. The
// performance is better than passing the std::function by value. However,
// the performance is still not as good as the vanilla way.
std::chrono::steady_clock::time_point const
time_start_pass_by_std_function_reference{
std::chrono::steady_clock::now()};
for (size_t i{0}; i &amp;lt; num_elements; ++i)&lt;/p&gt;
&lt;h2 id=&#34;text-3&#34;&gt;Text
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;std::chrono::steady_clock::now();&lt;/code&gt;
for (size_t i{0}; i &amp;lt; num_elements; ++i)
{
unitary_function_pass_by_std_function_reference(
output_vector.at(i), input_vector.at(i), std_function_add_one);
}
std::chrono::steady_clock::time_point const
time_end_pass_by_std_function_reference{
std::chrono::steady_clock::now()};
auto const time_elapsed_pass_by_std_function_reference{
std::chrono::duration_cast&lt;a class=&#34;link&#34; href=&#34;std::chrono::nanoseconds&#34; &gt;std::chrono::nanoseconds&lt;/a&gt;(&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Body
std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_std_function_reference -
            time_start_pass_by_std_function_reference)
            .count()};
    float const latency_pass_by_std_function_reference{
        time_elapsed_pass_by_std_function_reference /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Std Function Reference: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_std_function_reference &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;body-7&#34;&gt;Body
&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;&amp;lt; &amp;quot;ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;body-8&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;// &lt;code&gt;std::function&lt;/code&gt; is a general-purpose wrapper for function pointers,
// callable objects, and lambda functions. Because it&amp;rsquo;s general purpose,
// it’s not as efficient as a function pointer. In this case, we pass a
// function pointer to a function. The performance is better than passing
// the &lt;code&gt;std::function&lt;/code&gt; by reference.
std::chrono::steady_clock::time_point const
time_start_pass_by_function_pointer{std::chrono::steady_clock::now()};&lt;/p&gt;
&lt;h2 id=&#34;text-4&#34;&gt;Text
&lt;/h2&gt;&lt;p&gt;time_start_pass_by_function_pointer{std::chrono::steady_clock::now()};
for (size_t i{0}; i &amp;lt; num_elements; ++i)
{
unitary_function_pass_by_function_pointer(output_vector.at(i),
input_vector.at(i), &amp;amp;add_one);
}
std::chrono::steady_clock::time_point const
time_end_pass_by_function_pointer{std::chrono::steady_clock::now()};
auto const time_elapsed_pass_by_function_pointer{&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Body
auto const time_elapsed_pass_by_function_pointer{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_function_pointer -
            time_start_pass_by_function_pointer)
            .count()};
    float const latency_pass_by_function_pointer{
        time_elapsed_pass_by_function_pointer /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Function Pointer: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_function_pointer &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;body-9&#34;&gt;Body
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;&amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; latency_pass_by_function_pointer &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;body-10&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;// We can also pass a lambda function to a function.
// The compiler knows what function to call at compile time and can optimize
// the code. The performance is also better than passing the std::function
// by reference.
std::chrono::steady_clock::time_point const
time_start_pass_by_lambda_function{std::chrono::steady_clock::now()};
for (size_t i{0}; i &amp;lt; num_elements; ++i)
{
unitary_function_pass_by_lambda_function(&lt;/p&gt;
&lt;h2 id=&#34;text-5&#34;&gt;Text
&lt;/h2&gt;&lt;p&gt;for (size_t i{0}; i &amp;lt; num_elements; ++i)
{
unitary_function_pass_by_lambda_function(
output_vector.at(i), input_vector.at(i), lambda_function_add_one);
}
std::chrono::steady_clock::time_point const
time_end_pass_by_lambda_function{std::chrono::steady_clock::now()};
auto const time_elapsed_pass_by_lambda_function{
std::chrono::duration_cast&lt;a class=&#34;link&#34; href=&#34;std::chrono::nanoseconds&#34; &gt;std::chrono::nanoseconds&lt;/a&gt;(
time_end_pass_by_lambda_function -&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Main Body
time_end_pass_by_lambda_function -
            time_start_pass_by_lambda_function)
            .count();
float const latency_pass_by_lambda_function{
        time_elapsed_pass_by_lambda_function /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Lambda Function: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_lambda_function &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
assert(validate_vector_add_one(input_vector, output_vector));
reset_vector(output_vector);
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;body-11&#34;&gt;Body
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# The default optimization for the team is to enable O2, and the compiler selected was gcc13. Performance and execution times vary slightly between different versions of gcc, with higher versions resulting in better lambda performance.
# Function pointer size: 8
# std::function pointer size: 8
# std::function size: 32
# Vanilla Pass Latency: 0.418 ns
# Latency Pass By Std Function Value: 3.47 ns
# Latency Pass By Std Function Reference: 1.36 ns
# Latency Pass By Function Pointer: 0.396 ns
# Latency Pass By Lambda Function: 0.44 ns
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leimao.github.io/blog/CPP-Function-Call-Performance/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://leimao.github.io/blog/CPP-Function-Call-Performance/&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>C11: sleep for vs yield</title>
        <link>https://ttf248.life/en/p/c11-sleep-for-vs-yield/</link>
        <pubDate>Tue, 20 Sep 2022 20:54:51 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/c11-sleep-for-vs-yield/</guid>
        <description>&lt;p&gt;While reviewing the code, &lt;code&gt;std::this_thread::yield()&lt;/code&gt; suddenly popped into my view, a syntax sugar from &lt;code&gt;C11&lt;/code&gt; that I’d used quite a bit, but hadn&amp;rsquo;t noticed before.&lt;/p&gt;
&lt;p&gt;I didn&amp;rsquo;t consult the manual; first, I thought it had something to do with asynchronous operations – the word was used in the coroutine implementation of the Boost library.  Clearly, it wasn&amp;rsquo;t related to coroutines; it’s about controlling logic within a regular thread.&lt;/p&gt;
&lt;h2 id=&#34;documentation&#34;&gt;Documentation
&lt;/h2&gt;&lt;h3 id=&#34;yield&#34;&gt;yield
&lt;/h3&gt;&lt;p&gt;The accuracy of this function depends on the implementation, particularly the OS scheduler mechanism and system state used. For example, the First-Come, First-Served (FCFS) real-time scheduler (Linux’s SCHED_FIFO) will suspend the current thread and place it at the end of the queue for other threads with the same priority that are ready to run (and has no effect if there are no other threads with the same priority).&lt;/p&gt;
&lt;h3 id=&#34;sleep_for&#34;&gt;sleep_for
&lt;/h3&gt;&lt;p&gt;Blocks the current thread&amp;rsquo;s execution for at least the specified &lt;code&gt;sleep_duration&lt;/code&gt;.
This function may block longer than &lt;code&gt;sleep_duration&lt;/code&gt; due to scheduling or resource contention delays.
The standard library recommends measuring durations using a monotonic clock. If implementing with system time instead, waiting times may be sensitive to clock adjustments.&lt;/p&gt;
&lt;h3 id=&#34;analysis&#34;&gt;Analysis
&lt;/h3&gt;&lt;p&gt;Both functions are designed to release the current thread and allow it to no longer occupy a thread, with the actual effect depending on the platform situation. I’m still a bit confused at this point, so let&amp;rsquo;s run the code to see the execution results.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ThinkPad laptop (Visual Studio Community 2022), Tencent Cloud S2 Standard Server (gcc8.5)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;analysis-1&#34;&gt;Analysis
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Execution Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First/us&lt;/th&gt;
&lt;th&gt;Second/us&lt;/th&gt;
&lt;th&gt;Third/us&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h3 id=&#34;analysis-2&#34;&gt;Analysis
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Execution Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First Time / us&lt;/th&gt;
&lt;th&gt;Second Time / us&lt;/th&gt;
&lt;th&gt;Third Time / us&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h3 id=&#34;analysis-3&#34;&gt;Analysis
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Execution Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First/us&lt;/th&gt;
&lt;th&gt;Second/us&lt;/th&gt;
&lt;th&gt;Third/us&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h3 id=&#34;analysis-4&#34;&gt;Analysis
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Execution Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First/us&lt;/th&gt;
&lt;th&gt;Second/us&lt;/th&gt;
&lt;th&gt;Third/us&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h3 id=&#34;analysis-5&#34;&gt;Analysis
&lt;/h3&gt;&lt;p&gt;From the running results, it’s not difficult to understand that due to differences in operating system implementations, the stability of high-precision sleep varies greatly. If you want high-precision sleep, using &lt;code&gt;yield&lt;/code&gt; is more appropriate.&lt;/p&gt;
&lt;p&gt;When the time precision is increased to &lt;code&gt;ms&lt;/code&gt;, the difference between them is no longer significant.&lt;/p&gt;
&lt;h3 id=&#34;analysis-6&#34;&gt;Analysis
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;thread&amp;gt;

// Suggest other threads run for a short period of &amp;quot;busy sleeping&amp;quot;
void little_sleep(std::chrono::microseconds us)
{
    auto start = std::chrono::high_resolution_clock::now();
    auto end = start + us;
    do {
        std::this_thread::yield();
    } while (std::chrono::high_resolution_clock::now() &amp;lt; end);
}

int main()
{
    auto start = std::chrono::high_resolution_clock::now();

    little_sleep(std::chrono::microseconds(100));
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;### Analysis
little_sleep(std::chrono::microseconds(100));
    std::this_thread::sleep_for(std::chrono::microseconds(100));

    auto elapsed = std::chrono::high_resolution_clock::now() - start;
    std::cout &amp;lt;&amp;lt; &amp;quot;waited for &amp;quot;
              &amp;lt;&amp;lt; std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(elapsed).count()
              &amp;lt;&amp;lt; &amp;quot; microseconds\n&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Why Do We Need to Learn a New Language?</title>
        <link>https://ttf248.life/en/p/why-learn-a-new-language/</link>
        <pubDate>Thu, 04 Aug 2022 11:27:30 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/why-learn-a-new-language/</guid>
        <description>&lt;p&gt;Starting from my academic years, I’ve been working with &lt;code&gt;C++&lt;/code&gt; for over ten years. So, why do I need to learn other programming languages?&lt;/p&gt;
&lt;p&gt;Work experience: Lacking experience in elegant module design, &lt;code&gt;C++&lt;/code&gt; syntax is freeform. Learning other languages helps guide me to write more elegant designs.&lt;/p&gt;
&lt;p&gt;I frequently use it when developing some tools. The same design principles apply to the design of low-level libraries and business modules.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Standard Library Container Memory Allocators: allocator</title>
        <link>https://ttf248.life/en/p/standard-library-container-memory-allocator/</link>
        <pubDate>Mon, 30 Dec 2019 13:26:19 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/standard-library-container-memory-allocator/</guid>
        <description>&lt;p&gt;A custom allocator can improve performance, increase memory utilization efficiency, and address the issue of frequent, small memory allocations.&lt;/p&gt;
&lt;h4 id=&#34;antecedent&#34;&gt;Antecedent
&lt;/h4&gt;&lt;p&gt;Recently, I&amp;rsquo;ve been working on the development of network data packets, requiring frequent allocation and release of small blocks of memory. Initially, I considered using a memory pool, reviewing several existing ones and discovering this:
&lt;a class=&#34;link&#34; href=&#34;https://github.com/cacay/MemoryPool&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/cacay/MemoryPool&lt;/a&gt;
When looking at the interface, I was quite puzzled by how the memory pool&amp;rsquo;s implementation was a bit strange. The &lt;code&gt;MemoryPool&lt;/code&gt; implementation logic involves allocating fixed-size memory blocks. Having reviewed Boost’s memory pool interface, it provides a template that is instantiated when used. Fortunately, this library already had an article describing it, mentioning the concept of an &lt;code&gt;allocator&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;#### [wiki](https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_(C%2B%2B))

In C++ programming, an allocator is a key component of the C++ standard library. The C++ library defines various data structures commonly referred to as &amp;quot;containers&amp;quot; (such as linked lists, sets, etc.). A common feature of these containers is that their size can be changed at runtime; therefore, dynamic memory allocation is necessary to achieve this. The allocator is used to handle memory allocation and deallocation requests made by the containers. In other words, the allocator encapsulates the low-level details of memory management for standard template library (STL) containers. By default, the C++ standard library uses its built-in generic allocator, but programmers can customize allocators to replace it as needed.
``` The allocator was originally invented by Alexander Stepanov as part of the C++ Standard Template Library (STL) as a way to “make the library more flexible and independent of the underlying data model,” allowing programmers to use custom pointer and reference types within the library. However, when the STL was incorporated into the C++ standard, the C++ standards committee realized that full abstraction of the data model would lead to unacceptable performance penalties. To compromise, restrictions on allocators in the standard became much stricter, and as a result, the degree to which allocators can be customized is now greatly limited compared to Stepanov’s original vision.

```markdown
#### [wiki](https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_(C%2B%2B))
Although customization of the allocator is limited, it is still often necessary to use a custom allocator in many cases, typically for encapsulating access to different types of memory spaces (such as shared memory and reclaimed memory), or for improving performance when using memory pools. Furthermore, from the perspectives of memory usage and execution time, introducing a dedicated allocator for programs that frequently perform small amounts of memory allocation can also be beneficial.
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;usage-requirementshttpszhwikipediaorgwikie58886e9858de599a8_c2b2b&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Usage Requirements&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;Defining custom allocators primarily aims to improve performance. Utilizing a dedicated custom allocator can enhance program performance, or improve memory usage efficiency, or both [4][8]. The default allocator uses the &lt;code&gt;new&lt;/code&gt; operator to allocate storage [Reference 5], which often leverages the C language heap allocation function (malloc()) [9]. Because heap allocation functions are typically optimized for occasional large memory allocations, the default allocator generally performs well when allocating memory for containers that require a single large memory allocation, such as vectors and doubly-ended queues [8]. However, when using the default allocator to allocate memory for associative containers with linked lists or bidirectional linked lists – which frequently require allocating small amounts of memory – it is typically inefficient [4][9].&lt;/p&gt;
&lt;h4 id=&#34;usage-requirementshttpsenwikipediaorgwikipool_allocation_c2b2b&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Pool_allocation_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Usage Requirements&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;In short, this section (…)(like) is a “I Have a Dream” speech for the allocator. Before the dream comes true, programmers concerned with portability will be limited to (using) stateless custom allocators.
—Scott Meyers, &lt;em&gt;Effective STL&lt;/em&gt;
Given this, in this case, memory pools are often used to address frequent, small allocations [8]. Unlike the default “on-demand allocation” method, when using a memory pool allocator, the program pre-allocates large blocks of memory (referred to as the “memory pool”) upfront.  Then, when requesting memory, the custom allocator simply returns a pointer to an available block within the pool. Unlike object deconstruction, where memory is not actually released, this release is deferred until the lifecycle of the memory pool ends [Note 1][8].&lt;/p&gt;
&lt;h4 id=&#34;usage-requirementshttpszhwikipediaorgwikie58886e9858de599a8_c2b2b-1&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Usage Requirements&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;On the topic of &amp;ldquo;Custom Allocators,&amp;rdquo; numerous C++ experts and authors have participated in discussions, such as Scott Meyers&amp;rsquo; &lt;em&gt;Effective STL&lt;/em&gt; and Andrei Alexandrescu’s &lt;em&gt;Modern C++ Design&lt;/em&gt;, which both mention it. Meyers observed that if one requires all instances of a particular type &lt;code&gt;T&lt;/code&gt;’s allocator to be equal, then the portable allocator instance must not contain state. Although the C++ standard encourages library implementers to support stateful allocators [Ref 4], Meyers called this paragraph “(seemingly) a wonderful idea,” but it is almost nonsense, and he considered the allocator restrictions “too strict” [4]. For example, STL’s list allows the splice method, meaning a node from one list object A can be directly inserted into another list object B. This requires that the memory allocated by A’s allocator is released by B’s allocator, thereby deducing that A and B’s allocator instances must be equal. Meyer’s conclusion is that allocators should be defined as types using static methods. For example, according to the C++ standard, an allocator must provide a class template other that implements the rebind method.&lt;/p&gt;
&lt;h4 id=&#34;usage-requirementshttpszhwikipediaorgwikie58886e9858de599a8_c2b2b-2&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Usage Requirements&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;Additionally, in &lt;em&gt;The C++ Programming Language&lt;/em&gt; by Bjarne Stroustrup, he states “&amp;lsquo;strict allocation to avoid different information for each object,&amp;rsquo; this is clearly not an issue” (roughly), and notes that most allocators don’t need state, or even perform better when there is no state. He proposes three custom allocator use cases: a pool-based allocator, a shared memory allocator, and a garbage collector allocator, and demonstrates an implementation using an internal memory pool to quickly allocate/deallocate small amounts of memory. However, he also notes that such optimization may already be achieved in the sample allocator he provides [3].
Another use for custom allocators is debugging memory-related errors [10]. To achieve this, you can write a memory allocator that allocates additional memory when allocating, and uses it to store debugging information. This allocator not only ensures that memory is allocated/deallocated by the same type of allocator, but also provides some protection against cache overflows [11].&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>

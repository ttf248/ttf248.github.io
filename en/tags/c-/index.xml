<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>C&#43;&#43; on Uncle Xiang&#39;s Notebook</title>
        <link>https://ttf248.life/en/tags/c-/</link>
        <description>Recent content in C&#43;&#43; on Uncle Xiang&#39;s Notebook</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Sun, 25 May 2025 02:57:45 +0800</lastBuildDate><atom:link href="https://ttf248.life/en/tags/c-/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>C&#43;&#43; Bitwise Operations Basics: Bit Extraction and Flag Setting</title>
        <link>https://ttf248.life/en/p/cpp-bitwise-operations-basics-flags/</link>
        <pubDate>Fri, 17 Jan 2025 02:23:56 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-bitwise-operations-basics-flags/</guid>
        <description>&lt;p&gt;In practical C++ development, bit operations are a common technique, especially when dealing with system states, flags, or control bits. Bit operations can provide very efficient solutions. This article will explain how to use bit operations to get and set specific flag bits through an example.&lt;/p&gt;
&lt;h3 id=&#34;basic-operating-concepts&#34;&gt;Basic operating concepts
&lt;/h3&gt;&lt;p&gt;In computers, data is stored in binary digits (bits) of 0 and 1. Bitwise operations are operations performed on these binary digits. C++ has several commonly used bitwise operators:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bitwise AND (&amp;amp;): Used to check if a bit is 1&lt;/li&gt;
&lt;li&gt;Bitwise OR (|): Used to set a bit to 1&lt;/li&gt;
&lt;li&gt;XOR (exclusive OR) by bit: Used to invert a specific bit&lt;/li&gt;
&lt;li&gt;Bitwise NOT (~) : Inverts all bits&lt;/li&gt;
&lt;li&gt;Shift all bits left by several positions&lt;/li&gt;
&lt;li&gt;Shifts all bits to the right by several positions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this example, we need to perform a series of bit operations on an &lt;code&gt;unsigned short&lt;/code&gt; type variable &lt;code&gt;wInfo&lt;/code&gt;, using different flag bits to represent different states&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;flowchart LR
    A[原始数值: 00010000] --&amp;gt; B[左移: 00010000 &amp;lt;&amp;lt; 1]
    B --&amp;gt; C[结果: 00100000]
    C --&amp;gt; D[右移: 00100000 &amp;gt;&amp;gt; 1]
    D --&amp;gt; E[结果: 00010000]

    subgraph 左移操作
        direction LR
        A --&amp;gt; B --&amp;gt; C
    end

    subgraph 右移操作
        direction LR
        C --&amp;gt; D --&amp;gt; E
    end
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;requirements-analysis&#34;&gt;Requirements Analysis
&lt;/h3&gt;&lt;p&gt;According to the description in the question, we have a 16-bit flag used to represent different states. These states are represented by various binary bits, each corresponding to a specific meaning. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Has bit0 failed?&lt;/li&gt;
&lt;li&gt;Is bit1 compressed?&lt;/li&gt;
&lt;li&gt;Is bit2 incremental?&lt;/li&gt;
&lt;li&gt;Does bit3 have any follow-up packages?&lt;/li&gt;
&lt;li&gt;Normal request or logout&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;implement-using-bit-operations&#34;&gt;Implement using bit operations
&lt;/h3&gt;&lt;p&gt;We will use bit operations to set and get these flag bits. Specifically:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Extracting bit values: Obtain the value of a specific bit (0 or 1)&lt;/li&gt;
&lt;li&gt;Set a bit to 1&lt;/li&gt;
&lt;li&gt;Set a bit to 0&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We first define an &lt;code&gt;unsigned short&lt;/code&gt; type variable &lt;code&gt;wInfo&lt;/code&gt; to store these flags. Then, we use bit operations to check and set the corresponding flags.&lt;/p&gt;
&lt;h3 id=&#34;c-example-code&#34;&gt;C++ example code
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;bitset&amp;gt;

// 定义标志位常量
const unsigned short BIT_0_FAIL = 1 &amp;lt;&amp;lt; 0;    // bit0 是否失败
const unsigned short BIT_1_COMPRESSED = 1 &amp;lt;&amp;lt; 1; // bit1 是否压缩
const unsigned short BIT_2_INCREMENT = 1 &amp;lt;&amp;lt; 2;  // bit2 是否增量
const unsigned short BIT_3_HAS_MORE = 1 &amp;lt;&amp;lt; 3;   // bit3 是否有后续包
const unsigned short BIT_5_CANCEL = 1 &amp;lt;&amp;lt; 5;     // bit5 正常请求(0)或注销(1)

// 检查某一位是否为1
bool isBitSet(unsigned short wInfo, unsigned short bitMask) {
    return (wInfo &amp;amp; bitMask) != 0;
}

// 设置某一位为1
void setBit(unsigned short&amp;amp; wInfo, unsigned short bitMask) {
    wInfo |= bitMask;
}

// 清除某一位（设置为0）
void clearBit(unsigned short&amp;amp; wInfo, unsigned short bitMask) {
    wInfo &amp;amp;= ~bitMask;
}

int main() {
    // 假设wInfo的初始值为0
    unsigned short wInfo = 0;

    // 设置bit0（失败标志）
    setBit(wInfo, BIT_0_FAIL);
    
    // 设置bit1（压缩标志）
    setBit(wInfo, BIT_1_COMPRESSED);
    
    // 打印wInfo的二进制值
    std::cout &amp;lt;&amp;lt; &amp;quot;wInfo (in binary): &amp;quot; &amp;lt;&amp;lt; std::bitset&amp;lt;16&amp;gt;(wInfo) &amp;lt;&amp;lt; std::endl;

    // 检查各个标志位
    std::cout &amp;lt;&amp;lt; &amp;quot;bit0 (是否失败): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_0_FAIL) ? &amp;quot;是&amp;quot; : &amp;quot;否&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit1 (是否压缩): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_1_COMPRESSED) ? &amp;quot;是&amp;quot; : &amp;quot;否&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit2 (是否增量): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_2_INCREMENT) ? &amp;quot;是&amp;quot; : &amp;quot;否&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit3 (是否有后续包): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_3_HAS_MORE) ? &amp;quot;是&amp;quot; : &amp;quot;否&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit5 (是否注销): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_5_CANCEL) ? &amp;quot;是&amp;quot; : &amp;quot;否&amp;quot;) &amp;lt;&amp;lt; std::endl;

    // 清除bit1（压缩标志）
    clearBit(wInfo, BIT_1_COMPRESSED);
    
    // 打印更新后的wInfo
    std::cout &amp;lt;&amp;lt; &amp;quot;Updated wInfo (in binary): &amp;quot; &amp;lt;&amp;lt; std::bitset&amp;lt;16&amp;gt;(wInfo) &amp;lt;&amp;lt; std::endl;

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Execute code, recommended by an old friend: &lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;wInfo (in binary): 0000000000000011
bit0 (是否失败): 是
bit1 (是否压缩): 是
bit2 (是否增量): 否
bit3 (是否有后续包): 否
bit5 (是否注销): 否
Updated wInfo (in binary): 0000000000000001
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;code-explanation&#34;&gt;Code explanation
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Flag bits are defined using bit shift operations (&lt;code&gt;1 &amp;lt;&amp;lt; n&lt;/code&gt;). For example, &lt;code&gt;1 &amp;lt;&amp;lt; 0&lt;/code&gt; corresponds to &lt;code&gt;bit0&lt;/code&gt;, &lt;code&gt;1 &amp;lt;&amp;lt; 1&lt;/code&gt; corresponds to &lt;code&gt;bit1&lt;/code&gt;, and so on. This assigns a unique binary position to each flag bit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;code&gt;isBitSet&lt;/code&gt; function checks if a specific flag is set to 1 by performing a bitwise AND operation &lt;code&gt;wInfo &amp;amp; bitMask&lt;/code&gt;. If the bit is 1, the function returns &lt;code&gt;true&lt;/code&gt;; otherwise, it returns &lt;code&gt;false&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;code&gt;setBit&lt;/code&gt; function sets a specific flag to 1 using a bitwise OR operation &lt;code&gt;wInfo |= bitMask&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;code&gt;clearBit&lt;/code&gt; function sets a specific flag to 0 using a bitwise AND operation: &lt;code&gt;wInfo &amp;amp;= ~bitMask&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary
&lt;/h3&gt;&lt;p&gt;Through bit manipulation, we can efficiently handle multiple status flag bits. This technique is particularly useful in practical development. For example, it is often used in scenarios such as embedded development, network protocols, and system state management, where bit flags are used to represent multiple binary states, saving space and improving efficiency.&lt;/p&gt;
&lt;p&gt;I hope this blog helps you understand how to use bitwise operations in C++ to achieve bit extraction and setting. Mastering these skills is very helpful for writing efficient and maintainable code!&lt;/p&gt;</description>
        </item>
        <item>
        <title>Understanding GCC, GLIBC, and C&#43;&#43; Program Compatibility Issues</title>
        <link>https://ttf248.life/en/p/deep-understanding-gcc-glibc-cpp-compatibility-issues/</link>
        <pubDate>Mon, 06 Jan 2025 19:51:16 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/deep-understanding-gcc-glibc-cpp-compatibility-issues/</guid>
        <description>&lt;p&gt;In the field of C++ development, GCC and GLIBC are two indispensable key elements, and compatibility issues after program release often trouble developers. This article will deeply analyze their essence, explore the root causes of compatibility problems, and discuss coping strategies.&lt;/p&gt;
&lt;h2 id=&#34;i-gcc-a-powerful-compiler-foundation&#34;&gt;I. GCC: A Powerful Compiler Foundation
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Definition and Function&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GCC, which stands for GNU Compiler Collection, is an open-source compiler suite developed by the GNU project. It&amp;rsquo;s far from a typical compiler; it supports various mainstream languages including C, C++, Objective-C, Fortran, Ada, and Go, providing a one-stop solution for cross-language development.&lt;/li&gt;
&lt;li&gt;For example, with C++, when we write a source file containing complex features such as classes, templates, and function overloading, GCC can convert the high-level C++ code into an instruction sequence that the underlying machine can understand and execute, based on C++&amp;rsquo;s strict syntax and semantic rules. This process involves multiple fine-grained stages including lexical analysis, syntactic analysis, semantic analysis, optimization, and code generation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compilation Process Explained&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The preprocessing stage: GCC first performs preprocessing on the source file. During this period, it handles all directives that begin with &lt;code&gt;#&lt;/code&gt;. For example, the &lt;code&gt;#include&lt;/code&gt; directive embeds the entire content of the specified header file (such as &lt;code&gt;&amp;lt;iostream&amp;gt;&lt;/code&gt; for C++ input/output stream operations) into the corresponding position in the source file, allowing the program to use the functions, classes, and other resources declared in the header file; macros defined by the &lt;code&gt;#define&lt;/code&gt; directive are also expanded and replaced at this stage. For example, &lt;code&gt;#define PI 3.14159&lt;/code&gt;; all occurrences of &lt;code&gt;PI&lt;/code&gt; in the source file will be replaced with &lt;code&gt;3.14159&lt;/code&gt;. After preprocessing, the source file is initially “expanded.”&lt;/li&gt;
&lt;li&gt;The compilation stage: The preprocessed file enters the compilation link, where GCC, based on the C++ language standard, converts the source file into assembly language code. It carefully checks the code structure to ensure correct class inheritance, polymorphism implementation, and function call parameter matching. If it finds any errors that do not conform to syntax or semantics, it will promptly report an error and terminate the compilation process. For example, if there is a mismatch between the function declaration and definition&amp;rsquo;s parameter list, GCC will precisely point out the problem.&lt;/li&gt;
&lt;li&gt;The assembly phase: The assembler converts the assembly code generated in the previous step into machine code, producing target files with a &lt;code&gt;.o&lt;/code&gt; extension. These target files contain binary instructions that can be directly executed by the machine, but they cannot run independently because a complete program typically consists of multiple modules with unresolved function and variable references between them.&lt;/li&gt;
&lt;li&gt;The linking phase: This is the final sprint stage in generating an executable file. The linker integrates multiple object files and required library files (static or dynamic libraries) together. For example, when we use container classes from the C++ Standard Template Library, the linker needs to find the corresponding library implementation code during linking to ensure that the program can correctly call the functions of &lt;code&gt;vector&lt;/code&gt;, &lt;code&gt;list&lt;/code&gt; and other containers at runtime, ultimately generating a complete executable program.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;ii-glibc-the-behind-the-scenes-pillar-for-c-program-execution&#34;&gt;II. GLIBC: The Behind-the-Scenes Pillar for C++ Program Execution
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Essence and Function
&lt;ul&gt;
&lt;li&gt;GLIBC, or the GNU C Library, is a specific implementation of the C standard library within the GNU ecosystem. Although the name highlights its connection to C, C++ programs are equally reliant on it because C++ inherits the foundational aspects of C. It provides a vast number of basic functions, such as &lt;code&gt;malloc&lt;/code&gt; (dynamic memory allocation) and &lt;code&gt;free&lt;/code&gt; (memory release), which are essential when creating dynamic arrays and objects in C++; string processing functions like &lt;code&gt;strcpy&lt;/code&gt; (string copy) and &lt;code&gt;strcat&lt;/code&gt; (string concatenation), even though C++ has more advanced &lt;code&gt;string&lt;/code&gt; classes, are still used for interacting with C code at a lower level or pursuing extreme performance; and standard input/output functions such as &lt;code&gt;printf&lt;/code&gt; and &lt;code&gt;scanf&lt;/code&gt;, which frequently appear in early C++ development and in scenarios that are sensitive to performance and prioritize simplicity.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Coordination with the operating system
&lt;ul&gt;
&lt;li&gt;GLIBC acts as a crucial bridge between the operating system and applications. In Linux systems, when a C++ program makes a system call, such as opening a file (using the &lt;code&gt;open&lt;/code&gt; function, which relies on GLIBC implementation), GLIBC encapsulates the program&amp;rsquo;s request in a way that the operating system kernel expects and passes it to the kernel. After the kernel processes the request, GLIBC returns the result to the application. It allows applications to use various system resources, such as file systems, networks, and process management functions, conveniently without needing to understand the complex details of the underlying system call interfaces of the operating system.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;iii-analysis-of-compatibility-issues-after-c-program-release&#34;&gt;III. Analysis of Compatibility Issues After C++ Program Release
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Compatibility Issues Caused by GLIBC Version Differences
&lt;ul&gt;
&lt;li&gt;Different Linux distributions often use different versions of GLIBC. When a C++ program is compiled in a high-version GLIBC environment, it may inadvertently use certain new features or rely on more optimized function implementations added in that version. For example, newer GLIBC versions have improved memory allocation algorithms, and programs frequently take advantage of these new algorithms to improve performance at runtime. Once this program is ported to a system with an older GLIBC version, it may encounter issues such as missing functions (because the function was not introduced in the older version) or abnormal function behavior (due to discrepancies between the old and new implementations), leading to program crashes or incorrect results.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Compatibility issues caused by compiler differences
&lt;ul&gt;
&lt;li&gt;Even when using the same GCC compiler, different versions of GCC can vary in code generation, standard library support, and implementation details regarding C++ features. Newer GCC versions may offer complete support for the latest C++ standards (such as new features like modules and coroutines in C++20). If a program utilizes these cutting-edge features and is compiled under an older version of GCC, the compiler will report errors due to its inability to recognize these new syntax structures; even if there are no syntax errors, different optimization strategies across GCC versions can result in machine code that differs significantly in execution efficiency and memory usage. This difference can lead to vastly different program behavior in demanding performance scenarios.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Challenges Brought by System Architecture Differences
&lt;ul&gt;
&lt;li&gt;C++ programs may need to run on different hardware system architectures, such as x86, ARM, and PowerPC. Different architectures have their own unique instruction sets, memory layouts, and data alignment requirements. For example, the storage layout of a structure that runs normally on the x86 architecture can cause abnormal memory access and subsequent program errors on the ARM architecture due to different alignment rules; moreover, the machine code generated by GCC when compiling for different architectures differs greatly. If the program contains hardcoded architecture-specific instructions or assumptions, cross-architecture runtime failures are inevitable.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;strategies-for-addressing-compatibility-issues&#34;&gt;Strategies for Addressing Compatibility Issues
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;The Use of Static Link Libraries
&lt;ul&gt;
&lt;li&gt;Consider using a static library, which directly packages the code of libraries such as GLIBC that the program depends on into the executable file. This eliminates the program&amp;rsquo;s dependence on a specific version of GLIBC on the target system, effectively avoiding issues caused by GLIBC version mismatches. However, static linking significantly increases the size of the executable file and requires weighing the pros and cons in scenarios with limited storage resources.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Containerized Deployment
&lt;ul&gt;
&lt;li&gt;By leveraging containerization technologies like Docker, the C++ program and its required runtime environment (including specific versions of GCC, GLIBC, etc.) are encapsulated within a standalone container. Regardless of the underlying operating system it is deployed on, the container consistently maintains the environment as it was during development, ensuring the program runs as expected and greatly simplifying cross-environment deployment complexity.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Compatibility Testing and Continuous Integration
&lt;ul&gt;
&lt;li&gt;Establish a comprehensive compatibility testing system covering different GLIBC versions, GCC versions, and common system architectures. During the development process, use continuous integration tools to regularly perform automated tests in multiple environments. Address any compatibility issues promptly to eliminate potential risks at their inception and ensure stability after program launch.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In conclusion, a deep understanding of the workings of GCC and GLIBC, an accurate grasp of the root causes of C++ program compatibility issues, and the ability to apply appropriate strategies are essential skills for every C++ developer aiming to build robust, cross-platform applications. Only in this way can our C++ works navigate diverse technical ecosystems smoothly.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Slow efficiency when processing large string data in Linux backend services</title>
        <link>https://ttf248.life/en/p/linux-backend-slow-string-processing/</link>
        <pubDate>Wed, 13 Nov 2024 19:42:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-backend-slow-string-processing/</guid>
        <description>&lt;p&gt;In C++ development projects, we used a custom protocol for communication that adopted a two-dimensional array pattern. When processing large amounts of data, the protocol needed to traverse and serialize arrays internally to generate logs. Due to low efficiency, this caused noticeable lag in the system under high load, which was reported by the business department.&lt;/p&gt;
&lt;h2 id=&#34;problem-identification&#34;&gt;Problem identification
&lt;/h2&gt;&lt;p&gt;When troubleshooting the issue, we first performed a performance analysis of the system and found that the CPU utilization increased significantly when processing large amounts of data, and the system response time lengthened. By analyzing the system logs, we discovered numerous serialization operations, which were inefficient when handling two-dimensional arrays, leading to decreased system performance.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;pstack&lt;/code&gt; tool captured thread information for the service, revealing that the log thread spends most of its time processing string concatenation&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Here&amp;rsquo;s the key point for today: different accumulation methods can make a huge difference in efficiency. The historical code uses the &lt;code&gt;+&lt;/code&gt; operator, which frequently creates temporary objects and is very inefficient. You know it’s inefficient, but you don’t realize just how inefficient it is.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;demo-verification&#34;&gt;Demo verification
&lt;/h2&gt;&lt;p&gt;Based on the project code, we extracted the business logic and wrote a simple demo to verify the efficiency of string concatenation. Compile and run with the &lt;code&gt;vs2022&lt;/code&gt; compiler under &lt;code&gt;windows&lt;/code&gt;, the &lt;code&gt;gcc8.5&lt;/code&gt; compiler under &lt;code&gt;linux&lt;/code&gt;, in &lt;code&gt;Release&lt;/code&gt; mode, and compare their efficiencies.&lt;/p&gt;
&lt;h3 id=&#34;key-points-explanation&#34;&gt;Key points explanation
&lt;/h3&gt;&lt;p&gt;The project uses method four. Before receiving the test data, readers can first think about which method is most efficient and which is least efficient? I was still very surprised when I saw the results.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Method 1 (Concatenation using +=): Directly concatenate each field to the string using +=&lt;/li&gt;
&lt;li&gt;Method 2 (using &lt;code&gt;std::ostringstream&lt;/code&gt; concatenation): This method uses streams (&lt;code&gt;std::ostringstream&lt;/code&gt;) to concatenate each field, which is more efficient, especially when concatenating large amounts of data&lt;/li&gt;
&lt;li&gt;Method 3 (Pre-allocated Memory with &lt;code&gt;+=&lt;/code&gt;) involves allocating sufficient memory for the string in advance using &lt;code&gt;reserve&lt;/code&gt;, which reduces the overhead of memory reallocation and improves performance&lt;/li&gt;
&lt;li&gt;Method 4 (&lt;code&gt;bodys = bodys + body + &amp;quot;\n&amp;quot;&lt;/code&gt;): Creating a new temporary string object with each concatenation leads to performance degradation, especially when concatenating strings on a large scale, because each concatenation involves a new memory allocation and copy&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;According to the results, the project selected the least efficient method&lt;/p&gt;
&lt;p&gt;To take things a step further, let&amp;rsquo;s analyze the optimization efficiency of different platform compilers. Microsoft&amp;rsquo;s &lt;code&gt;Visual Studio&lt;/code&gt; remains consistently excellent, with very high optimization efficiency for strings, while the &lt;code&gt;GCC&lt;/code&gt; compiler is somewhat lacking in this area.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The code runs on different machines, and there is no direct comparison between the two sets of data. You can compare the differences between different concatenation methods separately.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;windows 平台下的 vs2022 编译器

----------------------------------------
Data Generation Time: 0.054 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.053 seconds.
+ ostringstream Data merging took: 0.054 seconds.
+ Pre-reserved Data merging took: 0.045 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 16.108 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;linux 平台下的 gcc8.5 编译器
----------------------------------------
Data Generation Time: 0.108 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.100 seconds.
+ ostringstream Data merging took: 0.083 seconds.
+ Pre-reserved Data merging took: 0.057 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 29.298 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code&#34;&gt;Complete code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;random&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;sstream&amp;gt;
#include &amp;lt;iomanip&amp;gt;

typedef std::vector&amp;lt;std::string&amp;gt; DataRow;
typedef std::vector&amp;lt;DataRow&amp;gt; DataGroup;

struct ResponsePackage
{
    std::string ErrorInfo;
    DataRow Head;
    std::string ClientId;
    std::string UUID;
    std::string MsgID;
    std::string SessionID;
    std::string ExtraInfo1;
    std::string ExtraInfo2;
    DataGroup DataBody;
};

// Generate specified length of random string
std::string generateRandomString(size_t length)
{
    const char charset[] = &amp;quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&amp;quot;;
    const size_t max_index = sizeof(charset) - 1;
    std::string random_string;
    random_string.reserve(length);

    std::random_device rd;
    std::mt19937 generator(rd());
    std::uniform_int_distribution&amp;lt;&amp;gt; distribution(0, max_index);

    for (size_t i = 0; i &amp;lt; length; ++i)
    {
        random_string += charset[distribution(generator)];
    }

    return random_string;
}

void create_large_string()
{
    // Example request package with 50 fields
    ResponsePackage requestPackage;

    requestPackage.Head = {
        &amp;quot;Field1&amp;quot;, &amp;quot;Field2&amp;quot;, &amp;quot;Field3&amp;quot;, &amp;quot;Field4&amp;quot;, &amp;quot;Field5&amp;quot;,
        &amp;quot;Field6&amp;quot;, &amp;quot;Field7&amp;quot;, &amp;quot;Field8&amp;quot;, &amp;quot;Field9&amp;quot;, &amp;quot;Field10&amp;quot;,
        &amp;quot;Field11&amp;quot;, &amp;quot;Field12&amp;quot;, &amp;quot;Field13&amp;quot;, &amp;quot;Field14&amp;quot;, &amp;quot;Field15&amp;quot;,
        &amp;quot;Field16&amp;quot;, &amp;quot;Field17&amp;quot;, &amp;quot;Field18&amp;quot;, &amp;quot;Field19&amp;quot;, &amp;quot;Field20&amp;quot;,
        &amp;quot;Field21&amp;quot;, &amp;quot;Field22&amp;quot;, &amp;quot;Field23&amp;quot;, &amp;quot;Field24&amp;quot;, &amp;quot;Field25&amp;quot;,
        &amp;quot;Field26&amp;quot;, &amp;quot;Field27&amp;quot;, &amp;quot;Field28&amp;quot;, &amp;quot;Field29&amp;quot;, &amp;quot;Field30&amp;quot;,
        &amp;quot;Field31&amp;quot;, &amp;quot;Field32&amp;quot;, &amp;quot;Field33&amp;quot;, &amp;quot;Field34&amp;quot;, &amp;quot;Field35&amp;quot;,
        &amp;quot;Field36&amp;quot;, &amp;quot;Field37&amp;quot;, &amp;quot;Field38&amp;quot;, &amp;quot;Field39&amp;quot;, &amp;quot;Field40&amp;quot;,
        &amp;quot;Field41&amp;quot;, &amp;quot;Field42&amp;quot;, &amp;quot;Field43&amp;quot;, &amp;quot;Field44&amp;quot;, &amp;quot;Field45&amp;quot;,
        &amp;quot;Field46&amp;quot;, &amp;quot;Field47&amp;quot;, &amp;quot;Field48&amp;quot;, &amp;quot;Field49&amp;quot;, &amp;quot;Field50&amp;quot;
    };

    requestPackage.ClientId = &amp;quot;ClientID&amp;quot;;
    requestPackage.UUID = &amp;quot;UUID&amp;quot;;
    requestPackage.MsgID = &amp;quot;MsgID&amp;quot;;
    requestPackage.SessionID = &amp;quot;SessionID&amp;quot;;
    requestPackage.ExtraInfo1 = &amp;quot;ExtraInfo1&amp;quot;;
    requestPackage.ExtraInfo2 = &amp;quot;ExtraInfo2&amp;quot;;

    // Start timing for data generation
    auto start_gen = std::chrono::high_resolution_clock::now();

    // Generate 10,000 rows of data, each with 50 fields
    for (size_t i = 0; i &amp;lt; 10000; ++i)
    {
        DataRow dataRow(50, &amp;quot;This is a test string&amp;quot;);
        requestPackage.DataBody.push_back(dataRow);
    }

    // End timing for data generation
    auto end_gen = std::chrono::high_resolution_clock::now();
    std::chrono::duration&amp;lt;double&amp;gt; duration_gen = end_gen - start_gen;

    // Display result generation time
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Generation Time: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_gen.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    // Data merging using different methods
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Performance:\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    {
        // Method 1: Using &#39;+=&#39; string concatenation
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys(&amp;quot;&amp;quot;);
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (+=) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 2: Using ostringstream
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::ostringstream bodys;
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::ostringstream body;
            body &amp;lt;&amp;lt; &amp;quot;This is a test string&amp;quot;;
            for (auto&amp;amp; item : vec)
            {
                body &amp;lt;&amp;lt; item &amp;lt;&amp;lt; &amp;quot; &amp;quot;;
            }
            bodys &amp;lt;&amp;lt; body.str() &amp;lt;&amp;lt; &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ ostringstream Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 3: Pre-allocated memory
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys;
        bodys.reserve(1000 * 50 * 20); // Pre-allocate enough memory
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            body.reserve(50 * 20); // Pre-allocate memory for each row
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Pre-reserved Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 4: Using &#39;bodys = bodys + body + &amp;quot;\n&amp;quot;&#39;
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys(&amp;quot;&amp;quot;);
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            for (auto&amp;amp; item : vec)
            {
                body = body + item + &amp;quot; &amp;quot;; // Note the use of &#39;body = body + item&#39;
            }
            bodys = bodys + body + &amp;quot;\n&amp;quot;; // Again, using &#39;bodys = bodys + body&#39;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (bodys = bodys + body + \&amp;quot;\\n\&amp;quot;) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Complete.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;
}

int main()
{
    try
    {
        create_large_string();
    }
    catch (const std::exception&amp;amp; e)
    {
        std::cerr &amp;lt;&amp;lt; &amp;quot;Caught exception: &amp;quot; &amp;lt;&amp;lt; e.what() &amp;lt;&amp;lt; std::endl;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\nProgram finished.\n&amp;quot;;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Lambda expression parameter lifetime in C&#43;&#43;</title>
        <link>https://ttf248.life/en/p/cpp-lambda-parameter-lifetime/</link>
        <pubDate>Wed, 13 Nov 2024 19:23:02 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-lambda-parameter-lifetime/</guid>
        <description>&lt;p&gt;In C++, lambda expressions are convenient anonymous functions that can capture external variables and use them within their bodies. This makes lambdas a flexible programming tool. However, the lifetime of lambda expression parameters is an aspect that requires special attention, especially when capturing and passing parameters.&lt;/p&gt;
&lt;h3 id=&#34;the-lifecycle-of-parameters-in-lambda-expressions&#34;&gt;The lifecycle of parameters in lambda expressions
&lt;/h3&gt;&lt;p&gt;The lifetime of lambda expression parameters is typically the same as that of other C++ functions. Function parameters exist during the function call and end when the function call completes. However, because lambda expressions may capture external variables, the lifetime of the parameters can also be affected by the capturing method.&lt;/p&gt;
&lt;h3 id=&#34;the-relationship-between-capture-and-parameter-lifecycle&#34;&gt;The relationship between capture and parameter lifecycle
&lt;/h3&gt;&lt;h4 id=&#34;21-capturing-external-variables&#34;&gt;2.1 Capturing External Variables
&lt;/h4&gt;&lt;p&gt;C++ lambda expressions allow capturing external variables in two ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Value capturing: Through value capture, the values of external variables are copied into the lambda, and the lifecycle of these copies is controlled by the lifecycle of the lambda&lt;/li&gt;
&lt;li&gt;Closure: Through closure capturing, references to external variables are preserved; references within a lambda point to the original external variables, and their lifecycle depends on the external variables&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int x = 10;
auto lambda_by_value = [x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };  // 捕获x的副本
auto lambda_by_reference = [&amp;amp;x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };  // 捕获x的引用

lambda_by_value();  // 打印10
lambda_by_reference();  // 打印10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The lifecycle of captured variables is as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;By-value capture: When capturing, the values of external variables are copied into the lambda, and when the lambda&amp;rsquo;s lifecycle ends, these copies are destroyed&lt;/li&gt;
&lt;li&gt;Capture by reference: A lambda holding a reference to an external variable must have the external variable be valid before the lambda is used, otherwise it can lead to undefined behavior&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;22-lambda-parameters&#34;&gt;2.2 Lambda Parameters
&lt;/h4&gt;&lt;p&gt;Lambda parameters are similar to regular function parameters, their lifecycle is limited to within the lambda function. That is, lambda parameters are created when the lambda is called and their lifecycle ends after the lambda call is completed.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;auto lambda = [](int a, int b) {
    std::cout &amp;lt;&amp;lt; a + b &amp;lt;&amp;lt; std::endl;
};
lambda(5, 10);  // a和b在这里是lambda的参数
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; are parameters of the lambda expression, they are created when the lambda is called and destroyed after the lambda execution ends&lt;/p&gt;
&lt;h3 id=&#34;lifecycle-issues-when-capturing-external-variables&#34;&gt;Lifecycle issues when capturing external variables
&lt;/h3&gt;&lt;h4 id=&#34;whether-captured-variables-can-be-valid-outside-of-a-lambda&#34;&gt;Whether captured variables can be valid outside of a lambda
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Capture by value: Even if external variables are destroyed after a lambda call, the lambda still holds a copy of the external variable. Therefore, the copy inside the lambda can be used safely, even if the external variable no longer exists.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int x = 10;
auto lambda = [x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };
x = 20;  // x 在lambda调用后修改
lambda();  // 打印10，捕获的是x的副本
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;By reference capture: If a variable is captured by reference, the lambda&amp;rsquo;s access to that reference depends on the lifetime of the external variable. If the external variable is destroyed before the lambda executes, this can lead to a dangling reference and undefined behavior.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int x = 10;
auto lambda = [&amp;amp;x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };
x = 20;  // x 在lambda调用前修改
lambda();  // 打印20，捕获的是x的引用
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;It is very important to ensure that captured external variables remain valid when the lambda function executes if the order of execution of lambdas is uncertain&lt;/p&gt;
&lt;/blockquote&gt;</description>
        </item>
        <item>
        <title>Upgrading GCC version leads to program crashes: Hidden dangers of non-compliant code</title>
        <link>https://ttf248.life/en/p/upgrade-gcc-version-causes-program-crash-code-irregularities/</link>
        <pubDate>Sun, 10 Mar 2024 23:19:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/upgrade-gcc-version-causes-program-crash-code-irregularities/</guid>
        <description>&lt;p&gt;In the same business code segment, the program compiled and ran normally in the CentOS 7 environment, but when switched to CentOS 8 and compiled with an updated version of GCC, it crashed. It is worth noting that the problem only occurred in &lt;strong&gt;Release mode&lt;/strong&gt;, there were no issues at all in &lt;strong&gt;Debug mode&lt;/strong&gt;. This was the first time we encountered a situation like this, and after three days of troubleshooting, we finally found the root cause.&lt;/p&gt;
&lt;h3 id=&#34;problem-identification&#34;&gt;Problem identification
&lt;/h3&gt;&lt;p&gt;After some troubleshooting, the root cause of the problem is that &lt;strong&gt;the function lacks a return value&lt;/strong&gt;. In Release mode, newer versions of GCC perform more optimizations, which leads to undefined behavior in functions that originally lacked explicit return values during execution, resulting in crashes. Our conclusion is that &lt;strong&gt;compiler warnings should not be ignored, especially in older projects where some warnings may have been overlooked; however, we should avoid suppressing all warnings&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;environmental-description&#34;&gt;Environmental Description
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;CentOS 7 GCC version:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39)
Copyright © 2015 Free Software Foundation, Inc.
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CentOS 8 GCC version:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-21)
Copyright (C) 2018 Free Software Foundation, Inc.
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;crash-phenomenon&#34;&gt;Crash phenomenon
&lt;/h3&gt;&lt;p&gt;When analyzing the crash stack of the program, we observed the following stack information:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[New LWP 1385902]
[Thread debugging using libthread_db enabled]
Using host libthread_db library &amp;quot;/lib64/libthread_db.so.1&amp;quot;.
Core was generated by `./pstack_main`.
Program terminated with signal SIGSEGV, Segmentation fault.
#0  0x00007ffe894b4420 in ?? ()
(gdb) bt
#0  0x00007ffe894b4420 in ?? ()
#1  0x00000000004008e9 in main ()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This stack looks far from intuitive; the crash function&amp;rsquo;s stack information is displayed as a &lt;code&gt;??&lt;/code&gt;, which makes troubleshooting even more complicated&lt;/p&gt;
&lt;h3 id=&#34;code-example&#34;&gt;Code example
&lt;/h3&gt;&lt;p&gt;To better understand the issue, here&amp;rsquo;s a minimal code example to reproduce the crash:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;map&amp;gt;

int test() {
    std::cout &amp;lt;&amp;lt; &amp;quot;1&amp;quot; &amp;lt;&amp;lt; std::endl;
}

int main() {
    test();
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;test()&lt;/code&gt; function in this code apparently does not explicitly return a value, while its return type is declared as &lt;code&gt;int&lt;/code&gt;. According to the C++ specification, when a function is declared as type &lt;code&gt;int&lt;/code&gt;, it must have a return value; otherwise, undefined behavior may occur.&lt;/p&gt;
&lt;h3 id=&#34;compilation-warning&#34;&gt;Compilation warning
&lt;/h3&gt;&lt;p&gt;In our project, CMake scripts have suppressed many compile-time warnings, including the following warning message:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;/root/pstack/main.cpp: In function ‘int test()’:
/root/pstack/main.cpp:7:1: warning: no return statement in function returning non-void [-Wreturn-type]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This warning indicates that the &lt;code&gt;test()&lt;/code&gt; function does not return a value, which is the root of the problem. High versions of GCC (such as 8.5.0) may make unstable optimizations when optimizing code due to this undefined behavior, leading to program crashes.&lt;/p&gt;
&lt;h3 id=&#34;assembly-code-differences&#34;&gt;Assembly code differences
&lt;/h3&gt;&lt;p&gt;To explain the differences in GCC compiler optimization behavior, we compared the assembly code generated by different versions of GCC&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Assembly code generated by GCC 4.8.5:&lt;/p&gt;
&lt;p&gt;Assembly code is relatively verbose and includes handling logic for the standard output stream (such as &lt;code&gt;std::cout&lt;/code&gt;). This indicates that the compiler performed more conservative optimizations, did not extensively optimize the missing return value issue in the &lt;code&gt;test()&lt;/code&gt; function, possibly to avoid crashes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Assembly code generated by GCC 8.5.0:&lt;/p&gt;
&lt;p&gt;The new version of GCC has undergone more optimizations, reducing code volume. However, this optimization may cause undefined behavior when functions lacking return values are executed, potentially leading to program crashes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h3&gt;&lt;p&gt;Through this issue investigation, we deeply realized that in C++, &lt;strong&gt;function return values must be explicit&lt;/strong&gt;, especially when a function is declared as &lt;code&gt;int&lt;/code&gt;, it must provide a return value. Projects using older compilers may encounter more optimizations and stricter warning mechanisms when upgrading to newer versions of GCC. Therefore, we recommend against suppressing all warnings during compilation; instead, they should be handled selectively, particularly common issues such as function return values and type matching.&lt;/p&gt;
&lt;p&gt;Ultimately, the issue was resolved by adding a return value to the &lt;code&gt;test()&lt;/code&gt; function, and the program returned to normal operation&lt;/p&gt;</description>
        </item>
        <item>
        <title>Traps in C&#43;&#43; Programming: Detailed Explanation of Program Crashes Caused by Misusing `std::map`</title>
        <link>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</link>
        <pubDate>Sun, 10 Mar 2024 22:03:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</guid>
        <description>&lt;p&gt;This article aims to reveal the potential for program crashes when &lt;code&gt;std::map&lt;/code&gt; containers are incorrectly used in C++ programming. Attempting to access a non-existent key through the bracket operator automatically adds an empty element. We will delve into this misunderstanding and demonstrate its potential risks with example code.&lt;/p&gt;
&lt;p&gt;Storing simple values is fine, but if you&amp;rsquo;re storing pointers, there will be problems. Because a pointer is an address, and if it’s not initialized, the address is uncertain, which can lead to program crashes.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;In the C++ standard library, &lt;code&gt;std::map&lt;/code&gt; is an associative container that stores elements in ascending order based on their keys (key) and provides efficient keyword lookup functionality. However, novice developers sometimes encounter difficulties due to a misunderstanding of the behavior of the &lt;code&gt;std::map&lt;/code&gt; bracket operator &lt;code&gt;[]&lt;/code&gt;. In fact, when using &lt;code&gt;[]&lt;/code&gt; to access a non-existent key, &lt;code&gt;std::map&lt;/code&gt; will insert a new key-value pair, and the default constructor will be used to initialize the value type corresponding to that key.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;map&amp;gt;

int main() {
    std::map&amp;lt;std::string, int&amp;gt; myMap;
    
    // 错误的用法：假设这里试图访问一个不存在的键并认为会得到0
    std::cout &amp;lt;&amp;lt; &amp;quot;Value for &#39;nonexistent_key&#39;: &amp;quot; &amp;lt;&amp;lt; myMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;

    // 实际上，上述行代码创建了一个新的键值对，其中值被默认初始化为int的默认值（通常是0）
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Although the above code does not directly cause the program to crash, this implicit insertion behavior can potentially lead to unexpected side effects in certain situations, such as resource leaks or state changes that do not meet expectations. Worse still, concurrent access to uninitialized memory regions in a multithreaded environment can even lead to program crashes.&lt;/p&gt;
&lt;p&gt;To prevent such issues, it is recommended to use the &lt;code&gt;std::map::find()&lt;/code&gt; or &lt;code&gt;std::map::count()&lt;/code&gt; methods to check if a key exists, or to explicitly insert elements using &lt;code&gt;std::map::insert()&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;std::map&amp;lt;std::string, int&amp;gt; safeMap;
if (safeMap.count(&amp;quot;nonexistent_key&amp;quot;) == 0) {
    std::cout &amp;lt;&amp;lt; &amp;quot;Key does not exist.&amp;quot; &amp;lt;&amp;lt; std::endl;
} else {
    std::cout &amp;lt;&amp;lt; &amp;quot;Value for existing key: &amp;quot; &amp;lt;&amp;lt; safeMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;
}

// 或者明确插入一个键值对，指定初始值
safeMap.insert({ &amp;quot;new_key&amp;quot;, 0 });
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the objects stored within a map container are of pointer type, the automatic insertion behavior will save an uninitialized pointer, and any operation on this pointer will lead to program crashes&lt;/p&gt;</description>
        </item>
        <item>
        <title>C&#43;&#43; function call time consumption</title>
        <link>https://ttf248.life/en/p/cpp-function-call-timing/</link>
        <pubDate>Wed, 24 Jan 2024 14:11:33 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-function-call-timing/</guid>
        <description>&lt;p&gt;We conducted a time-consuming test of the Design Quotation SDK, implementing different callback function approaches. Recently I&amp;rsquo;ve been looking at C++ functional programming – what difference does it make in terms of performance when functions become first-class citizens and circulate within a program?&lt;/p&gt;
&lt;p&gt;Previous link: [Compiler, Callback Functions, Performance Testing]&lt;/p&gt;
&lt;p&gt;lemao also did similar tests and borrowed the code for use&lt;/p&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;The execution platform remains our old friend, &lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;cassert&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;functional&amp;gt;
#include &amp;lt;iostream&amp;gt;
#include &amp;lt;vector&amp;gt;

int add_one(int input) { return input + 1; }

bool validate_vector_add_one(std::vector&amp;lt;int&amp;gt; const&amp;amp; input_vector,
                             std::vector&amp;lt;int&amp;gt; const&amp;amp; output_vector)
{
    bool is_valid{true};
    for (size_t i{0}; i &amp;lt; input_vector.size(); ++i)
    {
        if (output_vector.at(i) != input_vector.at(i) + 1)
        {
            is_valid = false;
            break;
        }
    }
    return is_valid;
}

void reset_vector(std::vector&amp;lt;int&amp;gt;&amp;amp; input_vector)
{
    for (size_t i{0}; i &amp;lt; input_vector.size(); ++i)
    {
        input_vector.at(i) = 0;
    }
}

template &amp;lt;typename T, typename Func&amp;gt;
void unitary_function_pass_by_lambda_function(T&amp;amp; output, T const&amp;amp; input,
                                              Func const func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_std_function_value(T&amp;amp; output, T const&amp;amp; input,
                                                 std::function&amp;lt;T(T)&amp;gt; const func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_std_function_reference(
    T&amp;amp; output, T const&amp;amp; input, std::function&amp;lt;T(T)&amp;gt; const&amp;amp; func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_function_pointer(T&amp;amp; output, T const&amp;amp; input,
                                               T (*func)(T))
{
    output = func(input);
}

int main()
{
    // Set floating point format std::cout with 3 decimal places.
    std::cout.precision(3);

    size_t const num_elements{10000000};
    std::vector&amp;lt;int&amp;gt; input_vector(num_elements, 0);
    std::vector&amp;lt;int&amp;gt; output_vector(num_elements, 0);

    auto const lambda_function_add_one{[](int const&amp;amp; input) -&amp;gt; int
                                       { return input + 1; }};
    std::function&amp;lt;int(int)&amp;gt; const std_function_add_one{lambda_function_add_one};

    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a function pointer: &amp;quot; &amp;lt;&amp;lt; sizeof(&amp;amp;add_one)
              &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a std::function pointer: &amp;quot;
              &amp;lt;&amp;lt; sizeof(&amp;amp;std_function_add_one) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a std::function: &amp;quot; &amp;lt;&amp;lt; sizeof(std_function_add_one)
              &amp;lt;&amp;lt; std::endl;

    // Call function frequently in a vanilla way.
    // The compiler knows what function to call at compile time and can optimize
    // the code.
    // This is the best performance we could get.
    std::chrono::steady_clock::time_point const time_start_vanilla{
        std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        output_vector.at(i) = add_one(input_vector.at(i));
    }
    std::chrono::steady_clock::time_point const time_end_vanilla{
        std::chrono::steady_clock::now()};
    auto const time_elapsed_vanilla{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(time_end_vanilla -
                                                             time_start_vanilla)
            .count()};
    float const latency_vanilla{time_elapsed_vanilla /
                                static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass Vanilla: &amp;quot; &amp;lt;&amp;lt; latency_vanilla &amp;lt;&amp;lt; &amp;quot; ns&amp;quot;
              &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // Sometimes, we don&#39;t know what function to call at compile time.
    // We can use std::function to pass a function as an argument.
    // In this case, we pass the std::function by value.
    // Because the size of a std::function is 32 bytes, passing by value
    // results in a lot of copying and bad performance.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_std_function_value{std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_std_function_value(
            output_vector.at(i), input_vector.at(i), std_function_add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_std_function_value{std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_std_function_value{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_std_function_value -
            time_start_pass_by_std_function_value)
            .count()};
    float const latency_pass_by_std_function_value{
        time_elapsed_pass_by_std_function_value /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Std Function Value: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_std_function_value &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // Instead of passing the std::function by value, we can pass it by
    // reference (pointer). In this case, object copying is eliminated. The
    // performance is better than passing the std::function by value. However,
    // the performance is still not as good as the vanilla way.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_std_function_reference{
            std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_std_function_reference(
            output_vector.at(i), input_vector.at(i), std_function_add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_std_function_reference{
            std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_std_function_reference{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_std_function_reference -
            time_start_pass_by_std_function_reference)
            .count()};
    float const latency_pass_by_std_function_reference{
        time_elapsed_pass_by_std_function_reference /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Std Function Reference: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_std_function_reference &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // std::function is a general purpose wrapper for function pointers,
    // callable objects, and lambda functions. Because it&#39;s general purpose,
    // it&#39;s not as efficient as a function pointer. In this case, we pass a
    // function pointer to a function. The performance is better than passing
    // the std::function by reference.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_function_pointer{std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_function_pointer(output_vector.at(i),
                                                  input_vector.at(i), &amp;amp;add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_function_pointer{std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_function_pointer{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_function_pointer -
            time_start_pass_by_function_pointer)
            .count()};
    float const latency_pass_by_function_pointer{
        time_elapsed_pass_by_function_pointer /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Function Pointer: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_function_pointer &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // We can also pass a lambda function to a function.
    // The compiler knows what function to call at compile time and can optimize
    // the code. The performance is also better than passing the std::function
    // by reference.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_lambda_function{std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_lambda_function(
            output_vector.at(i), input_vector.at(i), lambda_function_add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_lambda_function{std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_lambda_function{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_lambda_function -
            time_start_pass_by_lambda_function)
            .count()};
    float const latency_pass_by_lambda_function{
        time_elapsed_pass_by_lambda_function /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Lambda Function: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_lambda_function &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 组里常规也就开启 O2 优化，编译选用了 gcc13，不同版本的 gcc 性能耗时略有不同，版本越高 lambda 效果越好
The size of a function pointer: 8
The size of a std::function pointer: 8
The size of a std::function: 32
Latency Pass Vanilla: 0.418 ns
Latency Pass By Std Function Value: 3.47 ns
Latency Pass By Std Function Reference: 1.36 ns
Latency Pass By Function Pointer: 0.396 ns
Latency Pass By Lambda Function: 0.44 ns
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;reference-materials&#34;&gt;Reference materials
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leimao.github.io/blog/CPP-Function-Call-Performance/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://leimao.github.io/blog/CPP-Function-Call-Performance/&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>C11: sleep for vs yield</title>
        <link>https://ttf248.life/en/p/c11-sleep-for-vs-yield/</link>
        <pubDate>Tue, 20 Sep 2022 20:54:51 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/c11-sleep-for-vs-yield/</guid>
        <description>&lt;p&gt;While reviewing the code, &lt;code&gt;std::this_thread::yield()&lt;/code&gt; suddenly caught my eye – a syntactic sugar feature from &lt;code&gt;C11&lt;/code&gt;. I&amp;rsquo;ve used quite a bit of it, but this is the first time seeing &lt;code&gt;yield&lt;/code&gt;, and I hadn’t noticed it before.&lt;/p&gt;
&lt;p&gt;Without checking the manual, my first thought was whether it&amp;rsquo;s related to asynchrony. The word &lt;code&gt;yield&lt;/code&gt; is used in the coroutine implementation of the Boost library, but this definitely has nothing to do with coroutines here; the control logic is likely related to ordinary threads.&lt;/p&gt;
&lt;h2 id=&#34;document&#34;&gt;Document
&lt;/h2&gt;&lt;h3 id=&#34;yield&#34;&gt;yield
&lt;/h3&gt;&lt;p&gt;The accuracy of this function depends on the implementation, particularly the OS scheduler mechanism and system state in use. For example, a first-in, first-out real-time scheduler (SCHED_FIFO in Linux) will suspend the current thread and place it at the tail of the queue of threads with the same priority (and yield has no effect if there are no other threads at the same priority).&lt;/p&gt;
&lt;h3 id=&#34;sleep_for&#34;&gt;sleep_for
&lt;/h3&gt;&lt;p&gt;Blocks the current thread&amp;rsquo;s execution for at least the specified sleep_duration
This function may block for longer than sleep_duration due to scheduling delays or resource contention
The standard library recommends measuring duration using a stable clock. If implemented with system time, wait times may also be sensitive to clock adjustments.&lt;/p&gt;
&lt;h3 id=&#34;analysis&#34;&gt;Analysis
&lt;/h3&gt;&lt;p&gt;Are both functions designed to release the current thread, and the effect depends on the platform? Still a bit hazy here, let&amp;rsquo;s run the code to see the execution results&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ThinkPad laptop (Visual Studio Community Edition 2022), Tencent Cloud S2 standard server (gcc8.5)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Operating Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First Time/μs&lt;/th&gt;
&lt;th&gt;Second Time/μs&lt;/th&gt;
&lt;th&gt;Third Time/μs&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Windows&lt;/td&gt;
&lt;td&gt;sleep_for&lt;/td&gt;
&lt;td&gt;9872&lt;/td&gt;
&lt;td&gt;1884&lt;/td&gt;
&lt;td&gt;11302&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Windows&lt;/td&gt;
&lt;td&gt;yield&lt;/td&gt;
&lt;td&gt;119&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Linux&lt;/td&gt;
&lt;td&gt;sleep_for&lt;/td&gt;
&lt;td&gt;171&lt;/td&gt;
&lt;td&gt;168&lt;/td&gt;
&lt;td&gt;167&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Linux&lt;/td&gt;
&lt;td&gt;yield&lt;/td&gt;
&lt;td&gt;101&lt;/td&gt;
&lt;td&gt;102&lt;/td&gt;
&lt;td&gt;101&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It&amp;rsquo;s easy to understand from the execution results that there are huge differences in the stability of &lt;code&gt;sleep_for&lt;/code&gt; at high precision due to different operating system implementations. If you need high-precision sleep, using &lt;code&gt;yield&lt;/code&gt; is more appropriate.&lt;/p&gt;
&lt;p&gt;When the time precision is increased to &lt;code&gt;ms&lt;/code&gt;, there is no significant difference between them&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;thread&amp;gt;
 
// 建议其他线程运行一小段时间的“忙睡眠”
void little_sleep(std::chrono::microseconds us)
{
    auto start = std::chrono::high_resolution_clock::now();
    auto end = start + us;
    do {
        std::this_thread::yield();
    } while (std::chrono::high_resolution_clock::now() &amp;lt; end);
}
 
int main()
{
    auto start = std::chrono::high_resolution_clock::now();
 
    little_sleep(std::chrono::microseconds(100));
    std::this_thread::sleep_for(std::chrono::microseconds(100));
 
    auto elapsed = std::chrono::high_resolution_clock::now() - start;
    std::cout &amp;lt;&amp;lt; &amp;quot;waited for &amp;quot;
              &amp;lt;&amp;lt; std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(elapsed).count()
              &amp;lt;&amp;lt; &amp;quot; microseconds\n&amp;quot;;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Why learn a new language?</title>
        <link>https://ttf248.life/en/p/why-learn-a-new-language/</link>
        <pubDate>Thu, 04 Aug 2022 11:27:30 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/why-learn-a-new-language/</guid>
        <description>&lt;p&gt;Why learn other programming languages after having used C++ for over ten years, starting from my school days?&lt;/p&gt;
&lt;p&gt;Work Experience: Lacks experience in elegant module design, C++ syntax is flexible, and learning other languages can help guide the creation of more elegant designs&lt;/p&gt;
&lt;p&gt;I often find myself using these tools when writing them&lt;/p&gt;
&lt;p&gt;Whether it&amp;rsquo;s the design of the underlying libraries or the implementation of business modules, the design principles are consistent&lt;/p&gt;</description>
        </item>
        <item>
        <title>Allocator for standard library containers</title>
        <link>https://ttf248.life/en/p/standard-library-container-memory-allocator/</link>
        <pubDate>Mon, 30 Dec 2019 13:26:19 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/standard-library-container-memory-allocator/</guid>
        <description>&lt;p&gt;Custom allocators can improve performance, increase memory efficiency, and solve problems related to frequent small memory allocations&lt;/p&gt;
&lt;h4 id=&#34;cause&#34;&gt;Cause
&lt;/h4&gt;&lt;p&gt;Recently, I&amp;rsquo;ve been working on network packet development and frequently need to allocate and release small blocks of memory. I initially thought about using a memory pool, but after reviewing several existing ones, I found this&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/cacay/MemoryPool&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/cacay/MemoryPool&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Seeing the interface, I was a bit puzzled – the implementation of this memory pool seems a little strange. The &lt;code&gt;MemoryPool&lt;/code&gt;&amp;rsquo;s implementation logic allocates fixed-size memory spaces. Having looked at the boost memory pool interface, it provides a template that is instantiated when used. Fortunately, there are already articles introducing this library, mentioning the concept of &lt;code&gt;allocator&lt;/code&gt;.&lt;/p&gt;
&lt;h4 id=&#34;wikihttpszhwikipediaorgwikie58886e9858de599a8_c2b2b&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;wiki&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;In C++ programming, an allocator (in English: allocator) is an important component of the C++ standard library. The C++ library defines various data structures collectively referred to as &amp;ldquo;containers&amp;rdquo; (such as linked lists, sets, etc.), and a common feature of these containers is that their size can change at runtime; to achieve this, dynamic memory allocation becomes particularly necessary, and allocators are used to handle the container&amp;rsquo;s memory allocation and release requests. In other words, an allocator encapsulates the low-level details of memory management for Standard Template Library (STL) containers. By default, the C++ standard library uses its own built-in general allocator, but according to specific needs, programmers can also customize allocators to replace it.&lt;/p&gt;
&lt;p&gt;The allocator was originally invented by Alexander Stepanov as part of the C++ Standard Template Library (STL), with the initial goal of creating a way to &amp;ldquo;make the library more flexible and independent of the underlying data model,&amp;rdquo; allowing programmers to utilize custom pointer and reference types within the library; however, when incorporating the Standard Template Library into the C++ standard, the C++ Standards Committee realized that complete abstraction of the data model would result in unacceptable performance losses. As a compromise, the restrictions on allocators in the standard became stricter, and as a result, the current standard describes allocators with significantly less customizability than Stepanov originally envisioned.&lt;/p&gt;
&lt;p&gt;Although there are limitations on allocator customization, custom allocators are often necessary in many cases, typically to encapsulate access methods for different types of memory spaces (such as shared memory and recycled memory) or to improve performance when using memory pools for memory allocation. In addition, introducing a dedicated custom allocator in programs that frequently allocate small amounts of memory can also be greatly beneficial from the perspectives of memory usage and runtime.&lt;/p&gt;
&lt;h4 id=&#34;requirements&#34;&gt;Requirements
&lt;/h4&gt;&lt;p&gt;One of the primary reasons for defining custom allocators is to improve performance. Utilizing a dedicated custom allocator can enhance program performance, or increase memory efficiency, or both [4][8]. The default allocator allocates storage space using the new operator, which is often implemented using C language heap allocation functions (malloc()) [Wen 5]. Because heap allocation functions are often optimized for occasional large memory allocations, the default allocator generally performs well when allocating memory for containers that require a large amount of memory to be allocated at once (such as vectors and double-ended queues) [8]. However, for associative containers and doubly linked lists, which require frequent allocation of small amounts of memory, using the default allocator can often result in low efficiency [4][9]. In addition, malloc()-based default allocators have many problems, such as poor locality of reference [4] and potential memory fragmentation [4][9].&lt;/p&gt;
&lt;p&gt;In short, this section (……) is like a &amp;ldquo;I Have a Dream&amp;rdquo; speech for this standard regarding allocators. Before the dream comes true, programmers concerned with portability will limit themselves to stateless custom allocators.
——Scott Meyers, 《Effective STL》
In light of this, in such situations, memory pool allocators are often used to address the problem of frequent small allocations [8]. Unlike the default &amp;ldquo;on-demand allocation&amp;rdquo; approach, when using a memory pool allocator, the program pre-allocates a large block of memory (the &amp;ldquo;memory pool&amp;rdquo;), and then, when memory is requested, the custom allocator simply returns a pointer to memory within the pool; during object destruction, no actual deallocation is required, but it is delayed until the end of the memory pool&amp;rsquo;s lifecycle [Note 1][8].&lt;/p&gt;
&lt;p&gt;The topic of &amp;ldquo;custom allocators&amp;rdquo; has seen considerable discussion among C++ experts and authors, such as Scott Meyers&amp;rsquo; work &amp;ldquo;Effective STL&amp;rdquo; and Andrei Alexandrescu&amp;rsquo;s &amp;ldquo;Modern C++ Design.&amp;rdquo; Meyers observed that if you require all instances of an allocator for a given type T to be equal, then the allocator instances must not contain state. Although the C++ standard encourages library implementers to support allocators with state [Reference 4], Meyers calls this related passage a “seemingly wonderful idea” but also almost empty talk, and he considers the restriction on allocators &amp;ldquo;too strict&amp;rdquo; [4]. For example, STL&amp;rsquo;s list allows the splice method, where nodes of one list object A can be directly moved into another list object B, which requires that the memory allocated by A’s allocator can be released by B’s allocator, thus inferring that the allocator instances of A and B must be equal. Meyers concludes that allocators are best defined as types using static methods. For example, according to the C++ standard, an allocator must provide an other class template that implements the rebind method.&lt;/p&gt;
&lt;p&gt;Additionally, in &amp;ldquo;The C++ Programming Language,&amp;rdquo; Bjarne Stroustrup argues that “&amp;lsquo;strictly limiting the allocator to avoid different object information&amp;rsquo; is clearly not a big deal” (in essence) and points out that most allocators do not need state, and performance may even be better in the absence of state. He proposes three use cases for custom allocators: memory pool-based allocators, shared memory allocators, and garbage collection allocators, and demonstrates an implementation of an allocator that utilizes an internal memory pool to quickly allocate/deallocate small amounts of memory. However, he also mentions that such optimization may already be implemented in the sample allocator he provides [3].&lt;/p&gt;
&lt;p&gt;Another use of a custom allocator is debugging memory-related errors [10]. To do this, you can write an allocator that allocates extra memory when allocating, and use it to store debug information. This type of allocator not only ensures that memory is allocated/deallocated by the same allocator, but also protects the program from cache overflows to a certain extent [11].&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

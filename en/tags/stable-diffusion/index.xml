<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Stable-Diffusion on Uncle Xiang&#39;s Notebook</title>
        <link>https://blog.ttf248.life/en/tags/stable-diffusion/</link>
        <description>Recent content in Stable-Diffusion on Uncle Xiang&#39;s Notebook</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Wed, 28 May 2025 09:47:38 +0800</lastBuildDate><atom:link href="https://blog.ttf248.life/en/tags/stable-diffusion/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Stable Diffusion – A Saga of Installation Troubles</title>
        <link>https://blog.ttf248.life/en/p/stable-diffusion-zero-install-saga/</link>
        <pubDate>Thu, 13 Apr 2023 00:23:54 +0800</pubDate>
        
        <guid>https://blog.ttf248.life/en/p/stable-diffusion-zero-install-saga/</guid>
        <description>&lt;p&gt;Domestic resources generally recommend &lt;strong&gt;秋叶&lt;/strong&gt;&amp;rsquo;s one-click deployment package. Assuming they are based on &lt;code&gt;Python&lt;/code&gt; open-source projects, the deployment shouldn&amp;rsquo;t be too complex; let&amp;rsquo;s try starting from scratch.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;After messing around with AI-generated images, I specially replaced my graphics card, only to have it gloriously shut down&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The core encryption remains inactive&lt;/p&gt;
&lt;h2 id=&#34;pending&#34;&gt;Pending
&lt;/h2&gt;&lt;p&gt;Restructure the article, first introducing PyTorch, version compatibility, and how to check versions
How to create a new virtual environment from scratch and deploy PyTorch locally
Translate draft, starting from scratch, Stable Diffusion &lt;a class=&#34;link&#34; href=&#34;https://stable-diffusion-art.com/install-windows/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stable-diffusion-art.com/install-windows/&lt;/a&gt;
Organize reference materials&lt;/p&gt;
&lt;h2 id=&#34;steps&#34;&gt;Steps
&lt;/h2&gt;&lt;p&gt;You might not find a step-by-step installation tutorial by searching in Chinese. Then, you just download the repository and run the script with a double click.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/AUTOMATIC1111/stable-diffusion-webui&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For detailed usage instructions and FAQs, please refer to &lt;code&gt;issues&lt;/code&gt;，&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I don&amp;rsquo;t know why no one explained what this repository is for. Actually, it’s not hard to tell from the name—it&amp;rsquo;s an interface console that makes it more convenient to use. In fact, during installation, it will download the official repository content and obtain the actual &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; code.&lt;/p&gt;
&lt;p&gt;The warehouse also includes an installation startup script that automatically detects the presence of &lt;code&gt;Python&lt;/code&gt;虚拟环境。如果有的话默认使用当前路径的的&lt;code&gt;python&lt;/code&gt; in the current folder&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;re a complete beginner, it is recommended that you check out: &lt;a class=&#34;link&#34; href=&#34;https://stable-diffusion-art.com/install-windows/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stable-diffusion-art.com/install-windows/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;pytorch&#34;&gt;pytorch
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/get-started/locally/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://pytorch.org/get-started/locally/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s what I wanted to say today: First, don&amp;rsquo;t just run the script directly based on their instructions. Python installs dependencies through requirement files – that’s a minor issue. The core thing is your graphics card driver version needs to correspond with PyTorch. Many resources online explain this relationship; you can easily find it.&lt;/p&gt;
&lt;p&gt;Reference: &lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/weixin_40660408/article/details/129896700&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/weixin_40660408/article/details/129896700&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Creating a virtual environment first—an empty one—allows you to directly run the script from the official website to install PyTorch&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -c &amp;quot;import torch; print(torch.version.cuda)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -c &amp;quot;import torch; print(torch.__version__, torch.cuda.is_available())&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These two scripts can check your CUDA version and whether the installation was successful&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s not recommended to use complicated operations here. Just copy the logic from the official page and install it directly. Installing via pip may result in failure or CUDA activation issues.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Important: Ensure the folder path is clean; otherwise, PyTorch may not work properly&lt;/p&gt;
&lt;p&gt;It involved numerous installations and attempts to manually install the official files. The goal was to upgrade to version 2.0, as the official documentation states it offers improved speed. However, I wasn&amp;rsquo;t familiar with the software and unsure if the Python version or other factors were influencing performance. I also consulted the official manual, which recommends using version 3.8. This created a conflict since a previous one-click deployment package used version 3.10. Ultimately, I started from scratch: creating a new folder, establishing a virtual environment, and ensuring torch was successfully installed.&lt;/p&gt;
&lt;p&gt;Then move this installed virtual environment into the web UI folder. Starting the installation script again at this point should resolve most dependency issues.&lt;/p&gt;
&lt;p&gt;After moving, you need to run: python -m pip install &amp;ndash;upgrade &amp;ndash;force-reinstall pip to fix it&lt;/p&gt;
&lt;p&gt;It might seem odd, but I spent a while troubleshooting this. It couldn&amp;rsquo;t correctly identify my torch, so to eliminate all potential interference, I decided to install it first, before installing other dependencies.&lt;/p&gt;
&lt;h2 id=&#34;xformers&#34;&gt;Xformers
&lt;/h2&gt;&lt;p&gt;Recommended to enable; accelerates image generation and reduces current usage. Side effect: same parameter group, &lt;strong&gt;生成的图像相对不是那么稳定&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;stable-diffusion-webui:Xformers&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/diffusers/optimization/xformers&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;huggingface optimization&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Optimization Ratio&lt;/th&gt;
&lt;th&gt;Time taken&lt;/th&gt;
&lt;th&gt;Torch active/reserved&lt;/th&gt;
&lt;th&gt;Sys VRAM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;100.00%&lt;/td&gt;
&lt;td&gt;2m 57.03s&lt;/td&gt;
&lt;td&gt;7440/10058 MiB&lt;/td&gt;
&lt;td&gt;12288/12288 MiB (100.0%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;51.02%&lt;/td&gt;
&lt;td&gt;1m 29.21s&lt;/td&gt;
&lt;td&gt;4547/7164 MiB&lt;/td&gt;
&lt;td&gt;9298/12288 MiB (75.67%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;((masterpiece)),((best quality)),((high detial)),((realistic,))
Industrial age city, deep canyons in the middle,chinese architectural streets,bazaars, Bridges, (rainy days:1.2), (steampunk:0.8), chinese architecture
Negative prompt: nsfw,((cowboy)),(((pubic))), ((((pubic_hair))))sketch, duplicate, ugly, huge eyes, text, logo, monochrome, worst face, (bad and mutated hands:1.3), (worst quality:2.0), (low quality:2.0), (blurry:2.0), horror, geometry, bad_prompt, (bad hands), (missing fingers), multiple limbs, bad anatomy, (interlocked fingers:1.2), Ugly Fingers, (extra digit and hands and fingers and legs and arms:1.4), crown braid, ((2girl)), (deformed fingers:1.2), (long fingers:1.2),succubus wings,horn,succubus horn,succubus hairstyle, (bad-artist-anime), bad-artist, bad hand, borrowed character, text focus, watermark, sample watermark, character watermark, lofter username, photo date watermark, movie poster, magazine cover, journal, cover, cover page, doujin cover, album cover, manga cover, brand name imitation, EasyNegative,Tights, silk stockings,shorts
Steps: 35, Sampler: DPM adaptive, CFG scale: 5.5, Seed: 2223996555, Size: 1088x1088, Model hash: 543bcbc212, Model: base_Anything-V3.0-pruned, Clip skip: 2, ENSD: 31337
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;afterword&#34;&gt;Afterword
&lt;/h2&gt;&lt;p&gt;It&amp;rsquo;s better to recommend the one-click deployment package. However, that package contains some custom settings from the author, which differ from the official, original version. If you’re a beginner, you might not understand why it’s best to start with the official parameters. As you gain experience, refer to the official documentation to learn which parameters need adjustment.&lt;/p&gt;
&lt;h2 id=&#34;graphics-card-selection&#34;&gt;Graphics card selection
&lt;/h2&gt;&lt;p&gt;After the cryptocurrency mining boom, graphics card prices are relatively lower now. For ordinary entry-level players, the amount of VRAM is sufficient.&lt;/p&gt;
&lt;p&gt;Also, &lt;strong&gt;高清放大&lt;/strong&gt; options require more detailed implementation, enriching screen details and demanding more video memory&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a summary table of single-precision (FP32), half-precision (FP16), and double-precision (FP64) floating-point compute capabilities for NVIDIA GeForce GTX 970, GeForce RTX 3060 Ti, GeForce RTX 3060, GeForce RTX 3080, and GeForce RTX 3080 Ti&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating-Point Performance (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating-Point Performance (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating-Point Performance (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;GeForce GTX 970&lt;/td&gt;
&lt;td&gt;2014&lt;/td&gt;
&lt;td&gt;3.49&lt;/td&gt;
&lt;td&gt;87.2&lt;/td&gt;
&lt;td&gt;0.109&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GeForce RTX 3060 Ti&lt;/td&gt;
&lt;td&gt;2020&lt;/td&gt;
&lt;td&gt;16.2&lt;/td&gt;
&lt;td&gt;32.4&lt;/td&gt;
&lt;td&gt;0.51&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GeForce RTX 3060&lt;/td&gt;
&lt;td&gt;2021&lt;/td&gt;
&lt;td&gt;12.7&lt;/td&gt;
&lt;td&gt;25.4&lt;/td&gt;
&lt;td&gt;0.39&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GeForce RTX 3080&lt;/td&gt;
&lt;td&gt;2020&lt;/td&gt;
&lt;td&gt;29.8&lt;/td&gt;
&lt;td&gt;58.9&lt;/td&gt;
&lt;td&gt;0.93&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GeForce RTX 3080 Ti&lt;/td&gt;
&lt;td&gt;2021&lt;/td&gt;
&lt;td&gt;34.8&lt;/td&gt;
&lt;td&gt;68.7&lt;/td&gt;
&lt;td&gt;1.36&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Quoted from&lt;/p&gt;
&lt;h2 id=&#34;update&#34;&gt;Update
&lt;/h2&gt;&lt;p&gt;After six months, I intended to review the installation steps and explain more basic concepts. However, it turns out that for ordinary people using AI image generation, it&amp;rsquo;s mostly about adjusting parameters based on images provided by experts or re-rendering existing images in a formatted way.&lt;/p&gt;
&lt;p&gt;We tried using AI to generate UI assets for a mini-program, but after all that effort, the results were unsatisfactory. It&amp;rsquo;s better to just pull resources directly from the official mini-program.&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

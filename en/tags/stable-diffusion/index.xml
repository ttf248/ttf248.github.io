<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Stable-Diffusion on Uncle Xiang&#39;s Notebook</title>
        <link>https://ttf248.life/en/tags/stable-diffusion/</link>
        <description>Recent content in Stable-Diffusion on Uncle Xiang&#39;s Notebook</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Mon, 02 Jun 2025 20:54:02 +0800</lastBuildDate><atom:link href="https://ttf248.life/en/tags/stable-diffusion/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Stable Diffusion – The Love, Hate, and Drama of Installing it from Scratch</title>
        <link>https://ttf248.life/en/p/stable-diffusion-zero-install-story/</link>
        <pubDate>Thu, 13 Apr 2023 00:23:54 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/stable-diffusion-zero-install-story/</guid>
        <description>&lt;p&gt;Domestic resources are basically all recommending &lt;strong&gt;Autumn Leaf&lt;/strong&gt;’s one-click deployment package, thinking that they are open-source projects based on &lt;code&gt;Python&lt;/code&gt;, so deployment wouldn&amp;rsquo;t be very complicated, let&amp;rsquo;s try to start from scratch.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I was messing around with AI-generated images and specifically changed my graphics card, a beginner version of the &lt;code&gt;3060 12g&lt;/code&gt;; the seven-year-old &lt;code&gt;960&lt;/code&gt; retired gloriously.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The core &lt;code&gt;pytorch cuda&lt;/code&gt; installation, which I previously encountered issues with when writing Python game helper scripts (I had installed it locally before), still presented problems – the &lt;code&gt;cuda&lt;/code&gt; encryption consistently failed to activate.&lt;/p&gt;
&lt;h2 id=&#34;to-do&#34;&gt;To Do
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Replan the article structure, first introduce PyTorch, version correspondence, and how to check versions.&lt;/li&gt;
&lt;li&gt;How to create a new virtual environment from scratch locally and deploy PyTorch.&lt;/li&gt;
&lt;li&gt;Translate the manuscript from scratch: &lt;a class=&#34;link&#34; href=&#34;https://stable-diffusion-art.com/install-windows/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stable-diffusion-art.com/install-windows/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Organize reference materials&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;steps&#34;&gt;Steps
&lt;/h2&gt;&lt;p&gt;Step-by-step installation tutorials in Chinese may not be readily available. When you search in English on &lt;code&gt;Google&lt;/code&gt;, you’ll find many similar tutorials starting from scratch. After a brief introduction, we need to install &lt;code&gt;git&lt;/code&gt; and then explain the need to install &lt;code&gt;python&lt;/code&gt;. Then, you go ahead and download the repository – simply double-clicking the script does the trick.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/AUTOMATIC1111/stable-diffusion-webui&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For detailed usage and Q&amp;amp;A, consult the &lt;code&gt;issues&lt;/code&gt;, &lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki&lt;/a&gt;. I don’t know why no one explains what this repository is for. Actually, the name itself isn&amp;rsquo;t difficult to understand – it’s a graphical control console that makes it easier to use. During installation, it downloads the official repository content and obtains the actual &lt;code&gt;SD&lt;/code&gt; code.&lt;/p&gt;
&lt;p&gt;The repository also provides an installation and startup script that automatically recognizes the current folder and whether there is a &lt;code&gt;Python&lt;/code&gt; virtual environment. If one exists, it defaults to using the Python in the current path.&lt;/p&gt;
&lt;p&gt;For beginner users, we recommend checking out: &lt;a class=&#34;link&#34; href=&#34;https://stable-diffusion-art.com/install-windows/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stable-diffusion-art.com/install-windows/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;pytorch&#34;&gt;PyTorch
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/get-started/locally/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://pytorch.org/get-started/locally/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Here’s what I wanted to talk about today. Don&amp;rsquo;t just follow their steps and run the script directly. Python uses requirement files to install dependencies, which is a minor issue. The core thing is your GPU version and driver version, which need to match PyTorch. Many people have discussed this relationship online – you can find it by searching.&lt;/p&gt;
&lt;p&gt;Refer to: &lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/weixin_40660408/article/details/129896700&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/weixin_40660408/article/details/129896700&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Creating a virtual environment is like creating an empty virtual environment, where you first execute the official script and install PyTorch within it.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -c &amp;quot;import torch; print(torch.version.cuda)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -c &amp;quot;import torch; print(torch.__version__, torch.cuda.is_available())&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above two scripts can check the CUDA version you need to install and also check if PyTorch has been installed successfully.&lt;/p&gt;
&lt;p&gt;It’s not recommended to do fancy operations here – just follow the logic on the official page and copy it over directly to install.  Directly using &lt;code&gt;pip&lt;/code&gt; to install PyTorch is likely to fail or won&amp;rsquo;t activate CUDA.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Key point: Don’t use messy folder names, as this could cause PyTorch to not work correctly. I spent a lot of time installing and reinstalling, trying to upgrade to version 2.0 because the official documentation said it would be faster.  I hadn&amp;rsquo;t used it much before, and wasn&amp;rsquo;t sure if Python versions had an impact. I also reviewed the official manual, which recommended using version 3.8. This created a small conflict since I’d previously used a one-click installation package that contained version 3.10. Finally, I started from scratch by creating a new folder, creating a virtual environment, and ensuring PyTorch was installed successfully.&lt;/p&gt;
&lt;p&gt;Then I moved the newly installed virtual environment into the web UI folder.  At this point, running the script to install other dependencies didn’t cause any problems.&lt;/p&gt;
&lt;p&gt;After moving it, you need to execute: &lt;code&gt;python -m pip install --upgrade --force-reinstall pip&lt;/code&gt; to fix Pip.&lt;/p&gt;
&lt;p&gt;It might seem a bit strange, but I spent quite a long time troubleshooting this because it couldn&amp;rsquo;t correctly recognize my PyTorch.  I realized that by installing it first, then installing other dependencies, I could eliminate all sources of interference.&lt;/p&gt;
&lt;h2 id=&#34;xformers&#34;&gt;Xformers
&lt;/h2&gt;&lt;p&gt;It is recommended to enable this, which can accelerate image generation and reduce memory usage. However, a side effect is that &lt;strong&gt;generated images are relatively less stable&lt;/strong&gt; with the same set of parameters.
&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;stable-diffusion-webui:Xformers&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/diffusers/optimization/xformers&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;huggingface optimization&lt;/a&gt;
| 100.00% | 2m 57.03s | 7440/10058 MiB | 12288/12288 MiB (100.0%) |&lt;/p&gt;
&lt;h2 id=&#34;xformers-1&#34;&gt;Xformers
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Optimization Ratio&lt;/th&gt;
&lt;th&gt;Time taken&lt;/th&gt;
&lt;th&gt;Torch active/reserved&lt;/th&gt;
&lt;th&gt;Sys VRAM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;51.02%&lt;/td&gt;
&lt;td&gt;1m 29.21s&lt;/td&gt;
&lt;td&gt;4547/7164 MiB&lt;/td&gt;
&lt;td&gt;9298/12288 MiB (75.67%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;xformers-2&#34;&gt;Xformers
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;((masterpiece)),((best quality)),((high detail)),((realistic,))
Industrial age city, deep canyons in the middle, Chinese architectural streets, bazaars, Bridges, (rainy days:1.2), (steampunk:0.8), Chinese architecture
Negative prompt: nsfw,((cowboy)),(((pubic))), ((((pubic_hair))))sketch, duplicate, ugly, huge eyes, text, logo, monochrome, worst face, (bad and mutated hands:1.3), (worst quality:2.0), (low quality:2.0), (blurry:2.0), horror, geometry, bad_prompt, (bad hands), (missing fingers), multiple limbs, bad anatomy, (interlocked fingers:1.2), Ugly Fingers, (extra digit and hands and fingers and legs and arms:1.4), crown braid, ((2girl)), (deformed fingers:1.2), (long fingers:1.2), succubus wings,horn,succubus horn,succubus hairstyle, (bad-artist-anime), bad-artist, bad hand, borrowed character, text focus, watermark, sample watermark, character watermark, lofter username, photo date watermark, movie poster, magazine cover, journal, cover, cover page, doujin cover, album cover, manga cover, brand name imitation, EasyNegative,Tights, silk stockings,shorts
Steps: 35, Sampler: DPM adaptive, CFG scale: 5.5, Seed: 2223996555, Size: 1088x1088, Model hash: 543bcbc212, Model: base_Anything-V3.0-pruned, Clip skip: 2, ENSD: 31337
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;We didn’t recommend the one-click deployment package because it contained some settings that were customized by the author and differed from the official, out-of-the-box configuration. If you&amp;rsquo;re a beginner, you might not understand why those parameters are optimal; it’s generally best to start with the official version. As you use it more and more, take time to read the official documentation, and you’ll learn which parameters need adjustment.&lt;/p&gt;
&lt;h2 id=&#34;gpu-selection&#34;&gt;GPU Selection
&lt;/h2&gt;&lt;p&gt;Following the cryptocurrency mining boom, GPU prices have become relatively less high; for entry-level players choosing between the &lt;code&gt;3060&lt;/code&gt; and &lt;code&gt;3060ti&lt;/code&gt;, it’s generally recommended to opt for the 12G version of the 3060 due to its larger VRAM, as it can generate larger resolution images. Why do you need a higher resolution? Because you can increase the resolution during generation, which will result in clearer and more detailed images. If you only want to generate small images, then 8GB of VRAM is sufficient.&lt;/p&gt;
&lt;p&gt;There’s also the &lt;strong&gt;Super Resolution Upscaling&lt;/strong&gt; option, which enhances details and makes the image richer in detail, requiring more VRAM.&lt;/p&gt;
&lt;p&gt;Below is a summary table of the single-precision (FP32), half-precision (FP16), and double-precision (FP64) floating-point computing capabilities of NVIDIA GeForce GTX 970, GeForce RTX 3060 Ti, GeForce RTX 3060, GeForce RTX 3080, and GeForce RTX 3080 Ti:&lt;/p&gt;
&lt;p&gt;| GeForce GTX 970 | 2014 | 3.49 | 87.2 | 0.109 |&lt;/p&gt;
&lt;h2 id=&#34;graphics-card-selection&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;graphics-card-selection-1&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;graphics-card-selection-2&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;graphics-card-selection-3&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;gpu-selection-1&#34;&gt;GPU Selection
&lt;/h2&gt;&lt;p&gt;Excerpted from &lt;a class=&#34;link&#34; href=&#34;https://docs.google.com/spreadsheets/d/1Zlv4UFiciSgmJZncCujuXKHwc4BcxbjbSBg71-SdeNk/edit#gid=0&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;various GPU performance test data&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;updates&#34;&gt;Updates
&lt;/h2&gt;&lt;p&gt;Every six months, I originally planned to revisit and refine the installation steps, and explain more basic concepts. However, I discovered that most people using AI image generation are simply adjusting parameters based on images provided by experts, or re-rendering existing images with formatting changes.&lt;/p&gt;
&lt;p&gt;I had previously attempted a project using AI to generate UI materials for mini programs, but after struggling for half a day, the results were unsatisfactory compared to just pulling resource images directly from the official mini program documentation.&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

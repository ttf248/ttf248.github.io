<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Troubleshooting on Uncle Xiang&#39;s Notebook</title>
        <link>https://ttf248.life/en/tags/troubleshooting/</link>
        <description>Recent content in Troubleshooting on Uncle Xiang&#39;s Notebook</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Sun, 25 May 2025 03:15:22 +0800</lastBuildDate><atom:link href="https://ttf248.life/en/tags/troubleshooting/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Protobuf Zero-Value Trap: When Defaults Become Silent Killers of Business Logic</title>
        <link>https://ttf248.life/en/p/protobuf-zero-value-traps/</link>
        <pubDate>Thu, 20 Feb 2025 15:26:51 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/protobuf-zero-value-traps/</guid>
        <description>&lt;p&gt;US stocks have three trading periods: pre-market, intra-market, and after-hours. The data push interface uses an incremental logic (to minimize bandwidth usage), sending the full dataset only once initially, and then pushing all subsequent fields as increments.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Why not use the optimal solution? It involves different project teams, some of which have been live for many years. We are newly connected, so we can only try our best to ensure compatibility.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;a-series-of-questions&#34;&gt;A series of questions
&lt;/h2&gt;&lt;p&gt;Looking at the abstract alone, there might not seem to be any issues. However, bringing the system architecture into the problem-solving group has led to a series of problems. Just as one problem was resolved, a new one emerged, and this new problem stemmed from the previous ones.&lt;/p&gt;
&lt;h3 id=&#34;unable-to-identify-trading-period&#34;&gt;Unable to identify trading period
&lt;/h3&gt;&lt;p&gt;The known issue is that the stage in the table is defined as 0 in &lt;code&gt;protobuf&lt;/code&gt;, but due to incremental push when receiving data, the business side cannot effectively identify whether this 0 is a default value or a real business value&lt;/p&gt;
&lt;p&gt;A layman&amp;rsquo;s understanding: Each time we receive a 0, it’s impossible to determine whether this 0 is the value of a newly set quote or the default value of Protobuf&lt;/p&gt;
&lt;h3 id=&#34;introduce-optional&#34;&gt;Introduce optional
&lt;/h3&gt;&lt;p&gt;Since protobuf release 3.15, proto3 supports using the optional keyword (just as in proto2) to give a scalar field presence information&lt;/p&gt;
&lt;p&gt;The communication protocol within the group is based on &lt;code&gt;protobuf&lt;/code&gt;, but due to historical reasons, an older version was chosen that doesn&amp;rsquo;t support the &lt;code&gt;optional&lt;/code&gt; keyword. Those who understand know that because &lt;code&gt;protobuf&lt;/code&gt; was introduced from the bottom up and the project is released as a static library, upgrading the entire compilation chain would be very costly.&lt;/p&gt;
&lt;h3 id=&#34;gcc-version-issue&#34;&gt;GCC version issue
&lt;/h3&gt;&lt;p&gt;After much effort, we devised a plan to release two different versions at the underlying level, attempting to control the propagation of compilation dependencies for the new version of &lt;code&gt;protobuf&lt;/code&gt;. However, during compilation, we discovered that the &lt;code&gt;gcc&lt;/code&gt; version was too low and did not support the new features of &lt;code&gt;protobuf&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Commonly used server types within the group: CentOS 7, CentOS 8. The default &lt;code&gt;gcc&lt;/code&gt; version for CentOS 7 is 4.8, and the default &lt;code&gt;gcc&lt;/code&gt; version for CentOS 8 is 8.3. Because new features of &lt;code&gt;protobuf&lt;/code&gt; require a &lt;code&gt;gcc&lt;/code&gt; version above 7.4, CentOS 7 cannot be supported.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://gcc.gnu.org/bugzilla/show_bug.cgi?id=82461&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Bug 82461 - [7 Regression] Temporary required for brace-initializing (non-literal-type) member variable&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;After some troubleshooting, I moved the deployment and compilation servers for related services to CentOS 8, which resolved the issue&lt;/p&gt;
&lt;h2 id=&#34;reasonable-enumeration&#34;&gt;Reasonable enumeration
&lt;/h2&gt;&lt;p&gt;Looking back at the whole issue, there&amp;rsquo;s actually a simpler and more efficient solution: adjust the enumeration definition to start numbering from 1 instead of 0. This can effectively distinguish between default values and business values, avoiding the aforementioned series of problems.&lt;/p&gt;
&lt;h3 id=&#34;why-is-it-more-reasonable-to-start-from-1&#34;&gt;Why is it more reasonable to start from 1?
&lt;/h3&gt;&lt;p&gt;In &lt;code&gt;protobuf&lt;/code&gt;, enumeration types default to a value of 0. If we define a meaningful business value as 0 (for example, &amp;ldquo;in-play&amp;rdquo;), the receiving party cannot determine whether the received 0 is a business value or an unset default value during incremental push. However, if we start defining enumerations from 1, 0 can be reserved for a meaningless default value or an &amp;ldquo;unknown&amp;rdquo; state, and the problem is easily resolved.&lt;/p&gt;
&lt;p&gt;Suggested practices:&lt;/p&gt;
&lt;p&gt;When designing protobuf enums, always define 0 as a meaningless default value (such as &lt;code&gt;UNKNOWN&lt;/code&gt; or &lt;code&gt;RESERVED&lt;/code&gt;)
Assign actual business values starting from 1, ensuring they are distinct from the default value of 0&lt;/p&gt;
&lt;p&gt;This small adjustment not only resolved the issue of identifying trading periods, but also provided a valuable lesson for future protocol design&lt;/p&gt;</description>
        </item>
        <item>
        <title>Troubleshooting TCP Communication Abnormalities in Backend Services</title>
        <link>https://ttf248.life/en/p/backend-service-tcp-communication-troubleshooting/</link>
        <pubDate>Fri, 14 Feb 2025 22:54:13 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/backend-service-tcp-communication-troubleshooting/</guid>
        <description>&lt;p&gt;The business model involves backend services establishing a connection with the group&amp;rsquo;s market gateway via TCP. Each connection requires sending an authorization request first, followed by continuously sending heartbeat packets to maintain the connection status.
However, one day, we received an alert message indicating a service disconnection. After carefully checking the logs, we discovered that the backend service was continuously sending heartbeat packets, but there was no response from the other party, yet the connection never disconnected.&lt;/p&gt;
&lt;h2 id=&#34;brief-description-of-the-scene&#34;&gt;Brief description of the scene
&lt;/h2&gt;&lt;p&gt;I was originally working overtime at the company to push forward project progress when an alarm message suddenly popped up in the work group. At first glance, I thought it was just the usual issue – likely a network timeout causing heartbeat failures and subsequently disconnecting the service. However, after carefully checking the logs, I found that the actual situation was not like that. The backend had sent authorization login messages, but received no response. Meanwhile, heartbeats continued to be sent incessantly, yet the other party never replied with any heartbeat data. In-depth analysis of the logs revealed the following key issues:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Authorization message received no response: It is very likely that the other party&amp;rsquo;s system is restarting, preventing the authorization message from being processed in a timely manner&lt;/li&gt;
&lt;li&gt;The heartbeat data was sent even though authorization failed: After investigation, we found a flaw in the program logic. The judgment logic of the heartbeat sending function is flawed; it only checks the connection status but overlooks the authorization status check.&lt;/li&gt;
&lt;li&gt;If the service can be disconnected, it will trigger a reconnection mechanism and resend the authorization message&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Currently, there remains one last urgent issue that needs resolving—why the connection has not been disconnected. Solving this problem requires more in-depth and detailed troubleshooting work.&lt;/p&gt;
&lt;h2 id=&#34;analyzing-network-packets&#34;&gt;Analyzing network packets
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;tcpdump&lt;/code&gt; is a very powerful network packet capture tool that can be used to capture network data packets. By analyzing these network data packets, we can gain a more intuitive understanding of the details of network communication. Here, we can use &lt;code&gt;tcpdump&lt;/code&gt; to capture network data packets for further analysis.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/backend-service-tcp-communication-troubleshooting/20250220151952.png&#34;
	width=&#34;1126&#34;
	height=&#34;202&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;tcpdump&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;557&#34;
		data-flex-basis=&#34;1337px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Analyzing the data in the graph, I can see that the heartbeat is consistently being sent, but the other server isn&amp;rsquo;t responding with any data, yet it’s sending an &lt;code&gt;ACK&lt;/code&gt;. This prevents the connection from disconnecting on its own.&lt;/p&gt;
&lt;h2 id=&#34;common-flag-explanations&#34;&gt;Common Flag Explanations
&lt;/h2&gt;&lt;p&gt;In the TCP protocol, &lt;code&gt;PSH&lt;/code&gt; (Push) and &lt;code&gt;ACK&lt;/code&gt; (Acknowledgment) are two important flags used to control data transmission and flow confirmation. Their functions are as follows:&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;1-pshpush-flag&#34;&gt;&lt;strong&gt;1. PSH（Push Flag）&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Features
The purpose of the &lt;code&gt;PSH&lt;/code&gt; flag is to &lt;strong&gt;request that the receiver immediately push data from the buffer to the upper layer application&lt;/strong&gt; (instead of waiting for the buffer to fill up). This means that once a data segment with the &lt;code&gt;PSH&lt;/code&gt; flag is received, the receiver will process and pass it to the application as quickly as possible, rather than storing it in the operating system buffer.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Typical Scenarios&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HTTP/HTTPS requests: When a client sends a request (such as &lt;code&gt;GET /index.html&lt;/code&gt;), it sets the &lt;code&gt;PSH&lt;/code&gt; flag, hoping that the server will respond immediately&lt;/li&gt;
&lt;li&gt;The SSH protocol: Each keyboard input triggers a &lt;code&gt;PSH&lt;/code&gt;, ensuring that input characters are transmitted in real-time&lt;/li&gt;
&lt;li&gt;Real-time communication: Low-latency scenarios such as video streams and online games may use &lt;code&gt;PSH&lt;/code&gt; to reduce latency&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Note:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PSH is not mandatory; the receiving party can choose to ignore this flag (but still needs to process the data normally)&lt;/li&gt;
&lt;li&gt;The sender may not set the &lt;code&gt;PSH&lt;/code&gt;, in which case the receiver will decide when to push data based on its own buffering strategy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;2-ackacknowledgment-flag&#34;&gt;&lt;strong&gt;2. ACK（Acknowledgment Flag）&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Features
The ACK flag indicates that &lt;strong&gt;the preceding segment of data has been received correctly&lt;/strong&gt;. Each ACK contains an acknowledgment number (Acknowledgment Number), which represents the next expected byte sequence number. It is a core mechanism for reliable transmission in TCP.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Working principle:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When the sender sends a data segment, it carries the expected receiver&amp;rsquo;s &lt;code&gt;ACK&lt;/code&gt; value (for example, &lt;code&gt;ACK = sequence number + data length&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Upon receiving data, the receiver generates an &lt;code&gt;ACK&lt;/code&gt; segment confirming the received sequence number&lt;/li&gt;
&lt;li&gt;The sender will only retransmit unacknowledged data after receiving the corresponding ACK&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If the sender sends a data segment with sequence number &lt;code&gt;100~199&lt;/code&gt;, the expected &lt;code&gt;ACK&lt;/code&gt; from the receiver should be &lt;code&gt;200&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;If the receiving party fails to receive some of the data within the range of &lt;code&gt;100~199&lt;/code&gt;, it will inform the sending party to retransmit via &lt;code&gt;ACK=150&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;the-combination-of-psh-and-ack&#34;&gt;The combination of PSH and ACK
&lt;/h3&gt;&lt;p&gt;In TCP packets, &lt;code&gt;PSH&lt;/code&gt; and &lt;code&gt;ACK&lt;/code&gt; can appear simultaneously, commonly seen in the following scenarios:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;HTTP request response
When the client sends a &lt;code&gt;POST&lt;/code&gt; request (with data), it sets &lt;code&gt;PSH&lt;/code&gt; and &lt;code&gt;ACK&lt;/code&gt; (acknowledgment of previous responses)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-plaintext&#34;&gt;Client → Server: SYN, ACK=1 → 建立连接
Client → Server: PSH, ACK=1, 数据 → 发送请求数据
Server → Client: PSH, ACK=数据长度+1 → 返回响应
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Transmit commands after SSH handshake
After the client enters a command, it sends a data segment with &lt;code&gt;PSH&lt;/code&gt; and &lt;code&gt;ACK&lt;/code&gt; to ensure that the command is immediately transmitted and processed by the server&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;other-flag-bit-associations&#34;&gt;Other flag bit associations
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Flag&lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Brief Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;SYN Synchronization Initialization Connection (Three-Way Handshake)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;FIN&lt;/td&gt;
&lt;td&gt;End&lt;/td&gt;
&lt;td&gt;Gracefully close connection&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Reset&lt;/td&gt;
&lt;td&gt;Force connection termination (abnormal situation)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mark urgent pointer (rarely used)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;PSH focuses on getting data to the application layer as quickly as possible, reducing latency&lt;/li&gt;
&lt;li&gt;ACK focuses on reliable data transmission, avoiding packet loss or out-of-order delivery&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;They work together to balance the efficiency and reliability of the TCP protocol&lt;/p&gt;</description>
        </item>
        <item>
        <title>A Complete Guide to Monitoring Linux System Metrics with the atop Tool: Installation, Configuration, and Usage</title>
        <link>https://ttf248.life/en/p/using-atop-to-monitor-linux-system-metrics-installation-configuration-and-usage-guide/</link>
        <pubDate>Thu, 06 Feb 2025 22:48:55 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/using-atop-to-monitor-linux-system-metrics-installation-configuration-and-usage-guide/</guid>
        <description>&lt;p&gt;Real-time and comprehensive monitoring of system resources and process status is crucial in Linux system maintenance. As a powerful monitoring tool, atop can help us easily achieve this goal. This article will detail how to install, configure, and use the atop monitoring tool on a Linux instance.&lt;/p&gt;
&lt;h2 id=&#34;introduction-to-atop-tool&#34;&gt;Introduction to atop tool
&lt;/h2&gt;&lt;p&gt;Atop is a tool specifically designed for monitoring Linux system resources and processes. It records system and process activity, reporting the status of all running processes. The data collected covers resource usage such as CPU, memory, disk, and network, as well as process states. This data can also be saved to disk in log file format. For each process, we can obtain key information such as CPU utilization, memory growth, disk usage, priority, username, status, and exit code. Furthermore, through the atop configuration file, we can customize parameters such as logging frequency, log file storage path, and rotation policy.&lt;/p&gt;
&lt;h2 id=&#34;ii-installing-the-atop-tool&#34;&gt;II. Installing the atop tool
&lt;/h2&gt;&lt;p&gt;The installation methods of atop vary slightly across different Linux distributions; the following introduces it using a common operating system as an example&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Alibaba Cloud Linux 3/2、CentOS 7/8、Fedora、Rocky Linux 9&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Execute installation command: &lt;code&gt;sudo yum install -y atop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ubuntu / Debian&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Update software sources: &lt;code&gt;sudo apt update&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Execute the installation command: &lt;code&gt;sudo apt install -y atop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;CentOS Stream 9&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download and install: &lt;code&gt;sudo wget https://www.atoptool.nl/download/atop-2.11.0-1.el9.x86_64.rpm &amp;amp;&amp;amp; sudo rpm -i atop-2.11.0-1.el9.x86_64.rpm&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;openSUSE&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Execute installation command: &lt;code&gt;sudo zypper install -y atop atop-daemon&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If the operating systems listed above do not include your distribution, you can visit the atop official website for installation information&lt;/p&gt;
&lt;h2 id=&#34;iii-configuring-monitoring-cycle-and-log-retention-time&#34;&gt;III. Configuring Monitoring Cycle and Log Retention Time
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Configuration file location: On Alibaba Cloud Linux 3/2, CentOS 7/8, and Fedora systems, the atop configuration file is /etc/sysconfig/atop; on Ubuntu, Debian, and openSUSE systems, the configuration file is /etc/default/atop&lt;/li&gt;
&lt;li&gt;Default Configuration Parameters Description
&lt;ul&gt;
&lt;li&gt;LOGOPTS: Used to control log file recording options, defaults to empty&lt;/li&gt;
&lt;li&gt;The monitoring cycle, default is 600 seconds. If you need to collect historical logs to track issues, adjust this frequency according to your actual needs.&lt;/li&gt;
&lt;li&gt;LOGGENERATIONS: Log retention time, default 28 days&lt;/li&gt;
&lt;li&gt;LOGPATH: The path where log files are stored, default /var/log/atop&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Configuration Steps
&lt;ul&gt;
&lt;li&gt;Execute the command to open the configuration file:
&lt;ul&gt;
&lt;li&gt;On Alibaba Cloud Linux 3/2, CentOS 7/8, Fedora systems: &lt;code&gt;sudo vim /etc/sysconfig/atop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;In Ubuntu, Debian, openSUSE, CentOS Stream 9, Rocky Linux 9 systems: &lt;code&gt;sudo vim /etc/default/atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;i&lt;/code&gt; to enter edit mode and adjust configuration parameters as needed. For example, change the monitoring cycle to 30 seconds, set the log retention time to 7 days, and keep the log path at its default setting:&lt;/li&gt;
&lt;li&gt;Press the &lt;code&gt;Esc&lt;/code&gt; key, enter &lt;code&gt;:wq&lt;/code&gt;, save and exit editing&lt;/li&gt;
&lt;li&gt;Restarting the atop service will apply the configuration: &lt;code&gt;sudo systemctl restart atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;LOGOPTS=&amp;quot;&amp;quot;
LOGINTERVAL=30
LOGGENERATIONS=7
LOGPATH=/var/log/atop 
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;four-using-the-atop-tool&#34;&gt;Four, Using the atop tool
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Introduction to Common Commands: In interactive command mode, the following are common commands:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Switch back to the default composite output view&lt;/li&gt;
&lt;li&gt;Displays the full command line of processes&lt;/li&gt;
&lt;li&gt;Sort by process memory usage in descending order&lt;/li&gt;
&lt;li&gt;Sort by process disk usage in descending order&lt;/li&gt;
&lt;li&gt;Sort in descending order based on the comprehensive utilization rate of processes and resources&lt;/li&gt;
&lt;li&gt;Sort by process network usage in descending order&lt;/li&gt;
&lt;li&gt;Go to the next monitoring point&lt;/li&gt;
&lt;li&gt;Go to the previous monitoring point&lt;/li&gt;
&lt;li&gt;b: Specifies a point in time, formatted as &lt;code&gt;YYYYMMDDhhmm&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Introduction to Resource Monitoring Fields&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Host name, information sampling date and time&lt;/li&gt;
&lt;li&gt;Overall process runtime status, including kernel and user space running time, total number of processes, and the number of processes in different states&lt;/li&gt;
&lt;li&gt;The CPU utilization shows the overall usage, with each field&amp;rsquo;s numerical sum resulting in &lt;code&gt;N*100%&lt;/code&gt; (where N is the number of CPU cores), including kernel time, user time, interrupt time, idle time, and wait for disk I/O time proportions&lt;/li&gt;
&lt;li&gt;CPL: CPU load information, such as the average number of processes in the run queue over the past 1 minute, 5 minutes, and 15 minutes, context switch count, and interrupt occurrence count&lt;/li&gt;
&lt;li&gt;MEM: Memory usage, including total physical memory, idle memory, page cache memory, file cache memory, and kernel occupied memory&lt;/li&gt;
&lt;li&gt;SWP: Swap space usage, including total swap area and free swap space size&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PAG&lt;/strong&gt;: Virtual memory paging status, such as the number of pages swapped in and out&lt;/li&gt;
&lt;li&gt;DSK: Disk Usage, each disk device corresponds to a row, displaying device identifier, busy time ratio, and read/write request count&lt;/li&gt;
&lt;li&gt;NET: Network conditions, displaying receive and send packet sizes for the transport layer TCP and UDP, IP layer, and active network interfaces&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;View real-time system metrics&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Check system metrics every 5 seconds: &lt;code&gt;atop 5&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Check system metrics within the next 5 minutes (total of 30 times, with a 10-second interval): &lt;code&gt;atop -M 10 30&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Check system metrics after 10 minutes (10 times, with a 60-second interval) and write the results to a file: &lt;code&gt;atop -M 60 10 &amp;gt; /log/atop.mem&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To view historical indicator logs: After atop starts, the collection records are stored by default in the &lt;code&gt;/var/log/atop&lt;/code&gt; directory. When viewing, be sure to check that the log file for the specified date exists; otherwise, an error will occur.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;View daily history indicators log: &lt;code&gt;atop -r&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View yesterday&amp;rsquo;s historical indicator logs: &lt;code&gt;atop -r y&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View historical indicator logs for a specified date, such as November 6, 2024: &lt;code&gt;atop -r 20241106&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View historical indicator logs from a specified time within a specified date, such as starting at 14:00 on November 6, 2024: &lt;code&gt;atop -r 20241106 -b 14:00&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View the historical indicator logs for a specified time period within a specific date, such as November 5, 2024 from 00:04 to 00:08: &lt;code&gt;atop -r 20241105 -b 00:04 -e 00:08&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;View System Activity Report&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Check the CPU utilization report of the current system within 1 minute (12 times, interval 5 seconds): &lt;code&gt;atopsar -c 5 12&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;To view the memory metrics report for a specified time period on that day, such as from 18:00 to 18:01: &lt;code&gt;atopsar -m -b 18:00 -e 18:01&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View memory metrics reports for a specified date and time period, such as November 5, 2024, from 18:00 to 18:01: &lt;code&gt;atopsar -m -r 20241105 -b 18:00 -e 18:01&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;v-other-operations&#34;&gt;V. Other Operations
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Configure a Tian-level log rotation policy: If you want to generate an atop index log file every day, you can perform the following operations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(Optional) Adjust the monitoring cycle, log retention time, and log storage path as needed&lt;/li&gt;
&lt;li&gt;Run command to set daily log rotation related services to start on boot and start the services: &lt;code&gt;sudo systemctl enable --now atop atopacct atop-rotate.timer&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;If the business has more complex requirements for log processing, it can be combined with logrotate or custom scripts to implement log management&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Load the optional netatop kernel module: If you need to monitor network usage, you can install the netatop module (this module is not installed by default in atop). Taking Alibaba Cloud Linux 3 as an example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Install the kernel development package and software environment required for compilation: &lt;code&gt;sudo yum install -y kernel-devel dkms elfutils-libelf-devel&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Download the latest version of netatop source code to a designated directory: &lt;code&gt;cd /usr/src/ &amp;amp;&amp;amp; sudo wget https://www.atoptool.nl/download/netatop-3.2.2.tar.gz --no-check-certificate&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Extract the source code and enter the source directory: &lt;code&gt;sudo tar -zxvf netatop-3.2.2.tar.gz &amp;amp;&amp;amp; cd netatop-3.2.2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Build and install the module and daemon from source code: &lt;code&gt;sudo make &amp;amp;&amp;amp; sudo make install&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the netatop service: &lt;code&gt;sudo systemctl start netatop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The atop tool is powerful and flexible. With proper installation, configuration, and usage, we can better understand the operating status of the Linux system, promptly discover and resolve potential issues. We hope this article will help everyone improve their skills in Linux system monitoring.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;[atop official website]&lt;/li&gt;
&lt;li&gt;Installing, Configuring, and Using the atop Monitoring Tool&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Loading mismatched PDB files in Visual Studio</title>
        <link>https://ttf248.life/en/p/visual-studio-loading-unmatched-pdb-files/</link>
        <pubDate>Thu, 23 Jan 2025 20:04:33 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/visual-studio-loading-unmatched-pdb-files/</guid>
        <description>&lt;p&gt;When debugging a program in Visual Studio on Windows, if the PDB file does not match the executable file, Visual Studio will prompt &amp;ldquo;Unable to load symbol file.&amp;rdquo; If the program crashes and a crash dump file is generated, Visual Studio may also fail to smoothly enter the crash site if the PDB file is mismatched&lt;/p&gt;
&lt;h2 id=&#34;what-is-a-pdb-file&#34;&gt;What is a pdb file?
&lt;/h2&gt;&lt;p&gt;PDB files are debugging information files created by Microsoft, used for debugging programs. They contain information such as program symbol tables, source file names, and line numbers. PDB files can be generated during program compilation for debugging purposes.&lt;/p&gt;
&lt;h2 id=&#34;debugging-with-windbg&#34;&gt;Debugging with WinDbg
&lt;/h2&gt;&lt;p&gt;WinDbg is a debugging tool from Microsoft that can be used to debug Windows programs. WinDbg can load mismatched PDB files, but they need to be loaded manually. The &lt;code&gt;.reload /f /i&lt;/code&gt; command can force the loading of mismatched PDB files.&lt;/p&gt;
&lt;p&gt;However, WinDbg is not as convenient to use as Visual Studio, so we hope that Visual Studio can also load mismatched PDB files&lt;/p&gt;
&lt;h2 id=&#34;visual-studio-loading-mismatched-pdb-file&#34;&gt;Visual Studio loading mismatched PDB file
&lt;/h2&gt;&lt;p&gt;Source code is generally managed through git now, so it&amp;rsquo;s possible to find the corresponding version of the code, recompile it, and generate the corresponding pdb file. Why can’t it be loaded? It’s mainly due to metadata mismatches.&lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s a small tool that can modify metadata, generate a new PDB file based on the executable file information, allowing Visual Studio to load it&lt;/p&gt;
&lt;p&gt;chkmatch download address: [https://www.debuginfo.com/tools/chkmatch.html]&lt;/p&gt;
&lt;p&gt;Site cache address: &lt;a class=&#34;link&#34; href=&#34;chkmatch.zip&#34; &gt;chkmatch.zip&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;ChkMatch utility can be used to check whether an executable and debug information file match. It can also be used to enforce matching between an executable and debug information file, if they are compatible.

For more information about debug information matching and related issues, see this article.

Supported debug information formats: DBG, PDB 2.0, PDB 7.0.

chkmatch [-c ExeFile DebugInfoFile ] |
         [-m ExeFile DebugInfoFile]
-c
Check matching between the executable and the debug information file.
-m
Make the executable and the debug information file match.
ExeFile
The name of the executable file.
DebugInfoFile
The name of the debug information file.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;use-chkmatch&#34;&gt;Use chkmatch
&lt;/h2&gt;&lt;p&gt;First, perform a verification check, analyze the reason for the mismatch, and prompt that the signature does not match&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\tianlong.xiang\Downloads\chkmatch&amp;gt;ChkMatch.exe -c &amp;quot;D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe&amp;quot; E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb
ChkMatch - version 1.0
Copyright (C) 2004 Oleg Starodumov
http://www.debuginfo.com/


Executable: D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe
Debug info file: E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb

Executable:
TimeDateStamp: c26d9be3
Debug info: 2 ( CodeView )
TimeStamp: f86b0a4f  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 122  RVA: 001cdc44  FileOffset: 001cbe44
CodeView format: RSDS
Signature: {428c9b95-39a3-4a8d-a8e5-7be453684757}  Age: 1
PdbFile: D:\stock_UAT\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\obj\Release\YinTrade.Main.pdb
Debug info: 16 ( Unknown )
TimeStamp: 00000000  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 0  RVA: 00000000  FileOffset: 00000000

Debug information file:
Format: PDB 7.00
Signature: {06fae08e-c0a2-4f3d-9c7c-dfc684445dd1}  Age: 1

Result: Unmatched (reason: Signature mismatch)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then perform modification operations to make the PDB file match the EXE file&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\tianlong.xiang\Downloads\chkmatch&amp;gt;ChkMatch.exe -m &amp;quot;D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe&amp;quot; E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb
ChkMatch - version 1.0
Copyright (C) 2004 Oleg Starodumov
http://www.debuginfo.com/


Executable: D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe
Debug info file: E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb

Executable:
TimeDateStamp: c26d9be3
Debug info: 2 ( CodeView )
TimeStamp: f86b0a4f  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 122  RVA: 001cdc44  FileOffset: 001cbe44
CodeView format: RSDS
Signature: {428c9b95-39a3-4a8d-a8e5-7be453684757}  Age: 1
PdbFile: D:\stock_UAT\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\obj\Release\YinTrade.Main.pdb
Debug info: 16 ( Unknown )
TimeStamp: 00000000  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 0  RVA: 00000000  FileOffset: 00000000

Debug information file:
Format: PDB 7.00
Signature: {06fae08e-c0a2-4f3d-9c7c-dfc684445dd1}  Age: 1

Writing to the debug information file...
Result: Success.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;reference-materials&#34;&gt;Reference materials
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://stackoverflow.com/questions/38147487/forcing-to-load-unmatched-symbols-in-visual-studio-2015-debugger&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;forcing-to-load-unmatched-symbols-in-visual-studio-2015-debugger&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Slow efficiency when processing large string data in Linux backend services</title>
        <link>https://ttf248.life/en/p/linux-backend-slow-string-processing/</link>
        <pubDate>Wed, 13 Nov 2024 19:42:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-backend-slow-string-processing/</guid>
        <description>&lt;p&gt;In C++ development projects, we used a custom protocol for communication that adopted a two-dimensional array pattern. When processing large amounts of data, the protocol needed to traverse and serialize arrays internally to generate logs. Due to low efficiency, this caused noticeable lag in the system under high load, which was reported by the business department.&lt;/p&gt;
&lt;h2 id=&#34;problem-identification&#34;&gt;Problem identification
&lt;/h2&gt;&lt;p&gt;When troubleshooting the issue, we first performed a performance analysis of the system and found that the CPU utilization increased significantly when processing large amounts of data, and the system response time lengthened. By analyzing the system logs, we discovered numerous serialization operations, which were inefficient when handling two-dimensional arrays, leading to decreased system performance.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;pstack&lt;/code&gt; tool captured thread information for the service, revealing that the log thread spends most of its time processing string concatenation&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Here&amp;rsquo;s the key point for today: different accumulation methods can make a huge difference in efficiency. The historical code uses the &lt;code&gt;+&lt;/code&gt; operator, which frequently creates temporary objects and is very inefficient. You know it’s inefficient, but you don’t realize just how inefficient it is.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;demo-verification&#34;&gt;Demo verification
&lt;/h2&gt;&lt;p&gt;Based on the project code, we extracted the business logic and wrote a simple demo to verify the efficiency of string concatenation. Compile and run with the &lt;code&gt;vs2022&lt;/code&gt; compiler under &lt;code&gt;windows&lt;/code&gt;, the &lt;code&gt;gcc8.5&lt;/code&gt; compiler under &lt;code&gt;linux&lt;/code&gt;, in &lt;code&gt;Release&lt;/code&gt; mode, and compare their efficiencies.&lt;/p&gt;
&lt;h3 id=&#34;key-points-explanation&#34;&gt;Key points explanation
&lt;/h3&gt;&lt;p&gt;The project uses method four. Before receiving the test data, readers can first think about which method is most efficient and which is least efficient? I was still very surprised when I saw the results.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Method 1 (Concatenation using +=): Directly concatenate each field to the string using +=&lt;/li&gt;
&lt;li&gt;Method 2 (using &lt;code&gt;std::ostringstream&lt;/code&gt; concatenation): This method uses streams (&lt;code&gt;std::ostringstream&lt;/code&gt;) to concatenate each field, which is more efficient, especially when concatenating large amounts of data&lt;/li&gt;
&lt;li&gt;Method 3 (Pre-allocated Memory with &lt;code&gt;+=&lt;/code&gt;) involves allocating sufficient memory for the string in advance using &lt;code&gt;reserve&lt;/code&gt;, which reduces the overhead of memory reallocation and improves performance&lt;/li&gt;
&lt;li&gt;Method 4 (&lt;code&gt;bodys = bodys + body + &amp;quot;\n&amp;quot;&lt;/code&gt;): Creating a new temporary string object with each concatenation leads to performance degradation, especially when concatenating strings on a large scale, because each concatenation involves a new memory allocation and copy&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;According to the results, the project selected the least efficient method&lt;/p&gt;
&lt;p&gt;To take things a step further, let&amp;rsquo;s analyze the optimization efficiency of different platform compilers. Microsoft&amp;rsquo;s &lt;code&gt;Visual Studio&lt;/code&gt; remains consistently excellent, with very high optimization efficiency for strings, while the &lt;code&gt;GCC&lt;/code&gt; compiler is somewhat lacking in this area.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The code runs on different machines, and there is no direct comparison between the two sets of data. You can compare the differences between different concatenation methods separately.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;windows 平台下的 vs2022 编译器

----------------------------------------
Data Generation Time: 0.054 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.053 seconds.
+ ostringstream Data merging took: 0.054 seconds.
+ Pre-reserved Data merging took: 0.045 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 16.108 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;linux 平台下的 gcc8.5 编译器
----------------------------------------
Data Generation Time: 0.108 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.100 seconds.
+ ostringstream Data merging took: 0.083 seconds.
+ Pre-reserved Data merging took: 0.057 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 29.298 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code&#34;&gt;Complete code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;random&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;sstream&amp;gt;
#include &amp;lt;iomanip&amp;gt;

typedef std::vector&amp;lt;std::string&amp;gt; DataRow;
typedef std::vector&amp;lt;DataRow&amp;gt; DataGroup;

struct ResponsePackage
{
    std::string ErrorInfo;
    DataRow Head;
    std::string ClientId;
    std::string UUID;
    std::string MsgID;
    std::string SessionID;
    std::string ExtraInfo1;
    std::string ExtraInfo2;
    DataGroup DataBody;
};

// Generate specified length of random string
std::string generateRandomString(size_t length)
{
    const char charset[] = &amp;quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&amp;quot;;
    const size_t max_index = sizeof(charset) - 1;
    std::string random_string;
    random_string.reserve(length);

    std::random_device rd;
    std::mt19937 generator(rd());
    std::uniform_int_distribution&amp;lt;&amp;gt; distribution(0, max_index);

    for (size_t i = 0; i &amp;lt; length; ++i)
    {
        random_string += charset[distribution(generator)];
    }

    return random_string;
}

void create_large_string()
{
    // Example request package with 50 fields
    ResponsePackage requestPackage;

    requestPackage.Head = {
        &amp;quot;Field1&amp;quot;, &amp;quot;Field2&amp;quot;, &amp;quot;Field3&amp;quot;, &amp;quot;Field4&amp;quot;, &amp;quot;Field5&amp;quot;,
        &amp;quot;Field6&amp;quot;, &amp;quot;Field7&amp;quot;, &amp;quot;Field8&amp;quot;, &amp;quot;Field9&amp;quot;, &amp;quot;Field10&amp;quot;,
        &amp;quot;Field11&amp;quot;, &amp;quot;Field12&amp;quot;, &amp;quot;Field13&amp;quot;, &amp;quot;Field14&amp;quot;, &amp;quot;Field15&amp;quot;,
        &amp;quot;Field16&amp;quot;, &amp;quot;Field17&amp;quot;, &amp;quot;Field18&amp;quot;, &amp;quot;Field19&amp;quot;, &amp;quot;Field20&amp;quot;,
        &amp;quot;Field21&amp;quot;, &amp;quot;Field22&amp;quot;, &amp;quot;Field23&amp;quot;, &amp;quot;Field24&amp;quot;, &amp;quot;Field25&amp;quot;,
        &amp;quot;Field26&amp;quot;, &amp;quot;Field27&amp;quot;, &amp;quot;Field28&amp;quot;, &amp;quot;Field29&amp;quot;, &amp;quot;Field30&amp;quot;,
        &amp;quot;Field31&amp;quot;, &amp;quot;Field32&amp;quot;, &amp;quot;Field33&amp;quot;, &amp;quot;Field34&amp;quot;, &amp;quot;Field35&amp;quot;,
        &amp;quot;Field36&amp;quot;, &amp;quot;Field37&amp;quot;, &amp;quot;Field38&amp;quot;, &amp;quot;Field39&amp;quot;, &amp;quot;Field40&amp;quot;,
        &amp;quot;Field41&amp;quot;, &amp;quot;Field42&amp;quot;, &amp;quot;Field43&amp;quot;, &amp;quot;Field44&amp;quot;, &amp;quot;Field45&amp;quot;,
        &amp;quot;Field46&amp;quot;, &amp;quot;Field47&amp;quot;, &amp;quot;Field48&amp;quot;, &amp;quot;Field49&amp;quot;, &amp;quot;Field50&amp;quot;
    };

    requestPackage.ClientId = &amp;quot;ClientID&amp;quot;;
    requestPackage.UUID = &amp;quot;UUID&amp;quot;;
    requestPackage.MsgID = &amp;quot;MsgID&amp;quot;;
    requestPackage.SessionID = &amp;quot;SessionID&amp;quot;;
    requestPackage.ExtraInfo1 = &amp;quot;ExtraInfo1&amp;quot;;
    requestPackage.ExtraInfo2 = &amp;quot;ExtraInfo2&amp;quot;;

    // Start timing for data generation
    auto start_gen = std::chrono::high_resolution_clock::now();

    // Generate 10,000 rows of data, each with 50 fields
    for (size_t i = 0; i &amp;lt; 10000; ++i)
    {
        DataRow dataRow(50, &amp;quot;This is a test string&amp;quot;);
        requestPackage.DataBody.push_back(dataRow);
    }

    // End timing for data generation
    auto end_gen = std::chrono::high_resolution_clock::now();
    std::chrono::duration&amp;lt;double&amp;gt; duration_gen = end_gen - start_gen;

    // Display result generation time
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Generation Time: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_gen.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    // Data merging using different methods
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Performance:\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    {
        // Method 1: Using &#39;+=&#39; string concatenation
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys(&amp;quot;&amp;quot;);
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (+=) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 2: Using ostringstream
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::ostringstream bodys;
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::ostringstream body;
            body &amp;lt;&amp;lt; &amp;quot;This is a test string&amp;quot;;
            for (auto&amp;amp; item : vec)
            {
                body &amp;lt;&amp;lt; item &amp;lt;&amp;lt; &amp;quot; &amp;quot;;
            }
            bodys &amp;lt;&amp;lt; body.str() &amp;lt;&amp;lt; &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ ostringstream Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 3: Pre-allocated memory
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys;
        bodys.reserve(1000 * 50 * 20); // Pre-allocate enough memory
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            body.reserve(50 * 20); // Pre-allocate memory for each row
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Pre-reserved Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 4: Using &#39;bodys = bodys + body + &amp;quot;\n&amp;quot;&#39;
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys(&amp;quot;&amp;quot;);
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            for (auto&amp;amp; item : vec)
            {
                body = body + item + &amp;quot; &amp;quot;; // Note the use of &#39;body = body + item&#39;
            }
            bodys = bodys + body + &amp;quot;\n&amp;quot;; // Again, using &#39;bodys = bodys + body&#39;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (bodys = bodys + body + \&amp;quot;\\n\&amp;quot;) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Complete.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;
}

int main()
{
    try
    {
        create_large_string();
    }
    catch (const std::exception&amp;amp; e)
    {
        std::cerr &amp;lt;&amp;lt; &amp;quot;Caught exception: &amp;quot; &amp;lt;&amp;lt; e.what() &amp;lt;&amp;lt; std::endl;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\nProgram finished.\n&amp;quot;;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Win11 Logitech G431 Headphone Driver Installation</title>
        <link>https://ttf248.life/en/p/win11-logitech-g431-headphone-driver-installation/</link>
        <pubDate>Wed, 05 Jun 2024 07:20:17 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/win11-logitech-g431-headphone-driver-installation/</guid>
        <description>&lt;p&gt;Picking up where we left off, I came back to find that Ghub had been updated, which made me a little happy. The customer service said they fixed the issue of not being able to load problem drivers properly, but after messing around with it for a while – reinstalling and uninstalling – it still doesn&amp;rsquo;t work normally.&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background
&lt;/h2&gt;&lt;p&gt;I continued to contact customer service for a solution, but was told that an engineer could provide remote assistance. However, the engineer&amp;rsquo;s working hours were exactly the same as mine, so I had no choice but to give up. I reviewed the materials from the previous troubleshooting and prepared to try installing the driver manually.&lt;/p&gt;
&lt;h2 id=&#34;get-the-driver-installation-package&#34;&gt;Get the driver installation package
&lt;/h2&gt;&lt;p&gt;How can I obtain the driver files since Logitech doesn&amp;rsquo;t provide a separate driver installation package for their devices?&lt;/p&gt;
&lt;p&gt;With the system image installation package left over from the last system reinstallation, we can reinstall the system in a local virtual machine. In the cleanest system, deploy Ghub separately, insert the headset device into the virtual machine, find the driver path, and copy it out.&lt;/p&gt;
&lt;p&gt;Related paths:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C:\ProgramData\LGHUB&lt;/li&gt;
&lt;li&gt;C:\Windows\System32\DriverStore\FileRepository\logi_audio.inf_amd64_010b035044e24be4&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;device-manager&#34;&gt;Device Manager
&lt;/h2&gt;&lt;p&gt;The key is how to find the second path. Let&amp;rsquo;s first briefly review how to manually manage driver files in Win11 systems. This content was identified using the control variable method, by constantly plugging and unplugging devices and analyzing device information in Device Manager within a virtual machine. We identified that three drivers need to be handled for the headset. Two of these drivers are built-in system drivers, and only one is provided by Logitech.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Driver Manager&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;The second driver in the image is provided by Logitech. We analyze the current device drivers, and search through all driver paths within the virtual machine. Of course, you first need to find files starting with &amp;ldquo;logi,&amp;rdquo; then compare the files. You&amp;rsquo;ll be able to locate the driver file. Copy the entire folder, and you’ve got the driver installation package.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Driver installation package&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;install-driver&#34;&gt;Install driver
&lt;/h2&gt;&lt;p&gt;Still in the Device Manager interface, click: Update Driver, click: Browse My Computer for Drivers, and you will enter the following interface:&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Driver Installation&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Of course, when you open it, you can only see a drive – that&amp;rsquo;s the standard USB drive. Choose &amp;ldquo;Install from disk,&amp;rdquo; and the path is the folder we copied earlier. After installation, a Logitech-specific driver will appear in the drop-down list. Switch the device driver to the newly installed one.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Disk Installation&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;anatomy-equipment-drivers&#34;&gt;Anatomy equipment drivers
&lt;/h2&gt;&lt;p&gt;The drivers for this device are provided by the system. You only need to check if there&amp;rsquo;s an exclamation mark in front of the device driver; if there is, go into the driver selection interface and switch to a different type of driver, then change it back to restore normal functionality.&lt;/p&gt;
&lt;h2 id=&#34;completed&#34;&gt;Completed
&lt;/h2&gt;&lt;p&gt;The headset microphone volume has returned to normal, and the familiar ear monitoring function is back as well&lt;/p&gt;
&lt;p&gt;Side sound&lt;/p&gt;</description>
        </item>
        <item>
        <title>Why is the speed test result only 100 Mbps for a newly installed Gigabit fiber connection?</title>
        <link>https://ttf248.life/en/p/new-gigabit-fiber-slow-speed/</link>
        <pubDate>Mon, 18 Mar 2024 00:29:02 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/new-gigabit-fiber-slow-speed/</guid>
        <description>&lt;p&gt;Want your home network to be as fast as lightning? The key lies in understanding the choice of network cables, configuring the optical network terminal and router, and those seemingly insignificant details. This blog will guide you through how to build a Gigabit network with Cat6 Ethernet cable and how to ensure your network speed is not limited by simple device checks and configurations. Let&amp;rsquo;s explore together and make your home internet fly!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Manual Repair&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;chapter-1-in-depth-analysis-of-network-transmission-media&#34;&gt;Chapter 1: In-Depth Analysis of Network Transmission Media
&lt;/h2&gt;&lt;p&gt;When we talk about achieving gigabit network access, the carrier of information at high speed – the network cable – plays a crucial role. The following will provide a detailed explanation of Cat 5, Cat 6, and Cat 7 cables:&lt;/p&gt;
&lt;h3 id=&#34;cat-5-network-cable&#34;&gt;Cat 5 network cable
&lt;/h3&gt;&lt;p&gt;Category 5 network cables, also known as CAT5, are an early type of twisted-pair cable that uses a precise spiral structure design to reduce crosstalk. It is mainly used for 10/100Mbps fast Ethernet, with a maximum transmission frequency of approximately 100MHz. Although widely used in the past, Category 5 network cables cannot meet current requirements for gigabit and higher speeds due to physical limitations.&lt;/p&gt;
&lt;h3 id=&#34;six-category-ethernet-cable-cat6&#34;&gt;Six-Category Ethernet Cable (CAT6)
&lt;/h3&gt;&lt;p&gt;With the development of technology, Cat6 cabling emerged. Compared to Cat5 cabling, Cat6 cables adopted stricter manufacturing standards and more advanced structural designs, significantly improving anti-interference capabilities and transmission efficiency. They can support a transmission rate of up to 1Gbps and, under ideal conditions, achieve a transmission distance of 100 meters – perfectly meeting the access requirements of Gigabit networks.&lt;/p&gt;
&lt;h3 id=&#34;seven-category-ethernet-cable-cat7&#34;&gt;Seven-Category Ethernet Cable (CAT7)
&lt;/h3&gt;&lt;p&gt;Seven categories of network cable represent the pinnacle of current twisted-pair technology. It not only boasts a significant improvement in transmission rate, theoretically supporting up to 10Gbps of ultra-high speed, but also incorporates a complete shielding system in its design, including shielding between each pair of wires and overall outer layer shielding, thereby greatly reducing external electromagnetic interference and near-end crosstalk, ensuring the stability and accuracy of data transmission. However, seven categories of network cable is mainly used for future 10 Gigabit Ethernet or specific high-demand scenarios.&lt;/p&gt;
&lt;p&gt;When building a Gigabit home network, choosing Cat6 cabling is the most economical and efficient option to fully unleash the potential of the Gigabit fiber. Ensuring that all connecting cables are of qualified quality and strictly following standard wiring practices is also an important link in ensuring network performance.&lt;/p&gt;
&lt;h2 id=&#34;chapter-2-delving-into-network-core-devicesthe-impact-of-optical-network-terminal-ont-and-router-lan-port-bandwidth&#34;&gt;Chapter 2: Delving into Network Core Devices—The Impact of Optical Network Terminal (ONT) and Router LAN Port Bandwidth
&lt;/h2&gt;&lt;h3 id=&#34;the-importance-of-the-optical-network-terminal-and-its-lan-port-bandwidth&#34;&gt;The importance of the optical network terminal and its LAN port bandwidth
&lt;/h3&gt;&lt;p&gt;The Optical Network Terminal (ONT), also known as an optical modem, is the core device for home broadband access. Its function is to convert the light signal from fiber into a digital signal for use by home network devices. For users with gigabit fiber connections, whether the ONT supports gigabit transmission is particularly important. If the ONT&amp;rsquo;s WAN port only supports 100Mbps, even if the fiber-to-the-home rate is higher, it will be limited to within 100Mbps due to this bottleneck. Similarly, the ONT’s LAN port also needs to have gigabit output capabilities; otherwise, routers or other devices connected to it cannot achieve true gigabit speeds.&lt;/p&gt;
&lt;h3 id=&#34;the-role-of-bandwidth-for-the-lan-ports-on-a-router&#34;&gt;The role of bandwidth for the LAN ports on a router
&lt;/h3&gt;&lt;p&gt;The router&amp;rsquo;s LAN port is responsible for distributing received data to various terminal devices. When the router’s LAN port is limited to gigabit speed, even if other equipment is well-configured, it can only achieve gigabit network communication. Therefore, when building a Gigabit home network, ensure that the router’s WAN port can receive Gigabit data and that the LAN port can also provide Gigabit-level output capabilities so that all smart devices in your home can enjoy the smooth experience brought by high-speed networks.&lt;/p&gt;
&lt;p&gt;In addition, it is important to note that some older or low-end routers may have an auto-negotiation mechanism for the LAN port rate. This means that even if the router itself supports gigabit speeds, it may downgrade to 100Mbps mode due to factors such as cabling and device compatibility. Therefore, correctly configuring the router parameters, enabling forced gigabit mode, and using a gigabit switch or direct connection are key steps in achieving an all-gigabit network.&lt;/p&gt;
&lt;p&gt;After upgrading to Gigabit fiber, be sure to check and replace your Optical Network Terminal (ONT) and router with Gigabit devices, ensuring that all device interfaces meet the Gigabit standard&lt;/p&gt;
&lt;h2 id=&#34;chapter-3-the-mystery-of-latency--how-a-broken-thread-can-affect-gigabit-network-speed&#34;&gt;Chapter 3: The Mystery of Latency – How a Broken Thread Can Affect Gigabit Network Speed
&lt;/h2&gt;&lt;h3 id=&#34;subnet-cable-failure-and-network-performance-degradation&#34;&gt;Subnet cable failure and network performance degradation
&lt;/h3&gt;&lt;p&gt;The network remained connected throughout the speed test, with no obvious disconnections. As it&amp;rsquo;s a newly installed broadband connection, the wiring closet is quite cluttered, and I occasionally adjust the fiber modem’s cabling and power outlet location, which has resulted in speeds reaching gigabit on rare occasions.&lt;/p&gt;
&lt;p&gt;Based on the previous information, we analyzed and ruled out various factors such as network cable model and optical modem LAN port speed, ultimately discovering that the culprit was a broken brown internal wire within the network cable&lt;/p&gt;
&lt;p&gt;The reason for the disconnection: When the technician installed the crystal head, they pulled on this network cable a little too hard, causing one of the wires to break in half. It didn&amp;rsquo;t completely disconnect at the time, but subsequent adjustments to the optical modem’s position and repeated movement caused it to finally break.&lt;/p&gt;
&lt;h3 id=&#34;analysis-of-the-functions-of-eight-wires-in-six-categories-of-network-cables&#34;&gt;Analysis of the Functions of Eight Wires in Six Categories of Network Cables
&lt;/h3&gt;&lt;p&gt;Six categories of network cables follow the TIA/EIA-568-B standard, consisting of eight twisted pairs with the following color coding:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;White Orange / Orange&lt;/li&gt;
&lt;li&gt;White and green / Green&lt;/li&gt;
&lt;li&gt;White and blue / Blue&lt;/li&gt;
&lt;li&gt;Tan / Brown&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Under the Gigabit Ethernet (1000BASE-T) standard, four pairs of wires within these eight lines work simultaneously, with the following specific functions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The white-orange and orange pair of wires (1 &amp;amp; 2) are used for sending data (Tx+/–)&lt;/li&gt;
&lt;li&gt;The white-green and green-green pair of wires (3 &amp;amp; 6) are used for receiving data (Rx+/-);&lt;/li&gt;
&lt;li&gt;The white-blue and blue pair (4&amp;amp;5) as well as the white-brown and brown pair (7&amp;amp;8) are not originally designated for use in Gigabit Ethernet, but may be enabled in certain advanced applications (such as partial PoE power supply or future technology extensions). In traditional 100Mbps networks, only the four wires 1, 2, 3, and 6 are actually needed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;the-impact-of-broken-chains-on-network-speed&#34;&gt;The impact of broken chains on network speed
&lt;/h3&gt;&lt;p&gt;In the above situation, if a brown sub-line (brown or brown-white wire) is broken, it will theoretically cause a speed reduction in a Gigabit network environment because a Gigabit network requires all four pairs of wires to transmit bidirectionally at full speed. However, due to the automatic negotiation function often found in home network devices, when a cable problem is detected, it will revert to a lower rate mode that can operate normally, which is 100Mbps mode. This explains why even with one sub-line broken, the network can remain connected and operate at 100Mbps speed.&lt;/p&gt;
&lt;p&gt;In short, while a broken brown fiber strand does not affect the basic operation of a 100-megabit network, it can be a key factor limiting network speed in a gigabit environment. Only through thorough diagnosis and repair can the full potential of the gigabit fiber optic cable be realized. This also reminds us that when encountering similar situations, we should not overlook any potential network infrastructure issues, even seemingly minor faults that do not affect basic connectivity, as they may become hidden obstacles to high-speed network experiences.&lt;/p&gt;</description>
        </item>
        <item>
        <title>UI thread issues and solutions in WPF</title>
        <link>https://ttf248.life/en/p/wpf-ui-thread-and-freezing-issues-solutions/</link>
        <pubDate>Tue, 12 Mar 2024 07:12:21 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/wpf-ui-thread-and-freezing-issues-solutions/</guid>
        <description>&lt;p&gt;When developing desktop applications, especially when building rich client applications using the Windows Presentation Foundation (WPF) framework, correctly handling the user interface (UI) thread is crucial for ensuring application smoothness and responsiveness. The UI thread, also known as the main thread, is the core thread responsible for processing window and control events, layout calculations, and rendering the interface. Any operation that interacts with UI elements should be executed on the UI thread; this is a fundamental principle followed by WPF and most other GUI frameworks.&lt;/p&gt;
&lt;h2 id=&#34;what-is-the-ui-thread&#34;&gt;What is the UI thread?
&lt;/h2&gt;&lt;p&gt;The UI thread is created and initialized by the operating system when a WPF application starts, and it initializes the application&amp;rsquo;s main window. It’s the only thread that can directly access and modify the state of UI components in the application. This means all user interactions, such as button clicks, text box input, and window resizing, are handled within this thread&amp;rsquo;s context. Simultaneously, WPF&amp;rsquo;s dependency property system, data binding mechanism, and layout logic also execute synchronously on the UI thread.&lt;/p&gt;
&lt;h2 id=&#34;stuttering-phenomenon-and-its-causes&#34;&gt;Stuttering phenomenon and its causes
&lt;/h2&gt;&lt;p&gt;When the UI thread is occupied or blocked for an extended period, such as when performing time-consuming calculations, loading large amounts of data, querying databases, or other I/O-intensive tasks, it can prevent the UI thread from responding to user interactions in a timely manner, resulting in a frozen interface (Freeze), which we commonly refer to as &amp;ldquo;lag.&amp;rdquo; In this situation, users will noticeably feel the application&amp;rsquo;s delay and sluggishness, and severe cases may even trigger an “Application Not Responding” (ANR) warning&lt;/p&gt;
&lt;h2 id=&#34;the-two-basic-rules-of-the-ui-thread&#34;&gt;The two basic rules of the UI thread
&lt;/h2&gt;&lt;p&gt;To avoid these situations, WPF developers should follow these two key rules:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Avoid performing time-consuming operations on the UI thread. Any operation that may cause the UI thread to freeze should be moved to a background thread as much as possible to ensure that the UI thread can respond to user input and render screen changes in a timely manner.&lt;/li&gt;
&lt;li&gt;Do not directly update UI elements on non-UI threads. Due to the security mechanism design of WPF, only the UI thread is authorized to modify UI elements. Attempting to change the UI state directly from another thread will throw an exception. Therefore, even if a background thread has completed calculations or data preparation, it needs to display the results on the UI through appropriate cross-thread communication mechanisms.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;solution-asynchronous-programming-and-thread-safe-updates&#34;&gt;Solution: Asynchronous Programming and Thread-Safe Updates
&lt;/h2&gt;&lt;p&gt;To maintain a smooth UI while executing time-consuming tasks, WPF provides various asynchronous programming models and tools to help developers achieve this goal&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Dispatcher object: The WPF Dispatcher class allows you to schedule work items for execution in the UI thread&amp;rsquo;s task queue. You can safely update the UI from background threads using the &lt;code&gt;Dispatcher.Invoke&lt;/code&gt; or &lt;code&gt;Dispatcher.BeginInvoke&lt;/code&gt; methods.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;async/await&lt;/code&gt; keywords allow you to write asynchronous methods and use the &lt;code&gt;await&lt;/code&gt; keyword to wait for background tasks to complete, automatically returning to the UI thread to execute subsequent UI update code upon completion&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;case-study&#34;&gt;Case study
&lt;/h2&gt;&lt;h3 id=&#34;use-the-dispatcherinvoke-method-to-update-the-ui&#34;&gt;Use the &lt;code&gt;Dispatcher.Invoke&lt;/code&gt; method to update the UI
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;private void Button_Click(object sender, RoutedEventArgs e)
{
    // 假设这是一个耗时操作
    Task.Run(() =&amp;gt;
    {
        var result = LongRunningOperation(); // 这里是模拟一个耗时计算的方法
        
        // 当耗时操作完成后，在UI线程上更新UI
        Application.Current.Dispatcher.Invoke(() =&amp;gt;
        {
            LabelStatus.Text = $&amp;quot;计算结果: {result}&amp;quot;;
        });
    });
}

private string LongRunningOperation()
{
    // 模拟耗时操作
    Thread.Sleep(5000);
    return &amp;quot;已完成&amp;quot;;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;use-asyncawait-keywords-with-taskrun&#34;&gt;Use &lt;code&gt;async/await&lt;/code&gt; keywords with &lt;code&gt;Task.Run&lt;/code&gt;
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;private async void Button_ClickAsync(object sender, RoutedEventArgs e)
{
    Button button = sender as Button;
    button.IsEnabled = false; // 防止用户重复点击

    try
    {
        // 开启后台任务
        var result = await Task.Run(() =&amp;gt; LongRunningOperation());

        // 在后台任务完成后，自动切换回UI线程更新UI
        LabelStatus.Text = $&amp;quot;计算结果: {result}&amp;quot;;
    }
    catch (Exception ex)
    {
        MessageBox.Show($&amp;quot;发生错误: {ex.Message}&amp;quot;);
    }
    finally
    {
        button.IsEnabled = true; // 重新启用按钮
    }
}
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Upgrading GCC version leads to program crashes: Hidden dangers of non-compliant code</title>
        <link>https://ttf248.life/en/p/upgrade-gcc-version-causes-program-crash-code-irregularities/</link>
        <pubDate>Sun, 10 Mar 2024 23:19:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/upgrade-gcc-version-causes-program-crash-code-irregularities/</guid>
        <description>&lt;p&gt;In the same business code segment, the program compiled and ran normally in the CentOS 7 environment, but when switched to CentOS 8 and compiled with an updated version of GCC, it crashed. It is worth noting that the problem only occurred in &lt;strong&gt;Release mode&lt;/strong&gt;, there were no issues at all in &lt;strong&gt;Debug mode&lt;/strong&gt;. This was the first time we encountered a situation like this, and after three days of troubleshooting, we finally found the root cause.&lt;/p&gt;
&lt;h3 id=&#34;problem-identification&#34;&gt;Problem identification
&lt;/h3&gt;&lt;p&gt;After some troubleshooting, the root cause of the problem is that &lt;strong&gt;the function lacks a return value&lt;/strong&gt;. In Release mode, newer versions of GCC perform more optimizations, which leads to undefined behavior in functions that originally lacked explicit return values during execution, resulting in crashes. Our conclusion is that &lt;strong&gt;compiler warnings should not be ignored, especially in older projects where some warnings may have been overlooked; however, we should avoid suppressing all warnings&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;environmental-description&#34;&gt;Environmental Description
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;CentOS 7 GCC version:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39)
Copyright © 2015 Free Software Foundation, Inc.
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CentOS 8 GCC version:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-21)
Copyright (C) 2018 Free Software Foundation, Inc.
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;crash-phenomenon&#34;&gt;Crash phenomenon
&lt;/h3&gt;&lt;p&gt;When analyzing the crash stack of the program, we observed the following stack information:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[New LWP 1385902]
[Thread debugging using libthread_db enabled]
Using host libthread_db library &amp;quot;/lib64/libthread_db.so.1&amp;quot;.
Core was generated by `./pstack_main`.
Program terminated with signal SIGSEGV, Segmentation fault.
#0  0x00007ffe894b4420 in ?? ()
(gdb) bt
#0  0x00007ffe894b4420 in ?? ()
#1  0x00000000004008e9 in main ()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This stack looks far from intuitive; the crash function&amp;rsquo;s stack information is displayed as a &lt;code&gt;??&lt;/code&gt;, which makes troubleshooting even more complicated&lt;/p&gt;
&lt;h3 id=&#34;code-example&#34;&gt;Code example
&lt;/h3&gt;&lt;p&gt;To better understand the issue, here&amp;rsquo;s a minimal code example to reproduce the crash:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;map&amp;gt;

int test() {
    std::cout &amp;lt;&amp;lt; &amp;quot;1&amp;quot; &amp;lt;&amp;lt; std::endl;
}

int main() {
    test();
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;test()&lt;/code&gt; function in this code apparently does not explicitly return a value, while its return type is declared as &lt;code&gt;int&lt;/code&gt;. According to the C++ specification, when a function is declared as type &lt;code&gt;int&lt;/code&gt;, it must have a return value; otherwise, undefined behavior may occur.&lt;/p&gt;
&lt;h3 id=&#34;compilation-warning&#34;&gt;Compilation warning
&lt;/h3&gt;&lt;p&gt;In our project, CMake scripts have suppressed many compile-time warnings, including the following warning message:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;/root/pstack/main.cpp: In function ‘int test()’:
/root/pstack/main.cpp:7:1: warning: no return statement in function returning non-void [-Wreturn-type]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This warning indicates that the &lt;code&gt;test()&lt;/code&gt; function does not return a value, which is the root of the problem. High versions of GCC (such as 8.5.0) may make unstable optimizations when optimizing code due to this undefined behavior, leading to program crashes.&lt;/p&gt;
&lt;h3 id=&#34;assembly-code-differences&#34;&gt;Assembly code differences
&lt;/h3&gt;&lt;p&gt;To explain the differences in GCC compiler optimization behavior, we compared the assembly code generated by different versions of GCC&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Assembly code generated by GCC 4.8.5:&lt;/p&gt;
&lt;p&gt;Assembly code is relatively verbose and includes handling logic for the standard output stream (such as &lt;code&gt;std::cout&lt;/code&gt;). This indicates that the compiler performed more conservative optimizations, did not extensively optimize the missing return value issue in the &lt;code&gt;test()&lt;/code&gt; function, possibly to avoid crashes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Assembly code generated by GCC 8.5.0:&lt;/p&gt;
&lt;p&gt;The new version of GCC has undergone more optimizations, reducing code volume. However, this optimization may cause undefined behavior when functions lacking return values are executed, potentially leading to program crashes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h3&gt;&lt;p&gt;Through this issue investigation, we deeply realized that in C++, &lt;strong&gt;function return values must be explicit&lt;/strong&gt;, especially when a function is declared as &lt;code&gt;int&lt;/code&gt;, it must provide a return value. Projects using older compilers may encounter more optimizations and stricter warning mechanisms when upgrading to newer versions of GCC. Therefore, we recommend against suppressing all warnings during compilation; instead, they should be handled selectively, particularly common issues such as function return values and type matching.&lt;/p&gt;
&lt;p&gt;Ultimately, the issue was resolved by adding a return value to the &lt;code&gt;test()&lt;/code&gt; function, and the program returned to normal operation&lt;/p&gt;</description>
        </item>
        <item>
        <title>VMware virtual machine CPU resource usage anomaly</title>
        <link>https://ttf248.life/en/p/vmware-virtual-machine-cpu-resource-usage-anomaly/</link>
        <pubDate>Sun, 10 Mar 2024 22:14:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/vmware-virtual-machine-cpu-resource-usage-anomaly/</guid>
        <description>&lt;p&gt;The background is that the locally deployed Windows version of the business system occupies about 5% of CPU resources. The Linux version of the business system deployed in VMware-installed CentOS8 has abnormal resource occupancy.&lt;/p&gt;
&lt;h2 id=&#34;problem-description&#34;&gt;Problem description
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Host machine: Windows 10 Enterprise Edition&lt;/li&gt;
&lt;li&gt;vmware：17.5&lt;/li&gt;
&lt;li&gt;Virtual machine: CentOS 8&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Virtual machine resources are allocated as &lt;code&gt;4C8GB&lt;/code&gt;, and the business system is started. The business system is deployed in a virtual machine Linux environment. Inside the virtual machine, the top command observes system resource usage, and CPU utilization is not high. However, in the outer Windows system, Task Manager shows very high CPU resource utilization. Checking processes reveals that the VMware process consumes a lot of CPU resources.&lt;/p&gt;
&lt;p&gt;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+
|         Windows           |
|                           |
|   +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+  |
|   |      VMware        |  |
|   |      Program       |  |
|   +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+  |
|                           |
+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&lt;/p&gt;
&lt;h2 id=&#34;key-points&#34;&gt;Key points
&lt;/h2&gt;&lt;p&gt;Troubleshooting this issue has not been smooth, as the root cause wasn&amp;rsquo;t in the business system itself but rather a problem with the virtual machine. How to shift focus from routine business code to system load, then from anomalies in load data to soft interrupts, and finally pinpoint the key factor: what could affect the efficiency of VMware soft interrupts? This article will first explain the relevant knowledge points and then provide a solution.&lt;/p&gt;
&lt;h3 id=&#34;hyper-v&#34;&gt;hyper-v
&lt;/h3&gt;&lt;p&gt;Virtualization technology for Windows operating systems has undergone a significant change. When Microsoft first released WSL, enabling the Hyper-V service would prevent the simultaneous use of VMware virtual machines. It wasn&amp;rsquo;t until subsequent versions that VMware became compatible with the Hyper-V service.&lt;/p&gt;
&lt;h3 id=&#34;system-load&#34;&gt;System load
&lt;/h3&gt;&lt;p&gt;In a Linux system, &amp;ldquo;load&amp;rdquo; refers to the number of processes that are running or waiting to be executed in the system. Load is typically represented by three numbers, which represent the average number of processes in the run queue over 1 minute, 5 minutes, and 15 minutes. These numbers can be viewed by running the &amp;ldquo;uptime&amp;rdquo; command or the &amp;ldquo;top&amp;rdquo; command.&lt;/p&gt;
&lt;p&gt;Specifically, these three numbers represent:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Average number of processes in the run queue over the past 1 minute&lt;/li&gt;
&lt;li&gt;Average number of processes in the run queue over the past 5 minutes&lt;/li&gt;
&lt;li&gt;Average number of processes in the run queue over the past 15 minutes&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The meaning of load is the number of processes waiting to run in the system. If this number exceeds the logical CPU count of the system, it indicates a high system load, meaning that many processes are waiting for processor resources. This can lead to the system becoming slow or unresponsive, depending on the degree of the load and the system&amp;rsquo;s configuration and performance.&lt;/p&gt;
&lt;p&gt;Ideally, the load should be maintained within the logical CPU count of the system to optimize performance. If the load consistently exceeds the number of CPUs, further analysis of processes in the system may be necessary to identify the cause of the high load and take appropriate measures to adjust system resource allocation or optimize process execution methods.&lt;/p&gt;
&lt;h3 id=&#34;analyzing-load-with-mpstat&#34;&gt;Analyzing load with mpstat
&lt;/h3&gt;&lt;p&gt;The &lt;code&gt;mpstat&lt;/code&gt; command is used to report multiple pieces of information for single or multiple processors, including average load, CPU utilization, interrupts, and context switching. As a useful tool in the &lt;code&gt;sysstat&lt;/code&gt; package, &lt;code&gt;mpstat&lt;/code&gt; can be used to analyze system load conditions. The following are the steps for using &lt;code&gt;mpstat&lt;/code&gt; to perform load analysis:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Installing sysstat
If &lt;code&gt;sysstat&lt;/code&gt; is not installed on your system, you can use a package management tool suitable for your system to install it&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run mpstat
Use the &lt;code&gt;mpstat&lt;/code&gt; command to view CPU usage and load. By default, &lt;code&gt;mpstat&lt;/code&gt; displays the average CPU usage every second. You can adjust the output frequency by specifying a time interval. For example, to run &lt;code&gt;mpstat&lt;/code&gt; once per second, you can use the following command: &lt;code&gt;mpstat -P ALL 2&lt;/code&gt;, where &lt;code&gt;irq&lt;/code&gt; indicates resource occupancy.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;01:32:33 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
01:32:35 PM  all    0.00    0.00    0.26    0.00    3.73    0.26    0.00    0.00    0.00   95.76
01:32:35 PM    0    0.00    0.00    0.51    0.00    3.57    0.00    0.00    0.00    0.00   95.92
01:32:35 PM    1    0.00    0.00    0.00    0.00    3.59    0.51    0.00    0.00    0.00   95.90
01:32:35 PM    2    0.00    0.00    0.00    0.00    4.15    0.00    0.00    0.00    0.00   95.85
01:32:35 PM    3    0.00    0.00    0.52    0.00    3.61    0.52    0.00    0.00    0.00   95.36
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Analysis output
The output of &lt;code&gt;mpstat&lt;/code&gt; includes the utilization rate for each CPU and the system&amp;rsquo;s average load. Paying particular attention to the average load and the utilization rate of each CPU can help you understand the system’s load situation. If the load is high, further analysis can identify which processes are causing it and whether there are any performance bottlenecks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Combining with other tools
In addition to &lt;code&gt;mpstat&lt;/code&gt;, tools such as &lt;code&gt;sar&lt;/code&gt;, &lt;code&gt;pidstat&lt;/code&gt;, and &lt;code&gt;iostat&lt;/code&gt; can also be used for comprehensive system performance analysis. By combining the output of multiple tools, you can gain a more complete understanding of system load and identify the root causes of performance issues.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;interruption&#34;&gt;Interruption
&lt;/h3&gt;&lt;p&gt;I won&amp;rsquo;t elaborate on the content here
Recommended: &lt;a class=&#34;link&#34; href=&#34;https://www.codedump.info/post/20200522-sgfap-softirq/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;System Guide for Application Developers - CPU Part on Soft Interrupts&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Frequent triggering of soft interrupts will also be reflected in system load&lt;/p&gt;
&lt;h2 id=&#34;troubleshooting&#34;&gt;Troubleshooting
&lt;/h2&gt;&lt;p&gt;Considering that analyzing the problem solely from a CPU perspective is unable to pinpoint the issue, should we start suspecting an anomaly in the system? It&amp;rsquo;s possible that the Linux operating system has an excessively high load, leading VMware to consume excessive CPU resources. By using &lt;code&gt;mpstat&lt;/code&gt; to analyze the local virtual machine, we found abnormal &lt;code&gt;irq&lt;/code&gt; usage, approaching 25% on a single core. Under normal circumstances, when running business processes without any load, the &lt;code&gt;irq&lt;/code&gt; percentage should be around 5%.&lt;/p&gt;
&lt;p&gt;Within the development environment of his team, CentOS 7 is deployed on VMware and resource usage appears normal. On the other hand, in the Shanghai development environment, although it&amp;rsquo;s also VMware, we cannot directly observe the CPU resources of the host machine. We are now facing multiple variables: the VMware virtual machine, the Linux operating system, and the GCC version.&lt;/p&gt;
&lt;p&gt;Turning to analyze the test environment, Shenzhen&amp;rsquo;s test environment is deployed on physical machines and runs a low-version GCC compilation service, and it operates on CentOS 8. Interestingly, in the Shenzhen environment, &lt;code&gt;irq&lt;/code&gt; occupancy is normal.&lt;/p&gt;
&lt;p&gt;To investigate issues introduced by GCC versions, we deployed programs compiled with a newer version of GCC to the Shenzhen environment for testing, and the results were also normal&lt;/p&gt;
&lt;p&gt;The issue seems to be becoming clearer, and we&amp;rsquo;ve started to suspect there might be a problem with the operating system. After all, CentOS 8 is no longer officially supported. But even after redeploying clean installations of both CentOS 7 and CentOS 8, the problem persists.&lt;/p&gt;
&lt;p&gt;At this point, we began to suspect the only remaining uncertainty: VMware virtualization software. Suddenly, an idea struck us – Hyper-V technology. Could Hyper-V have been enabled previously but not completely shut down, leading to this issue? After all, soft interrupts are also implemented through virtualization software. Are there bugs in different virtualization technologies? These questions warrant further thought and investigation.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h2&gt;&lt;p&gt;According to the Microsoft official manual, we completely shut down the local Hyper-V service and found that VMware recovered normally on the host machine. With this, the problem was finally resolved. As mentioned earlier, this experience was tortuous and arduous, requiring comprehensive analysis and judgment. This was also the first time we troubleshooted the issue and located it at the virtual machine level.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Disable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V-Hypervisor
bcdedit /set hypervisorlaunchtype off
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/troubleshoot/windows-client/application-management/virtualization-apps-not-work-with-hyper-v&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://learn.microsoft.com/zh-cn/troubleshoot/windows-client/application-management/virtualization-apps-not-work-with-hyper-v&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Traps in C&#43;&#43; Programming: Detailed Explanation of Program Crashes Caused by Misusing `std::map`</title>
        <link>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</link>
        <pubDate>Sun, 10 Mar 2024 22:03:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</guid>
        <description>&lt;p&gt;This article aims to reveal the potential for program crashes when &lt;code&gt;std::map&lt;/code&gt; containers are incorrectly used in C++ programming. Attempting to access a non-existent key through the bracket operator automatically adds an empty element. We will delve into this misunderstanding and demonstrate its potential risks with example code.&lt;/p&gt;
&lt;p&gt;Storing simple values is fine, but if you&amp;rsquo;re storing pointers, there will be problems. Because a pointer is an address, and if it’s not initialized, the address is uncertain, which can lead to program crashes.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;In the C++ standard library, &lt;code&gt;std::map&lt;/code&gt; is an associative container that stores elements in ascending order based on their keys (key) and provides efficient keyword lookup functionality. However, novice developers sometimes encounter difficulties due to a misunderstanding of the behavior of the &lt;code&gt;std::map&lt;/code&gt; bracket operator &lt;code&gt;[]&lt;/code&gt;. In fact, when using &lt;code&gt;[]&lt;/code&gt; to access a non-existent key, &lt;code&gt;std::map&lt;/code&gt; will insert a new key-value pair, and the default constructor will be used to initialize the value type corresponding to that key.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;map&amp;gt;

int main() {
    std::map&amp;lt;std::string, int&amp;gt; myMap;
    
    // 错误的用法：假设这里试图访问一个不存在的键并认为会得到0
    std::cout &amp;lt;&amp;lt; &amp;quot;Value for &#39;nonexistent_key&#39;: &amp;quot; &amp;lt;&amp;lt; myMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;

    // 实际上，上述行代码创建了一个新的键值对，其中值被默认初始化为int的默认值（通常是0）
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Although the above code does not directly cause the program to crash, this implicit insertion behavior can potentially lead to unexpected side effects in certain situations, such as resource leaks or state changes that do not meet expectations. Worse still, concurrent access to uninitialized memory regions in a multithreaded environment can even lead to program crashes.&lt;/p&gt;
&lt;p&gt;To prevent such issues, it is recommended to use the &lt;code&gt;std::map::find()&lt;/code&gt; or &lt;code&gt;std::map::count()&lt;/code&gt; methods to check if a key exists, or to explicitly insert elements using &lt;code&gt;std::map::insert()&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;std::map&amp;lt;std::string, int&amp;gt; safeMap;
if (safeMap.count(&amp;quot;nonexistent_key&amp;quot;) == 0) {
    std::cout &amp;lt;&amp;lt; &amp;quot;Key does not exist.&amp;quot; &amp;lt;&amp;lt; std::endl;
} else {
    std::cout &amp;lt;&amp;lt; &amp;quot;Value for existing key: &amp;quot; &amp;lt;&amp;lt; safeMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;
}

// 或者明确插入一个键值对，指定初始值
safeMap.insert({ &amp;quot;new_key&amp;quot;, 0 });
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the objects stored within a map container are of pointer type, the automatic insertion behavior will save an uninitialized pointer, and any operation on this pointer will lead to program crashes&lt;/p&gt;</description>
        </item>
        <item>
        <title>Troubleshooting process freezing with pstack</title>
        <link>https://ttf248.life/en/p/pstack-troubleshooting-process-hang/</link>
        <pubDate>Sat, 24 Feb 2024 23:55:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/pstack-troubleshooting-process-hang/</guid>
        <description>&lt;p&gt;In software development and operations, you often encounter situations where processes appear to be frozen. This can lead to system performance degradation or service unavailability. This article introduces how to use the pstack tool to troubleshoot these frozen process issues by analyzing the process&amp;rsquo;s stack information to identify the cause of the problem and resolve it.&lt;/p&gt;
&lt;p&gt;Background: A subsystem of the risk control system experienced a freeze, rendering the risk control service unavailable. Due to the lack of service availability monitoring, the frozen process was not detected in time, leading to system unavailability.&lt;/p&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;A hung process refers to a state where the process stops responding but does not exit. This situation can be caused by various factors, such as deadlock, resource exhaustion, or exceptions. To resolve these issues, we can use the pstack tool to analyze the process&amp;rsquo;s stack information and identify the root cause of the problem.&lt;/p&gt;
&lt;h2 id=&#34;steps&#34;&gt;Steps
&lt;/h2&gt;&lt;p&gt;pstack is a commonly used tool, typically provided with gdb (the GNU debugger). You can install it using the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt-get install gdb
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To obtain the process ID: First, we need to get the process ID (PID) of the frozen process. You can use the &lt;code&gt;ps&lt;/code&gt; command to list all processes and find the process ID that needs troubleshooting.
Use the pstack tool to analyze process stacks; once you obtain the process ID, you can use the pstack tool to retrieve the stack information for that process. Run the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pstack &amp;lt;PID&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will output the process&amp;rsquo;s stack information, displaying the current sequence of function calls. By analyzing this information, you can identify where the process is stalled and thus locate the problem.&lt;/p&gt;
&lt;p&gt;Analyzing stack information can help identify the cause of a process freeze. You might discover deadlocks, infinite loops, or other anomalies. Take appropriate measures based on the specific situation, such as releasing locks or fixing code logic.&lt;/p&gt;
&lt;h2 id=&#34;case-study&#34;&gt;Case study
&lt;/h2&gt;&lt;p&gt;This simple demo, after the main function starts, creates a child thread that enters a dead loop when executing the actual function, causing the program to fail to end normally and fall into a frozen state&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cmake_minimum_required(VERSION 3.0.0)
project(pstack_main VERSION 0.1.0 LANGUAGES C CXX)

include(CTest)
enable_testing()

# 查找线程库
find_package(Threads REQUIRED)

add_executable(pstack_main main.cpp)

# 链接线程库
target_link_libraries(pstack_main PRIVATE Threads::Threads)

set(CPACK_PROJECT_NAME ${PROJECT_NAME})
set(CPACK_PROJECT_VERSION ${PROJECT_VERSION})
include(CPack)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;thread&amp;gt;
#include &amp;lt;chrono&amp;gt;

void infiniteLoop() {
    while (true) {
        // 主线程进入死循环
    }
}

int main() {
    std::thread thread(infiniteLoop); // 创建一个线程，执行死循环函数
    thread.join(); // 等待线程结束
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Starting the program, execution of pstack results:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Thread 2 (Thread 0x7eff3619b700 (LWP 1315017)):
#0  infiniteLoop () at /root/pstack/main.cpp:6
#1  0x0000000000402ca9 in std::__invoke_impl&amp;lt;void, void (*)()&amp;gt; (__f=@0x2260eb8: 0x4029a6 &amp;lt;infiniteLoop()&amp;gt;) at /usr/include/c++/8/bits/invoke.h:60
#2  0x0000000000402b02 in std::__invoke&amp;lt;void (*)()&amp;gt; (__fn=@0x2260eb8: 0x4029a6 &amp;lt;infiniteLoop()&amp;gt;) at /usr/include/c++/8/bits/invoke.h:95
#3  0x0000000000403150 in std::thread::_Invoker&amp;lt;std::tuple&amp;lt;void (*)()&amp;gt; &amp;gt;::_M_invoke&amp;lt;0ul&amp;gt; (this=0x2260eb8) at /usr/include/c++/8/thread:244
#4  0x0000000000403126 in std::thread::_Invoker&amp;lt;std::tuple&amp;lt;void (*)()&amp;gt; &amp;gt;::operator() (this=0x2260eb8) at /usr/include/c++/8/thread:253
#5  0x000000000040310a in std::thread::_State_impl&amp;lt;std::thread::_Invoker&amp;lt;std::tuple&amp;lt;void (*)()&amp;gt; &amp;gt; &amp;gt;::_M_run (this=0x2260eb0) at /usr/include/c++/8/thread:196
#6  0x00007eff36bceb23 in execute_native_thread_routine () from /lib64/libstdc++.so.6
#7  0x00007eff36ea91ca in start_thread () from /lib64/libpthread.so.0
#8  0x00007eff361d58d3 in clone () from /lib64/libc.so.6
Thread 1 (Thread 0x7eff372e1740 (LWP 1315016)):
#0  0x00007eff36eaa6cd in __pthread_timedjoin_ex () from /lib64/libpthread.so.0
#1  0x00007eff36bceda7 in std::thread::join() () from /lib64/libstdc++.so.6
#2  0x00000000004029d2 in main () at /root/pstack/main.cpp:13
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It can be seen that the reason for the process freeze is a dead loop. The main thread enters a dead loop, and the child thread cannot exit, leading to the process freezing.&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

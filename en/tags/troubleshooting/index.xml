<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Troubleshooting on Uncle Xiang&#39;s Notebook</title>
        <link>https://ttf248.life/en/tags/troubleshooting/</link>
        <description>Recent content in Troubleshooting on Uncle Xiang&#39;s Notebook</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Mon, 02 Jun 2025 19:00:25 +0800</lastBuildDate><atom:link href="https://ttf248.life/en/tags/troubleshooting/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Protobuf Zero Value Pitfalls: When Default Values Become an Invisible Killer of Business Logic</title>
        <link>https://ttf248.life/en/p/protobuf-zero-value-trap/</link>
        <pubDate>Thu, 20 Feb 2025 15:26:51 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/protobuf-zero-value-trap/</guid>
        <description>&lt;p&gt;The US stock market has three trading sessions: pre-market, live market, and post-market. The logic for pushing data – whether it’s full data or numerical increments – is optimized to conserve bandwidth (sending as little data as possible). Initially, a full dataset is sent in the first transmission, and subsequent transmissions are incremental updates of all fields.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Why not use the optimal solution? This involves multiple project teams, some of which have been live for many years. As we’re a new integration, we can only try to be compatible with existing systems.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;a-series-of-issues&#34;&gt;A Series of Issues
&lt;/h2&gt;&lt;p&gt;Just from the summary, it might seem like there aren&amp;rsquo;t any problems, but once the system architecture is brought in, a series of issues arise. Immediately after resolving the previous issue, a new one emerged – this problem was caused by the prior one.&lt;/p&gt;
&lt;h3 id=&#34;unable-to-identify-trading-intervals&#34;&gt;Unable to Identify Trading Intervals
&lt;/h3&gt;&lt;p&gt;The market phase is defined in &lt;code&gt;protobuf&lt;/code&gt; as 0, but because it’s received via incremental push, the business side cannot effectively identify whether this ‘0’ represents the default value or a genuine business value.&lt;/p&gt;
&lt;p&gt;In simpler terms: Each time a &amp;lsquo;0&amp;rsquo; is received, it’s impossible to determine if it’s the new market phase setting or the &lt;code&gt;protobuf&lt;/code&gt; default value.&lt;/p&gt;
&lt;h3 id=&#34;introducing-optional&#34;&gt;Introducing Optional
&lt;/h3&gt;&lt;p&gt;Since protobuf release 3.15, proto3 supports using the optional keyword (just as in proto2) to provide presence information for scalar fields.&lt;/p&gt;
&lt;p&gt;The communication protocol within the group is based on &lt;code&gt;protobuf&lt;/code&gt;, but due to historical reasons, the version selected was older and did not support the &lt;code&gt;optional&lt;/code&gt; keyword. As you know, because we’re introducing &lt;code&gt;protobuf&lt;/code&gt; from the ground up, the project publishes its underlying static library, which necessitates upgrading the entire build chain – a very high cost.&lt;/p&gt;
&lt;h3 id=&#34;gcc-version-issues&#34;&gt;GCC Version Issues
&lt;/h3&gt;&lt;p&gt;After painstakingly devising a solution – deploying two different versions of the underlying release to control &lt;code&gt;protobuf&lt;/code&gt;’s new version compilation dependencies as much as possible – we encountered an issue during compilation. The &lt;code&gt;gcc&lt;/code&gt; version was too low, preventing support for &lt;code&gt;protobuf&lt;/code&gt;&amp;rsquo;s new features.&lt;/p&gt;
&lt;p&gt;Common server types within our team: CentOS 7 and CentOS 8.  The default &lt;code&gt;gcc&lt;/code&gt; version on CentOS 7 is 4.8, while the default on CentOS 8 is 8.3. Since &lt;code&gt;protobuf&lt;/code&gt;’s new features require a &lt;code&gt;gcc&lt;/code&gt; version of 7.4 or higher, CentOS 7 could not support it.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://gcc.gnu.org/bugzilla/show_bug.cgi?id=82461&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Bug 82461 - [7 Regression] Temporary required for brace-initializing (non-literal-type) member variable&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Ultimately, after considerable troubleshooting, we moved the deployments and compilation servers to CentOS 8, resolving this problem.&lt;/p&gt;
&lt;h2 id=&#34;reasonable-enumeration&#34;&gt;Reasonable Enumeration
&lt;/h2&gt;&lt;p&gt;Reviewing the entire problem, there’s a simpler and more efficient solution: adjust the enumeration definition to start numbering from 1 instead of 0. This effectively distinguishes between default values and business values, avoiding all the aforementioned issues.&lt;/p&gt;
&lt;h3 id=&#34;why-starting-from-1-is-more-reasonable&#34;&gt;Why Starting from 1 is More Reasonable?
&lt;/h3&gt;&lt;p&gt;In &lt;code&gt;protobuf&lt;/code&gt;, enum types have a default value fixed to 0. If we define meaningful business values as 0 (e.g., &amp;ldquo;Market Open&amp;rdquo;), in incremental pushes, the business side cannot determine whether the received 0 is a business value or an unset default value.  If instead, we defined the enumeration starting from 1, 0 could be retained as a meaningless default value or “Unknown” state, resolving the issue neatly.&lt;/p&gt;
&lt;p&gt;Recommended Practice:
When designing &lt;code&gt;protobuf&lt;/code&gt; enums, always define 0 as a meaningless default value (e.g., &lt;code&gt;UNKNOWN&lt;/code&gt; or &lt;code&gt;RESERVED&lt;/code&gt;).
Assign actual business values starting from 1 to ensure they are distinguished from the default value of 0.&lt;/p&gt;
&lt;p&gt;With this small adjustment, we not only resolved the issue of identifying trading hours but also provided a valuable lesson for future protocol design.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Background Service TCP Communication Anomaly Troubleshooting</title>
        <link>https://ttf248.life/en/p/backend-service-tcp-communication-troubleshooting/</link>
        <pubDate>Fri, 14 Feb 2025 22:54:13 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/backend-service-tcp-communication-troubleshooting/</guid>
        <description>&lt;p&gt;Business Model: The backend service establishes a connection with the group’s market data gateway using TCP. Each time a connection is established, it must first send an authorization request and then continuously send heartbeat packages to maintain the connection status.&lt;/p&gt;
&lt;p&gt;However, one day, an alert message was received indicating that the service had disconnected. After carefully examining the logs, it was discovered that the backend service was continuously sending heartbeat packages, but the other party did not respond at all, yet the connection remained open.&lt;/p&gt;
&lt;h2 id=&#34;on-site-summary&#34;&gt;On-Site Summary
&lt;/h2&gt;&lt;p&gt;I was originally working late in the office to advance project progress when an alarm message suddenly popped up in our work group. At first glance, I thought it was just a recurring issue – likely due to network timeouts causing heartbeat failures, leading to service disconnection. However, after careful log examination, the actual situation turned out to be different. The backend had already sent authorization messages, but they were never acknowledged. Meanwhile, heartbeat packets continued to send persistently, yet the other party never responded with any heartbeat data. After in-depth analysis of the logs, several key issues were exposed:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Authorization message without response: This was likely due to the other system being in the process of restarting, which prevented the authorization message from being processed promptly.&lt;/li&gt;
&lt;li&gt;Sending heartbeat data despite unsuccessful authorization: Upon investigation, it was found that this was a logical flaw in the program’s logic. - The judgment logic of the heartbeat sending function has a defect; it only checks the connection status but misses verifying the authorization status.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;If the service can disconnect, a reconnection mechanism can be triggered to resend the authorization message.&lt;/li&gt;
&lt;li&gt;Currently, the last urgent problem is why the service hasn’t disconnected. Resolving this issue requires more in-depth and detailed troubleshooting work.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;analyzing-network-packets&#34;&gt;Analyzing Network Packets
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;tcpdump&lt;/code&gt; is a very powerful network packet capture tool that can be used to capture network packets. By analyzing network packets, we can gain a more intuitive understanding of the details of network communication. Here, we can use &lt;code&gt;tcpdump&lt;/code&gt; to capture network packets for further analysis.
&lt;img src=&#34;https://ttf248.life/p/backend-service-tcp-communication-troubleshooting/20250220151952.png&#34;
	width=&#34;1126&#34;
	height=&#34;202&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;tcpdump&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;557&#34;
		data-flex-basis=&#34;1337px&#34;
	
&gt;
Analyzing the data in the diagram, I see that the heartbeat is constantly sending normally, and the other server did not respond with any data, but sent an &lt;code&gt;ACK&lt;/code&gt;, which prevents the connection from disconnecting proactively.&lt;/p&gt;
&lt;h2 id=&#34;common-flag-bit-explanation&#34;&gt;Common Flag Bit Explanation
&lt;/h2&gt;&lt;p&gt;In the TCP protocol, &lt;code&gt;PSH&lt;/code&gt; (Push) and &lt;code&gt;ACK&lt;/code&gt; (Acknowledgment) are two important flag bits used to control data transmission and traffic confirmation, respectively. Their functions are as follows:&lt;/p&gt;
&lt;h3 id=&#34;1-psh-push-flag&#34;&gt;&lt;strong&gt;1. PSH (Push Flag)&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Function:&lt;/strong&gt; The &lt;code&gt;PSH&lt;/code&gt; flag serves to &lt;strong&gt;request that the receiver immediately push data from the buffer to the upper-layer application&lt;/strong&gt; (rather than waiting for the buffer to fill). This means that once a data segment with the &lt;code&gt;PSH&lt;/code&gt; flag is received, the receiver will process and transmit it as quickly as possible to the application, rather than storing it in an operating system buffer.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Typical Scenarios:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;HTTP/HTTPS Requests:&lt;/strong&gt; Clients setting &lt;code&gt;PSH&lt;/code&gt; when sending requests (e.g., &lt;code&gt;GET /index.html&lt;/code&gt;) to ensure immediate response from the server.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SSH Protocol:&lt;/strong&gt; Each keystroke triggers &lt;code&gt;PSH&lt;/code&gt;, ensuring real-time transmission of input characters.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Real-Time Communication:&lt;/strong&gt; Low-latency scenarios like video streaming or online games may utilize &lt;code&gt;PSH&lt;/code&gt; to reduce latency. - &lt;strong&gt;Note:&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PSH&lt;/code&gt; is not mandatory; the receiver can choose to ignore this flag (but must still process the data correctly).&lt;/li&gt;
&lt;li&gt;The sender may not set &lt;code&gt;PSH&lt;/code&gt;; in this case, the receiver will determine when to push data based on its own buffering policy.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-ack-acknowledgment-flag&#34;&gt;&lt;strong&gt;2. ACK (Acknowledgment Flag)&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Function:&lt;/strong&gt; The ACK flag indicates that the preceding data segment has been &lt;strong&gt;acknowledged as received correctly&lt;/strong&gt;. Each ACK contains an acknowledgment number (Acknowledgment Number), representing the expected next byte sequence number. It is the core mechanism of TCP reliable transmission.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Working Principle:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;When the sender transmits a data segment, it carries the expected ACK value from the receiver (e.g., &lt;code&gt;ACK = Sequence Number + Data Length&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Upon receiving the data, the receiver generates an ACK message to acknowledge the received byte sequence number.&lt;/li&gt;
&lt;li&gt;The sender only retransmits unacknowledged data after receiving the corresponding ACK.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Example:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;If the sender transmits a data segment with sequence numbers &lt;code&gt;100~199&lt;/code&gt;, then the expected ACK from the receiver should be &lt;code&gt;200&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-combination-of-psh-and-ack&#34;&gt;&lt;strong&gt;3. Combination of PSH and ACK&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;In the TCP header, &lt;code&gt;PSH&lt;/code&gt; and &lt;code&gt;ACK&lt;/code&gt; can appear simultaneously, commonly seen in the following scenarios:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;HTTP Request Response&lt;/strong&gt;:
When a client sends a &lt;code&gt;POST&lt;/code&gt; request (including data), it sets both &lt;code&gt;PSH&lt;/code&gt; and &lt;code&gt;ACK&lt;/code&gt; (to acknowledge previous responses).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Command Transmission after SSH Handshake&lt;/strong&gt;:
After the client enters a command, it sends a data segment with &lt;code&gt;PSH&lt;/code&gt; and &lt;code&gt;ACK&lt;/code&gt;, ensuring that the command is immediately transmitted and processed by the server.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;4-other-flagged-associations&#34;&gt;&lt;strong&gt;4. Other Flagged Associations&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Flag&lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Brief Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;SYN&lt;/td&gt;
&lt;td&gt;Synchronize&lt;/td&gt;
&lt;td&gt;Initiate connection (three-way handshake)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;4-other-flagged-associations-1&#34;&gt;&lt;strong&gt;4. Other Flagged Associations&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Flag&lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Brief Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;FIN&lt;/td&gt;
&lt;td&gt;End&lt;/td&gt;
&lt;td&gt;Graceful connection closure&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;4-other-flagged-associations-2&#34;&gt;&lt;strong&gt;4. Other Flagged Associations&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Flag&lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Brief Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;RST&lt;/td&gt;
&lt;td&gt;Reset&lt;/td&gt;
&lt;td&gt;Forcefully terminates the connection (exceptional circumstances)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;4-other-flagged-associations-3&#34;&gt;&lt;strong&gt;4. Other Flagged Associations&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Flag&lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Brief Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;URG&lt;/td&gt;
&lt;td&gt;Urgent&lt;/td&gt;
&lt;td&gt;Marks an urgent pointer (rarely used)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;4-other-flagged-associations-4&#34;&gt;&lt;strong&gt;4. Other Flagged Associations&lt;/strong&gt;
&lt;/h3&gt;&lt;h3 id=&#34;summary&#34;&gt;Summary
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PSH&lt;/strong&gt; focuses on &lt;strong&gt;data arriving at the application layer as quickly as possible&lt;/strong&gt;, reducing latency.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ACK&lt;/strong&gt; focuses on &lt;strong&gt;reliable data transmission&lt;/strong&gt;, avoiding packet loss or out-of-order delivery.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The two work together to balance TCP protocol efficiency and reliability.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Mastering atop: A Comprehensive Guide to Monitoring Linux System Metrics – Installation, Configuration, and Usage</title>
        <link>https://ttf248.life/en/p/atop-linux-system-monitoring-guide/</link>
        <pubDate>Thu, 06 Feb 2025 22:48:55 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/atop-linux-system-monitoring-guide/</guid>
        <description>&lt;p&gt;In Linux system administration, real-time and comprehensive monitoring of system resources and process status is crucial. The atop tool, as a powerful monitoring utility, helps us easily achieve this goal. This article will provide a detailed introduction on how to install, configure, and use the atop monitoring tool in a Linux instance.&lt;/p&gt;
&lt;h2 id=&#34;i-atop-tool-introduction&#34;&gt;I. atop Tool Introduction
&lt;/h2&gt;&lt;p&gt;atop is a tool specifically designed for monitoring Linux system resources and processes. It records the activity of systems and processes, and reports on the running status of all processes. The data collected by this tool covers resource usage such as CPU, memory, disk, and network, as well as process states. It can also save the data in log files to disk. For each process, we can obtain key information such as CPU utilization, memory growth, disk usage, priority, username, status, and exit code. Furthermore, through the atop configuration file, we can customize parameters such as logging collection frequency, log file storage path, and rotation strategy.&lt;/p&gt;
&lt;h2 id=&#34;ii-installing-the-atop-tool&#34;&gt;II. Installing the atop Tool
&lt;/h2&gt;&lt;p&gt;The installation method for atop varies slightly depending on the Linux distribution. The following provides an introduction based on common operating systems:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Alibaba Cloud Linux 3/2, CentOS 7/8, Fedora, Rocky Linux 9:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Execute the installation command: &lt;code&gt;sudo yum install -y atop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ubuntu / Debian:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Update the software source list: &lt;code&gt;sudo apt update&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Execute the installation command: &lt;code&gt;sudo apt install -y atop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;CentOS Stream 9:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download and install: &lt;code&gt;sudo wget https://www.atoptool.nl/download/atop-2.11.0-1.el9.x86_64.rpm &amp;amp;&amp;amp; sudo rpm -i atop-2.11.0-1.el9.x86_64.rpm&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;ii-installing-the-atop-tool-1&#34;&gt;II. Installing the atop Tool
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;openSUSE&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;Execute the installation command: &lt;code&gt;sudo zypper install -y atop atop-daemon&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;
If your distribution is not listed above, you can visit the official atop website for installation information.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;iii-configuring-monitoring-cycle-and-log-retention-time&#34;&gt;III. Configuring Monitoring Cycle and Log Retention Time
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Configuration File Location:&lt;/strong&gt; In Alibaba Cloud Linux 3/2, CentOS 7/8, and Fedora systems, the atop configuration file is &lt;code&gt;/etc/sysconfig/atop&lt;/code&gt;; in Ubuntu, Debian, and openSUSE systems, the configuration file is &lt;code&gt;/etc/default/atop&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Default Configuration Parameter Explanation&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;LOGOPTS&lt;/code&gt;: Controls logging options for log files, defaults to empty.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LOGINTERVAL&lt;/code&gt;: Monitoring cycle, default 600 seconds. To collect historical logs for tracking issues, it&amp;rsquo;s recommended to adjust this frequency based on actual needs.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LOGGENERATIONS&lt;/code&gt;: Log retention time, default 28 days.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LOGPATH&lt;/code&gt;: Log file storage path, defaults to &lt;code&gt;/var/log/atop&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;iii-configure-monitoring-cycle-and-log-retention-time&#34;&gt;III. Configure Monitoring Cycle and Log Retention Time
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Configuration Steps&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Execute the command to open the configuration file:
&lt;ul&gt;
&lt;li&gt;In Alibaba Cloud Linux 3/2, CentOS 7/8, Fedora systems: &lt;code&gt;sudo vim /etc/sysconfig/atop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;In Ubuntu, Debian, openSUSE, CentOS Stream 9, Rocky Linux 9 systems: &lt;code&gt;sudo vim /etc/default/atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Press ‘i’ to enter edit mode and adjust the configuration parameters according to your needs. For example, change the monitoring cycle to 30 seconds, set the log retention time to 7 days, and maintain the default log path:&lt;/li&gt;
&lt;li&gt;Press ‘Esc’ to return to normal editing mode, type &lt;code&gt;:wq&lt;/code&gt; to save and exit.&lt;/li&gt;
&lt;li&gt;Restart the atop service to apply the configuration: &lt;code&gt;sudo systemctl restart atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;LOGOPTS=&amp;quot;&amp;quot;
LOGINTERVAL=30
LOGGENERATIONS=7
LOGPATH=/var/log/atop 
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;four-using-atop-tool&#34;&gt;Four. Using atop Tool
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Common Commands:&lt;/strong&gt; In interactive command mode, the following commands are commonly used:
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;g&lt;/code&gt;: Return to the default comprehensive output view.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;c&lt;/code&gt;: Display the full command line for each process.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;m&lt;/code&gt;: Sort processes by memory usage in descending order.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;d&lt;/code&gt;: Sort processes by disk usage in descending order.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;a&lt;/code&gt;: Sort processes by overall resource usage in descending order.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;n&lt;/code&gt;: Sort processes by network usage in descending order.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;t&lt;/code&gt;: Jump to the next monitoring collection point.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;T&lt;/code&gt;: Jump to the previous monitoring collection point.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;b&lt;/code&gt;: Specify a timestamp in the format &lt;code&gt;YYYYMMDDhhmm&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;four-using-the-atop-tool&#34;&gt;Four. Using the atop Tool
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Resource Monitoring Field Meanings&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;atop&lt;/strong&gt;: Hostname, sampling date and time point.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PRC&lt;/strong&gt;: Overall process running status, including kernel state and user state runtime, total process count, number of processes in different states, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CPU&lt;/strong&gt;: Overall CPU usage, the sum of the numbers is &lt;code&gt;N*100%&lt;/code&gt; (N is the number of CPU cores), including the proportion of time for kernel state, user state, interrupt, idle, and disk I/O waiting.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CPL&lt;/strong&gt;: CPU load situation, such as the average number of processes in the queue over 1 minute, 5 minutes, and 15 minutes, context switch times, and interrupt occurrences.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MEM&lt;/strong&gt;: Memory usage, including total physical memory, free memory, page cache memory, file cache memory, and kernel occupied memory, etc. - &lt;strong&gt;SWP:&lt;/strong&gt; Swap space utilization, including total swap area and available swap space size.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PAG:&lt;/strong&gt; Virtual memory page situation, such as inbound and outbound memory page numbers.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DSK:&lt;/strong&gt; Disk usage, with each disk device corresponding to a column, displaying device identifier, busy time proportion, read/write request quantity.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NET:&lt;/strong&gt; Network status, showcasing transport layer TCP and UDP, IP layer, and receive and send packet sizes for each active port.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;four-using-the-atop-tool-1&#34;&gt;Four. Using the atop Tool
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;View Real-time System Metrics&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;View system metrics every 5 seconds: &lt;code&gt;atop 5&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View system metrics from the last 30 intervals (each interval is 10 seconds) after the current time: &lt;code&gt;atop -M 10 30&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View system metrics from the last 10 minutes (10 intervals, each interval is 60 seconds), and write the results to a file: &lt;code&gt;atop -M 60 10 &amp;gt; /log/atop.mem&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;View Historical Metric Logs&lt;/strong&gt;: After atop starts, collected records are stored by default in the &lt;code&gt;/var/log/atop&lt;/code&gt; directory. When viewing, be sure to specify the date of the log file must exist, otherwise it will error. - View daily historical metrics log: &lt;code&gt;atop -r&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View yesterday&amp;rsquo;s historical metrics log: &lt;code&gt;atop -r y&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View historical metrics log for a specific date, such as November 6, 2024: &lt;code&gt;atop -r 20241106&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View historical metrics log from a specific date and time, such as starting from November 6, 2024, 14:00: &lt;code&gt;atop -r 20241106 -b 14:00&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View historical metrics log for a specified time range on a specific date, such as from November 5, 2024, 00:04 to 00:08: &lt;code&gt;atop -r 20241105 -b 00:04 -e 00:08&lt;/code&gt; ## Four. Using the atop Tool&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;View Real-Time System Metrics&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;View system metrics every 5 seconds: &lt;code&gt;atop 5&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View system metrics from the last 30 intervals (each interval is 10 seconds) after the current time: &lt;code&gt;atop -M 10 30&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View system metrics from the last 10 minutes (10 intervals, each interval is 60 seconds), and write the results to a file: &lt;code&gt;atop -M 60 10 &amp;gt; /log/atop.mem&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;View Historical Metric Logs&lt;/strong&gt;: After atop starts, collected records are stored by default in the &lt;code&gt;/var/log/atop&lt;/code&gt; directory. When viewing, be sure to specify the log file for the desired date; otherwise, an error will occur.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;four-using-the-atop-tool-2&#34;&gt;Four. Using the atop Tool
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;View System Activity Report&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;View the CPU utilization report for the current system over 1 minute (12 times, with an interval of 5 seconds): &lt;code&gt;atopsar -c 5 12&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View the memory metrics report for a specified time period during the day, such as 18:00 to 18:01: &lt;code&gt;atopsar -m -b 18:00 -e 18:01&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View the memory metrics report for a specified date and time period, such as November 5, 2024 from 18:00 to 18:01: &lt;code&gt;atopsar -m -r 20241105 -b 18:00 -e 18:01&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;five-other-operations&#34;&gt;Five. Other Operations
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Configure Daily Log Rotation Policy&lt;/strong&gt;: If you want to generate a daily &lt;code&gt;atop&lt;/code&gt; metric log file, you can perform the following actions:
&lt;ul&gt;
&lt;li&gt;(Optional) Adjust monitoring period, log retention time, and log storage path according to your needs.&lt;/li&gt;
&lt;li&gt;Execute the command to enable and start the services related to daily log rotation: &lt;code&gt;sudo systemctl enable --now atop atopacct atop-rotate.timer&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;If your business has more complex requirements for log processing, you can also combine it with &lt;code&gt;logrotate&lt;/code&gt; or custom scripts to implement log management.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;five-other-operations-1&#34;&gt;Five. Other Operations
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Load the optional netatop kernel module:&lt;/strong&gt; If you need to monitor network usage, you can install the netatop module (the module is not installed by default in atop). As an example on Alibaba Cloud Linux 3:
&lt;ul&gt;
&lt;li&gt;Install the kernel development package and the software environment required for compiling: &lt;code&gt;sudo yum install -y kernel-devel dkms elfutils-libelf-devel&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Download the latest version of netatop source code to a specified directory: &lt;code&gt;cd /usr/src/ &amp;amp;&amp;amp; sudo wget https://www.atoptool.nl/download/netatop-3.2.2.tar.gz --no-check-certificate&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Extract the source code and enter the source code directory: &lt;code&gt;sudo tar -zxvf netatop-3.2.2.tar.gz &amp;amp;&amp;amp; cd netatop-3.2.2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Build and install the module and daemon based on the source code: &lt;code&gt;sudo make &amp;amp;&amp;amp; sudo make install&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the netatop service: &lt;code&gt;sudo systemctl start netatop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v-other-operations&#34;&gt;V. Other Operations
&lt;/h2&gt;&lt;p&gt;The atop tool is powerful and flexible to use. By installing, configuring, and using it properly, we can better understand the running status of our Linux system and promptly identify and resolve potential issues. We hope this article will help everyone take Linux system monitoring to a new level.&lt;/p&gt;
&lt;h2 id=&#34;vi-references&#34;&gt;VI. References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.atoptool.nl/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;atop official website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://help.aliyun.com/zh/ecs/use-cases/use-the-atop-tool-to-monitor-linux-system-metrics#99e53d0198euu&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Installation, configuration, and usage of the atop monitoring tool&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Visual Studio loading a mismatched PDB file</title>
        <link>https://ttf248.life/en/p/visual-studio-load-unmatched-pdb/</link>
        <pubDate>Thu, 23 Jan 2025 20:04:33 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/visual-studio-load-unmatched-pdb/</guid>
        <description>&lt;p&gt;When debugging programs under Windows using Visual Studio, if the PDB file does not match the executable file, Visual Studio will display &amp;ldquo;Unable to load symbol file.&amp;rdquo; The program crashes and generates a crash dump. If it&amp;rsquo;s an mismatched PDB file, Visual Studio cannot smoothly enter the crash site.&lt;/p&gt;
&lt;h2 id=&#34;what-is-a-pdb-file&#34;&gt;What is a PDB File?
&lt;/h2&gt;&lt;p&gt;A PDB file is a debugging information file created by Microsoft, used for debugging programs. It contains information such as the symbol table, source code filenames, line numbers, and other debugging data. A PDB file can be generated during program compilation to aid in debugging.&lt;/p&gt;
&lt;h2 id=&#34;windbg-debugging&#34;&gt;WinDbg Debugging
&lt;/h2&gt;&lt;p&gt;WinDbg is a debugging tool from Microsoft that can be used to debug Windows programs. WinDbg can load mismatched PDB files, but this requires manual loading. The &lt;code&gt;.reload /f /i&lt;/code&gt; command forces the loading of mismatched PDB files.&lt;/p&gt;
&lt;p&gt;However, WinDbg is less convenient to use than Visual Studio, so we want Visual Studio to also be able to load mismatched PDB files.&lt;/p&gt;
&lt;h2 id=&#34;visual-studio-cannot-load-matching-pdb-files&#34;&gt;Visual Studio Cannot Load Matching PDB Files
&lt;/h2&gt;&lt;p&gt;Source code is now generally managed through Git, allowing you to find the corresponding version of the code and recompile it to generate a matching PDB file. Why can&amp;rsquo;t it load? The main reason is that metadata doesn’t match.&lt;/p&gt;
&lt;p&gt;There’s a small tool that can modify metadata based on EXE file information to generate a new PDB file, enabling Visual Studio to load it.&lt;/p&gt;
&lt;p&gt;Chkmatch Download Address: &lt;a class=&#34;link&#34; href=&#34;https://www.debuginfo.com/tools/chkmatch.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.debuginfo.com/tools/chkmatch.html&lt;/a&gt;
Site Cache Address: &lt;a class=&#34;link&#34; href=&#34;chkmatch.zip&#34; &gt;chkmatch.zip&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;visual-studio-loading-mismatched-pdb-files&#34;&gt;Visual Studio Loading Mismatched PDB Files
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;The ChkMatch utility can be used to check whether an executable and debug information file match. It can also be used to enforce matching between an executable and debug information file, if they are compatible.

For more information about debug information matching and related issues, see this article.

Supported debug information formats: DBG, PDB 2.0, PDB 7.0.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;visual-studio-loading-mismatched-pdb-files-1&#34;&gt;Visual Studio Loading Mismatched PDB Files
&lt;/h2&gt;&lt;p&gt;Supported debug information formats: DBG, PDB 2.0, PDB 7.0.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;chkmatch [-c ExeFile DebugInfoFile] | [-m ExeFile DebugInfoFile]&lt;/code&gt;
-c
Check matching between the executable and the debug information file.
-m
Make the executable and the debug information file match.
ExeFile
The name of the executable file.
DebugInfoFile
The name of the debug information file.&lt;/p&gt;
&lt;h2 id=&#34;using-chkmatch&#34;&gt;Using chkmatch
&lt;/h2&gt;&lt;p&gt;First perform the check operation, analyze the cause of mismatch, and prompt for an unmatched signature.&lt;/p&gt;
&lt;h2 id=&#34;using-chkmatch-1&#34;&gt;Using chkmatch
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\tianlong.xiang\Downloads\chkmatch&amp;gt;ChkMatch.exe -c &amp;quot;D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe&amp;quot; E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb
ChkMatch - version 1.0
Copyright (C) 2004 Oleg Starodumov
http://www.debuginfo.com/


Executable: D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe
Debug info file: E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;using-chkmatch-2&#34;&gt;Using chkmatch
&lt;/h2&gt;&lt;p&gt;Executable:
TimeDateStamp: c26d9be3
Debug info: 2 ( CodeView )
TimeStamp: f86b0a4f  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 122  RVA: 001cdc44  FileOffset: 001cbe44
CodeView format: RSDS
Signature: {428c9b95-39a3-4a8d-a8e5-7be453684757}  Age: 1
PdbFile: D:\stock_UAT\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\obj\Release\YinTrade.Main.pdb
Debug info: 16 ( Unknown )
TimeStamp: 00000000  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 0  RVA: 00000000  FileOffset: 00000000&lt;/p&gt;
&lt;h2 id=&#34;using-chkmatch-3&#34;&gt;Using chkmatch
&lt;/h2&gt;&lt;p&gt;Debug information file:
Format: PDB 7.00
Signature: {06fae08e-c0a2-4f3d-9c7c-dfc684445dd1}  Age: 1&lt;/p&gt;
&lt;p&gt;Result: Unmatched (reason: Signature mismatch)&lt;/p&gt;
&lt;h2 id=&#34;using-chkmatch-4&#34;&gt;Using chkmatch
&lt;/h2&gt;&lt;p&gt;Then perform the modification operation to match the pdb file with the exe file.&lt;/p&gt;
&lt;h2 id=&#34;using-chkmatch-5&#34;&gt;Using chkmatch
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\tianlong.xiang\Downloads\chkmatch&amp;gt;ChkMatch.exe -m &amp;quot;D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe&amp;quot; E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb
ChkMatch - version 1.0
Copyright (C) 2004 Oleg Starodumov
http://www.debuginfo.com/


Executable: D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe
Debug info file: E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;using-chkmatch-6&#34;&gt;Using chkmatch
&lt;/h2&gt;&lt;p&gt;Executable:
TimeDateStamp: c26d9be3
Debug info: 2 ( CodeView )
TimeStamp: f86b0a4f  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 122  RVA: 001cdc44  FileOffset: 001cbe44
CodeView format: RSDS
Signature: {428c9b95-39a3-4a8d-a8e5-7be453684757}  Age: 1
PdbFile: D:\stock_UAT\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\obj\Release\YinTrade.Main.pdb
Debug info: 16 ( Unknown )
TimeStamp: 00000000  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 0  RVA: 00000000  FileOffset: 00000000&lt;/p&gt;
&lt;h2 id=&#34;using-chkmatch-7&#34;&gt;Using chkmatch
&lt;/h2&gt;&lt;p&gt;Debug information file:
Format: PDB 7.00
Signature: {06fae08e-c0a2-4f3d-9c7c-dfc684445dd1}  Age: 1&lt;/p&gt;
&lt;p&gt;Writing to the debug information file&amp;hellip;
Result: Success.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://stackoverflow.com/questions/38147487/forcing-to-load-unmatched-symbols-in-visual-studio-2015-debugger&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;forcing-to-load-unmatched-symbols-in-visual-studio-2015-debugger&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Linux backend services handling large volumes of string data – performance is slow.</title>
        <link>https://ttf248.life/en/p/linux-backend-slow-string-processing/</link>
        <pubDate>Wed, 13 Nov 2024 19:42:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-backend-slow-string-processing/</guid>
        <description>&lt;p&gt;In the history of C++ development projects, we utilized a custom protocol for communication, which employed a two-dimensional array pattern. When processing large volumes of data, the protocol required iterating through the arrays and performing serialization operations to generate logs. Due to its low efficiency, this resulted in noticeable lag or stuttering within the system under heavy load, as reported by the business department.&lt;/p&gt;
&lt;h2 id=&#34;problem-identification&#34;&gt;Problem Identification
&lt;/h2&gt;&lt;p&gt;When troubleshooting the issue, we first performed a performance analysis of the system and discovered that CPU utilization increased significantly when processing large amounts of data, and system response times became longer. By analyzing the system logs, we identified numerous serialization operations, which were inefficient when handling two-dimensional arrays, leading to a decline in system performance.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;pstack&lt;/code&gt; tool captured thread information for the service, pinpointing that the log threads spent most of their time processing string concatenation.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is today’s focus: different accumulation methods have significant efficiency differences. Historically, the code used the &lt;code&gt;+&lt;/code&gt; operator, which frequently creates temporary objects and is very inefficient. You know it&amp;rsquo;s bad, but you don&amp;rsquo;t know &lt;em&gt;how&lt;/em&gt; bad it is.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;demo-verification&#34;&gt;Demo Verification
&lt;/h2&gt;&lt;p&gt;Based on the project code, we extracted the business logic and wrote a simple demo to verify the efficiency issues of string concatenation. We compiled and ran it in &lt;code&gt;Release&lt;/code&gt; mode using the &lt;code&gt;vs2022&lt;/code&gt; compiler under &lt;code&gt;windows&lt;/code&gt; and the &lt;code&gt;gcc8.5&lt;/code&gt; compiler under &lt;code&gt;linux&lt;/code&gt;, comparing the efficiencies.&lt;/p&gt;
&lt;h3 id=&#34;key-points-explanation&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;p&gt;The project utilized Method Four, and before obtaining test data, readers should consider which method is most efficient and which is least efficient. I was quite surprised by the results.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Method 1 (&lt;code&gt;+=&lt;/code&gt; Concatenation)&lt;/strong&gt;: Directly concatenates each field using &lt;code&gt;+=&lt;/code&gt; to a string.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 2 (&lt;code&gt;std::ostringstream&lt;/code&gt; Concatenation)&lt;/strong&gt;: Uses a stream (&lt;code&gt;std::ostringstream&lt;/code&gt;) to concatenate each field, which is more efficient, especially when dealing with large amounts of data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 3 (Pre-allocated Memory &lt;code&gt;+=&lt;/code&gt; Concatenation)&lt;/strong&gt;: Pre-allocates enough memory for the string using &lt;code&gt;reserve&lt;/code&gt; to reduce the overhead of memory reallocation and improve performance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 4 (&lt;code&gt;bodys = bodys + body + &amp;quot;\n&amp;quot;&lt;/code&gt;)&lt;/strong&gt;: Each concatenation creates a new temporary string object, leading to performance degradation, especially with large-scale concatenations due to the allocation and copying of a new memory space each time.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Referring to the results, we can see that this method was selected as the least efficient.&lt;/p&gt;
&lt;p&gt;Furthermore, let&amp;rsquo;s analyze the optimization efficiency of different platform compilers – Microsoft’s &lt;code&gt;visual studio&lt;/code&gt; remains consistently excellent, with high string optimization efficiency, while the &lt;code&gt;gcc&lt;/code&gt; compiler lags somewhat in this regard.&lt;/p&gt;
&lt;h3 id=&#34;key-points-explanation-1&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;The code executes on different machines, and the two datasets do not have a direct comparison; instead, differences can be compared between various splicing methods.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;key-points-explanation-2&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Windows platform under Visual Studio 2022 compiler

----------------------------------------
Data Generation Time: 0.054 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.053 seconds.
+ ostringstream Data merging took: 0.054 seconds.
+ Pre-reserved Data merging took: 0.045 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 16.108 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;key-points-explanation-3&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Linux platform under GCC 8.5 compiler
----------------------------------------
Data Generation Time: 0.108 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.100 seconds.
+ ostringstream Data merging took: 0.083 seconds.
+ Pre-reserved Data merging took: 0.057 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 29.298 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;random&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;sstream&amp;gt;
#include &amp;lt;iomanip&amp;gt;

typedef std::vector&amp;lt;std::string&amp;gt; DataRow;
typedef std::vector&amp;lt;DataRow&amp;gt; DataGroup;

struct ResponsePackage
{
    std::string ErrorInfo;
    DataRow Head;
    std::string ClientId;
    std::string UUID;
    std::string MsgID;
    std::string SessionID;
    std::string ExtraInfo1;
    std::string ExtraInfo2;
    DataGroup DataBody;
};
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-1&#34;&gt;Complete Code
&lt;/h2&gt;&lt;p&gt;// Generate specified length of random string
std::string generateRandomString(size_t length)
{
const char charset[] = &amp;ldquo;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&amp;rdquo;;
const size_t max_index = sizeof(charset) - 1;
std::string random_string;
random_string.reserve(length);&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;std::random_device rd;
std::mt19937 generator(rd());
std::uniform_int_distribution&amp;lt;&amp;gt; distribution(0, max_index);
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-2&#34;&gt;Complete Code
&lt;/h2&gt;&lt;p&gt;for (size_t i = 0; i &amp;lt; length; ++i)
{
random_string += charset[distribution(generator)];
}&lt;/p&gt;
&lt;p&gt;return random_string;
}&lt;/p&gt;
&lt;p&gt;void create_large_string()
{
// Example request package with 50 fields
ResponsePackage requestPackage;&lt;/p&gt;
&lt;h2 id=&#34;complete-code-3&#34;&gt;Complete Code
&lt;/h2&gt;&lt;p&gt;requestPackage.Head = {
&amp;ldquo;Field1&amp;rdquo;, &amp;ldquo;Field2&amp;rdquo;, &amp;ldquo;Field3&amp;rdquo;, &amp;ldquo;Field4&amp;rdquo;, &amp;ldquo;Field5&amp;rdquo;,
&amp;ldquo;Field6&amp;rdquo;, &amp;ldquo;Field7&amp;rdquo;, &amp;ldquo;Field8&amp;rdquo;, &amp;ldquo;Field9&amp;rdquo;, &amp;ldquo;Field10&amp;rdquo;,
&amp;ldquo;Field11&amp;rdquo;, &amp;ldquo;Field12&amp;rdquo;, &amp;ldquo;Field13&amp;rdquo;, &amp;ldquo;Field14&amp;rdquo;, &amp;ldquo;Field15&amp;rdquo;,
&amp;ldquo;Field16&amp;rdquo;, &amp;ldquo;Field17&amp;rdquo;, &amp;ldquo;Field18&amp;rdquo;, &amp;ldquo;Field19&amp;rdquo;, &amp;ldquo;Field20&amp;rdquo;,
&amp;ldquo;Field21&amp;rdquo;, &amp;ldquo;Field22&amp;rdquo;, &amp;ldquo;Field23&amp;rdquo;, &amp;ldquo;Field24&amp;rdquo;, &amp;ldquo;Field25&amp;rdquo;,
&amp;ldquo;Field26&amp;rdquo;, &amp;ldquo;Field27&amp;rdquo;, &amp;ldquo;Field28&amp;rdquo;, &amp;ldquo;Field29&amp;rdquo;, &amp;ldquo;Field30&amp;rdquo;,
&amp;ldquo;Field31&amp;rdquo;, &amp;ldquo;Field32&amp;rdquo;, &amp;ldquo;Field33&amp;rdquo;, &amp;ldquo;Field34&amp;rdquo;, &amp;ldquo;Field35&amp;rdquo;
};&lt;/p&gt;
&lt;h2 id=&#34;complete-code-4&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;Field31&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field32&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field33&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field34&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field35&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field36&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field37&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field38&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field39&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field40&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field41&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field42&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field43&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field44&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field45&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field46&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field47&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field48&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field49&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field50&amp;quot;: &amp;quot;&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-5&#34;&gt;Complete Code
&lt;/h2&gt;&lt;p&gt;requestPackage.ClientId = &amp;ldquo;ClientID&amp;rdquo;;
requestPackage.UUID = &amp;ldquo;UUID&amp;rdquo;;
requestPackage.MsgID = &amp;ldquo;MsgID&amp;rdquo;;
requestPackage.SessionID = &amp;ldquo;SessionID&amp;rdquo;;
requestPackage.ExtraInfo1 = &amp;ldquo;ExtraInfo1&amp;rdquo;;
requestPackage.ExtraInfo2 = &amp;ldquo;ExtraInfo2&amp;rdquo;;&lt;/p&gt;
&lt;p&gt;// Start timing for data generation
auto start_gen = std::chrono::high_resolution_clock::now();&lt;/p&gt;
&lt;h2 id=&#34;complete-code-6&#34;&gt;Complete Code
&lt;/h2&gt;&lt;p&gt;// Generate 10,000 rows of data, each with 50 fields
for (size_t i = 0; i &amp;lt; 10000; ++i)
{
DataRow dataRow(50, &amp;ldquo;This is a test string&amp;rdquo;);
requestPackage.DataBody.push_back(dataRow);
}&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// End timing for data generation
auto end_gen = std::chrono::high_resolution_clock::now();
std::chrono::duration&amp;lt;double&amp;gt; duration_gen = end_gen - start_gen;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code
// Display result generation time
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Generation Time: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_gen.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    // Data merging using different methods
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Performance:\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-7&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Method 1: Using &#39;+=&#39; string concatenation
auto start_merge = std::chrono::high_resolution_clock::now();
std::string bodys(&amp;quot;&amp;quot;);
for (auto&amp;amp; vec : requestPackage.DataBody)
{
    std::string body(&amp;quot;This is a test string&amp;quot;);
    for (auto&amp;amp; item : vec)
    {
        body += item + &amp;quot; &amp;quot;;
    }
    bodys += body + &amp;quot;\n&amp;quot;;
}
auto end_merge = std::chrono::high_resolution_clock::now();
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code
}
    auto end_merge = std::chrono::high_resolution_clock::now();
    std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
    std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (+=) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-8&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Method 2: Using ostringstream
auto start_merge = std::chrono::high_resolution_clock::now();
std::ostringstream bodys;
for (auto&amp;amp; vec : requestPackage.DataBody)
{
    std::ostringstream body;
    body &amp;lt;&amp;lt; &amp;quot;This is a test string&amp;quot;;
    for (auto&amp;amp; item : vec)
    {
        body &amp;lt;&amp;lt; item &amp;lt;&amp;lt; &amp;quot; &amp;quot;;
    }
    bodys &amp;lt;&amp;lt; body.str() &amp;lt;&amp;lt; &amp;quot;\n&amp;quot;;
}
auto end_merge = std::chrono::high_resolution_clock::now();
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code
}
    auto end_merge = std::chrono::high_resolution_clock::now();
    std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
    std::cout &amp;lt;&amp;lt; &amp;quot;+ ostringstream Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code
{
        // Method 3: Pre-allocated memory
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys;
        bodys.reserve(1000 * 50 * 20); // Pre-allocate enough memory
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            body.reserve(50 * 20); // Pre-allocate memory for each row
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code

for (auto&amp;amp; item : vec) {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Pre-reserved Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-9&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;// Method 4: Using &#39;bodys = bodys + body + &amp;quot;\n&amp;quot;&#39;
auto start_merge = std::chrono::high_resolution_clock::now();
std::string bodys(&amp;quot;&amp;quot;);
for (auto&amp;amp; vec : requestPackage.DataBody)
{
    std::string body(&amp;quot;This is a test string&amp;quot;);
    for (auto&amp;amp; item : vec)
    {
        body = body + item + &amp;quot; &amp;quot;; // Note the use of &#39;body = body + item&#39;
    }
    bodys = bodys + body + &amp;quot;\n&amp;quot;; // Again, using &#39;bodys = bodys + body&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code

```cpp
        auto start_merge = std::chrono::high_resolution_clock::now();
        bodys = bodys + body + &amp;quot;\n&amp;quot;; // Again, using &#39;bodys = bodys + body&#39;
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (bodys = bodys + body + \&amp;quot;\\n\&amp;quot;) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-10&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Complete.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;
}

int main()
{
    try
    {
        create_large_string();
    }
    catch (const std::exception&amp;amp; e)
    {
        std::cerr &amp;lt;&amp;lt; &amp;quot;Caught exception: &amp;quot; &amp;lt;&amp;lt; e.what() &amp;lt;&amp;lt; std::endl;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\nProgram finished.\n&amp;quot;;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Win11 Logitech G431 Headset Driver Installation</title>
        <link>https://ttf248.life/en/p/win11-logitech-g431-headphone-driver-installation/</link>
        <pubDate>Wed, 05 Jun 2024 07:20:17 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/win11-logitech-g431-headphone-driver-installation/</guid>
        <description>&lt;p&gt;Picking up where we left off, I discovered that GitHub had an update, which was a little exciting. The customer service team said the issue with the driver not loading properly was resolved. However, after going through all of this – reinstalling and uninstalling – it still wasn’t working correctly.&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background
&lt;/h2&gt;&lt;p&gt;Continuing to contact customer service to inquire about a resolution, I was informed that an engineer could provide remote assistance. However, the engineer’s working hours coincided exactly with my own, leaving me with no option but to abandon the effort. Reviewing the documentation from the previous troubleshooting issue, I decided to attempt a manual driver installation.&lt;/p&gt;
&lt;h2 id=&#34;obtaining-driver-installation-packages&#34;&gt;Obtaining Driver Installation Packages
&lt;/h2&gt;&lt;p&gt;Logitech does not provide separate driver installation packages for devices. How can I obtain the driver files?&lt;/p&gt;
&lt;p&gt;In conjunction with the system image package left over from the previous system reinstallation, we can reinstall the system once in a local virtual machine, and then deploy a clean copy of Ghub in the pure system, inserting the headset device into the virtual machine to find the driver path and copy it out.&lt;/p&gt;
&lt;p&gt;Relevant paths:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C:\ProgramData\LGHUB&lt;/li&gt;
&lt;li&gt;C:\Windows\System32\DriverStore\FileRepository\logi_audio.inf_amd64_010b035044e24be4&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;device-manager&#34;&gt;Device Manager
&lt;/h2&gt;&lt;p&gt;The focus is on how to find the second path – let’s first briefly outline how to manually manage driver files in a Windows 11 system. This content &lt;strong&gt;is identified using the method of controlling variables by repeatedly plugging and unplugging devices, analyzing device information within Device Manager inside a virtual machine, and identifying three drivers that need to be handled for headphones.&lt;/strong&gt; Two of these drivers are system-provided, while one is provided by Logitech.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/win11-logitech-g431-headphone-driver-installation/20240605073331.png&#34;
	width=&#34;433&#34;
	height=&#34;904&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Driver Manager&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;47&#34;
		data-flex-basis=&#34;114px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;In the second driver shown in the image, it’s provided by Logitech.  Let&amp;rsquo;s analyze the current driver program for the device and then search all driver paths within the virtual machine. Of course, you first need to find files starting with “logi,” and then compare the files – this will allow you to pinpoint the location of the driver folder, copy the entire folder, and you’ll have the driver installation package.&lt;/p&gt;
&lt;h2 id=&#34;installing-the-driver&#34;&gt;Installing the Driver
&lt;/h2&gt;&lt;p&gt;In the device manager interface, click: Update driver, then click: Browse my computer to find drivers, and you’ll arrive at the following interface:&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/win11-logitech-g431-headphone-driver-installation/20240605074130.png&#34;
	width=&#34;528&#34;
	height=&#34;381&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Driver Installation&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;138&#34;
		data-flex-basis=&#34;332px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Of course, when you open it, you&amp;rsquo;ll only see one driver – the standard USB driver. Select &amp;ldquo;Install from disk&amp;rdquo; and the path is the folder we copied earlier. After installation, you’ll be able to add Logitech-specific drivers in the dropdown list. Switch the device driver to the newly installed driver.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/win11-logitech-g431-headphone-driver-installation/20240605074208.png&#34;
	width=&#34;593&#34;
	height=&#34;423&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Disk Installation&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;140&#34;
		data-flex-basis=&#34;336px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;human-anatomy-device-driven&#34;&gt;Human Anatomy Device-Driven
&lt;/h2&gt;&lt;p&gt;These driver files are provided by the system. You only need to check if there is an exclamation mark preceding the device driver name. If there is, enter the Driver Selection interface, randomly switch to a different type of driver, and then revert it back to restore normal operation.&lt;/p&gt;
&lt;h2 id=&#34;completed&#34;&gt;Completed
&lt;/h2&gt;&lt;p&gt;The microphone volume on the headphones has been restored to normal, and the familiar in-ear functionality has returned.
&lt;img src=&#34;https://ttf248.life/p/win11-logitech-g431-headphone-driver-installation/20240605074823.png&#34;
	width=&#34;485&#34;
	height=&#34;739&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Side Noise&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;65&#34;
		data-flex-basis=&#34;157px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Why does a newly installed gigabit fiber to the home (FTTH) connection only test at 100 Mbps?</title>
        <link>https://ttf248.life/en/p/gigabit-fiber-slow-speed/</link>
        <pubDate>Mon, 18 Mar 2024 00:29:02 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/gigabit-fiber-slow-speed/</guid>
        <description>&lt;p&gt;Want your home network to be lightning fast? The key is understanding cable selection, optical lines (ONTs), and router configuration, as well as those seemingly insignificant details. This blog post will guide you through easily learning how to build a gigabit network using six types of cables, and how to ensure your network speed isn&amp;rsquo;t restricted by simple device checks and configurations. Let’s explore together and make your home network fly!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/gigabit-fiber-slow-speed/image.png&#34;
	width=&#34;1001&#34;
	height=&#34;590&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Manual Repair&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;169&#34;
		data-flex-basis=&#34;407px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;chapter-1-an-in-depth-analysis-of-network-transmission-media&#34;&gt;Chapter 1: An In-Depth Analysis of Network Transmission Media
&lt;/h2&gt;&lt;p&gt;When discussing achieving gigabit network access, the carrier that supports high-speed information transmission – cables – plays a crucial role. Below we will provide detailed interpretations of Cat5, Cat6, and Cat7 cables.&lt;/p&gt;
&lt;h3 id=&#34;1-five-category-cables-cat5&#34;&gt;1. &lt;strong&gt;Five-Category Cables (CAT5)&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;CAT5 cables, also known as CAT5, are an earlier and more widely adopted type of twisted pair cable. Each pair of wire pairs is designed with a precise helical structure to reduce crosstalk. It’s primarily used for 10/100Mbps Fast Ethernet, with a maximum transmission frequency of approximately 100MHz. While it was once widely applied, CAT5 cables cannot meet current demands for gigabit and even higher speeds due to physical limitations.&lt;/p&gt;
&lt;h3 id=&#34;2-six-category-cables-cat6&#34;&gt;2. &lt;strong&gt;Six-Category Cables (CAT6)&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;With the development of technology, six-category cables have emerged. Compared to five-category cables, six-core wires adopted stricter manufacturing standards and more advanced structural designs, significantly improving anti-interference capability and transmission efficiency, supporting data transfer rates up to 1Gbps, and with a transmission distance of up to 100 meters under ideal conditions, which perfectly meets the access requirements of Gigabit networks.&lt;/p&gt;
&lt;h3 id=&#34;3-seven-category-cables-cat7&#34;&gt;3. &lt;strong&gt;Seven-Category Cables (CAT7)&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;Seven-category cables represent the current cutting edge of twisted pair cabling technology. It not only offers a significant leap in transmission rates, theoretically supporting speeds up to 10Gbps, but also incorporates a complete shielding system, including shielding between each pair and overall external shielding, which greatly reduces external electromagnetic interference and near-end crosstalk, ensuring data transmission stability and accuracy. However, CAT7 cables are primarily used for future 10 Gigabit Ethernet or specific high-requirement scenarios.&lt;/p&gt;
&lt;p&gt;When setting up a gigabit home network environment, choosing six-category cables is the most economical and efficient choice to fully unleash the potential of the gigabit fiber optic.  Furthermore, ensuring that all cabling materials meet quality standards and strictly adhering to standard wiring practices are also crucial aspects in guaranteeing network performance.&lt;/p&gt;
&lt;h2 id=&#34;chapter-two-deep-dive-into-core-network-devices--the-impact-of-optical-cat-光猫-and-router-lan-port-bandwidth&#34;&gt;Chapter Two: Deep Dive into Core Network Devices – The Impact of Optical Cat (光猫) and Router LAN Port Bandwidth
&lt;/h2&gt;&lt;h3 id=&#34;the-importance-of-optical-cat-ont-and-its-lan-port-bandwidth&#34;&gt;The Importance of Optical Cat (ONT) and its LAN Port Bandwidth
&lt;/h3&gt;&lt;p&gt;An ONT, or optical network terminal, is the core device for home broadband access. Its function is to convert optical signals from fiber optic cables into digital signals for use by home network devices. For users with gigabit fiber connections, whether the ONT supports gigabit transmission is particularly important. If the ONT’s WAN port only supports 100 Mbps, even if the incoming fiber rate is high, it will be limited to 100 Mbps due to this bottleneck. Similarly, the ONT’s LAN port also needs to have a gigabit output capability; otherwise, routers or other devices connected to it cannot obtain the true gigabit rate.&lt;/p&gt;
&lt;h3 id=&#34;the-role-of-bandwidth-on-router-lan-ports&#34;&gt;The Role of Bandwidth on Router LAN Ports
&lt;/h3&gt;&lt;p&gt;The router’s LAN ports are responsible for distributing the data received to various terminal devices. When a router&amp;rsquo;s LAN port is only 100 Mbps, even if other devices are configured well, it can only achieve 100 Mbps local network communication. Therefore, when building a Gigabit home network, it’s important to ensure that the router’s WAN port can receive 1 Gbps data and that the LAN ports also provide data output capabilities at the Gigabit level, so that all smart devices in your home can enjoy the smooth experience brought by high-speed networks.&lt;/p&gt;
&lt;p&gt;Furthermore, it&amp;rsquo;s worth noting that some older or low-end routers may have a LAN port automatic negotiation mechanism, which means that even if the router itself supports 1 Gbps, it may be downgraded to a 100 Mbps mode due to cable issues, device compatibility, and other reasons. Therefore, correctly configuring router parameters, enabling forced gigabit mode, and pairing it with a gigabit switch or direct device are key steps in achieving a full gigabit network. After upgrading to gigabit fiber, be sure to check and replace with gigabit optical switches and gigabit routers to ensure all device interfaces meet gigabit standards.&lt;/p&gt;
&lt;h2 id=&#34;chapter-three-the-hidden-mystery--how-a-broken-subline-impacts-gigabit-network-speed&#34;&gt;Chapter Three: The Hidden Mystery – How a Broken Subline Impacts Gigabit Network Speed
&lt;/h2&gt;&lt;h3 id=&#34;line-fault-and-network-performance-degradation&#34;&gt;Line Fault and Network Performance Degradation
&lt;/h3&gt;&lt;p&gt;During the speed tests, the network consistently maintained a connection without any apparent disconnects. As it was a newly deployed broadband for residential customers, the distribution box was cluttered and frequently adjusted the optical cat’s wiring and power outlet positions, occasionally resulting in speeds reaching gigabit.&lt;/p&gt;
&lt;p&gt;Based on the previous information, we had analyzed and eliminated potential issues related to cable type and optical cat LAN port speed. Ultimately, the culprit was discovered to be a broken brown sub-cable within the network cable itself.&lt;/p&gt;
&lt;p&gt;The cause of the break: When the technician installed the crystal head, this cable was applied with slightly excessive force, causing one of the sub-cables to break in half. It wasn’t completely severed, and subsequent adjustments to the optical cat&amp;rsquo;s position caused it to eventually break completely.&lt;/p&gt;
&lt;h3 id=&#34;six-category-cable-lines-function-analysis&#34;&gt;Six Category Cable Lines Function Analysis
&lt;/h3&gt;&lt;p&gt;Six category cables adhere to the TIA/EIA-568-B standard and contain eight twisted pairs of wires, color-coded as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;White Orange / Orange&lt;/li&gt;
&lt;li&gt;White Green / Green&lt;/li&gt;
&lt;li&gt;White Blue / Blue&lt;/li&gt;
&lt;li&gt;White Brown / Brown&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Under the standard of Gigabit Ethernet (1000BASE-T), these eight lines consist of four pairs working simultaneously, with the following division of labor:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The White Orange and Orange pair of wires (1&amp;amp;2) is used for transmitting data (Tx+/-);&lt;/li&gt;
&lt;li&gt;The White Green and Green pair of wires (3&amp;amp;6) is used for receiving data (Rx+/-);&lt;/li&gt;
&lt;li&gt;The White Blue and Blue pair of wires (4&amp;amp;5) and the White Brown and Brown pair of wires (7&amp;amp;8) were not originally primary in Gigabit Ethernet, but may be enabled in certain advanced applications (such as some PoE power delivery or future technology expansions). In traditional 100 Mbps networks, only four lines – 1, 2, 3, and 6 – could be used.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;impact-of-breakaway-pairs-on-network-speed&#34;&gt;Impact of Breakaway Pairs on Network Speed
&lt;/h3&gt;&lt;p&gt;In the above scenarios, if a brown sub-cable (i.e., brown or brown-white wire) breaks, theoretically it will cause speed degradation in gigabit networks, as gigabit networks require all four pairs of wires to transmit bidirectionally simultaneously to achieve full speed. However, due to home network devices often having auto-negotiation features, when a cable issue is detected, they will revert to a lower operating rate that functions normally, which is the megabit mode, explaining why even with a broken sub-cable, the network can maintain connectivity and operate at megabit speeds.&lt;/p&gt;
&lt;p&gt;In short, although a brown sub-cable break does not affect the basic operation of a megabit network, it can become a key limiting factor for network speed in gigabit environments. Until a thorough diagnosis and repair is conducted, the full potential of gigabit fiber cannot be truly realized. This also serves as a reminder that we should not overlook any potential network infrastructure issues when encountering similar situations – even seemingly minor connection glitches can become hidden obstacles to a high-speed networking experience.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>WPF UI Thread Blocking Issues and Solutions</title>
        <link>https://ttf248.life/en/p/wpf-ui-thread-and-freezing-solutions/</link>
        <pubDate>Tue, 12 Mar 2024 07:12:21 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/wpf-ui-thread-and-freezing-solutions/</guid>
        <description>&lt;p&gt;When developing desktop applications, particularly when using the Windows Presentation Foundation (WPF) framework to build rich client applications, properly handling the user interface (UI) thread is crucial for ensuring the application’s smoothness and responsiveness. The UI thread, also known as the main thread, is the core thread responsible for processing window and control events, layout calculations, and rendering the UI. Any interaction with UI elements should be executed on the UI thread; this is a fundamental principle followed by WPF and most other GUI frameworks.&lt;/p&gt;
&lt;h2 id=&#34;what-is-the-ui-thread&#34;&gt;What is the UI Thread?
&lt;/h2&gt;&lt;p&gt;The UI thread is created by the operating system when a WPF application starts and initializes the main application window. It’s the only thread within the application that can directly access and modify the state of UI components. This means all user interactions, such as button clicks, text box input, or window size changes, are processed in this thread context. Furthermore, WPF&amp;rsquo;s dependency property system, data binding mechanism, and layout logic are all synchronized on the UI thread.&lt;/p&gt;
&lt;h2 id=&#34;screen-freezing-phenomenon-and-its-causes&#34;&gt;Screen Freezing Phenomenon and Its Causes
&lt;/h2&gt;&lt;p&gt;When the UI thread is heavily occupied or blocked for an extended period, such as when performing time-consuming calculations, loading large amounts of data, database queries, or other I/O-intensive tasks, it becomes unable to promptly respond to user interaction requests. This results in the UI freezing – what we commonly refer to as “stuttering” or “freezing.” In this situation, users will noticeably feel the application’s lag and lack of smoothness, and in severe cases, an &amp;ldquo;Application Not Responding&amp;rdquo; (ANR) warning may appear.&lt;/p&gt;
&lt;h2 id=&#34;two-basic-rules-for-the-ui-thread&#34;&gt;Two Basic Rules for the UI Thread
&lt;/h2&gt;&lt;p&gt;To avoid the above scenarios, WPF developers should adhere to the following two key rules:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Do not perform time-consuming operations on the UI thread:&lt;/strong&gt; Any operation that could cause the UI thread to block should be moved to a background thread as much as possible to ensure the UI thread can promptly respond to user input and render screen changes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Do not directly update UI elements from non-UI threads:&lt;/strong&gt; Due to WPF’s security mechanism design, only the UI thread has permission to modify UI elements. Attempting to change UI state directly from another thread will throw an exception. Therefore, even if a background thread completes calculations or data preparation, you must use appropriate cross-thread communication mechanisms to display the results on the UI.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;solutions-asynchronous-programming-and-thread-safe-updates&#34;&gt;Solutions: Asynchronous Programming and Thread-Safe Updates
&lt;/h2&gt;&lt;p&gt;To execute time-consuming tasks while maintaining UI fluency, WPF provides various asynchronous programming models and tools to assist developers in achieving this goal:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Dispatcher Object:&lt;/strong&gt; The WPF Dispatcher class allows you to schedule work items into the UI thread&amp;rsquo;s task queue for execution. You can use the &lt;code&gt;Dispatcher.Invoke&lt;/code&gt; or &lt;code&gt;Dispatcher.BeginInvoke&lt;/code&gt; methods to safely update the UI from a background thread.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;async/await Keywords:&lt;/strong&gt; Leveraging C#’s asynchronous features, you can write asynchronous methods and utilize the &lt;code&gt;await&lt;/code&gt; keyword within them to wait for background tasks to complete, automatically returning to the UI thread to execute subsequent UI update code upon completion.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;case-studies&#34;&gt;Case Studies
&lt;/h2&gt;&lt;h3 id=&#34;updating-the-ui-using-dispatcherinvoke-method&#34;&gt;Updating the UI Using &lt;code&gt;Dispatcher.Invoke&lt;/code&gt; Method
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;private void Button_Click(object sender, RoutedEventArgs e)
{
    // Assume this is a time-consuming operation
    Task.Run(() =&amp;gt;
    {
        var result = LongRunningOperation(); // This is a simulated method for a long calculation
        
        // When the time-consuming operation is complete, update the UI on the UI thread
        Application.Current.Dispatcher.Invoke(() =&amp;gt;
        {
            LabelStatus.Text = $&amp;quot;Calculation Result: {result}&amp;quot;;
        });
    });
}

private string LongRunningOperation()
{
    // Simulate a time-consuming operation
    Thread.Sleep(5000);
    return &amp;quot;Completed&amp;quot;;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;using-the-asyncawait-keyword-with-taskrun&#34;&gt;Using the &lt;code&gt;async/await&lt;/code&gt; keyword with &lt;code&gt;Task.Run&lt;/code&gt;
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;private async void Button_ClickAsync(object sender, RoutedEventArgs e)
{
    Button button = sender as Button;
    button.IsEnabled = false; // Prevent duplicate clicks by the user

    try
    {
        // Start a background task
        var result = await Task.Run(() =&amp;gt; LongRunningOperation());

        // Automatically switch back to the UI thread to update the UI after the background task completes
        LabelStatus.Text = $&amp;quot;Calculation Result: {result}&amp;quot;;
    }
    catch (Exception ex)
    {
        MessageBox.Show($&amp;quot;An error occurred: {ex.Message}&amp;quot;);
    }
    finally
    {
        button.IsEnabled = true; // Re-enable the button
    }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Upgrading the GCC version caused program crashes: hidden issues due to code non-compliance.</title>
        <link>https://ttf248.life/en/p/gcc-upgrade-causes-program-crash-code-irregularities/</link>
        <pubDate>Sun, 10 Mar 2024 23:19:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/gcc-upgrade-causes-program-crash-code-irregularities/</guid>
        <description>&lt;p&gt;In the same business code scenario, the program compiled and ran normally in a CentOS 7 environment. However, when switching to CentOS 8 and using an updated version of GCC for compilation, the program crashed. It’s worth noting that the issue only occurs in &lt;strong&gt;Release mode&lt;/strong&gt;, while &lt;strong&gt;Debug mode&lt;/strong&gt; does not exhibit any problems. This is the first time we&amp;rsquo;ve encountered a situation like this; after three days of investigation, we finally identified the root cause.&lt;/p&gt;
&lt;h3 id=&#34;problem-identification&#34;&gt;Problem Identification
&lt;/h3&gt;&lt;p&gt;After investigation, the root cause of the issue was &lt;strong&gt;the function lacking a return value&lt;/strong&gt;. In Release mode, new versions of GCC perform more optimizations, which caused an unknown logic to occur within the function that originally did not have an explicit return value during execution, ultimately triggering a crash. Our conclusion is that &lt;strong&gt;compiler warnings should not be ignored, especially in legacy projects where some warnings may be dismissed, but it’s also important to avoid suppressing all warnings.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;environment-details&#34;&gt;Environment Details
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CentOS 7 GCC Version:&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CentOS 8 GCC Version:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;crash-phenomena&#34;&gt;Crash Phenomena
&lt;/h3&gt;&lt;p&gt;When analyzing the stack information for program crashes, we observed the following stack details:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[New LWP 1385902]
[Thread debugging using libthread_db enabled]
Using host libthread_db library &amp;quot;/lib64/libthread_db.so.1&amp;quot;.
Core was generated by `./pstack_main`.
Program terminated with signal SIGSEGV, Segmentation fault.
#0  0x00007ffe894b4420 in ?? ()
(gdb) bt
#0  0x00007ffe894b4420 in ?? ()
#1  0x00000000004008e9 in main ()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This stack doesn&amp;rsquo;t appear intuitive; the crash function’s stack information shows a &lt;code&gt;??&lt;/code&gt;, which makes troubleshooting even more complex.&lt;/p&gt;
&lt;h3 id=&#34;code-example&#34;&gt;Code Example
&lt;/h3&gt;&lt;p&gt;To better understand the issue, here’s a minimal code example that reproduces the crash:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;map&amp;gt;

int test() {
    std::cout &amp;lt;&amp;lt; &amp;quot;1&amp;quot; &amp;lt;&amp;lt; std::endl;
}

int main() {
    test();
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;test()&lt;/code&gt; function in this code clearly doesn&amp;rsquo;t explicitly return a value, and its return type is &lt;code&gt;int&lt;/code&gt;. According to the C++ standard, when a function is declared as an &lt;code&gt;int&lt;/code&gt; type, it must have a return value, otherwise it may lead to undefined behavior.&lt;/p&gt;
&lt;h3 id=&#34;compilation-warning&#34;&gt;Compilation Warning
&lt;/h3&gt;&lt;p&gt;In our project, the CMake script suppresses many compile-time warnings, including the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;/root/pstack/main.cpp: In function ‘int test()’:
/root/pstack/main.cpp:7:1: warning: no return statement in function returning non-void [-Wreturn-type]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This warning indicates that the &lt;code&gt;test()&lt;/code&gt; function does not return a value, which is the root cause of the problem. Newer versions of GCC (such as 8.5.0) may make unstable optimizations with this undefined behavior when optimizing code, potentially leading to program crashes.&lt;/p&gt;
&lt;h3 id=&#34;assembly-code-differences&#34;&gt;Assembly Code Differences
&lt;/h3&gt;&lt;p&gt;To explain the differences in GCC compiler optimization behavior, we compared assembly code generated by different versions of GCC:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GCC 4.8.5 Generated Assembly Code:&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The assembly code is relatively verbose and includes handling logic for standard output streams (such as &lt;code&gt;std::cout&lt;/code&gt;). This indicates that the compiler performed more conservative optimizations, not optimizing excessively for the missing return value issue in the &lt;code&gt;test()&lt;/code&gt; function, possibly to avoid a crash.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GCC 8.5.0 Generated Assembly Code:&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The new version of GCC performed more optimizations, reducing the code volume. However, this optimization may have resulted in undefined behavior when calling functions without returning values, leading to program crashes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h3&gt;&lt;p&gt;Through this troubleshooting process, we deeply realized that in C++, &lt;strong&gt;function return values must be explicit&lt;/strong&gt;, especially when a function is declared as &lt;code&gt;int&lt;/code&gt;, a return value must be provided. When upgrading from older versions of compilers to newer versions of GCC, more optimization and stricter warning mechanisms may be encountered. Therefore, we recommend not suppressing all warnings during compilation, but rather selectively addressing them, particularly common issues such as function return values and type matching.
Ultimately, by adding a return value to the &lt;code&gt;test()&lt;/code&gt; function, the problem was resolved, and the program returned to normal operation.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>VMware Virtual Machine CPU Resource Usage Anomaly</title>
        <link>https://ttf248.life/en/p/vmware-virtual-machine-cpu-usage-anomaly/</link>
        <pubDate>Sun, 10 Mar 2024 22:14:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/vmware-virtual-machine-cpu-usage-anomaly/</guid>
        <description>&lt;p&gt;Background: The business system, running in Windows version, is deployed on an on-premise machine with CPU resource utilization at around 5%. The Linux version of the business system, deployed within a VMware-installed CentOS8 environment, exhibits abnormal resource usage.&lt;/p&gt;
&lt;h2 id=&#34;problem-description&#34;&gt;Problem Description
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Host Machine: Windows 10 Enterprise&lt;/li&gt;
&lt;li&gt;VMware: 17.5&lt;/li&gt;
&lt;li&gt;Virtual Machine: CentOS8
The virtual machine resource allocation is &lt;code&gt;4C8GB&lt;/code&gt;, running the business system. The business system is deployed in the Linux system within the virtual machine, and the internal top command observes system resource usage. CPU utilization is not high, while the external Windows system&amp;rsquo;s Task Manager shows very high CPU resource consumption. Examining processes reveals that the VMware process consumes a large amount of CPU resources.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+
|         Windows           |
|                           |
|   +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+  |
|   |      VMware        |  |
|   |      Program       |  |
|   +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+  |
|                           |
+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&lt;/p&gt;
&lt;h2 id=&#34;key-concepts&#34;&gt;Key Concepts
&lt;/h2&gt;&lt;p&gt;Troubleshooting this issue was not straightforward, as the root cause wasn&amp;rsquo;t the business system itself but rather issues with the virtual machine.  How to shift thinking from conventional business code to system load, then from abnormal load data to pinpoint a soft interrupt, and finally arrive at the critical point – what factors affect VMware soft interrupt efficiency? This article will first explain these key concepts before offering solutions.&lt;/p&gt;
&lt;h3 id=&#34;hyper-v&#34;&gt;Hyper-V
&lt;/h3&gt;&lt;p&gt;The virtualization technology for Windows operating systems underwent a significant transformation. When Microsoft initially released WSL, enabling the Hyper-V service would prevent VMware virtual machines from working simultaneously. It wasn&amp;rsquo;t until subsequent versions that VMware could be compatible with the Hyper-V service.&lt;/p&gt;
&lt;h3 id=&#34;system-load&#34;&gt;System Load
&lt;/h3&gt;&lt;p&gt;In Linux systems, &amp;ldquo;load&amp;rdquo; refers to the number of processes currently running or waiting to be executed. The load is typically represented by three numbers, which are the average number of processes in the run queue over 1 minute, 5 minutes, and 15 minutes, respectively. These numbers can be viewed by running the &lt;code&gt;uptime&lt;/code&gt; command or the &lt;code&gt;top&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;Specifically, these three numbers represent:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;1-minute load:&lt;/strong&gt; The average number of processes in the run queue over the past 1 minute.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;5-minute load:&lt;/strong&gt; The average number of processes in the run queue over the past 5 minutes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;15-minute load:&lt;/strong&gt; The average number of processes in the run queue over the past 15 minutes.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The meaning of the load is the number of processes waiting to be executed within the system. - If this number exceeds the logical CPU count of the system, it indicates a high system load, meaning many processes are waiting for processor resources. This can lead to sluggish performance or unresponsiveness, depending on the severity of the load and the configuration and performance of the system.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ideally, the load should remain within the logical CPU count range to optimize system performance. If the load consistently exceeds the CPU count, further analysis of processes within the system may be necessary to identify the cause of the high load and take appropriate measures to adjust resource allocation or optimize process execution.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;analyzing-load---mpstat&#34;&gt;Analyzing Load - mpstat
&lt;/h3&gt;&lt;p&gt;The &lt;code&gt;mpstat&lt;/code&gt; command is used to report multiple statistics for a single or multiple processors, including average load, CPU utilization, interrupts, and context switches. Within the &lt;code&gt;sysstat&lt;/code&gt; package, &lt;code&gt;mpstat&lt;/code&gt; is a very useful tool for analyzing system load conditions.  Below are the steps involved in performing a load analysis using &lt;code&gt;mpstat&lt;/code&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Install sysstat&lt;/strong&gt;:
If &lt;code&gt;sysstat&lt;/code&gt; is not already installed on your system, you can use your system&amp;rsquo;s package manager to install it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Run mpstat&lt;/strong&gt;:
Use the &lt;code&gt;mpstat&lt;/code&gt; command to view CPU usage and load. By default, &lt;code&gt;mpstat&lt;/code&gt; displays CPU utilization averages once per second. You can adjust the output frequency by specifying an interval. - For example, to run &lt;code&gt;mpstat&lt;/code&gt; at a rate of one frequency per second, you can use the following command: &lt;code&gt;mpstat -P ALL 2&lt;/code&gt;, where &lt;code&gt;irq&lt;/code&gt; represents resource utilization.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Analyze Output&lt;/strong&gt;:
The output of &lt;code&gt;mpstat&lt;/code&gt; includes CPU utilization for each CPU, as well as the system&amp;rsquo;s average load. Pay particular attention to the average load and the utilization of each CPU to understand the system’s workload. If the load is high, you can further analyze which processes are causing it, and whether there are any performance bottlenecks.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;analyze-load---mpstat&#34;&gt;Analyze Load - mpstat
&lt;/h3&gt;&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;Combine with Other Tools&lt;/strong&gt;:
In addition to &lt;code&gt;mpstat&lt;/code&gt;, you can also use tools like &lt;code&gt;sar&lt;/code&gt;, &lt;code&gt;pidstat&lt;/code&gt;, and &lt;code&gt;iostat&lt;/code&gt; to comprehensively analyze system performance. By combining the outputs of multiple tools, you can gain a more complete understanding of the system&amp;rsquo;s load situation and identify the root causes of performance issues.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;interrupt&#34;&gt;Interrupt
&lt;/h3&gt;&lt;p&gt;This section doesn&amp;rsquo;t elaborate on the content too much,
Recommended: &lt;a class=&#34;link&#34; href=&#34;https://www.codedump.info/post/20200522-sgfap-softirq/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;System Guide for Application Developers - CPU Part - Soft Interrupt&lt;/a&gt;
Frequent triggering of soft interrupts will also be reflected in system load.&lt;/p&gt;
&lt;h2 id=&#34;troubleshooting&#34;&gt;Troubleshooting
&lt;/h2&gt;&lt;p&gt;Considering that analysis solely from the CPU perspective couldn’t pinpoint the issue, should we start to suspect that the system had become abnormal? It might be due to high load on the Linux operating system, causing VMware to consume excessive CPU resources. By using &lt;code&gt;mpstat&lt;/code&gt; to analyze local virtual machines, we found that &lt;code&gt;irq&lt;/code&gt; utilization was abnormally high, approaching 25% per core, while in normal circumstances, when business processes were idle, &lt;code&gt;irq&lt;/code&gt; should have been around 5%.&lt;/p&gt;
&lt;p&gt;In a colleague’s development environment within the team, his CentOS 7 deployment on VMware showed normal resource usage. Conversely, in the Shanghai development environment, although also running on VMware, we couldn&amp;rsquo;t directly observe the host machine’s CPU resource situation. At this point, we were faced with multiple variables: the VMware virtual machines, the Linux operating system, and the GCC version. - Analyzing the test environment, the Shenzhen test environment is deployed on physical machines running a low version of GCC compiled services. It’s also running on CentOS 8. Interestingly, &lt;code&gt;irq&lt;/code&gt; usage remained normal in the Shenzhen environment.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;To investigate potential issues introduced by the GCC version, we deployed programs compiled with a higher version of GCC to the Shenzhen environment for testing, and the results were normal as well.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The problem seemed to become clearer, and we began to suspect that there might be an issue with the operating system itself. After all, CentOS 8 is no longer officially supported. Even after deploying clean CentOS 7 and CentOS 8 instances, the problem persisted.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;troubleshooting-1&#34;&gt;Troubleshooting
&lt;/h2&gt;&lt;p&gt;At this point, we began to suspect the only unknown factor – VMware virtual machine software. Suddenly, a flash of insight occurred; we thought of Hyper-V technology. Could Hyper-V have been enabled previously but not completely disabled, causing this issue? After all, soft interrupts are also implemented through virtualization software. Do different virtualization technologies have bugs? These questions deserve in-depth consideration and investigation.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h2&gt;&lt;p&gt;According to the Microsoft official documentation, after completely disabling the Hyper-V service on the machine as described, VMware recovered normal operation on the host. This finally resolved the issue. As initially stated, this experience was convoluted and arduous, requiring comprehensive analysis and judgment. It was also our first time troubleshooting and pinpointing the problem down to the virtual machine level.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Disable-WindowsOptionalFeature -Online -FeatureName Microsoft-HyperV-Hypervisor
bcdedit /set hypervisorlaunchtype off
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/troubleshoot/windows-client/application-management/virtualization-apps-not-work-with-hyper-v&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://learn.microsoft.com/zh-cn/troubleshoot/windows-client/application-management/virtualization-apps-not-work-with-hyper-v&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>C&#43;&#43; Programming Traps: A Detailed Explanation of Program Crashes Caused by Improper Use of `std::map`</title>
        <link>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</link>
        <pubDate>Sun, 10 Mar 2024 22:03:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</guid>
        <description>e&gt;
&lt;h2 id=&#34;body&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;In the C++ standard library, &lt;code&gt;std::map&lt;/code&gt; is an associative container that stores elements in ascending order based on their keys (key), and provides efficient keyword lookup functionality. However, novice developers sometimes find themselves in trouble due to a misunderstanding of the behavior of the square bracket operator &lt;code&gt;[]&lt;/code&gt; within &lt;code&gt;std::map&lt;/code&gt;. In fact, when using &lt;code&gt;[]&lt;/code&gt; to access a non-existent key, &lt;code&gt;std::map&lt;/code&gt; inserts a new key-value pair, and the default constructor will be used to initialize the value type associated with that key. ```cpp
#include &lt;iostream&gt;
#include &lt;map&gt;&lt;/p&gt;
&lt;p&gt;int main() {
std::map&amp;lt;std::string, int&amp;gt; myMap;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Incorrect usage: Assuming this attempts to access a non-existent key and will return 0
std::cout &amp;lt;&amp;lt; &amp;quot;Value for &#39;nonexistent_key&#39;: &amp;quot; &amp;lt;&amp;lt; myMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;

// In reality, the above line of code creates a new key-value pair, where the value is initialized to the default value for an int (usually 0)
return 0;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-##&#34;&gt;In the C++ standard library, `std::map` is an associative container that stores elements in ascending order based on their keys (key), and provides efficient keyword lookup functionality. However, novice developers sometimes find themselves in trouble due to a misunderstanding of the behavior of the square bracket operator `[]` within `std::map`. In fact, when using `[]` to access a non-existent key, `std::map` inserts a new key-value pair, and the default constructor will be used to initialize the value type associated with that key.

## Text
Although this code does not directly cause the program to crash, this implicit insertion behavior can lead to unexpected side effects in some cases, such as resource leaks or changes in state that are not expected. Worse still, concurrent access to uninitialized memory regions in a multithreaded environment can even cause the program to crash.

To prevent these issues, it is recommended to use the `std::map::find()` or `std::map::count()` methods to check if a key exists, or to utilize the `std::map::insert()` method to explicitly insert elements:

```cpp
std::map&amp;lt;std::string, int&amp;gt; safeMap;
if (safeMap.count(&amp;quot;nonexistent_key&amp;quot;) == 0) {
    std::cout &amp;lt;&amp;lt; &amp;quot;Key does not exist.&amp;quot; &amp;lt;&amp;lt; std::endl;
} else {
    std::cout &amp;lt;&amp;lt; &amp;quot;Value for existing key: &amp;quot; &amp;lt;&amp;lt; safeMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;
}

// Or explicitly insert a key-value pair, specifying the initial value
safeMap. ## Text
Although the code does not directly cause a program crash, this implicit insertion behavior can lead to unexpected side effects in some cases, such as resource leaks or changes in state that are not expected. Worse still, concurrent access to uninitialized memory regions in a multithreaded environment can even cause a program to crash.

To prevent these issues, it is recommended to use the `std::map::find()` or `std::map::count()` methods to check if a key exists, or to utilize the `std::map::insert()` method to explicitly insert elements:

```cpp
std::map&amp;lt;std::string, int&amp;gt; safeMap;
if (safeMap.count(&amp;quot;nonexistent_key&amp;quot;) == 0) {
    std::cout &amp;lt;&amp;lt; &amp;quot;Key does not exist.&amp;quot; &amp;lt;&amp;lt; std::endl;
} else {
    std::cout &amp;lt;&amp;lt; &amp;quot;Value for existing key: &amp;quot; &amp;lt;&amp;lt; safeMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;
}

// Or explicitly insert a key-value pair, specifying the initial value
safeMap.

## Text
If the objects stored within the map container are pointer types, the automatic insertion behavior will save an uninitialized pointer, and any call to this pointer will cause the program to crash.&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>pstack troubleshoot a hung process</title>
        <link>https://ttf248.life/en/p/pstack-troubleshooting-process-hangs/</link>
        <pubDate>Sat, 24 Feb 2024 23:55:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/pstack-troubleshooting-process-hangs/</guid>
        <description>&lt;p&gt;In software development and operations, deadlocked processes are frequently encountered. This situation can lead to performance degradation or service unavailability. This article introduces how to use the pstack tool to troubleshoot deadlocked process issues by analyzing process stack information to identify the root cause and resolve it.&lt;/p&gt;
&lt;p&gt;Background: A child service within the risk control system experienced a deadlocked state, resulting in the unavailability of the risk control service. Due to the lack of service availability monitoring, the process deadlocks were not detected in a timely manner, leading to system downtime.&lt;/p&gt;
&lt;h2 id=&#34;text&#34;&gt;Text
&lt;/h2&gt;&lt;p&gt;A hung process refers to a process that has stopped responding but hasn&amp;rsquo;t exited. This situation can be caused by various reasons, such as deadlocks, resource exhaustion, or exceptions. To resolve these issues, we can use the &lt;code&gt;pstack&lt;/code&gt; tool to analyze the process’s stack information and identify the root cause.&lt;/p&gt;
&lt;h2 id=&#34;steps&#34;&gt;Steps
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;pstack&lt;/code&gt; is a commonly used tool, often provided alongside &lt;code&gt;gdb&lt;/code&gt; (GNU Debugger). You can install it using the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt-get install gdb
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Obtain Process ID: First, we need to obtain the process ID (PID) of the zombie process. We can use the &lt;code&gt;ps&lt;/code&gt; command to list all processes and find the process ID that needs to be investigated.&lt;/p&gt;
&lt;p&gt;Use the &lt;code&gt;pstack&lt;/code&gt; tool to analyze the process stack. Once you have obtained the process ID, you can use the &lt;code&gt;pstack&lt;/code&gt; tool to retrieve the stack information for that process. Run the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pstack &amp;lt;PID&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will output the stack information of the process, displaying the sequence of function calls currently being executed. By analyzing this information, you can identify where the process is stuck and thus pinpoint the problem.&lt;/p&gt;
&lt;p&gt;Analyze Stack Information: Through reviewing the stack information, you can find the cause of the zombie process.&lt;/p&gt;
&lt;h2 id=&#34;case-study&#34;&gt;Case Study
&lt;/h2&gt;&lt;p&gt;Simple demo: after the main function starts, a child thread is created and the actual function enters a dead loop, causing the program to fail to terminate normally and enter a state of false death.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cmake_minimum_required(VERSION 3.0.0)
project(pstack_main VERSION 0.1.0 LANGUAGES C CXX)

include(CTest)
enable_testing()

# Find the thread library
find_package(Threads REQUIRED)

add_executable(pstack_main main.cpp)

# Link the thread library
target_link_libraries(pstack_main PRIVATE Threads::Threads)

set(CPACK_PROJECT_NAME ${PROJECT_NAME})
set(CPACK_PROJECT_VERSION ${PROJECT_VERSION})
include(CPack)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;case-study-1&#34;&gt;Case Study
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;thread&amp;gt;
#include &amp;lt;chrono&amp;gt;

void infiniteLoop() {
    while (true) {
        // Main thread enters an infinite loop
    }
}

int main() {
    std::thread thread(infiniteLoop); // Create a thread to execute the infinite loop function
    thread.join(); // Wait for the thread to finish
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Run the program and examine the pstack output:&lt;/p&gt;
&lt;h2 id=&#34;case-studies&#34;&gt;Case Studies
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Thread 2 (Thread 0x7eff3619b700 (LWP 1315017)):
#0  infiniteLoop () at /root/pstack/main.cpp:6
#1  0x0000000000402ca9 in std::__invoke_impl&amp;lt;void, void (*)()&amp;gt; (__f=@0x2260eb8: 0x4029a6 &amp;lt;infiniteLoop()&amp;gt;) at /usr/include/c++/8/bits/invoke.h:60
#2  0x0000000000402b02 in std::__invoke&amp;lt;void (*)()&amp;gt; (__fn=@0x2260eb8: 0x4029a6 &amp;lt;infiniteLoop()&amp;gt;) at /usr/include/c++/8/bits/invoke.h:95
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;case-studies-1&#34;&gt;Case Studies
&lt;/h2&gt;&lt;p&gt;#3 0x0000000000403150 in std::thread::_Invoker&amp;lt;std::tuple&amp;lt;void (&lt;em&gt;)()&amp;gt; &amp;gt;::_M_invoke&amp;lt;0ul&amp;gt; (this=0x2260eb8) at /usr/include/c++/8/thread:244
#4 0x0000000000403126 in std::thread::_Invoker&amp;lt;std::tuple&amp;lt;void (&lt;/em&gt;)()&amp;gt; &amp;gt;::operator() (this=0x2260eb8) at /usr/include/c++/8/thread:253
#5 0x000000000040310a in std::thread::_State_impl&amp;lt;std::thread::_Invoker&amp;lt;std::tuple&amp;lt;void (*)()&amp;gt; &amp;gt; &amp;gt;::_M_run (this=0x2260eb0) at /usr/include/c++/8/thread:196&lt;/p&gt;
&lt;h2 id=&#34;case-studies-2&#34;&gt;Case Studies
&lt;/h2&gt;&lt;p&gt;#6 0x00007eff36bceb23 in execute_native_thread_routine () from /lib64/libstdc++.so.6
#7 0x00007eff36ea91ca in start_thread () from /lib64/libpthread.so.0
#8 0x00007eff361d58d3 in clone () from /lib64/libc.so.6
Thread 1 (Thread 0x7eff372e1740 (LWP 1315016)):
#0 0x00007eff36eaa6cd in __pthread_timedjoin_ex () from /lib64/libpthread.so.0
#1 0x00007eff36bceda7 in std::thread::join() () from /lib64/libstdc++.so.6
#2 0x00000000004029d2 in main () at /root/pstack/main.cpp:13&lt;/p&gt;
&lt;h2 id=&#34;case-study-2&#34;&gt;Case Study
&lt;/h2&gt;&lt;p&gt;As can be seen, the reason for the process hanging indefinitely was a deadlock situation where the main thread entered an infinite loop, preventing the child thread from exiting and ultimately causing the process to hang.&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>

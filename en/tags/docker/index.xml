<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Docker on Uncle Xiang&#39;s Notebook</title>
        <link>https://ttf248.life/en/tags/docker/</link>
        <description>Recent content in Docker on Uncle Xiang&#39;s Notebook</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Wed, 28 May 2025 09:47:38 +0800</lastBuildDate><atom:link href="https://ttf248.life/en/tags/docker/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Two years of AI development: Its somewhat like the state before Docker was released</title>
        <link>https://ttf248.life/en/p/ai-development-two-years-docker-pre-release/</link>
        <pubDate>Thu, 20 Feb 2025 18:16:37 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/ai-development-two-years-docker-pre-release/</guid>
        <description>&lt;p&gt;Artificial intelligence (AI) has undoubtedly been one of the most discussed topics in technology in recent years, especially with its rapid advancements over the past two years. From deep learning and natural language processing to computer vision and automated decision systems, AI applications are constantly emerging. However, despite continuous technological breakthroughs, AI still faces a bottleneck similar to that of Docker before its release – a lack of a killer application to truly ignite the market.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The development of AI over the past two years is similar to the state before Docker&amp;rsquo;s release – lacking a killer application. It needs a perfect practical implementation based on existing technology, like Docker: not relying on groundbreaking new technologies, but offering a complete and reasonable solution that transforms operations and development workflows.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;the-current-state-of-ai-development-technology-is-mature-but-application-still-needs-breakthroughs&#34;&gt;The current state of AI development: technology is mature, but application still needs breakthroughs
&lt;/h2&gt;&lt;p&gt;From a technical perspective, AI has made significant progress in the past two years. Whether it&amp;rsquo;s OpenAI’s GPT series models or Google’s BERT and DeepMind’s Alpha series, AI processing capabilities have far exceeded previous expectations. Particularly in natural language processing, models like GPT-4 not only possess powerful generation abilities but also demonstrate astonishing performance in understanding and reasoning.&lt;/p&gt;
&lt;p&gt;However, despite rapid technological advancements, the practical application of AI faces certain challenges. Similar to the state before Docker&amp;rsquo;s release, while AI has immense potential, a truly widespread and industry-transforming &amp;ldquo;killer&amp;rdquo; application hasn&amp;rsquo;t yet emerged. People discuss AI’s prospects but may struggle to find an application that can bring revolutionary change. Many AI applications remain in early experimental stages and require further integration and optimization.&lt;/p&gt;
&lt;h2 id=&#34;the-similarity-between-docker-and-ai-technology-isnt-necessarily-innovation-solutions-are-key&#34;&gt;The similarity between Docker and AI: Technology isn&amp;rsquo;t necessarily innovation, solutions are key
&lt;/h2&gt;&lt;p&gt;Looking back at the history before Docker&amp;rsquo;s release, we find striking similarities with the current state of AI development. Prior to Docker, container technology wasn&amp;rsquo;t new; early technologies like LXC (Linux Containers) and virtualization already possessed basic containerization capabilities. However, Docker cleverly integrated and optimized existing technologies, proposing a simpler, more intuitive, and efficient solution. This approach didn’t introduce revolutionary technology but addressed many pain points in operations and development processes, significantly simplifying software deployment, scaling, and management.&lt;/p&gt;
&lt;p&gt;Similarly, the AI field faces a similar situation. While current AI technology is no longer &amp;ldquo;new,&amp;rdquo; achieving widespread application still requires a perfect implementation scenario – like Docker, integrating and optimizing existing technologies to form a practical solution. The “killer” application of AI may not depend on breakthrough new technologies, but rather on how to integrate existing ones to solve real-world business pain points and needs.&lt;/p&gt;
&lt;h2 id=&#34;how-to-find-ais-docker-moment&#34;&gt;How to find AI&amp;rsquo;s &amp;ldquo;Docker moment&amp;rdquo;?
&lt;/h2&gt;&lt;p&gt;To achieve widespread application of AI technology, several aspects need to be addressed&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are!
Currently, many AI applications remain experimental and lack large-scale practical implementation. While areas like AI customer service and intelligent recommendations are widely used, their functionality is still limited and hasn&amp;rsquo;t yet overcome industry bottlenecks. True breakthroughs may come from industries long burdened by traditional methods—such as healthcare, manufacturing, and logistics—where AI can improve efficiency and reduce costs through more efficient data processing and predictive analysis.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are!
Just as Docker improves operational efficiency by streamlining the containerization process, the usability of AI products is equally crucial. The popularization of AI isn&amp;rsquo;t just about technology; it’s about productization. Integrating AI into daily workflows and enabling users to easily utilize these tools without needing a deep understanding of the underlying technology is a key step in its successful implementation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are!
The widespread adoption of any new technology hinges on building a robust ecosystem. Docker&amp;rsquo;s rapid rise is due to its openness and compatibility, allowing developers to easily connect with various cloud platforms, tools, and services. Similarly, the future of AI depends on ecosystem development. Standardization, model sharing, data accessibility, and technical integration will all influence whether AI can achieve broad industry applications.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;conclusion-the-future-of-ai-is-full-of-possibilities-but-still-requires-more-robust-implementation-plans&#34;&gt;Conclusion: The future of AI is full of possibilities, but still requires more robust implementation plans
&lt;/h2&gt;&lt;p&gt;Despite significant advancements in AI technology over the past two years, it remains in a stage without a killer application. Similar to containerization technology before Docker&amp;rsquo;s release, AI needs a practical application scenario that deeply integrates existing technologies with business needs to achieve widespread adoption and scale. While technological innovation is important, solutions that simplify processes and improve efficiency are more likely to drive the popularization and development of the technology.&lt;/p&gt;
&lt;p&gt;In the future, AI may not revolutionize through groundbreaking technology, but rather create a perfect application scenario by integrating existing technologies—ultimately transforming how we work and live&lt;/p&gt;</description>
        </item>
        <item>
        <title>Docker domestic image proxy failure</title>
        <link>https://ttf248.life/en/p/docker-domestic-mirror-failure/</link>
        <pubDate>Sat, 04 Jan 2025 18:29:25 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/docker-domestic-mirror-failure/</guid>
        <description>&lt;p&gt;Deploying Docker on domestic servers. If the company doesn&amp;rsquo;t provide an image registry, developers must first configure a domestic mirror acceleration address. Today, I configured a mirror acceleration address on a server, but it consistently fails to pull images.&lt;/p&gt;
&lt;p&gt;Error message:&lt;/p&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/p&gt;
&lt;h2 id=&#34;troubleshooting-and-repair-attempts&#34;&gt;Troubleshooting and Repair Attempts
&lt;/h2&gt;&lt;p&gt;Initially, I attempted to switch to an alternative mirror address hoping to resolve the issue, but it proved ineffective; the problem persists&lt;/p&gt;
&lt;p&gt;Immediately, I began modifying the local DNS configuration, attempting to find a breakthrough at the network resolution level; unfortunately, after some debugging, the fault persisted&lt;/p&gt;
&lt;p&gt;The local network&amp;rsquo;s stability is now questionable, so I switched to my phone’s hotspot to bypass potential issues. However, the problem persists unchanged – a frustrating result.&lt;/p&gt;
&lt;h2 id=&#34;problems-spreading&#34;&gt;Problems spreading
&lt;/h2&gt;&lt;p&gt;We have several servers available, all with Docker environments installed. Attempting to pull images from them proved unsuccessful; the error messages were identical across all devices, indicating a systemic issue rather than a problem with a single server.&lt;/p&gt;
&lt;p&gt;Further investigation revealed that the mirror proxy appeared to have failed instantly. Switching quickly to an overseas machine proved successful, and thankfully, image pulling resumed normally. This suggests the issue likely lies within the domestic network link or related configurations.&lt;/p&gt;
&lt;h2 id=&#34;strategic-adjustment-circumventing-solutions&#34;&gt;Strategic adjustment: Circumventing solutions
&lt;/h2&gt;&lt;p&gt;To overcome obstacles in accessing domestic images, and with foreign mirrors accessible, we&amp;rsquo;ve decided on a workaround to expedite project progress. We will first switch to a foreign server to pull the necessary images, then push them to a domestic mirror repository, effectively creating a &amp;ldquo;data bridge.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Meanwhile, the Dockerfile was modified to replace the image address with one suitable for domestic environments, and the image was rebuilt and successfully deployed&lt;/p&gt;</description>
        </item>
        <item>
        <title>Office relocation, servers are inaccessible</title>
        <link>https://ttf248.life/en/p/office-migration-server-unavailable/</link>
        <pubDate>Sat, 11 Mar 2023 01:42:05 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/office-migration-server-unavailable/</guid>
        <description>&lt;p&gt;Office relocation notice: Moving from the second floor to the fifteenth floor, a routine desk move&lt;/p&gt;
&lt;h2 id=&#34;design-sense&#34;&gt;Design sense
&lt;/h2&gt;&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;h2 id=&#34;migration&#34;&gt;Migration
&lt;/h2&gt;&lt;p&gt;Packing up and moving on, setting up my new workstation – adjusting cables and finding a comfortable posture before starting work&lt;/p&gt;
&lt;p&gt;Oh no! The internet connection is up, but I can&amp;rsquo;t access the usual servers in our group. Switching to Wi-Fi works fine.&lt;/p&gt;
&lt;p&gt;Initially, I thought it was a server network segment issue. The new workstation&amp;rsquo;s wired network wasn’t in the firewall configuration, so I figured an IT colleague could adjust it. However, this network segment hosts multiple servers, and accessing others worked fine, which raised my suspicions. Professional matters should be handled by professionals; eventually, the operations team identified the problem: the server deployed &lt;code&gt;docker&lt;/code&gt;，服务的默认网络__INLINE_CODE_1__和办公室有线网络配置的网段冲突了，导致发过去的数据包，都收不到应答，被路由给了__INLINE_CODE_2__ services.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s not unusual for addresses starting with &lt;strong&gt;INLINE_CODE_0__服务，也就这台，我比较常用，偶尔用容器部署一些测试服务，没想到还能碰到这个场景。后来细想想，由于整个集团都在一个办公大楼里面，IT部门的同事划分网段，用到了__INLINE_CODE_1&lt;/strong&gt; to not be deployed on other servers&lt;/p&gt;
&lt;h2 id=&#34;docker0&#34;&gt;docker0
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# vim /etc/docker/daemon.json
{
    &amp;quot;bip&amp;quot;:&amp;quot;172.200.0.1/24&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Restart the service, switch to a new network, and the server will return to normal access&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/p&gt;</description>
        </item>
        <item>
        <title>docker-two-three-things</title>
        <link>https://ttf248.life/en/p/docker-two-three-things/</link>
        <pubDate>Thu, 21 Jan 2021 09:26:07 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/docker-two-three-things/</guid>
        <description>&lt;p&gt;After working for many years, I&amp;rsquo;ve encountered numerous users, and some content is not applicable&lt;/p&gt;
&lt;p&gt;Installation can refer to the manual from Tsinghua University: &lt;a class=&#34;link&#34; href=&#34;https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;install&#34;&gt;Install
&lt;/h2&gt;&lt;p&gt;Due to an unknown mysterious force, it is recommended to use cloud vendor-provided repository addresses for Docker installations within China; here, we recommend &lt;strong&gt;阿里云&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;set-repository-source-address&#34;&gt;Set repository source address
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum install yum-utils device-mapper-persistent-data lvm2 &amp;amp;&amp;amp; \
sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;deploy-the-latest-version&#34;&gt;Deploy the latest version
&lt;/h3&gt;&lt;p&gt;Docker, as a commonly used background service, is recommended to be set up for startup on boot. This command applies to CentOS 7.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo yum install -y docker-ce docker-ce-cli containerd.io &amp;amp;&amp;amp; systemctl enable --now docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;deploy-specified-version&#34;&gt;Deploy specified version
&lt;/h3&gt;&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum list docker-ce --showduplicates | sort -r
sudo yum install -y docker-ce-18.09.2-3.el7 docker-ce-cli-18.09.2-3.el7 containerd.io-18.09.2-3.el7 &amp;amp;&amp;amp; systemctl enable --now docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;add-docker-permissions-for-regular-users&#34;&gt;Add Docker permissions for regular users
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo usermod -aG docker ${USER}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;uninstall&#34;&gt;Uninstall
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo yum erase -y docker-ce docker-ce-cli containerd.io
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;everyday-use&#34;&gt;Everyday use
&lt;/h2&gt;&lt;h3 id=&#34;mirror-acceleration&#34;&gt;Mirror Acceleration
&lt;/h3&gt;&lt;p&gt;There are still unknown mysterious forces causing slow image pulls. Domestic cloud providers have stepped up, offering many acceleration services; I still recommend them.&lt;/p&gt;
&lt;p&gt;To obtain the accelerated access addresses, please register for an Alibaba Cloud account. This service is free, and Alibaba Cloud also provides a free image building service.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cat &amp;gt; /etc/docker/daemon.json &amp;lt;&amp;lt;EOF
{
  &amp;quot;registry-mirrors&amp;quot;: [
    &amp;quot;https://docker.nju.edu.cn&amp;quot;,
    &amp;quot;https://mirror.baidubce.com&amp;quot;,
    &amp;quot;https://docker.m.daocloud.io&amp;quot;,
    &amp;quot;https://docker.mirrors.sjtug.sjtu.edu.cn&amp;quot;
  ]
}
EOF
systemctl daemon-reload &amp;amp;&amp;amp; \
systemctl restart docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;highly-recommended-control-panel&#34;&gt;Highly recommended control panel
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker volume create portainer_data &amp;amp;&amp;amp; \
docker run -d --name=portainer --restart=always -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:2.20.3-alpine
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;commonly-used-image-pulls&#34;&gt;Commonly Used Image Pulls
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker pull rancher/rancher:stable &amp;amp;&amp;amp; docker pull  portainer/portainer-ce:2.0.1 &amp;amp;&amp;amp; \
docker pull centos:7 &amp;amp;&amp;amp; docker pull ubuntu:20.04 &amp;amp;&amp;amp; docker pull ubuntu:18.04 &amp;amp;&amp;amp; \
docker pull redis:5 &amp;amp;&amp;amp; docker pull redis:6 &amp;amp;&amp;amp; \
docker pull alpine:3.11 &amp;amp;&amp;amp; docker pull busybox:1.32 &amp;amp;&amp;amp; \
docker pull rabbitmq:3.7-management &amp;amp;&amp;amp; \
docker pull mariadb:10.2 &amp;amp;&amp;amp; \
docker pull nginx:1.18 &amp;amp;&amp;amp; docker pull nginx:1.19 &amp;amp;&amp;amp; \
docker pull mysql:5.6 &amp;amp;&amp;amp; docker pull mysql:8 &amp;amp;&amp;amp; \
docker pull elasticsearch:6.8.11 &amp;amp;&amp;amp; docker pull logstash:6.8.11 &amp;amp;&amp;amp; docker pull kibana:6.8.11 &amp;amp;&amp;amp; \
docker pull zookeeper:3.4 &amp;amp;&amp;amp; \
docker pull influxdb:1.7 &amp;amp;&amp;amp; docker pull grafana/grafana:7.3.1 &amp;amp;&amp;amp; \
docker pull percona:8 &amp;amp;&amp;amp; docker pull percona:5.6 &amp;amp;&amp;amp; \
docker pull cloverzrg/frps-docker:0.34.3 &amp;amp;&amp;amp; docker pull cloverzrg/frpc-docker:0.34.3
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;common-command-combinations&#34;&gt;Common Command Combinations
&lt;/h3&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.docker.com/engine/reference/commandline/docker/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://docs.docker.com/engine/reference/commandline/docker/&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Check container runtime status, add the __INLINE_CODE_0 parameter, view detailed container information; ignore image information at this time&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker ps --format &amp;quot;{{.Names}}: {{.Ports}}: {{.Size}}&amp;quot;
#portainer: 0.0.0.0:8000-&amp;gt;8000/tcp, 0.0.0.0:9000-&amp;gt;9000/tcp: 0B (virtual 172MB)
#influxdb: 0.0.0.0:8086-&amp;gt;8086/tcp: 183B (virtual 311MB)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;Stop all containers&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker stop $(docker ps -a -q)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Delete all images&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;dokcer rmi $(docker images -a -q)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;Export image&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker save &amp;lt;IMAGE NAME&amp;gt;:&amp;lt;IMAGE TAG&amp;gt; &amp;gt; -o XXX.tar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Export image and compress&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker save &amp;lt;IMAGE NAME&amp;gt;:&amp;lt;IMAGE TAG&amp;gt; | gzip &amp;gt; XXX.tar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Import image&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker load -i XXX.tar
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Setting up a JMeter Testing Environment on Linux</title>
        <link>https://ttf248.life/en/p/linux-setup-jmeter-testing-environment/</link>
        <pubDate>Tue, 22 Dec 2020 10:12:50 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-setup-jmeter-testing-environment/</guid>
        <description>&lt;p&gt;The author, with a strong interest in hardware, conducted performance testing using JMeter and documented the deployment process of JMeter, InfluxDB, and Grafana on CentOS 7. They shared details on JMeter installation and command usage, InfluxDB features and Docker installation, as well as simple Grafana deployment and configuration. The document summarizes experiences and references for high-performance programming patterns.&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background
&lt;/h2&gt;&lt;p&gt;What use is a web panel in addition to data display?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You won&amp;rsquo;t understand until you try it yourself
Don&amp;rsquo;t use GUI mode for load testing! only for Test creation and Test debuggin.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The official recommendation is to obtain the load test report via command line and display it with a GUI, which may introduce data errors? I don&amp;rsquo;t have a deep understanding of JMeter, but at least this gives me a reason to experiment with the console panel in version &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The deployment method of Open Source China&amp;rsquo;s posts is not user-friendly, and the required files for installation also need to be downloaded via a public account. As a new generation, I naturally chose an alternative. Ultimately, it’s still slow accessing cross-border sources due to servers being located domestically; at least mirror services offer acceleration, like the free one from Alibaba Cloud.&lt;/p&gt;
&lt;p&gt;Installation deployment of &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; is not detailed here; please refer to previous articles for guidance&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;The following content is divided into two parts: building basic testing environment components and a brief introduction to each component&lt;/p&gt;
&lt;h2 id=&#34;jmeter&#34;&gt;Jmeter
&lt;/h2&gt;&lt;p&gt;Apache JMeter is a load testing tool developed by the Apache organization, based on Java. It was initially designed for web application testing but has since been extended to other testing areas. It can be used to test static and dynamic resources such as static files, Java microservices, CGI scripts, Java objects, databases, FTP servers, etc. JMeter can simulate a large load on servers, networks, or objects to test their strength and analyze overall performance under different stress categories. Additionally, JMeter can perform functional/regression testing by creating scripts with assertions to verify that your program returns the expected results. For maximum flexibility, JMeter allows the use of regular expressions for creating assertions.&lt;/p&gt;
&lt;p&gt;Apache JMeter can be used to test the performance of static and dynamic resources (files, Servlets, Perl scripts, Java objects, databases and queries, FTP servers, etc.). It can simulate heavy loads on servers, networks, or objects to test their resilience or analyze overall performance under different types of stress. You can use it for graphical analysis of performance or to load test your servers/scripts/objects with high concurrency.&lt;/p&gt;
&lt;h3 id=&#34;jmeter-deployment-on-centos-7&#34;&gt;JMeter deployment on CentOS 7
&lt;/h3&gt;&lt;p&gt;Installation package&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum install java-1.8.0-openjdk -y &amp;amp;&amp;amp; \
wget https://mirrors.bfsu.edu.cn/apache//jmeter/binaries/apache-jmeter-5.4.tgz &amp;amp;&amp;amp; tar -xf apache-jmeter-5.4.tgz
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Configure environment variables&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export JMETER_HOME=$HOME/jmeter/apache-jmeter-5.4
export PATH=$JMETER_HOME/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;jmeter-commands&#34;&gt;JMeter commands
&lt;/h3&gt;&lt;p&gt;Finally, observe data on the control panel&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;jmeter -n -t /tmp/order-500-10s.jmx -l /tmp/jmeter-order-report-20200109/order-500-10s.jtl
# 一般不用测试结果和测试报告，简化命令
jmeter -n -t /tmp/order-500-10s.jmx
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;influxdb&#34;&gt;InfluxDB
&lt;/h2&gt;&lt;p&gt;InfluxDB is an open-source distributed time series, event, and metrics database written in Go, requiring no external dependencies. It&amp;rsquo;s now primarily used to store large volumes of timestamped data, such as DevOps monitoring data, app metrics, IoT sensor data, and real-time analytics data.&lt;/p&gt;
&lt;h3 id=&#34;influxdb-features&#34;&gt;InfluxDB Features
&lt;/h3&gt;&lt;p&gt;The features of InfluxDB can be summarized into 9 aspects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Unstructured (no pattern): Can have an arbitrary number of columns;&lt;/li&gt;
&lt;li&gt;The retention period for metrics can be configured&lt;/li&gt;
&lt;li&gt;Supports time-related functions (e.g., min, max, sum, count, mean, median) for statistical analysis&lt;/li&gt;
&lt;li&gt;Supports storage policies: Can be used for data deletion and modification (InfluxDB does not provide methods for deleting or modifying data)&lt;/li&gt;
&lt;li&gt;Continuous queries are a set of statements that automatically start on a schedule in the database, and when paired with storage policies, can reduce InfluxDB system resource usage&lt;/li&gt;
&lt;li&gt;Native HTTP support, built-in HTTP API&lt;/li&gt;
&lt;li&gt;Supports SQL-like syntax&lt;/li&gt;
&lt;li&gt;Allows configuring the number of data replicas within the cluster&lt;/li&gt;
&lt;li&gt;Supports periodic sampling data, writing it to another measurement for granular storage&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;installing-influxdb-docker&#34;&gt;Installing InfluxDB Docker
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mkdir influxdb &amp;amp;&amp;amp; cd influxdb &amp;amp;&amp;amp; \
docker run -p 8086:8086 -d --name influxdb -v $PWD:/var/lib/influxdb influxdb:1.7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Enter container, execute command, manually create database&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;root@bce0a55bbc72:/# influx
Connected to http://localhost:8086 version 1.7.10
InfluxDB shell version: 1.7.10
&amp;gt; 交互面板执行命令
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;creating-databases-and-users-in-influxdb&#34;&gt;Creating databases and users in InfluxDB
&lt;/h3&gt;&lt;p&gt;Create database jmeter_t2
View databases
Switch database: use jmeter_t2
Create user &amp;ldquo;admin&amp;rdquo; with password &amp;lsquo;admin&amp;rsquo; and all privileges
View Users&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;&amp;gt; show users
user  admin
----  -----
admin true
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If user permissions are displayed, database preparation is complete&lt;/p&gt;
&lt;h2 id=&#34;grafana&#34;&gt;Grafana
&lt;/h2&gt;&lt;p&gt;The need for chart display is not essential; the &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; data from the interface can already be observed when executed in the command line, and it&amp;rsquo;s more about understanding the program&amp;rsquo;s internal execution time&lt;/p&gt;
&lt;p&gt;Simple deployment&lt;/p&gt;
&lt;p&gt;The console supports filtering test results by tag, and typically only requires configuring one database&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Application Name&lt;/li&gt;
&lt;li&gt;Test Case Name&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/linux-setup-jmeter-testing-environment/Snipaste_2021-03-09_19-44-22.png&#34;
	width=&#34;861&#34;
	height=&#34;357&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;grafana&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;241&#34;
		data-flex-basis=&#34;578px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -d --name=grafana -p 3000:3000 grafana/grafana:7.3.1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Web version calculations are affected by sampler interval&lt;/p&gt;
&lt;p&gt;The document also describes how to customize __INLINE_CODE_0&lt;/p&gt;
&lt;h2 id=&#34;afterword&#34;&gt;Afterword
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;High-performance programming inherently relies on a single loop thread; any locks, queuing (for entry and exit), will cause unnecessary performance loss&lt;/li&gt;
&lt;li&gt;The time spent on core business logic exceeds the time spent on introducing other code; concurrency is effective only when this core processing time is sufficiently small, and otherwise, introducing additional code should be approached cautiously&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/@jasonli.studio/to-install-apache-jmeter-in-centos7-294bc72a97ba&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;To install Apache JMeter in CentOS7&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        
    </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Pytorch on Uncle Xiang&#39;s Notebook</title>
        <link>https://ttf248.life/en/tags/pytorch/</link>
        <description>Recent content in Pytorch on Uncle Xiang&#39;s Notebook</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Mon, 02 Jun 2025 05:33:00 +0800</lastBuildDate><atom:link href="https://ttf248.life/en/tags/pytorch/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Stable Diffusion – The Love, Hate, and Drama of Installing it from Scratch</title>
        <link>https://ttf248.life/en/p/stable-diffusion-zero-install-saga/</link>
        <pubDate>Thu, 13 Apr 2023 00:23:54 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/stable-diffusion-zero-install-saga/</guid>
        <description>&lt;p&gt;Domestic resources are basically all recommending &lt;strong&gt;Autumn Leaf&lt;/strong&gt;’s one-click deployment package, thinking that they are open-source projects based on &lt;code&gt;Python&lt;/code&gt;, so the deployment wouldn&amp;rsquo;t be very complicated, let’s try to start from scratch.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I was messing around with AI-generated images and specifically changed my graphics card, a beginner version of the &lt;code&gt;3060 12g&lt;/code&gt;; the venerable &lt;code&gt;960&lt;/code&gt; served its seven years and retired in glory.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The core &lt;code&gt;pytorch cuda&lt;/code&gt; installation, which I previously encountered issues with when writing Python game helper scripts (I had installed it locally before), still presented problems – the &lt;code&gt;cuda&lt;/code&gt; encryption consistently failed to activate.&lt;/p&gt;
&lt;h2 id=&#34;to-do&#34;&gt;To Do
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Replan the article structure, first introduce PyTorch, version correspondence, and how to check versions.&lt;/li&gt;
&lt;li&gt;How to create a new virtual environment from scratch locally and deploy PyTorch.&lt;/li&gt;
&lt;li&gt;Translate the manuscript from scratch: &lt;a class=&#34;link&#34; href=&#34;https://stable-diffusion-art.com/install-windows/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stable-diffusion-art.com/install-windows/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Organize reference materials&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;steps&#34;&gt;Steps
&lt;/h2&gt;&lt;p&gt;Step-by-step installation tutorials in Chinese may not be readily available. When you search in English on &lt;code&gt;Google&lt;/code&gt;, you’ll find many similar tutorials starting from scratch. We introduce the need to install &lt;code&gt;git&lt;/code&gt; and then explain the need to install &lt;code&gt;python&lt;/code&gt;. Then, you go ahead and download the repository – simply double-clicking the script gets it running.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/AUTOMATIC1111/stable-diffusion-webui&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For detailed usage and troubleshooting, consult the &lt;code&gt;issues&lt;/code&gt;, &lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki&lt;/a&gt;. I don’t know why no one explains what this repository is for. In fact, the name itself makes it pretty clear – it&amp;rsquo;s a graphical console that makes it easier to use.&lt;/p&gt;
&lt;h2 id=&#34;steps-1&#34;&gt;Steps
&lt;/h2&gt;&lt;p&gt;The repository also created an installation and startup script. It automatically identifies the current folder and checks for a &lt;code&gt;Python&lt;/code&gt; virtual environment. If one exists, it defaults to using the &lt;code&gt;python&lt;/code&gt; in the current path.&lt;/p&gt;
&lt;p&gt;For new users who are unfamiliar with the process, we recommend reviewing: &lt;a class=&#34;link&#34; href=&#34;https://stable-diffusion-art.com/install-windows/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stable-diffusion-art.com/install-windows/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;pytorch&#34;&gt;PyTorch
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/get-started/locally/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://pytorch.org/get-started/locally/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Don&amp;rsquo;t follow their steps directly to launch the script. Python uses &lt;code&gt;requirement&lt;/code&gt; files to install dependency libraries – this is just a minor issue. The core thing is your GPU version and driver version, which need to match PyTorch. Many people have discussed the corresponding relationship online; you can find it by searching.
Reference: &lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/weixin_40660408/article/details/129896700&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/weixin_40660408/article/details/129896700&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Creating a virtual environment is like creating an empty virtual environment, where you first execute the official script to install PyTorch within it.
You can use the above two scripts to check the CUDA version you need to install and also verify whether the installation was successful. - It’s not recommended to use fancy operations here. First, copy over according to the logic of the official page, and then just install it directly. Using pip to install will likely fail or won&amp;rsquo;t activate CUDA.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The key point is that don’t put random characters in your folder paths, as this could prevent PyTorch from working.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;pytorch-1&#34;&gt;PyTorch
&lt;/h2&gt;&lt;p&gt;I went through a lot of trial and error installing it repeatedly, even trying to download the official installation files and manually install them. I was hoping to upgrade to version 2.0 because the official documentation said it would be faster. However, I hadn&amp;rsquo;t used it much before, and I wasn’t sure about the impact of Python versions on it. In between, I also reviewed the official documentation, which recommended using version 3.8. This created a small conflict since I had previously used a one-click installation package that included version 3.10. Finally, I started from scratch by creating a new folder and a virtual environment to ensure that PyTorch was installed successfully. Then, I moved this installed virtual environment into the web UI folder. At that point, when running the script to install the other dependencies, all the dependency issues were resolved. Afterwards, you need to execute: &lt;code&gt;python -m pip install --upgrade --force-reinstall pip&lt;/code&gt; to fix pip. It might seem a bit strange, but I’ve spent quite a while troubleshooting this. I realized it couldn&amp;rsquo;t correctly identify my torch, so I thought it best to install it first before installing other dependency libraries to eliminate all potential interference.&lt;/p&gt;
&lt;h2 id=&#34;xformers&#34;&gt;Xformers
&lt;/h2&gt;&lt;p&gt;It is recommended to enable this, which can accelerate image generation and reduce memory usage. However, a side effect is that &lt;strong&gt;generated images tend to be less stable&lt;/strong&gt; with the same set of parameters.
&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;stable-diffusion-webui:Xformers&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/diffusers/optimization/xformers&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;huggingface optimization&lt;/a&gt;
| 100.00% | 2m 57.03s | 7440/10058 MiB | 12288/12288 MiB (100.0%) |&lt;/p&gt;
&lt;h2 id=&#34;xformers-1&#34;&gt;Xformers
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Optimization Ratio&lt;/th&gt;
&lt;th&gt;Time taken&lt;/th&gt;
&lt;th&gt;Torch active/reserved&lt;/th&gt;
&lt;th&gt;Sys VRAM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;51.02%&lt;/td&gt;
&lt;td&gt;1m 29.21s&lt;/td&gt;
&lt;td&gt;4547/7164 MiB&lt;/td&gt;
&lt;td&gt;9298/12288 MiB (75.67%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;We didn’t recommend the one-click deployment package because it contained some settings that were customized by the author and differed from the official, out-of-the-box configuration. If you&amp;rsquo;re a beginner, you might not understand why those parameters are optimal; it’s best to start with the official package first. As you use it more and more, take time to read the official documentation, and you’ll learn which parameters need adjustment.&lt;/p&gt;
&lt;h2 id=&#34;choosing-a-graphics-card&#34;&gt;Choosing a Graphics Card
&lt;/h2&gt;&lt;p&gt;Following the cryptocurrency mining boom, graphics card prices have become relatively more reasonable. When choosing between the RTX 3060 and RTX 3060 Ti for entry-level players, it’s generally recommended to opt for the version with larger VRAM – specifically the ‘12G’ models. This is because they can generate images at higher resolutions. Why do you need a higher resolution? Because you can adjust the resolution during generation, resulting in clearer and more detailed images. If you&amp;rsquo;re primarily generating smaller images, then 8GB of VRAM will suffice.&lt;/p&gt;
&lt;p&gt;There’s also the &lt;strong&gt;Super Resolution Upscaling&lt;/strong&gt; option, which enhances details and makes the image richer. This feature also requires more VRAM. Here’s a summary table of the single-precision (FP32), half-precision (FP16), and double-precision (FP64) floating-point compute capabilities for NVIDIA GeForce GTX 970, GeForce RTX 3060 Ti, GeForce RTX 3060, GeForce RTX 3080, and GeForce RTX 3080 Ti:&lt;/p&gt;
&lt;p&gt;| GeForce GTX 970 | 2014 | 3.49 | 87.2 | 0.109 |&lt;/p&gt;
&lt;h2 id=&#34;graphics-card-selection&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;graphics-card-selection-1&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;graphics-card-selection-2&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;graphics-card-selection-3&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;graphics-card-selection-4&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;p&gt;Excerpted from &lt;a class=&#34;link&#34; href=&#34;https://docs.google.com/spreadsheets/d/1Zlv4UFiciSgmJZncCujuXKHwc4BcxbjbSBg71-SdeNk/edit#gid=0&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;various graphics card performance test data&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;updates&#34;&gt;Updates
&lt;/h2&gt;&lt;p&gt;Every six months, I originally planned to revisit and refine the installation steps, and explain more basic concepts. However, I discovered that most people using AI image generation are simply adjusting parameters based on images provided by experts, or re-rendering existing images with formatting changes.&lt;/p&gt;
&lt;p&gt;I had previously attempted a project using AI to generate UI assets for mini programs, but after struggling for half a day, the results were unsatisfactory compared to just pulling resource images directly from the official mini program documentation.&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

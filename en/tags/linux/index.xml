<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Linux on Uncle Xiang&#39;s Notebook</title>
        <link>https://ttf248.life/en/tags/linux/</link>
        <description>Recent content in Linux on Uncle Xiang&#39;s Notebook</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Mon, 02 Jun 2025 20:54:02 +0800</lastBuildDate><atom:link href="https://ttf248.life/en/tags/linux/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Linux backend services handling large volumes of string data – performance is slow.</title>
        <link>https://ttf248.life/en/p/linux-backend-slow-string-processing/</link>
        <pubDate>Wed, 13 Nov 2024 19:42:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-backend-slow-string-processing/</guid>
        <description>&lt;p&gt;In the history of C++ development projects, we utilized a custom protocol for communication, which employed a two-dimensional array pattern. When processing large volumes of data, the protocol required iterating through the arrays and performing serialization operations to generate logs. Due to its low efficiency, this resulted in noticeable lag or stuttering within the system under heavy load, as reported by the business departments.&lt;/p&gt;
&lt;h2 id=&#34;problem-identification&#34;&gt;Problem Identification
&lt;/h2&gt;&lt;p&gt;When troubleshooting the issue, we first performed a performance analysis of the system and discovered that CPU utilization increased significantly when processing large amounts of data, and system response times became longer. By analyzing the system logs, we identified numerous serialization operations, which were inefficient when handling two-dimensional arrays, leading to a decline in system performance.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;pstack&lt;/code&gt; tool captured thread information for the service, pinpointing that the log threads spent most of their time processing string concatenation.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is today’s focus: different accumulation methods have significant efficiency differences. Historically, the code used the &lt;code&gt;+&lt;/code&gt; operator, which frequently creates temporary objects and is very inefficient. You know it&amp;rsquo;s bad, but you don&amp;rsquo;t know &lt;em&gt;how&lt;/em&gt; bad it is.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;demo-verification&#34;&gt;Demo Verification
&lt;/h2&gt;&lt;p&gt;Based on the project code, we extracted the business logic and wrote a simple demo to verify the efficiency issues of string concatenation. We compiled and ran it in &lt;code&gt;Release&lt;/code&gt; mode using the &lt;code&gt;vs2022&lt;/code&gt; compiler under &lt;code&gt;windows&lt;/code&gt; and the &lt;code&gt;gcc8.5&lt;/code&gt; compiler under &lt;code&gt;linux&lt;/code&gt;, comparing the efficiencies.&lt;/p&gt;
&lt;h3 id=&#34;key-point-explanation&#34;&gt;Key Point Explanation
&lt;/h3&gt;&lt;p&gt;The project utilized Method Four, and before obtaining test data, readers were encouraged to consider which method was most efficient and which was least efficient. I was quite surprised by the results.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Method 1 (&lt;code&gt;+=&lt;/code&gt; Concatenation)&lt;/strong&gt;: Directly concatenates each field using &lt;code&gt;+=&lt;/code&gt; into a string.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 2 (&lt;code&gt;std::ostringstream&lt;/code&gt; Concatenation)&lt;/strong&gt;: Uses a stream (&lt;code&gt;std::ostringstream&lt;/code&gt;) to concatenate fields, which is more efficient, especially when dealing with large amounts of data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 3 (Pre-allocated Memory &lt;code&gt;+=&lt;/code&gt; Concatenation)&lt;/strong&gt;: Pre-allocates enough memory for the string using &lt;code&gt;reserve&lt;/code&gt;, reducing the overhead of memory reallocation and improving performance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 4 (&lt;code&gt;bodys = bodys + body + &amp;quot;\n&amp;quot;&lt;/code&gt;)&lt;/strong&gt;: Creates a new temporary string object each time it concatenates, leading to decreased performance, particularly when dealing with large-scale concatenation due to repeated memory allocation and copying.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Referring to the results, we can see that the project inadvertently selected the least efficient method.&lt;/p&gt;
&lt;p&gt;Furthermore, let&amp;rsquo;s analyze the optimization efficiency of different platforms and compilers. Microsoft’s &lt;code&gt;visual studio&lt;/code&gt; consistently performs excellently in terms of string optimization, while the &lt;code&gt;gcc&lt;/code&gt; compiler has somewhat lower optimization efficiency in this area.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When running the code on different machines, direct comparison between the two datasets is meaningless; instead, we can compare the differences between the various concatenation methods.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;key-points-explanation&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Windows platform under VS2022 compiler

----------------------------------------
Data Generation Time: 0.054 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.053 seconds.
+ ostringstream Data merging took: 0.054 seconds.
+ Pre-reserved Data merging took: 0.045 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 16.108 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Linux platform under gcc8.5 compiler
----------------------------------------
Data Generation Time: 0.108 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.100 seconds.
+ ostringstream Data merging took: 0.083 seconds.
+ Pre-reserved Data merging took: 0.057 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 29.298 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;random&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;sstream&amp;gt;
#include &amp;lt;iomanip&amp;gt;

typedef std::vector&amp;lt;std::string&amp;gt; DataRow;
typedef std::vector&amp;lt;DataRow&amp;gt; DataGroup;

struct ResponsePackage
{
    std::string ErrorInfo;
    DataRow Head;
    std::string ClientId;
    std::string UUID;
    std::string MsgID;
    std::string SessionID;
    std::string ExtraInfo1;
    std::string ExtraInfo2;
    DataGroup DataBody;
};

// Generate specified length of random string
std::string generateRandomString(size_t length)
{
    const char charset[] = &amp;quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&amp;quot;;
    const size_t max_index = sizeof(charset) - 1;
    std::string random_string;
    random_string.reserve(length);

    std::random_device rd;
    std::mt19937 generator(rd());
    std::uniform_int_distribution&amp;lt;&amp;gt; distribution(0, max_index);

    for (size_t i = 0; i &amp;lt; length; ++i)
    {
        random_string += charset[distribution(generator)];
    }

    return random_string;
}

void create_large_string()
{
    // Example request package with 50 fields
    ResponsePackage requestPackage;

    requestPackage.Head = {
        &amp;quot;Field1&amp;quot;, &amp;quot;Field2&amp;quot;, &amp;quot;Field3&amp;quot;, &amp;quot;Field4&amp;quot;, &amp;quot;Field5&amp;quot;,
        &amp;quot;Field6&amp;quot;, &amp;quot;Field7&amp;quot;, &amp;quot;Field8&amp;quot;, &amp;quot;Field9&amp;quot;, &amp;quot;Field10&amp;quot;,
        &amp;quot;Field11&amp;quot;, &amp;quot;Field12&amp;quot;, &amp;quot;Field13&amp;quot;, &amp;quot;Field14&amp;quot;, &amp;quot;Field15&amp;quot;,
        &amp;quot;Field16&amp;quot;, &amp;quot;Field17&amp;quot;, &amp;quot;Field18&amp;quot;, &amp;quot;Field19&amp;quot;, &amp;quot;Field20&amp;quot;,
        &amp;quot;Field21&amp;quot;, &amp;quot;Field22&amp;quot;, &amp;quot;Field23&amp;quot;, &amp;quot;Field24&amp;quot;, &amp;quot;Field25&amp;quot;,
        &amp;quot;Field26&amp;quot;, &amp;quot;Field27&amp;quot;, &amp;quot;Field28&amp;quot;, &amp;quot;Field29&amp;quot;, &amp;quot;Field30&amp;quot;,
        &amp;quot;Field31&amp;quot;, &amp;quot;Field32&amp;quot;, &amp;quot;Field33&amp;quot;, &amp;quot;Field34&amp;quot;, &amp;quot;Field35&amp;quot;,
        &amp;quot;Field36&amp;quot;, &amp;quot;Field37&amp;quot;, &amp;quot;Field38&amp;quot;, &amp;quot;Field39&amp;quot;, &amp;quot;Field40&amp;quot;,
        &amp;quot;Field41&amp;quot;, &amp;quot;Field42&amp;quot;, &amp;quot;Field43&amp;quot;, &amp;quot;Field44&amp;quot;, &amp;quot;Field45&amp;quot;,
        &amp;quot;Field46&amp;quot;, &amp;quot;Field47&amp;quot;, &amp;quot;Field48&amp;quot;, &amp;quot;Field49&amp;quot;, &amp;quot;Field50&amp;quot;
    };

    requestPackage.ClientId = &amp;quot;ClientID&amp;quot;;
    requestPackage.UUID = &amp;quot;UUID&amp;quot;;
    requestPackage.MsgID = &amp;quot;MsgID&amp;quot;;
    requestPackage.SessionID = &amp;quot;SessionID&amp;quot;;
    requestPackage.ExtraInfo1 = &amp;quot;ExtraInfo1&amp;quot;;
    requestPackage.ExtraInfo2 = &amp;quot;ExtraInfo2&amp;quot;;

    // Start timing for data generation
    auto start_gen = std::chrono::high_resolution_clock::now();

    // Generate 10,000 rows of data, each with 50 fields
    for (size_t i = 0; i &amp;lt; 10000; ++i)
    {
        DataRow dataRow(50, &amp;quot;This is a test string&amp;quot;);
        requestPackage.DataBody.push_back(dataRow);
    }

    // End timing for data generation
    auto end_gen = std::chrono::high_resolution_clock::now();
    std::chrono::duration&amp;lt;double&amp;gt; duration_gen = end_gen - start_gen;

    // Display result generation time
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Generation Time: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_gen.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    // Data merging using different methods
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Performance:\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    {
        // Method 1: Using &#39;+=&#39; string concatenation
        auto start_merge = std::chrono::high_resolution_

```markdown
## Complete Code
{
        // Method 2: Using ostringstream
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::ostringstream bodys;
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::ostringstream body;
            body &amp;lt;&amp;lt; &amp;quot;This is a test string&amp;quot;;
            for (auto&amp;amp; item : vec)
            {
                body &amp;lt;&amp;lt; item &amp;lt;&amp;lt; &amp;quot; &amp;quot;;
            }
            bodys &amp;lt;&amp;lt; body.str() &amp;lt;&amp;lt; &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ ostringstream Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 3: Pre-allocated memory
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys;
        bodys.reserve(1000 * 50 * 20); // Pre-allocate enough memory
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            body.reserve(50 * 20); // Pre-allocate memory for each row
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Pre-reserved Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 4: Using &#39;bodys = bodys + body + &amp;quot;\n&amp;quot;&#39;
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys(&amp;quot;&amp;quot;);
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            for (auto&amp;amp; item : vec)
            {
                body = body + item + &amp;quot; &amp;quot;; // Note the use of &#39;body = body + item&#39;
            }
            bodys = bodys + body + &amp;quot;\n&amp;quot;; // Again, using &#39;bodys = bodys + body&#39;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (bodys = bodys + body + \&amp;quot;\\n\&amp;quot;) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Complete.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;
}

int main()
{
    try
    {
        create_large_string();
    }
    catch (const std::exception&amp;amp; e)
    {
        std::cerr &amp;lt;&amp;lt; &amp;quot;Caught exception: &amp;quot; &amp;lt;&amp;lt; e.what() &amp;lt;&amp;lt; std::endl;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\nProgram finished.\n&amp;quot;;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Upgrading the GCC version caused program crashes: hidden issues due to code non-compliance.</title>
        <link>https://ttf248.life/en/p/gcc-upgrade-causes-program-crash-code-irregularities/</link>
        <pubDate>Sun, 10 Mar 2024 23:19:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/gcc-upgrade-causes-program-crash-code-irregularities/</guid>
        <description>&lt;p&gt;In the same business code scenario, the program compiled and ran normally in a CentOS 7 environment. However, when switching to CentOS 8 and using an updated version of GCC for compilation, the program crashed. It’s worth noting that the issue only occurs in &lt;strong&gt;Release mode&lt;/strong&gt;, while &lt;strong&gt;Debug mode&lt;/strong&gt; does not exhibit any problems. This is the first time we&amp;rsquo;ve encountered a situation like this; after three days of investigation, we finally identified the root cause.&lt;/p&gt;
&lt;h3 id=&#34;problem-identification&#34;&gt;Problem Identification
&lt;/h3&gt;&lt;p&gt;After investigation, the root cause of the issue was &lt;strong&gt;the function lacked a return value&lt;/strong&gt;. In Release mode, new versions of GCC perform more optimizations, which caused an unknown logic to occur within the function that originally did not have an explicit return value during execution, ultimately triggering a crash. Our conclusion is that &lt;strong&gt;compiler warnings should not be ignored, especially in legacy projects where some warnings may be dismissed, but it’s also important to avoid suppressing all warnings.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;environment-details&#34;&gt;Environment Details
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CentOS 7 GCC Version:&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CentOS 8 GCC Version:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;crash-phenomena&#34;&gt;Crash Phenomena
&lt;/h3&gt;&lt;p&gt;When analyzing the stack information for program crashes, we observed the following stack details:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[New LWP 1385902]
[Thread debugging using libthread_db enabled]
Using host libthread_db library &amp;quot;/lib64/libthread_db.so.1&amp;quot;.
Core was generated by `./pstack_main`.
Program terminated with signal SIGSEGV, Segmentation fault.
#0  0x00007ffe894b4420 in ?? ()
(gdb) bt
#0  0x00007ffe894b4420 in ?? ()
#1  0x00000000004008e9 in main ()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This stack doesn&amp;rsquo;t appear intuitive; the crash function’s stack information shows a &lt;code&gt;??&lt;/code&gt;, which makes troubleshooting even more complex.&lt;/p&gt;
&lt;h3 id=&#34;code-example&#34;&gt;Code Example
&lt;/h3&gt;&lt;p&gt;To better understand the issue, here is a minimal code example that reproduces the crash:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;map&amp;gt;

int test() {
    std::cout &amp;lt;&amp;lt; &amp;quot;1&amp;quot; &amp;lt;&amp;lt; std::endl;
}

int main() {
    test();
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;test()&lt;/code&gt; function in this code clearly does not explicitly return a value, and its return type is &lt;code&gt;int&lt;/code&gt;. According to the C++ standard, when a function is declared as an &lt;code&gt;int&lt;/code&gt; type, it must have a return value, otherwise it may lead to undefined behavior.&lt;/p&gt;
&lt;h3 id=&#34;compilation-warning&#34;&gt;Compilation Warning
&lt;/h3&gt;&lt;p&gt;In our project, the CMake script suppresses many compile-time warnings, including the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;/root/pstack/main.cpp: In function ‘int test()’:
/root/pstack/main.cpp:7:1: warning: no return statement in function returning non-void [-Wreturn-type]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This warning indicates that the &lt;code&gt;test()&lt;/code&gt; function does not return a value, which is the root cause of the problem. Newer versions of GCC (such as 8.5.0) may make unstable optimizations with this undefined behavior when optimizing code, potentially leading to program crashes.&lt;/p&gt;
&lt;h3 id=&#34;assembly-code-differences&#34;&gt;Assembly Code Differences
&lt;/h3&gt;&lt;p&gt;To explain the differences in GCC compiler optimization behavior, we compared assembly code generated by different versions of GCC:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GCC 4.8.5 Generated Assembly Code:&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The assembly code is relatively verbose and includes handling logic for standard output streams (such as &lt;code&gt;std::cout&lt;/code&gt;). This indicates that the compiler performed more conservative optimizations, not optimizing excessively for the missing return value issue in the &lt;code&gt;test()&lt;/code&gt; function, possibly to avoid a crash.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GCC 8.5.0 Generated Assembly Code:&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The new version of GCC performed more optimizations, reducing the code volume. However, this optimization may have resulted in unpredictable behavior when executing functions without returning values, leading to program crashes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h3&gt;&lt;p&gt;Through this troubleshooting process, we deeply realized that in C++, &lt;strong&gt;function return values must be explicit&lt;/strong&gt;, particularly when a function is declared as &lt;code&gt;int&lt;/code&gt;, a return value must be provided. When upgrading from older versions of compilers to newer versions of GCC, more optimization and stricter warning mechanisms may be encountered. Therefore, we recommend not &lt;strong&gt;disabling all warnings&lt;/strong&gt; during compilation, but rather selectively addressing them, especially common issues such as function return values and type matching.
Ultimately, by adding a return value to the &lt;code&gt;test()&lt;/code&gt; function, the problem was resolved, and the program returned to normal operation.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Linux System Benchmark Test</title>
        <link>https://ttf248.life/en/p/linux-system-benchmark-test/</link>
        <pubDate>Tue, 09 Jan 2024 10:56:23 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-system-benchmark-test/</guid>
        <description>&lt;p&gt;Windows platform has RuMaster (Entertainment Master), which isn&amp;rsquo;t known for highly accurate data, but it’s still useful as a reference. Of course, there are other professional benchmarking software options available. When it comes to Linux systems, there haven’t seemed to be any particularly suitable benchmarking software found.&lt;/p&gt;
&lt;p&gt;Sysbench is a versatile benchmark testing tool that can be used to test CPU, memory, file I/O, thread performance, and more. You can use Sysbench to execute various performance testing tasks.&lt;/p&gt;
&lt;p&gt;I currently have three machines available for testing: the Mechanical Artist mini laptop, a local small host machine, an Alibaba Cloud Dev development cloud server, and a Huawei Cloud Dev server.&lt;/p&gt;
&lt;h2 id=&#34;installing-sysbench&#34;&gt;Installing Sysbench
&lt;/h2&gt;&lt;p&gt;On most Linux distributions, you can use the package manager to install Sysbench. For example, on CentOS 8, you can use the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo dnf install sysbench
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;sysbench-usage-examples&#34;&gt;Sysbench Usage Examples
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Testing CPU performance: &lt;code&gt;sysbench --test=cpu run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Testing memory read performance: &lt;code&gt;sysbench --test=memory run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Testing file I/O performance:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sysbench --test=fileio --file-test-mode=rndrw prepare
sysbench --test=fileio --file-test-mode=rndrw run
sysbench --test=fileio --file-test-mode=rndrw cleanup
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Testing multi-threaded performance: &lt;code&gt;sysbench --test=threads --num-threads=4 run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Testing MySQL database performance (requires adjusting the maximum connection number):&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword --oltp-table-size=1000000 prepare
sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword --max-time=60 --oltp-read-only=off --oltp-test-mode=complex --max-requests=0 run
sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword cleanup
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;score-report&#34;&gt;Score Report
&lt;/h2&gt;&lt;meta http-equiv=&#34;Content-Type&#34; content=&#34;text/html; charset=utf-8&#34;&gt;&lt;link type=&#34;text/css&#34; rel=&#34;stylesheet&#34; href=&#34;resources/sheet.css&#34; &gt;
&lt;h2 id=&#34;run-score-report&#34;&gt;Run Score Report
&lt;/h2&gt;&lt;style type=&#34;text/css&#34;&gt;.ritz .waffle a { color: inherit; }.ritz .waffle .s0{background-color:#ffffff;text-align:left;color:#000000;font-family:&#39;Arial&#39;;font-size:10pt;vertical-align:bottom;white-space:nowrap;direction:ltr;padding:2px 3px 2px 3px;}&lt;/style&gt;&lt;div class=&#34;ritz grid-container&#34; dir=&#34;ltr&#34;&gt;&lt;table class=&#34;waffle&#34; cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th class=&#34;row-header freezebar-origin-ltr&#34;&gt;&lt;/th&gt;&lt;th id=&#34;0C0&#34; style=&#34;width:100px;&#34; class=&#34;column-headers-background&#34;&gt;A&lt;/th&gt;&lt;th id=&#34;0C1&#34; style=&#34;width:421px;&#34; class=&#34;column-headers-background&#34;&gt;B&lt;/th&gt;&lt;th id=&#34;0C2&#34; style=&#34;width:398px;&#34; class=&#34;column-headers-background&#34;&gt;C&lt;/th&gt;&lt;th id=&#34;0C3&#34; style=&#34;width:422px;&#34; class=&#34;column-headers-background&#34;&gt;D&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R0&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;1&lt;/div&gt;&lt;/th&gt;&lt;td&gt;&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Local Technician&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Alibaba Cloud&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Huawei Cloud&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R1&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;2&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Configuration&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Information&lt;br&gt;  Operating System              Ubuntu 23.04&lt;br&gt;  Kernel                        Linux 6.2.0-36-generic x86_64&lt;br&gt;  Model                         Machenike Machenike DT Computer&lt;br&gt;  Motherboard                   Machenike Machenike DT Computer&lt;br&gt;  BIOS                          American Megatrends International, LLC.&lt;br&gt;DB19V012&lt;br&gt;&lt;br&gt;CPU Information&lt;br&gt;  Name                          Intel Core i7-12650H&lt;br&gt;  Topology                      1 Processor, 10 Cores, 16 Threads&lt;br&gt;  Identifier                    GenuineIntel Family 6 Model 154 Stepping 3&lt;br&gt;  Base Frequency                4.60 GHz&lt;br&gt;  L1 Instruction Cache          32.0 KB x 8&lt;br&gt;  L1 Data Cache                 48.0 KB x 8&lt;br&gt;  L2 Cache                      1.25 MB x 2&lt;br&gt;  L3 Cache                      24.0 MB&lt;br&gt;&lt;br&gt;Memory Information&lt;br&gt;  Size                          62.6 GB&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Information&lt;br&gt;  Operating System              CentOS Stream 8&lt;br&gt;  Kernel                        Linux 4.18.0-513.el8.x86_64 x86_64&lt;br&gt;  Model                         Alibaba Cloud Alibaba Cloud ECS&lt;br&gt;  Motherboard                   N/A&lt;br&gt;  BIOS                          SeaBIOS 449e491&lt;br&gt;&lt;br&gt;CPU Information&lt;br&gt;  Name                          Intel(R) Xeon(R) Platinum&lt;br&gt;  Topology                      1 Processor, 1 Core, 2 Threads&lt;br&gt;  Identifier                    GenuineIntel Family 6 Model 85 Stepping 4&lt;br&gt;  Base Frequency                2.50 GHz&lt;br&gt;  L1 Instruction Cache          32.0 KB&lt;br&gt;  L1 Data Cache                 32.0 KB&lt;br&gt;  L2 Cache                      1.00 MB&lt;br&gt;  L3 Cache                      33.0 MB&lt;br&gt;&lt;br&gt;Memory Information&lt;br&gt;  Size                          1.65 GB&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Information&lt;br&gt;  Operating System              Ubuntu 22.04.1 LTS&lt;br&gt;  Kernel                        Linux 5.15.0-60-generic x86_64&lt;br&gt;  Model                         OpenStack Foundation OpenStack Nova - 64 GB
&lt;tr&gt;&lt;th id=&#34;0R2&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;3&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;CPU&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Benchmark Data Report
system LuaJIT 2.1.0-beta3&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  4032.48&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0004s&lt;br&gt;    total number of events:              40330&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.25&lt;br&gt;         avg:                                    0.25&lt;br&gt;         max:                                    0.73&lt;br&gt;         95th percentile:                        0.25&lt;br&gt;         sum:                                 9997.55&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           40330.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9975/0.00&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  1062.51&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0008s&lt;br&gt;    total number of events:              10628&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.91&lt;br&gt;         avg:                                    0.94&lt;br&gt;         max:                                   22.84&lt;br&gt;         95th percentile:                        1.06&lt;br&gt;         sum:                                 9993.46&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           10628.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9935/0.00&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  1125.56&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0005s&lt;br&gt;    total number of events:              11258&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.86&lt;br&gt;         avg:                                    0.89&lt;br&gt;         max:                                    1.70&lt;br&gt;         95th percentile:                        0.99&lt;br&gt;         sum:                                 9995.40&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           11258.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9954/0.00&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 101993199 (10198146.52 per second)&lt;br&gt;&lt;br&gt;99602.73 MiB transferred (9959.13 MiB/sec)&amp;lt; - Benchmark Data Report
system LuaJIT 2.1.0-beta3&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  4032.48&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0004s&lt;br&gt;    total number of events:              40330&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.25&lt;br&gt;         avg:                                    0.25&lt;br&gt;         max:                                    0.73&lt;br&gt;         95th percentile:                        0.25&lt;br&gt;         sum:                                 9997.55&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           40330.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9975/0.00&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  1062.51&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0008s&lt;br&gt;    total number of events:              10628&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.91&lt;br&gt;         avg:                                    0.94&lt;br&gt;         max:                                   22.84&lt;br&gt;         95th percentile:                        1.06&lt;br&gt;         sum:                                 9993.46&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           10628.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9935/0.00&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  1125.56&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0005s&lt;br&gt;    total number of events:              11258&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.86&lt;br&gt;         avg:                                    0.89&lt;br&gt;         max:                                    1.70&lt;br&gt;         95th percentile:                        0.99&lt;br&gt;         sum:                                 9995.40&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           11258.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9954/0.00&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 101993199 (10198146.52 per second)&lt;br&gt;&lt;br&gt;99602.73 MiB transferred (9959.13 MiB/sec)&amp;lt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run Score Reports
random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 48418803 (4841004.79 per second)&lt;br&gt;&lt;br&gt;47283.99 MiB transferred (4727.54 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              48418803&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                   25.26&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4578.95&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           48418803.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.5789/0.00&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Machine Learning&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Neural Networks - Run Score Reports
random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt; block size: 1KiB&lt;br&gt; total size: 102400MiB&lt;br&gt; operation: write&lt;br&gt; scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 48418803 (4841004.79 per second)&lt;br&gt;&lt;br&gt;47283.99 MiB transferred (4727.54 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt; total time:                          10.0001s&lt;br&gt; total number of events:              48418803&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt; min:                                    0.00&lt;br&gt; avg:                                    0.00&lt;br&gt; max:                                   25.26&lt;br&gt; 95th percentile:                        0.00&lt;br&gt; sum:                                 4578.95&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt; events (avg/stddev):           48418803.0000/0.00&lt;br&gt; execution time (avg/stddev):   4.5789/0.00&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Machine Learning&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Neural Networks&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;score-report-data&#34;&gt;Score Report Data
&lt;/h2&gt;&lt;p&gt;enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      1593.12&lt;br&gt;    writes/s:                     1062.08&lt;br&gt;    fsyncs/s:                     3406.64&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  24.89&lt;br&gt;    written, MiB/s:               16.60&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0164s&lt;br&gt;    total number of events:              60600&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.16&lt;br&gt;         max:                                   31.32&lt;br&gt;         95th percentile:                        0.54&lt;br&gt;         sum:                                 9956.30&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           60600.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9563/0.00&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;2147483648 bytes written in 18.29 seconds (111.98 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      1665.88&lt;br&gt;    writes/s:                     1110.59&lt;br&gt;    fsyncs/s:                     3563.77&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  26.03&lt;br&gt;    written, MiB/s:               17.35&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0112s&lt;br&gt;    total number of events:              63355&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.16&lt;br&gt;         max:                                  205.01&lt;br&gt;         95th percentile:                        0.78&lt;br&gt;         sum:                                 9972.64&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           63355.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9726/0.00&lt;/p&gt;
&lt;hr&gt;
&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R5&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;6&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Multi-threaded&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0002s&lt;br&gt;    total number of events:              197956&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0
&lt;h2 id=&#34;score-report-1&#34;&gt;Score Report
&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;sum:                                40050.41&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;Threads fairness:&amp;lt;br&amp;gt;    events (avg/stddev):           4590.0000/94.36&amp;lt;br&amp;gt;    execution time (avg/stddev):   10.0126/0.00

Running the test with following options:
Number of threads: 4
Initializing random number generator from current time&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;
Initializing worker threads...&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;
Threads started!&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;
General statistics:
    total time:                          10.0004s
    total number of events:              28536&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;
Latency (ms):
         min:                                    0.23
         avg:                                    1.40
         max:                                    3.56
         95th percentile:                        1.47
         sum:                                39975.16&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;
Threads fairness:&amp;lt;br&amp;gt;    events (avg/stddev):           7134.0000/39.87
    execution time (avg/stddev):   9.9938/0.01
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;Whether &lt;code&gt;ChatGPT&lt;/code&gt; is a good thing or not, the table above could not be arranged according to the previously mastered &lt;code&gt;Markdown&lt;/code&gt;, and it was not made into a table to display, which would result in a very poor effect. Customizing the theme limited the maximum page width, and a series of page configurations were adjusted accordingly, changing the width to percentage limits.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A simple method is to use tools like TablesGenerator to generate HTML tables (content complexity is not suitable).&lt;/li&gt;
&lt;li&gt;Or write it using Google Docs online and then download and save it as an HTML document, directly copy it into the blog (simple and direct, ultimately adopted).
Ensure that the config configuration is enabled with unsafe configuration items, and independently configure the page width.
In Hugo, you can set the width of a page individually. This can be achieved by adding a custom parameter in the page&amp;rsquo;s Front Matter.  Here’s an example:&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;In your Markdown page&amp;rsquo;s Front Matter section (usually at the beginning of the file), add a custom parameter such as &lt;code&gt;custom_width&lt;/code&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;---
title: &amp;quot;My Page&amp;quot;
date: 2024-01-09
custom_width: &amp;quot;800px&amp;quot;  # Set width to 800 pixels
---

Content...
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;In your Hugo theme, find or create the corresponding single page template file (e.g., &lt;code&gt;layouts/_default/single.html&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;In the single page template, check if there is a &lt;code&gt;custom_width&lt;/code&gt; parameter in the Front Matter and apply it to the appropriate HTML elements, such as &lt;code&gt;div&lt;/code&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;{{ define &amp;quot;main&amp;quot; }}
  &amp;lt;div style=&amp;quot;max-width: {{ with .Params.custom_width }}{{ . }}{{ else }}100%{{ end }}; margin: 0 auto;&amp;quot;&amp;gt;
    {{ .Content }}
  &amp;lt;/div&amp;gt;
{{ end }}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, we used inline styles (the &lt;code&gt;style&lt;/code&gt; attribute) to set the &lt;code&gt;max-width&lt;/code&gt; property for the &lt;code&gt;div&lt;/code&gt; element when no &lt;code&gt;custom_width&lt;/code&gt; parameter is specified, defaulting the width to 100%. &lt;code&gt;margin: 0 auto;&lt;/code&gt; centers the &lt;code&gt;div&lt;/code&gt; element.&lt;/p&gt;
&lt;p&gt;Please note that in actual applications, you may need to adjust this example based on your theme structure and CSS styling details. Ensure that when adjusting styles, you maintain consistency and readability with the theme.&lt;/p&gt;
&lt;p&gt;Due to the slight difference in the enabled theme, the site&amp;rsquo;s custom &lt;code&gt;CSS&lt;/code&gt; configuration was finally adjusted.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Docker Basics, Intermediate, and Advanced</title>
        <link>https://ttf248.life/en/p/docker-two-three-things/</link>
        <pubDate>Thu, 21 Jan 2021 09:26:07 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/docker-two-three-things/</guid>
        <description>&lt;p&gt;Having worked with CentOS for many years, content may not apply to macOS or Ubuntu users in some cases.&lt;/p&gt;
&lt;p&gt;You can refer to the documentation from Tsinghua University for installation guidance: &lt;a class=&#34;link&#34; href=&#34;https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation
&lt;/h2&gt;&lt;p&gt;Due to unknown mysterious forces, domestic Docker installation is recommended to set the cloud vendor&amp;rsquo;s repository address. Here we recommend using &lt;strong&gt;Alibaba Cloud&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;set-repository-source-address&#34;&gt;Set Repository Source Address
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum install yum-utils device-mapper-persistent-data lvm2 &amp;amp;&amp;amp; \
sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;deploy-the-latest-version&#34;&gt;Deploy the Latest Version
&lt;/h3&gt;&lt;p&gt;Docker is a commonly used background service, we recommend setting it to start on boot. The following command applies to CentOS 7:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo yum install -y docker-ce docker-ce-cli containerd.io &amp;amp;&amp;amp; systemctl enable --now docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;deploying-a-specific-version&#34;&gt;Deploying a Specific Version
&lt;/h3&gt;&lt;p&gt;The releases of &lt;code&gt;kubernetes&lt;/code&gt; and &lt;code&gt;docker&lt;/code&gt; are not fully synchronized. If you need to deploy &lt;code&gt;kubernetes&lt;/code&gt; subsequently, refer to the &lt;code&gt;kubernetes&lt;/code&gt; deployment instructions and install a specific version of &lt;code&gt;docker&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum list docker-ce --showduplicates | sort -r
sudo yum install -y docker-ce-18.09.2-3.el7 docker-ce-cli-18.09.2-3.el7 containerd.io-18.09.2-3.el7 &amp;amp;&amp;amp; systemctl enable --now docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;adding-docker-permissions-for-regular-users&#34;&gt;Adding Docker Permissions for Regular Users
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo usermod -aG docker ${USER}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;uninstall&#34;&gt;Uninstall
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo yum erase -y docker-ce docker-ce-cli containerd.io
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;everyday-use&#34;&gt;Everyday Use
&lt;/h2&gt;&lt;h3 id=&#34;mirror-acceleration&#34;&gt;Mirror Acceleration
&lt;/h3&gt;&lt;p&gt;There’s still an unknown mysterious force that causes slow image pulls. At this time, domestic cloud vendors have emerged and provided many acceleration services, which are still recommended – &lt;strong&gt;Alibaba Cloud&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The acceleration addresses can be managed by you registering an Alibaba Cloud account; this service is free. Alibaba Cloud also offers a free image build service.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cat &amp;gt; /etc/docker/daemon.json &amp;lt;&amp;lt;EOF
{
  &amp;quot;registry-mirrors&amp;quot;: [
    &amp;quot;https://docker.nju.edu.cn&amp;quot;,
    &amp;quot;https://mirror.baidubce.com&amp;quot;,
    &amp;quot;https://docker.m.daocloud.io&amp;quot;,
    &amp;quot;https://docker.mirrors.sjtug.sjtu.edu.cn&amp;quot;
  ]
}
EOF
systemctl daemon-reload &amp;amp;&amp;amp; \
systemctl restart docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;recommended-control-panels&#34;&gt;Recommended Control Panels
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker volume create portainer_data &amp;amp;&amp;amp; \
docker run -d --name=portainer --restart=always -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:2.20.3-alpine
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;frequently-used-image-pull-list&#34;&gt;Frequently Used Image Pull List
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker pull rancher/rancher:stable &amp;amp;&amp;amp; docker pull portainer/portainer-ce:2.0.1 &amp;amp;&amp;amp; \
docker pull centos:7 &amp;amp;&amp;amp; docker pull ubuntu:20.04 &amp;amp;&amp;amp; docker pull ubuntu:18.04 &amp;amp;&amp;amp; \
docker pull redis:5 &amp;amp;&amp;amp; docker pull redis:6 &amp;amp;&amp;amp; \
docker pull alpine:3.11 &amp;amp;&amp;amp; docker pull busybox:1.32 &amp;amp;&amp;amp; \
docker pull rabbitmq:3.7-management &amp;amp;&amp;amp; \
docker pull mariadb:10.2 &amp;amp;&amp;amp; \
docker pull nginx:1.18 &amp;amp;&amp;amp; docker pull nginx:1.19 &amp;amp;&amp;amp; \
docker pull mysql:5.6 &amp;amp;&amp;amp; docker pull mysql:8 &amp;amp;&amp;amp; \
docker pull elasticsearch:6.8.11 &amp;amp;&amp;amp; docker pull logstash:6.8.11 &amp;amp;&amp;amp; docker pull kibana:6.8.11 &amp;amp;&amp;amp; \
docker pull zookeeper:3.4 &amp;amp;&amp;amp; \
docker pull influxdb:1.7 &amp;amp;&amp;amp; docker pull grafana/grafana:7.3.1 &amp;amp;&amp;amp; \
docker pull percona:8 &amp;amp;&amp;amp; docker pull percona:5.6 &amp;amp;&amp;amp; \
docker pull cloverzrg/frps-docker:0.34.3 &amp;amp;&amp;amp; docker pull cloverzrg/frpc-docker:0.34.3
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;common-command-combinations&#34;&gt;Common Command Combinations
&lt;/h3&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.docker.com/engine/reference/commandline/docker/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://docs.docker.com/engine/reference/commandline/docker/&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;View container running status, append the &lt;code&gt;format&lt;/code&gt; parameter to view detailed container information, and ignore image information.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker ps --format &amp;quot;{{.Names}}: {{.Ports}}: {{.Size}}&amp;quot;
#portainer: 0.0.0.0:8000-&amp;gt;8000/tcp, 0.0.0.0:9000-&amp;gt;9000/tcp: 0B (virtual 172MB)
#influxdb: 0.0.0.0:8086-&amp;gt;8086/tcp: 183B (virtual 311MB)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;Stop all containers with one command&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker stop $(docker ps -a -q)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Delete all images with one command&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker rmi $(docker images -a -q)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;Export image&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker save &amp;lt;IMAGE NAME&amp;gt;:&amp;lt;IMAGE TAG&amp;gt; &amp;gt; XXX.tar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Export image and compress it&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker save &amp;lt;IMAGE NAME&amp;gt;:&amp;lt;IMAGE TAG&amp;gt; | gzip &amp;gt; XXX.tar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Import image&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker load -i XXX.tar
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Linux Setup JMeter Test Environment</title>
        <link>https://ttf248.life/en/p/linux-setup-jmeter-testing-environment/</link>
        <pubDate>Tue, 22 Dec 2020 10:12:50 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-setup-jmeter-testing-environment/</guid>
        <description>&lt;p&gt;The author has a strong interest in hardware and used JMeter to conduct load testing, documenting the process of deploying JMeter, InfluxDB, and Grafana on CentOS 7. They shared installation and command usage for JMeter, InfluxDB’s features and Docker installation method, as well as a simple deployment and configuration for Grafana. They summarized experience and references related to high-performance programming patterns.&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background
&lt;/h2&gt;&lt;p&gt;As widely known, I have a very strong interest in hardware. By chance, the test team was using &lt;code&gt;JMeter&lt;/code&gt; to perform load tests and discovered that performance wasn&amp;rsquo;t improving. As a curious individual, I decisively took action to see how the company conducted its testing. There’s also a small story: at some point in the distant past, I read a post on OpenChina about how to create more impressive-looking performance test graphs – after observing &lt;code&gt;Windows&lt;/code&gt; versions execute tests and achieving visualized &lt;code&gt;TPS&lt;/code&gt; data display, what&amp;rsquo;s the use of configuring a web panel?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Thinking is all well and good, but you have to try it yourself to understand.
Don’t use GUI mode for load testing! only for Test creation and Test debugging.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;background-1&#34;&gt;Background
&lt;/h2&gt;&lt;p&gt;Officially, it’s recommended to obtain test reports via the command line and display them using a GUI, which introduces data errors.  I don&amp;rsquo;t have deep knowledge of JMeter – at least I found a reason to tinker with a &lt;code&gt;Linux&lt;/code&gt; version console panel. The openchinese post’s core component deployment isn’t friendly; you need to follow their WeChat channel to download the required files, so as a young millennial, of course I used &lt;code&gt;Docker&lt;/code&gt; instead. Basically, my server is located domestically, and accessing the overseas source addresses is very slow – at least using an image service, Alibaba Cloud has a free acceleration.&lt;/p&gt;
&lt;p&gt;Regarding &lt;code&gt;docker&lt;/code&gt; installation and deployment, this will not be elaborated on here; please refer to previous articles for recommendations.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;The following content focuses on two main areas: setting up the basic test environment components and a simple explanation of each component.&lt;/p&gt;
&lt;h2 id=&#34;jmeter&#34;&gt;JMeter
&lt;/h2&gt;&lt;p&gt;Apache JMeter is a Java-based load testing tool developed by the Apache Software Foundation. It’s used to perform stress tests on software, initially designed for web application testing but later expanded to other testing domains. It can be used to test static and dynamic resources, such as static files, Java microservices, CGI scripts, Java objects, databases, FTP servers, etc. JMeter can simulate massive loads from various stress categories to test the strength of servers, networks, or objects and analyze overall performance. Furthermore, JMeter can perform functional/regression testing on applications by creating scripts with assertions to verify that your program returns the expected results. To maximize flexibility, JMeter allows using regular expressions to create assertions.&lt;/p&gt;
&lt;p&gt;Apache jmeter can be used to perform performance tests on static and dynamic resources (files, Servlets, Perl scripts, Java objects, databases and queries, FTP servers, etc.). It can be used to simulate heavy loads on servers, networks, or objects to test their strength or analyze overall performance under different stress types. You can use it for performance graphing or large concurrent load testing of your server/script/object.&lt;/p&gt;
&lt;h3 id=&#34;jmeter-deployment-on-centos7&#34;&gt;Jmeter Deployment on CentOS7
&lt;/h3&gt;&lt;p&gt;Install the &lt;code&gt;JDK&lt;/code&gt; runtime environment, download the &lt;code&gt;Jmeter&lt;/code&gt; installation package:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum install java-1.8.0-openjdk -y &amp;amp;&amp;amp; \
wget https://mirrors.bfsu.edu.cn/apache//jmeter/binaries/apache-jmeter-5.4.tgz &amp;amp;&amp;amp; tar -xf apache-jmeter-5.4.tgz
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Configure environment variables:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export JMETER_HOME=$HOME/jmeter/apache-jmeter-5.4
export PATH=$JMETER_HOME/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;jmeter-commands&#34;&gt;JMeter Commands
&lt;/h3&gt;&lt;p&gt;Finally, it will be connected to the &lt;code&gt;Grafana&lt;/code&gt; dashboard, and you don&amp;rsquo;t need to input the &lt;code&gt;-l&lt;/code&gt; parameter to observe data in the &lt;code&gt;web&lt;/code&gt; console.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;jmeter -n -t /tmp/order-500-10s.jmx -l /tmp/jmeter-order-report-20200109/order-500-10s.jtl
# Generally, don&#39;t use test results and test reports to simplify the command
jmeter -n -t /tmp/order-500-10s.jmx
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;influxdb&#34;&gt;InfluxDB
&lt;/h2&gt;&lt;p&gt;InfluxDB is an open-source distributed time series database written in Go. It requires no external dependencies. The database is now primarily used for storing large volumes of timestamped data such as DevOps monitoring data, app metrics, IoT sensor data, and real-time analytics data.&lt;/p&gt;
&lt;h3 id=&#34;influxdb-features&#34;&gt;InfluxDB Features
&lt;/h3&gt;&lt;p&gt;InfluxDB’s features can be summarized into the following 9 aspects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Schema-less (Schemaless):&lt;/strong&gt; Can contain an arbitrary number of columns;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Metric Retention Time Setting:&lt;/strong&gt;  Allows setting the retention time for metrics;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Support for Time-Related Functions:&lt;/strong&gt; Supports functions related to time (such as min, max, sum, count, mean, median, etc.) for convenient statistical analysis;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Storage Policy Support:&lt;/strong&gt; Can be used for data deletion and modification (InfluxDB does not provide methods for deleting or modifying data);&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Continuous Query Support:&lt;/strong&gt;  Automatically scheduled sets of statements that run within the database, combined with storage policies to reduce InfluxDB’s system footprint;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Native HTTP Support:&lt;/strong&gt; Built-in HTTP API;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Support for Similar SQL Syntax:&lt;/strong&gt; Supports a syntax similar to SQL;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Support for Setting Data Replica Count in Clusters:&lt;/strong&gt; Allows setting the number of replicas for data within clusters;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Support for Periodic Sampling of Data:&lt;/strong&gt;  Writes data to another measurement, facilitating granular data storage.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;influxdb-docker-installation&#34;&gt;InfluxDB Docker Installation
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mkdir influxdb &amp;amp;&amp;amp; cd influxdb &amp;amp;&amp;amp; \
docker run -p 8086:8086 -d --name influxdb -v $PWD:/var/lib/influxdb influxdb:1.7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;docker exec -it influxdb /bin/bash&lt;/code&gt; enters the container, executes commands, and manually creates a database&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;root@bce0a55bbc72:/# influx
Connected to http://localhost:8086 version 1.7.10
InfluxDB shell version: 1.7.10
&amp;gt; Execute commands in the interactive shell
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;influxdb-database-and-user-creation&#34;&gt;InfluxDB Database and User Creation
&lt;/h3&gt;&lt;p&gt;Create database: &lt;code&gt;create database jmeter_t2&lt;/code&gt;
View databases: &lt;code&gt;show databases&lt;/code&gt;
Switch to database: &lt;code&gt;use jmeter_t2&lt;/code&gt;
Create user: &lt;code&gt;create user &amp;quot;admin&amp;quot; with password &#39;admin&#39; with all privileges&lt;/code&gt;
View users: &lt;code&gt;show users&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;&amp;gt; show users
user  admin
----  -----
admin true
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the user permissions for &lt;code&gt;admin&lt;/code&gt; are displayed as &lt;code&gt;true&lt;/code&gt;, the database setup is complete.&lt;/p&gt;
&lt;h2 id=&#34;grafana&#34;&gt;Grafana
&lt;/h2&gt;&lt;p&gt;When writing test cases, it was found that the chart visualization effect is not very necessary; the &lt;code&gt;tps&lt;/code&gt; data from the interface can be observed when executed in the command line, and more importantly, we wanted to know the internal timing of the program.&lt;/p&gt;
&lt;p&gt;A simple deployment of the &lt;code&gt;grafana&lt;/code&gt; console panel, importing a configuration file to connect with &lt;code&gt;InfluxDB&lt;/code&gt;, was performed. The console supports filtering test results through tags; generally, only one &lt;code&gt;InfluxDB&lt;/code&gt; database needs to be configured:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Application Name&lt;/li&gt;
&lt;li&gt;Test Case Name&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/linux-setup-jmeter-testing-environment/Snipaste_2021-03-09_19-44-22.png&#34;
	width=&#34;861&#34;
	height=&#34;357&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;grafana&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;241&#34;
		data-flex-basis=&#34;578px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -d --name=grafana -p 3000:3000 grafana/grafana:7.3.1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Due to the sampling interval in the web version, the calculated &lt;code&gt;TPS&lt;/code&gt; and related values do not match the aggregated report from &lt;code&gt;JMeter&lt;/code&gt;.  Refer to this link for reference: &lt;a class=&#34;link&#34; href=&#34;https://www.vinsguru.com/jmeter-real-time-results-influxdb-grafana/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.vinsguru.com/jmeter-real-time-results-influxdb-grafana/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The documentation also describes how to customize the &lt;code&gt;listener&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;High-performance program patterns invariably are one-loop thread; any locks, enqueueing, and dequeueing will cause unnecessary performance loss.&lt;/li&gt;
&lt;li&gt;The time spent on core business logic is greater than the time spent introducing other code, concurrency can effectively improve efficiency; if the core latency is sufficient, be cautious about introducing other code.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://my.oschina.net/u/4617935/blog/4680856&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;JMeter Series - JMeter + Grafana + InfluxDB Real-time Monitoring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://hub.docker.com/_/influxdb&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;InfluxDB Official Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://hub.docker.com/r/grafana/grafana&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Grafana Official Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://jmeter.apache.org/download_jmeter.cgi&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;JMeter Website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/@jasonli.studio/to-install-apache-jmeter-in-centos7-294bc72a97ba&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;To install Apache JMeter in CentOS7&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Red Hat and CentOS Lifecycle</title>
        <link>https://ttf248.life/en/p/redhat-centos-lifecycle/</link>
        <pubDate>Tue, 21 Jul 2020 20:02:35 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/redhat-centos-lifecycle/</guid>
        <description>&lt;p&gt;Production environment operating systems, with Red Hat and CentOS being the mainstream choices. The documentation includes links to two system lifecycles and shares experience upgrading from CentOS 8 to CentOS Stream 8.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction
&lt;/h2&gt;&lt;p&gt;In the current domestic environment, Red Hat and CentOS are the mainstream choices for production environments. After experiencing the retirement of Red Hat 6 two years ago, this record includes the official website links for the lifecycles of both systems.&lt;/p&gt;
&lt;h2 id=&#34;main-content&#34;&gt;Main Content
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://access.redhat.com/support/policy/updates/errata&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Red Hat Enterprise Linux Life Cycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://wiki.centos.org/zh/About/Product&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CentOS Product Specifications&lt;/a&gt;
Red Hat Enterprise Linux (RHEL) and CentOS are the mainstream choices for enterprise servers. RHEL provides stable support and update cycles, suitable for enterprise applications. CentOS as RHEL&amp;rsquo;s community edition, offers similar functionality and stability but without official support.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;follow-up&#34;&gt;Follow-up
&lt;/h2&gt;&lt;p&gt;When publishing this article, I didn’t expect to update it two years later. Just a few days ago, I upgraded my daily virtual machine from CentOS 8 to CentOS 8 Stream. I can&amp;rsquo;t say much about what to choose in production – I prefer to keep the latest version in my local environment.&lt;/p&gt;
&lt;p&gt;CentOS 8 Stream is a rolling release version that offers faster updates and new features than traditional CentOS, making it suitable for development and testing environments.&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

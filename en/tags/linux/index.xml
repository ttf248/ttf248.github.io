<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Linux on Uncle Xiang&#39;s Notebook</title>
        <link>https://ttf248.life/en/tags/linux/</link>
        <description>Recent content in Linux on Uncle Xiang&#39;s Notebook</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Mon, 02 Jun 2025 19:00:25 +0800</lastBuildDate><atom:link href="https://ttf248.life/en/tags/linux/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Mastering atop: A Comprehensive Guide to Monitoring Linux System Metrics – Installation, Configuration, and Usage</title>
        <link>https://ttf248.life/en/p/atop-linux-system-monitoring-guide/</link>
        <pubDate>Thu, 06 Feb 2025 22:48:55 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/atop-linux-system-monitoring-guide/</guid>
        <description>&lt;p&gt;In Linux system administration, real-time and comprehensive monitoring of system resources and process status is crucial. The atop tool, as a powerful monitoring utility, helps us easily achieve this goal. This article will provide a detailed introduction on how to install, configure, and use the atop monitoring tool in a Linux instance.&lt;/p&gt;
&lt;h2 id=&#34;i-atop-tool-introduction&#34;&gt;I. atop Tool Introduction
&lt;/h2&gt;&lt;p&gt;atop is a tool specifically designed for monitoring Linux system resources and processes. It records the activity of systems and processes, and reports on the running status of all processes. The data collected by this tool covers resource usage such as CPU, memory, disk, and network, as well as process states. It can also save the data in log files to disk. For each process, we can obtain key information such as CPU utilization, memory growth, disk usage, priority, username, status, and exit code. Furthermore, through the atop configuration file, we can customize parameters such as logging collection frequency, log file storage path, and rotation strategy.&lt;/p&gt;
&lt;h2 id=&#34;ii-installing-the-atop-tool&#34;&gt;II. Installing the atop Tool
&lt;/h2&gt;&lt;p&gt;The installation method for atop varies slightly depending on the Linux distribution. The following provides an introduction based on common operating systems:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Alibaba Cloud Linux 3/2, CentOS 7/8, Fedora, Rocky Linux 9:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Execute the installation command: &lt;code&gt;sudo yum install -y atop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ubuntu / Debian:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Update the software source list: &lt;code&gt;sudo apt update&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Execute the installation command: &lt;code&gt;sudo apt install -y atop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;CentOS Stream 9:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download and install: &lt;code&gt;sudo wget https://www.atoptool.nl/download/atop-2.11.0-1.el9.x86_64.rpm &amp;amp;&amp;amp; sudo rpm -i atop-2.11.0-1.el9.x86_64.rpm&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;ii-installing-the-atop-tool-1&#34;&gt;II. Installing the atop Tool
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;openSUSE&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;Execute the installation command: &lt;code&gt;sudo zypper install -y atop atop-daemon&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;
If your distribution is not listed above, you can visit the official atop website for installation information.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;iii-configuring-monitoring-cycle-and-log-retention-time&#34;&gt;III. Configuring Monitoring Cycle and Log Retention Time
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Configuration File Location:&lt;/strong&gt; In Alibaba Cloud Linux 3/2, CentOS 7/8, and Fedora systems, the atop configuration file is &lt;code&gt;/etc/sysconfig/atop&lt;/code&gt;; in Ubuntu, Debian, and openSUSE systems, the configuration file is &lt;code&gt;/etc/default/atop&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Default Configuration Parameter Explanation&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;LOGOPTS&lt;/code&gt;: Controls logging options for log files, defaults to empty.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LOGINTERVAL&lt;/code&gt;: Monitoring cycle, default 600 seconds. To collect historical logs for tracking issues, it&amp;rsquo;s recommended to adjust this frequency based on actual needs.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LOGGENERATIONS&lt;/code&gt;: Log retention time, default 28 days.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LOGPATH&lt;/code&gt;: Log file storage path, defaults to &lt;code&gt;/var/log/atop&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;iii-configure-monitoring-cycle-and-log-retention-time&#34;&gt;III. Configure Monitoring Cycle and Log Retention Time
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Configuration Steps&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Execute the command to open the configuration file:
&lt;ul&gt;
&lt;li&gt;In Alibaba Cloud Linux 3/2, CentOS 7/8, Fedora systems: &lt;code&gt;sudo vim /etc/sysconfig/atop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;In Ubuntu, Debian, openSUSE, CentOS Stream 9, Rocky Linux 9 systems: &lt;code&gt;sudo vim /etc/default/atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Press ‘i’ to enter edit mode and adjust the configuration parameters according to your needs. For example, change the monitoring cycle to 30 seconds, set the log retention time to 7 days, and maintain the default log path:&lt;/li&gt;
&lt;li&gt;Press ‘Esc’ to return to normal editing mode, type &lt;code&gt;:wq&lt;/code&gt; to save and exit.&lt;/li&gt;
&lt;li&gt;Restart the atop service to apply the configuration: &lt;code&gt;sudo systemctl restart atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;LOGOPTS=&amp;quot;&amp;quot;
LOGINTERVAL=30
LOGGENERATIONS=7
LOGPATH=/var/log/atop 
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;four-using-atop-tool&#34;&gt;Four. Using atop Tool
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Common Commands:&lt;/strong&gt; In interactive command mode, the following commands are commonly used:
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;g&lt;/code&gt;: Return to the default comprehensive output view.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;c&lt;/code&gt;: Display the full command line for each process.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;m&lt;/code&gt;: Sort processes by memory usage in descending order.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;d&lt;/code&gt;: Sort processes by disk usage in descending order.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;a&lt;/code&gt;: Sort processes by overall resource usage in descending order.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;n&lt;/code&gt;: Sort processes by network usage in descending order.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;t&lt;/code&gt;: Jump to the next monitoring collection point.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;T&lt;/code&gt;: Jump to the previous monitoring collection point.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;b&lt;/code&gt;: Specify a timestamp in the format &lt;code&gt;YYYYMMDDhhmm&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;four-using-the-atop-tool&#34;&gt;Four. Using the atop Tool
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Resource Monitoring Field Meanings&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;atop&lt;/strong&gt;: Hostname, sampling date and time point.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PRC&lt;/strong&gt;: Overall process running status, including kernel state and user state runtime, total process count, number of processes in different states, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CPU&lt;/strong&gt;: Overall CPU usage, the sum of the numbers is &lt;code&gt;N*100%&lt;/code&gt; (N is the number of CPU cores), including the proportion of time for kernel state, user state, interrupt, idle, and disk I/O waiting.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CPL&lt;/strong&gt;: CPU load situation, such as the average number of processes in the queue over 1 minute, 5 minutes, and 15 minutes, context switch times, and interrupt occurrences.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MEM&lt;/strong&gt;: Memory usage, including total physical memory, free memory, page cache memory, file cache memory, and kernel occupied memory, etc. - &lt;strong&gt;SWP:&lt;/strong&gt; Swap space utilization, including total swap area and available swap space size.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PAG:&lt;/strong&gt; Virtual memory page situation, such as inbound and outbound memory page numbers.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DSK:&lt;/strong&gt; Disk usage, with each disk device corresponding to a column, displaying device identifier, busy time proportion, read/write request quantity.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NET:&lt;/strong&gt; Network status, showcasing transport layer TCP and UDP, IP layer, and receive and send packet sizes for each active port.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;four-using-the-atop-tool-1&#34;&gt;Four. Using the atop Tool
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;View Real-time System Metrics&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;View system metrics every 5 seconds: &lt;code&gt;atop 5&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View system metrics from the last 30 intervals (each interval is 10 seconds) after the current time: &lt;code&gt;atop -M 10 30&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View system metrics from the last 10 minutes (10 intervals, each interval is 60 seconds), and write the results to a file: &lt;code&gt;atop -M 60 10 &amp;gt; /log/atop.mem&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;View Historical Metric Logs&lt;/strong&gt;: After atop starts, collected records are stored by default in the &lt;code&gt;/var/log/atop&lt;/code&gt; directory. When viewing, be sure to specify the date of the log file must exist, otherwise it will error. - View daily historical metrics log: &lt;code&gt;atop -r&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View yesterday&amp;rsquo;s historical metrics log: &lt;code&gt;atop -r y&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View historical metrics log for a specific date, such as November 6, 2024: &lt;code&gt;atop -r 20241106&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View historical metrics log from a specific date and time, such as starting from November 6, 2024, 14:00: &lt;code&gt;atop -r 20241106 -b 14:00&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View historical metrics log for a specified time range on a specific date, such as from November 5, 2024, 00:04 to 00:08: &lt;code&gt;atop -r 20241105 -b 00:04 -e 00:08&lt;/code&gt; ## Four. Using the atop Tool&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;View Real-Time System Metrics&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;View system metrics every 5 seconds: &lt;code&gt;atop 5&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View system metrics from the last 30 intervals (each interval is 10 seconds) after the current time: &lt;code&gt;atop -M 10 30&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View system metrics from the last 10 minutes (10 intervals, each interval is 60 seconds), and write the results to a file: &lt;code&gt;atop -M 60 10 &amp;gt; /log/atop.mem&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;View Historical Metric Logs&lt;/strong&gt;: After atop starts, collected records are stored by default in the &lt;code&gt;/var/log/atop&lt;/code&gt; directory. When viewing, be sure to specify the log file for the desired date; otherwise, an error will occur.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;four-using-the-atop-tool-2&#34;&gt;Four. Using the atop Tool
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;View System Activity Report&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;View the CPU utilization report for the current system over 1 minute (12 times, with an interval of 5 seconds): &lt;code&gt;atopsar -c 5 12&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View the memory metrics report for a specified time period during the day, such as 18:00 to 18:01: &lt;code&gt;atopsar -m -b 18:00 -e 18:01&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View the memory metrics report for a specified date and time period, such as November 5, 2024 from 18:00 to 18:01: &lt;code&gt;atopsar -m -r 20241105 -b 18:00 -e 18:01&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;five-other-operations&#34;&gt;Five. Other Operations
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Configure Daily Log Rotation Policy&lt;/strong&gt;: If you want to generate a daily &lt;code&gt;atop&lt;/code&gt; metric log file, you can perform the following actions:
&lt;ul&gt;
&lt;li&gt;(Optional) Adjust monitoring period, log retention time, and log storage path according to your needs.&lt;/li&gt;
&lt;li&gt;Execute the command to enable and start the services related to daily log rotation: &lt;code&gt;sudo systemctl enable --now atop atopacct atop-rotate.timer&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;If your business has more complex requirements for log processing, you can also combine it with &lt;code&gt;logrotate&lt;/code&gt; or custom scripts to implement log management.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;five-other-operations-1&#34;&gt;Five. Other Operations
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Load the optional netatop kernel module:&lt;/strong&gt; If you need to monitor network usage, you can install the netatop module (the module is not installed by default in atop). As an example on Alibaba Cloud Linux 3:
&lt;ul&gt;
&lt;li&gt;Install the kernel development package and the software environment required for compiling: &lt;code&gt;sudo yum install -y kernel-devel dkms elfutils-libelf-devel&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Download the latest version of netatop source code to a specified directory: &lt;code&gt;cd /usr/src/ &amp;amp;&amp;amp; sudo wget https://www.atoptool.nl/download/netatop-3.2.2.tar.gz --no-check-certificate&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Extract the source code and enter the source code directory: &lt;code&gt;sudo tar -zxvf netatop-3.2.2.tar.gz &amp;amp;&amp;amp; cd netatop-3.2.2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Build and install the module and daemon based on the source code: &lt;code&gt;sudo make &amp;amp;&amp;amp; sudo make install&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the netatop service: &lt;code&gt;sudo systemctl start netatop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v-other-operations&#34;&gt;V. Other Operations
&lt;/h2&gt;&lt;p&gt;The atop tool is powerful and flexible to use. By installing, configuring, and using it properly, we can better understand the running status of our Linux system and promptly identify and resolve potential issues. We hope this article will help everyone take Linux system monitoring to a new level.&lt;/p&gt;
&lt;h2 id=&#34;vi-references&#34;&gt;VI. References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.atoptool.nl/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;atop official website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://help.aliyun.com/zh/ecs/use-cases/use-the-atop-tool-to-monitor-linux-system-metrics#99e53d0198euu&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Installation, configuration, and usage of the atop monitoring tool&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Linux backend services handling large volumes of string data – performance is slow.</title>
        <link>https://ttf248.life/en/p/linux-backend-slow-string-processing/</link>
        <pubDate>Wed, 13 Nov 2024 19:42:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-backend-slow-string-processing/</guid>
        <description>&lt;p&gt;In the history of C++ development projects, we utilized a custom protocol for communication, which employed a two-dimensional array pattern. When processing large volumes of data, the protocol required iterating through the arrays and performing serialization operations to generate logs. Due to its low efficiency, this resulted in noticeable lag or stuttering within the system under heavy load, as reported by the business department.&lt;/p&gt;
&lt;h2 id=&#34;problem-identification&#34;&gt;Problem Identification
&lt;/h2&gt;&lt;p&gt;When troubleshooting the issue, we first performed a performance analysis of the system and discovered that CPU utilization increased significantly when processing large amounts of data, and system response times became longer. By analyzing the system logs, we identified numerous serialization operations, which were inefficient when handling two-dimensional arrays, leading to a decline in system performance.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;pstack&lt;/code&gt; tool captured thread information for the service, pinpointing that the log threads spent most of their time processing string concatenation.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is today’s focus: different accumulation methods have significant efficiency differences. Historically, the code used the &lt;code&gt;+&lt;/code&gt; operator, which frequently creates temporary objects and is very inefficient. You know it&amp;rsquo;s bad, but you don&amp;rsquo;t know &lt;em&gt;how&lt;/em&gt; bad it is.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;demo-verification&#34;&gt;Demo Verification
&lt;/h2&gt;&lt;p&gt;Based on the project code, we extracted the business logic and wrote a simple demo to verify the efficiency issues of string concatenation. We compiled and ran it in &lt;code&gt;Release&lt;/code&gt; mode using the &lt;code&gt;vs2022&lt;/code&gt; compiler under &lt;code&gt;windows&lt;/code&gt; and the &lt;code&gt;gcc8.5&lt;/code&gt; compiler under &lt;code&gt;linux&lt;/code&gt;, comparing the efficiencies.&lt;/p&gt;
&lt;h3 id=&#34;key-points-explanation&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;p&gt;The project utilized Method Four, and before obtaining test data, readers should consider which method is most efficient and which is least efficient. I was quite surprised by the results.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Method 1 (&lt;code&gt;+=&lt;/code&gt; Concatenation)&lt;/strong&gt;: Directly concatenates each field using &lt;code&gt;+=&lt;/code&gt; to a string.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 2 (&lt;code&gt;std::ostringstream&lt;/code&gt; Concatenation)&lt;/strong&gt;: Uses a stream (&lt;code&gt;std::ostringstream&lt;/code&gt;) to concatenate each field, which is more efficient, especially when dealing with large amounts of data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 3 (Pre-allocated Memory &lt;code&gt;+=&lt;/code&gt; Concatenation)&lt;/strong&gt;: Pre-allocates enough memory for the string using &lt;code&gt;reserve&lt;/code&gt; to reduce the overhead of memory reallocation and improve performance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 4 (&lt;code&gt;bodys = bodys + body + &amp;quot;\n&amp;quot;&lt;/code&gt;)&lt;/strong&gt;: Each concatenation creates a new temporary string object, leading to performance degradation, especially with large-scale concatenations due to the allocation and copying of a new memory space each time.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Referring to the results, we can see that this method was selected as the least efficient.&lt;/p&gt;
&lt;p&gt;Furthermore, let&amp;rsquo;s analyze the optimization efficiency of different platform compilers – Microsoft’s &lt;code&gt;visual studio&lt;/code&gt; remains consistently excellent, with high string optimization efficiency, while the &lt;code&gt;gcc&lt;/code&gt; compiler lags somewhat in this regard.&lt;/p&gt;
&lt;h3 id=&#34;key-points-explanation-1&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;The code executes on different machines, and the two datasets do not have a direct comparison; instead, differences can be compared between various splicing methods.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;key-points-explanation-2&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Windows platform under Visual Studio 2022 compiler

----------------------------------------
Data Generation Time: 0.054 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.053 seconds.
+ ostringstream Data merging took: 0.054 seconds.
+ Pre-reserved Data merging took: 0.045 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 16.108 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;key-points-explanation-3&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Linux platform under GCC 8.5 compiler
----------------------------------------
Data Generation Time: 0.108 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.100 seconds.
+ ostringstream Data merging took: 0.083 seconds.
+ Pre-reserved Data merging took: 0.057 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 29.298 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;random&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;sstream&amp;gt;
#include &amp;lt;iomanip&amp;gt;

typedef std::vector&amp;lt;std::string&amp;gt; DataRow;
typedef std::vector&amp;lt;DataRow&amp;gt; DataGroup;

struct ResponsePackage
{
    std::string ErrorInfo;
    DataRow Head;
    std::string ClientId;
    std::string UUID;
    std::string MsgID;
    std::string SessionID;
    std::string ExtraInfo1;
    std::string ExtraInfo2;
    DataGroup DataBody;
};
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-1&#34;&gt;Complete Code
&lt;/h2&gt;&lt;p&gt;// Generate specified length of random string
std::string generateRandomString(size_t length)
{
const char charset[] = &amp;ldquo;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&amp;rdquo;;
const size_t max_index = sizeof(charset) - 1;
std::string random_string;
random_string.reserve(length);&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;std::random_device rd;
std::mt19937 generator(rd());
std::uniform_int_distribution&amp;lt;&amp;gt; distribution(0, max_index);
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-2&#34;&gt;Complete Code
&lt;/h2&gt;&lt;p&gt;for (size_t i = 0; i &amp;lt; length; ++i)
{
random_string += charset[distribution(generator)];
}&lt;/p&gt;
&lt;p&gt;return random_string;
}&lt;/p&gt;
&lt;p&gt;void create_large_string()
{
// Example request package with 50 fields
ResponsePackage requestPackage;&lt;/p&gt;
&lt;h2 id=&#34;complete-code-3&#34;&gt;Complete Code
&lt;/h2&gt;&lt;p&gt;requestPackage.Head = {
&amp;ldquo;Field1&amp;rdquo;, &amp;ldquo;Field2&amp;rdquo;, &amp;ldquo;Field3&amp;rdquo;, &amp;ldquo;Field4&amp;rdquo;, &amp;ldquo;Field5&amp;rdquo;,
&amp;ldquo;Field6&amp;rdquo;, &amp;ldquo;Field7&amp;rdquo;, &amp;ldquo;Field8&amp;rdquo;, &amp;ldquo;Field9&amp;rdquo;, &amp;ldquo;Field10&amp;rdquo;,
&amp;ldquo;Field11&amp;rdquo;, &amp;ldquo;Field12&amp;rdquo;, &amp;ldquo;Field13&amp;rdquo;, &amp;ldquo;Field14&amp;rdquo;, &amp;ldquo;Field15&amp;rdquo;,
&amp;ldquo;Field16&amp;rdquo;, &amp;ldquo;Field17&amp;rdquo;, &amp;ldquo;Field18&amp;rdquo;, &amp;ldquo;Field19&amp;rdquo;, &amp;ldquo;Field20&amp;rdquo;,
&amp;ldquo;Field21&amp;rdquo;, &amp;ldquo;Field22&amp;rdquo;, &amp;ldquo;Field23&amp;rdquo;, &amp;ldquo;Field24&amp;rdquo;, &amp;ldquo;Field25&amp;rdquo;,
&amp;ldquo;Field26&amp;rdquo;, &amp;ldquo;Field27&amp;rdquo;, &amp;ldquo;Field28&amp;rdquo;, &amp;ldquo;Field29&amp;rdquo;, &amp;ldquo;Field30&amp;rdquo;,
&amp;ldquo;Field31&amp;rdquo;, &amp;ldquo;Field32&amp;rdquo;, &amp;ldquo;Field33&amp;rdquo;, &amp;ldquo;Field34&amp;rdquo;, &amp;ldquo;Field35&amp;rdquo;
};&lt;/p&gt;
&lt;h2 id=&#34;complete-code-4&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;Field31&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field32&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field33&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field34&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field35&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field36&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field37&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field38&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field39&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field40&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field41&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field42&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field43&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field44&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field45&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field46&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field47&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field48&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field49&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field50&amp;quot;: &amp;quot;&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-5&#34;&gt;Complete Code
&lt;/h2&gt;&lt;p&gt;requestPackage.ClientId = &amp;ldquo;ClientID&amp;rdquo;;
requestPackage.UUID = &amp;ldquo;UUID&amp;rdquo;;
requestPackage.MsgID = &amp;ldquo;MsgID&amp;rdquo;;
requestPackage.SessionID = &amp;ldquo;SessionID&amp;rdquo;;
requestPackage.ExtraInfo1 = &amp;ldquo;ExtraInfo1&amp;rdquo;;
requestPackage.ExtraInfo2 = &amp;ldquo;ExtraInfo2&amp;rdquo;;&lt;/p&gt;
&lt;p&gt;// Start timing for data generation
auto start_gen = std::chrono::high_resolution_clock::now();&lt;/p&gt;
&lt;h2 id=&#34;complete-code-6&#34;&gt;Complete Code
&lt;/h2&gt;&lt;p&gt;// Generate 10,000 rows of data, each with 50 fields
for (size_t i = 0; i &amp;lt; 10000; ++i)
{
DataRow dataRow(50, &amp;ldquo;This is a test string&amp;rdquo;);
requestPackage.DataBody.push_back(dataRow);
}&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// End timing for data generation
auto end_gen = std::chrono::high_resolution_clock::now();
std::chrono::duration&amp;lt;double&amp;gt; duration_gen = end_gen - start_gen;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code
// Display result generation time
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Generation Time: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_gen.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    // Data merging using different methods
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Performance:\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-7&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Method 1: Using &#39;+=&#39; string concatenation
auto start_merge = std::chrono::high_resolution_clock::now();
std::string bodys(&amp;quot;&amp;quot;);
for (auto&amp;amp; vec : requestPackage.DataBody)
{
    std::string body(&amp;quot;This is a test string&amp;quot;);
    for (auto&amp;amp; item : vec)
    {
        body += item + &amp;quot; &amp;quot;;
    }
    bodys += body + &amp;quot;\n&amp;quot;;
}
auto end_merge = std::chrono::high_resolution_clock::now();
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code
}
    auto end_merge = std::chrono::high_resolution_clock::now();
    std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
    std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (+=) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-8&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Method 2: Using ostringstream
auto start_merge = std::chrono::high_resolution_clock::now();
std::ostringstream bodys;
for (auto&amp;amp; vec : requestPackage.DataBody)
{
    std::ostringstream body;
    body &amp;lt;&amp;lt; &amp;quot;This is a test string&amp;quot;;
    for (auto&amp;amp; item : vec)
    {
        body &amp;lt;&amp;lt; item &amp;lt;&amp;lt; &amp;quot; &amp;quot;;
    }
    bodys &amp;lt;&amp;lt; body.str() &amp;lt;&amp;lt; &amp;quot;\n&amp;quot;;
}
auto end_merge = std::chrono::high_resolution_clock::now();
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code
}
    auto end_merge = std::chrono::high_resolution_clock::now();
    std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
    std::cout &amp;lt;&amp;lt; &amp;quot;+ ostringstream Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code
{
        // Method 3: Pre-allocated memory
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys;
        bodys.reserve(1000 * 50 * 20); // Pre-allocate enough memory
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            body.reserve(50 * 20); // Pre-allocate memory for each row
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code

for (auto&amp;amp; item : vec) {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Pre-reserved Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-9&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;// Method 4: Using &#39;bodys = bodys + body + &amp;quot;\n&amp;quot;&#39;
auto start_merge = std::chrono::high_resolution_clock::now();
std::string bodys(&amp;quot;&amp;quot;);
for (auto&amp;amp; vec : requestPackage.DataBody)
{
    std::string body(&amp;quot;This is a test string&amp;quot;);
    for (auto&amp;amp; item : vec)
    {
        body = body + item + &amp;quot; &amp;quot;; // Note the use of &#39;body = body + item&#39;
    }
    bodys = bodys + body + &amp;quot;\n&amp;quot;; // Again, using &#39;bodys = bodys + body&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code

```cpp
        auto start_merge = std::chrono::high_resolution_clock::now();
        bodys = bodys + body + &amp;quot;\n&amp;quot;; // Again, using &#39;bodys = bodys + body&#39;
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (bodys = bodys + body + \&amp;quot;\\n\&amp;quot;) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-10&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Complete.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;
}

int main()
{
    try
    {
        create_large_string();
    }
    catch (const std::exception&amp;amp; e)
    {
        std::cerr &amp;lt;&amp;lt; &amp;quot;Caught exception: &amp;quot; &amp;lt;&amp;lt; e.what() &amp;lt;&amp;lt; std::endl;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\nProgram finished.\n&amp;quot;;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Upgrading the GCC version caused program crashes: hidden issues due to code non-compliance.</title>
        <link>https://ttf248.life/en/p/gcc-upgrade-causes-program-crash-code-irregularities/</link>
        <pubDate>Sun, 10 Mar 2024 23:19:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/gcc-upgrade-causes-program-crash-code-irregularities/</guid>
        <description>&lt;p&gt;In the same business code scenario, the program compiled and ran normally in a CentOS 7 environment. However, when switching to CentOS 8 and using an updated version of GCC for compilation, the program crashed. It’s worth noting that the issue only occurs in &lt;strong&gt;Release mode&lt;/strong&gt;, while &lt;strong&gt;Debug mode&lt;/strong&gt; does not exhibit any problems. This is the first time we&amp;rsquo;ve encountered a situation like this; after three days of investigation, we finally identified the root cause.&lt;/p&gt;
&lt;h3 id=&#34;problem-identification&#34;&gt;Problem Identification
&lt;/h3&gt;&lt;p&gt;After investigation, the root cause of the issue was &lt;strong&gt;the function lacking a return value&lt;/strong&gt;. In Release mode, new versions of GCC perform more optimizations, which caused an unknown logic to occur within the function that originally did not have an explicit return value during execution, ultimately triggering a crash. Our conclusion is that &lt;strong&gt;compiler warnings should not be ignored, especially in legacy projects where some warnings may be dismissed, but it’s also important to avoid suppressing all warnings.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;environment-details&#34;&gt;Environment Details
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CentOS 7 GCC Version:&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CentOS 8 GCC Version:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;crash-phenomena&#34;&gt;Crash Phenomena
&lt;/h3&gt;&lt;p&gt;When analyzing the stack information for program crashes, we observed the following stack details:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[New LWP 1385902]
[Thread debugging using libthread_db enabled]
Using host libthread_db library &amp;quot;/lib64/libthread_db.so.1&amp;quot;.
Core was generated by `./pstack_main`.
Program terminated with signal SIGSEGV, Segmentation fault.
#0  0x00007ffe894b4420 in ?? ()
(gdb) bt
#0  0x00007ffe894b4420 in ?? ()
#1  0x00000000004008e9 in main ()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This stack doesn&amp;rsquo;t appear intuitive; the crash function’s stack information shows a &lt;code&gt;??&lt;/code&gt;, which makes troubleshooting even more complex.&lt;/p&gt;
&lt;h3 id=&#34;code-example&#34;&gt;Code Example
&lt;/h3&gt;&lt;p&gt;To better understand the issue, here’s a minimal code example that reproduces the crash:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;map&amp;gt;

int test() {
    std::cout &amp;lt;&amp;lt; &amp;quot;1&amp;quot; &amp;lt;&amp;lt; std::endl;
}

int main() {
    test();
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;test()&lt;/code&gt; function in this code clearly doesn&amp;rsquo;t explicitly return a value, and its return type is &lt;code&gt;int&lt;/code&gt;. According to the C++ standard, when a function is declared as an &lt;code&gt;int&lt;/code&gt; type, it must have a return value, otherwise it may lead to undefined behavior.&lt;/p&gt;
&lt;h3 id=&#34;compilation-warning&#34;&gt;Compilation Warning
&lt;/h3&gt;&lt;p&gt;In our project, the CMake script suppresses many compile-time warnings, including the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;/root/pstack/main.cpp: In function ‘int test()’:
/root/pstack/main.cpp:7:1: warning: no return statement in function returning non-void [-Wreturn-type]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This warning indicates that the &lt;code&gt;test()&lt;/code&gt; function does not return a value, which is the root cause of the problem. Newer versions of GCC (such as 8.5.0) may make unstable optimizations with this undefined behavior when optimizing code, potentially leading to program crashes.&lt;/p&gt;
&lt;h3 id=&#34;assembly-code-differences&#34;&gt;Assembly Code Differences
&lt;/h3&gt;&lt;p&gt;To explain the differences in GCC compiler optimization behavior, we compared assembly code generated by different versions of GCC:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GCC 4.8.5 Generated Assembly Code:&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The assembly code is relatively verbose and includes handling logic for standard output streams (such as &lt;code&gt;std::cout&lt;/code&gt;). This indicates that the compiler performed more conservative optimizations, not optimizing excessively for the missing return value issue in the &lt;code&gt;test()&lt;/code&gt; function, possibly to avoid a crash.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GCC 8.5.0 Generated Assembly Code:&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The new version of GCC performed more optimizations, reducing the code volume. However, this optimization may have resulted in undefined behavior when calling functions without returning values, leading to program crashes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h3&gt;&lt;p&gt;Through this troubleshooting process, we deeply realized that in C++, &lt;strong&gt;function return values must be explicit&lt;/strong&gt;, especially when a function is declared as &lt;code&gt;int&lt;/code&gt;, a return value must be provided. When upgrading from older versions of compilers to newer versions of GCC, more optimization and stricter warning mechanisms may be encountered. Therefore, we recommend not suppressing all warnings during compilation, but rather selectively addressing them, particularly common issues such as function return values and type matching.
Ultimately, by adding a return value to the &lt;code&gt;test()&lt;/code&gt; function, the problem was resolved, and the program returned to normal operation.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Linux System Benchmark Test</title>
        <link>https://ttf248.life/en/p/linux-system-benchmark-test/</link>
        <pubDate>Tue, 09 Jan 2024 10:56:23 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-system-benchmark-test/</guid>
        <description>&lt;p&gt;Windows platform has RuMaster (Entertainment Master), which isn’t known for highly accurate data, but it still provides some reference. Of course, there are other professional benchmarking software as well. When it comes to Linux systems, there haven&amp;rsquo;t seemed to be particularly suitable benchmarking software encountered.&lt;/p&gt;
&lt;p&gt;Sysbench is a versatile benchmark testing tool that can be used to test CPU, memory, file I/O, thread performance, and more. You can use Sysbench to execute various performance testing tasks.&lt;/p&gt;
&lt;p&gt;I just happen to have three machines available for testing: the Mechanical Artist mini laptop, a small local host, an Alibaba Cloud Dev development cloud server, and a Huawei Cloud Dev server.&lt;/p&gt;
&lt;h2 id=&#34;installing-sysbench&#34;&gt;Installing Sysbench
&lt;/h2&gt;&lt;p&gt;On most Linux distributions, you can use the package manager to install Sysbench. For example, on CentOS 8, you can use the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo dnf install sysbench
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;sysbench-usage-examples&#34;&gt;Sysbench Usage Examples
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Testing CPU performance: &lt;code&gt;sysbench --test=cpu run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Testing memory read performance: &lt;code&gt;sysbench --test=memory run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Testing file I/O performance:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sysbench --test=fileio --file-test-mode=rndrw prepare
sysbench --test=fileio --file-test-mode=rndrw run
sysbench --test=fileio --file-test-mode=rndrw cleanup
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Testing multi-threaded performance: &lt;code&gt;sysbench --test=threads --num-threads=4 run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Testing MySQL database performance (adjust maximum connection number):&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sysbench-usage-examples-1&#34;&gt;Sysbench Usage Examples
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword --oltp-table-size=1000000 prepare
sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword --max-time=60 --oltp-read-only=off --oltp-test-mode=complex --max-requests=0 run
sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword cleanup
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;score-report&#34;&gt;Score Report
&lt;/h2&gt;&lt;meta http-equiv=&#34;Content-Type&#34; content=&#34;text/html; charset=utf-8&#34;&gt;&lt;link type=&#34;text/css&#34; rel=&#34;stylesheet&#34; href=&#34;resources/sheet.css&#34; &gt;
&lt;h2 id=&#34;score-report-1&#34;&gt;Score Report
&lt;/h2&gt;&lt;style type=&#34;text/css&#34;&gt;.ritz .waffle a { color: inherit; }.ritz .waffle .s0{background-color:#ffffff;text-align:left;color:#000000;font-family:&#39;Arial&#39;;font-size:10pt;vertical-align:bottom;white-space:nowrap;direction:ltr;padding:2px 3px 2px 3px;}&lt;/style&gt;&lt;div class=&#34;ritz grid-container&#34; dir=&#34;ltr&#34;&gt;&lt;table class=&#34;waffle&#34; cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th class=&#34;row-header freezebar-origin-ltr&#34;&gt;&lt;/th&gt;&lt;th id=&#34;0C0&#34; style=&#34;width:100px;&#34; class=&#34;column-headers-background&#34;&gt;A&lt;/th&gt;&lt;th id=&#34;0C1&#34;
&lt;h2 id=&#34;score-report-2&#34;&gt;Score Report
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Column A (id=&amp;ldquo;0C0&amp;rdquo; style=&amp;ldquo;width:100px;&amp;rdquo; class=&amp;ldquo;column-headers-background&amp;rdquo;)&lt;/th&gt;
&lt;th&gt;Column B (id=&amp;ldquo;0C1&amp;rdquo; style=&amp;ldquo;width:421px;&amp;rdquo; class=&amp;ldquo;column-headers-background&amp;rdquo;)&lt;/th&gt;
&lt;th&gt;Column C (id=&amp;ldquo;0C2&amp;rdquo; style=&amp;ldquo;width:398px;&amp;rdquo; class=&amp;ldquo;column-headers-background&amp;rdquo;)&lt;/th&gt;
&lt;th&gt;Column D (id=&amp;ldquo;0C3&amp;rdquo; style=&amp;ldquo;width:422px;&amp;rdquo; class=&amp;ldquo;column-headers-background&amp;rdquo;)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Row 1 &lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;1&lt;/div&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;score-report-3&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;class=&amp;ldquo;row-header-wrapper&amp;rdquo; style=&amp;ldquo;line-height: 20px&amp;rdquo;&amp;gt;1&lt;/div&gt;&lt;/th&gt;&lt;td&gt;&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Local Technician&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;阿里云 (Alibaba Cloud)&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;华为云 (Huawei Cloud)&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R1&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;2&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Configuration&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Information&lt;br&gt;  Operating System              Ubuntu 23.04&lt;br&gt;  Kernel                        Linux&lt;/p&gt;
&lt;h2 id=&#34;score-report-4&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;Information
Operating System              Ubuntu 23.04
Kernel                        Linux 6.2.0-36-generic x86_64
Model                         Machenike Machenike DT Computer
Motherboard                   Machenike Machenike DT Computer
BIOS                          American Megatrends International, LLC.
DB19V012&lt;/p&gt;
&lt;p&gt;CPU Information
Name                          Intel Core i7-12650H
Topology                      1 Processor, 10 Cores, 16 Threads
Identifier&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;i7-12650H
Topology: 1 Processor, 10 Cores, 16 Threads
Identifier: GenuineIntel Family 6 Model 154 Stepping 3
Base Frequency: 4.60 GHz
L1 Instruction Cache: 32.0 KB x 8
L1 Data Cache: 48.0 KB x 8
L2 Cache: 1.25 MB x 2
L3 Cache: 24.0 MB&lt;/p&gt;
&lt;p&gt;Memory Information:
Size: 62.6 GB&lt;/p&gt;
&lt;h2 id=&#34;score-report-5&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;Size                          62.6 GB&lt;/p&gt;
&lt;p&gt;System Information
Operating System              CentOS Stream 8
Kernel                        Linux 4.18.0-513.el8.x86_64 x86_64
Model                         Alibaba Cloud Alibaba Cloud ECS
Motherboard                   N/A
BIOS                          SeaBIOS 449e491&lt;/p&gt;
&lt;p&gt;CPU Information
Name                          Intel(R) Xeon(R) Platinum
Topology                      1 Processor, 1 Core, 2&amp;hellip;&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-1&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;Intel(R) Xeon(R) Platinum
Topology: 1 Processor, 1 Core, 2 Threads
Identifier: GenuineIntel Family 6 Model 85 Stepping 4
Base Frequency: 2.50 GHz
L1 Instruction Cache: 32.0 KB
L1 Data Cache: 32.0 KB
L2 Cache: 1.00 MB
L3 Cache: 33.0 MB&lt;/p&gt;
&lt;p&gt;Memory Information:
Size: 1.65 GB&lt;/p&gt;
&lt;h2 id=&#34;score-report-data&#34;&gt;Score Report Data
&lt;/h2&gt;&lt;p&gt;Information
Size 1.65 GB&lt;/p&gt;
&lt;p&gt;System Information
Operating System Ubuntu 22.04.1 LTS
Kernel Linux 5.15.0-60-generic x86_64
Model OpenStack Foundation OpenStack Nova
Motherboard N/A
BIOS SeaBIOS
rel-1.10.2-0-g5f4c7b1-20181220_000000-szxrtosci10000&lt;/p&gt;
&lt;p&gt;CPU Information
Name Intel(R) Xeon(R) Gold&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-2&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;Information:
Name                          Intel(R) Xeon(R) Gold 6278C CPU @ 2.60GHz
Topology                      1 Processor, 1 Core, 2 Threads
Identifier                    GenuineIntel Family 6 Model 85 Stepping 7
Base Frequency                2.60 GHz
L1 Instruction Cache          32.0 KB
L1 Data Cache                 32.0 KB
L2 Cache                      1.00 MB
L3 Cache                      35.8 MB&lt;/p&gt;
&lt;p&gt;Memory Information:
Size&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-3&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;L3 Cache                      35.8 MB&lt;br&gt;&lt;br&gt;Memory Information&lt;br&gt;  Size                          3.64 GB&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R2&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;3&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;CPU&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current&lt;/p&gt;
&lt;h2 id=&#34;score-report-6&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;with following options:
Number of threads: 1
Initializing random number generator from current time&lt;/p&gt;
&lt;p&gt;Prime numbers limit: 10000&lt;/p&gt;
&lt;p&gt;Initializing worker threads&amp;hellip;
Threads started!&lt;/p&gt;
&lt;p&gt;CPU speed:
events per second:  4032.48&lt;/p&gt;
&lt;p&gt;General statistics:
total time:                          10.0004s
total number of events:              40330&lt;/p&gt;
&lt;p&gt;Latency (ms):
min:                                    0.25
avg:&lt;/p&gt;
&lt;h2 id=&#34;score-report-7&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;min:                                    0.25&lt;br&gt;         avg:                                    0.25&lt;br&gt;         max:                                    0.73&lt;br&gt;         95th percentile:                        0.25&lt;br&gt;         sum:                                 9997.55&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           40330.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9975/0.00&lt;/p&gt;
&lt;p&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-4&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;class=&amp;ldquo;s0&amp;rdquo; dir=&amp;ldquo;ltr&amp;rdquo;&amp;gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  1062.51&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0008s&lt;br&gt;    total number of events:              10628&lt;br&gt;&lt;br&gt;Latency (ms):&lt;/p&gt;
&lt;h2 id=&#34;score-report-8&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;10.0008s &lt;br&gt;
total number of events: 10628 &lt;br&gt;&lt;br&gt;
Latency (ms):&lt;br&gt;
min: 0.91 &lt;br&gt;
avg: 0.94 &lt;br&gt;
max: 22.84 &lt;br&gt;
95th percentile: 1.06 &lt;br&gt;
sum: 9993.46 &lt;br&gt;&lt;br&gt;
Threads fairness:&lt;br&gt;
events (avg/stddev): 10628.0000/0.00 &lt;br&gt;
execution time (avg/stddev):&lt;/p&gt;
&lt;h2 id=&#34;score-report-9&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;events (avg/stddev):           10628.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9935/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  1125.56&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:&lt;/p&gt;
&lt;h2 id=&#34;score-report-10&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;speed:
events per second: 1125.56&lt;/p&gt;
&lt;p&gt;General statistics:
total time: 10.0005s
total number of events: 11258&lt;/p&gt;
&lt;p&gt;Latency (ms):
min: 0.86
avg: 0.89
max: 1.70
95th percentile: 0.99
sum: 9995.40&lt;/p&gt;
&lt;p&gt;Threads fairness:&lt;/p&gt;
&lt;h2 id=&#34;score-report-11&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;0.99 &lt;br&gt;         sum:                                 9995.40 &lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           11258.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9954/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R3&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;4&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Memory&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random&lt;/p&gt;
&lt;h2 id=&#34;run-test-report&#34;&gt;Run Test Report
&lt;/h2&gt;&lt;p&gt;dir=&amp;ldquo;ltr&amp;rdquo;&amp;gt;Running the test with the following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 101993199 (10198146.52 per second)&lt;br&gt;&lt;br&gt;99602.73 MiB transferred (9959.13 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:&lt;/p&gt;
&lt;h2 id=&#34;score-report-12&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;MiB transferred (9959.13 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              101993199&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                    0.03&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4059.50&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;score-report-13&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;0.00
sum:                                 4059.50
Threads fairness:&lt;br&gt;    events (avg/stddev):           101993199.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.0595/0.00&lt;/p&gt;
&lt;p&gt;Running the test with following options:
Number of threads: 1
Initializing random number generator from current time&lt;/p&gt;
&lt;p&gt;Running memory speed test with the following options:
block size: 1KiB
total size: 102400MiB
operation: write
scope:&lt;/p&gt;
&lt;h2 id=&#34;score-report-14&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 48418803 (4841.00 per second)&lt;br&gt;&lt;br&gt;47283.99 MiB transferred (4727.54 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              48418803&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:&lt;/p&gt;
&lt;h2 id=&#34;score-report-15&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;(ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                   25.26&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4578.95&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           48418803.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.5789/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of&lt;/p&gt;
&lt;h2 id=&#34;score-report-16&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;4.5789/0.00 &lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with the following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 57056904 (5704765.11 per second)&lt;br&gt;&lt;br&gt;55719.63 MiB transferred (5571.06 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General&lt;/p&gt;
&lt;h2 id=&#34;scoring-data-report&#34;&gt;Scoring Data Report
&lt;/h2&gt;&lt;p&gt;(5704765.11 per second)&lt;/p&gt;
&lt;p&gt;55719.63 MiB transferred (5571.06 MiB/sec)&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;General statistics:
total time:                          10.0001s
total number of events:              57056904&lt;/p&gt;
&lt;p&gt;Latency (ms):
min:                                    0.00
avg:                                    0.00
max:                                    0.06
95th percentile:                        0.00
sum:&lt;/p&gt;
&lt;h2 id=&#34;score-report-17&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;95th percentile:                        0.00&lt;br&gt;         sum:                                 4556.06&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           57056904.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.5561/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R4&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;5&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Disk&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 1.81 seconds&lt;/p&gt;
&lt;h2 id=&#34;score-report-18&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;class=&amp;ldquo;s0&amp;rdquo; dir=&amp;ldquo;ltr&amp;rdquo;&amp;gt;Hard Drive&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 1.81 seconds (1129.59 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with the following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-5&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      3373.41&lt;br&gt;    writes/s:                     2248.94&lt;br&gt;    fsyncs/s:                     7201.80&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  52.71&lt;br&gt;    written, MiB/s:&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-6&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;read, MiB/s:                  52.71&lt;br&gt;    written, MiB/s:               35.14&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0127s&lt;br&gt;    total number of events:              128288&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.08&lt;br&gt;         max:                                    5.14&lt;br&gt;         95th percentile:                        0.34&lt;br&gt;         sum:&lt;/p&gt;
&lt;h2 id=&#34;score-report-19&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;95th percentile: 0.34&lt;br&gt;         sum: 9977.78&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev): 128288.0000/0.00&lt;br&gt;    execution time (avg/stddev): 9.9778/0.00&lt;br&gt;&lt;br&gt;2147483648 bytes written in 19.29 seconds (106.16 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files,&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-7&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;Random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:&lt;/p&gt;
&lt;h2 id=&#34;score-report-20&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      1593.12&lt;br&gt;    writes/s:                     1062.08&lt;br&gt;    fsyncs/s:                     3406.64&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  24.89&lt;br&gt;    written, MiB/s:               16.60&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0164s&lt;br&gt;    total number of events:              60600&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:&lt;/p&gt;
&lt;h2 id=&#34;score-report-21&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;events: 60600&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min: 0.00&lt;br&gt;         avg: 0.16&lt;br&gt;         max: 31.32&lt;br&gt;         95th percentile: 0.54&lt;br&gt;         sum: 9956.30&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev): 60600.0000/0.00&lt;br&gt;    execution time (avg/stddev): 9.9563/0.00
bytes: 2147483648&lt;/p&gt;
&lt;h2 id=&#34;score-report-22&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;execution time (avg/stddev):   9.9563/0.00&lt;/p&gt;
&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 18.29 seconds (111.98 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100
&lt;h2 id=&#34;benchmark-data-report-8&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;Ratio for combined random IO test: 1.50 &lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      1665.88&lt;br&gt;    writes/s:                     1110.59&lt;br&gt;    fsyncs/s:                     3563.77&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  26.03&lt;br&gt;    written, MiB/s:&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-9&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;3563.77&lt;/p&gt;
&lt;p&gt;Throughput:
read, MiB/s:                  26.03
written, MiB/s:               17.35&lt;/p&gt;
&lt;p&gt;General statistics:
total time:                          10.0112s
total number of events:              63355&lt;/p&gt;
&lt;p&gt;Latency (ms):
min:                                    0.00
avg:                                    0.16
max:                                  205.01
95th percentile:                        0.78&lt;/p&gt;
&lt;h2 id=&#34;score-report-23&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;205.01&lt;br&gt;         95th percentile:                        0.78&lt;br&gt;         sum:                                 9972.64&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           63355.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9726/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R5&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;6&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Multi-threaded&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running&lt;/p&gt;
&lt;h2 id=&#34;score-report-24&#34;&gt;Score Report
&lt;/h2&gt;&lt;div style=&#34;width: 6vw&#34;&gt;6&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Multi-Thread&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with the following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0002s&lt;br&gt;    total number of events:              197956&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.16&lt;br&gt;         avg:
&lt;h2 id=&#34;score-report-25&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;(ms):&lt;br&gt;         min:                                    0.16&lt;br&gt;         avg:                                    0.20&lt;br&gt;         max:                                    0.34&lt;br&gt;         95th percentile:                        0.21&lt;br&gt;         sum:                                39970.47&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           49489.0000/5.70&lt;br&gt;    execution time (avg/stddev):   9.9926/0.00&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads:&lt;/p&gt;
&lt;h2 id=&#34;score-report-26&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;class=&amp;ldquo;s0&amp;rdquo; dir=&amp;ldquo;ltr&amp;rdquo;&amp;gt;Running the test with the following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0174s&lt;br&gt;    total number of events:              18360&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.57&lt;br&gt;         avg:                                    2.18&lt;br&gt;         max:&lt;/p&gt;
&lt;h2 id=&#34;score-report-27&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;0.57&lt;br&gt;         avg:                                    2.18&lt;br&gt;         max:                                   32.77&lt;br&gt;         95th percentile:                        2.61&lt;br&gt;         sum:                                40050.41&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           4590.0000/94.36&lt;br&gt;    execution time (avg/stddev):   10.0126/0.00&lt;/p&gt;
&lt;p&gt;Running the test with following options:
Number of threads: 4
Initializing random number generator from&lt;/p&gt;
&lt;h2 id=&#34;score-report-28&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;Test with the following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0004s&lt;br&gt;    total number of events:              28536&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.23&lt;br&gt;         avg:                                    1.40&lt;br&gt;         max:                                    3.56&lt;/p&gt;
&lt;h2 id=&#34;score-report-29&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;1.40 &lt;br&gt; max: 3.56 &lt;br&gt; 95th percentile: 1.47 &lt;br&gt; sum: 39975.16 &lt;br&gt;&lt;br&gt; Threads fairness:&lt;br&gt; events (avg/stddev): 7134.0000/39.87 &lt;br&gt; execution time (avg/stddev): 9.9938/0.01&lt;/p&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;Whether &lt;code&gt;ChatGPT&lt;/code&gt; is a good thing or not, the table above couldn’t be arranged according to previously mastered &lt;code&gt;Markdown&lt;/code&gt;, and failing to create a table would result in a poor display effect. Customizing the theme limited the maximum width of the page, so I adjusted the configuration of the pages accordingly, changing the width to percentage limits.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A simple method is to use tools like TablesGenerator to generate HTML tables (content complexity doesn’t suit this).&lt;/li&gt;
&lt;li&gt;Or you can write it in Google Docs and then download and save it as an HTML document, directly copy it into a blog (simple and direct, which was ultimately adopted).
Ensure that the config is enabled with unsafe configuration items, and give the page configuration width separately. In Hugo, you can set the width of a page individually. This can be achieved by adding custom parameters in the page’s Front Matter. Here&amp;rsquo;s an example: - In your Markdown page&amp;rsquo;s Front Matter section (typically at the beginning of the file), add a custom parameter, such as &lt;code&gt;custom_width&lt;/code&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;---
title: &amp;quot;My Page&amp;quot;
date: 2024-01-09
custom_width: &amp;quot;800px&amp;quot;  # Set width to 800 pixels
---

Content...
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;epilogue-1&#34;&gt;Epilogue
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;In your Hugo theme, find or create the corresponding single page template file (e.g., &lt;code&gt;layouts/_default/single.html&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Within the single page template, check if there is a &lt;code&gt;custom_width&lt;/code&gt; parameter in the page&amp;rsquo;s Front Matter and apply it to the relevant HTML elements, such as &lt;code&gt;div&lt;/code&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;{{ define &amp;quot;main&amp;quot; }}
  &amp;lt;div style=&amp;quot;max-width: {{ with .Params.custom_width }}{{ . }}{{ else }}100%{{ end }}; margin: 0 auto;&amp;quot;&amp;gt;
    {{ .Content }}
  &amp;lt;/div&amp;gt;
{{ end }}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, we&amp;rsquo;ve used inline styles (&lt;code&gt;style&lt;/code&gt; attribute) to set the &lt;code&gt;max-width&lt;/code&gt; property on the &lt;code&gt;div&lt;/code&gt; element, making it default to 100% when no &lt;code&gt;custom_width&lt;/code&gt; parameter is specified. &lt;code&gt;margin: 0 auto;&lt;/code&gt; is used to center the &lt;code&gt;div&lt;/code&gt; element.&lt;/p&gt;
&lt;h2 id=&#34;postscript&#34;&gt;Postscript
&lt;/h2&gt;&lt;p&gt;Please note that in actual applications, you may need to adjust the examples above based on your theme structure and CSS styling details. Ensure that when adjusting styles, you maintain consistency and readability of the theme.
Due to slight differences in the enabled theme, the site’s custom &lt;code&gt;CSS&lt;/code&gt; configuration was finally adjusted.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Docker Basics, Intermediate, and Advanced</title>
        <link>https://ttf248.life/en/p/docker-two-three-things/</link>
        <pubDate>Thu, 21 Jan 2021 09:26:07 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/docker-two-three-things/</guid>
        <description>&lt;p&gt;Having worked with CentOS for many years, content may not apply to macOS or Ubuntu users in some cases.&lt;/p&gt;
&lt;p&gt;You can refer to the documentation from Tsinghua University for installation guidance: &lt;a class=&#34;link&#34; href=&#34;https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation
&lt;/h2&gt;&lt;p&gt;Due to unknown mysterious forces, installing Docker domestically is recommended to set the cloud vendor&amp;rsquo;s repository address. Here we recommend using &lt;strong&gt;Alibaba Cloud&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;set-repository-source-address&#34;&gt;Set Repository Source Address
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum install yum-utils device-mapper-persistent-data lvm2 &amp;amp;&amp;amp; \
sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;deploy-the-latest-version&#34;&gt;Deploy the Latest Version
&lt;/h3&gt;&lt;p&gt;Docker is a commonly used background service, we recommend setting it to start on boot. The following command applies to CentOS 7:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo yum install -y docker-ce docker-ce-cli containerd.io &amp;amp;&amp;amp; systemctl enable --now docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;deploying-a-specific-version&#34;&gt;Deploying a Specific Version
&lt;/h3&gt;&lt;p&gt;The releases of &lt;code&gt;kubernetes&lt;/code&gt; and &lt;code&gt;docker&lt;/code&gt; are not fully synchronized. If you need to deploy &lt;code&gt;kubernetes&lt;/code&gt; subsequently, refer to the &lt;code&gt;kubernetes&lt;/code&gt; deployment instructions and install a specific version of &lt;code&gt;docker&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum list docker-ce --showduplicates | sort -r
sudo yum install -y docker-ce-18.09.2-3.el7 docker-ce-cli-18.09.2-3.el7 containerd.io-18.09.2-3.el7 &amp;amp;&amp;amp; systemctl enable --now docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;adding-docker-permissions-for-regular-users&#34;&gt;Adding Docker Permissions for Regular Users
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo usermod -aG docker ${USER}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;uninstall&#34;&gt;Uninstall
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo yum erase -y docker-ce docker-ce-cli containerd.io
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;everyday-use&#34;&gt;Everyday Use
&lt;/h2&gt;&lt;h3 id=&#34;mirror-acceleration&#34;&gt;Mirror Acceleration
&lt;/h3&gt;&lt;p&gt;There’s still an unknown mysterious force that causes slow image pulls. At this time, domestic cloud vendors have emerged and provided many acceleration services, which are still recommended – &lt;strong&gt;Alibaba Cloud&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The acceleration addresses can be managed by you registering an Alibaba Cloud account; this service is free. Alibaba Cloud also offers a free image build service.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cat &amp;gt; /etc/docker/daemon.json &amp;lt;&amp;lt;EOF
{
  &amp;quot;registry-mirrors&amp;quot;: [
    &amp;quot;https://docker.nju.edu.cn&amp;quot;,
    &amp;quot;https://mirror.baidubce.com&amp;quot;,
    &amp;quot;https://docker.m.daocloud.io&amp;quot;,
    &amp;quot;https://docker.mirrors.sjtug.sjtu.edu.cn&amp;quot;
  ]
}
EOF
systemctl daemon-reload &amp;amp;&amp;amp; \
systemctl restart docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;recommended-control-panels&#34;&gt;Recommended Control Panels
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker volume create portainer_data &amp;amp;&amp;amp; \
docker run -d --name=portainer --restart=always -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:2.20.3-alpine
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;frequently-used-image-pull-list&#34;&gt;Frequently Used Image Pull List
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker pull rancher/rancher:stable &amp;amp;&amp;amp; docker pull portainer/portainer-ce:2.0.1 &amp;amp;&amp;amp; \
docker pull centos:7 &amp;amp;&amp;amp; docker pull ubuntu:20.04 &amp;amp;&amp;amp; docker pull ubuntu:18.04 &amp;amp;&amp;amp; \
docker pull redis:5 &amp;amp;&amp;amp; docker pull redis:6 &amp;amp;&amp;amp; \
docker pull alpine:3.11 &amp;amp;&amp;amp; docker pull busybox:1.32 &amp;amp;&amp;amp; \
docker pull rabbitmq:3.7-management &amp;amp;&amp;amp; \
docker pull mariadb:10.2 &amp;amp;&amp;amp; \
docker pull nginx:1.18 &amp;amp;&amp;amp; docker pull nginx:1.19 &amp;amp;&amp;amp; \
docker pull mysql:5.6 &amp;amp;&amp;amp; docker pull mysql:8 &amp;amp;&amp;amp; \
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;frequently-used-image-pull-list-1&#34;&gt;Frequently Used Image Pull List
&lt;/h3&gt;&lt;p&gt;docker pull mysql:5.6 &amp;amp;&amp;amp; docker pull mysql:8 &amp;amp;&amp;amp; &lt;br&gt;
docker pull elasticsearch:6.8.11 &amp;amp;&amp;amp; docker pull logstash:6.8.11 &amp;amp;&amp;amp; docker pull kibana:6.8.11 &amp;amp;&amp;amp; &lt;br&gt;
docker pull zookeeper:3.4 &amp;amp;&amp;amp; &lt;br&gt;
docker pull influxdb:1.7 &amp;amp;&amp;amp; docker pull grafana/grafana:7.3.1 &amp;amp;&amp;amp; &lt;br&gt;
docker pull percona:8 &amp;amp;&amp;amp; docker pull percona:5.6 &amp;amp;&amp;amp; &lt;br&gt;
docker pull cloverzrg/frps-docker:0.34.3 &amp;amp;&amp;amp; docker pull cloverzrg/frpc-docker:0.34.3&lt;/p&gt;
&lt;h3 id=&#34;common-command-combinations&#34;&gt;Common Command Combinations
&lt;/h3&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.docker.com/engine/reference/commandline/docker/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://docs.docker.com/engine/reference/commandline/docker/&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;View container running status, append the &lt;code&gt;format&lt;/code&gt; parameter to view detailed container information, without focusing on image information:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker ps --format &amp;quot;{{.Names}}: {{.Ports}}: {{.Size}}&amp;quot;
#portainer: 0.0.0.0:8000-&amp;gt;8000/tcp, 0.0.0.0:9000-&amp;gt;9000/tcp: 0B (virtual 172MB)
#influxdb: 0.0.0.0:8086-&amp;gt;8086/tcp: 183B (virtual 311MB)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;Stop all containers with a single command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker stop $(docker ps -a -q)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Delete all images with a single command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;dokcer rmi $(docker images -a -q)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;Export image&lt;/p&gt;
&lt;h3 id=&#34;common-combination-commands&#34;&gt;Common Combination Commands
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker save &amp;lt;IMAGE NAME&amp;gt;:&amp;lt;IMAGE TAG&amp;gt; &amp;gt; -o XXX.tar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Export image and compress&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker save &amp;lt;IMAGE NAME&amp;gt;:&amp;lt;IMAGE TAG&amp;gt; | gzip &amp;gt; XXX.tar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Import image&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker load -i XXX.tar
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Linux Setup JMeter Test Environment</title>
        <link>https://ttf248.life/en/p/linux-setup-jmeter-testing-environment/</link>
        <pubDate>Tue, 22 Dec 2020 10:12:50 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-setup-jmeter-testing-environment/</guid>
        <description>&lt;p&gt;The author has a strong interest in hardware and used JMeter to conduct load testing, documenting the process of deploying JMeter, InfluxDB, and Grafana on CentOS 7. They shared installation and command usage for JMeter, InfluxDB’s features and Docker installation method, as well as simple deployment and configuration for Grafana. They summarized experience and references related to high-performance programming patterns.&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background
&lt;/h2&gt;&lt;p&gt;As widely known, I have a very strong interest in hardware. By chance, the test team was using &lt;code&gt;JMeter&lt;/code&gt; to perform load tests and discovered that performance wasn&amp;rsquo;t improving. As a curious individual, I decisively took action to see how the company conducted its testing. There’s also a small story: at some point in the distant past, I read a post on OpenChina about how to create more impressive-looking performance test graphs – after observing &lt;code&gt;Windows&lt;/code&gt; versions execute tests and achieving visualized &lt;code&gt;TPS&lt;/code&gt; data display, what&amp;rsquo;s the use of configuring a web panel?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Thinking is all well and good, but you have to try it yourself to understand.
Don’t use GUI mode for load testing! only for Test creation and Test debugging.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;background-1&#34;&gt;Background
&lt;/h2&gt;&lt;p&gt;Officially, it’s recommended to obtain test reports via the command line and display them using a GUI, which introduces data errors.  I don&amp;rsquo;t have deep knowledge of JMeter – at least I found a reason to tinker with a &lt;code&gt;Linux&lt;/code&gt; version console panel. The openchinese post’s core component deployment isn’t friendly; you need to follow their WeChat channel to download the required files, and as a millennial, of course I used &lt;code&gt;Docker&lt;/code&gt; instead. Basically, my server is located domestically, and accessing the overseas source addresses is very slow – at least using an image service, Alibaba Cloud has a free acceleration.&lt;/p&gt;
&lt;p&gt;Regarding &lt;code&gt;docker&lt;/code&gt; installation and deployment, this will not be elaborated on here; please refer to previous articles for recommendations.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;The following content focuses on two main areas: setting up the basic test environment components and a simple explanation of each component.&lt;/p&gt;
&lt;h2 id=&#34;jmeter&#34;&gt;JMeter
&lt;/h2&gt;&lt;p&gt;Apache JMeter is a Java-based load testing tool developed by the Apache Software Foundation. It’s used to perform stress tests on software, initially designed for web application testing but later expanded to other testing domains. It can be used to test static and dynamic resources such as static files, Java microservices, CGI scripts, Java objects, databases, FTP servers, etc. JMeter can simulate massive loads from various stress categories onto servers, networks, or objects to test their strength and analyze overall performance. Furthermore, JMeter can perform functional/regression testing on applications by creating scripts with assertions to validate that your program returns the expected results. To maximize flexibility, JMeter allows using regular expressions to create assertions. Apache JMeter can be used to perform performance testing of static and dynamic resources (files, Servlets, Perl scripts, Java objects, databases and queries, FTP servers, etc.). It can be used to simulate heavy loads on servers, networks, or objects to test their strength or analyze overall performance under different stress types. You can use it for graphical analysis of performance metrics or for large concurrent load testing of your server/script/object.&lt;/p&gt;
&lt;h3 id=&#34;jmeter-deployment-on-centos7&#34;&gt;Jmeter Deployment on CentOS7
&lt;/h3&gt;&lt;p&gt;Install the &lt;code&gt;JDK&lt;/code&gt; runtime environment, download the &lt;code&gt;Jmeter&lt;/code&gt; installation package:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum install java-1.8.0-openjdk -y &amp;amp;&amp;amp; \
wget https://mirrors.bfsu.edu.cn/apache//jmeter/binaries/apache-jmeter-5.4.tgz &amp;amp;&amp;amp; tar -xf apache-jmeter-5.4.tgz
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Configure environment variables:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export JMETER_HOME=$HOME/jmeter/apache-jmeter-5.4
export PATH=$JMETER_HOME/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;jmeter-commands&#34;&gt;JMeter Commands
&lt;/h3&gt;&lt;p&gt;Finally, it will be connected to the &lt;code&gt;Grafana&lt;/code&gt; dashboard, and you don&amp;rsquo;t need to input the &lt;code&gt;-l&lt;/code&gt; parameter to observe data in the &lt;code&gt;web&lt;/code&gt; console.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;jmeter -n -t /tmp/order-500-10s.jmx -l /tmp/jmeter-order-report-20200109/order-500-10s.jtl
# Generally, don&#39;t use test results and test reports to simplify the command
jmeter -n -t /tmp/order-500-10s.jmx
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;influxdb&#34;&gt;InfluxDB
&lt;/h2&gt;&lt;p&gt;InfluxDB is an open-source distributed time series database written in Go. It requires no external dependencies. The database is now primarily used for storing large volumes of timestamped data such as DevOps monitoring data, app metrics, IoT sensor data, and real-time analytics data.&lt;/p&gt;
&lt;h3 id=&#34;influxdb-features&#34;&gt;InfluxDB Features
&lt;/h3&gt;&lt;p&gt;InfluxDB’s features can be summarized into the following 9 aspects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Schema-less (Schemaless):&lt;/strong&gt; Can accommodate an arbitrary number of columns;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Metric Retention Time Setting:&lt;/strong&gt;  Allows setting retention times for metrics;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Support for Time-Related Functions:&lt;/strong&gt; Supports functions related to time (such as min, max, sum, count, mean, median, etc.) for convenient statistical analysis;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Storage Policy Support:&lt;/strong&gt; Can be used for data deletion and modification (InfluxDB does not provide direct methods for deleting or modifying data);&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Continuous Query Support:&lt;/strong&gt;  Automatically scheduled sets of queries that run continuously, combined with storage policies to reduce InfluxDB’s system footprint;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Native HTTP Support:&lt;/strong&gt; Built-in HTTP API;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Support for Similar SQL Syntax:&lt;/strong&gt; Supports a syntax similar to SQL;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Support for Setting Replica Count in Clusters:&lt;/strong&gt; Allows setting the number of replicas for data within clusters;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Support for Periodic Data Sampling:&lt;/strong&gt;  Allows sampling data periodically and writing it to another measurement, facilitating granular data storage.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;influxdb-docker-installation&#34;&gt;InfluxDB Docker Installation
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mkdir influxdb &amp;amp;&amp;amp; cd influxdb &amp;amp;&amp;amp; \
docker run -p 8086:8086 -d --name influxdb -v $PWD:/var/lib/influxdb influxdb:1.7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;docker exec -it influxdb /bin/bash&lt;/code&gt; enters the container, executes commands, and manually creates a database&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;root@bce0a55bbc72:/# influx
Connected to http://localhost:8086 version 1.7.10
InfluxDB shell version: 1.7.10
&amp;gt; Execute commands in the interactive shell
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;influxdb-database-and-user-creation&#34;&gt;InfluxDB Database and User Creation
&lt;/h3&gt;&lt;p&gt;Create database: &lt;code&gt;create database jmeter_t2&lt;/code&gt;
View databases: &lt;code&gt;show databases&lt;/code&gt;
Switch to database: &lt;code&gt;use jmeter_t2&lt;/code&gt;
Create user: &lt;code&gt;create user &amp;quot;admin&amp;quot; with password &#39;admin&#39; with all privileges&lt;/code&gt;
View users: &lt;code&gt;show users&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;&amp;gt; show users
user  admin
----  -----
admin true
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the user permissions for &lt;code&gt;admin&lt;/code&gt; are displayed as &lt;code&gt;true&lt;/code&gt;, the database setup is complete.&lt;/p&gt;
&lt;h2 id=&#34;grafana&#34;&gt;Grafana
&lt;/h2&gt;&lt;p&gt;When writing test cases, it was found that the effect of chart visualization is not very necessary; the &lt;code&gt;tps&lt;/code&gt; data from the interface can be observed when executed in the command line, and more importantly, we wanted to know the internal timing of the program.&lt;/p&gt;
&lt;p&gt;A simple deployment of the &lt;code&gt;grafana&lt;/code&gt; console panel and importing a configuration file to connect with &lt;code&gt;InfluxDB&lt;/code&gt; was performed. The console supports filtering test results through tags; generally, only one &lt;code&gt;InfluxDB&lt;/code&gt; database needs to be configured:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Application Name&lt;/li&gt;
&lt;li&gt;Test Case Name&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/linux-setup-jmeter-testing-environment/Snipaste_2021-03-09_19-44-22.png&#34;
	width=&#34;861&#34;
	height=&#34;357&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;grafana&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;241&#34;
		data-flex-basis=&#34;578px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -d --name=grafana -p 3000:3000 grafana/grafana:7.3.1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Due to the sampling interval in the web version, the calculated &lt;code&gt;TPS&lt;/code&gt; and related values do not match the aggregated report from &lt;code&gt;JMeter&lt;/code&gt;. Please refer to this link: &lt;a class=&#34;link&#34; href=&#34;https://www.vinsguru.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.vinsguru.com/jmeter-real-time-results-influxdb-grafana/&lt;/a&gt; ## Grafana&lt;/p&gt;
&lt;p&gt;When writing test cases, it was found that the chart visualization effect is not very necessary; the &lt;code&gt;tps&lt;/code&gt; data from the interface can be observed when executed in the command line, and more importantly, we wanted to know the internal timing of the program.&lt;/p&gt;
&lt;p&gt;A simple deployment of the &lt;code&gt;grafana&lt;/code&gt; console panel and importing a configuration file to connect with &lt;code&gt;InfluxDB&lt;/code&gt; was performed. The console supports filtering test results through tags; generally, only one &lt;code&gt;InfluxDB&lt;/code&gt; database needs to be configured:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Application Name&lt;/li&gt;
&lt;li&gt;Test Case Name&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/linux-setup-jmeter-testing-environment/Snipaste_2021-03-09_19-44-22.png&#34;
	width=&#34;861&#34;
	height=&#34;357&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;grafana&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;241&#34;
		data-flex-basis=&#34;578px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -d --name=grafana -p 3000:3000 grafana/grafana:7.3.1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Due to the sampling interval in the web version, the calculated &lt;code&gt;TPS&lt;/code&gt; and related values do not match the &lt;code&gt;JMeter&lt;/code&gt; aggregated report. Please refer to this link: &lt;a class=&#34;link&#34; href=&#34;https://www.vinsguru.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.vinsguru.com/jmeter-real-time-results-influxdb-grafana/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;High-performance program patterns invariably are one-loop thread; any locks, enqueueing, and dequeueing will cause unnecessary performance loss.&lt;/li&gt;
&lt;li&gt;The time spent on core business logic is greater than the time spent introducing other code; concurrency can effectively improve efficiency only when the core latency is sufficiently large; otherwise, it’s best to be cautious about introducing other code.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://my.oschina.net/u/4617935/blog/4680856&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;JMeter Series - JMeter + Grafana + InfluxDB Real-time Monitoring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://hub.docker.com/_/influxdb&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;InfluxDB Official Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://hub.docker.com/r/grafana/grafana&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Grafana Official Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://jmeter.apache.org/download_jmeter.cgi&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;JMeter Website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/@jasonli.studio/to-install-apache-jmeter-in-centos7-294bc72a97ba&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;To Install Apache JMeter in CentOS7&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Red Hat and CentOS Lifecycle</title>
        <link>https://ttf248.life/en/p/redhat-centos-lifecycle/</link>
        <pubDate>Tue, 21 Jul 2020 20:02:35 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/redhat-centos-lifecycle/</guid>
        <description>&lt;p&gt;Production environment operating systems, with Red Hat and CentOS being the mainstream choices. The documentation includes links to two system lifecycles and shares experience upgrading from CentOS 8 to CentOS Stream 8.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction
&lt;/h2&gt;&lt;p&gt;In the current domestic environment, Red Hat and CentOS are the mainstream choices for production environments. After experiencing the retirement of Red Hat 6 two years ago, this record specifically documents the official website links for the lifecycles of these two systems.&lt;/p&gt;
&lt;h2 id=&#34;main-content&#34;&gt;Main Content
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://access.redhat.com/support/policy/updates/errata&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Red Hat Enterprise Linux Life Cycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://wiki.centos.org/zh/About/Product&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CentOS Product Specifications&lt;/a&gt;
Red Hat Enterprise Linux (RHEL) and CentOS are the mainstream choices for enterprise servers. RHEL provides stable support and update cycles, suitable for enterprise applications. CentOS as RHEL&amp;rsquo;s community edition, offers similar functionality and stability but without official support.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;follow-up&#34;&gt;Follow-up
&lt;/h2&gt;&lt;p&gt;When publishing this article, I didn’t expect to update it two years later. Just a few days ago, I upgraded my daily virtual machine from CentOS 8 to CentOS 8 Stream. I can&amp;rsquo;t say much about what to choose in production – I prefer to keep the latest version in my local environment.&lt;/p&gt;
&lt;p&gt;CentOS 8 Stream is a rolling release version that offers faster updates and new features than traditional CentOS, making it suitable for development and testing environments.&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

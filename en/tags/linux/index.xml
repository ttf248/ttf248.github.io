<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Linux on Uncle Xiang&#39;s Notebook</title>
        <link>https://blog.ttf248.life/en/tags/linux/</link>
        <description>Recent content in Linux on Uncle Xiang&#39;s Notebook</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Wed, 28 May 2025 09:47:38 +0800</lastBuildDate><atom:link href="https://blog.ttf248.life/en/tags/linux/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Monitoring Linux System Metrics with atop: A Complete Guide to Installation, Configuration, and Usage</title>
        <link>https://blog.ttf248.life/en/p/using-atop-to-monitor-linux-system-metrics-installation-configuration-and-usage-guide/</link>
        <pubDate>Thu, 06 Feb 2025 22:48:55 +0800</pubDate>
        
        <guid>https://blog.ttf248.life/en/p/using-atop-to-monitor-linux-system-metrics-installation-configuration-and-usage-guide/</guid>
        <description>&lt;p&gt;Real-time and comprehensive monitoring of system resources and process status is crucial in Linux system maintenance. The atop tool, as a powerful monitoring utility, can help us achieve this goal easily. This article will detail how to install, configure, and use the atop monitoring tool on a Linux instance.&lt;/p&gt;
&lt;h2 id=&#34;introduction-to-atop-tool&#34;&gt;Introduction to atop tool
&lt;/h2&gt;&lt;p&gt;Atop is a tool dedicated to monitoring Linux system resources and processes. It records system and process activity, reporting on the status of all running processes. Data collected includes resource usage (CPU, memory, disk, network) and process states, which can be saved as log files. For each process, we obtain key information such as CPU utilization, memory growth, disk usage, priority, username, status, and exit code. Furthermore, through the Atop configuration file, users can customize parameters like logging frequency, storage path, and rotation policy.&lt;/p&gt;
&lt;h2 id=&#34;installing-atop-tool&#34;&gt;Installing atop tool
&lt;/h2&gt;&lt;p&gt;Installation methods for atop vary slightly across different Linux distributions; the following explanation uses a common operating system as an example&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Alibaba Cloud Linux 3/2、CentOS 7/8、Fedora、Rocky Linux 9&lt;/strong&gt;：&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Execute installation command:&lt;/li&gt;
&lt;li&gt;Start atop service:&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;Ubuntu / Debian&lt;/strong&gt;：&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Update software source list:&lt;/li&gt;
&lt;li&gt;Execute installation command:&lt;/li&gt;
&lt;li&gt;Start atop service:&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;CentOS Stream 9&lt;/strong&gt;：&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Download and install:&lt;/li&gt;
&lt;li&gt;Start atop service:&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;openSUSE&lt;/strong&gt;：&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Execute installation command:&lt;/li&gt;
&lt;li&gt;Start atop service:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If your operating system distribution is not listed above, please visit the atop official website for installation information&lt;/p&gt;
&lt;h2 id=&#34;configure-monitoring-cycle-and-log-retention-time&#34;&gt;Configure monitoring cycle and log retention time
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;In Alibaba Cloud Linux 3/2, CentOS 7/8, and Fedora systems, the atop configuration file is __；在Ubuntu、Debian和openSUSE系统中，配置文件是__INLINE_CODE_1&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Used to control log file recording options; defaults to empty&lt;/li&gt;
&lt;li&gt;Monitoring cycle, default 600 seconds. To collect historical logs for troubleshooting, adjust this frequency as needed.&lt;/li&gt;
&lt;li&gt;Log retention period, default 28 days&lt;/li&gt;
&lt;li&gt;It appears you&amp;rsquo;ve provided a string of formatting codes rather than actual Chinese text. Without the Chinese characters, I cannot translate. Please provide the Chinese text you want translated.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Execute command to open configuration file:&lt;/li&gt;
&lt;li&gt;On Alibaba Cloud Linux 3/2, CentOS 7/8, and Fedora systems:&lt;/li&gt;
&lt;li&gt;In Ubuntu, Debian, openSUSE, CentOS Stream 9, Rocky Linux 9 systems:&lt;/li&gt;
&lt;li&gt;Enter edit mode by pressing &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;, then adjust the configuration parameters as needed. For example, change the monitoring cycle to 30 seconds, set the log retention time to 7 days, and keep the default log path:&lt;/li&gt;
&lt;li&gt;Press, save, and exit editing&lt;/li&gt;
&lt;li&gt;Restarting the atop service applies the configuration&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;LOGOPTS=&amp;quot;&amp;quot;
LOGINTERVAL=30
LOGGENERATIONS=7
LOGPATH=/var/log/atop 
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;using-the-atop-tool&#34;&gt;Using the atop tool
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;The following are common commands in interactive command mode:&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Switch back to the default combined output view&lt;/li&gt;
&lt;li&gt;Display the full command line of processes&lt;/li&gt;
&lt;li&gt;Sort by process memory usage in descending order&lt;/li&gt;
&lt;li&gt;Sort processes by disk usage in descending order&lt;/li&gt;
&lt;li&gt;Sort by process resource utilization in descending order&lt;/li&gt;
&lt;li&gt;Sort by process network usage in descending order&lt;/li&gt;
&lt;li&gt;Go to the next monitoring point&lt;/li&gt;
&lt;li&gt;Go to the previous monitoring point&lt;/li&gt;
&lt;li&gt;It appears you&amp;rsquo;ve provided a string of formatting codes rather than actual Chinese text. Without the Chinese characters, I cannot translate. Please provide the Chinese text you want translated.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Hostname, information sampling date and time&lt;/li&gt;
&lt;li&gt;Overall process runtime information, including kernel and user space execution time, total number of processes, and the count of processes in different states&lt;/li&gt;
&lt;li&gt;Overall CPU utilization, the sum of values for each field equals &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; (N being the number of CPU cores), including kernel time, user time, interrupts, idle time, and wait for disk I/O&lt;/li&gt;
&lt;li&gt;CPU load information, such as the average number of processes in the run queue over the past 1, 5, and 15 minutes, context switch count, and interrupt occurrence count&lt;/li&gt;
&lt;li&gt;Memory usage, including total physical memory, idle memory, page cache memory, file cache memory, and kernel occupied memory&lt;/li&gt;
&lt;li&gt;Swap space usage, including total swap area and free swap space size&lt;/li&gt;
&lt;li&gt;Virtual memory paging information, such as page swap in and swap out counts&lt;/li&gt;
&lt;li&gt;Disk usage, with each disk device represented by a column, displaying device identifier, busy time ratio, and read/write request count&lt;/li&gt;
&lt;li&gt;Network conditions, displaying receive and send packet sizes for TCP/UDP, IP layer, and active network interfaces&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Check system metrics every 5 seconds&lt;/li&gt;
&lt;li&gt;Check system metrics within the next 5 minutes (30 times, 10-second intervals): &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Check system metrics 10 minutes after the current time (10 times, with 60-second intervals) and write the results to a file: &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;After &lt;strong&gt;查看历史指标日志&lt;/strong&gt; starts, log records are saved by default in the &lt;code&gt;/var/log/atop&lt;/code&gt; directory. When viewing, ensure the log file for the specified date exists, otherwise an error will occur.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;View daily history indicator logs&lt;/li&gt;
&lt;li&gt;View yesterday&amp;rsquo;s historical metric logs:&lt;/li&gt;
&lt;li&gt;View historical metric logs for a specified date, such as November 6, 2024&lt;/li&gt;
&lt;li&gt;View historical indicator logs from a specified time within a designated date range, such as from 2:00 PM on November 6, 2024&lt;/li&gt;
&lt;li&gt;View historical indicator logs for a specified date and time period, such as from 00:04 to 00:08 on November 5, 2024&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;View the CPU utilization report for the current system over 1 minute (12 times, with 5-second intervals): &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;View memory indicator reports for a specified time period on a given day, such as 18:00 to 18:01&lt;/li&gt;
&lt;li&gt;View memory metrics reports for specified dates and time periods, such as 6:00 PM to 6:01 PM on November 5, 2024&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;other-operations&#34;&gt;Other Operations
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;To generate an atop index log file daily, you can do the following:&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Adjust monitoring cycle, log retention time, and log storage path as needed&lt;/li&gt;
&lt;li&gt;Start the daily log rotation service and enable it to start automatically at boot&lt;/li&gt;
&lt;li&gt;If the business has more complex requirements for log processing, it can be combined with logrotate or custom scripts to implement log management&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;If network usage monitoring is required, you can install the netatop module (which is not installed by default in atop). For example, using Alibaba Cloud Linux 3 system:&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Install the kernel development package and software environment required for compilation&lt;/li&gt;
&lt;li&gt;Download the latest version of netatop source code to the designated directory&lt;/li&gt;
&lt;li&gt;Unzip the source code and enter the source directory: &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Build and install modules and daemons from source code&lt;/li&gt;
&lt;li&gt;Start netatop service:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The atop tool is powerful and flexible. With proper installation, configuration, and usage, we can better understand the status of a Linux system, promptly identify and resolve potential issues. We hope this article helps everyone improve their Linux system monitoring skills.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Slow efficiency when processing large string data in Linux backend services</title>
        <link>https://blog.ttf248.life/en/p/linux-backend-slow-string-processing/</link>
        <pubDate>Wed, 13 Nov 2024 19:42:59 +0800</pubDate>
        
        <guid>https://blog.ttf248.life/en/p/linux-backend-slow-string-processing/</guid>
        <description>&lt;p&gt;In past C++ development projects, we used a custom protocol for communication that employed a two-dimensional array structure. Due to inefficient traversal and serialization of this array when handling large amounts of data, the system experienced noticeable lag under high load, prompting feedback from the business department regarding these slowdowns.&lt;/p&gt;
&lt;h2 id=&#34;issue-identification&#34;&gt;Issue identification
&lt;/h2&gt;&lt;p&gt;During troubleshooting, we first performed a performance analysis of the system. We found that CPU usage increased significantly and response times lengthened when processing large amounts of data. Analyzing system logs revealed numerous serialization operations, which were inefficient when handling two-dimensional arrays, leading to decreased system performance.&lt;/p&gt;
&lt;p&gt;The tool&amp;rsquo;s thread analysis revealed that the logging thread spends most of its time string concatenation&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The key takeaway today is that different accumulation methods have vastly different efficiencies. Legacy code used the &lt;code&gt;__INLINE_CODE_0&lt;/code&gt; operator, which frequently creates temporary objects and is very inefficient—the kind of inefficiency you know is bad but don&amp;rsquo;t realize just how bad it is.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;demo-verification&#34;&gt;Demo verification
&lt;/h2&gt;&lt;p&gt;We extracted the business logic based on the project code and created a simple demo to verify the efficiency of string concatenation. We compared the efficiency while compiling and running it in &lt;code&gt;windows&lt;/code&gt; 下的 &lt;code&gt;vs2022&lt;/code&gt; 编译器，&lt;strong&gt;INLINE_CODE_2&lt;/strong&gt; 下的 &lt;strong&gt;INLINE_CODE_3&lt;/strong&gt; 编译器，&lt;strong&gt;INLINE_CODE_4&lt;/strong&gt; mode.&lt;/p&gt;
&lt;h3 id=&#34;key-points&#34;&gt;Key points
&lt;/h3&gt;&lt;p&gt;The project uses method four. Before receiving the test data, readers can first consider which approach is most efficient and which is least efficient. I was still surprised by the results.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Concatenate each field directly into a string&lt;/li&gt;
&lt;li&gt;Using streams (concatenating) to join each field is more efficient, especially when dealing with large amounts of data&lt;/li&gt;
&lt;li&gt;Pre-allocating sufficient memory for strings reduces the overhead of memory reallocation, thereby improving performance&lt;/li&gt;
&lt;li&gt;Creating a new temporary string object for each concatenation degrades performance, especially during large-scale concatenations, as it involves repeated memory allocation and copying&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Based on the results, the project selected the least efficient method&lt;/p&gt;
&lt;p&gt;Furthermore, let&amp;rsquo;s analyze the optimization efficiency of different platforms&amp;rsquo; compilers. Microsoft&amp;rsquo;s compiler falls short in this regard.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Running the code on different machines makes direct comparison of the data meaningless; instead, compare the differences between different concatenation methods&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;windows 平台下的 vs2022 编译器

----------------------------------------
Data Generation Time: 0.054 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.053 seconds.
+ ostringstream Data merging took: 0.054 seconds.
+ Pre-reserved Data merging took: 0.045 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 16.108 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;linux 平台下的 gcc8.5 编译器
----------------------------------------
Data Generation Time: 0.108 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.100 seconds.
+ ostringstream Data merging took: 0.083 seconds.
+ Pre-reserved Data merging took: 0.057 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 29.298 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code&#34;&gt;Complete code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;random&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;sstream&amp;gt;
#include &amp;lt;iomanip&amp;gt;

typedef std::vector&amp;lt;std::string&amp;gt; DataRow;
typedef std::vector&amp;lt;DataRow&amp;gt; DataGroup;

struct ResponsePackage
{
    std::string ErrorInfo;
    DataRow Head;
    std::string ClientId;
    std::string UUID;
    std::string MsgID;
    std::string SessionID;
    std::string ExtraInfo1;
    std::string ExtraInfo2;
    DataGroup DataBody;
};

// Generate specified length of random string
std::string generateRandomString(size_t length)
{
    const char charset[] = &amp;quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&amp;quot;;
    const size_t max_index = sizeof(charset) - 1;
    std::string random_string;
    random_string.reserve(length);

    std::random_device rd;
    std::mt19937 generator(rd());
    std::uniform_int_distribution&amp;lt;&amp;gt; distribution(0, max_index);

    for (size_t i = 0; i &amp;lt; length; ++i)
    {
        random_string += charset[distribution(generator)];
    }

    return random_string;
}

void create_large_string()
{
    // Example request package with 50 fields
    ResponsePackage requestPackage;

    requestPackage.Head = {
        &amp;quot;Field1&amp;quot;, &amp;quot;Field2&amp;quot;, &amp;quot;Field3&amp;quot;, &amp;quot;Field4&amp;quot;, &amp;quot;Field5&amp;quot;,
        &amp;quot;Field6&amp;quot;, &amp;quot;Field7&amp;quot;, &amp;quot;Field8&amp;quot;, &amp;quot;Field9&amp;quot;, &amp;quot;Field10&amp;quot;,
        &amp;quot;Field11&amp;quot;, &amp;quot;Field12&amp;quot;, &amp;quot;Field13&amp;quot;, &amp;quot;Field14&amp;quot;, &amp;quot;Field15&amp;quot;,
        &amp;quot;Field16&amp;quot;, &amp;quot;Field17&amp;quot;, &amp;quot;Field18&amp;quot;, &amp;quot;Field19&amp;quot;, &amp;quot;Field20&amp;quot;,
        &amp;quot;Field21&amp;quot;, &amp;quot;Field22&amp;quot;, &amp;quot;Field23&amp;quot;, &amp;quot;Field24&amp;quot;, &amp;quot;Field25&amp;quot;,
        &amp;quot;Field26&amp;quot;, &amp;quot;Field27&amp;quot;, &amp;quot;Field28&amp;quot;, &amp;quot;Field29&amp;quot;, &amp;quot;Field30&amp;quot;,
        &amp;quot;Field31&amp;quot;, &amp;quot;Field32&amp;quot;, &amp;quot;Field33&amp;quot;, &amp;quot;Field34&amp;quot;, &amp;quot;Field35&amp;quot;,
        &amp;quot;Field36&amp;quot;, &amp;quot;Field37&amp;quot;, &amp;quot;Field38&amp;quot;, &amp;quot;Field39&amp;quot;, &amp;quot;Field40&amp;quot;,
        &amp;quot;Field41&amp;quot;, &amp;quot;Field42&amp;quot;, &amp;quot;Field43&amp;quot;, &amp;quot;Field44&amp;quot;, &amp;quot;Field45&amp;quot;,
        &amp;quot;Field46&amp;quot;, &amp;quot;Field47&amp;quot;, &amp;quot;Field48&amp;quot;, &amp;quot;Field49&amp;quot;, &amp;quot;Field50&amp;quot;
    };

    requestPackage.ClientId = &amp;quot;ClientID&amp;quot;;
    requestPackage.UUID = &amp;quot;UUID&amp;quot;;
    requestPackage.MsgID = &amp;quot;MsgID&amp;quot;;
    requestPackage.SessionID = &amp;quot;SessionID&amp;quot;;
    requestPackage.ExtraInfo1 = &amp;quot;ExtraInfo1&amp;quot;;
    requestPackage.ExtraInfo2 = &amp;quot;ExtraInfo2&amp;quot;;

    // Start timing for data generation
    auto start_gen = std::chrono::high_resolution_clock::now();

    // Generate 10,000 rows of data, each with 50 fields
    for (size_t i = 0; i &amp;lt; 10000; ++i)
    {
        DataRow dataRow(50, &amp;quot;This is a test string&amp;quot;);
        requestPackage.DataBody.push_back(dataRow);
    }

    // End timing for data generation
    auto end_gen = std::chrono::high_resolution_clock::now();
    std::chrono::duration&amp;lt;double&amp;gt; duration_gen = end_gen - start_gen;

    // Display result generation time
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Generation Time: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_gen.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    // Data merging using different methods
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Performance:\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    {
        // Method 1: Using &#39;+=&#39; string concatenation
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys(&amp;quot;&amp;quot;);
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (+=) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 2: Using ostringstream
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::ostringstream bodys;
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::ostringstream body;
            body &amp;lt;&amp;lt; &amp;quot;This is a test string&amp;quot;;
            for (auto&amp;amp; item : vec)
            {
                body &amp;lt;&amp;lt; item &amp;lt;&amp;lt; &amp;quot; &amp;quot;;
            }
            bodys &amp;lt;&amp;lt; body.str() &amp;lt;&amp;lt; &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ ostringstream Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 3: Pre-allocated memory
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys;
        bodys.reserve(1000 * 50 * 20); // Pre-allocate enough memory
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            body.reserve(50 * 20); // Pre-allocate memory for each row
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Pre-reserved Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 4: Using &#39;bodys = bodys + body + &amp;quot;\n&amp;quot;&#39;
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys(&amp;quot;&amp;quot;);
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            for (auto&amp;amp; item : vec)
            {
                body = body + item + &amp;quot; &amp;quot;; // Note the use of &#39;body = body + item&#39;
            }
            bodys = bodys + body + &amp;quot;\n&amp;quot;; // Again, using &#39;bodys = bodys + body&#39;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (bodys = bodys + body + \&amp;quot;\\n\&amp;quot;) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Complete.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;
}

int main()
{
    try
    {
        create_large_string();
    }
    catch (const std::exception&amp;amp; e)
    {
        std::cerr &amp;lt;&amp;lt; &amp;quot;Caught exception: &amp;quot; &amp;lt;&amp;lt; e.what() &amp;lt;&amp;lt; std::endl;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\nProgram finished.\n&amp;quot;;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Upgrading GCC version leads to program crashes: Hidden dangers of non-compliant code</title>
        <link>https://blog.ttf248.life/en/p/upgrade-gcc-version-causes-program-crash-code-irregularities/</link>
        <pubDate>Sun, 10 Mar 2024 23:19:06 +0800</pubDate>
        
        <guid>https://blog.ttf248.life/en/p/upgrade-gcc-version-causes-program-crash-code-irregularities/</guid>
        <description>&lt;p&gt;The program compiled and ran normally in the CentOS 7 environment, but crashed when switched to CentOS 8 and compiled with a newer version of GCC. Notably, this issue only occurred under &lt;strong&gt;Release 模式&lt;/strong&gt;, while &lt;strong&gt;Debug 模式&lt;/strong&gt; was unaffected. This was the first time we encountered such a situation, and after three days of troubleshooting, we finally found the root cause.&lt;/p&gt;
&lt;h3 id=&#34;issue-identification&#34;&gt;Issue identification
&lt;/h3&gt;&lt;p&gt;The root cause of the problem lies in &lt;strong&gt;函数缺少返回值&lt;/strong&gt;. The increased optimization performed by newer versions of GCC in Release mode has introduced unknown logic into functions without explicit return values, leading to crashes. Our conclusion is that &lt;strong&gt;编译器的警告不容忽视，尤其是在老项目中，部分警告可能被无视，但也应当避免屏蔽所有警告&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;environmental-description&#34;&gt;Environmental Description
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39)
Copyright © 2015 Free Software Foundation, Inc.
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-21)
Copyright (C) 2018 Free Software Foundation, Inc.
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;crash-phenomenon&#34;&gt;Crash phenomenon
&lt;/h3&gt;&lt;p&gt;When analyzing the program crash stack, we observed the following stack information:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[New LWP 1385902]
[Thread debugging using libthread_db enabled]
Using host libthread_db library &amp;quot;/lib64/libthread_db.so.1&amp;quot;.
Core was generated by `./pstack_main`.
Program terminated with signal SIGSEGV, Segmentation fault.
#0  0x00007ffe894b4420 in ?? ()
(gdb) bt
#0  0x00007ffe894b4420 in ?? ()
#1  0x00000000004008e9 in main ()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This stack trace isn&amp;rsquo;t intuitive; the crash information shows as a &lt;code&gt;__INLINE_CODE_0&lt;/code&gt;, making debugging more difficult&lt;/p&gt;
&lt;h3 id=&#34;code-example&#34;&gt;Code example
&lt;/h3&gt;&lt;p&gt;To better understand the issue, here&amp;rsquo;s a minimal code example to reproduce the crash:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;map&amp;gt;

int test() {
    std::cout &amp;lt;&amp;lt; &amp;quot;1&amp;quot; &amp;lt;&amp;lt; std::endl;
}

int main() {
    test();
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When a ``test()&lt;code&gt; 函数显然没有显式返回一个值，而它的返回类型是 __INLINE_CODE_1__。根据 C++ 规范，当一个函数声明为 __INLINE_CODE_2__&lt;/code&gt; type is used, it must have a return value; otherwise, undefined behavior may occur&lt;/p&gt;
&lt;h3 id=&#34;compilation-warning&#34;&gt;Compilation warning
&lt;/h3&gt;&lt;p&gt;In our project, CMake scripts suppress many compile-time warnings, including the following message:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;/root/pstack/main.cpp: In function ‘int test()’:
/root/pstack/main.cpp:7:1: warning: no return statement in function returning non-void [-Wreturn-type]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This warning indicates that the &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; function has no return value, which is the root of the problem. High-version GCC (such as 8.5.0) may perform unstable optimizations on this undefined behavior during code optimization, leading to program crashes.&lt;/p&gt;
&lt;h3 id=&#34;assembly-code-differences&#34;&gt;Assembly code differences
&lt;/h3&gt;&lt;p&gt;To explain the differences in GCC compiler optimization behavior, we compared assembly code generated by different versions of GCC&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The assembly code is lengthy and includes excessive optimizations for issues like the missing return value in functions such as __INLINE_CODE_0__BOLD_2&lt;code&gt;test()&lt;/code&gt;, which may have prevented a crash&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The new version of GCC includes more optimizations that reduce code size. However, these optimizations can lead to undefined behavior when executing functions lacking return values, potentially causing program crashes.&lt;/p&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h3&gt;&lt;p&gt;This troubleshooting has highlighted the importance of carefully addressing warnings in C++, particularly when functions are declared inline. It&amp;rsquo;s crucial to selectively handle these warnings, especially those related to function return values and type matching, rather than suppressing them all.&lt;/p&gt;
&lt;p&gt;The issue was resolved by adding a return value to the &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; function, and the program returned to normal operation&lt;/p&gt;</description>
        </item>
        <item>
        <title>Linux system benchmark testing</title>
        <link>https://blog.ttf248.life/en/p/linux-system-benchmark-test/</link>
        <pubDate>Tue, 09 Jan 2024 10:56:23 +0800</pubDate>
        
        <guid>https://blog.ttf248.life/en/p/linux-system-benchmark-test/</guid>
        <description>&lt;p&gt;The Windows platform has &amp;ldquo;Ruluzishi&amp;rdquo; (Entertainment Master), which isn&amp;rsquo;t entirely accurate but provides a reference. There are also other professional benchmarking tools, but suitable ones are lacking on the Linux system.&lt;/p&gt;
&lt;p&gt;Sysbench is a versatile benchmarking tool that can be used to test CPU, memory, file I/O, and thread performance. You can use Sysbench to perform various performance testing tasks.&lt;/p&gt;
&lt;p&gt;I currently have three machines available for testing: Mecha-Debug Mini local host, Alibaba Cloud Dev development cloud server, and Huawei Cloud development server&lt;/p&gt;
&lt;h2 id=&#34;installing-sysbench&#34;&gt;Installing Sysbench
&lt;/h2&gt;&lt;p&gt;In most Linux distributions, you can use a package management tool to install Sysbench. For example, on CentOS 8, you can use the following command for installation.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo dnf install sysbench
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;sysbench-usage-examples&#34;&gt;Sysbench Usage Examples
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Testing CPU performance:&lt;/li&gt;
&lt;li&gt;Testing memory read performance: &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Testing file I/O performance:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sysbench --test=fileio --file-test-mode=rndrw prepare
sysbench --test=fileio --file-test-mode=rndrw run
sysbench --test=fileio --file-test-mode=rndrw cleanup
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Testing multi-threaded performance: &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Testing MySQL database performance (requires adjusting the maximum number of connections)&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword --oltp-table-size=1000000 prepare
sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword --max-time=60 --oltp-read-only=off --oltp-test-mode=complex --max-requests=0 run
sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword cleanup
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;performance-data-report&#34;&gt;Performance Data Report
&lt;/h2&gt;&lt;meta http-equiv=&#34;Content-Type&#34; content=&#34;text/html; charset=utf-8&#34;&gt;&lt;link type=&#34;text/css&#34; rel=&#34;stylesheet&#34; href=&#34;resources/sheet.css&#34; &gt;
&lt;style type=&#34;text/css&#34;&gt;.ritz .waffle a { color: inherit; }.ritz .waffle .s0{background-color:#ffffff;text-align:left;color:#000000;font-family:&#39;Arial&#39;;font-size:10pt;vertical-align:bottom;white-space:nowrap;direction:ltr;padding:2px 3px 2px 3px;}&lt;/style&gt;&lt;div class=&#34;ritz grid-container&#34; dir=&#34;ltr&#34;&gt;&lt;table class=&#34;waffle&#34; cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th class=&#34;row-header freezebar-origin-ltr&#34;&gt;&lt;/th&gt;&lt;th id=&#34;0C0&#34; style=&#34;width:100px;&#34; class=&#34;column-headers-background&#34;&gt;A&lt;/th&gt;&lt;th id=&#34;0C1&#34; style=&#34;width:421px;&#34; class=&#34;column-headers-background&#34;&gt;B&lt;/th&gt;&lt;th id=&#34;0C2&#34; style=&#34;width:398px;&#34; class=&#34;column-headers-background&#34;&gt;C&lt;/th&gt;&lt;th id=&#34;0C3&#34; style=&#34;width:422px;&#34; class=&#34;column-headers-background&#34;&gt;D&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R0&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;1&lt;/div&gt;&lt;/th&gt;&lt;td&gt;&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;本地机械师&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;阿里云&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;华为云&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R1&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;2&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;系统配置&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Information&lt;br&gt;  Operating System              Ubuntu 23.04&lt;br&gt;  Kernel                        Linux 6.2.0-36-generic x86_64&lt;br&gt;  Model                         Machenike Machenike DT Computer&lt;br&gt;  Motherboard                   Machenike Machenike DT Computer&lt;br&gt;  BIOS                          American Megatrends International, LLC.&lt;br&gt;DB19V012&lt;br&gt;&lt;br&gt;CPU Information&lt;br&gt;  Name                          Intel Core i7-12650H&lt;br&gt;  Topology                      1 Processor, 10 Cores, 16 Threads&lt;br&gt;  Identifier                    GenuineIntel Family 6 Model 154 Stepping 3&lt;br&gt;  Base Frequency                4.60 GHz&lt;br&gt;  L1 Instruction Cache          32.0 KB x 8&lt;br&gt;  L1 Data Cache                 48.0 KB x 8&lt;br&gt;  L2 Cache                      1.25 MB x 2&lt;br&gt;  L3 Cache                      24.0 MB&lt;br&gt;&lt;br&gt;Memory Information&lt;br&gt;  Size                          62.6 GB&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Information&lt;br&gt;  Operating System              CentOS Stream 8&lt;br&gt;  Kernel                        Linux 4.18.0-513.el8.x86_64 x86_64&lt;br&gt;  Model                         Alibaba Cloud Alibaba Cloud ECS&lt;br&gt;  Motherboard                   N/A&lt;br&gt;  BIOS                          SeaBIOS 449e491&lt;br&gt;&lt;br&gt;CPU Information&lt;br&gt;  Name                          Intel(R) Xeon(R) Platinum&lt;br&gt;  Topology                      1 Processor, 1 Core, 2 Threads&lt;br&gt;  Identifier                    GenuineIntel Family 6 Model 85 Stepping 4&lt;br&gt;  Base Frequency                2.50 GHz&lt;br&gt;  L1 Instruction Cache          32.0 KB&lt;br&gt;  L1 Data Cache                 32.0 KB&lt;br&gt;  L2 Cache                      1.00 MB&lt;br&gt;  L3 Cache                      33.0 MB&lt;br&gt;&lt;br&gt;Memory Information&lt;br&gt;  Size                          1.65 GB&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Information&lt;br&gt;  Operating System              Ubuntu 22.04.1 LTS&lt;br&gt;  Kernel                        Linux 5.15.0-60-generic x86_64&lt;br&gt;  Model                         OpenStack Foundation OpenStack Nova&lt;br&gt;  Motherboard                   N/A&lt;br&gt;  BIOS                          SeaBIOS&lt;br&gt;rel-1.10.2-0-g5f4c7b1-20181220_000000-szxrtosci10000&lt;br&gt;&lt;br&gt;CPU Information&lt;br&gt;  Name                          Intel(R) Xeon(R) Gold 6278C CPU @ 2.60GHz&lt;br&gt;  Topology                      1 Processor, 1 Core, 2 Threads&lt;br&gt;  Identifier                    GenuineIntel Family 6 Model 85 Stepping 7&lt;br&gt;  Base Frequency                2.60 GHz&lt;br&gt;  L1 Instruction Cache          32.0 KB&lt;br&gt;  L1 Data Cache                 32.0 KB&lt;br&gt;  L2 Cache                      1.00 MB&lt;br&gt;  L3 Cache                      35.8 MB&lt;br&gt;&lt;br&gt;Memory Information&lt;br&gt;  Size                          3.64 GB&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R2&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;3&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;CPU&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  4032.48&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0004s&lt;br&gt;    total number of events:              40330&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.25&lt;br&gt;         avg:                                    0.25&lt;br&gt;         max:                                    0.73&lt;br&gt;         95th percentile:                        0.25&lt;br&gt;         sum:                                 9997.55&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           40330.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9975/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  1062.51&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0008s&lt;br&gt;    total number of events:              10628&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.91&lt;br&gt;         avg:                                    0.94&lt;br&gt;         max:                                   22.84&lt;br&gt;         95th percentile:                        1.06&lt;br&gt;         sum:                                 9993.46&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           10628.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9935/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  1125.56&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0005s&lt;br&gt;    total number of events:              11258&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.86&lt;br&gt;         avg:                                    0.89&lt;br&gt;         max:                                    1.70&lt;br&gt;         95th percentile:                        0.99&lt;br&gt;         sum:                                 9995.40&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           11258.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9954/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R3&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;4&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;内存&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 101993199 (10198146.52 per second)&lt;br&gt;&lt;br&gt;99602.73 MiB transferred (9959.13 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              101993199&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                    0.03&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4059.50&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           101993199.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.0595/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 48418803 (4841004.79 per second)&lt;br&gt;&lt;br&gt;47283.99 MiB transferred (4727.54 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              48418803&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                   25.26&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4578.95&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           48418803.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.5789/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 57056904 (5704765.11 per second)&lt;br&gt;&lt;br&gt;55719.63 MiB transferred (5571.06 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              57056904&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                    0.06&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4556.06&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           57056904.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.5561/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R4&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;5&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;硬盘&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 1.81 seconds (1129.59 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      3373.41&lt;br&gt;    writes/s:                     2248.94&lt;br&gt;    fsyncs/s:                     7201.80&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  52.71&lt;br&gt;    written, MiB/s:               35.14&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0127s&lt;br&gt;    total number of events:              128288&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.08&lt;br&gt;         max:                                    5.14&lt;br&gt;         95th percentile:                        0.34&lt;br&gt;         sum:                                 9977.78&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           128288.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9778/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 19.29 seconds (106.16 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      1593.12&lt;br&gt;    writes/s:                     1062.08&lt;br&gt;    fsyncs/s:                     3406.64&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  24.89&lt;br&gt;    written, MiB/s:               16.60&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0164s&lt;br&gt;    total number of events:              60600&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.16&lt;br&gt;         max:                                   31.32&lt;br&gt;         95th percentile:                        0.54&lt;br&gt;         sum:                                 9956.30&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           60600.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9563/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 18.29 seconds (111.98 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      1665.88&lt;br&gt;    writes/s:                     1110.59&lt;br&gt;    fsyncs/s:                     3563.77&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  26.03&lt;br&gt;    written, MiB/s:               17.35&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0112s&lt;br&gt;    total number of events:              63355&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.16&lt;br&gt;         max:                                  205.01&lt;br&gt;         95th percentile:                        0.78&lt;br&gt;         sum:                                 9972.64&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           63355.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9726/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R5&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;6&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;多线程&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0002s&lt;br&gt;    total number of events:              197956&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.16&lt;br&gt;         avg:                                    0.20&lt;br&gt;         max:                                    0.34&lt;br&gt;         95th percentile:                        0.21&lt;br&gt;         sum:                                39970.47&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           49489.0000/5.70&lt;br&gt;    execution time (avg/stddev):   9.9926/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0174s&lt;br&gt;    total number of events:              18360&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.57&lt;br&gt;         avg:                                    2.18&lt;br&gt;         max:                                   32.77&lt;br&gt;         95th percentile:                        2.61&lt;br&gt;         sum:                                40050.41&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           4590.0000/94.36&lt;br&gt;    execution time (avg/stddev):   10.0126/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0004s&lt;br&gt;    total number of events:              28536&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.23&lt;br&gt;         avg:                                    1.40&lt;br&gt;         max:                                    3.56&lt;br&gt;         95th percentile:                        1.47&lt;br&gt;         sum:                                39975.16&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           7134.0000/39.87&lt;br&gt;    execution time (avg/stddev):   9.9938/0.01&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;
&lt;h2 id=&#34;afterword&#34;&gt;Afterword
&lt;/h2&gt;&lt;p&gt;Without proper formatting, the display will be very poor. The custom theme limits the maximum page width, and I&amp;rsquo;ve adjusted the page configuration to use percentage-based width restrictions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Simple methods include using online tools like TablesGenerator to create HTML tables (unsuitable for complex content)&lt;/li&gt;
&lt;li&gt;Or use Google Docs, write there, then download as an HTML document and directly copy it into your blog (simple and direct, this is our final approach)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ensure the config is enabled with the unsafe option, and configure the width separately for each page&lt;/p&gt;
&lt;p&gt;In Hugo, you can set the width for individual pages. This can be achieved by adding a custom parameter in the page&amp;rsquo;s Front Matter. Here’s an example:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Add a custom parameter, such as &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;, in the Front Matter section of your Markdown page (typically at the beginning of the file)&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;---
title: &amp;quot;我的页面&amp;quot;
date: 2024-01-09
custom_width: &amp;quot;800px&amp;quot;  # 设置宽度为 800 像素
---

正文内容...
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;
&lt;p&gt;In your Hugo theme, locate or create the corresponding single-page template file (e.g., &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check if the page&amp;rsquo;s Front Matter contains &lt;code&gt;custom_width&lt;/code&gt; 参数，并将其应用到相应的 HTML 元素上，例如 &lt;code&gt;div&lt;/code&gt; in single-page templates:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;{{ define &amp;quot;main&amp;quot; }}
  &amp;lt;div style=&amp;quot;max-width: {{ with .Params.custom_width }}{{ . }}{{ else }}100%{{ end }}; margin: 0 auto;&amp;quot;&amp;gt;
    {{ .Content }}
  &amp;lt;/div&amp;gt;
{{ end }}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, we used inline styles to center the elements&lt;/p&gt;
&lt;p&gt;Please note that in practical applications, you may need to adjust the above examples according to your theme structure and CSS styles. Ensure consistency and readability when adjusting styles.&lt;/p&gt;
&lt;p&gt;The site&amp;rsquo;s custom &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; configuration was adjusted due to slight differences in the enabled theme&lt;/p&gt;</description>
        </item>
        <item>
        <title>docker-two-three-things</title>
        <link>https://blog.ttf248.life/en/p/docker-two-three-things/</link>
        <pubDate>Thu, 21 Jan 2021 09:26:07 +0800</pubDate>
        
        <guid>https://blog.ttf248.life/en/p/docker-two-three-things/</guid>
        <description>&lt;p&gt;After working for many years, I&amp;rsquo;ve encountered numerous users, and some content is not applicable&lt;/p&gt;
&lt;p&gt;Installation can refer to the manual from Tsinghua University: &lt;a class=&#34;link&#34; href=&#34;https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;install&#34;&gt;Install
&lt;/h2&gt;&lt;p&gt;Due to an unknown mysterious force, it is recommended to use cloud vendor-provided repository addresses for Docker installations within China; here, we recommend &lt;strong&gt;阿里云&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;set-repository-source-address&#34;&gt;Set repository source address
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum install yum-utils device-mapper-persistent-data lvm2 &amp;amp;&amp;amp; \
sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;deploy-the-latest-version&#34;&gt;Deploy the latest version
&lt;/h3&gt;&lt;p&gt;Docker, as a commonly used background service, is recommended to be set up for startup on boot. This command applies to CentOS 7.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo yum install -y docker-ce docker-ce-cli containerd.io &amp;amp;&amp;amp; systemctl enable --now docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;deploy-specified-version&#34;&gt;Deploy specified version
&lt;/h3&gt;&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum list docker-ce --showduplicates | sort -r
sudo yum install -y docker-ce-18.09.2-3.el7 docker-ce-cli-18.09.2-3.el7 containerd.io-18.09.2-3.el7 &amp;amp;&amp;amp; systemctl enable --now docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;add-docker-permissions-for-regular-users&#34;&gt;Add Docker permissions for regular users
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo usermod -aG docker ${USER}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;uninstall&#34;&gt;Uninstall
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo yum erase -y docker-ce docker-ce-cli containerd.io
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;everyday-use&#34;&gt;Everyday use
&lt;/h2&gt;&lt;h3 id=&#34;mirror-acceleration&#34;&gt;Mirror Acceleration
&lt;/h3&gt;&lt;p&gt;There are still unknown mysterious forces causing slow image pulls. Domestic cloud providers have stepped up, offering many acceleration services; I still recommend them.&lt;/p&gt;
&lt;p&gt;To obtain the accelerated access addresses, please register for an Alibaba Cloud account. This service is free, and Alibaba Cloud also provides a free image building service.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cat &amp;gt; /etc/docker/daemon.json &amp;lt;&amp;lt;EOF
{
  &amp;quot;registry-mirrors&amp;quot;: [
    &amp;quot;https://docker.nju.edu.cn&amp;quot;,
    &amp;quot;https://mirror.baidubce.com&amp;quot;,
    &amp;quot;https://docker.m.daocloud.io&amp;quot;,
    &amp;quot;https://docker.mirrors.sjtug.sjtu.edu.cn&amp;quot;
  ]
}
EOF
systemctl daemon-reload &amp;amp;&amp;amp; \
systemctl restart docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;highly-recommended-control-panel&#34;&gt;Highly recommended control panel
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker volume create portainer_data &amp;amp;&amp;amp; \
docker run -d --name=portainer --restart=always -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:2.20.3-alpine
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;commonly-used-image-pulls&#34;&gt;Commonly Used Image Pulls
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker pull rancher/rancher:stable &amp;amp;&amp;amp; docker pull  portainer/portainer-ce:2.0.1 &amp;amp;&amp;amp; \
docker pull centos:7 &amp;amp;&amp;amp; docker pull ubuntu:20.04 &amp;amp;&amp;amp; docker pull ubuntu:18.04 &amp;amp;&amp;amp; \
docker pull redis:5 &amp;amp;&amp;amp; docker pull redis:6 &amp;amp;&amp;amp; \
docker pull alpine:3.11 &amp;amp;&amp;amp; docker pull busybox:1.32 &amp;amp;&amp;amp; \
docker pull rabbitmq:3.7-management &amp;amp;&amp;amp; \
docker pull mariadb:10.2 &amp;amp;&amp;amp; \
docker pull nginx:1.18 &amp;amp;&amp;amp; docker pull nginx:1.19 &amp;amp;&amp;amp; \
docker pull mysql:5.6 &amp;amp;&amp;amp; docker pull mysql:8 &amp;amp;&amp;amp; \
docker pull elasticsearch:6.8.11 &amp;amp;&amp;amp; docker pull logstash:6.8.11 &amp;amp;&amp;amp; docker pull kibana:6.8.11 &amp;amp;&amp;amp; \
docker pull zookeeper:3.4 &amp;amp;&amp;amp; \
docker pull influxdb:1.7 &amp;amp;&amp;amp; docker pull grafana/grafana:7.3.1 &amp;amp;&amp;amp; \
docker pull percona:8 &amp;amp;&amp;amp; docker pull percona:5.6 &amp;amp;&amp;amp; \
docker pull cloverzrg/frps-docker:0.34.3 &amp;amp;&amp;amp; docker pull cloverzrg/frpc-docker:0.34.3
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;common-command-combinations&#34;&gt;Common Command Combinations
&lt;/h3&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.docker.com/engine/reference/commandline/docker/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://docs.docker.com/engine/reference/commandline/docker/&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Check container runtime status, add the __INLINE_CODE_0 parameter, view detailed container information; ignore image information at this time&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker ps --format &amp;quot;{{.Names}}: {{.Ports}}: {{.Size}}&amp;quot;
#portainer: 0.0.0.0:8000-&amp;gt;8000/tcp, 0.0.0.0:9000-&amp;gt;9000/tcp: 0B (virtual 172MB)
#influxdb: 0.0.0.0:8086-&amp;gt;8086/tcp: 183B (virtual 311MB)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;Stop all containers&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker stop $(docker ps -a -q)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Delete all images&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;dokcer rmi $(docker images -a -q)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;Export image&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker save &amp;lt;IMAGE NAME&amp;gt;:&amp;lt;IMAGE TAG&amp;gt; &amp;gt; -o XXX.tar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Export image and compress&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker save &amp;lt;IMAGE NAME&amp;gt;:&amp;lt;IMAGE TAG&amp;gt; | gzip &amp;gt; XXX.tar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Import image&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker load -i XXX.tar
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Setting up a JMeter Testing Environment on Linux</title>
        <link>https://blog.ttf248.life/en/p/linux-setup-jmeter-testing-environment/</link>
        <pubDate>Tue, 22 Dec 2020 10:12:50 +0800</pubDate>
        
        <guid>https://blog.ttf248.life/en/p/linux-setup-jmeter-testing-environment/</guid>
        <description>&lt;p&gt;The author, with a strong interest in hardware, conducted performance testing using JMeter and documented the deployment process of JMeter, InfluxDB, and Grafana on CentOS 7. They shared details on JMeter installation and command usage, InfluxDB features and Docker installation, as well as simple Grafana deployment and configuration. The document summarizes experiences and references for high-performance programming patterns.&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background
&lt;/h2&gt;&lt;p&gt;What use is a web panel in addition to data display?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You won&amp;rsquo;t understand until you try it yourself
Don&amp;rsquo;t use GUI mode for load testing! only for Test creation and Test debuggin.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The official recommendation is to obtain the load test report via command line and display it with a GUI, which may introduce data errors? I don&amp;rsquo;t have a deep understanding of JMeter, but at least this gives me a reason to experiment with the console panel in version &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The deployment method of Open Source China&amp;rsquo;s posts is not user-friendly, and the required files for installation also need to be downloaded via a public account. As a new generation, I naturally chose an alternative. Ultimately, it’s still slow accessing cross-border sources due to servers being located domestically; at least mirror services offer acceleration, like the free one from Alibaba Cloud.&lt;/p&gt;
&lt;p&gt;Installation deployment of &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; is not detailed here; please refer to previous articles for guidance&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;The following content is divided into two parts: building basic testing environment components and a brief introduction to each component&lt;/p&gt;
&lt;h2 id=&#34;jmeter&#34;&gt;Jmeter
&lt;/h2&gt;&lt;p&gt;Apache JMeter is a load testing tool developed by the Apache organization, based on Java. It was initially designed for web application testing but has since been extended to other testing areas. It can be used to test static and dynamic resources such as static files, Java microservices, CGI scripts, Java objects, databases, FTP servers, etc. JMeter can simulate a large load on servers, networks, or objects to test their strength and analyze overall performance under different stress categories. Additionally, JMeter can perform functional/regression testing by creating scripts with assertions to verify that your program returns the expected results. For maximum flexibility, JMeter allows the use of regular expressions for creating assertions.&lt;/p&gt;
&lt;p&gt;Apache JMeter can be used to test the performance of static and dynamic resources (files, Servlets, Perl scripts, Java objects, databases and queries, FTP servers, etc.). It can simulate heavy loads on servers, networks, or objects to test their resilience or analyze overall performance under different types of stress. You can use it for graphical analysis of performance or to load test your servers/scripts/objects with high concurrency.&lt;/p&gt;
&lt;h3 id=&#34;jmeter-deployment-on-centos-7&#34;&gt;JMeter deployment on CentOS 7
&lt;/h3&gt;&lt;p&gt;Installation package&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum install java-1.8.0-openjdk -y &amp;amp;&amp;amp; \
wget https://mirrors.bfsu.edu.cn/apache//jmeter/binaries/apache-jmeter-5.4.tgz &amp;amp;&amp;amp; tar -xf apache-jmeter-5.4.tgz
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Configure environment variables&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export JMETER_HOME=$HOME/jmeter/apache-jmeter-5.4
export PATH=$JMETER_HOME/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;jmeter-commands&#34;&gt;JMeter commands
&lt;/h3&gt;&lt;p&gt;Finally, observe data on the control panel&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;jmeter -n -t /tmp/order-500-10s.jmx -l /tmp/jmeter-order-report-20200109/order-500-10s.jtl
# 一般不用测试结果和测试报告，简化命令
jmeter -n -t /tmp/order-500-10s.jmx
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;influxdb&#34;&gt;InfluxDB
&lt;/h2&gt;&lt;p&gt;InfluxDB is an open-source distributed time series, event, and metrics database written in Go, requiring no external dependencies. It&amp;rsquo;s now primarily used to store large volumes of timestamped data, such as DevOps monitoring data, app metrics, IoT sensor data, and real-time analytics data.&lt;/p&gt;
&lt;h3 id=&#34;influxdb-features&#34;&gt;InfluxDB Features
&lt;/h3&gt;&lt;p&gt;The features of InfluxDB can be summarized into 9 aspects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Unstructured (no pattern): Can have an arbitrary number of columns;&lt;/li&gt;
&lt;li&gt;The retention period for metrics can be configured&lt;/li&gt;
&lt;li&gt;Supports time-related functions (e.g., min, max, sum, count, mean, median) for statistical analysis&lt;/li&gt;
&lt;li&gt;Supports storage policies: Can be used for data deletion and modification (InfluxDB does not provide methods for deleting or modifying data)&lt;/li&gt;
&lt;li&gt;Continuous queries are a set of statements that automatically start on a schedule in the database, and when paired with storage policies, can reduce InfluxDB system resource usage&lt;/li&gt;
&lt;li&gt;Native HTTP support, built-in HTTP API&lt;/li&gt;
&lt;li&gt;Supports SQL-like syntax&lt;/li&gt;
&lt;li&gt;Allows configuring the number of data replicas within the cluster&lt;/li&gt;
&lt;li&gt;Supports periodic sampling data, writing it to another measurement for granular storage&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;installing-influxdb-docker&#34;&gt;Installing InfluxDB Docker
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mkdir influxdb &amp;amp;&amp;amp; cd influxdb &amp;amp;&amp;amp; \
docker run -p 8086:8086 -d --name influxdb -v $PWD:/var/lib/influxdb influxdb:1.7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Enter container, execute command, manually create database&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;root@bce0a55bbc72:/# influx
Connected to http://localhost:8086 version 1.7.10
InfluxDB shell version: 1.7.10
&amp;gt; 交互面板执行命令
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;creating-databases-and-users-in-influxdb&#34;&gt;Creating databases and users in InfluxDB
&lt;/h3&gt;&lt;p&gt;Create database jmeter_t2
View databases
Switch database: use jmeter_t2
Create user &amp;ldquo;admin&amp;rdquo; with password &amp;lsquo;admin&amp;rsquo; and all privileges
View Users&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;&amp;gt; show users
user  admin
----  -----
admin true
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If user permissions are displayed, database preparation is complete&lt;/p&gt;
&lt;h2 id=&#34;grafana&#34;&gt;Grafana
&lt;/h2&gt;&lt;p&gt;The need for chart display is not essential; the &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; data from the interface can already be observed when executed in the command line, and it&amp;rsquo;s more about understanding the program&amp;rsquo;s internal execution time&lt;/p&gt;
&lt;p&gt;Simple deployment&lt;/p&gt;
&lt;p&gt;The console supports filtering test results by tag, and typically only requires configuring one database&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Application Name&lt;/li&gt;
&lt;li&gt;Test Case Name&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://blog.ttf248.life/p/linux-setup-jmeter-testing-environment/Snipaste_2021-03-09_19-44-22.png&#34;
	width=&#34;861&#34;
	height=&#34;357&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;grafana&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;241&#34;
		data-flex-basis=&#34;578px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -d --name=grafana -p 3000:3000 grafana/grafana:7.3.1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Web version calculations are affected by sampler interval&lt;/p&gt;
&lt;p&gt;The document also describes how to customize __INLINE_CODE_0&lt;/p&gt;
&lt;h2 id=&#34;afterword&#34;&gt;Afterword
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;High-performance programming inherently relies on a single loop thread; any locks, queuing (for entry and exit), will cause unnecessary performance loss&lt;/li&gt;
&lt;li&gt;The time spent on core business logic exceeds the time spent on introducing other code; concurrency is effective only when this core processing time is sufficiently small, and otherwise, introducing additional code should be approached cautiously&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/@jasonli.studio/to-install-apache-jmeter-in-centos7-294bc72a97ba&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;To install Apache JMeter in CentOS7&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Red Hat and CentOS lifecycles</title>
        <link>https://blog.ttf248.life/en/p/redhat-centos-lifecycle/</link>
        <pubDate>Tue, 21 Jul 2020 20:02:35 +0800</pubDate>
        
        <guid>https://blog.ttf248.life/en/p/redhat-centos-lifecycle/</guid>
        <description>&lt;p&gt;Red Hat and CentOS are popular choices for online production environment operating systems. Links to the official lifecycle information for both systems are provided, along with experience upgrading from CentOS 8 to CentOS 8 Stream.&lt;/p&gt;
&lt;h2 id=&#34;preface&#34;&gt;Preface
&lt;/h2&gt;&lt;p&gt;In online production environments, Red Hat and CentOS are currently the mainstream choices in China. Following the retirement of Red Hat 6 in recent years, here are links to the official life cycle websites for both systems.&lt;/p&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://access.redhat.com/support/policy/updates/errata&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Red Hat Enterprise Linux Life Cycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Red Hat Enterprise Linux (RHEL) and CentOS are popular choices for enterprise server operating systems. RHEL offers stable support and update cycles, suitable for enterprise applications. CentOS, as a community version of RHEL, provides similar functionality and stability but lacks official support.&lt;/p&gt;
&lt;h2 id=&#34;chase-for-more&#34;&gt;Chase for more
&lt;/h2&gt;&lt;p&gt;When publishing this article, I never thought I would update it again after two years. Just the other day, I upgraded my daily-use virtual machine from CentOS 8 to CentOS 8 Stream. I won&amp;rsquo;t elaborate on production choices, but I still prefer the latest versions for local environments.&lt;/p&gt;
&lt;p&gt;CentOS 8 Stream is a rolling release offering faster updates and new features compared to traditional CentOS, making it suitable for development and testing environments&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Python on Uncle Xiang&#39;s Notebook</title>
        <link>https://ttf248.life/en/tags/python/</link>
        <description>Recent content in Python on Uncle Xiang&#39;s Notebook</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Mon, 02 Jun 2025 19:00:25 +0800</lastBuildDate><atom:link href="https://ttf248.life/en/tags/python/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Python Dictionary Storage of Custom Objects: The Importance of References vs. Deep Copies</title>
        <link>https://ttf248.life/en/p/python-dictionary-custom-objects-reference-vs-deepcopy/</link>
        <pubDate>Fri, 22 Mar 2024 01:08:05 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/python-dictionary-custom-objects-reference-vs-deepcopy/</guid>
        <description>&lt;p&gt;In Python programming, a dictionary is a very powerful data structure that allows us to associate key-value pairs and efficiently search and manipulate these data. When we try to store custom objects in a dictionary, we often encounter a crucial concept: In Python, object assignment is actually reference assignment, not a deep copy of the object itself. This means that when you put a custom object into a dictionary, the dictionary stores a reference to that object, rather than a brand new copy of the object.&lt;/p&gt;
&lt;h2 id=&#34;basic-example-of-storing-custom-objects&#34;&gt;Basic Example of Storing Custom Objects
&lt;/h2&gt;&lt;p&gt;Let&amp;rsquo;s consider a simple &lt;code&gt;Person&lt;/code&gt; class:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Person:
    def __init__(self, name, age):
        self.name = name
        self.age = age

# Create a Person object
p1 = Person(&amp;quot;Alice&amp;quot;, 30)

# Store the object in a dictionary
people_dict = {}
people_dict[&amp;quot;alice&amp;quot;] = p1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, the &lt;code&gt;people_dict&lt;/code&gt; dictionary now contains an item with a key &lt;code&gt;&amp;quot;alice&amp;quot;&lt;/code&gt; and its value is a reference to the &lt;code&gt;Person&lt;/code&gt; type object &lt;code&gt;p1&lt;/code&gt;. If we modify the properties of this object:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;p1.age = 31
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then when accessing this object through the dictionary, we will find that its age has also been updated:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(people_dict[&amp;quot;alice&amp;quot;].age)  # Output: 31
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is because the dictionary stores references to &lt;code&gt;Person&lt;/code&gt; objects rather than independent copies of them. It stores a reference to the same memory address.&lt;/p&gt;
&lt;h2 id=&#34;deep-copy-vs-shallow-copy&#34;&gt;Deep Copy vs. Shallow Copy
&lt;/h2&gt;&lt;p&gt;This referencing behavior can lead to unexpected results when dealing with nested data structures or custom objects. For example, if a custom object contains mutable attribute types (such as lists or another custom object), directly storing such an object in a dictionary and modifying it will affect the object obtained through the dictionary.&lt;/p&gt;
&lt;h2 id=&#34;deep-copy-vs-shallow-copy-1&#34;&gt;Deep Copy vs. Shallow Copy
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Address:
    def __init__(self, street, city):
        self.street = street
        self.city = city

class Person:
    def __init__(self, name, age, address):
        self.name = name
        self.age = age
        self.address = address

address = Address(&amp;quot;Main St.&amp;quot;, &amp;quot;Springfield&amp;quot;)
p1 = Person(&amp;quot;Bob&amp;quot;, 40, address)
people_dict[&amp;quot;bob&amp;quot;] = p1

# Modify the original address object
address.city = &amp;quot;Shelbyville&amp;quot;

# The person in the dictionary also changed their address
print(people_dict[&amp;quot;bob&amp;quot;].address.city)  # Output: Shelbyville
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Solution: Deep Copy&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;deep-copy-vs-shallow-copy-2&#34;&gt;Deep Copy vs. Shallow Copy
&lt;/h2&gt;&lt;p&gt;To avoid issues caused by shared state, sometimes we need to ensure that the dictionary stores a complete copy of an object, rather than a reference to it. Python provides the &lt;code&gt;copy&lt;/code&gt; module&amp;rsquo;s &lt;code&gt;deepcopy&lt;/code&gt; function to achieve this goal:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import copy

# Use deep copy to store the object
people_dict[&amp;quot;bob_deepcopy&amp;quot;] = copy.deepcopy(p1)

# At this point, even if you modify the original referenced object, the deep copy object will not be affected
address.city = &amp;quot;Capital City&amp;quot;
print(people_dict[&amp;quot;bob&amp;quot;].address.city)  # Output: Capital City
print(people_dict[&amp;quot;bob_deepcopy&amp;quot;].address.city)  # Output: Shelbyville
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In summary, when storing custom objects in Python dictionaries, be sure to pay attention to the fact that by default, they store object references.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Stable Diffusion – The Love, Hate, and Drama of Installing it from Scratch</title>
        <link>https://ttf248.life/en/p/stable-diffusion-zero-install-story/</link>
        <pubDate>Thu, 13 Apr 2023 00:23:54 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/stable-diffusion-zero-install-story/</guid>
        <description>&lt;p&gt;Domestic resources are basically all recommending &lt;strong&gt;Autumn Leaf&lt;/strong&gt;’s one-click deployment package, thinking that they are open-source projects based on &lt;code&gt;Python&lt;/code&gt;, so the deployment wouldn&amp;rsquo;t be complicated, let’s try to start from scratch.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I was messing around with AI-generated images and specifically changed my graphics card, a beginner version of the &lt;code&gt;3060 12g&lt;/code&gt;; the seven-year-old &lt;code&gt;960&lt;/code&gt; retired gracefully.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The core &lt;code&gt;pytorch cuda&lt;/code&gt; installation, which I previously encountered issues with when writing Python game helper scripts (I had installed it locally before), still presented problems – the &lt;code&gt;cuda&lt;/code&gt; encryption consistently failed to activate.&lt;/p&gt;
&lt;h2 id=&#34;to-do&#34;&gt;To Do
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Replan the article structure, first introduce PyTorch, version correspondence, and how to check versions.&lt;/li&gt;
&lt;li&gt;How to create a new virtual environment from scratch locally and deploy PyTorch.&lt;/li&gt;
&lt;li&gt;Translate the manuscript from scratch: &lt;a class=&#34;link&#34; href=&#34;https://stable-diffusion-art.com/install-windows/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stable-diffusion-art.com/install-windows/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Organize reference materials&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;steps&#34;&gt;Steps
&lt;/h2&gt;&lt;p&gt;Step-by-step installation tutorials in Chinese may not be readily available. If you search in English on &lt;code&gt;Google&lt;/code&gt;, you’ll find many similar tutorials starting from scratch. We introduce the need to install &lt;code&gt;git&lt;/code&gt; and then explain that we also need to install &lt;code&gt;python&lt;/code&gt;. Then, you go ahead and download the repository – simply double-clicking the script gets it running.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/AUTOMATIC1111/stable-diffusion-webui&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For detailed usage and FAQs, consult the &lt;code&gt;issues&lt;/code&gt; page: &lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki&lt;/a&gt;. I don’t know why no one explains what this repository is for. Actually, the name itself isn&amp;rsquo;t difficult to understand – it’s a graphical console that makes it easier for us to use.&lt;/p&gt;
&lt;h2 id=&#34;steps-1&#34;&gt;Steps
&lt;/h2&gt;&lt;p&gt;The repository also created an installation and startup script. It automatically identifies the current folder and checks for a &lt;code&gt;Python&lt;/code&gt; virtual environment. If one exists, it defaults to using the &lt;code&gt;python&lt;/code&gt; in the current path.&lt;/p&gt;
&lt;p&gt;For new users who are unfamiliar with the process, we recommend reviewing: &lt;a class=&#34;link&#34; href=&#34;https://stable-diffusion-art.com/install-windows/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stable-diffusion-art.com/install-windows/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;pytorch&#34;&gt;PyTorch
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/get-started/locally/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://pytorch.org/get-started/locally/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Don&amp;rsquo;t follow their steps directly to launch the script. Python uses &lt;code&gt;requirement&lt;/code&gt; files to install dependency libraries, which is just a minor issue. The core thing is your GPU version and driver version, which need to match PyTorch. Many people have discussed this relationship online – you can find it by searching.
Reference: &lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/weixin_40660408/article/details/129896700&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/weixin_40660408/article/details/129896700&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Creating a virtual environment is like creating an empty virtual environment, where you first execute the official script to install PyTorch within it.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -c &amp;quot;import torch; print(torch.version.cuda)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -c &amp;quot;import torch; print(torch.__version__, torch.cuda.is_available())&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;pytorch-1&#34;&gt;PyTorch
&lt;/h2&gt;&lt;p&gt;The following two scripts can check the CUDA version you need to install and also check if the installation was successful.
We don&amp;rsquo;t recommend fancy operations here; first, follow the logic on the official page to copy it over directly, and then just install it directly using pip. You’re likely to fail or not activate CUDA if you try to install directly with pip.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Don&amp;rsquo;t use messy folder names, as this could prevent PyTorch from working.
I went back and forth installing many times and even tried downloading the official installation files manually to upgrade to version 2.0 because the official documentation said it would be faster. - However, I hadn’t used it much before, and I wasn&amp;rsquo;t sure about the Python version and whether that was having an impact. I also reviewed the official documentation in between, which recommended using version 3.8. This created a small conflict because I had previously used a one-click installation package that contained version 3.10. Finally, I started from scratch by creating a new folder and setting up a virtual environment to ensure that Torch was successfully installed.&lt;/p&gt;
&lt;h2 id=&#34;pytorch-2&#34;&gt;PyTorch
&lt;/h2&gt;&lt;p&gt;Then, move the installed virtual environment into the web UI folder. At this point, running the script to install the other dependencies should resolve most of the issues.
After moving it, execute: &lt;code&gt;python -m pip install --upgrade --force-reinstall pip&lt;/code&gt; to fix Pip.
It might seem quite weird, but I’ve spent a lot of time messing around here because it couldn&amp;rsquo;t correctly recognize my Torch. To eliminate all potential interference, I thought it was best to install it first, then install the other dependency libraries.&lt;/p&gt;
&lt;h2 id=&#34;xformers&#34;&gt;Xformers
&lt;/h2&gt;&lt;p&gt;It is recommended to enable this, which can accelerate image generation and reduce memory usage. However, a side effect is that &lt;strong&gt;generated images tend to be less stable&lt;/strong&gt; with the same set of parameters.
&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;stable-diffusion-webui:Xformers&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/diffusers/optimization/xformers&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;huggingface optimization&lt;/a&gt;
| 100.00% | 2m 57.03s | 7440/10058 MiB | 12288/12288 MiB (100.0%) |&lt;/p&gt;
&lt;h2 id=&#34;xformers-1&#34;&gt;Xformers
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Optimization Ratio&lt;/th&gt;
&lt;th&gt;Time taken&lt;/th&gt;
&lt;th&gt;Torch active/reserved&lt;/th&gt;
&lt;th&gt;Sys VRAM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;51.02%&lt;/td&gt;
&lt;td&gt;1m 29.21s&lt;/td&gt;
&lt;td&gt;4547/7164 MiB&lt;/td&gt;
&lt;td&gt;9298/12288 MiB (75.67%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;xformers-2&#34;&gt;Xformers
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;(masterpiece), (best quality), (high detail), (realistic,)
Industrial age city, deep canyons in the middle, Chinese architectural streets, bazaars, bridges, (rainy days:1.2), (steampunk:0.8), Chinese architecture
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;xformers-3&#34;&gt;Xformers
&lt;/h2&gt;&lt;p&gt;Negative prompt: nsfw,((cowboy)),(((pubic))), ((((pubic_hair))))sketch, duplicate, ugly, huge eyes, text, logo, monochrome, worst face, (bad and mutated hands:1.3), (worst quality:2.0), (low quality:2.0), (blurry:2.0), horror, geometry, bad_prompt, (bad hands), (missing fingers), multiple limbs, bad anatomy, (interlocked fingers:1.2), Ugly Fingers, (extra digit and hands and fingers and legs and arms:1.4), crown braid, ((2girl)), (deformed fingers:1.2), (long fingers:1.2),succubus wings,horn,succubus&lt;/p&gt;
&lt;h2 id=&#34;xformers-4&#34;&gt;Xformers
&lt;/h2&gt;&lt;p&gt;crown braid, ((2girl)), (deformed fingers:1.2), (long fingers:1.2), succubus wings, horn, succubus horn, succubus hairstyle, (bad-artist-anime), bad-artist, bad hand, borrowed character, text focus, watermark, sample watermark, character watermark, lofter username, photo date watermark, movie poster, magazine cover, journal, cover, cover page, doujin cover, album cover, manga cover, brand name imitation, EasyNegative, Tights, silk stockings, shorts&lt;/p&gt;
&lt;h2 id=&#34;xformers-5&#34;&gt;Xformers
&lt;/h2&gt;&lt;p&gt;Steps: 35, Sampler: DPM adaptive, CFG scale: 5.5, Seed: 2223996555, Size: 1088x1088, Model hash: 543bcbc212, Model: base_Anything-V3.0-pruned, Clip skip: 2, ENSD: 31337&lt;/p&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;We didn’t recommend the one-click deployment package because it contained some settings that were customized by the author and differed from the official original configuration. If you are a beginner, you might not understand why those parameters are optimal; it&amp;rsquo;s best to start with the official package first. As you use it more and more, take time to read the official documentation, and you’ll learn which parameters need adjustment.&lt;/p&gt;
&lt;h2 id=&#34;choosing-a-graphics-card&#34;&gt;Choosing a Graphics Card
&lt;/h2&gt;&lt;p&gt;Following the cryptocurrency mining boom, graphics card prices have become relatively less high. When ordinary entry-level players are choosing between the &lt;code&gt;3060&lt;/code&gt; and &lt;code&gt;3060ti&lt;/code&gt;, they generally recommend the &lt;code&gt;12G&lt;/code&gt; version of the 3060 due to its larger VRAM, as it can generate larger resolution images. Why do you need a higher resolution? Because you can adjust the resolution when generating images, which will result in clearer and more detailed images. If you only want to generate small images, then &lt;code&gt;8G&lt;/code&gt; of VRAM is sufficient.&lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s also the &lt;strong&gt;upscaling&lt;/strong&gt; option – “High Definition Upscaling” – which enhances details and makes the image richer in detail, requiring more VRAM. Here’s a summary table of the single-precision (FP32), half-precision (FP16), and double-precision (FP64) floating-point compute capabilities for NVIDIA GeForce GTX 970, GeForce RTX 3060 Ti, GeForce RTX 3060, GeForce RTX 3080, and GeForce RTX 3080 Ti:&lt;/p&gt;
&lt;p&gt;| GeForce GTX 970 | 2014 | 3.49 | 87.2 | 0.109 |&lt;/p&gt;
&lt;h2 id=&#34;graphics-card-selection&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;graphics-card-selection-1&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;graphics-card-selection-2&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating Point Performance (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating Point Performance (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating Point Performance (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;graphics-card-selection-3&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;graphics-card-selection-4&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;p&gt;Excerpted from &lt;a class=&#34;link&#34; href=&#34;https://docs.google.com/spreadsheets/d/1Zlv4UFiciSgmJZncCujuXKHwc4BcxbjbSBg71-SdeNk/edit#gid=0&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;various graphics card performance test data&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;updates&#34;&gt;Updates
&lt;/h2&gt;&lt;p&gt;Every six months, I originally planned to revisit and refine the installation steps, and explain more basic concepts. However, I discovered that most people using AI image generation are simply adjusting parameters based on images provided by experts, or re-rendering existing images with formatting changes.&lt;/p&gt;
&lt;p&gt;I had previously attempted a project using AI to generate UI materials for mini programs, but after struggling for half a day, the results were unsatisfactory compared to just pulling resource images directly from the official mini program documentation.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Why Do We Need to Learn a New Language?</title>
        <link>https://ttf248.life/en/p/why-learn-a-new-language/</link>
        <pubDate>Thu, 04 Aug 2022 11:27:30 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/why-learn-a-new-language/</guid>
        <description>&lt;p&gt;Starting from my academic years, I’ve been working with &lt;code&gt;C++&lt;/code&gt; for over ten years. So, why do I need to learn other programming languages?&lt;/p&gt;
&lt;p&gt;Work experience: Lacking experience in elegant module design, &lt;code&gt;C++&lt;/code&gt; syntax is freeform. Learning other languages helps guide me to write more elegant designs.&lt;/p&gt;
&lt;p&gt;I frequently use it when developing some tools. The same design principles apply to the design of low-level libraries and business modules.&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Python on Uncle Xiang&#39;s Notebook</title>
        <link>https://ttf248.life/en/tags/python/</link>
        <description>Recent content in Python on Uncle Xiang&#39;s Notebook</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Sun, 25 May 2025 02:57:45 +0800</lastBuildDate><atom:link href="https://ttf248.life/en/tags/python/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Storing Custom Objects in Python Dictionaries: The Importance of References and Deep Copies</title>
        <link>https://ttf248.life/en/p/python-dictionary-custom-objects-reference-vs-deepcopy/</link>
        <pubDate>Fri, 22 Mar 2024 01:08:05 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/python-dictionary-custom-objects-reference-vs-deepcopy/</guid>
        <description>&lt;p&gt;In Python programming, dictionaries are a very powerful data structure that allows us to associate key-value pairs and efficiently find and manipulate this data. When we try to store custom objects in a dictionary, we often encounter a key concept: object assignment in Python is actually reference assignment, not a deep copy of the object itself. This means that when you put a custom object into a dictionary, the dictionary stores a reference to that object, rather than a brand new copy of the object.&lt;/p&gt;
&lt;h2 id=&#34;storing-custom-objects---a-basic-example&#34;&gt;Storing Custom Objects - A Basic Example
&lt;/h2&gt;&lt;p&gt;Suppose we have a simple &lt;code&gt;Person&lt;/code&gt; class:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Person:
    def __init__(self, name, age):
        self.name = name
        self.age = age

# 创建一个 Person 对象
p1 = Person(&amp;quot;Alice&amp;quot;, 30)

# 将对象存储到字典中
people_dict = {}
people_dict[&amp;quot;alice&amp;quot;] = p1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, the &lt;code&gt;people_dict&lt;/code&gt; dictionary now contains an item with the key &lt;code&gt;&amp;quot;alice&amp;quot;&lt;/code&gt; and a value that is a reference to the &lt;code&gt;Person&lt;/code&gt; type object &lt;code&gt;p1&lt;/code&gt;. If we modify the attributes of &lt;code&gt;p1&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;p1.age = 31
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When accessing this object through the dictionary, we will find that its age has also been updated:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(people_dict[&amp;quot;alice&amp;quot;].age)  # 输出：31
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is because the dictionary stores not independent copies of &lt;code&gt;Person&lt;/code&gt; objects, but references pointing to the same memory address&lt;/p&gt;
&lt;h2 id=&#34;the-difference-between-deep-copy-and-shallow-copy&#34;&gt;The difference between deep copy and shallow copy
&lt;/h2&gt;&lt;p&gt;This referencing behavior can lead to unexpected results when dealing with nested data structures or custom objects. For example, if a custom object contains mutable attributes (such as lists or another custom object), directly storing such an object in a dictionary and modifying it will affect the object retrieved through the dictionary.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Address:
    def __init__(self, street, city):
        self.street = street
        self.city = city

class Person:
    def __init__(self, name, age, address):
        self.name = name
        self.age = age
        self.address = address

address = Address(&amp;quot;Main St.&amp;quot;, &amp;quot;Springfield&amp;quot;)
p1 = Person(&amp;quot;Bob&amp;quot;, 40, address)
people_dict[&amp;quot;bob&amp;quot;] = p1

# 修改原始地址对象
address.city = &amp;quot;Shelbyville&amp;quot;

# 字典中的人的地址也变了
print(people_dict[&amp;quot;bob&amp;quot;].address.city)  # 输出：Shelbyville
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Solution: Deep Copy&lt;/p&gt;
&lt;p&gt;To avoid problems caused by this shared state, sometimes we need to ensure that the dictionary stores a complete copy of an object, rather than a reference. Python provides the &lt;code&gt;deepcopy&lt;/code&gt; function in the &lt;code&gt;copy&lt;/code&gt; module to achieve this goal:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import copy

# 使用深拷贝存储对象
people_dict[&amp;quot;bob_deepcopy&amp;quot;] = copy.deepcopy(p1)

# 此时即使修改原始地址对象，深拷贝的对象不会受影响
address.city = &amp;quot;Capital City&amp;quot;
print(people_dict[&amp;quot;bob&amp;quot;].address.city)  # 输出：Capital City
print(people_dict[&amp;quot;bob_deepcopy&amp;quot;].address.city)  # 输出：Shelbyville
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In short, when using dictionaries to store custom objects in Python, be mindful that object references are stored by default. For situations requiring independent state, use &lt;code&gt;deepcopy&lt;/code&gt; for a deep copy to avoid unexpected data changes due to shared references.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Stable Diffusion - The ups and downs of installing from scratch</title>
        <link>https://ttf248.life/en/p/stable-diffusion-zero-install-saga/</link>
        <pubDate>Thu, 13 Apr 2023 00:23:54 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/stable-diffusion-zero-install-saga/</guid>
        <description>&lt;p&gt;Domestic resources generally recommend &lt;strong&gt;Chuyou&amp;rsquo;s&lt;/strong&gt; one-click deployment package. Thinking it’s an open-source project based on &lt;code&gt;Python&lt;/code&gt;, I figured the deployment wouldn&amp;rsquo;t be too complex, so I decided to try starting from scratch.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I messed around with AI image generation, specifically upgraded my graphics card to an entry-level &lt;code&gt;3060 12g&lt;/code&gt;; the &lt;code&gt;960&lt;/code&gt;, which served faithfully for seven years, has now been retired&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The core &lt;code&gt;pytorch CUDA&lt;/code&gt; installation, I had installed it locally before when writing &lt;code&gt;Python&lt;/code&gt; game assistant scripts, but still encountered problems – the &lt;code&gt;CUDA&lt;/code&gt; license could not be activated&lt;/p&gt;
&lt;h2 id=&#34;pending&#34;&gt;Pending
&lt;/h2&gt;&lt;p&gt;Reorganize the article structure, first introducing PyTorch, version compatibility, and how to check versions
How to create a new virtual environment from scratch and deploy PyTorch locally
Translate drafts from scratch, stable diffusion &lt;a class=&#34;link&#34; href=&#34;https://stable-diffusion-art.com/install-windows/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stable-diffusion-art.com/install-windows/&lt;/a&gt;
Organize reference materials&lt;/p&gt;
&lt;h2 id=&#34;steps&#34;&gt;Steps
&lt;/h2&gt;&lt;p&gt;You might not find a step-by-step installation tutorial by searching in Chinese. If you search in English on &lt;code&gt;Google&lt;/code&gt;, there are many similar tutorials that start from scratch. It briefly introduced the need to install &lt;code&gt;git&lt;/code&gt;, then explained the need to install &lt;code&gt;python&lt;/code&gt;. Then, it just involved downloading the repository and running the script with a double click.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/AUTOMATIC1111/stable-diffusion-webui&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For detailed usage and troubleshooting, please refer to the &lt;code&gt;issues&lt;/code&gt; section: &lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I also don&amp;rsquo;t know why no one explained what this repository is for. Actually, it’s not hard to tell from the name – it’s an interface console that makes it more convenient for us to use. In fact, when installing, it will download the official repository content and obtain the actual &lt;code&gt;SD&lt;/code&gt; code.&lt;/p&gt;
&lt;p&gt;The warehouse also includes an installation startup script. It automatically detects whether there is a &lt;code&gt;Python&lt;/code&gt; virtual environment in the current folder. If so, it defaults to using the &lt;code&gt;python&lt;/code&gt; from the current path.&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;re a complete beginner, it’s recommended that you check out: &lt;a class=&#34;link&#34; href=&#34;https://stable-diffusion-art.com/install-windows/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stable-diffusion-art.com/install-windows/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;pytorch&#34;&gt;pytorch
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/get-started/locally/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://pytorch.org/get-started/locally/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is what I wanted to talk about today. First, don&amp;rsquo;t listen to their instructions and start the script directly. Python installs dependencies through requirement files, which are minor issues. The core issue is your graphics card driver version, which needs to correspond with PyTorch. Many people have already explained this relationship; you can find it online if you search for it.&lt;/p&gt;
&lt;p&gt;Reference: &lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/weixin_40660408/article/details/129896700&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/weixin_40660408/article/details/129896700&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Creating a virtual environment is like having an empty space where you can directly run the script from the official website to install PyTorch&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -c &amp;quot;import torch; print(torch.version.cuda)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -c &amp;quot;import torch; print(torch.__version__, torch.cuda.is_available())&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The two scripts above can check the CUDA version you need to install and whether the installation was successful&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s not recommended to use fancy operations here. Just copy the logic from the official page and install it directly. Install it directly using pip, and your PyTorch is likely to fail or CUDA might not be activated.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Important: Make sure the folder path doesn&amp;rsquo;t contain any unnecessary characters, otherwise it may prevent PyTorch from working properly&lt;/p&gt;
&lt;p&gt;I installed it many times back and forth, and also tried downloading the official installation file and installing it manually. I was just thinking about upgrading to version 2.0 because the official documentation says that version 2.0 will be faster. But I haven&amp;rsquo;t used it much before, and I don’t know if the Python version or something else is affecting it. In the meantime, I also checked the official manual, which recommends using version 3.8. This created a small conflict because the one-click installation package previously used had version 3.10. Finally, I started from scratch by creating a new folder, creating a virtual environment, and ensuring that torch was installed successfully.&lt;/p&gt;
&lt;p&gt;Then move this installed virtual environment into the web UI folder. After that, when you start the installation script, most of the dependency issues should be resolved.&lt;/p&gt;
&lt;p&gt;After moving, you need to run: python -m pip install &amp;ndash;upgrade &amp;ndash;force-reinstall pip to fix it&lt;/p&gt;
&lt;p&gt;It might seem a bit strange, but I spent quite a while troubleshooting this. It couldn&amp;rsquo;t correctly identify my torch, so to eliminate all possible interference factors, I decided to install it first and then the other dependencies.&lt;/p&gt;
&lt;h2 id=&#34;xformers&#34;&gt;Xformers
&lt;/h2&gt;&lt;p&gt;It is recommended to enable it, as it can accelerate image generation and reduce existing usage. The side effect is that &lt;strong&gt;images generated with the same parameters may not be as stable&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;stable-diffusion-webui:Xformers&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/diffusers/optimization/xformers&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;huggingface optimization&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Optimization Ratio&lt;/th&gt;
&lt;th&gt;Time taken&lt;/th&gt;
&lt;th&gt;Torch active/reserved&lt;/th&gt;
&lt;th&gt;Sys VRAM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;100.00%&lt;/td&gt;
&lt;td&gt;2m 57.03s&lt;/td&gt;
&lt;td&gt;7440/10058 MiB&lt;/td&gt;
&lt;td&gt;12288/12288 MiB (100.0%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;51.02%&lt;/td&gt;
&lt;td&gt;1m 29.21s&lt;/td&gt;
&lt;td&gt;4547/7164 MiB&lt;/td&gt;
&lt;td&gt;9298/12288 MiB (75.67%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;((masterpiece)),((best quality)),((high detial)),((realistic,))
Industrial age city, deep canyons in the middle,chinese architectural streets,bazaars, Bridges, (rainy days:1.2), (steampunk:0.8), chinese architecture
Negative prompt: nsfw,((cowboy)),(((pubic))), ((((pubic_hair))))sketch, duplicate, ugly, huge eyes, text, logo, monochrome, worst face, (bad and mutated hands:1.3), (worst quality:2.0), (low quality:2.0), (blurry:2.0), horror, geometry, bad_prompt, (bad hands), (missing fingers), multiple limbs, bad anatomy, (interlocked fingers:1.2), Ugly Fingers, (extra digit and hands and fingers and legs and arms:1.4), crown braid, ((2girl)), (deformed fingers:1.2), (long fingers:1.2),succubus wings,horn,succubus horn,succubus hairstyle, (bad-artist-anime), bad-artist, bad hand, borrowed character, text focus, watermark, sample watermark, character watermark, lofter username, photo date watermark, movie poster, magazine cover, journal, cover, cover page, doujin cover, album cover, manga cover, brand name imitation, EasyNegative,Tights, silk stockings,shorts
Steps: 35, Sampler: DPM adaptive, CFG scale: 5.5, Seed: 2223996555, Size: 1088x1088, Model hash: 543bcbc212, Model: base_Anything-V3.0-pruned, Clip skip: 2, ENSD: 31337
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;afterword&#34;&gt;Afterword
&lt;/h2&gt;&lt;p&gt;Why not recommend the one-click deployment package? Because that package contains some settings that were custom-made by the author, and they are not the same as the official original version. If you&amp;rsquo;re a beginner, you may not know why it’s best to start with the parameters provided by the official source first. As you use it for longer, refer to the official manual more often, and you will understand which parameters need adjustment.&lt;/p&gt;
&lt;h2 id=&#34;choosing-a-graphics-card&#34;&gt;Choosing a Graphics Card
&lt;/h2&gt;&lt;p&gt;After the cryptocurrency mining boom, graphics card prices are relatively lower now. For ordinary entry-level players choosing between a 3060 and a 3060 Ti, it&amp;rsquo;s generally recommended to go with the 3060 version with 12GB of VRAM because it can generate images at higher resolutions. Why do you need a higher resolution? Because you can increase the resolution during generation, resulting in clearer and more detailed images. If you’re just generating smaller images, 8GB of VRAM is sufficient.&lt;/p&gt;
&lt;p&gt;Also, the &lt;strong&gt;high-definition enhancement&lt;/strong&gt; option refines details, making the picture more detailed and also requiring more video memory&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a summary table of the single-precision (FP32), half-precision (FP16), and double-precision (FP64) floating-point compute capabilities specifications for NVIDIA GeForce GTX 970, GeForce RTX 3060 Ti, GeForce RTX 3060, GeForce RTX 3080, and GeForce RTX 3080 Ti&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Year of Release&lt;/th&gt;
&lt;th&gt;Single-Precision Floating-Point Calculation Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating-Point Calculation Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating-Point Calculation Capability (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;GeForce GTX 970&lt;/td&gt;
&lt;td&gt;2014&lt;/td&gt;
&lt;td&gt;3.49&lt;/td&gt;
&lt;td&gt;87.2&lt;/td&gt;
&lt;td&gt;0.109&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GeForce RTX 3060 Ti&lt;/td&gt;
&lt;td&gt;2020&lt;/td&gt;
&lt;td&gt;16.2&lt;/td&gt;
&lt;td&gt;32.4&lt;/td&gt;
&lt;td&gt;0.51&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GeForce RTX 3060&lt;/td&gt;
&lt;td&gt;2021&lt;/td&gt;
&lt;td&gt;12.7&lt;/td&gt;
&lt;td&gt;25.4&lt;/td&gt;
&lt;td&gt;0.39&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GeForce RTX 3080&lt;/td&gt;
&lt;td&gt;2020&lt;/td&gt;
&lt;td&gt;29.8&lt;/td&gt;
&lt;td&gt;58.9&lt;/td&gt;
&lt;td&gt;0.93&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GeForce RTX 3080 Ti&lt;/td&gt;
&lt;td&gt;2021&lt;/td&gt;
&lt;td&gt;34.8&lt;/td&gt;
&lt;td&gt;68.7&lt;/td&gt;
&lt;td&gt;1.36&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Extracted, &lt;a class=&#34;link&#34; href=&#34;https://docs.google.com/spreadsheets/d/1Zlv4UFiciSgmJZncCujuXKHwc4BcxbjbSBg71-SdeNk/edit#gid=0&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;various graphics card performance test data&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;update&#34;&gt;Update
&lt;/h2&gt;&lt;p&gt;After six months, I had intended to review the installation steps and explain more basic concepts, but it turns out that for ordinary people using AI image generation, it really just involves adjusting parameters based on images provided by experts or re-rendering existing images in a formatted way&lt;/p&gt;
&lt;p&gt;We tried using AI to generate UI assets for a mini-program, but after all that effort, the results weren&amp;rsquo;t satisfactory. It’s better if I just pull the resource images directly from the official mini-program.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Why learn a new language?</title>
        <link>https://ttf248.life/en/p/why-learn-a-new-language/</link>
        <pubDate>Thu, 04 Aug 2022 11:27:30 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/why-learn-a-new-language/</guid>
        <description>&lt;p&gt;Why learn other programming languages after having used C++ for over ten years, starting from my school days?&lt;/p&gt;
&lt;p&gt;Work Experience: Lacks experience in elegant module design, C++ syntax is flexible, and learning other languages can help guide the creation of more elegant designs&lt;/p&gt;
&lt;p&gt;I often find myself using these tools when writing them&lt;/p&gt;
&lt;p&gt;Whether it&amp;rsquo;s the design of the underlying libraries or the implementation of business modules, the design principles are consistent&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

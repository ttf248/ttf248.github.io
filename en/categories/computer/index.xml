<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Computer on Uncle Xiang&#39;s Notebook</title>
        <link>https://ttf248.life/en/categories/computer/</link>
        <description>Recent content in Computer on Uncle Xiang&#39;s Notebook</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Mon, 02 Jun 2025 19:00:25 +0800</lastBuildDate><atom:link href="https://ttf248.life/en/categories/computer/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Git Submodule Merge History Lost</title>
        <link>https://ttf248.life/en/p/git-submodule-merge-history-lost/</link>
        <pubDate>Mon, 02 Jun 2025 16:44:58 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/git-submodule-merge-history-lost/</guid>
        <description>&lt;p&gt;There’s a Git repository locally where submodules were in temporary branches during the initial pull. I made commits on that temporary branch, and then switched back to the &lt;code&gt;main&lt;/code&gt; branch. However, those committed changes seem to be lost and cannot be found within the &lt;code&gt;main&lt;/code&gt; branch. I also can&amp;rsquo;t find any record of that temporary branch.&lt;/p&gt;
&lt;h2 id=&#34;solutions&#34;&gt;Solutions
&lt;/h2&gt;&lt;p&gt;When you’ve committed to a temporary branch within a Git submodule and then switch back to the &lt;code&gt;main&lt;/code&gt; branch, you lose those commits. You can resolve this situation by following these steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Verify Commit History&lt;/strong&gt;: Navigate into the submodule directory and use &lt;code&gt;reflog&lt;/code&gt; to find the lost commits.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Create a New Branch to Preserve Commits&lt;/strong&gt;: Create a new branch based on the lost commits.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Merge or Cherry-Pick Commits to Main&lt;/strong&gt;: Integrate the code into the main branch.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here&amp;rsquo;s a breakdown of the specific steps:&lt;/p&gt;
&lt;h2 id=&#34;solutions-1&#34;&gt;Solutions
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Enter the submodule directory
cd path/to/your/submodule

# View the reflog record of all HEAD changes (including commits not associated with branches)
git reflog
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;solutions-2&#34;&gt;Solutions
&lt;/h2&gt;&lt;p&gt;PS F:\dev\notebook\scripts\hugo-content-suite&amp;gt; git reflog
de05175 (HEAD -&amp;gt; main, origin/main, origin/HEAD): checkout: moving from c8d070651310e90d283cb64d98da088c5fe05e73 to main
c8d0706 HEAD@{1}: commit: feat: Add Markdown tag usage documentation, providing detailed syntax examples and effect demonstrations
48250f5 HEAD@{2}: commit: feat: Remove article translation preview functionality, simplifying the translation process
b8280b6 HEAD@{3}: commit: feat: Add absolute path retrieval function, supporting converting relative paths to absolute paths
92c354b HEAD@{4}: commit: fix: Fix article scanning logic to ensure scanning with absolute paths&lt;/p&gt;
&lt;h2 id=&#34;solutions-3&#34;&gt;Solutions
&lt;/h2&gt;&lt;p&gt;92c354b HEAD@{4}: commit: fix: Fix article scanning logic to ensure absolute path scanning
de05175 (HEAD -&amp;gt; main, origin/main, origin/HEAD) HEAD@{5}: checkout: Moving from main to de05175d4ec0828e3ae95d726b09dfff18f67a23
de05175 (HEAD -&amp;gt; main, origin/main, origin/HEAD) HEAD@{6}: clone: from &lt;a class=&#34;link&#34; href=&#34;https://cnb.cool/ttf248/hugo-content-suite.git&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://cnb.cool/ttf248/hugo-content-suite.git&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;solutions-4&#34;&gt;Solutions
&lt;/h2&gt;&lt;h1 id=&#34;create-a-new-branch-based-on-a-lost-commit-eg-using-commit-456def&#34;&gt;Create a new branch based on a lost commit (e.g., using commit 456def)
&lt;/h1&gt;&lt;p&gt;git checkout -b saved-work 456def&lt;/p&gt;
&lt;h1 id=&#34;switch-back-to-the-main-branch&#34;&gt;Switch back to the main branch
&lt;/h1&gt;&lt;p&gt;git checkout main&lt;/p&gt;
&lt;h1 id=&#34;merge-the-saved-work-into-main-or-use-cherry-pick-to-select-specific-commits&#34;&gt;Merge the saved work into main (or use cherry-pick to select specific commits)
&lt;/h1&gt;&lt;p&gt;git merge saved-work&lt;/p&gt;
&lt;h1 id=&#34;or&#34;&gt;or
&lt;/h1&gt;&lt;p&gt;git cherry-pick 456def&lt;/p&gt;
&lt;h1 id=&#34;return-to-the-root-project-directory-and-commit-submodule-updates&#34;&gt;Return to the root project directory and commit submodule updates
&lt;/h1&gt;&lt;p&gt;cd ..
git add path/to/your/submodule
git commit -m &amp;ldquo;Update submodule to include new changes&amp;rdquo;&lt;/p&gt;
&lt;h2 id=&#34;key-operations-guide&#34;&gt;Key Operations Guide
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;git reflog&lt;/strong&gt;: Displays the entire history of HEAD, including commits not associated with any branch.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;git checkout -b&lt;/strong&gt;: Creates a new branch from any commit and saves your work.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;git merge/cherry-pick&lt;/strong&gt;: Integrates saved commits into the target branch.
If no record is found in reflog, you may need to try using &lt;code&gt;git fsck --lost-found&lt;/code&gt; to find orphaned commits, but this situation is rare.&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>GitHub Pages Easter Egg: Deploying Multiple Pages</title>
        <link>https://ttf248.life/en/p/github-pages-easter-egg-deploy-multiple-sites/</link>
        <pubDate>Wed, 28 May 2025 02:55:54 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/github-pages-easter-egg-deploy-multiple-sites/</guid>
        <description>&lt;p&gt;Recently, my biological clock has been a bit off, still messing around with GitHub Pages deployments at nearly 2 AM.&lt;/p&gt;
&lt;p&gt;I went to eat after work, and I just wanted to sleep as soon as I finished eating. After eating, I came back around 8:30 PM, feeling drowsy, I thought about taking a nap, and then fell asleep immediately. When I woke up, it was already nearly 2 AM.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Categories that haven&amp;rsquo;t even launched yet: AI Study Group&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;facepalm&#34;&gt;Facepalm
&lt;/h2&gt;&lt;p&gt;Yesterday we said there wouldn&amp;rsquo;t be much frontend development, but today it’s not frontend – it’s the experience of UI/UX.&lt;/p&gt;
&lt;h2 id=&#34;project&#34;&gt;Project
&lt;/h2&gt;&lt;p&gt;Please join our old friend, &lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/ai-coding-demo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/ai-coding-demo&lt;/a&gt;.
That’s the original self-selected stock project – we&amp;rsquo;re restructuring the overall project structure, and all subsequent AI programming content will be housed within this project.&lt;/p&gt;
&lt;h2 id=&#34;deploying-multiple-pages&#34;&gt;Deploying Multiple Pages
&lt;/h2&gt;&lt;p&gt;The project is hosted domestically at [https://cnb.cool/ttf248/ai-coding-demo]. Due to well-known reasons, pages cannot be published within China, so we need to publish them on GitHub outside of the country.&lt;/p&gt;
&lt;p&gt;The blog is published on this external GitHub. I haven&amp;rsquo;t tried it before, and also, the current project I’m working on isn’t a traditional blog site; it simply contains a lot of documentation layered with several static HTML design mockups.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/github-pages-easter-egg-deploy-multiple-sites/20250528030230.png&#34;
	width=&#34;798&#34;
	height=&#34;530&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;pages&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;150&#34;
		data-flex-basis=&#34;361px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;That’s right – this page is where I first discovered that deploying multiple pages using Pages doesn&amp;rsquo;t affect the blog’s publication, but instead adds a new path under the blog’s domain name.&lt;/p&gt;
&lt;p&gt;[https://ttf248.life/ai-coding-demo/](https://ttf248.&lt;/p&gt;
&lt;h2 id=&#34;ai-study-group&#34;&gt;AI Study Group
&lt;/h2&gt;&lt;p&gt;Yesterday, I created a new category and thought about using AI to learn many computer courses, such as algorithms and LeetCode practice problems.
Each learning record is published on the blog to form a knowledge base. A new category was created: AI Study Group.
Now it seems that different courses require creating separate projects, and all learning notes are written in the project&amp;rsquo;s Readme.md file.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Old problems, the flamboyant beauty of blossoming flowers (a reference to a famous Chinese poem).</title>
        <link>https://ttf248.life/en/p/old-ailment-stunning-flowers/</link>
        <pubDate>Mon, 26 May 2025 23:54:12 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/old-ailment-stunning-flowers/</guid>
        <description>&lt;p&gt;For many years, I’ve focused on backend development, and recently started to explore &lt;code&gt;AI&lt;/code&gt; programming while dipping my toes into some frontend-related content. However, during this period of tinkering, I gradually realized I was falling back into an old habit – being dazzled by shiny new things. I constantly want to use &lt;code&gt;AI&lt;/code&gt; to create a frontend interface, but in reality, these attempts haven’t provided much practical benefit for my current work and have instead wasted my energy.&lt;/p&gt;
&lt;h2 id=&#34;ai-use-cases&#34;&gt;AI Use Cases
&lt;/h2&gt;&lt;p&gt;In small projects, AI tools can truly shine, particularly when writing independent functions with low system coupling and simple business logic. These tasks typically have clear inputs and outputs, and rely on limited context – perfectly suited to the current capabilities of AI-assisted programming.&lt;/p&gt;
&lt;p&gt;However, when facing complex system architectures or deep business logic, AI’s limitations begin to emerge. It may generate code that appears reasonable but is actually detached from the project&amp;rsquo;s real needs, or even introduce potential issues that are difficult to debug. In these scenarios, AI is best suited as an assistive tool rather than a fully autonomous code generator. We need to conduct rigorous review and testing of generated code to ensure it meets actual requirements.&lt;/p&gt;
&lt;h2 id=&#34;errors-and-the-cost-of-learning&#34;&gt;Errors and the Cost of Learning
&lt;/h2&gt;&lt;p&gt;While attempting to generate frontend code using AI, I encountered numerous challenges. As frontend development isn&amp;rsquo;t a domain I’m familiar with, troubleshooting often proved time-consuming and frustrating. Even after adjusting prompts to have the AI rewrite the code, it was difficult to avoid the appearance of some low-level errors. This iterative process not only wasted time but also highlighted that my current focus should be on backend business logic rather than groping around in unfamiliar territory.&lt;/p&gt;
&lt;p&gt;Looking back at the project completed over the weekend, I’m more confident that focusing on backend development and user interaction logic, implementing functionality through a console, is the most efficient approach currently. Perhaps systematically learning frontend knowledge would be a better strategy when I have more time and energy.&lt;/p&gt;
&lt;h2 id=&#34;frontend-learning-plan&#34;&gt;Frontend Learning Plan
&lt;/h2&gt;&lt;p&gt;The frontend technology stack is complex and diverse, so it’s unrealistic to quickly master it. I plan to first choose a framework, such as Vue.js or React.js, and deeply learn its core concepts and usage methods. Only after becoming familiar with the fundamentals will I attempt to use AI to generate frontend code, which can effectively avoid errors and wasted time caused by unfamiliarity.&lt;/p&gt;
&lt;p&gt;In short, the focus for this stage should be on backend development, steadily building my core skills. Once the timing is right, I’ll explore the combination of frontend and AI – potentially yielding greater rewards.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Claude4 released, attempting to develop: Hugo tags, hyperlink translation assistant</title>
        <link>https://ttf248.life/en/p/claude-4-release-hugo-tags-hyperlink-translation-assistant/</link>
        <pubDate>Sat, 24 May 2025 03:05:31 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/claude-4-release-hugo-tags-hyperlink-translation-assistant/</guid>
        <description>&lt;p&gt;This site is developed using Hugo, but I’ve always used Chinese titles, which results in less friendly generated article links. In simpler terms, when shared, they don&amp;rsquo;t look as good because the Chinese characters are escaped into formats like %E4%BD%A0%E5%A5%BD within the links. While you can solve this by setting a slug, it’s tedious to do manually every time.&lt;/p&gt;
&lt;p&gt;Therefore, I decided to try using Claude4 to develop a translation assistant that automatically converts Chinese titles to English slugs and adds hyperlinks within the articles. This would eliminate the need for manual setup.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Claude4 is amazing – its contextual understanding has significantly improved, as has its efficiency in handling complex tasks.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;project-address&#34;&gt;Project Address
&lt;/h2&gt;&lt;p&gt;Domestic Project Address: &lt;a class=&#34;link&#34; href=&#34;https://cnb.cool/ttf248/hugo-content-suite&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://cnb.cool/ttf248/hugo-content-suite&lt;/a&gt;
International Project Address: &lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/hugo-content-suite&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/hugo-content-suite&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;code-implementation&#34;&gt;Code Implementation
&lt;/h2&gt;&lt;p&gt;Let&amp;rsquo;s first discuss the implementation approach: We need to scan all articles, extract tag information and article titles, and then call the local large model (such as gemma-3-12b-it) for translation.&lt;/p&gt;
&lt;p&gt;In actual development, Claude4 showcased several significant advantages compared to previous generation large models. Due to the diverse functional requirements, Claude4 automatically designed an interactive menu, comprehensively considering various usage scenarios. For example, in tag processing, Claude4 not only supports tag statistics and analysis but also includes classification statistics and can even detect &lt;strong&gt;unlabeled articles&lt;/strong&gt;. Furthermore, it provides &lt;strong&gt;preview&lt;/strong&gt; and tag page generation functionalities.&lt;/p&gt;
&lt;p&gt;Whether it&amp;rsquo;s integrating with local large models, adding translation caches, or performing large-scale code refactoring, Claude4 completes everything in one go, with almost no issues. Despite the project’s small scale, it incorporates many minor features. Previously, large models often forgot earlier content during development, but this time the &lt;code&gt;Claude4&lt;/code&gt; performed exceptionally well, &lt;strong&gt;virtually eliminating context loss&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In short, its intelligence has increased, and we plan to switch to &lt;code&gt;Claude4&lt;/code&gt; for more development work as our primary coding model.&lt;/p&gt;
&lt;h2 id=&#34;translation-cache&#34;&gt;Translation Cache
&lt;/h2&gt;&lt;p&gt;This approach, besides reducing the number of calls to large models, is quite efficient when running a 12b model locally – it doesn’t waste much time. However, if you need to call the large model every time, it will still be somewhat slow. Secondly, to fix the connections within articles, if a full update operation is executed and the article title is very long, there&amp;rsquo;s occasionally a situation where the two translated results differ, causing the link to change – which is quite awkward.&lt;/p&gt;
&lt;h2 id=&#34;feature-optimization&#34;&gt;Feature Optimization
&lt;/h2&gt;&lt;p&gt;The entire project was handed over to &lt;code&gt;Claude4&lt;/code&gt; to analyze the space for optimization and generate the following recommendations:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Externalize Configuration - Improve maintainability and flexibility
Structured Logging - Facilitates troubleshooting and monitoring
Performance Monitoring - Understand system runtime status
User Experience - Visual feedback such as progress bars
Error Handling - A more robust exception handling mechanism
Code Organization - Clearer module partitioning
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The code was reviewed, and everything appeared to be in order. For example, the configuration files were modified to convert existing configurations from the original code into default configurations. If a corresponding configuration file was not found when reading the configuration file, a default configuration file would automatically generate to avoid user errors. Here&amp;rsquo;s the English translation of the provided text:&lt;/p&gt;
&lt;p&gt;“Requirements: When translating, dynamically calculate the current translation efficiency, estimate remaining time, and output relevant information to the console. Currently, we’re obtaining the character count of the article, the number of characters translated per line, the time taken, and fitting a calculation for the translation time of every 100 characters. Simultaneously, we&amp;rsquo;re calculating the estimated remaining translation time.&lt;/p&gt;
&lt;p&gt;The code is complete, but the results aren’t satisfactory, so I asked AI to provide a new design solution:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Provide multiple efficiency calculation methods: real-time efficiency, average efficiency, and sliding window efficiency&lt;/li&gt;
&lt;li&gt;Improve display methods: progress bars, segmented statistics, and dynamic refresh&lt;/li&gt;
&lt;li&gt;Add more useful metrics: API call counts, success rates, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After completing the code, I discovered a new surprise – translation efficiency statistics were flooding the console in real time, but without endless scrolling.”&lt;/p&gt;
&lt;h2 id=&#34;feature-optimization-1&#34;&gt;Feature Optimization
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Translate text to English (total 7163 characters)...
Detected 53 lines needing translation
  [1/53] Stage1/6 [░░░░░░░░░░░░░░░░░░░░░░░░░] 1.9% translating 354 characters...
    ✅ Completed (3.1s) | API call #1
    ✅ Completed (1.5s) | API call #2
    ✅ Completed (0.9s) | API call #3
    ✅ Completed (0.2s) | API call #4
    ✅ Completed (1.0s) | API call #5
    ✅ Completed (1.0s) | API call #6
    ✅ Completed (0.2s) | API call #7
    📊 Progress: Lines 13.2% (7/53) | Characters 12.9% (925/7163) 114.6 characters per second 📊
    ⚡ Efficiency: Real-time 76.4 | Average 117.9 | Recent 109.0 | Stage 113.6 characters per second 📊
    🎯 Success rate: 100.0% (7/7) | Remaining: 46 lines 7 seconds] 9.4% translating 110 characters...
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;feature-optimization-2&#34;&gt;Feature Optimization
&lt;/h2&gt;&lt;p&gt;🎯 Success Rate: 100.0% (7/7) | Remaining: 46 lines 7 7s] 9.4% Translation 110 characters&amp;hellip;
⏱️ Estimated Remaining: 55s | Expected Completion: 00:10:19 8s] 11.3% Translation 114 characters&amp;hellip;
💾 Processing Speed: 3211.3 rows/minute | Total Time: 8s] 13.2% Translation 16 characters&amp;hellip;
[8/53] Stage1/6 [███░░░░░░░░░░░░░░░░░░░░░░] 15.1% Translation 166 characters&amp;hellip;&lt;/p&gt;
&lt;h2 id=&#34;feature-optimization-3&#34;&gt;Feature Optimization
&lt;/h2&gt;&lt;p&gt;Previously, the code used to control the program wasn&amp;rsquo;t extensive, so I was curious about how it was implemented. Examining the code:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;// Clear screen and redraw (dynamic refresh effect)
if translationCount &amp;gt; 1 {
    fmt.Print(&amp;quot;\033[6A\033[K&amp;quot;) // Move up 6 lines and clear
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;performance-statistics-menu&#34;&gt;Performance Statistics Menu
&lt;/h3&gt;&lt;p&gt;The newly added &lt;strong&gt;Performance Statistics Menu&lt;/strong&gt;, which I myself designed, isn&amp;rsquo;t as well-designed as this one.&lt;/p&gt;
&lt;p&gt;📊 Performance Statistics:
🔄 Translation Count: 360
⚡ Cache Hit Rate: 1.4% (5/365)
⏱️ Average Translation Time: 315.927234ms
📁 File Operations: 73
❌ Error Count: 0&lt;/p&gt;
&lt;h3 id=&#34;progress-bar-display&#34;&gt;Progress Bar Display
&lt;/h3&gt;&lt;p&gt;The newly added &lt;strong&gt;Progress Bar Display&lt;/strong&gt;, providing detailed progress, elapsed time, and estimated remaining time.
Please select function (0-13): 10
🔍 Collecting translation target&amp;hellip;
📄 Cached file loaded, containing 0 translation records
📊 Translation cache statistics:
🏷️ Total tags: 229
📝 Total articles: 131
✅ Cached: 0
🔄 To be translated: 360&lt;/p&gt;
&lt;h3 id=&#34;progress-bar-display-1&#34;&gt;Progress Bar Display
&lt;/h3&gt;&lt;p&gt;Confirm full translation cache generation? (y/n): y
🚀 Generating full translation cache&amp;hellip;
📄 Loaded cache file, containing 0 translation records
🔍 Checking translations in cache&amp;hellip;
🔄 Need to translate 360 new tags
[░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 5/360 (1.4%) - Time taken: 3s - Estimated remaining: 3m8s
💾 Saved cache file, containing 5 translation records
[█░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 10/360 (2. 8%) - Time taken: 6s - Estimated remaining: 3m28s 💾 Cache file saved, containing 10 translation records
[██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 15/360 (4.2%) - Time taken: 9s - Estimated remaining: 3m30s 💾 Cache file saved, containing 15 translation records&lt;/p&gt;
&lt;h3 id=&#34;progress-bar-display-2&#34;&gt;Progress Bar Display
&lt;/h3&gt;&lt;p&gt;[██████████████████████████████████] 20/360 (5.6%) - Time Elapsed: 13s - Estimated Remaining: 3m36s💾 Cache file saved, containing 20 translation records
[████████████████████████████████░░] 25/360 (6.9%) - Time Elapsed: 16s - Estimated Remaining: 3m33s💾 Cache file saved, containing 25 translation records
[██████████████████████████████████] 30/360 (8. (3%) - Time taken: 19s - Estimated remaining: 3m30s [████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 35/360 (9.7%) - Time taken: 22s - Estimated remaining: 3m25s [████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░]&lt;/p&gt;
&lt;h3 id=&#34;progress-bar-display-3&#34;&gt;Progress Bar Display
&lt;/h3&gt;&lt;hr&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;=== Hugo Blog Management Tool ===

🚀 Core Features
  1. One-Click Processing of All (Complete Blog Handling Process)

📝 Content Management
  2. Generate Tag Pages
  3. Generate Article Slug
  4. Translate Articles into Multi-Language Versions

💾 Cache Management
  5. View Cache Status
  6. Generate Full Translation Cache
  7. Clear Translation Cache

  0. Exit Program
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Merge the Pull Request into the Repository of the Fork</title>
        <link>https://ttf248.life/en/p/merge-pullrequest-to-forked-repo/</link>
        <pubDate>Wed, 07 May 2025 18:44:03 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/merge-pullrequest-to-forked-repo/</guid>
        <description>&lt;p&gt;&lt;code&gt;github-readme-stats&lt;/code&gt; is a GitHub profile statistics generator that allows users to display various statistics and charts within their GitHub profiles. It offers multiple customization options to tailor it to user needs.&lt;/p&gt;
&lt;p&gt;I manage my repository habits by grouping them by project; GitHub doesn&amp;rsquo;t support repository grouping, so I have to achieve this by splitting repositories across different organizations. The latest branch of &lt;code&gt;github-readme-stats&lt;/code&gt; cannot support statistics for repositories spanning different organizations; I forked a branch and merged the corresponding code.&lt;/p&gt;
&lt;h2 id=&#34;final-result&#34;&gt;Final Result
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://github-readme-stats-chi-one-17.vercel.app/api?username=ttf248&amp;amp;hide_title=true&amp;amp;show_icons=true&amp;amp;hide=contribs&amp;amp;line_height=24&amp;amp;include_all_commits=true&amp;amp;count_private=true&amp;amp;bg_color=0000&amp;amp;text_color=8A919F&amp;amp;locale=cn&amp;amp;role=OWNER,COLLABORATOR,ORGANIZATION_MEMBER&amp;amp;timstamp=1746608356&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;GitHub Stats&#34;
	
	
&gt;
&lt;img src=&#34;https://github-readme-stats-chi-one-17.vercel.app/api/top-langs/?username=ttf248&amp;amp;hide_title=true&amp;amp;hide=html,javascript,css&amp;amp;layout=compact&amp;amp;bg_color=0000&amp;amp;text_color=8A919F&amp;amp;locale=cn&amp;amp;role=OWNER,COLLABORATOR,ORGANIZATION_MEMBER&amp;amp;timstamp=1746608356&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Top Languages&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;pull-request-original-address&#34;&gt;Pull Request Original Address
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/anuraghazra/github-readme-stats/pull/2459&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Adds the ability to include data from organization repositories&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;merging-a-pull-request-into-your-forked-repository&#34;&gt;Merging a Pull Request into Your Forked Repository
&lt;/h2&gt;&lt;p&gt;To merge a &lt;strong&gt;Pull Request (PR)&lt;/strong&gt; into your &lt;strong&gt;forked repository&lt;/strong&gt;, there are several ways to do this, depending on whether you want to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Merge the PR from the &lt;strong&gt;upstream repository&lt;/strong&gt; into your fork, or&lt;/li&gt;
&lt;li&gt;Merge a PR from another person’s fork into your fork, or&lt;/li&gt;
&lt;li&gt;Merge a PR that was opened on your fork (e.g., someone forked and created a PR for you)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I&amp;rsquo;ll first give you a common scenario: &lt;strong&gt;You have forked a repository and want to merge a PR from the upstream into your fork&lt;/strong&gt;.  Here’s the workflow below 👇&lt;/p&gt;
&lt;h3 id=&#34;-method-one-command-line-most-universal&#34;&gt;✅ Method One: Command Line (Most Universal)
&lt;/h3&gt;&lt;h4 id=&#34;step-1-clone-your-own-fork&#34;&gt;Step 1: Clone your own fork
&lt;/h4&gt;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/your-username/repository-name.git
cd repository-name
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;step-2-add-upstream-original-repository-address&#34;&gt;Step 2: Add Upstream (Original Repository Address)
&lt;/h4&gt;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git remote add upstream https://github.com/original-author-username/repository-name.git
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;step-3-fetch-the-upstream-pr-branch&#34;&gt;Step 3: Fetch the Upstream PR Branch
&lt;/h4&gt;&lt;p&gt;Find the PR number you want to merge, for example PR #123.
You can then checkout the code for that PR like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git fetch upstream pull/123/head:pr-123
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;step-4-switch-and-merge-branches&#34;&gt;Step 4: Switch and Merge Branches
&lt;/h4&gt;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git checkout main    # Or your own target branch
git merge pr-123
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If everything goes well, you can push to your forked GitHub repository:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git push origin main
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;-method-two-github-web-interface-simple-but-limited&#34;&gt;✅ Method Two: GitHub Web Interface (Simple but Limited)
&lt;/h3&gt;&lt;p&gt;If you see a PR on GitHub’s web interface that is against the upstream repository, you can:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Navigate to the PR page.&lt;/li&gt;
&lt;li&gt;Click “&lt;strong&gt;Commits&lt;/strong&gt;” or “&lt;strong&gt;Files changed&lt;/strong&gt;” in the top-right corner to see which branch this PR is based on.&lt;/li&gt;
&lt;li&gt;On your fork page, create a new branch and then manually cherry-pick the PR’s commit (requires Git knowledge).&lt;/li&gt;
&lt;li&gt;Or, click “&lt;strong&gt;Open in GitHub Desktop&lt;/strong&gt;” and use the GUI tool to merge.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;-if-someone-has-created-a-fork-and-submitted-a-pr-to-it-simply-navigate-to-the-pr-page-click-the-merge-pull-request-button-and-youre-done&#34;&gt;🚀 If someone has created a fork and submitted a PR to it, simply navigate to the PR page, click the &amp;ldquo;&lt;strong&gt;Merge pull request&lt;/strong&gt;&amp;rdquo; button, and you’re done.
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;Would you like me to walk you through it step-by-step based on your specific scenario (e.g., PR link, whether you&amp;rsquo;re using a web interface or command line)? Or, please provide the link and I can analyze the simplest approach for you.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Commit messages in Git’s history</title>
        <link>https://ttf248.life/en/p/git-modify-commit-message/</link>
        <pubDate>Wed, 07 May 2025 18:38:31 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/git-modify-commit-message/</guid>
        <description>&lt;ul&gt;
&lt;li&gt;Scripts for batch modifying Git history commit author information, rewriting Git history records using &lt;code&gt;git filter-branch&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You provided the script to modify author information in Git repository history commits in bulk. The overall approach is correct, but using an array (e.g., &lt;code&gt;OLD_EMAILS=(&amp;quot;...&amp;quot;)&lt;/code&gt;) within the &lt;code&gt;git filter-branch&lt;/code&gt; &lt;code&gt;--env-filter&lt;/code&gt; may cause compatibility issues because some shell environments (such as &lt;code&gt;/bin/sh&lt;/code&gt;) do not support array syntax.
To improve compatibility, it is recommended to replace the array with a string separated by spaces and iterate through each old email address using a &lt;code&gt;for&lt;/code&gt; loop. Here&amp;rsquo;s an example of the modified script:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/sh

git filter-branch --env-filter &#39;
OLD_EMAILS=&amp;quot;TianlongXiang51@gmail.com nick@qq.com tianlongxiang51@gmail.com&amp;quot;
CORRECT_NAME=&amp;quot;tianlong.xiang&amp;quot;
CORRECT_EMAIL=&amp;quot;tianlong.xiang@foxmail.com&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-english&#34;&gt;for OLD_EMAIL in $OLD_EMAILS
do
  if [ &amp;quot;$GIT_COMMITTER_EMAIL&amp;quot; = &amp;quot;$OLD_EMAIL&amp;quot; ]
  then
    export GIT_COMMITTER_NAME=&amp;quot;$CORRECT_NAME&amp;quot;
    export GIT_COMMITTER_EMAIL=&amp;quot;$CORRECT_EMAIL&amp;quot;
  fi
  if [ &amp;quot;$GIT_AUTHOR_EMAIL&amp;quot; = &amp;quot;$OLD_EMAIL&amp;quot; ]
  then
    export GIT_AUTHOR_NAME=&amp;quot;$CORRECT_NAME&amp;quot;
    export GIT_AUTHOR_EMAIL=&amp;quot;$CORRECT_EMAIL&amp;quot;
  fi
done
&#39; --tag-name-filter cat -- --branches --tags
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Before executing this script, it is recommended to back up your repository to prevent any unforeseen issues.&lt;/li&gt;
&lt;li&gt;This operation will rewrite Git history and modify commit author information, which may cause the commit hash values to change.&lt;/li&gt;
&lt;li&gt;If you have already pushed changes to a remote repository, you need to use a forced push:
Please exercise caution when using forced pushes, especially in collaborative projects, to avoid impacting others.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Count all unique author email addresses in the repository&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git log --format=&#39;%an &amp;lt;%ae&amp;gt;&#39; | sort -u
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Feeling bored and wanting to design a theme based on traditional Chinese ink wash painting.</title>
        <link>https://ttf248.life/en/p/designing-a-chinese-ink-style-theme/</link>
        <pubDate>Tue, 08 Apr 2025 03:42:47 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/designing-a-chinese-ink-style-theme/</guid>
        <description>&lt;p&gt;I’ve grown tired of endlessly tweaking my homepage and suddenly want to embrace a minimalist style, designing a Chinese ink wash theme.&lt;/p&gt;
&lt;p&gt;Currently, the stylesheet is heavily customized – specific styles are configured to override the default theme styles for different elements. Without refactoring, I attempted to generate a new theme directly using AI, but the results were incredibly unstable.  Coincidentally, I also encountered a queue for trae claude large model, switching to vscode agent mode, which further degraded the results; the generated output lacked any design sense. Ultimately, it comes down to my own lack of understanding of frontend development, preventing me from effectively breaking down tasks and delegating them to AI.&lt;/p&gt;</description>
        </item>
        <item>
        <title>No coding, design and develop a self-selected stock module.</title>
        <link>https://ttf248.life/en/p/design-develop-custom-stock-module-no-code/</link>
        <pubDate>Thu, 27 Feb 2025 23:20:39 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/design-develop-custom-stock-module-no-code/</guid>
        <description>&lt;ul&gt;
&lt;li&gt;Last month, we experimented with cursor, but due to the limitations of the free quota, we didn&amp;rsquo;t develop overly complex features; we just did some basic testing. We discovered then that Byte also released similar products, both using the same large models – Claude-3.5 – at their core.
Byte’s product is called Trae, initially launched in the Mac version and finally released its Windows version in February of this year. Big companies are good because you can freely “white嫖” (literally translates to &amp;ldquo;free grab&amp;rdquo;), without having to pay, with unlimited use of Claude-3.5. The performance of this model is quite impressive.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Ultimately, we got stuck on the development of candlestick charts. As I don’t understand React at all, I had to give up. To continue developing, I would need to supplement my knowledge of front-end basics, breaking down the task into smaller, more manageable pieces instead of giving a single large task: developing candlestick charts.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;issues-found&#34;&gt;Issues Found
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Due to the lack of sufficient training data using foreign AI models, and Vue3 + Element-Plus, we chose React as the frontend framework.&lt;/li&gt;
&lt;li&gt;There may be occasional syntax errors requiring manual fixes.&lt;/li&gt;
&lt;li&gt;Solutions for some complex problems require manual guidance.&lt;/li&gt;
&lt;li&gt;Code structure optimization requires manual instruction.&lt;/li&gt;
&lt;li&gt;The most time-consuming part was packaging the frontend code into a container – this was due to my zero experience with &lt;code&gt;.env.production&lt;/code&gt; and &lt;code&gt;tsconfig.json&lt;/code&gt;, completely lacking understanding of these concepts; I sought help from community members along the way to sort out the logic. There are significant differences between the development (dev) mode and build mode in frontend development, and the checks performed on code. Backend database and service container scripts were completed in a total of five minutes.
&lt;strong&gt;Currently, AI primarily focuses on increasing development efficiency; having a foundation is best, not relying on AI to solve all problems.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;repository-address&#34;&gt;Repository Address
&lt;/h2&gt;&lt;p&gt;As the title indicates, this time we&amp;rsquo;re going to chat with AI without actually coding and see what we can achieve.  Let’s take a look at the final outcome.&lt;/p&gt;
&lt;p&gt;Repository Address: &lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/trae-demo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/trae-demo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For detailed usage instructions, please refer to the README.md file in the repository.&lt;/p&gt;
&lt;p&gt;The repository contains numerous submission records, most of which are conversations between me and Trae, as well as my testing of Trae’s functionalities, with notes on whether manual intervention was used to implement each feature.&lt;/p&gt;
&lt;h2 id=&#34;prompt&#34;&gt;Prompt
&lt;/h2&gt;&lt;p&gt;The project involves developing functionality from scratch, based on the following prompt:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Based on the project prototype diagram, develop features including: stock selection (portfolio management), which requires support for adding, deleting, modifying, and querying contracts. The stock selection interface needs to display basic market data. Support multiple different market switches.

Frontend: React
Backend: Golang Gin GORM
Database: PostgreSQL

The backend needs to support cross-domain requests, while also considering data validation and error handling. If the backend service is unavailable, the frontend should display an alert message.

The backend needs to log requests and responses; the frontend also prints communication logs for troubleshooting purposes.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;ui-and-interaction-optimization&#34;&gt;UI and Interaction Optimization
&lt;/h2&gt;&lt;p&gt;The design of the front-end interface relies entirely on Grok. We initially created a prototype within Trae, but it lacked aesthetics. Because the model used has strong coding capabilities but weaker other abilities, we need to use Grok to optimize the front-end UI.&lt;/p&gt;
&lt;p&gt;By taking screenshots of the current interface and uploading them to Grok, we can receive numerous optimization suggestions at once. We then manually evaluate these suggestions and copy them into Trae to execute and observe the results of the optimizations.&lt;/p&gt;
&lt;h3 id=&#34;technology-stack&#34;&gt;Technology Stack
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Frontend: React + TypeScript&lt;/li&gt;
&lt;li&gt;Backend: Golang + Gin + GORM&lt;/li&gt;
&lt;li&gt;Database: PostgreSQL 17&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;system-architecture&#34;&gt;System Architecture
&lt;/h2&gt;&lt;h2 id=&#34;backend-architecture&#34;&gt;Backend Architecture
&lt;/h2&gt;&lt;p&gt;The backend utilizes the Gin framework (Go) to implement RESTful APIs, with the following key modules:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Database Module&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Utilizes GORM as an ORM framework&lt;/li&gt;
&lt;li&gt;Supports database connection configuration via environment variables&lt;/li&gt;
&lt;li&gt;Automatically performs database schema migrations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Routing Module&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;RESTful API design&lt;/li&gt;
&lt;li&gt;A unified error handling mechanism&lt;/li&gt;
&lt;li&gt;Built-in request logging&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cross-Origin Handling&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Supports cross-origin requests from local development environments&lt;/li&gt;
&lt;li&gt;Configurable CORS policies&lt;/li&gt;
&lt;li&gt;Cookie cross-domain support&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;frontend-architecture&#34;&gt;Frontend Architecture
&lt;/h2&gt;&lt;p&gt;The frontend was built using React + TypeScript, implementing the following features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stock list display&lt;/li&gt;
&lt;li&gt;Watchlist management&lt;/li&gt;
&lt;li&gt;Real-time quote data display&lt;/li&gt;
&lt;li&gt;Error handling mechanism&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Protobuf Zero Value Pitfalls: When Default Values Become an Invisible Killer of Business Logic</title>
        <link>https://ttf248.life/en/p/protobuf-zero-value-trap/</link>
        <pubDate>Thu, 20 Feb 2025 15:26:51 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/protobuf-zero-value-trap/</guid>
        <description>&lt;p&gt;The US stock market has three trading sessions: pre-market, live market, and post-market. The logic for pushing data – whether it’s full data or numerical increments – is optimized to conserve bandwidth (sending as little data as possible). Initially, a full dataset is sent in the first transmission, and subsequent transmissions are incremental updates of all fields.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Why not use the optimal solution? This involves multiple project teams, some of which have been live for many years. As we’re a new integration, we can only try to be compatible with existing systems.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;a-series-of-issues&#34;&gt;A Series of Issues
&lt;/h2&gt;&lt;p&gt;Just from the summary, it might seem like there aren&amp;rsquo;t any problems, but once the system architecture is brought in, a series of issues arise. Immediately after resolving the previous issue, a new one emerged – this problem was caused by the prior one.&lt;/p&gt;
&lt;h3 id=&#34;unable-to-identify-trading-intervals&#34;&gt;Unable to Identify Trading Intervals
&lt;/h3&gt;&lt;p&gt;The market phase is defined in &lt;code&gt;protobuf&lt;/code&gt; as 0, but because it’s received via incremental push, the business side cannot effectively identify whether this ‘0’ represents the default value or a genuine business value.&lt;/p&gt;
&lt;p&gt;In simpler terms: Each time a &amp;lsquo;0&amp;rsquo; is received, it’s impossible to determine if it’s the new market phase setting or the &lt;code&gt;protobuf&lt;/code&gt; default value.&lt;/p&gt;
&lt;h3 id=&#34;introducing-optional&#34;&gt;Introducing Optional
&lt;/h3&gt;&lt;p&gt;Since protobuf release 3.15, proto3 supports using the optional keyword (just as in proto2) to provide presence information for scalar fields.&lt;/p&gt;
&lt;p&gt;The communication protocol within the group is based on &lt;code&gt;protobuf&lt;/code&gt;, but due to historical reasons, the version selected was older and did not support the &lt;code&gt;optional&lt;/code&gt; keyword. As you know, because we’re introducing &lt;code&gt;protobuf&lt;/code&gt; from the ground up, the project publishes its underlying static library, which necessitates upgrading the entire build chain – a very high cost.&lt;/p&gt;
&lt;h3 id=&#34;gcc-version-issues&#34;&gt;GCC Version Issues
&lt;/h3&gt;&lt;p&gt;After painstakingly devising a solution – deploying two different versions of the underlying release to control &lt;code&gt;protobuf&lt;/code&gt;’s new version compilation dependencies as much as possible – we encountered an issue during compilation. The &lt;code&gt;gcc&lt;/code&gt; version was too low, preventing support for &lt;code&gt;protobuf&lt;/code&gt;&amp;rsquo;s new features.&lt;/p&gt;
&lt;p&gt;Common server types within our team: CentOS 7 and CentOS 8.  The default &lt;code&gt;gcc&lt;/code&gt; version on CentOS 7 is 4.8, while the default on CentOS 8 is 8.3. Since &lt;code&gt;protobuf&lt;/code&gt;’s new features require a &lt;code&gt;gcc&lt;/code&gt; version of 7.4 or higher, CentOS 7 could not support it.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://gcc.gnu.org/bugzilla/show_bug.cgi?id=82461&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Bug 82461 - [7 Regression] Temporary required for brace-initializing (non-literal-type) member variable&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Ultimately, after considerable troubleshooting, we moved the deployments and compilation servers to CentOS 8, resolving this problem.&lt;/p&gt;
&lt;h2 id=&#34;reasonable-enumeration&#34;&gt;Reasonable Enumeration
&lt;/h2&gt;&lt;p&gt;Reviewing the entire problem, there’s a simpler and more efficient solution: adjust the enumeration definition to start numbering from 1 instead of 0. This effectively distinguishes between default values and business values, avoiding all the aforementioned issues.&lt;/p&gt;
&lt;h3 id=&#34;why-starting-from-1-is-more-reasonable&#34;&gt;Why Starting from 1 is More Reasonable?
&lt;/h3&gt;&lt;p&gt;In &lt;code&gt;protobuf&lt;/code&gt;, enum types have a default value fixed to 0. If we define meaningful business values as 0 (e.g., &amp;ldquo;Market Open&amp;rdquo;), in incremental pushes, the business side cannot determine whether the received 0 is a business value or an unset default value.  If instead, we defined the enumeration starting from 1, 0 could be retained as a meaningless default value or “Unknown” state, resolving the issue neatly.&lt;/p&gt;
&lt;p&gt;Recommended Practice:
When designing &lt;code&gt;protobuf&lt;/code&gt; enums, always define 0 as a meaningless default value (e.g., &lt;code&gt;UNKNOWN&lt;/code&gt; or &lt;code&gt;RESERVED&lt;/code&gt;).
Assign actual business values starting from 1 to ensure they are distinguished from the default value of 0.&lt;/p&gt;
&lt;p&gt;With this small adjustment, we not only resolved the issue of identifying trading hours but also provided a valuable lesson for future protocol design.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Background Service TCP Communication Anomaly Troubleshooting</title>
        <link>https://ttf248.life/en/p/backend-service-tcp-communication-troubleshooting/</link>
        <pubDate>Fri, 14 Feb 2025 22:54:13 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/backend-service-tcp-communication-troubleshooting/</guid>
        <description>&lt;p&gt;Business Model: The backend service establishes a connection with the group’s market data gateway using TCP. Each time a connection is established, it must first send an authorization request and then continuously send heartbeat packages to maintain the connection status.&lt;/p&gt;
&lt;p&gt;However, one day, an alert message was received indicating that the service had disconnected. After carefully examining the logs, it was discovered that the backend service was continuously sending heartbeat packages, but the other party did not respond at all, yet the connection remained open.&lt;/p&gt;
&lt;h2 id=&#34;on-site-summary&#34;&gt;On-Site Summary
&lt;/h2&gt;&lt;p&gt;I was originally working late in the office to advance project progress when an alarm message suddenly popped up in our work group. At first glance, I thought it was just a recurring issue – likely due to network timeouts causing heartbeat failures, leading to service disconnection. However, after careful log examination, the actual situation turned out to be different. The backend had already sent authorization messages, but they were never acknowledged. Meanwhile, heartbeat packets continued to send persistently, yet the other party never responded with any heartbeat data. After in-depth analysis of the logs, several key issues were exposed:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Authorization message without response: This was likely due to the other system being in the process of restarting, which prevented the authorization message from being processed promptly.&lt;/li&gt;
&lt;li&gt;Sending heartbeat data despite unsuccessful authorization: Upon investigation, it was found that this was a logical flaw in the program’s logic. - The judgment logic of the heartbeat sending function has a defect; it only checks the connection status but misses verifying the authorization status.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;If the service can disconnect, a reconnection mechanism can be triggered to resend the authorization message.&lt;/li&gt;
&lt;li&gt;Currently, the last urgent problem is why the service hasn’t disconnected. Resolving this issue requires more in-depth and detailed troubleshooting work.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;analyzing-network-packets&#34;&gt;Analyzing Network Packets
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;tcpdump&lt;/code&gt; is a very powerful network packet capture tool that can be used to capture network packets. By analyzing network packets, we can gain a more intuitive understanding of the details of network communication. Here, we can use &lt;code&gt;tcpdump&lt;/code&gt; to capture network packets for further analysis.
&lt;img src=&#34;https://ttf248.life/p/backend-service-tcp-communication-troubleshooting/20250220151952.png&#34;
	width=&#34;1126&#34;
	height=&#34;202&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;tcpdump&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;557&#34;
		data-flex-basis=&#34;1337px&#34;
	
&gt;
Analyzing the data in the diagram, I see that the heartbeat is constantly sending normally, and the other server did not respond with any data, but sent an &lt;code&gt;ACK&lt;/code&gt;, which prevents the connection from disconnecting proactively.&lt;/p&gt;
&lt;h2 id=&#34;common-flag-bit-explanation&#34;&gt;Common Flag Bit Explanation
&lt;/h2&gt;&lt;p&gt;In the TCP protocol, &lt;code&gt;PSH&lt;/code&gt; (Push) and &lt;code&gt;ACK&lt;/code&gt; (Acknowledgment) are two important flag bits used to control data transmission and traffic confirmation, respectively. Their functions are as follows:&lt;/p&gt;
&lt;h3 id=&#34;1-psh-push-flag&#34;&gt;&lt;strong&gt;1. PSH (Push Flag)&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Function:&lt;/strong&gt; The &lt;code&gt;PSH&lt;/code&gt; flag serves to &lt;strong&gt;request that the receiver immediately push data from the buffer to the upper-layer application&lt;/strong&gt; (rather than waiting for the buffer to fill). This means that once a data segment with the &lt;code&gt;PSH&lt;/code&gt; flag is received, the receiver will process and transmit it as quickly as possible to the application, rather than storing it in an operating system buffer.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Typical Scenarios:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;HTTP/HTTPS Requests:&lt;/strong&gt; Clients setting &lt;code&gt;PSH&lt;/code&gt; when sending requests (e.g., &lt;code&gt;GET /index.html&lt;/code&gt;) to ensure immediate response from the server.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SSH Protocol:&lt;/strong&gt; Each keystroke triggers &lt;code&gt;PSH&lt;/code&gt;, ensuring real-time transmission of input characters.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Real-Time Communication:&lt;/strong&gt; Low-latency scenarios like video streaming or online games may utilize &lt;code&gt;PSH&lt;/code&gt; to reduce latency. - &lt;strong&gt;Note:&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PSH&lt;/code&gt; is not mandatory; the receiver can choose to ignore this flag (but must still process the data correctly).&lt;/li&gt;
&lt;li&gt;The sender may not set &lt;code&gt;PSH&lt;/code&gt;; in this case, the receiver will determine when to push data based on its own buffering policy.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-ack-acknowledgment-flag&#34;&gt;&lt;strong&gt;2. ACK (Acknowledgment Flag)&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Function:&lt;/strong&gt; The ACK flag indicates that the preceding data segment has been &lt;strong&gt;acknowledged as received correctly&lt;/strong&gt;. Each ACK contains an acknowledgment number (Acknowledgment Number), representing the expected next byte sequence number. It is the core mechanism of TCP reliable transmission.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Working Principle:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;When the sender transmits a data segment, it carries the expected ACK value from the receiver (e.g., &lt;code&gt;ACK = Sequence Number + Data Length&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Upon receiving the data, the receiver generates an ACK message to acknowledge the received byte sequence number.&lt;/li&gt;
&lt;li&gt;The sender only retransmits unacknowledged data after receiving the corresponding ACK.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Example:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;If the sender transmits a data segment with sequence numbers &lt;code&gt;100~199&lt;/code&gt;, then the expected ACK from the receiver should be &lt;code&gt;200&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-combination-of-psh-and-ack&#34;&gt;&lt;strong&gt;3. Combination of PSH and ACK&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;In the TCP header, &lt;code&gt;PSH&lt;/code&gt; and &lt;code&gt;ACK&lt;/code&gt; can appear simultaneously, commonly seen in the following scenarios:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;HTTP Request Response&lt;/strong&gt;:
When a client sends a &lt;code&gt;POST&lt;/code&gt; request (including data), it sets both &lt;code&gt;PSH&lt;/code&gt; and &lt;code&gt;ACK&lt;/code&gt; (to acknowledge previous responses).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Command Transmission after SSH Handshake&lt;/strong&gt;:
After the client enters a command, it sends a data segment with &lt;code&gt;PSH&lt;/code&gt; and &lt;code&gt;ACK&lt;/code&gt;, ensuring that the command is immediately transmitted and processed by the server.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;4-other-flagged-associations&#34;&gt;&lt;strong&gt;4. Other Flagged Associations&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Flag&lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Brief Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;SYN&lt;/td&gt;
&lt;td&gt;Synchronize&lt;/td&gt;
&lt;td&gt;Initiate connection (three-way handshake)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;4-other-flagged-associations-1&#34;&gt;&lt;strong&gt;4. Other Flagged Associations&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Flag&lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Brief Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;FIN&lt;/td&gt;
&lt;td&gt;End&lt;/td&gt;
&lt;td&gt;Graceful connection closure&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;4-other-flagged-associations-2&#34;&gt;&lt;strong&gt;4. Other Flagged Associations&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Flag&lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Brief Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;RST&lt;/td&gt;
&lt;td&gt;Reset&lt;/td&gt;
&lt;td&gt;Forcefully terminates the connection (exceptional circumstances)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;4-other-flagged-associations-3&#34;&gt;&lt;strong&gt;4. Other Flagged Associations&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Flag&lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Brief Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;URG&lt;/td&gt;
&lt;td&gt;Urgent&lt;/td&gt;
&lt;td&gt;Marks an urgent pointer (rarely used)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;4-other-flagged-associations-4&#34;&gt;&lt;strong&gt;4. Other Flagged Associations&lt;/strong&gt;
&lt;/h3&gt;&lt;h3 id=&#34;summary&#34;&gt;Summary
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PSH&lt;/strong&gt; focuses on &lt;strong&gt;data arriving at the application layer as quickly as possible&lt;/strong&gt;, reducing latency.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ACK&lt;/strong&gt; focuses on &lt;strong&gt;reliable data transmission&lt;/strong&gt;, avoiding packet loss or out-of-order delivery.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The two work together to balance TCP protocol efficiency and reliability.&lt;/p&gt;</description>
        </item>
        <item>
        <title>ollama local deployment of deepseek-R1</title>
        <link>https://ttf248.life/en/p/ollama-local-deployment-deepseek-r1/</link>
        <pubDate>Fri, 07 Feb 2025 22:41:02 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/ollama-local-deployment-deepseek-r1/</guid>
        <description>&lt;p&gt;Ollama is an open-source AI tool designed to enable users to run and deploy large language models (LLMs) locally. Its goal is to provide a convenient and efficient way for developers to use models like GPT on their local machines without relying on cloud services. Ollama supports multiple models and focuses on optimizing performance, allowing even resource-constrained devices to smoothly run these models.&lt;/p&gt;
&lt;p&gt;Through Ollama, users can utilize text-based AI applications and interact with locally deployed models without concerns about data privacy or high API usage fees. You can invoke different models via a command-line interface (CLI) for tasks such as natural language processing and question answering. &amp;gt; ollama is suitable for trying out different models, and after testing the Windows version, it couldn&amp;rsquo;t fully leverage the hardware’s performance – this may be due to the Windows version. When deploying 32b parameter models with low memory and GPU load, the response speed is very slow.&lt;/p&gt;
&lt;h2 id=&#34;hardware-overview&#34;&gt;Hardware Overview
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Operating System: Windows 11&lt;/li&gt;
&lt;li&gt;CPU: i7-10700K&lt;/li&gt;
&lt;li&gt;Memory: 40GB&lt;/li&gt;
&lt;li&gt;Graphics Card: RTX 3060 12GB&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;environment-setup&#34;&gt;Environment Setup
&lt;/h2&gt;&lt;p&gt;Add the following system environment variables for easier use:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_MODELS=E:\ollama&lt;/code&gt;&lt;/strong&gt;
This variable specifies the location where Ollama models are stored. &lt;code&gt;E:\ollama&lt;/code&gt; is a folder path indicating that all local model files will be stored in this directory. Ollama will load and use the language models you download or deploy based on this path. You can store your model files in another location by simply changing this path.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_HOST=127.0.0.1:8000&lt;/code&gt;&lt;/strong&gt;
This environment variable sets the host and port for the Ollama service.
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;127.0.0.1&lt;/code&gt; is the localhost address, meaning the Ollama service will only listen for requests from the local machine.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;8000&lt;/code&gt; is the specified port number, indicating that the Ollama service will wait for and process requests on port 8000.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;environment-setup-1&#34;&gt;Environment Setup
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_ORIGINS=*&lt;/code&gt;&lt;/strong&gt;
This environment variable controls which origins are allowed to access the Ollama service.
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;*&lt;/code&gt; indicates that all sources (i.e., all domains and IP addresses) are permitted to access Ollama service. This is typically used in development and debugging environments, where production environments usually specify stricter origin control, limiting only specific domains or IPs to access your service to improve security.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;deepseek-r1-model-deployment&#34;&gt;DeepSeek-R1 Model Deployment
&lt;/h2&gt;&lt;p&gt;ollama installation is straightforward, so we won&amp;rsquo;t detail it here.&lt;/p&gt;
&lt;p&gt;Post-installation verification:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core&amp;gt;ollama -v
ollama version is 0.5.11
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To deploy the model, refer to the official model page and select the appropriate parameter model: &lt;code&gt;ollama run deepseek-r1:14b&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The 14b parameter version effectively remembers conversation context; smaller parameter versions cannot retain context. The 32b parameter version is very sluggish when deployed locally and hasn&amp;rsquo;t been further tested.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ollama.com/library/deepseek-r1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.ollama.com/library/deepseek-r1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/x18990027/article/details/145368094&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/x18990027/article/details/145368094&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>PowerShell 7 and Persistent Settings Command-Line Prediction View</title>
        <link>https://ttf248.life/en/p/powershell-7-persisting-settings-commandline-prediction-view/</link>
        <pubDate>Fri, 07 Feb 2025 22:19:12 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/powershell-7-persisting-settings-commandline-prediction-view/</guid>
        <description>&lt;p&gt;“I’d gotten used to using zsh on Linux, and when I was writing a blog post the other day, I suddenly realized that PowerShell 7 also supports persistent command-line prediction views, so I tried it out. It turns out it&amp;rsquo;s pretty handy.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I don’t know what I did to enable this feature, but it just appeared.”&lt;/p&gt;
&lt;/blockquote&gt;
e&gt;
&lt;h2 id=&#34;powershell-7-a-powerful-tool-across-platforms&#34;&gt;PowerShell 7: A Powerful Tool Across Platforms
&lt;/h2&gt;&lt;h3 id=&#34;cross-platform-features&#34;&gt;Cross-Platform Features
&lt;/h3&gt;&lt;p&gt;PowerShell 7 breaks down platform limitations, allowing you to perform enterprise-level server management on Windows systems, system administration in Linux environments, or daily development tasks on macOS – all with a unified PowerShell 7 tool. This significantly increases productivity and reduces the learning curve and operational complexity associated with platform differences.&lt;/p&gt;
&lt;h3 id=&#34;powerful-features&#34;&gt;Powerful Features
&lt;/h3&gt;&lt;p&gt;It possesses powerful scripting capabilities, supporting object-oriented programming, functions, modules, and other advanced programming features. Through PowerShell 7, users can easily operate the file system, create, delete, copy, move, and perform other operations on files and folders; it can access and modify the registry to deeply adjust system configurations; it can manage processes and services to effectively monitor and control the system&amp;rsquo;s running status. Furthermore, PowerShell 7 can interact with various Windows and non-Windows technologies, such as user and permission management in Active Directory and resource allocation and management on the Azure cloud platform.&lt;/p&gt;
&lt;h3 id=&#34;open-source-ecosystem&#34;&gt;Open Source Ecosystem
&lt;/h3&gt;&lt;p&gt;PowerShell 7 is open source, a feature that allows developers and enthusiasts worldwide to actively participate in its development and improvement. A large number of open-source modules and tools are constantly emerging, enriching the functionality and application scenarios of PowerShell 7. Users can find suitable modules within the open-source community to extend the capabilities of PowerShell 7 or contribute their own code to drive the development of the entire community.&lt;/p&gt;
&lt;h3 id=&#34;compatibility-and-stability&#34;&gt;Compatibility and Stability
&lt;/h3&gt;&lt;p&gt;PowerShell 7 maintains compatibility with older versions of PowerShell while introducing many new features and improvements. These enhancements not only improve performance but also increase stability, allowing users to complete various tasks more smoothly and reducing disruptions caused by software failures.&lt;/p&gt;
&lt;h2 id=&#34;enable-command-line-prediction-view&#34;&gt;Enable Command-Line Prediction View
&lt;/h2&gt;&lt;p&gt;Within the many useful features of PowerShell 7, the &lt;code&gt;Set-PSReadLineOption -PredictionViewStyle ListView&lt;/code&gt; command is a practical tool that enhances the user&amp;rsquo;s command-line input experience.&lt;/p&gt;
&lt;p&gt;While the command itself isn’t necessary to achieve auto-completion, it only provides in-line completion; once enabled, it allows for prediction view, displaying all possible completion options in a list format. Users can then select the desired option using the up and down arrow keys, thereby improving the accuracy and efficiency of command input.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/powershell-7-persisting-settings-commandline-prediction-view/20250207222546.png&#34;
	width=&#34;814&#34;
	height=&#34;205&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;powershell7&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;397&#34;
		data-flex-basis=&#34;952px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;methods-to-make-commands-persistent&#34;&gt;Methods to Make Commands Persistent
&lt;/h2&gt;&lt;p&gt;To ensure that the &lt;code&gt;Set-PSReadLineOption -PredictionViewStyle ListView&lt;/code&gt; command takes effect every time PowerShell starts, we can add it to PowerShell&amp;rsquo;s profile. A PowerShell profile is a special script that automatically executes its commands when PowerShell launches.&lt;/p&gt;
&lt;h3 id=&#34;determine-configuration-file-path&#34;&gt;Determine Configuration File Path
&lt;/h3&gt;&lt;p&gt;In PowerShell, we can use the &lt;code&gt;$PROFILE&lt;/code&gt; variable to view the path of the configuration file. If the file does not exist under that path, users can manually create one.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;echo $PROFILE
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;open-configuration-file&#34;&gt;Open Configuration File
&lt;/h3&gt;&lt;p&gt;Use a text editor, such as the powerful Notepad++ or the lightweight Visual Studio Code, to open the file corresponding to the configuration file path obtained through the &lt;code&gt;$PROFILE&lt;/code&gt; variable.&lt;/p&gt;
&lt;h3 id=&#34;add-command&#34;&gt;Add Command
&lt;/h3&gt;&lt;p&gt;In the opened configuration file, add the command &lt;code&gt;Set-PSReadLineOption -PredictionViewStyle ListView&lt;/code&gt;. Ensure that the command is written accurately to guarantee that the configuration file takes effect correctly when executed.&lt;/p&gt;
&lt;h3 id=&#34;save-configuration&#34;&gt;Save Configuration
&lt;/h3&gt;&lt;p&gt;After adding the commands, save the configuration file and close the text editor. At this point, the configuration file contains the commands we want to execute every time PowerShell starts.&lt;/p&gt;
&lt;h3 id=&#34;verification-settings&#34;&gt;Verification Settings
&lt;/h3&gt;&lt;p&gt;Close the current PowerShell window and restart PowerShell. In the newly launched PowerShell, when entering commands, the command-line input prediction view style should already be displayed in list view according to our settings, indicating that our settings have been successfully applied.&lt;/p&gt;
&lt;p&gt;Through these steps, we not only gained a deeper understanding of the powerful features and characteristics of PowerShell 7 but also learned how to use the command-line input prediction view style to enhance the user experience, and how to make these settings persistent. We hope this knowledge can help you operate PowerShell 7 more confidently and efficiently complete various system management and automation tasks.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/PowerShell/PowerShell/releases&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/PowerShell/PowerShell/releases&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.v2ex.com/t/911909&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.v2ex.com/t/911909&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Mastering atop: A Comprehensive Guide to Monitoring Linux System Metrics – Installation, Configuration, and Usage</title>
        <link>https://ttf248.life/en/p/atop-linux-system-monitoring-guide/</link>
        <pubDate>Thu, 06 Feb 2025 22:48:55 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/atop-linux-system-monitoring-guide/</guid>
        <description>&lt;p&gt;In Linux system administration, real-time and comprehensive monitoring of system resources and process status is crucial. The atop tool, as a powerful monitoring utility, helps us easily achieve this goal. This article will provide a detailed introduction on how to install, configure, and use the atop monitoring tool in a Linux instance.&lt;/p&gt;
&lt;h2 id=&#34;i-atop-tool-introduction&#34;&gt;I. atop Tool Introduction
&lt;/h2&gt;&lt;p&gt;atop is a tool specifically designed for monitoring Linux system resources and processes. It records the activity of systems and processes, and reports on the running status of all processes. The data collected by this tool covers resource usage such as CPU, memory, disk, and network, as well as process states. It can also save the data in log files to disk. For each process, we can obtain key information such as CPU utilization, memory growth, disk usage, priority, username, status, and exit code. Furthermore, through the atop configuration file, we can customize parameters such as logging collection frequency, log file storage path, and rotation strategy.&lt;/p&gt;
&lt;h2 id=&#34;ii-installing-the-atop-tool&#34;&gt;II. Installing the atop Tool
&lt;/h2&gt;&lt;p&gt;The installation method for atop varies slightly depending on the Linux distribution. The following provides an introduction based on common operating systems:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Alibaba Cloud Linux 3/2, CentOS 7/8, Fedora, Rocky Linux 9:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Execute the installation command: &lt;code&gt;sudo yum install -y atop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ubuntu / Debian:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Update the software source list: &lt;code&gt;sudo apt update&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Execute the installation command: &lt;code&gt;sudo apt install -y atop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;CentOS Stream 9:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download and install: &lt;code&gt;sudo wget https://www.atoptool.nl/download/atop-2.11.0-1.el9.x86_64.rpm &amp;amp;&amp;amp; sudo rpm -i atop-2.11.0-1.el9.x86_64.rpm&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;ii-installing-the-atop-tool-1&#34;&gt;II. Installing the atop Tool
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;openSUSE&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;Execute the installation command: &lt;code&gt;sudo zypper install -y atop atop-daemon&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;
If your distribution is not listed above, you can visit the official atop website for installation information.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;iii-configuring-monitoring-cycle-and-log-retention-time&#34;&gt;III. Configuring Monitoring Cycle and Log Retention Time
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Configuration File Location:&lt;/strong&gt; In Alibaba Cloud Linux 3/2, CentOS 7/8, and Fedora systems, the atop configuration file is &lt;code&gt;/etc/sysconfig/atop&lt;/code&gt;; in Ubuntu, Debian, and openSUSE systems, the configuration file is &lt;code&gt;/etc/default/atop&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Default Configuration Parameter Explanation&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;LOGOPTS&lt;/code&gt;: Controls logging options for log files, defaults to empty.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LOGINTERVAL&lt;/code&gt;: Monitoring cycle, default 600 seconds. To collect historical logs for tracking issues, it&amp;rsquo;s recommended to adjust this frequency based on actual needs.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LOGGENERATIONS&lt;/code&gt;: Log retention time, default 28 days.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LOGPATH&lt;/code&gt;: Log file storage path, defaults to &lt;code&gt;/var/log/atop&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;iii-configure-monitoring-cycle-and-log-retention-time&#34;&gt;III. Configure Monitoring Cycle and Log Retention Time
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Configuration Steps&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Execute the command to open the configuration file:
&lt;ul&gt;
&lt;li&gt;In Alibaba Cloud Linux 3/2, CentOS 7/8, Fedora systems: &lt;code&gt;sudo vim /etc/sysconfig/atop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;In Ubuntu, Debian, openSUSE, CentOS Stream 9, Rocky Linux 9 systems: &lt;code&gt;sudo vim /etc/default/atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Press ‘i’ to enter edit mode and adjust the configuration parameters according to your needs. For example, change the monitoring cycle to 30 seconds, set the log retention time to 7 days, and maintain the default log path:&lt;/li&gt;
&lt;li&gt;Press ‘Esc’ to return to normal editing mode, type &lt;code&gt;:wq&lt;/code&gt; to save and exit.&lt;/li&gt;
&lt;li&gt;Restart the atop service to apply the configuration: &lt;code&gt;sudo systemctl restart atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;LOGOPTS=&amp;quot;&amp;quot;
LOGINTERVAL=30
LOGGENERATIONS=7
LOGPATH=/var/log/atop 
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;four-using-atop-tool&#34;&gt;Four. Using atop Tool
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Common Commands:&lt;/strong&gt; In interactive command mode, the following commands are commonly used:
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;g&lt;/code&gt;: Return to the default comprehensive output view.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;c&lt;/code&gt;: Display the full command line for each process.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;m&lt;/code&gt;: Sort processes by memory usage in descending order.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;d&lt;/code&gt;: Sort processes by disk usage in descending order.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;a&lt;/code&gt;: Sort processes by overall resource usage in descending order.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;n&lt;/code&gt;: Sort processes by network usage in descending order.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;t&lt;/code&gt;: Jump to the next monitoring collection point.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;T&lt;/code&gt;: Jump to the previous monitoring collection point.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;b&lt;/code&gt;: Specify a timestamp in the format &lt;code&gt;YYYYMMDDhhmm&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;four-using-the-atop-tool&#34;&gt;Four. Using the atop Tool
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Resource Monitoring Field Meanings&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;atop&lt;/strong&gt;: Hostname, sampling date and time point.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PRC&lt;/strong&gt;: Overall process running status, including kernel state and user state runtime, total process count, number of processes in different states, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CPU&lt;/strong&gt;: Overall CPU usage, the sum of the numbers is &lt;code&gt;N*100%&lt;/code&gt; (N is the number of CPU cores), including the proportion of time for kernel state, user state, interrupt, idle, and disk I/O waiting.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CPL&lt;/strong&gt;: CPU load situation, such as the average number of processes in the queue over 1 minute, 5 minutes, and 15 minutes, context switch times, and interrupt occurrences.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MEM&lt;/strong&gt;: Memory usage, including total physical memory, free memory, page cache memory, file cache memory, and kernel occupied memory, etc. - &lt;strong&gt;SWP:&lt;/strong&gt; Swap space utilization, including total swap area and available swap space size.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PAG:&lt;/strong&gt; Virtual memory page situation, such as inbound and outbound memory page numbers.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DSK:&lt;/strong&gt; Disk usage, with each disk device corresponding to a column, displaying device identifier, busy time proportion, read/write request quantity.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NET:&lt;/strong&gt; Network status, showcasing transport layer TCP and UDP, IP layer, and receive and send packet sizes for each active port.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;four-using-the-atop-tool-1&#34;&gt;Four. Using the atop Tool
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;View Real-time System Metrics&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;View system metrics every 5 seconds: &lt;code&gt;atop 5&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View system metrics from the last 30 intervals (each interval is 10 seconds) after the current time: &lt;code&gt;atop -M 10 30&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View system metrics from the last 10 minutes (10 intervals, each interval is 60 seconds), and write the results to a file: &lt;code&gt;atop -M 60 10 &amp;gt; /log/atop.mem&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;View Historical Metric Logs&lt;/strong&gt;: After atop starts, collected records are stored by default in the &lt;code&gt;/var/log/atop&lt;/code&gt; directory. When viewing, be sure to specify the date of the log file must exist, otherwise it will error. - View daily historical metrics log: &lt;code&gt;atop -r&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View yesterday&amp;rsquo;s historical metrics log: &lt;code&gt;atop -r y&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View historical metrics log for a specific date, such as November 6, 2024: &lt;code&gt;atop -r 20241106&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View historical metrics log from a specific date and time, such as starting from November 6, 2024, 14:00: &lt;code&gt;atop -r 20241106 -b 14:00&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View historical metrics log for a specified time range on a specific date, such as from November 5, 2024, 00:04 to 00:08: &lt;code&gt;atop -r 20241105 -b 00:04 -e 00:08&lt;/code&gt; ## Four. Using the atop Tool&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;View Real-Time System Metrics&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;View system metrics every 5 seconds: &lt;code&gt;atop 5&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View system metrics from the last 30 intervals (each interval is 10 seconds) after the current time: &lt;code&gt;atop -M 10 30&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View system metrics from the last 10 minutes (10 intervals, each interval is 60 seconds), and write the results to a file: &lt;code&gt;atop -M 60 10 &amp;gt; /log/atop.mem&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;View Historical Metric Logs&lt;/strong&gt;: After atop starts, collected records are stored by default in the &lt;code&gt;/var/log/atop&lt;/code&gt; directory. When viewing, be sure to specify the log file for the desired date; otherwise, an error will occur.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;four-using-the-atop-tool-2&#34;&gt;Four. Using the atop Tool
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;View System Activity Report&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;View the CPU utilization report for the current system over 1 minute (12 times, with an interval of 5 seconds): &lt;code&gt;atopsar -c 5 12&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View the memory metrics report for a specified time period during the day, such as 18:00 to 18:01: &lt;code&gt;atopsar -m -b 18:00 -e 18:01&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View the memory metrics report for a specified date and time period, such as November 5, 2024 from 18:00 to 18:01: &lt;code&gt;atopsar -m -r 20241105 -b 18:00 -e 18:01&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;five-other-operations&#34;&gt;Five. Other Operations
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Configure Daily Log Rotation Policy&lt;/strong&gt;: If you want to generate a daily &lt;code&gt;atop&lt;/code&gt; metric log file, you can perform the following actions:
&lt;ul&gt;
&lt;li&gt;(Optional) Adjust monitoring period, log retention time, and log storage path according to your needs.&lt;/li&gt;
&lt;li&gt;Execute the command to enable and start the services related to daily log rotation: &lt;code&gt;sudo systemctl enable --now atop atopacct atop-rotate.timer&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;If your business has more complex requirements for log processing, you can also combine it with &lt;code&gt;logrotate&lt;/code&gt; or custom scripts to implement log management.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;five-other-operations-1&#34;&gt;Five. Other Operations
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Load the optional netatop kernel module:&lt;/strong&gt; If you need to monitor network usage, you can install the netatop module (the module is not installed by default in atop). As an example on Alibaba Cloud Linux 3:
&lt;ul&gt;
&lt;li&gt;Install the kernel development package and the software environment required for compiling: &lt;code&gt;sudo yum install -y kernel-devel dkms elfutils-libelf-devel&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Download the latest version of netatop source code to a specified directory: &lt;code&gt;cd /usr/src/ &amp;amp;&amp;amp; sudo wget https://www.atoptool.nl/download/netatop-3.2.2.tar.gz --no-check-certificate&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Extract the source code and enter the source code directory: &lt;code&gt;sudo tar -zxvf netatop-3.2.2.tar.gz &amp;amp;&amp;amp; cd netatop-3.2.2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Build and install the module and daemon based on the source code: &lt;code&gt;sudo make &amp;amp;&amp;amp; sudo make install&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the netatop service: &lt;code&gt;sudo systemctl start netatop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v-other-operations&#34;&gt;V. Other Operations
&lt;/h2&gt;&lt;p&gt;The atop tool is powerful and flexible to use. By installing, configuring, and using it properly, we can better understand the running status of our Linux system and promptly identify and resolve potential issues. We hope this article will help everyone take Linux system monitoring to a new level.&lt;/p&gt;
&lt;h2 id=&#34;vi-references&#34;&gt;VI. References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.atoptool.nl/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;atop official website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://help.aliyun.com/zh/ecs/use-cases/use-the-atop-tool-to-monitor-linux-system-metrics#99e53d0198euu&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Installation, configuration, and usage of the atop monitoring tool&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Visual Studio loading a mismatched PDB file</title>
        <link>https://ttf248.life/en/p/visual-studio-load-unmatched-pdb/</link>
        <pubDate>Thu, 23 Jan 2025 20:04:33 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/visual-studio-load-unmatched-pdb/</guid>
        <description>&lt;p&gt;When debugging programs under Windows using Visual Studio, if the PDB file does not match the executable file, Visual Studio will display &amp;ldquo;Unable to load symbol file.&amp;rdquo; The program crashes and generates a crash dump. If it&amp;rsquo;s an mismatched PDB file, Visual Studio cannot smoothly enter the crash site.&lt;/p&gt;
&lt;h2 id=&#34;what-is-a-pdb-file&#34;&gt;What is a PDB File?
&lt;/h2&gt;&lt;p&gt;A PDB file is a debugging information file created by Microsoft, used for debugging programs. It contains information such as the symbol table, source code filenames, line numbers, and other debugging data. A PDB file can be generated during program compilation to aid in debugging.&lt;/p&gt;
&lt;h2 id=&#34;windbg-debugging&#34;&gt;WinDbg Debugging
&lt;/h2&gt;&lt;p&gt;WinDbg is a debugging tool from Microsoft that can be used to debug Windows programs. WinDbg can load mismatched PDB files, but this requires manual loading. The &lt;code&gt;.reload /f /i&lt;/code&gt; command forces the loading of mismatched PDB files.&lt;/p&gt;
&lt;p&gt;However, WinDbg is less convenient to use than Visual Studio, so we want Visual Studio to also be able to load mismatched PDB files.&lt;/p&gt;
&lt;h2 id=&#34;visual-studio-cannot-load-matching-pdb-files&#34;&gt;Visual Studio Cannot Load Matching PDB Files
&lt;/h2&gt;&lt;p&gt;Source code is now generally managed through Git, allowing you to find the corresponding version of the code and recompile it to generate a matching PDB file. Why can&amp;rsquo;t it load? The main reason is that metadata doesn’t match.&lt;/p&gt;
&lt;p&gt;There’s a small tool that can modify metadata based on EXE file information to generate a new PDB file, enabling Visual Studio to load it.&lt;/p&gt;
&lt;p&gt;Chkmatch Download Address: &lt;a class=&#34;link&#34; href=&#34;https://www.debuginfo.com/tools/chkmatch.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.debuginfo.com/tools/chkmatch.html&lt;/a&gt;
Site Cache Address: &lt;a class=&#34;link&#34; href=&#34;chkmatch.zip&#34; &gt;chkmatch.zip&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;visual-studio-loading-mismatched-pdb-files&#34;&gt;Visual Studio Loading Mismatched PDB Files
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;The ChkMatch utility can be used to check whether an executable and debug information file match. It can also be used to enforce matching between an executable and debug information file, if they are compatible.

For more information about debug information matching and related issues, see this article.

Supported debug information formats: DBG, PDB 2.0, PDB 7.0.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;visual-studio-loading-mismatched-pdb-files-1&#34;&gt;Visual Studio Loading Mismatched PDB Files
&lt;/h2&gt;&lt;p&gt;Supported debug information formats: DBG, PDB 2.0, PDB 7.0.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;chkmatch [-c ExeFile DebugInfoFile] | [-m ExeFile DebugInfoFile]&lt;/code&gt;
-c
Check matching between the executable and the debug information file.
-m
Make the executable and the debug information file match.
ExeFile
The name of the executable file.
DebugInfoFile
The name of the debug information file.&lt;/p&gt;
&lt;h2 id=&#34;using-chkmatch&#34;&gt;Using chkmatch
&lt;/h2&gt;&lt;p&gt;First perform the check operation, analyze the cause of mismatch, and prompt for an unmatched signature.&lt;/p&gt;
&lt;h2 id=&#34;using-chkmatch-1&#34;&gt;Using chkmatch
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\tianlong.xiang\Downloads\chkmatch&amp;gt;ChkMatch.exe -c &amp;quot;D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe&amp;quot; E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb
ChkMatch - version 1.0
Copyright (C) 2004 Oleg Starodumov
http://www.debuginfo.com/


Executable: D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe
Debug info file: E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;using-chkmatch-2&#34;&gt;Using chkmatch
&lt;/h2&gt;&lt;p&gt;Executable:
TimeDateStamp: c26d9be3
Debug info: 2 ( CodeView )
TimeStamp: f86b0a4f  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 122  RVA: 001cdc44  FileOffset: 001cbe44
CodeView format: RSDS
Signature: {428c9b95-39a3-4a8d-a8e5-7be453684757}  Age: 1
PdbFile: D:\stock_UAT\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\obj\Release\YinTrade.Main.pdb
Debug info: 16 ( Unknown )
TimeStamp: 00000000  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 0  RVA: 00000000  FileOffset: 00000000&lt;/p&gt;
&lt;h2 id=&#34;using-chkmatch-3&#34;&gt;Using chkmatch
&lt;/h2&gt;&lt;p&gt;Debug information file:
Format: PDB 7.00
Signature: {06fae08e-c0a2-4f3d-9c7c-dfc684445dd1}  Age: 1&lt;/p&gt;
&lt;p&gt;Result: Unmatched (reason: Signature mismatch)&lt;/p&gt;
&lt;h2 id=&#34;using-chkmatch-4&#34;&gt;Using chkmatch
&lt;/h2&gt;&lt;p&gt;Then perform the modification operation to match the pdb file with the exe file.&lt;/p&gt;
&lt;h2 id=&#34;using-chkmatch-5&#34;&gt;Using chkmatch
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\tianlong.xiang\Downloads\chkmatch&amp;gt;ChkMatch.exe -m &amp;quot;D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe&amp;quot; E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb
ChkMatch - version 1.0
Copyright (C) 2004 Oleg Starodumov
http://www.debuginfo.com/


Executable: D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe
Debug info file: E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;using-chkmatch-6&#34;&gt;Using chkmatch
&lt;/h2&gt;&lt;p&gt;Executable:
TimeDateStamp: c26d9be3
Debug info: 2 ( CodeView )
TimeStamp: f86b0a4f  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 122  RVA: 001cdc44  FileOffset: 001cbe44
CodeView format: RSDS
Signature: {428c9b95-39a3-4a8d-a8e5-7be453684757}  Age: 1
PdbFile: D:\stock_UAT\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\obj\Release\YinTrade.Main.pdb
Debug info: 16 ( Unknown )
TimeStamp: 00000000  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 0  RVA: 00000000  FileOffset: 00000000&lt;/p&gt;
&lt;h2 id=&#34;using-chkmatch-7&#34;&gt;Using chkmatch
&lt;/h2&gt;&lt;p&gt;Debug information file:
Format: PDB 7.00
Signature: {06fae08e-c0a2-4f3d-9c7c-dfc684445dd1}  Age: 1&lt;/p&gt;
&lt;p&gt;Writing to the debug information file&amp;hellip;
Result: Success.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://stackoverflow.com/questions/38147487/forcing-to-load-unmatched-symbols-in-visual-studio-2015-debugger&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;forcing-to-load-unmatched-symbols-in-visual-studio-2015-debugger&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Cursor AI Programming IDE Trial</title>
        <link>https://ttf248.life/en/p/cursor-ai-programming-ide-trial/</link>
        <pubDate>Thu, 23 Jan 2025 19:30:13 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cursor-ai-programming-ide-trial/</guid>
        <description>&lt;p&gt;It seems like another year has passed, and the biggest change at work is a significant increase in the involvement of AI. Previously, switching between different development languages required developers to be familiar with various language-specific API interfaces. Now, these basic code snippets can all be generated by AI, which is a huge blessing for developers.&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;As early as 23 years ago, I’ve written two simple introductory articles about it. Now it&amp;rsquo;s been 25 years – how to say this? – I haven’t felt a significant improvement. It still needs to develop its own cognition, be able to reasonably break down tasks, and, of course, most importantly, identify whether AI-generated code contains bugs.&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;Github Copilot
&lt;/h2&gt;&lt;p&gt;It was a long time ago, but I saw some information saying that Singapore deployed the server and it’s used domestically. So there&amp;rsquo;s no need to use a VPN for extended periods anymore. However, when logging in, you still need to connect to a VPN. But this VPN only needs to be used during login, and then you can turn it off.&lt;/p&gt;
&lt;p&gt;I use Github Copilot more frequently for daily tasks. This plugin can be directly used in VS Code and Visual Studio without switching between the two applications. Compared to ChatGPT, Github Copilot offers better support for projects, is more user-friendly in interaction, and allows you to feed parts of your local files to it – &lt;strong&gt;“training” the AI&lt;/strong&gt; – so that the generated code is more aligned with your project.&lt;/p&gt;
&lt;h2 id=&#34;cursor-ai&#34;&gt;Cursor AI
&lt;/h2&gt;&lt;p&gt;Recently I’ve come across a new AI programming IDE, Cursor AI. This IDE is based on Github Copilot, but it&amp;rsquo;s more intelligent and can help you create files directly.
I gave it a quick try and found it to be pretty good, however, its understanding of existing projects isn’t quite there yet. When dealing with large local project files, or major refactoring, optimization, and adjustments, developers still need to &lt;strong&gt;break down tasks&lt;/strong&gt;.
Here&amp;rsquo;s an example: Switching to Cursor’s engineering mode, inputting the following content: “Create a personal resume webpage, supporting multiple different styles switching, and remember to fill in some personal information for data display.”
After several back-and-forths, you can get the following webpage – of course, this webpage is relatively simple, but it&amp;rsquo;s still quite good for beginners. ## Cursor AI
Recently I’ve come across a new AI programming IDE, Cursor AI. This IDE is based on Github Copilot, but it&amp;rsquo;s more intelligent and can help you create files directly.
I gave it a quick try and found it to be pretty good, however, its understanding of existing projects isn’t quite there yet. When dealing with large local project files, or major refactoring, optimization, and adjustments, developers still need to &lt;strong&gt;break down tasks&lt;/strong&gt;.
Here&amp;rsquo;s an example: Switching to Cursor’s engineering mode, inputting the following content: “Create a personal resume webpage, supporting multiple different styles switching, and remember to populate some personal information for data display.”
After several back-and-forths (&lt;strong&gt;pulling&lt;/strong&gt; on it), you can get the following webpage. Of course, this webpage is relatively simple, but it’s still quite good for beginners.&lt;/p&gt;
&lt;h2 id=&#34;cursor-ai-1&#34;&gt;Cursor AI
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://ttf248.life/cursor/index.html&#34; &gt;Resume&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>C&#43;&#43; Bitwise Operations Fundamentals: Bitwise Extraction and Flag Setting</title>
        <link>https://ttf248.life/en/p/cpp-bitwise-operations-flags/</link>
        <pubDate>Fri, 17 Jan 2025 02:23:56 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-bitwise-operations-flags/</guid>
        <description>&lt;p&gt;In actual C++ development, bitwise operations are a common technique, especially when dealing with system states, flags, or control bits. Bitwise operations can provide very efficient solutions. This article will illustrate how to use bitwise operations to retrieve and set specific flags through an example.&lt;/p&gt;
&lt;h3 id=&#34;bitwise-operations-fundamentals&#34;&gt;Bitwise Operations Fundamentals
&lt;/h3&gt;&lt;p&gt;In computers, data is stored in binary bits (0 and 1). Bitwise operations are operations performed on these binary bits. C++ provides several commonly used bitwise operators:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Bitwise AND (&amp;amp;)&lt;/strong&gt;: Used to check if a particular bit is set to 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise OR (|)&lt;/strong&gt;: Used to set a particular bit to 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise XOR (^)&lt;/strong&gt;: Used to flip a particular bit.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise NOT (~)&lt;/strong&gt;: Inverts all the bits.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Left Shift (&amp;laquo;)&lt;/strong&gt;: Shifts all bits to the left by a specified number of positions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Right Shift (&amp;raquo;)&lt;/strong&gt;: Shifts all bits to the right by a specified number of positions.
In this example, we need to perform a series of bitwise operations on an &lt;code&gt;unsigned short&lt;/code&gt; variable &lt;code&gt;wInfo&lt;/code&gt; to represent different states using various flags.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bitwise-operations-fundamentals-1&#34;&gt;Bitwise Operations Fundamentals
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;flowchart LR
    A[Original Value: 00010000] --&amp;gt; B[Left Shift: 00010000 &amp;lt;&amp;lt; 1]
    B --&amp;gt; C[Result: 00100000]
    C --&amp;gt; D[Right Shift: 00100000 &amp;gt;&amp;gt; 1]
    D --&amp;gt; E[Result: 00010000]

    subgraph Left Shift Operation
        direction LR
        A --&amp;gt; B --&amp;gt; C
    end

    subgraph Right Shift Operation
        direction LR
        C --&amp;gt; D --&amp;gt; E
    end
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;requirement-analysis&#34;&gt;Requirement Analysis
&lt;/h3&gt;&lt;p&gt;Based on the description, we have a 16-bit flag to represent different states. These states are represented by various binary bits, with each binary bit corresponding to a specific meaning. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;bit0&lt;/strong&gt;: Failure status&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bit1&lt;/strong&gt;: Compression status&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bit2&lt;/strong&gt;: Incremental status&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bit3&lt;/strong&gt;: Presence of subsequent packets&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bit5&lt;/strong&gt;: Normal request or cancellation&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;using-bitwise-operations&#34;&gt;Using Bitwise Operations
&lt;/h3&gt;&lt;p&gt;We will use bitwise operations to set and retrieve these flags. Specifically:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Bitwise AND:&lt;/strong&gt; Retrieve the value of a particular bit (0 or 1).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise OR:&lt;/strong&gt; Set a particular bit to 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise XOR:&lt;/strong&gt; Set a particular bit to 0.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We first define an &lt;code&gt;unsigned short&lt;/code&gt; type variable &lt;code&gt;wInfo&lt;/code&gt; to store these flags. Then, we use bitwise operations to check and set the corresponding flags.&lt;/p&gt;
&lt;h3 id=&#34;c-example-code&#34;&gt;C++ Example Code
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;bitset&amp;gt;

// Define flag constants
const unsigned short BIT_0_FAIL = 1 &amp;lt;&amp;lt; 0;    // Bit0 failed?
const unsigned short BIT_1_COMPRESSED = 1 &amp;lt;&amp;lt; 1; // Bit1 compressed?
const unsigned short BIT_2_INCREMENT = 1 &amp;lt;&amp;lt; 2;  // Bit2 incremented?
const unsigned short BIT_3_HAS_MORE = 1 &amp;lt;&amp;lt; 3;   // Bit3 has more packets?
const unsigned short BIT_5_CANCEL = 1 &amp;lt;&amp;lt; 5;     // Bit5 normal request (0) or cancellation (1)

// Check if a bit is set
bool isBitSet(unsigned short wInfo, unsigned short bitMask) {
    return (wInfo &amp;amp; bitMask) != 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;### C++ Example Code
// Set a bit to 1
void setBit(unsigned short&amp;amp; wInfo, unsigned short bitMask) {
    wInfo |= bitMask;
}

// Clear a bit (set it to 0)
void clearBit(unsigned short&amp;amp; wInfo, unsigned short bitMask) {
    wInfo &amp;amp;= ~bitMask;
}

int main() {
    // Assume wInfo&#39;s initial value is 0
    unsigned short wInfo = 0;

    // Set bit0 (failure flag)
    setBit(wInfo, BIT_0_FAIL);

    // Set bit1 (compressed flag)
    setBit(wInfo, BIT_1_COMPRESSED);

    // Print wInfo&#39;s binary value
    std::cout &amp;lt;&amp;lt; &amp;quot;wInfo (in binary): &amp;quot; &amp;lt;&amp;lt; std::bitset&amp;lt;16&amp;gt;(wInfo) &amp;lt;&amp;lt; std::endl;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;c-example-code-1&#34;&gt;C++ Example Code
&lt;/h3&gt;&lt;p&gt;// Check the various flags
std::cout &amp;laquo; &amp;ldquo;bit0 (failure flag): &amp;quot; &amp;laquo; (isBitSet(wInfo, BIT_0_FAIL) ? &amp;ldquo;yes&amp;rdquo; : &amp;ldquo;no&amp;rdquo;) &amp;laquo; std::endl;
std::cout &amp;laquo; &amp;ldquo;bit1 (compression flag): &amp;quot; &amp;laquo; (isBitSet(wInfo, BIT_1_COMPRESSED) ? &amp;ldquo;yes&amp;rdquo; : &amp;ldquo;no&amp;rdquo;) &amp;laquo; std::endl;
std::cout &amp;laquo; &amp;ldquo;bit2 (incremental flag): &amp;quot; &amp;laquo; (isBitSet(wInfo, BIT_2_INCREMENT) ? &amp;ldquo;yes&amp;rdquo; : &amp;ldquo;no&amp;rdquo;) &amp;laquo; std::endl;
std::cout &amp;laquo; &amp;ldquo;bit3 (more packets flag): &amp;quot; &amp;laquo; (isBitSet(wInfo, BIT_3_HAS_MORE) ? &amp;ldquo;yes&amp;rdquo; : &amp;ldquo;no&amp;rdquo;) &amp;laquo; std::endl;
std::cout &amp;laquo; &amp;ldquo;bit5 (cancel flag): &amp;quot; &amp;laquo; (isBitSet(wInfo, BIT_5_CANCEL) ? &amp;ldquo;yes&amp;rdquo; : &amp;ldquo;no&amp;rdquo;) &amp;laquo; std::endl;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;### C++ Example Code
// Clear bit 1 (compression flag)
    clearBit(wInfo, BIT_1_COMPRESSED);

    // Print the updated wInfo
    std::cout &amp;lt;&amp;lt; &amp;quot;Updated wInfo (in binary): &amp;quot; &amp;lt;&amp;lt; std::bitset&amp;lt;16&amp;gt;(wInfo) &amp;lt;&amp;lt; std::endl;

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;c-example-code-2&#34;&gt;C++ Example Code
&lt;/h3&gt;&lt;p&gt;Execute the code, recommended for old friends: &lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;wInfo (in binary): 0000000000000011
bit0 (failure flag): Yes
bit1 (compression flag): Yes
bit2 (incremental flag): No
bit3 (has subsequent package flag): No
bit5 (log out flag): No
Updated wInfo (in binary): 0000000000000001
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;code-explanation&#34;&gt;Code Explanation
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Flag Definition&lt;/strong&gt;: Use shift operations (&lt;code&gt;1 &amp;lt;&amp;lt; n&lt;/code&gt;) to define each flag bit. For example, &lt;code&gt;1 &amp;lt;&amp;lt; 0&lt;/code&gt; corresponds to &lt;code&gt;bit0&lt;/code&gt;, &lt;code&gt;1 &amp;lt;&amp;lt; 1&lt;/code&gt; corresponds to &lt;code&gt;bit1&lt;/code&gt;, and so on. This way, we allocate a unique binary position for each flag.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Check a Bit&lt;/strong&gt;: The &lt;code&gt;isBitSet&lt;/code&gt; function uses the bitwise AND operation (&lt;code&gt;wInfo &amp;amp; bitMask&lt;/code&gt;) to check if a specific flag is set to 1. If the bit is 1, the function returns &lt;code&gt;true&lt;/code&gt;, otherwise it returns &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Set a Bit&lt;/strong&gt;: The &lt;code&gt;setBit&lt;/code&gt; function uses the bitwise OR operation (&lt;code&gt;wInfo |= bitMask&lt;/code&gt;) to set a specific flag bit to 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clear a Bit&lt;/strong&gt;: The &lt;code&gt;clearBit&lt;/code&gt; function uses the bitwise AND operation (&lt;code&gt;wInfo &amp;amp;= ~bitMask&lt;/code&gt;) to clear a specific flag bit to 0.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary
&lt;/h3&gt;&lt;p&gt;Through bitwise operations, we can efficiently handle multiple state flags. This technique is particularly useful in practical development. For example, in embedded development, network protocols, and system status management scenarios, bit flags are often used to represent multiple binary states, saving space and improving efficiency.&lt;/p&gt;
&lt;p&gt;We hope this blog post helps you understand how to use bitwise operations in C++ to perform bitwise selection and setting, and mastering these skills is very helpful for writing efficient and maintainable code!&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Upgrading from a desktop to a 2.5G network card, accelerating local area network connectivity.</title>
        <link>https://ttf248.life/en/p/desktop-upgrade-to-2-5g-network-card-accelerates-local-area-network-interconnection/</link>
        <pubDate>Fri, 10 Jan 2025 00:37:52 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/desktop-upgrade-to-2-5g-network-card-accelerates-local-area-network-interconnection/</guid>
        <description>&lt;p&gt;Desktop hardware three-in-one, in the previous text we mentioned PCIe adapter for solid state drives, where did the old SSDs go? Of course they weren’t wasted – if they were damaged, they were disassembled and installed on the newly purchased ‘MechMaker Mini-3765H’ (bought a year ago).&lt;/p&gt;
&lt;p&gt;This new machine has powerful hardware specifications: 2.5G dual network interfaces, PCIe4.0, WiFi6.&lt;/p&gt;
&lt;p&gt;Recently I moved house and my room doesn&amp;rsquo;t have a dedicated router for networking, so the machines are connected via wireless networks. The ASUS motherboard desktop’s wireless card performance wasn’t great, or perhaps it was the router’s wireless access, which resulted in slow upload speeds between local networks, leading to poor network speeds between the machines. I purchased a 2.5G network card and installed it on the desktop.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;At this point, all the slots on the motherboard are full: graphics card, wireless card, 2.5G network card, PCIe adapter for solid state drives.&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;network-instructions&#34;&gt;Network Instructions
&lt;/h2&gt;&lt;p&gt;Both machines connect to the internet using their original wireless network cards, but are directly connected via Ethernet cables between the two, with both ends equipped with 2.5G network cards.  The specifics of how to physically connect the cables aren&amp;rsquo;t detailed here – numerous tutorials are available online; just remember to disable your firewall. You can select either machine as the gateway.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TD;
    A[Machine 1&amp;lt;br&amp;gt;IP: 192.168.4.1&amp;lt;br&amp;gt;Subnet Mask: 255.255.255.0&amp;lt;br&amp;gt;Default Gateway: - &amp;lt;br&amp;gt;Obtain DNS Automatically] --&amp;gt;|Ethernet Cable (2.5G)| B[Machine 2&amp;lt;br&amp;gt;IP: 192.168.4.2&amp;lt;br&amp;gt;Subnet Mask: 255.255.255.0&amp;lt;br&amp;gt;Default Gateway: 192.168.4.1&amp;lt;br&amp;gt;Obtain DNS Automatically];
    A --&amp;gt;|Wireless Card| Internet;
    B --&amp;gt;|Wireless Card| Internet;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;two-subnet-speed-testing&#34;&gt;Two Subnet Speed Testing
&lt;/h2&gt;&lt;h3 id=&#34;router-lan&#34;&gt;Router LAN
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core\Desktop\iperf-3.1.3-win32&amp;gt;iperf3.exe -c 192.168.3.237
Connecting to host 192.168.3.237, port 5201
[  4] local 192.168.3.122 port 1656 connected to 192.168.3.237 port 5201
[ ID] Interval           Transfer     Bandwidth
[  4]   0.00-1.00   sec  9.17 MBytes  76.7 Mbits/sec
[  4]   1.00-2.00   sec  9.91 MBytes  83.2 Mbits/sec
[  4]   2.00-3.00   sec  8.74 MBytes  73.3 Mbits/sec
[  4]   3.00-4.00   sec  10.2 MBytes  85.2 Mbits/sec
[  4]   4.00-5.00   sec  9.23 MBytes  77.1 Mbits/sec

### Router LAN
[ 4 ] 4.00-5.00 sec 9.23 MB 77.1 Mbits/sec
[ 4 ] 5.00-6.00 sec 8.80 MB 73.9 Mbits/sec
[ 4 ] 6.00-7.01 sec 8.00 MB 66.8 Mbits/sec
[ 4 ] 7.01-8.00 sec 7.69 MB 64.9 Mbits/sec
[ 4 ] 8.00-9.01 sec 9.72 MB 81.1 Mbits/sec
[ 4 ] 9.01-10.01 sec 7.63 MB 63.6 Mbits/sec
--- --- --- --- --- --- --- --- ---
[ ID] Interval           Transfer     Bandwidth
[ 4 ] 0.00-10.01 sec 89.0 MB 74.6 Mbits/sec                  sender

### Router LAN
[ 4 ] 0.00-10.01 sec 89.0 MBytes 74.6 Mbits/sec                sender
[ 4 ] 0.00-10.01 sec 89.0 MBytes 74.6 Mbits/sec                receiver

### Router LAN
iperf Done.

### Direct LAN Connection
```shell
C:\Users\core\Desktop\iperf-3.1.3-win32&amp;gt;iperf3.exe -c 192.168.4.1
Connecting to host 192.168.4.1, port 5201
[  4] local 192.168.4.2 port 1524 connected to 192.168.4.1 port 5201
[ ID] Interval           Transfer     Bandwidth
[  4]   0.00-1.01   sec   178 MBytes  1.48 Gbits/sec
[  4]   1.01-2.00   sec   204 MBytes  1.72 Gbits/sec
[  4]   2.00-3.00   sec   214 MBytes  1.80 Gbits/sec
[  4]   3.00-4.00   sec   229 MBytes  1.92 Gbits/sec
[  4]   4.00-5.00   sec   202 MBytes  1.69 Gbits/sec
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;direct-lan&#34;&gt;Direct LAN
&lt;/h3&gt;&lt;p&gt;[ 4 ]   4.00-5.00   sec   202 MBytes  1.69 Gbits/sec
[ 4 ]   5.00-6.00   sec   213 MBytes  1.79 Gbits/sec
[ 4 ]   6.00-7.00   sec   230 MBytes  1.93 Gbits/sec
[ 4 ]   7.00-8.00   sec   192 MBytes  1.61 Gbits/sec
[ 4 ]   8.00-9.00   sec   220 MBytes  1.84 Gbits/sec
[ 4 ]   9.00-10.00  sec   230 MBytes  1.93 Gbits/sec&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;[ ID] Interval           Transfer     Bandwidth
[ 4 ]   0.00-10.00  sec  2.06 GBytes  1.77 Gbits/sec                  sender&lt;/p&gt;
&lt;h3 id=&#34;direct-lan-1&#34;&gt;Direct LAN
&lt;/h3&gt;&lt;p&gt;[ 4 ] 0.00-10.00 sec 2.06 GB 1.77 Gbps                  sender
[ 4 ] 0.00-10.00 sec 2.06 GB 1.77 Gbps                  receiver&lt;/p&gt;
&lt;h3 id=&#34;direct-lan-2&#34;&gt;Direct LAN
&lt;/h3&gt;&lt;p&gt;iperf Done.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://wutongsuimeng.github.io/post/%E7%BB%99hugo%E6%B7%BB%E5%8A%A0mermaid%E6%94%AF%E6%8C%81/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Adding Mermaid Support to Hugo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>ASUS Z490 motherboard has too many disks, resulting in intermittent disk unrecognition.</title>
        <link>https://ttf248.life/en/p/asus-z490-motherboard-disk-recognition-issues/</link>
        <pubDate>Fri, 10 Jan 2025 00:08:51 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/asus-z490-motherboard-disk-recognition-issues/</guid>
        <description>&lt;p&gt;Continuing from the previous text, an issue suddenly arose where the wireless network card was unable to be recognized. Before rebuilding the partitions, I had also researched other solutions online, such as: removing the motherboard battery and disconnecting power for fifteen minutes; upgrading to the latest version of the BOIS driver, but all attempts were unsuccessful.&lt;/p&gt;
&lt;p&gt;Thinking there were still tasks to complete, I switched to a limited network by pulling a web across from the living room into the room. However, this is when the problem returned – wired networking was also unable to be recognized. I then resorted to the ultimate solution of reinstalling the system, which resulted in partition loss during the boot process. If the issue had consistently occurred, I wouldn’t have spent so long troubleshooting it; the ASUS disk conflict is intermittent and triggered by unstable system restarts.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Last week, I purchased a new 2TB solid-state drive from长江存储 (Jiangang Chengsu – Yangtze Storage), an M.2 interface, and the machine never rebooted until yesterday when I shut it down once.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/asus-z490-motherboard-disk-recognition-issues/20250110002801.png&#34;
	width=&#34;553&#34;
	height=&#34;322&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Family photo of a disk&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;171&#34;
		data-flex-basis=&#34;412px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;reinstall-system&#34;&gt;Reinstall System
&lt;/h2&gt;&lt;p&gt;It’s been almost two years since the last system reinstall. The C drive is now full, and Windows keeps causing old issues, with various software constantly storing things on C: Drive. Therefore, I decided to reinstall the system. After the system was reinstalled, the network card issue was resolved, and my daily development environment was restored. While preparing to create a system backup, a new problem arose: after restarting the system, the boot partition disappeared.&lt;/p&gt;
&lt;p&gt;Following the steps in the previous article, I rebuilt the boot partition; however, it wasn’t stable, and the partition would frequently fail to load upon restart. I started to question whether the case was being jostled when I was troubleshooting, but after several checks, there were no issues.&lt;/p&gt;
&lt;h2 id=&#34;memory-retrieval&#34;&gt;Memory Retrieval
&lt;/h2&gt;&lt;p&gt;Many years ago, this machine had once been equipped with a solid-state drive; it was like buying a new PCIE converter (plugged into the graphics card slot) instead of directly installing the hard drive onto the motherboard. This time, it’s installed directly on the motherboard, which may be due to an issue with the motherboard.
&lt;img src=&#34;https://ttf248.life/p/asus-z490-motherboard-disk-recognition-issues/20250110002148.png&#34;
	width=&#34;325&#34;
	height=&#34;545&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Solid State Converter&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;59&#34;
		data-flex-basis=&#34;143px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;motherboard-manual&#34;&gt;Motherboard Manual
&lt;/h2&gt;&lt;p&gt;The motherboard manual has issues, with the labeled SATA port positions differing from the actual positions. Due to a large number of disks, all ports are populated with hard drives, with older SSDs utilizing SATA ports. According to the manual, there is a conflict between the ports. However, after testing, this conflict was found to be unstable and would trigger, causing the corresponding disk to fail to load – specifically, as it’s the system disk, the bootloader is also located on that disk, resulting in boot loader failure during system startup.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/asus-z490-motherboard-disk-recognition-issues/20250110002401.png&#34;
	width=&#34;807&#34;
	height=&#34;847&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Z490&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;95&#34;
		data-flex-basis=&#34;228px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;solutions&#34;&gt;Solutions
&lt;/h2&gt;&lt;p&gt;Reinstall the solid state drive onto a PCIe adapter, at this point, the SATA ports on the motherboard will no longer conflict and the system starts normally.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Exploring the Mysteries of ESP Partitions, GPT Partitions Table, and the Synergy with Windows Operating Systems</title>
        <link>https://ttf248.life/en/p/esp-partitioning-gpt-windows-cooperation/</link>
        <pubDate>Thu, 09 Jan 2025 23:58:20 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/esp-partitioning-gpt-windows-cooperation/</guid>
        <description>&lt;p&gt;Yesterday after finishing work, I followed the usual routine of booting up my desktop computer. The system started normally but couldn&amp;rsquo;t load the wireless network card. I thought it might be loose, so I disassembled the computer and reinstalled the wireless card. That’s when things went really wrong – the system simply wouldn’t boot, and the boot loader failed.&lt;/p&gt;
&lt;p&gt;It had been a long time since I’d messed around with a desktop computer, and partitioning and booting felt a bit unfamiliar. I used DisGenius to create a blank partition (usually partitioned at the beginning of the disk) and allocated it as an ESP partition (defaulting to 300M), then entered PE system to rebuild the boot, and relevant information could be found online.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/esp-partitioning-gpt-windows-cooperation/20250110000433.png&#34;
	width=&#34;330&#34;
	height=&#34;269&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;New ESP Partition&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;122&#34;
		data-flex-basis=&#34;294px&#34;
	
&gt;
&lt;img src=&#34;https://ttf248.life/p/esp-partitioning-gpt-windows-cooperation/20250110000509.png&#34;
	width=&#34;433&#34;
	height=&#34;355&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;You can remove the MSR partition&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;121&#34;
		data-flex-basis=&#34;292px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;In the world of computer storage, the ESP partition, GPT partition table, and Windows operating system are closely linked, each playing a unique and crucial role in supporting the stability and efficient management of the system. However, before delving into their intricacies, we must acknowledge the “pioneers” – the MBR partition table format – that flowed through the history of computer partitioning. It mirrored subsequent technologies, further highlighting the evolution of technology. Today, let’s explore their inner connections and nuances in detail.&lt;/p&gt;
&lt;h2 id=&#34;i-mbr-partition-table--the-foundation-of-traditional-hard-disk-partitioning&#34;&gt;I. MBR Partition Table – The “Foundation” of Traditional Hard Disk Partitioning
&lt;/h2&gt;&lt;p&gt;MBR, which stands for Master Boot Record, has existed since the early days of personal computers and has dominated the hard disk partitioning landscape for decades.&lt;/p&gt;
&lt;h3 id=&#34;1-basic-architecture&#34;&gt;1. Basic Architecture
&lt;/h3&gt;&lt;p&gt;It is located in the first sector of the hard disk, which is sector 0, occupying 512 bytes of space. These 512 bytes are primarily divided into three parts: firstly, the boot program code, responsible for loading the operating system&amp;rsquo;s boot loader during computer startup, typically 446 bytes; secondly, the disk partition table, occupying 64 bytes, which can define up to 4 main partitions, with each partition describing 16 bytes of information, recording the starting head, sector, and cylinder of the partition, as well as key parameters such as partition type and size; and finally, the last 2 bytes are the MBR end marker “55 AA”, used to identify this sector as a valid MBR.&lt;/p&gt;
&lt;h3 id=&#34;2-historical-achievements-and-limitations&#34;&gt;2. Historical Achievements and Limitations
&lt;/h3&gt;&lt;p&gt;In the early days, MBR partition tables fully met the storage needs of relatively simple personal computers. It allowed operating systems to seamlessly recognize hard disk partitions, enabling orderly data storage and retrieval. However, as times evolved, its limitations became increasingly apparent. Firstly, limited by a 64-byte partition table space, it could only define a maximum of 4 primary partitions; creating more partitions required the use of extended partitions and logical partitions – methods that were somewhat complex and added to the difficulty of disk management. Secondly, its maximum support was only 2TB of hard drives, which seemed inadequate in the face of today’s large-capacity drives routinely measuring several TB or even dozens of TB. This became a bottleneck hindering further development of storage technology.&lt;/p&gt;
&lt;h2 id=&#34;ii-esp-partition--the-systems-invisible-boot-key&#34;&gt;II. ESP Partition – The System’s “Invisible Boot Key”
&lt;/h2&gt;&lt;p&gt;ESP, which stands for EFI System Partition, is a special partition required by computers based on the UEFI (Unified Extensible Firmware Interface) standard.&lt;/p&gt;
&lt;h3 id=&#34;1-functional-features&#34;&gt;1. Functional Features
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Boot Loading:&lt;/strong&gt; When the computer starts up, UEFI firmware first searches for the ESP partition on the hard drive and reads the boot loader (such as Windows Boot Manager) stored within it, thereby launching the operating system. This is like a precise key that opens the door to system startup; without it, the system would be lost and confused during startup, not knowing where to go.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Storage Driver:&lt;/strong&gt; The ESP partition also stores some driver programs necessary for the system boot process, ensuring that hardware devices (such as hard disk controllers, graphics cards, etc.) function normally in the early stages of booting, laying the foundation for the smooth takeover of the operating system.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-space-requirements-and-formatting&#34;&gt;2. Space Requirements and Formatting
&lt;/h3&gt;&lt;p&gt;Typically, ESP partition sizes should range from 100MB to 500MB, with an allocation of around 200MB generally sufficient for basic needs. Its file system format must be FAT32, as UEFI firmware can only recognize FAT32 formatting to read boot files, ensuring compatibility and cross-platform support.&lt;/p&gt;
&lt;h2 id=&#34;three-gpt-partition-table--the-hard-drives-smart-manager&#34;&gt;Three. GPT Partition Table – The Hard Drive’s “Smart Manager”
&lt;/h2&gt;&lt;p&gt;GPT (GUID Partition Table), also known as the Globally Unique Identifier Partition Table, is a new partitioning scheme designed to replace the traditional MBR partition table.&lt;/p&gt;
&lt;h3 id=&#34;1-advantages-demonstrated&#34;&gt;1. Advantages Demonstrated
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Large Capacity Support:&lt;/strong&gt; In this era of exploding data, large-capacity hard drives are emerging one after another. GPT partition tables break the MBR&amp;rsquo;s 2TB capacity limit, theoretically enabling support for up to 9.4ZB (zettabytes – 1ZB = 1024 EB, 1EB = 1024 PB, 1PB = 1024 TB) of ultra-large storage space, providing the possibility of storing massive amounts of data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Many Partition Numbers:&lt;/strong&gt; Unlike MBR which can only partition a maximum of 4 primary partitions, GPT allows for the creation of up to 128 partitions, giving users and system administrators great flexibility whether it&amp;rsquo;s partitioning multiple systems partitions, data partitions, or reserving partitions for special purposes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;High Reliability:&lt;/strong&gt; The GPT partition table uses redundancy backup mechanisms, storing one partition table piece of information at the head and tail of the hard drive.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-structural-analysis&#34;&gt;2. Structural Analysis
&lt;/h3&gt;&lt;p&gt;The GPT partition table consists of multiple components, including a protected MBR (maintained as a small portion of the traditional BIOS structure for compatibility with legacy BIOS and not used for actual partition management), a GPT header (storing basic information about the GPT partition table such as partition table version, number of partitions, partition table size, etc.), and a partition entry array (each partition entry details key information such as the starting sector, ending sector, partition type GUID, and unique identifier for each partition). These structures work together to precisely plan and manage disk space.&lt;/p&gt;
&lt;h2 id=&#34;four-windows-operating-system--the-users-digital-interaction-heaven&#34;&gt;Four. Windows Operating System – The User’s “Digital Interaction Heaven”
&lt;/h2&gt;&lt;p&gt;Windows, as the world’s most widely used operating system, builds a friendly bridge between people and computer hardware.&lt;/p&gt;
&lt;h3 id=&#34;1-fusion-of-esp-and-gpt-partition-tables&#34;&gt;1. Fusion of ESP and GPT Partition Tables
&lt;/h3&gt;&lt;p&gt;During Windows system installation based on UEFI booting, the installer automatically creates an ESP (Extensible Firmware Interface) partition and deploys boot files to it. Simultaneously, the hard drive is initialized with a GPT (GUID Partition Table) partition scheme, dividing it into partitions such as the System Reserved Partition (used for storing critical system files, similar to the system boot file area in traditional BIOS), the Windows System Partition (where the core system files are installed), and other user-defined data partitions. The Windows system relies on the GPT partition table to precisely identify each partition, enabling seamless booting through the ESP partition, and ensuring a smooth boot and usage experience.&lt;/p&gt;
&lt;h3 id=&#34;2-system-management-and-optimization-based-on&#34;&gt;2. System Management and Optimization Based on
&lt;/h3&gt;&lt;p&gt;During operation, Windows fully utilizes the advantages of the GPT partition table for disk management. For example, in the Disk Management tool, it can easily identify GPT partitions, allowing users to create, delete, format, and adjust partition sizes – meeting different data storage needs at various stages. Furthermore, processes such as system updates and software installations are closely related to partition layouts.  A well-planned partition scheme helps improve system performance and stability, and reduces issues caused by insufficient disk space or partition confusion.&lt;/p&gt;
&lt;h2 id=&#34;v-practical-tips-maintenance-and-troubleshooting&#34;&gt;V. Practical Tips: Maintenance and Troubleshooting
&lt;/h2&gt;&lt;p&gt;Now that you understand their close relationship, daily maintenance and troubleshooting have a clear path to follow.&lt;/p&gt;
&lt;h3 id=&#34;1-disk-space-management&#34;&gt;1. Disk Space Management
&lt;/h3&gt;&lt;p&gt;Regularly check ESP partition space to avoid running out of space due to installing too many startup-related software, which can affect system boot. For data partitions under GPT partitions, plan storage appropriately, promptly clean up unnecessary files, and prevent a single partition from filling up to impact system operation.&lt;/p&gt;
&lt;h3 id=&#34;2-troubleshooting-startup-failures&#34;&gt;2. Troubleshooting Startup Failures
&lt;/h3&gt;&lt;p&gt;If the system fails to start, first check if the ESP (EFI System Partition) is damaged or files are missing. You can use the startup repair tool built into the UEFI firmware, or enter the Windows recovery environment using an installation media to rebuild the boot files of the ESP partition. If you suspect a GPT partition table failure, use a professional disk utility (such as DiskGenius) to check the integrity of the partition table and attempt to repair it by restoring backup partition information.&lt;/p&gt;
&lt;p&gt;The ESP partition, GPT partition table, and Windows operating system are like a precise team working together, each playing its part to create a stable and efficient computer usage environment for us. Understanding them deeply not only helps us handle system installation and maintenance with confidence, but also allows us to understand the underlying logic of computer operation and explore the digital world.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Deeply understand GCC, GLIBC, and C&#43;&#43; program compatibility issues</title>
        <link>https://ttf248.life/en/p/gcc-glibc-cpp-compatibility/</link>
        <pubDate>Mon, 06 Jan 2025 19:51:16 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/gcc-glibc-cpp-compatibility/</guid>
        <description>&lt;p&gt;In the C++ development field, GCC and GLIBC are two indispensable key elements, and compatibility issues after program release often trouble developers. This article will delve into their essence, explore the root causes of compatibility problems, and investigate coping strategies.&lt;/p&gt;
&lt;h2 id=&#34;i-gcc-a-powerful-compiler-cornerstone&#34;&gt;I. GCC: A Powerful Compiler Cornerstone
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Definition and Function&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;GCC, or GNU Compiler Collection, is a suite of open-source compilers developed by the GNU project. It’s far from a typical compiler; it supports a wide range of programming languages including C, C++, Objective - C, Fortran, Ada, and Go, providing a one-stop solution for cross-language development.&lt;/li&gt;
&lt;li&gt;Taking C++ as an example, when we write a source file containing complex features like classes, templates, and function overloading, GCC can translate the advanced C++ code into low-level machine instructions that can be understood and executed by the system. This process involves multiple fine-grained stages such as lexical analysis, syntax analysis, semantic analysis, optimization, and code generation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;i-gcc-a-powerful-compiler-foundation&#34;&gt;I. GCC: A Powerful Compiler Foundation
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Compilation Process Details&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Preprocessing Stage:&lt;/strong&gt; GCC first performs preprocessing operations on the source file. During this stage, it handles all preprocessor directives starting with &lt;code&gt;#&lt;/code&gt;, such as &lt;code&gt;#include&lt;/code&gt; instructions. These instructions embed the entire contents of specified header files (e.g., &lt;code&gt;&amp;lt;iostream&amp;gt;&lt;/code&gt; for C++ input/output stream operations) into the corresponding locations in the source file, allowing the program to use functions, classes, and other resources declared in those headers; &lt;code&gt;#define&lt;/code&gt; directives defining macros are also expanded and replaced during this stage, such as &lt;code&gt;#define PI 3.14159&lt;/code&gt;.  Every occurrence of &lt;code&gt;PI&lt;/code&gt; in the source file is replaced with &lt;code&gt;3.14159&lt;/code&gt;. After preprocessing, the source file undergoes an initial &amp;ldquo;expansion.&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compilation Stage:&lt;/strong&gt; The preprocessed file enters the compilation phase, where GCC converts the source file into assembly language code based on the C++ language standard. It carefully checks the code structure, ensuring that class inheritance and polymorphism implementations are correct, as well as that function call parameters match. Upon detecting errors that violate the grammatical semantics, it immediately reports them and terminates the compilation process. For example, if the parameter list in a function declaration does not match its definition, GCC will accurately pinpoint the issue.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-gcc-a-powerful-compiler-cornerstone-1&#34;&gt;I. GCC: A Powerful Compiler Cornerstone
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Assembly Stage:&lt;/strong&gt; The assembler converts the assembly code generated in the previous step into machine code, producing object files with a &lt;code&gt;.o&lt;/code&gt; extension. These object files contain binary instructions that can be directly executed by the machine, but they cannot run independently because a complete program is typically composed of multiple modules, and function and variable references between these modules have not yet been resolved.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Linking Stage:&lt;/strong&gt; This is the final sprint to generate an executable file. The linker integrates multiple object files as well as required libraries (static or dynamic) together. For example, when using container classes from the C++ Standard Template Library, linking requires finding the corresponding library implementation code to ensure that the program can correctly call functions of objects like &lt;code&gt;vector&lt;/code&gt; and &lt;code&gt;list&lt;/code&gt; at runtime, ultimately generating a complete executable program.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ii-glibc-the-backbone-of-c-program-execution&#34;&gt;II. GLIBC: The Backbone of C++ Program Execution
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Nature and Function&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;GLIBC, or the GNU C Library, is a concrete implementation of the C standard library within the GNU ecosystem. Although its name emphasizes C, C++ programs heavily rely on it as well, because C++ inherits its foundational elements. It provides a vast array of basic functions, such as those for memory management – &lt;code&gt;malloc&lt;/code&gt; (dynamic memory allocation) and &lt;code&gt;free&lt;/code&gt; (memory deallocation) – which are indispensable when creating dynamic arrays and objects in C++, as well as string manipulation functions like &lt;code&gt;strcpy&lt;/code&gt; (string copy) and &lt;code&gt;strcat&lt;/code&gt; (string concatenation). Even though C++ has a more advanced &lt;code&gt;string&lt;/code&gt; class, these functions are still frequently used at the underlying level when interacting with C code or pursuing extreme performance, as well as in early C++ development and scenarios where simplicity is paramount.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;ii-glibc-the-backbone-of-c-program-execution-1&#34;&gt;II. GLIBC: The Backbone of C++ Program Execution
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Collaboration with the Operating System&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;GLIBC acts as a crucial bridge between the operating system and applications. In Linux systems, when a C++ program initiates a system call – such as opening a file (using the &lt;code&gt;open&lt;/code&gt; function, which relies on GLIBC’s implementation), GLIBC encapsulates the program&amp;rsquo;s request in a manner conforming to the operating system kernel’s specifications and passes it to the kernel for processing. Upon completion by the kernel, GLIBC returns the results to the application. This allows applications to utilize various system resources – such as file systems, networks, and process management – without needing to delve into the complex details of the underlying system call interfaces.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;iii-compatibility-issues-after-c-program-deployment-analysis&#34;&gt;III. Compatibility Issues After C++ Program Deployment Analysis
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Compatibility Dilemmas Triggered by Differences in GLIBC Version&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Different Linux distributions often utilize different versions of GLIBC. When a C++ program is compiled in a newer GLIBC environment, it may unknowingly use certain new function features or rely on optimized function implementations introduced in that version. For example, the new GLIBC version has improved memory allocation algorithms; the program frequently utilizes this new algorithm to enhance performance at runtime. Once this program is deployed on a lower-version GLIBC system, it may encounter issues such as failing to find the corresponding function (because the older version did not introduce it) or abnormal function behavior (the old version’s implementation logic differs from the new one), leading to program crashes or incorrect results.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;iii-compatibility-issues-after-c-program-publishing-an-analysis&#34;&gt;III. Compatibility Issues After C++ Program Publishing: An Analysis
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Compatibility Risks Due to Compiler Differences&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Even when using the same GCC compiler, different versions of GCC differ in code generation, standard library support, and implementation details for C++ features. Newer GCC versions may have full support for the latest C++ standards (such as new feature modules in C++20 like coroutines), and if a program uses these advanced features and is compiled under an older GCC version, the compiler will error out due to its inability to recognize these new syntax structures. Even without syntax errors, different GCC versions have different optimization strategies, which can lead to significant differences in machine code generated in terms of execution efficiency and memory usage. In performance-critical scenarios, this can cause programs to behave differently in different environments. - &lt;strong&gt;Challenges Posed by Architectural Differences&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;C++ programs may need to run on different hardware system architectures, such as x86, ARM, and PowerPC. These architectures have unique instruction sets, memory layouts, and data alignment requirements. For example, a structure data layout that runs correctly on an x86 architecture might cause memory access exceptions on an ARM architecture due to differing alignment rules, leading to program errors. Furthermore, GCC generates significantly different machine code when compiling for various architectures; if the program contains hardcoded architectural-specific instructions or assumptions, it will inevitably fail during cross-architecture execution.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;four-strategies-for-addressing-compatibility-issues&#34;&gt;Four. Strategies for Addressing Compatibility Issues
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Utilization of Static Link Libraries&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Consider using static link libraries, packaging the code of libraries that your program depends on (such as GLIBC) directly into the executable file. This eliminates the need for the target system’s specific GLIBC version at runtime, effectively preventing issues caused by GLIBC version mismatches. However, static linking will significantly increase the size of the executable file, requiring a trade-off in resource-constrained scenarios.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Containerized Deployment&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Leveraging containerization technologies like Docker, encapsulate your C++ program and its required runtime environment (including specific versions of GCC, GLIBC, etc.) within an independent container. Regardless of the underlying operating system to which it is deployed, the container maintains consistency with the development environment, ensuring the program runs as expected and greatly simplifies cross-environment deployment complexity. - &lt;strong&gt;Compatibility Testing and Continuous Integration&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Establish a comprehensive compatibility testing system, covering different GLIBC versions, GCC versions, and common system architectures. During the software development process, use continuous integration tools to perform automated testing on various environments regularly. Once compatibility issues are identified, they are promptly fixed, eliminating potential problems at their earliest stages and ensuring stability after program deployment.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;four-strategies-for-addressing-compatibility-issues-1&#34;&gt;Four. Strategies for Addressing Compatibility Issues
&lt;/h2&gt;&lt;p&gt;As a summary, a deep understanding of the workings of GCC and GLIBC, accurately identifying the root causes of C++ compatibility issues, and flexibly applying appropriate strategies are essential skills for every C++ developer to build robust, cross-platform applications. Only in this way can our C++ works run smoothly within diverse technological ecosystems.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Windows Built-in Disk Cleanup Tool: Storage</title>
        <link>https://ttf248.life/en/p/windows-disk-cleanup-storage/</link>
        <pubDate>Mon, 06 Jan 2025 19:29:45 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/windows-disk-cleanup-storage/</guid>
        <description>&lt;p&gt;I’m not sure from what version it started, but in Windows 11, the Disk Cleanup tool has been significantly improved and become much smarter.&lt;/p&gt;
&lt;p&gt;The key is that it&amp;rsquo;s an official tool, so it won’t accidentally delete files, won’t have ads, won’t have pop-ups, won’t have background processes, or any unnecessary elements.&lt;/p&gt;
&lt;p&gt;You can access the Disk Cleanup tool in Windows 11 by going to &lt;code&gt;Settings&lt;/code&gt; - &lt;code&gt;System&lt;/code&gt; - &lt;code&gt;Storage&lt;/code&gt; - &lt;code&gt;Temporary Files&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/windows-disk-cleanup-storage/20250106194453.png&#34;
	width=&#34;1041&#34;
	height=&#34;775&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Storage Interface&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;134&#34;
		data-flex-basis=&#34;322px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;For regular users, simply selecting “Clean Recommendations” is sufficient; the system will provide suggestions based on your usage.&lt;/p&gt;
&lt;p&gt;As a developer, I have many temporary files on my disk, so I choose “Temporary Files,” which contains items like Visual Studio temporary files and Windows Update temporary files, among others.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/windows-disk-cleanup-storage/Snipaste_2024-12-19_13-39-51.png&#34;
	width=&#34;465&#34;
	height=&#34;980&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Temporary Files&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;47&#34;
		data-flex-basis=&#34;113px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Docker Domestic Mirror Proxy Failed</title>
        <link>https://ttf248.life/en/p/docker-domestic-image-proxy-failure/</link>
        <pubDate>Sat, 04 Jan 2025 18:29:25 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/docker-domestic-image-proxy-failure/</guid>
        <description>&lt;p&gt;Deploying Docker on domestic servers, after deployment, if the company doesn’t provide a registry center, the first thing developers need to do is configure a domestic registry acceleration address. It&amp;rsquo;s lucky that today there was a server configured with a registry acceleration address, but when pulling images, it kept failing to pull.&lt;/p&gt;
&lt;p&gt;Error response from daemon: “https://registry-1.docker.io/v2/”: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)&lt;/p&gt;
&lt;!-- 20250106 – Two days after, all servers were restored, and this didn’t even make the news! All domestic registry proxies went down --&gt;
&lt;h2 id=&#34;troubleshooting-and-repair-attempts&#34;&gt;Troubleshooting and Repair Attempts
&lt;/h2&gt;&lt;p&gt;Initially, we attempted to switch to alternative mirror acceleration addresses, hoping to resolve the issue. However, contrary to our expectations, the problem persisted.&lt;/p&gt;
&lt;p&gt;Subsequently, we began modifying the local DNS configuration, attempting to find a breakthrough at the network resolution level. Unfortunately, after some debugging, the fault remained.&lt;/p&gt;
&lt;p&gt;At this point, the stability of the local network was heavily questioned, so we decisively switched to a mobile hotspot, attempting to bypass potential local network faults, but the results were discouraging – there was no sign of improvement.&lt;/p&gt;
&lt;h2 id=&#34;problem-propagation&#34;&gt;Problem Propagation
&lt;/h2&gt;&lt;p&gt;We currently have &lt;strong&gt;a few servers deployed domestically&lt;/strong&gt; with Docker environments, and all of them failed to successfully pull the image. We initially hoped to find an alternative solution, but we found that they all consistently failed with identical error messages, indicating that the issue isn&amp;rsquo;t isolated to a single device.&lt;/p&gt;
&lt;p&gt;Further investigation revealed that the image proxy seemingly malfunctioned instantaneously. In this critical moment, we quickly switched to a machine outside of the country, and thankfully, image pulls were restored at this location. This suggests that the problem is most likely related to network links or configurations within China.&lt;/p&gt;
&lt;h2 id=&#34;strategy-adjustment-circumventing-the-issue&#34;&gt;Strategy Adjustment: Circumventing the Issue
&lt;/h2&gt;&lt;p&gt;Given that direct image pulling methods within China have been heavily restricted while foreign mirrors remain accessible, in order to expedite project progress, we’ve decided to employ a circumvention tactic. Initially, we switched to a foreign server to successfully pull the required images, subsequently pushing them to domestic mirror repositories to establish a “data bridge.”&lt;/p&gt;
&lt;p&gt;At the same time, we synchronized modifications to the Dockerfile files, replacing image addresses with those adapted for the Chinese environment and then rebuilt the images, ultimately achieving successful deployment.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>CentOS 8 Stream EOL</title>
        <link>https://ttf248.life/en/p/centos-8-stream-eol/</link>
        <pubDate>Sat, 16 Nov 2024 23:24:50 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/centos-8-stream-eol/</guid>
        <description>&lt;p&gt;&lt;code&gt;CentOS Stream&lt;/code&gt; is the upstream open-source development platform prior to Red Hat’s &lt;code&gt;Linux&lt;/code&gt; distribution.&lt;/p&gt;
&lt;p&gt;I first noticed the open-source operating system lifecycle &lt;a class=&#34;link&#34; href=&#34;https://ttf248.life/en/p/redhat-centos-lifecycle/&#34; &gt;redhat and centos life cycle&lt;/a&gt; had ended, and I was wondering what was going on? Besides security issues, dnf wasn’t working, and I recently encountered failures when installing tools – checking the repository sources revealed that &lt;code&gt;CentOS 8 Stream&lt;/code&gt; had reached its end of life.&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;centos-stream-introduction&#34;&gt;CentOS Stream Introduction
&lt;/h2&gt;&lt;h3 id=&#34;positioning-and-roles&#34;&gt;Positioning and Roles
&lt;/h3&gt;&lt;p&gt;CentOS Stream sits between Fedora Linux (upstream development) and RHEL (Red Hat Enterprise Linux, downstream development), acting as a bridge.&lt;/p&gt;
&lt;p&gt;It can be considered a version for experiencing the latest Red Hat-based Linux features, suitable for early adopters.&lt;/p&gt;
&lt;h3 id=&#34;origins-and-background&#34;&gt;Origins and Background
&lt;/h3&gt;&lt;p&gt;Over time, Red Hat began to seek more effective ways to develop its enterprise-grade Linux platform, leading to the launch of CentOS Stream.&lt;/p&gt;
&lt;p&gt;CentOS 8 ended maintenance at the end of 2021, and CentOS Stream continued to be updated as its successor, becoming the future direction of the CentOS project.&lt;/p&gt;
&lt;h3 id=&#34;features-and-advantages&#34;&gt;Features and Advantages
&lt;/h3&gt;&lt;p&gt;CentOS Stream is a rolling-release Linux distribution that provides faster updates. It offers greater transparency and more opportunities for community, partner, and customer participation, allowing users to contribute to Red Hat Enterprise Linux (RHEL) more quickly and directly.
The content of CentOS Stream is software that Red Hat intends to include in the next stable release of RHEL, therefore it provides a stable ABI/API for developers and testers within the community.&lt;/p&gt;
&lt;h3 id=&#34;use-cases-and-target-users&#34;&gt;Use Cases and Target Users
&lt;/h3&gt;&lt;p&gt;CentOS Stream is suitable for those CentOS users who want to continue receiving the latest Linux feature updates, as well as developers and partners who wish to participate in Red Hat Enterprise Linux development.&lt;/p&gt;
&lt;p&gt;It also aims to help community members, Red Hat partners, and others take full advantage of innovative open-source software in a more stable and predictable Linux ecosystem.&lt;/p&gt;
&lt;h2 id=&#34;end-of-lifehttpsendoflifedatecentos-stream&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://endoflife.date/centos-stream&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;End of Life&lt;/a&gt;
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Release&lt;/th&gt;
&lt;th&gt;Released&lt;/th&gt;
&lt;th&gt;Active Support&lt;/th&gt;
&lt;th&gt;Security Support&lt;/th&gt;
&lt;th&gt;Latest&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;3 years ago (15 Sep 2021)&lt;/td&gt;
&lt;td&gt;Ends in 2 years and 6 months (31 May 2027)&lt;/td&gt;
&lt;td&gt;Ends in 2 years and 6 months (31 May 2027)&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;end-of-lifehttpsendoflifedatecentos-stream-1&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://endoflife.date/centos-stream&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;End of Life&lt;/a&gt;
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Release&lt;/th&gt;
&lt;th&gt;Released&lt;/th&gt;
&lt;th&gt;Active Support&lt;/th&gt;
&lt;th&gt;Security Support&lt;/th&gt;
&lt;th&gt;Latest&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;5 years ago (24 Sep 2019)&lt;/td&gt;
&lt;td&gt;Ended 5 months and 3 weeks ago (31 May 2024)&lt;/td&gt;
&lt;td&gt;Ended 5 months and 3 weeks ago (31 May 2024)&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;solutions&#34;&gt;Solutions
&lt;/h2&gt;&lt;p&gt;Rather than bothering with upgrades, we opted for the long-term support version of &lt;code&gt;Ubuntu 24.04&lt;/code&gt;.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Hugo Module Customizing Theme: Explanation of Approach</title>
        <link>https://ttf248.life/en/p/hugo-module-customizing-themes-ideas/</link>
        <pubDate>Fri, 15 Nov 2024 22:01:17 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/hugo-module-customizing-themes-ideas/</guid>
        <description>&lt;p&gt;Reviewing the historical commit records, the site has undergone many theme switches. Each theme switch involved some custom modifications, and this is where I’m documenting the approach to customizing themes. My &lt;code&gt;Github&lt;/code&gt; repository briefly maintained the even theme, but due to my obsessive-compulsive tendencies, I didn&amp;rsquo;t want to upgrade the &lt;code&gt;hugo&lt;/code&gt; compiler to the latest version, which resulted in incompatibility with the even theme, so I switched back to the &lt;code&gt;stack&lt;/code&gt; theme.&lt;/p&gt;
&lt;h2 id=&#34;hugos-modularity&#34;&gt;Hugo&amp;rsquo;s Modularity
&lt;/h2&gt;&lt;p&gt;When we talk about modularity, many people think of things like Nginx modules and IDEA plugins. Typically, I can upload various modules to satisfy my specific needs. The reason everyone likes this kind of module is that it’s incredibly flexible – you don’t have to put in too much effort to meet your own requirements. Often, even though the overall concepts are similar, there are always subtle differences. This highlights the complexity of software, not just technically, but also from a business perspective. Most often, we face business complexity. This is precisely where the saying “it’s like crossing a river and climbing a mountain” – “隔行如隔山” – is best illustrated. Today, not only the internet industry and finance, but even traditional manufacturing industries are using information systems to help with their production and management. Here’s the English translation of the provided text:&lt;/p&gt;
&lt;p&gt;“Similarly, even within the same industry, different companies will have variations in their leave systems. However, Hugo&amp;rsquo;s modules differ somewhat from what people typically expect – they aren’t organized based on functionality to meet specific differentiation needs. Instead, they are primarily structured around directory hierarchies to identify and recognize identical structures.”&lt;/p&gt;
&lt;p&gt;Resource link: &lt;a class=&#34;link&#34; href=&#34;https://medium.com/@sunwei.xyz/07-hugo%E6%9E%B6%E6%9E%84-hugo%E7%9A%84%E6%A8%A1%E5%9D%97-8ef5a520a822&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;07. Hugo Architecture — Hugo Modules&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;hugos-modularization&#34;&gt;Hugo&amp;rsquo;s Modularization
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[[imports]]
path = &amp;quot;github.com/CaiJimmy/hugo-theme-stack/v3&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;git submodule&lt;/code&gt; still works, but it’s not recommended. Maintaining this approach can be complex, as the theme requires separate Git repository management.&lt;/p&gt;
&lt;h2 id=&#34;theme-modification-logichttpsstackjimmycaicomguidemodify-theme&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://stack.jimmycai.com/guide/modify-theme&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Theme Modification Logic&lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;Once you’ve grasped the foundational concepts of modularization, understanding custom themes becomes much simpler. Hugo themes are currently assembled from multiple different modules. To modify a single module, locate its corresponding template file and make the necessary changes.&lt;/p&gt;
&lt;p&gt;Excerpted from the official &lt;code&gt;stack&lt;/code&gt; documentation:&lt;/p&gt;
&lt;p&gt;Using this method, there will be no files under the &lt;code&gt;themes&lt;/code&gt; directory.  To modify the theme, you will need to copy the file you want to modify to the same directory under the &lt;code&gt;layouts&lt;/code&gt; directory.&lt;/p&gt;
&lt;h2 id=&#34;theme-modification-logichttpsstackjimmycaicomguidemodify-theme-1&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://stack.jimmycai.com/guide/modify-theme&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Theme Modification Logic&lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;For example, in order to modify the &lt;code&gt;themes/hugo-theme-stack/layouts/partials/head/custom.html&lt;/code&gt; file, you will need to copy it to &lt;code&gt;layouts/partials/head/custom.html&lt;/code&gt; and modify it there (copy the code from the theme&amp;rsquo;s repository). The same applies to the &lt;code&gt;assets&lt;/code&gt; and &lt;code&gt;static&lt;/code&gt; directories.&lt;/p&gt;
&lt;h2 id=&#34;how-to-find-template-files&#34;&gt;How to Find Template Files
&lt;/h2&gt;&lt;h3 id=&#34;conventional-approach&#34;&gt;Conventional Approach
&lt;/h3&gt;&lt;p&gt;Review the source files of the topic, understand its design rationale, identify the corresponding template file, and modify it.&lt;/p&gt;
&lt;h3 id=&#34;bruteforce-approach&#34;&gt;Bruteforce Approach
&lt;/h3&gt;&lt;p&gt;As I don’t have a deep understanding of frontend code, I sometimes resort to a brute-force approach, such as opening the corresponding page directly in the browser, finding the areas I want to modify, and using “Inspect Element” to pinpoint the &lt;code&gt;css name&lt;/code&gt;, then searching the source code for the relevant file, copying it into the site directory, and making changes.&lt;/p&gt;
&lt;h2 id=&#34;tips&#34;&gt;Tips
&lt;/h2&gt;&lt;p&gt;The official setup provides a default file for customizing styles. To modify specific areas, we can split them into multiple files and import them using &lt;code&gt;custom.scss&lt;/code&gt;. This approach allows for better management of style files.
&lt;img src=&#34;https://ttf248.life/p/hugo-module-customizing-themes-ideas/image.png&#34;
	width=&#34;141&#34;
	height=&#34;375&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;37&#34;
		data-flex-basis=&#34;90px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;summarize-modified-content-6h&#34;&gt;Summarize Modified Content (6h)
&lt;/h2&gt;&lt;p&gt;It’s now the first year of AI coding, and the detailed content will not be pasted here for brevity; instead, we simply list some of the modifications made to this site, such as adjusting the copy button styles, reconfiguring the code block styles, and ChatGPT can be easily handled.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Overall: Global text style, adopting the display style previously used by merging &lt;code&gt;even&lt;/code&gt; with &lt;code&gt;info cn&lt;/code&gt;, which is friendly to Chinese&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Homepage: Added mouse interaction animation to the right navigation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Homepage: New article summaries are added (a time-consuming task, achieved using a clever workaround)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Scroll Bar: Improved the styling of the scroll bar&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Code Blocks: Introduced &lt;code&gt;highlight.&lt;/code&gt;. - JavaScript code highlighting plugin, beautify code block styles&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Article details: Some content is a reprint, with new original author information display and original link display&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Archived page: Top category image, remove the theme&amp;rsquo;s color mask, display the original image&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Archived page: Added a statistical display panel for classification by year&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Archived page: Two-column layout display ## Summarize Modified Content (6h)
It’s now the first year of AI coding, and the detailed content will not be pasted here for brevity; instead, we simply list some of the modifications made to this site, such as adjusting the copy button styles, reconfiguring the code block styles, and ChatGPT can be easily handled.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Overall: Global text style, adopting the display style previously used by merging &lt;code&gt;even&lt;/code&gt; with &lt;code&gt;info cn&lt;/code&gt;, which is friendly to Chinese&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Homepage: Added mouse interaction animation to the right navigation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Homepage: New article added summary preview (took quite a while, implemented using a clever trick)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Scroll Bar: Beautified the scroll bar’s style&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Code Blocks: Introduced &lt;code&gt;highlight.&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;consolidated-modifications-6h&#34;&gt;Consolidated Modifications (6h)
&lt;/h2&gt;&lt;p&gt;The &lt;code&gt;stack&lt;/code&gt; theme component reuse rate was very high, leading to significant delays in adding summary previews to new homepage articles.  I modified the corresponding component, which also triggered changes to the article’s detail page, resulting in redundant display of the main content. My familiarity with &lt;code&gt;golang templates&lt;/code&gt; wasn&amp;rsquo;t strong, so it took up a considerable amount of time. I struggled to get component parameter passing working and ultimately resolved it through a workaround: introducing a &lt;code&gt;JavaScript&lt;/code&gt; script separately on the homepage and using custom special variables to implement the summary preview.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Sometimes high component reuse rates can also be problematic, leading to changes in one place affecting others. Therefore, when modifying themes, you must pay attention not to disrupt existing logic.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments
&lt;/h3&gt;&lt;p&gt;This guy&amp;rsquo;s modifications are more refined: &lt;a class=&#34;link&#34; href=&#34;https://blog.reincarnatey.net/2024/0719-better-waline/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.reincarnatey.net/2024/0719-better-waline/&lt;/a&gt;
&lt;del&gt;This site simply enabled the &lt;code&gt;Waline&lt;/code&gt; comment system, as the &lt;code&gt;stack&lt;/code&gt; theme defaults to supporting &lt;code&gt;Waline&lt;/code&gt;. Just configure it in the &lt;code&gt;config.toml&lt;/code&gt; file.&lt;/del&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Recommend contacting via email on the homepage, this site does not open the comments section.&lt;/p&gt;
&lt;/blockquote&gt;</description>
        </item>
        <item>
        <title>Linux backend services handling large volumes of string data – performance is slow.</title>
        <link>https://ttf248.life/en/p/linux-backend-slow-string-processing/</link>
        <pubDate>Wed, 13 Nov 2024 19:42:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-backend-slow-string-processing/</guid>
        <description>&lt;p&gt;In the history of C++ development projects, we utilized a custom protocol for communication, which employed a two-dimensional array pattern. When processing large volumes of data, the protocol required iterating through the arrays and performing serialization operations to generate logs. Due to its low efficiency, this resulted in noticeable lag or stuttering within the system under heavy load, as reported by the business department.&lt;/p&gt;
&lt;h2 id=&#34;problem-identification&#34;&gt;Problem Identification
&lt;/h2&gt;&lt;p&gt;When troubleshooting the issue, we first performed a performance analysis of the system and discovered that CPU utilization increased significantly when processing large amounts of data, and system response times became longer. By analyzing the system logs, we identified numerous serialization operations, which were inefficient when handling two-dimensional arrays, leading to a decline in system performance.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;pstack&lt;/code&gt; tool captured thread information for the service, pinpointing that the log threads spent most of their time processing string concatenation.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is today’s focus: different accumulation methods have significant efficiency differences. Historically, the code used the &lt;code&gt;+&lt;/code&gt; operator, which frequently creates temporary objects and is very inefficient. You know it&amp;rsquo;s bad, but you don&amp;rsquo;t know &lt;em&gt;how&lt;/em&gt; bad it is.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;demo-verification&#34;&gt;Demo Verification
&lt;/h2&gt;&lt;p&gt;Based on the project code, we extracted the business logic and wrote a simple demo to verify the efficiency issues of string concatenation. We compiled and ran it in &lt;code&gt;Release&lt;/code&gt; mode using the &lt;code&gt;vs2022&lt;/code&gt; compiler under &lt;code&gt;windows&lt;/code&gt; and the &lt;code&gt;gcc8.5&lt;/code&gt; compiler under &lt;code&gt;linux&lt;/code&gt;, comparing the efficiencies.&lt;/p&gt;
&lt;h3 id=&#34;key-points-explanation&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;p&gt;The project utilized Method Four, and before obtaining test data, readers should consider which method is most efficient and which is least efficient. I was quite surprised by the results.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Method 1 (&lt;code&gt;+=&lt;/code&gt; Concatenation)&lt;/strong&gt;: Directly concatenates each field using &lt;code&gt;+=&lt;/code&gt; to a string.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 2 (&lt;code&gt;std::ostringstream&lt;/code&gt; Concatenation)&lt;/strong&gt;: Uses a stream (&lt;code&gt;std::ostringstream&lt;/code&gt;) to concatenate each field, which is more efficient, especially when dealing with large amounts of data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 3 (Pre-allocated Memory &lt;code&gt;+=&lt;/code&gt; Concatenation)&lt;/strong&gt;: Pre-allocates enough memory for the string using &lt;code&gt;reserve&lt;/code&gt; to reduce the overhead of memory reallocation and improve performance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 4 (&lt;code&gt;bodys = bodys + body + &amp;quot;\n&amp;quot;&lt;/code&gt;)&lt;/strong&gt;: Each concatenation creates a new temporary string object, leading to performance degradation, especially with large-scale concatenations due to the allocation and copying of a new memory space each time.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Referring to the results, we can see that this method was selected as the least efficient.&lt;/p&gt;
&lt;p&gt;Furthermore, let&amp;rsquo;s analyze the optimization efficiency of different platform compilers – Microsoft’s &lt;code&gt;visual studio&lt;/code&gt; remains consistently excellent, with high string optimization efficiency, while the &lt;code&gt;gcc&lt;/code&gt; compiler lags somewhat in this regard.&lt;/p&gt;
&lt;h3 id=&#34;key-points-explanation-1&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;The code executes on different machines, and the two datasets do not have a direct comparison; instead, differences can be compared between various splicing methods.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;key-points-explanation-2&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Windows platform under Visual Studio 2022 compiler

----------------------------------------
Data Generation Time: 0.054 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.053 seconds.
+ ostringstream Data merging took: 0.054 seconds.
+ Pre-reserved Data merging took: 0.045 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 16.108 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;key-points-explanation-3&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Linux platform under GCC 8.5 compiler
----------------------------------------
Data Generation Time: 0.108 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.100 seconds.
+ ostringstream Data merging took: 0.083 seconds.
+ Pre-reserved Data merging took: 0.057 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 29.298 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;random&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;sstream&amp;gt;
#include &amp;lt;iomanip&amp;gt;

typedef std::vector&amp;lt;std::string&amp;gt; DataRow;
typedef std::vector&amp;lt;DataRow&amp;gt; DataGroup;

struct ResponsePackage
{
    std::string ErrorInfo;
    DataRow Head;
    std::string ClientId;
    std::string UUID;
    std::string MsgID;
    std::string SessionID;
    std::string ExtraInfo1;
    std::string ExtraInfo2;
    DataGroup DataBody;
};
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-1&#34;&gt;Complete Code
&lt;/h2&gt;&lt;p&gt;// Generate specified length of random string
std::string generateRandomString(size_t length)
{
const char charset[] = &amp;ldquo;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&amp;rdquo;;
const size_t max_index = sizeof(charset) - 1;
std::string random_string;
random_string.reserve(length);&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;std::random_device rd;
std::mt19937 generator(rd());
std::uniform_int_distribution&amp;lt;&amp;gt; distribution(0, max_index);
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-2&#34;&gt;Complete Code
&lt;/h2&gt;&lt;p&gt;for (size_t i = 0; i &amp;lt; length; ++i)
{
random_string += charset[distribution(generator)];
}&lt;/p&gt;
&lt;p&gt;return random_string;
}&lt;/p&gt;
&lt;p&gt;void create_large_string()
{
// Example request package with 50 fields
ResponsePackage requestPackage;&lt;/p&gt;
&lt;h2 id=&#34;complete-code-3&#34;&gt;Complete Code
&lt;/h2&gt;&lt;p&gt;requestPackage.Head = {
&amp;ldquo;Field1&amp;rdquo;, &amp;ldquo;Field2&amp;rdquo;, &amp;ldquo;Field3&amp;rdquo;, &amp;ldquo;Field4&amp;rdquo;, &amp;ldquo;Field5&amp;rdquo;,
&amp;ldquo;Field6&amp;rdquo;, &amp;ldquo;Field7&amp;rdquo;, &amp;ldquo;Field8&amp;rdquo;, &amp;ldquo;Field9&amp;rdquo;, &amp;ldquo;Field10&amp;rdquo;,
&amp;ldquo;Field11&amp;rdquo;, &amp;ldquo;Field12&amp;rdquo;, &amp;ldquo;Field13&amp;rdquo;, &amp;ldquo;Field14&amp;rdquo;, &amp;ldquo;Field15&amp;rdquo;,
&amp;ldquo;Field16&amp;rdquo;, &amp;ldquo;Field17&amp;rdquo;, &amp;ldquo;Field18&amp;rdquo;, &amp;ldquo;Field19&amp;rdquo;, &amp;ldquo;Field20&amp;rdquo;,
&amp;ldquo;Field21&amp;rdquo;, &amp;ldquo;Field22&amp;rdquo;, &amp;ldquo;Field23&amp;rdquo;, &amp;ldquo;Field24&amp;rdquo;, &amp;ldquo;Field25&amp;rdquo;,
&amp;ldquo;Field26&amp;rdquo;, &amp;ldquo;Field27&amp;rdquo;, &amp;ldquo;Field28&amp;rdquo;, &amp;ldquo;Field29&amp;rdquo;, &amp;ldquo;Field30&amp;rdquo;,
&amp;ldquo;Field31&amp;rdquo;, &amp;ldquo;Field32&amp;rdquo;, &amp;ldquo;Field33&amp;rdquo;, &amp;ldquo;Field34&amp;rdquo;, &amp;ldquo;Field35&amp;rdquo;
};&lt;/p&gt;
&lt;h2 id=&#34;complete-code-4&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;Field31&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field32&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field33&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field34&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field35&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field36&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field37&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field38&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field39&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field40&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field41&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field42&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field43&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field44&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field45&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field46&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field47&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field48&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field49&amp;quot;: &amp;quot;&amp;quot;,
  &amp;quot;Field50&amp;quot;: &amp;quot;&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-5&#34;&gt;Complete Code
&lt;/h2&gt;&lt;p&gt;requestPackage.ClientId = &amp;ldquo;ClientID&amp;rdquo;;
requestPackage.UUID = &amp;ldquo;UUID&amp;rdquo;;
requestPackage.MsgID = &amp;ldquo;MsgID&amp;rdquo;;
requestPackage.SessionID = &amp;ldquo;SessionID&amp;rdquo;;
requestPackage.ExtraInfo1 = &amp;ldquo;ExtraInfo1&amp;rdquo;;
requestPackage.ExtraInfo2 = &amp;ldquo;ExtraInfo2&amp;rdquo;;&lt;/p&gt;
&lt;p&gt;// Start timing for data generation
auto start_gen = std::chrono::high_resolution_clock::now();&lt;/p&gt;
&lt;h2 id=&#34;complete-code-6&#34;&gt;Complete Code
&lt;/h2&gt;&lt;p&gt;// Generate 10,000 rows of data, each with 50 fields
for (size_t i = 0; i &amp;lt; 10000; ++i)
{
DataRow dataRow(50, &amp;ldquo;This is a test string&amp;rdquo;);
requestPackage.DataBody.push_back(dataRow);
}&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// End timing for data generation
auto end_gen = std::chrono::high_resolution_clock::now();
std::chrono::duration&amp;lt;double&amp;gt; duration_gen = end_gen - start_gen;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code
// Display result generation time
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Generation Time: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_gen.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    // Data merging using different methods
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Performance:\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-7&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Method 1: Using &#39;+=&#39; string concatenation
auto start_merge = std::chrono::high_resolution_clock::now();
std::string bodys(&amp;quot;&amp;quot;);
for (auto&amp;amp; vec : requestPackage.DataBody)
{
    std::string body(&amp;quot;This is a test string&amp;quot;);
    for (auto&amp;amp; item : vec)
    {
        body += item + &amp;quot; &amp;quot;;
    }
    bodys += body + &amp;quot;\n&amp;quot;;
}
auto end_merge = std::chrono::high_resolution_clock::now();
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code
}
    auto end_merge = std::chrono::high_resolution_clock::now();
    std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
    std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (+=) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-8&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Method 2: Using ostringstream
auto start_merge = std::chrono::high_resolution_clock::now();
std::ostringstream bodys;
for (auto&amp;amp; vec : requestPackage.DataBody)
{
    std::ostringstream body;
    body &amp;lt;&amp;lt; &amp;quot;This is a test string&amp;quot;;
    for (auto&amp;amp; item : vec)
    {
        body &amp;lt;&amp;lt; item &amp;lt;&amp;lt; &amp;quot; &amp;quot;;
    }
    bodys &amp;lt;&amp;lt; body.str() &amp;lt;&amp;lt; &amp;quot;\n&amp;quot;;
}
auto end_merge = std::chrono::high_resolution_clock::now();
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code
}
    auto end_merge = std::chrono::high_resolution_clock::now();
    std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
    std::cout &amp;lt;&amp;lt; &amp;quot;+ ostringstream Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code
{
        // Method 3: Pre-allocated memory
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys;
        bodys.reserve(1000 * 50 * 20); // Pre-allocate enough memory
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            body.reserve(50 * 20); // Pre-allocate memory for each row
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code

for (auto&amp;amp; item : vec) {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Pre-reserved Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-9&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;// Method 4: Using &#39;bodys = bodys + body + &amp;quot;\n&amp;quot;&#39;
auto start_merge = std::chrono::high_resolution_clock::now();
std::string bodys(&amp;quot;&amp;quot;);
for (auto&amp;amp; vec : requestPackage.DataBody)
{
    std::string body(&amp;quot;This is a test string&amp;quot;);
    for (auto&amp;amp; item : vec)
    {
        body = body + item + &amp;quot; &amp;quot;; // Note the use of &#39;body = body + item&#39;
    }
    bodys = bodys + body + &amp;quot;\n&amp;quot;; // Again, using &#39;bodys = bodys + body&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Complete Code

```cpp
        auto start_merge = std::chrono::high_resolution_clock::now();
        bodys = bodys + body + &amp;quot;\n&amp;quot;; // Again, using &#39;bodys = bodys + body&#39;
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (bodys = bodys + body + \&amp;quot;\\n\&amp;quot;) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code-10&#34;&gt;Complete Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Complete.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;
}

int main()
{
    try
    {
        create_large_string();
    }
    catch (const std::exception&amp;amp; e)
    {
        std::cerr &amp;lt;&amp;lt; &amp;quot;Caught exception: &amp;quot; &amp;lt;&amp;lt; e.what() &amp;lt;&amp;lt; std::endl;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\nProgram finished.\n&amp;quot;;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>C&#43;&#43; Lambda Expression Parameter Lifetimes</title>
        <link>https://ttf248.life/en/p/cpp-lambda-parameter-lifetime/</link>
        <pubDate>Wed, 13 Nov 2024 19:23:02 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-lambda-parameter-lifetime/</guid>
        <description>&lt;p&gt;In C++, lambda expressions are a convenient way to create anonymous functions that can capture external variables and use them within their bodies. This makes lambdas a flexible programming tool. However, the lifetime of parameters in a lambda expression is an aspect that requires particular attention, especially when capturing and passing parameters.&lt;/p&gt;
&lt;h3 id=&#34;1-lambda-expression-parameter-lifetime&#34;&gt;1. Lambda Expression Parameter Lifetime
&lt;/h3&gt;&lt;p&gt;The lifetime of parameters in a lambda expression is typically the same as that of other C++ functions. Parameters exist while the function is called, and their lifetime ends when the function call terminates. However, due to the possibility of lambdas capturing external variables, the parameter&amp;rsquo;s lifetime is also affected by how it’s captured.&lt;/p&gt;
&lt;h3 id=&#34;2-capturing-the-relationship-with-parameter-lifecycles&#34;&gt;2. Capturing the Relationship with Parameter Lifecycles
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;#### 2.1 Capturing External Variables

C++ lambda expressions allow external variables to be captured in two ways:

- **Capture by Value:** When capturing by value, the value of the external variable is copied into the lambda, and the lifetime of the copy is controlled by the lifetime of the lambda.
- **Capture by Reference:** When capturing by reference, a reference to the external variable is retained, and the lambda&#39;s reference points to the original external variable. The lifetime depends on the lifetime of the external variable.
``` ```cpp
int x = 10;
auto lambda_by_value = [x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };  // Captures a copy of x
auto lambda_by_reference = [&amp;amp;x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };  // Captures a reference to x

lambda_by_value();  // Prints 10
lambda_by_reference();  // Prints 10

For the captured variables, their lifetimes are as follows:
- **Capture by value**: When the lambda is created, a copy of the external variable x is made and stored within the lambda. When the lambda&#39;s lifetime ends, this copied value is destroyed.
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;21-capture-external-variables&#34;&gt;2.1 Capture External Variables
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;By Reference Capture:&lt;/strong&gt; The lambda holds a reference to the external variable, &lt;strong&gt;the external variable must be valid before it is used within the lambda, otherwise undefined behavior will occur.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;22-lambda-parameters&#34;&gt;2.2 Lambda Parameters
&lt;/h4&gt;&lt;p&gt;Lambda parameters are similar to regular function parameters; their lifetime is limited to the lambda function body. That is, lambda parameters are created when the lambda is called and their lifetime ends when the lambda call completes.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;auto lambda = [](int a, int b) {
    std::cout &amp;lt;&amp;lt; a + b &amp;lt;&amp;lt; std::endl;
};
lambda(5, 10);  // a and b are the parameters of the lambda here
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; are the parameters of the lambda expression, they are created when the lambda is called and destroyed after the lambda executes.&lt;/p&gt;
&lt;h3 id=&#34;3-lifecycle-issues-when-capturing-external-variables&#34;&gt;3. Lifecycle Issues When Capturing External Variables
&lt;/h3&gt;&lt;h4 id=&#34;31-whether-captured-variables-are-valid-outside-lambda&#34;&gt;3.1 Whether Captured Variables Are Valid Outside Lambda
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Value Capture&lt;/strong&gt;: Even if the external variable is destroyed after the lambda call, the lambda internally holds a copy of the external variable. Therefore, the copy within the lambda can be used safely, even if the external variable no longer exists.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int x = 10;
auto lambda = [x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };
x = 20;  // x is modified after the lambda call
lambda();  // Prints 10, captures a copy of x
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Reference Capture&lt;/strong&gt;: If the external variable is captured by reference, the lambda&amp;rsquo;s access to that reference depends on the lifetime of the external variable. If the external variable is destroyed before the lambda executes, it results in a dangling reference problem and undefined behavior. ```cpp
int x = 10;
auto lambda = &lt;a class=&#34;link&#34; href=&#34;&#34; &gt;&amp;amp;x&lt;/a&gt; { std::cout &amp;laquo; x &amp;laquo; std::endl; };
x = 20;  // x is modified before lambda execution
lambda();  // Prints 20, captures a reference to x&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;
&amp;gt; If the execution order of the lambda is uncertain, it&#39;s crucial to ensure that any external variables captured within the lambda are still valid when the lambda executes.&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Win11 Logitech G431 Headset Driver Installation</title>
        <link>https://ttf248.life/en/p/win11-logitech-g431-headphone-driver-installation/</link>
        <pubDate>Wed, 05 Jun 2024 07:20:17 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/win11-logitech-g431-headphone-driver-installation/</guid>
        <description>&lt;p&gt;Picking up where we left off, I discovered that GitHub had an update, which was a little exciting. The customer service team said the issue with the driver not loading properly was resolved. However, after going through all of this – reinstalling and uninstalling – it still wasn’t working correctly.&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background
&lt;/h2&gt;&lt;p&gt;Continuing to contact customer service to inquire about a resolution, I was informed that an engineer could provide remote assistance. However, the engineer’s working hours coincided exactly with my own, leaving me with no option but to abandon the effort. Reviewing the documentation from the previous troubleshooting issue, I decided to attempt a manual driver installation.&lt;/p&gt;
&lt;h2 id=&#34;obtaining-driver-installation-packages&#34;&gt;Obtaining Driver Installation Packages
&lt;/h2&gt;&lt;p&gt;Logitech does not provide separate driver installation packages for devices. How can I obtain the driver files?&lt;/p&gt;
&lt;p&gt;In conjunction with the system image package left over from the previous system reinstallation, we can reinstall the system once in a local virtual machine, and then deploy a clean copy of Ghub in the pure system, inserting the headset device into the virtual machine to find the driver path and copy it out.&lt;/p&gt;
&lt;p&gt;Relevant paths:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C:\ProgramData\LGHUB&lt;/li&gt;
&lt;li&gt;C:\Windows\System32\DriverStore\FileRepository\logi_audio.inf_amd64_010b035044e24be4&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;device-manager&#34;&gt;Device Manager
&lt;/h2&gt;&lt;p&gt;The focus is on how to find the second path – let’s first briefly outline how to manually manage driver files in a Windows 11 system. This content &lt;strong&gt;is identified using the method of controlling variables by repeatedly plugging and unplugging devices, analyzing device information within Device Manager inside a virtual machine, and identifying three drivers that need to be handled for headphones.&lt;/strong&gt; Two of these drivers are system-provided, while one is provided by Logitech.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/win11-logitech-g431-headphone-driver-installation/20240605073331.png&#34;
	width=&#34;433&#34;
	height=&#34;904&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Driver Manager&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;47&#34;
		data-flex-basis=&#34;114px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;In the second driver shown in the image, it’s provided by Logitech.  Let&amp;rsquo;s analyze the current driver program for the device and then search all driver paths within the virtual machine. Of course, you first need to find files starting with “logi,” and then compare the files – this will allow you to pinpoint the location of the driver folder, copy the entire folder, and you’ll have the driver installation package.&lt;/p&gt;
&lt;h2 id=&#34;installing-the-driver&#34;&gt;Installing the Driver
&lt;/h2&gt;&lt;p&gt;In the device manager interface, click: Update driver, then click: Browse my computer to find drivers, and you’ll arrive at the following interface:&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/win11-logitech-g431-headphone-driver-installation/20240605074130.png&#34;
	width=&#34;528&#34;
	height=&#34;381&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Driver Installation&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;138&#34;
		data-flex-basis=&#34;332px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Of course, when you open it, you&amp;rsquo;ll only see one driver – the standard USB driver. Select &amp;ldquo;Install from disk&amp;rdquo; and the path is the folder we copied earlier. After installation, you’ll be able to add Logitech-specific drivers in the dropdown list. Switch the device driver to the newly installed driver.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/win11-logitech-g431-headphone-driver-installation/20240605074208.png&#34;
	width=&#34;593&#34;
	height=&#34;423&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Disk Installation&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;140&#34;
		data-flex-basis=&#34;336px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;human-anatomy-device-driven&#34;&gt;Human Anatomy Device-Driven
&lt;/h2&gt;&lt;p&gt;These driver files are provided by the system. You only need to check if there is an exclamation mark preceding the device driver name. If there is, enter the Driver Selection interface, randomly switch to a different type of driver, and then revert it back to restore normal operation.&lt;/p&gt;
&lt;h2 id=&#34;completed&#34;&gt;Completed
&lt;/h2&gt;&lt;p&gt;The microphone volume on the headphones has been restored to normal, and the familiar in-ear functionality has returned.
&lt;img src=&#34;https://ttf248.life/p/win11-logitech-g431-headphone-driver-installation/20240605074823.png&#34;
	width=&#34;485&#34;
	height=&#34;739&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Side Noise&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;65&#34;
		data-flex-basis=&#34;157px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Logitech Headset Driver Installation Failed</title>
        <link>https://ttf248.life/en/p/logitech-headphone-driver-installation-failure/</link>
        <pubDate>Fri, 31 May 2024 21:46:12 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/logitech-headphone-driver-installation-failure/</guid>
        <description>&lt;p&gt;If you completely don&amp;rsquo;t understand these things, contacting official customer service first will also avoid wasting several hours.&lt;/p&gt;
&lt;h2 id=&#34;main-text&#34;&gt;Main Text
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/logitech-headphone-driver-installation-failure/20240531220709.png&#34;
	width=&#34;693&#34;
	height=&#34;489&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;GHUB&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;141&#34;
		data-flex-basis=&#34;340px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Recently, the C drive of my desktop computer used for development was running out of space, so I took out a 256GB semi-retired solid state hard drive to use as the C drive. Unfortunately, I kept messing around with it. Since moving to Shanghai, I&amp;rsquo;ve been busy with various things, and finally last week I took some time to reinstall the system.&lt;/p&gt;
&lt;p&gt;The system reinstallation went smoothly, and installing daily software and deploying development environments didn’t encounter any problems. A few days later, I planned to relax and play a few games when I realized that the drivers for my mouse and headphones hadn&amp;rsquo;t been installed. Both devices are Logitech products, so I downloaded the GHUB software, which can automatically identify hardware and install drivers.&lt;/p&gt;
&lt;p&gt;However, an unexpected event occurred. The mouse driver installed successfully, but the headphone driver kept displaying &amp;ldquo;Loading&amp;hellip;&amp;rdquo; I suspect it may be incompatibility between the latest version of Windows 11 and Logitech’s drivers, causing the installation to fail. Therefore, I began searching for information and attempting manual driver installations, but the problem remained unresolved.&lt;/p&gt;
&lt;p&gt;Let me briefly explain the roles of these two drivers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The mouse driver primarily focuses on adjusting mouse movement speed and other functions. I rarely use macros; I simply restore previously remembered parameters.&lt;/li&gt;
&lt;li&gt;The headphone driver mainly handles the microphone functionality (earphone mic), which is very useful during team voice calls, allowing me to hear my own voice. Although there’s a similar listening function in the system&amp;rsquo;s microphone settings, it doesn’t perform as well as the driver implementation.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;main-text-1&#34;&gt;Main Text
&lt;/h2&gt;&lt;p&gt;Despite my repeated attempts, the headset driver consistently failed to load properly. Today, I finally thought of reaching out to customer service to inquire about the situation and see if there were any solutions. Customer service informed me that their servers had recently experienced an issue, leading to abnormal driver downloads. They are currently addressing this problem and asked me not to worry; the issue should be resolved after the next update.&lt;/p&gt;
&lt;p&gt;Although the headset driver issue hasn’t been resolved yet, at least I now know the cause, and I hope the problem can be fixed as soon as possible.&lt;/p&gt;
&lt;h2 id=&#34;mouse-driver-settings&#34;&gt;Mouse Driver Settings
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/logitech-headphone-driver-installation-failure/20240531220930.png&#34;
	width=&#34;1024&#34;
	height=&#34;768&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;G502&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;
&lt;img src=&#34;https://ttf248.life/p/logitech-headphone-driver-installation-failure/20240531220903.png&#34;
	width=&#34;1024&#34;
	height=&#34;768&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;G502&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Python Dictionary Storage of Custom Objects: The Importance of References vs. Deep Copies</title>
        <link>https://ttf248.life/en/p/python-dictionary-custom-objects-reference-vs-deepcopy/</link>
        <pubDate>Fri, 22 Mar 2024 01:08:05 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/python-dictionary-custom-objects-reference-vs-deepcopy/</guid>
        <description>&lt;p&gt;In Python programming, a dictionary is a very powerful data structure that allows us to associate key-value pairs and efficiently search and manipulate these data. When we try to store custom objects in a dictionary, we often encounter a crucial concept: In Python, object assignment is actually reference assignment, not a deep copy of the object itself. This means that when you put a custom object into a dictionary, the dictionary stores a reference to that object, rather than a brand new copy of the object.&lt;/p&gt;
&lt;h2 id=&#34;basic-example-of-storing-custom-objects&#34;&gt;Basic Example of Storing Custom Objects
&lt;/h2&gt;&lt;p&gt;Let&amp;rsquo;s consider a simple &lt;code&gt;Person&lt;/code&gt; class:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Person:
    def __init__(self, name, age):
        self.name = name
        self.age = age

# Create a Person object
p1 = Person(&amp;quot;Alice&amp;quot;, 30)

# Store the object in a dictionary
people_dict = {}
people_dict[&amp;quot;alice&amp;quot;] = p1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, the &lt;code&gt;people_dict&lt;/code&gt; dictionary now contains an item with a key &lt;code&gt;&amp;quot;alice&amp;quot;&lt;/code&gt; and its value is a reference to the &lt;code&gt;Person&lt;/code&gt; type object &lt;code&gt;p1&lt;/code&gt;. If we modify the properties of this object:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;p1.age = 31
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then when accessing this object through the dictionary, we will find that its age has also been updated:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(people_dict[&amp;quot;alice&amp;quot;].age)  # Output: 31
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is because the dictionary stores references to &lt;code&gt;Person&lt;/code&gt; objects rather than independent copies of them. It stores a reference to the same memory address.&lt;/p&gt;
&lt;h2 id=&#34;deep-copy-vs-shallow-copy&#34;&gt;Deep Copy vs. Shallow Copy
&lt;/h2&gt;&lt;p&gt;This referencing behavior can lead to unexpected results when dealing with nested data structures or custom objects. For example, if a custom object contains mutable attribute types (such as lists or another custom object), directly storing such an object in a dictionary and modifying it will affect the object obtained through the dictionary.&lt;/p&gt;
&lt;h2 id=&#34;deep-copy-vs-shallow-copy-1&#34;&gt;Deep Copy vs. Shallow Copy
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Address:
    def __init__(self, street, city):
        self.street = street
        self.city = city

class Person:
    def __init__(self, name, age, address):
        self.name = name
        self.age = age
        self.address = address

address = Address(&amp;quot;Main St.&amp;quot;, &amp;quot;Springfield&amp;quot;)
p1 = Person(&amp;quot;Bob&amp;quot;, 40, address)
people_dict[&amp;quot;bob&amp;quot;] = p1

# Modify the original address object
address.city = &amp;quot;Shelbyville&amp;quot;

# The person in the dictionary also changed their address
print(people_dict[&amp;quot;bob&amp;quot;].address.city)  # Output: Shelbyville
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Solution: Deep Copy&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;deep-copy-vs-shallow-copy-2&#34;&gt;Deep Copy vs. Shallow Copy
&lt;/h2&gt;&lt;p&gt;To avoid issues caused by shared state, sometimes we need to ensure that the dictionary stores a complete copy of an object, rather than a reference to it. Python provides the &lt;code&gt;copy&lt;/code&gt; module&amp;rsquo;s &lt;code&gt;deepcopy&lt;/code&gt; function to achieve this goal:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import copy

# Use deep copy to store the object
people_dict[&amp;quot;bob_deepcopy&amp;quot;] = copy.deepcopy(p1)

# At this point, even if you modify the original referenced object, the deep copy object will not be affected
address.city = &amp;quot;Capital City&amp;quot;
print(people_dict[&amp;quot;bob&amp;quot;].address.city)  # Output: Capital City
print(people_dict[&amp;quot;bob_deepcopy&amp;quot;].address.city)  # Output: Shelbyville
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In summary, when storing custom objects in Python dictionaries, be sure to pay attention to the fact that by default, they store object references.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Why does a newly installed gigabit fiber to the home (FTTH) connection only test at 100 Mbps?</title>
        <link>https://ttf248.life/en/p/gigabit-fiber-slow-speed/</link>
        <pubDate>Mon, 18 Mar 2024 00:29:02 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/gigabit-fiber-slow-speed/</guid>
        <description>&lt;p&gt;Want your home network to be lightning fast? The key is understanding cable selection, optical lines (ONTs), and router configuration, as well as those seemingly insignificant details. This blog post will guide you through easily learning how to build a gigabit network using six types of cables, and how to ensure your network speed isn&amp;rsquo;t restricted by simple device checks and configurations. Let’s explore together and make your home network fly!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/gigabit-fiber-slow-speed/image.png&#34;
	width=&#34;1001&#34;
	height=&#34;590&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Manual Repair&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;169&#34;
		data-flex-basis=&#34;407px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;chapter-1-an-in-depth-analysis-of-network-transmission-media&#34;&gt;Chapter 1: An In-Depth Analysis of Network Transmission Media
&lt;/h2&gt;&lt;p&gt;When discussing achieving gigabit network access, the carrier that supports high-speed information transmission – cables – plays a crucial role. Below we will provide detailed interpretations of Cat5, Cat6, and Cat7 cables.&lt;/p&gt;
&lt;h3 id=&#34;1-five-category-cables-cat5&#34;&gt;1. &lt;strong&gt;Five-Category Cables (CAT5)&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;CAT5 cables, also known as CAT5, are an earlier and more widely adopted type of twisted pair cable. Each pair of wire pairs is designed with a precise helical structure to reduce crosstalk. It’s primarily used for 10/100Mbps Fast Ethernet, with a maximum transmission frequency of approximately 100MHz. While it was once widely applied, CAT5 cables cannot meet current demands for gigabit and even higher speeds due to physical limitations.&lt;/p&gt;
&lt;h3 id=&#34;2-six-category-cables-cat6&#34;&gt;2. &lt;strong&gt;Six-Category Cables (CAT6)&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;With the development of technology, six-category cables have emerged. Compared to five-category cables, six-core wires adopted stricter manufacturing standards and more advanced structural designs, significantly improving anti-interference capability and transmission efficiency, supporting data transfer rates up to 1Gbps, and with a transmission distance of up to 100 meters under ideal conditions, which perfectly meets the access requirements of Gigabit networks.&lt;/p&gt;
&lt;h3 id=&#34;3-seven-category-cables-cat7&#34;&gt;3. &lt;strong&gt;Seven-Category Cables (CAT7)&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;Seven-category cables represent the current cutting edge of twisted pair cabling technology. It not only offers a significant leap in transmission rates, theoretically supporting speeds up to 10Gbps, but also incorporates a complete shielding system, including shielding between each pair and overall external shielding, which greatly reduces external electromagnetic interference and near-end crosstalk, ensuring data transmission stability and accuracy. However, CAT7 cables are primarily used for future 10 Gigabit Ethernet or specific high-requirement scenarios.&lt;/p&gt;
&lt;p&gt;When setting up a gigabit home network environment, choosing six-category cables is the most economical and efficient choice to fully unleash the potential of the gigabit fiber optic.  Furthermore, ensuring that all cabling materials meet quality standards and strictly adhering to standard wiring practices are also crucial aspects in guaranteeing network performance.&lt;/p&gt;
&lt;h2 id=&#34;chapter-two-deep-dive-into-core-network-devices--the-impact-of-optical-cat-光猫-and-router-lan-port-bandwidth&#34;&gt;Chapter Two: Deep Dive into Core Network Devices – The Impact of Optical Cat (光猫) and Router LAN Port Bandwidth
&lt;/h2&gt;&lt;h3 id=&#34;the-importance-of-optical-cat-ont-and-its-lan-port-bandwidth&#34;&gt;The Importance of Optical Cat (ONT) and its LAN Port Bandwidth
&lt;/h3&gt;&lt;p&gt;An ONT, or optical network terminal, is the core device for home broadband access. Its function is to convert optical signals from fiber optic cables into digital signals for use by home network devices. For users with gigabit fiber connections, whether the ONT supports gigabit transmission is particularly important. If the ONT’s WAN port only supports 100 Mbps, even if the incoming fiber rate is high, it will be limited to 100 Mbps due to this bottleneck. Similarly, the ONT’s LAN port also needs to have a gigabit output capability; otherwise, routers or other devices connected to it cannot obtain the true gigabit rate.&lt;/p&gt;
&lt;h3 id=&#34;the-role-of-bandwidth-on-router-lan-ports&#34;&gt;The Role of Bandwidth on Router LAN Ports
&lt;/h3&gt;&lt;p&gt;The router’s LAN ports are responsible for distributing the data received to various terminal devices. When a router&amp;rsquo;s LAN port is only 100 Mbps, even if other devices are configured well, it can only achieve 100 Mbps local network communication. Therefore, when building a Gigabit home network, it’s important to ensure that the router’s WAN port can receive 1 Gbps data and that the LAN ports also provide data output capabilities at the Gigabit level, so that all smart devices in your home can enjoy the smooth experience brought by high-speed networks.&lt;/p&gt;
&lt;p&gt;Furthermore, it&amp;rsquo;s worth noting that some older or low-end routers may have a LAN port automatic negotiation mechanism, which means that even if the router itself supports 1 Gbps, it may be downgraded to a 100 Mbps mode due to cable issues, device compatibility, and other reasons. Therefore, correctly configuring router parameters, enabling forced gigabit mode, and pairing it with a gigabit switch or direct device are key steps in achieving a full gigabit network. After upgrading to gigabit fiber, be sure to check and replace with gigabit optical switches and gigabit routers to ensure all device interfaces meet gigabit standards.&lt;/p&gt;
&lt;h2 id=&#34;chapter-three-the-hidden-mystery--how-a-broken-subline-impacts-gigabit-network-speed&#34;&gt;Chapter Three: The Hidden Mystery – How a Broken Subline Impacts Gigabit Network Speed
&lt;/h2&gt;&lt;h3 id=&#34;line-fault-and-network-performance-degradation&#34;&gt;Line Fault and Network Performance Degradation
&lt;/h3&gt;&lt;p&gt;During the speed tests, the network consistently maintained a connection without any apparent disconnects. As it was a newly deployed broadband for residential customers, the distribution box was cluttered and frequently adjusted the optical cat’s wiring and power outlet positions, occasionally resulting in speeds reaching gigabit.&lt;/p&gt;
&lt;p&gt;Based on the previous information, we had analyzed and eliminated potential issues related to cable type and optical cat LAN port speed. Ultimately, the culprit was discovered to be a broken brown sub-cable within the network cable itself.&lt;/p&gt;
&lt;p&gt;The cause of the break: When the technician installed the crystal head, this cable was applied with slightly excessive force, causing one of the sub-cables to break in half. It wasn’t completely severed, and subsequent adjustments to the optical cat&amp;rsquo;s position caused it to eventually break completely.&lt;/p&gt;
&lt;h3 id=&#34;six-category-cable-lines-function-analysis&#34;&gt;Six Category Cable Lines Function Analysis
&lt;/h3&gt;&lt;p&gt;Six category cables adhere to the TIA/EIA-568-B standard and contain eight twisted pairs of wires, color-coded as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;White Orange / Orange&lt;/li&gt;
&lt;li&gt;White Green / Green&lt;/li&gt;
&lt;li&gt;White Blue / Blue&lt;/li&gt;
&lt;li&gt;White Brown / Brown&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Under the standard of Gigabit Ethernet (1000BASE-T), these eight lines consist of four pairs working simultaneously, with the following division of labor:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The White Orange and Orange pair of wires (1&amp;amp;2) is used for transmitting data (Tx+/-);&lt;/li&gt;
&lt;li&gt;The White Green and Green pair of wires (3&amp;amp;6) is used for receiving data (Rx+/-);&lt;/li&gt;
&lt;li&gt;The White Blue and Blue pair of wires (4&amp;amp;5) and the White Brown and Brown pair of wires (7&amp;amp;8) were not originally primary in Gigabit Ethernet, but may be enabled in certain advanced applications (such as some PoE power delivery or future technology expansions). In traditional 100 Mbps networks, only four lines – 1, 2, 3, and 6 – could be used.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;impact-of-breakaway-pairs-on-network-speed&#34;&gt;Impact of Breakaway Pairs on Network Speed
&lt;/h3&gt;&lt;p&gt;In the above scenarios, if a brown sub-cable (i.e., brown or brown-white wire) breaks, theoretically it will cause speed degradation in gigabit networks, as gigabit networks require all four pairs of wires to transmit bidirectionally simultaneously to achieve full speed. However, due to home network devices often having auto-negotiation features, when a cable issue is detected, they will revert to a lower operating rate that functions normally, which is the megabit mode, explaining why even with a broken sub-cable, the network can maintain connectivity and operate at megabit speeds.&lt;/p&gt;
&lt;p&gt;In short, although a brown sub-cable break does not affect the basic operation of a megabit network, it can become a key limiting factor for network speed in gigabit environments. Until a thorough diagnosis and repair is conducted, the full potential of gigabit fiber cannot be truly realized. This also serves as a reminder that we should not overlook any potential network infrastructure issues when encountering similar situations – even seemingly minor connection glitches can become hidden obstacles to a high-speed networking experience.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>WPF UI Thread Blocking Issues and Solutions</title>
        <link>https://ttf248.life/en/p/wpf-ui-thread-and-freezing-solutions/</link>
        <pubDate>Tue, 12 Mar 2024 07:12:21 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/wpf-ui-thread-and-freezing-solutions/</guid>
        <description>&lt;p&gt;When developing desktop applications, particularly when using the Windows Presentation Foundation (WPF) framework to build rich client applications, properly handling the user interface (UI) thread is crucial for ensuring the application’s smoothness and responsiveness. The UI thread, also known as the main thread, is the core thread responsible for processing window and control events, layout calculations, and rendering the UI. Any interaction with UI elements should be executed on the UI thread; this is a fundamental principle followed by WPF and most other GUI frameworks.&lt;/p&gt;
&lt;h2 id=&#34;what-is-the-ui-thread&#34;&gt;What is the UI Thread?
&lt;/h2&gt;&lt;p&gt;The UI thread is created by the operating system when a WPF application starts and initializes the main application window. It’s the only thread within the application that can directly access and modify the state of UI components. This means all user interactions, such as button clicks, text box input, or window size changes, are processed in this thread context. Furthermore, WPF&amp;rsquo;s dependency property system, data binding mechanism, and layout logic are all synchronized on the UI thread.&lt;/p&gt;
&lt;h2 id=&#34;screen-freezing-phenomenon-and-its-causes&#34;&gt;Screen Freezing Phenomenon and Its Causes
&lt;/h2&gt;&lt;p&gt;When the UI thread is heavily occupied or blocked for an extended period, such as when performing time-consuming calculations, loading large amounts of data, database queries, or other I/O-intensive tasks, it becomes unable to promptly respond to user interaction requests. This results in the UI freezing – what we commonly refer to as “stuttering” or “freezing.” In this situation, users will noticeably feel the application’s lag and lack of smoothness, and in severe cases, an &amp;ldquo;Application Not Responding&amp;rdquo; (ANR) warning may appear.&lt;/p&gt;
&lt;h2 id=&#34;two-basic-rules-for-the-ui-thread&#34;&gt;Two Basic Rules for the UI Thread
&lt;/h2&gt;&lt;p&gt;To avoid the above scenarios, WPF developers should adhere to the following two key rules:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Do not perform time-consuming operations on the UI thread:&lt;/strong&gt; Any operation that could cause the UI thread to block should be moved to a background thread as much as possible to ensure the UI thread can promptly respond to user input and render screen changes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Do not directly update UI elements from non-UI threads:&lt;/strong&gt; Due to WPF’s security mechanism design, only the UI thread has permission to modify UI elements. Attempting to change UI state directly from another thread will throw an exception. Therefore, even if a background thread completes calculations or data preparation, you must use appropriate cross-thread communication mechanisms to display the results on the UI.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;solutions-asynchronous-programming-and-thread-safe-updates&#34;&gt;Solutions: Asynchronous Programming and Thread-Safe Updates
&lt;/h2&gt;&lt;p&gt;To execute time-consuming tasks while maintaining UI fluency, WPF provides various asynchronous programming models and tools to assist developers in achieving this goal:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Dispatcher Object:&lt;/strong&gt; The WPF Dispatcher class allows you to schedule work items into the UI thread&amp;rsquo;s task queue for execution. You can use the &lt;code&gt;Dispatcher.Invoke&lt;/code&gt; or &lt;code&gt;Dispatcher.BeginInvoke&lt;/code&gt; methods to safely update the UI from a background thread.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;async/await Keywords:&lt;/strong&gt; Leveraging C#’s asynchronous features, you can write asynchronous methods and utilize the &lt;code&gt;await&lt;/code&gt; keyword within them to wait for background tasks to complete, automatically returning to the UI thread to execute subsequent UI update code upon completion.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;case-studies&#34;&gt;Case Studies
&lt;/h2&gt;&lt;h3 id=&#34;updating-the-ui-using-dispatcherinvoke-method&#34;&gt;Updating the UI Using &lt;code&gt;Dispatcher.Invoke&lt;/code&gt; Method
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;private void Button_Click(object sender, RoutedEventArgs e)
{
    // Assume this is a time-consuming operation
    Task.Run(() =&amp;gt;
    {
        var result = LongRunningOperation(); // This is a simulated method for a long calculation
        
        // When the time-consuming operation is complete, update the UI on the UI thread
        Application.Current.Dispatcher.Invoke(() =&amp;gt;
        {
            LabelStatus.Text = $&amp;quot;Calculation Result: {result}&amp;quot;;
        });
    });
}

private string LongRunningOperation()
{
    // Simulate a time-consuming operation
    Thread.Sleep(5000);
    return &amp;quot;Completed&amp;quot;;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;using-the-asyncawait-keyword-with-taskrun&#34;&gt;Using the &lt;code&gt;async/await&lt;/code&gt; keyword with &lt;code&gt;Task.Run&lt;/code&gt;
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;private async void Button_ClickAsync(object sender, RoutedEventArgs e)
{
    Button button = sender as Button;
    button.IsEnabled = false; // Prevent duplicate clicks by the user

    try
    {
        // Start a background task
        var result = await Task.Run(() =&amp;gt; LongRunningOperation());

        // Automatically switch back to the UI thread to update the UI after the background task completes
        LabelStatus.Text = $&amp;quot;Calculation Result: {result}&amp;quot;;
    }
    catch (Exception ex)
    {
        MessageBox.Show($&amp;quot;An error occurred: {ex.Message}&amp;quot;);
    }
    finally
    {
        button.IsEnabled = true; // Re-enable the button
    }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Upgrading the GCC version caused program crashes: hidden issues due to code non-compliance.</title>
        <link>https://ttf248.life/en/p/gcc-upgrade-causes-program-crash-code-irregularities/</link>
        <pubDate>Sun, 10 Mar 2024 23:19:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/gcc-upgrade-causes-program-crash-code-irregularities/</guid>
        <description>&lt;p&gt;In the same business code scenario, the program compiled and ran normally in a CentOS 7 environment. However, when switching to CentOS 8 and using an updated version of GCC for compilation, the program crashed. It’s worth noting that the issue only occurs in &lt;strong&gt;Release mode&lt;/strong&gt;, while &lt;strong&gt;Debug mode&lt;/strong&gt; does not exhibit any problems. This is the first time we&amp;rsquo;ve encountered a situation like this; after three days of investigation, we finally identified the root cause.&lt;/p&gt;
&lt;h3 id=&#34;problem-identification&#34;&gt;Problem Identification
&lt;/h3&gt;&lt;p&gt;After investigation, the root cause of the issue was &lt;strong&gt;the function lacking a return value&lt;/strong&gt;. In Release mode, new versions of GCC perform more optimizations, which caused an unknown logic to occur within the function that originally did not have an explicit return value during execution, ultimately triggering a crash. Our conclusion is that &lt;strong&gt;compiler warnings should not be ignored, especially in legacy projects where some warnings may be dismissed, but it’s also important to avoid suppressing all warnings.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;environment-details&#34;&gt;Environment Details
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CentOS 7 GCC Version:&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CentOS 8 GCC Version:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;crash-phenomena&#34;&gt;Crash Phenomena
&lt;/h3&gt;&lt;p&gt;When analyzing the stack information for program crashes, we observed the following stack details:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[New LWP 1385902]
[Thread debugging using libthread_db enabled]
Using host libthread_db library &amp;quot;/lib64/libthread_db.so.1&amp;quot;.
Core was generated by `./pstack_main`.
Program terminated with signal SIGSEGV, Segmentation fault.
#0  0x00007ffe894b4420 in ?? ()
(gdb) bt
#0  0x00007ffe894b4420 in ?? ()
#1  0x00000000004008e9 in main ()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This stack doesn&amp;rsquo;t appear intuitive; the crash function’s stack information shows a &lt;code&gt;??&lt;/code&gt;, which makes troubleshooting even more complex.&lt;/p&gt;
&lt;h3 id=&#34;code-example&#34;&gt;Code Example
&lt;/h3&gt;&lt;p&gt;To better understand the issue, here’s a minimal code example that reproduces the crash:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;map&amp;gt;

int test() {
    std::cout &amp;lt;&amp;lt; &amp;quot;1&amp;quot; &amp;lt;&amp;lt; std::endl;
}

int main() {
    test();
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;test()&lt;/code&gt; function in this code clearly doesn&amp;rsquo;t explicitly return a value, and its return type is &lt;code&gt;int&lt;/code&gt;. According to the C++ standard, when a function is declared as an &lt;code&gt;int&lt;/code&gt; type, it must have a return value, otherwise it may lead to undefined behavior.&lt;/p&gt;
&lt;h3 id=&#34;compilation-warning&#34;&gt;Compilation Warning
&lt;/h3&gt;&lt;p&gt;In our project, the CMake script suppresses many compile-time warnings, including the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;/root/pstack/main.cpp: In function ‘int test()’:
/root/pstack/main.cpp:7:1: warning: no return statement in function returning non-void [-Wreturn-type]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This warning indicates that the &lt;code&gt;test()&lt;/code&gt; function does not return a value, which is the root cause of the problem. Newer versions of GCC (such as 8.5.0) may make unstable optimizations with this undefined behavior when optimizing code, potentially leading to program crashes.&lt;/p&gt;
&lt;h3 id=&#34;assembly-code-differences&#34;&gt;Assembly Code Differences
&lt;/h3&gt;&lt;p&gt;To explain the differences in GCC compiler optimization behavior, we compared assembly code generated by different versions of GCC:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GCC 4.8.5 Generated Assembly Code:&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The assembly code is relatively verbose and includes handling logic for standard output streams (such as &lt;code&gt;std::cout&lt;/code&gt;). This indicates that the compiler performed more conservative optimizations, not optimizing excessively for the missing return value issue in the &lt;code&gt;test()&lt;/code&gt; function, possibly to avoid a crash.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GCC 8.5.0 Generated Assembly Code:&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The new version of GCC performed more optimizations, reducing the code volume. However, this optimization may have resulted in undefined behavior when calling functions without returning values, leading to program crashes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h3&gt;&lt;p&gt;Through this troubleshooting process, we deeply realized that in C++, &lt;strong&gt;function return values must be explicit&lt;/strong&gt;, especially when a function is declared as &lt;code&gt;int&lt;/code&gt;, a return value must be provided. When upgrading from older versions of compilers to newer versions of GCC, more optimization and stricter warning mechanisms may be encountered. Therefore, we recommend not suppressing all warnings during compilation, but rather selectively addressing them, particularly common issues such as function return values and type matching.
Ultimately, by adding a return value to the &lt;code&gt;test()&lt;/code&gt; function, the problem was resolved, and the program returned to normal operation.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>VMware Virtual Machine CPU Resource Usage Anomaly</title>
        <link>https://ttf248.life/en/p/vmware-virtual-machine-cpu-usage-anomaly/</link>
        <pubDate>Sun, 10 Mar 2024 22:14:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/vmware-virtual-machine-cpu-usage-anomaly/</guid>
        <description>&lt;p&gt;Background: The business system, running in Windows version, is deployed on an on-premise machine with CPU resource utilization at around 5%. The Linux version of the business system, deployed within a VMware-installed CentOS8 environment, exhibits abnormal resource usage.&lt;/p&gt;
&lt;h2 id=&#34;problem-description&#34;&gt;Problem Description
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Host Machine: Windows 10 Enterprise&lt;/li&gt;
&lt;li&gt;VMware: 17.5&lt;/li&gt;
&lt;li&gt;Virtual Machine: CentOS8
The virtual machine resource allocation is &lt;code&gt;4C8GB&lt;/code&gt;, running the business system. The business system is deployed in the Linux system within the virtual machine, and the internal top command observes system resource usage. CPU utilization is not high, while the external Windows system&amp;rsquo;s Task Manager shows very high CPU resource consumption. Examining processes reveals that the VMware process consumes a large amount of CPU resources.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+
|         Windows           |
|                           |
|   +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+  |
|   |      VMware        |  |
|   |      Program       |  |
|   +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+  |
|                           |
+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&lt;/p&gt;
&lt;h2 id=&#34;key-concepts&#34;&gt;Key Concepts
&lt;/h2&gt;&lt;p&gt;Troubleshooting this issue was not straightforward, as the root cause wasn&amp;rsquo;t the business system itself but rather issues with the virtual machine.  How to shift thinking from conventional business code to system load, then from abnormal load data to pinpoint a soft interrupt, and finally arrive at the critical point – what factors affect VMware soft interrupt efficiency? This article will first explain these key concepts before offering solutions.&lt;/p&gt;
&lt;h3 id=&#34;hyper-v&#34;&gt;Hyper-V
&lt;/h3&gt;&lt;p&gt;The virtualization technology for Windows operating systems underwent a significant transformation. When Microsoft initially released WSL, enabling the Hyper-V service would prevent VMware virtual machines from working simultaneously. It wasn&amp;rsquo;t until subsequent versions that VMware could be compatible with the Hyper-V service.&lt;/p&gt;
&lt;h3 id=&#34;system-load&#34;&gt;System Load
&lt;/h3&gt;&lt;p&gt;In Linux systems, &amp;ldquo;load&amp;rdquo; refers to the number of processes currently running or waiting to be executed. The load is typically represented by three numbers, which are the average number of processes in the run queue over 1 minute, 5 minutes, and 15 minutes, respectively. These numbers can be viewed by running the &lt;code&gt;uptime&lt;/code&gt; command or the &lt;code&gt;top&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;Specifically, these three numbers represent:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;1-minute load:&lt;/strong&gt; The average number of processes in the run queue over the past 1 minute.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;5-minute load:&lt;/strong&gt; The average number of processes in the run queue over the past 5 minutes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;15-minute load:&lt;/strong&gt; The average number of processes in the run queue over the past 15 minutes.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The meaning of the load is the number of processes waiting to be executed within the system. - If this number exceeds the logical CPU count of the system, it indicates a high system load, meaning many processes are waiting for processor resources. This can lead to sluggish performance or unresponsiveness, depending on the severity of the load and the configuration and performance of the system.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ideally, the load should remain within the logical CPU count range to optimize system performance. If the load consistently exceeds the CPU count, further analysis of processes within the system may be necessary to identify the cause of the high load and take appropriate measures to adjust resource allocation or optimize process execution.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;analyzing-load---mpstat&#34;&gt;Analyzing Load - mpstat
&lt;/h3&gt;&lt;p&gt;The &lt;code&gt;mpstat&lt;/code&gt; command is used to report multiple statistics for a single or multiple processors, including average load, CPU utilization, interrupts, and context switches. Within the &lt;code&gt;sysstat&lt;/code&gt; package, &lt;code&gt;mpstat&lt;/code&gt; is a very useful tool for analyzing system load conditions.  Below are the steps involved in performing a load analysis using &lt;code&gt;mpstat&lt;/code&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Install sysstat&lt;/strong&gt;:
If &lt;code&gt;sysstat&lt;/code&gt; is not already installed on your system, you can use your system&amp;rsquo;s package manager to install it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Run mpstat&lt;/strong&gt;:
Use the &lt;code&gt;mpstat&lt;/code&gt; command to view CPU usage and load. By default, &lt;code&gt;mpstat&lt;/code&gt; displays CPU utilization averages once per second. You can adjust the output frequency by specifying an interval. - For example, to run &lt;code&gt;mpstat&lt;/code&gt; at a rate of one frequency per second, you can use the following command: &lt;code&gt;mpstat -P ALL 2&lt;/code&gt;, where &lt;code&gt;irq&lt;/code&gt; represents resource utilization.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Analyze Output&lt;/strong&gt;:
The output of &lt;code&gt;mpstat&lt;/code&gt; includes CPU utilization for each CPU, as well as the system&amp;rsquo;s average load. Pay particular attention to the average load and the utilization of each CPU to understand the system’s workload. If the load is high, you can further analyze which processes are causing it, and whether there are any performance bottlenecks.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;analyze-load---mpstat&#34;&gt;Analyze Load - mpstat
&lt;/h3&gt;&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;Combine with Other Tools&lt;/strong&gt;:
In addition to &lt;code&gt;mpstat&lt;/code&gt;, you can also use tools like &lt;code&gt;sar&lt;/code&gt;, &lt;code&gt;pidstat&lt;/code&gt;, and &lt;code&gt;iostat&lt;/code&gt; to comprehensively analyze system performance. By combining the outputs of multiple tools, you can gain a more complete understanding of the system&amp;rsquo;s load situation and identify the root causes of performance issues.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;interrupt&#34;&gt;Interrupt
&lt;/h3&gt;&lt;p&gt;This section doesn&amp;rsquo;t elaborate on the content too much,
Recommended: &lt;a class=&#34;link&#34; href=&#34;https://www.codedump.info/post/20200522-sgfap-softirq/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;System Guide for Application Developers - CPU Part - Soft Interrupt&lt;/a&gt;
Frequent triggering of soft interrupts will also be reflected in system load.&lt;/p&gt;
&lt;h2 id=&#34;troubleshooting&#34;&gt;Troubleshooting
&lt;/h2&gt;&lt;p&gt;Considering that analysis solely from the CPU perspective couldn’t pinpoint the issue, should we start to suspect that the system had become abnormal? It might be due to high load on the Linux operating system, causing VMware to consume excessive CPU resources. By using &lt;code&gt;mpstat&lt;/code&gt; to analyze local virtual machines, we found that &lt;code&gt;irq&lt;/code&gt; utilization was abnormally high, approaching 25% per core, while in normal circumstances, when business processes were idle, &lt;code&gt;irq&lt;/code&gt; should have been around 5%.&lt;/p&gt;
&lt;p&gt;In a colleague’s development environment within the team, his CentOS 7 deployment on VMware showed normal resource usage. Conversely, in the Shanghai development environment, although also running on VMware, we couldn&amp;rsquo;t directly observe the host machine’s CPU resource situation. At this point, we were faced with multiple variables: the VMware virtual machines, the Linux operating system, and the GCC version. - Analyzing the test environment, the Shenzhen test environment is deployed on physical machines running a low version of GCC compiled services. It’s also running on CentOS 8. Interestingly, &lt;code&gt;irq&lt;/code&gt; usage remained normal in the Shenzhen environment.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;To investigate potential issues introduced by the GCC version, we deployed programs compiled with a higher version of GCC to the Shenzhen environment for testing, and the results were normal as well.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The problem seemed to become clearer, and we began to suspect that there might be an issue with the operating system itself. After all, CentOS 8 is no longer officially supported. Even after deploying clean CentOS 7 and CentOS 8 instances, the problem persisted.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;troubleshooting-1&#34;&gt;Troubleshooting
&lt;/h2&gt;&lt;p&gt;At this point, we began to suspect the only unknown factor – VMware virtual machine software. Suddenly, a flash of insight occurred; we thought of Hyper-V technology. Could Hyper-V have been enabled previously but not completely disabled, causing this issue? After all, soft interrupts are also implemented through virtualization software. Do different virtualization technologies have bugs? These questions deserve in-depth consideration and investigation.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h2&gt;&lt;p&gt;According to the Microsoft official documentation, after completely disabling the Hyper-V service on the machine as described, VMware recovered normal operation on the host. This finally resolved the issue. As initially stated, this experience was convoluted and arduous, requiring comprehensive analysis and judgment. It was also our first time troubleshooting and pinpointing the problem down to the virtual machine level.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Disable-WindowsOptionalFeature -Online -FeatureName Microsoft-HyperV-Hypervisor
bcdedit /set hypervisorlaunchtype off
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/troubleshoot/windows-client/application-management/virtualization-apps-not-work-with-hyper-v&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://learn.microsoft.com/zh-cn/troubleshoot/windows-client/application-management/virtualization-apps-not-work-with-hyper-v&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>C&#43;&#43; Programming Traps: A Detailed Explanation of Program Crashes Caused by Improper Use of `std::map`</title>
        <link>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</link>
        <pubDate>Sun, 10 Mar 2024 22:03:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</guid>
        <description>e&gt;
&lt;h2 id=&#34;body&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;In the C++ standard library, &lt;code&gt;std::map&lt;/code&gt; is an associative container that stores elements in ascending order based on their keys (key), and provides efficient keyword lookup functionality. However, novice developers sometimes find themselves in trouble due to a misunderstanding of the behavior of the square bracket operator &lt;code&gt;[]&lt;/code&gt; within &lt;code&gt;std::map&lt;/code&gt;. In fact, when using &lt;code&gt;[]&lt;/code&gt; to access a non-existent key, &lt;code&gt;std::map&lt;/code&gt; inserts a new key-value pair, and the default constructor will be used to initialize the value type associated with that key. ```cpp
#include &lt;iostream&gt;
#include &lt;map&gt;&lt;/p&gt;
&lt;p&gt;int main() {
std::map&amp;lt;std::string, int&amp;gt; myMap;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Incorrect usage: Assuming this attempts to access a non-existent key and will return 0
std::cout &amp;lt;&amp;lt; &amp;quot;Value for &#39;nonexistent_key&#39;: &amp;quot; &amp;lt;&amp;lt; myMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;

// In reality, the above line of code creates a new key-value pair, where the value is initialized to the default value for an int (usually 0)
return 0;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-##&#34;&gt;In the C++ standard library, `std::map` is an associative container that stores elements in ascending order based on their keys (key), and provides efficient keyword lookup functionality. However, novice developers sometimes find themselves in trouble due to a misunderstanding of the behavior of the square bracket operator `[]` within `std::map`. In fact, when using `[]` to access a non-existent key, `std::map` inserts a new key-value pair, and the default constructor will be used to initialize the value type associated with that key.

## Text
Although this code does not directly cause the program to crash, this implicit insertion behavior can lead to unexpected side effects in some cases, such as resource leaks or changes in state that are not expected. Worse still, concurrent access to uninitialized memory regions in a multithreaded environment can even cause the program to crash.

To prevent these issues, it is recommended to use the `std::map::find()` or `std::map::count()` methods to check if a key exists, or to utilize the `std::map::insert()` method to explicitly insert elements:

```cpp
std::map&amp;lt;std::string, int&amp;gt; safeMap;
if (safeMap.count(&amp;quot;nonexistent_key&amp;quot;) == 0) {
    std::cout &amp;lt;&amp;lt; &amp;quot;Key does not exist.&amp;quot; &amp;lt;&amp;lt; std::endl;
} else {
    std::cout &amp;lt;&amp;lt; &amp;quot;Value for existing key: &amp;quot; &amp;lt;&amp;lt; safeMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;
}

// Or explicitly insert a key-value pair, specifying the initial value
safeMap. ## Text
Although the code does not directly cause a program crash, this implicit insertion behavior can lead to unexpected side effects in some cases, such as resource leaks or changes in state that are not expected. Worse still, concurrent access to uninitialized memory regions in a multithreaded environment can even cause a program to crash.

To prevent these issues, it is recommended to use the `std::map::find()` or `std::map::count()` methods to check if a key exists, or to utilize the `std::map::insert()` method to explicitly insert elements:

```cpp
std::map&amp;lt;std::string, int&amp;gt; safeMap;
if (safeMap.count(&amp;quot;nonexistent_key&amp;quot;) == 0) {
    std::cout &amp;lt;&amp;lt; &amp;quot;Key does not exist.&amp;quot; &amp;lt;&amp;lt; std::endl;
} else {
    std::cout &amp;lt;&amp;lt; &amp;quot;Value for existing key: &amp;quot; &amp;lt;&amp;lt; safeMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;
}

// Or explicitly insert a key-value pair, specifying the initial value
safeMap.

## Text
If the objects stored within the map container are pointer types, the automatic insertion behavior will save an uninitialized pointer, and any call to this pointer will cause the program to crash.&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>pstack troubleshoot a hung process</title>
        <link>https://ttf248.life/en/p/pstack-troubleshooting-process-hangs/</link>
        <pubDate>Sat, 24 Feb 2024 23:55:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/pstack-troubleshooting-process-hangs/</guid>
        <description>&lt;p&gt;In software development and operations, deadlocked processes are frequently encountered. This situation can lead to performance degradation or service unavailability. This article introduces how to use the pstack tool to troubleshoot deadlocked process issues by analyzing process stack information to identify the root cause and resolve it.&lt;/p&gt;
&lt;p&gt;Background: A child service within the risk control system experienced a deadlocked state, resulting in the unavailability of the risk control service. Due to the lack of service availability monitoring, the process deadlocks were not detected in a timely manner, leading to system downtime.&lt;/p&gt;
&lt;h2 id=&#34;text&#34;&gt;Text
&lt;/h2&gt;&lt;p&gt;A hung process refers to a process that has stopped responding but hasn&amp;rsquo;t exited. This situation can be caused by various reasons, such as deadlocks, resource exhaustion, or exceptions. To resolve these issues, we can use the &lt;code&gt;pstack&lt;/code&gt; tool to analyze the process’s stack information and identify the root cause.&lt;/p&gt;
&lt;h2 id=&#34;steps&#34;&gt;Steps
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;pstack&lt;/code&gt; is a commonly used tool, often provided alongside &lt;code&gt;gdb&lt;/code&gt; (GNU Debugger). You can install it using the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt-get install gdb
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Obtain Process ID: First, we need to obtain the process ID (PID) of the zombie process. We can use the &lt;code&gt;ps&lt;/code&gt; command to list all processes and find the process ID that needs to be investigated.&lt;/p&gt;
&lt;p&gt;Use the &lt;code&gt;pstack&lt;/code&gt; tool to analyze the process stack. Once you have obtained the process ID, you can use the &lt;code&gt;pstack&lt;/code&gt; tool to retrieve the stack information for that process. Run the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pstack &amp;lt;PID&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will output the stack information of the process, displaying the sequence of function calls currently being executed. By analyzing this information, you can identify where the process is stuck and thus pinpoint the problem.&lt;/p&gt;
&lt;p&gt;Analyze Stack Information: Through reviewing the stack information, you can find the cause of the zombie process.&lt;/p&gt;
&lt;h2 id=&#34;case-study&#34;&gt;Case Study
&lt;/h2&gt;&lt;p&gt;Simple demo: after the main function starts, a child thread is created and the actual function enters a dead loop, causing the program to fail to terminate normally and enter a state of false death.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cmake_minimum_required(VERSION 3.0.0)
project(pstack_main VERSION 0.1.0 LANGUAGES C CXX)

include(CTest)
enable_testing()

# Find the thread library
find_package(Threads REQUIRED)

add_executable(pstack_main main.cpp)

# Link the thread library
target_link_libraries(pstack_main PRIVATE Threads::Threads)

set(CPACK_PROJECT_NAME ${PROJECT_NAME})
set(CPACK_PROJECT_VERSION ${PROJECT_VERSION})
include(CPack)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;case-study-1&#34;&gt;Case Study
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;thread&amp;gt;
#include &amp;lt;chrono&amp;gt;

void infiniteLoop() {
    while (true) {
        // Main thread enters an infinite loop
    }
}

int main() {
    std::thread thread(infiniteLoop); // Create a thread to execute the infinite loop function
    thread.join(); // Wait for the thread to finish
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Run the program and examine the pstack output:&lt;/p&gt;
&lt;h2 id=&#34;case-studies&#34;&gt;Case Studies
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Thread 2 (Thread 0x7eff3619b700 (LWP 1315017)):
#0  infiniteLoop () at /root/pstack/main.cpp:6
#1  0x0000000000402ca9 in std::__invoke_impl&amp;lt;void, void (*)()&amp;gt; (__f=@0x2260eb8: 0x4029a6 &amp;lt;infiniteLoop()&amp;gt;) at /usr/include/c++/8/bits/invoke.h:60
#2  0x0000000000402b02 in std::__invoke&amp;lt;void (*)()&amp;gt; (__fn=@0x2260eb8: 0x4029a6 &amp;lt;infiniteLoop()&amp;gt;) at /usr/include/c++/8/bits/invoke.h:95
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;case-studies-1&#34;&gt;Case Studies
&lt;/h2&gt;&lt;p&gt;#3 0x0000000000403150 in std::thread::_Invoker&amp;lt;std::tuple&amp;lt;void (&lt;em&gt;)()&amp;gt; &amp;gt;::_M_invoke&amp;lt;0ul&amp;gt; (this=0x2260eb8) at /usr/include/c++/8/thread:244
#4 0x0000000000403126 in std::thread::_Invoker&amp;lt;std::tuple&amp;lt;void (&lt;/em&gt;)()&amp;gt; &amp;gt;::operator() (this=0x2260eb8) at /usr/include/c++/8/thread:253
#5 0x000000000040310a in std::thread::_State_impl&amp;lt;std::thread::_Invoker&amp;lt;std::tuple&amp;lt;void (*)()&amp;gt; &amp;gt; &amp;gt;::_M_run (this=0x2260eb0) at /usr/include/c++/8/thread:196&lt;/p&gt;
&lt;h2 id=&#34;case-studies-2&#34;&gt;Case Studies
&lt;/h2&gt;&lt;p&gt;#6 0x00007eff36bceb23 in execute_native_thread_routine () from /lib64/libstdc++.so.6
#7 0x00007eff36ea91ca in start_thread () from /lib64/libpthread.so.0
#8 0x00007eff361d58d3 in clone () from /lib64/libc.so.6
Thread 1 (Thread 0x7eff372e1740 (LWP 1315016)):
#0 0x00007eff36eaa6cd in __pthread_timedjoin_ex () from /lib64/libpthread.so.0
#1 0x00007eff36bceda7 in std::thread::join() () from /lib64/libstdc++.so.6
#2 0x00000000004029d2 in main () at /root/pstack/main.cpp:13&lt;/p&gt;
&lt;h2 id=&#34;case-study-2&#34;&gt;Case Study
&lt;/h2&gt;&lt;p&gt;As can be seen, the reason for the process hanging indefinitely was a deadlock situation where the main thread entered an infinite loop, preventing the child thread from exiting and ultimately causing the process to hang.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>C&#43;&#43; Function Call Latency</title>
        <link>https://ttf248.life/en/p/cpp-function-call-timing/</link>
        <pubDate>Wed, 24 Jan 2024 14:11:33 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-function-call-timing/</guid>
        <description>&lt;p&gt;Designed a行情 SDK, implementing different callback function implementations, and performed an extensive test. Recently I’ve been looking into C++ function programming, where functions have become first-class citizens, flowing within the program internally – what are the differences in performance?&lt;/p&gt;
&lt;p&gt;Previous article link: &lt;a class=&#34;link&#34; href=&#34;https://ttf248.life/en/p/compiler-callback-performance-testing/&#34; &gt;Compiler, Callback Functions, Performance Testing&lt;/a&gt;
&lt;code&gt;leimao&lt;/code&gt;大佬 also did similar tests, so I borrowed their code.&lt;/p&gt;
&lt;h2 id=&#34;main-content&#34;&gt;Main Content
&lt;/h2&gt;&lt;p&gt;The execution platform remains our old friend, &lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;content&#34;&gt;Content
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;cassert&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;functional&amp;gt;
#include &amp;lt;iostream&amp;gt;
#include &amp;lt;vector&amp;gt;

int add_one(int input) { return input + 1; }
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;body&#34;&gt;Body
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;int add_one(int input) { return input + 1; }

bool validate_vector_add_one(std::vector&amp;lt;int&amp;gt; const&amp;amp; input_vector,
                             std::vector&amp;lt;int&amp;gt; const&amp;amp; output_vector)
{
    bool is_valid{true};
    for (size_t i{0}; i &amp;lt; input_vector.size(); ++i)
    {
        if (output_vector.at(i) != input_vector.at(i) + 1)
        {
            is_valid = false;
            break;
        }
    }
    return is_valid;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Main Content
```cpp
void reset_vector(std::vector&amp;lt;int&amp;gt;&amp;amp; input_vector)
{
    for (size_t i{0}; i &amp;lt; input_vector.size(); ++i)
    {
        input_vector.at(i) = 0;
    }
}

template &amp;lt;typename T, typename Func&amp;gt;
void unitary_function_pass_by_lambda_function(T&amp;amp; output, T const&amp;amp; input,
                                              Func const func)
{
    output = func(input);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Body
template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_std_function_value(T&amp;amp; output, T const&amp;amp; input,
                                                 std::function&amp;lt;T(T)&amp;gt; const func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_std_function_reference(
    T&amp;amp; output, T const&amp;amp; input, std::function&amp;lt;T(T)&amp;gt; const&amp;amp; func)
{
    output = func(input);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;body-1&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;template &lt;typename T&gt;
void unitary_function_pass_by_function_pointer(T&amp;amp; output, T const&amp;amp; input,
T (*func)(T))
{
output = func(input);
}&lt;/p&gt;
&lt;p&gt;int main()
{
// Set floating point format std::cout with 3 decimal places.
std::cout.precision(3);&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;size_t const num_elements{10000000};
std::vector&amp;lt;int&amp;gt; input_vector(num_elements, 0);
std::vector&amp;lt;int&amp;gt; output_vector(num_elements, 0);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;h2 id=&#34;text&#34;&gt;Text
&lt;/h2&gt;&lt;p&gt;auto const lambda_function_add_one{[](int const&amp;amp; input) -&amp;gt; int
{ return input + 1; }};
std::function&amp;lt;int(int)&amp;gt; const std_function_add_one{lambda_function_add_one};&lt;/p&gt;
&lt;h2 id=&#34;body-2&#34;&gt;Body
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;std::cout &amp;lt;&amp;lt; &amp;quot;The size of a function pointer: &amp;quot; &amp;lt;&amp;lt; sizeof(&amp;amp;add_one)
              &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a std::function pointer: &amp;quot;
              &amp;lt;&amp;lt; sizeof(&amp;amp;std_function_add_one) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a std::function: &amp;quot; &amp;lt;&amp;lt; sizeof(std_function_add_one)
              &amp;lt;&amp;lt; std::endl;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;body-3&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;// Call function frequently in a vanilla way.
// The compiler knows what function to call at compile time and can optimize
// the code.
// This is the best performance we could get.
std::chrono::steady_clock::time_point const time_start_vanilla{
std::chrono::steady_clock::now()};
for (size_t i{0}; i &amp;lt; num_elements; ++i)
{
output_vector.at(i) = add_one(input_vector.at(i));
}
std::chrono::steady_clock::time_point const time_end_vanilla{&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Body
}
    std::chrono::steady_clock::time_point const time_end_vanilla{
        std::chrono::steady_clock::now()};
    auto const time_elapsed_vanilla{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(time_end_vanilla -
                                                             time_start_vanilla)
            .count()};
    float const latency_vanilla{time_elapsed_vanilla /
                                static_cast&amp;lt;float&amp;gt;(num_elements)};
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;text-1&#34;&gt;Text
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;static_cast&amp;lt;float&amp;gt;(num_elements)}; std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass Vanilla: &amp;quot; &amp;lt;&amp;lt; latency_vanilla &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl; assert(validate_vector_add_one(input_vector, output_vector)); reset_vector(output_vector);&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;body-4&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;// Sometimes, we don&amp;rsquo;t know what function to call at compile time.
// We can use std::function to pass a function as an argument.
// In this case, we pass the std::function by value.
// Because the size of a std::function is 32 bytes, passing by value
// results in a lot of copying and bad performance.
std::chrono::steady_clock::time_point const
time_start_pass_by_std_function_value{std::chrono::steady_clock::now()};
for (size_t i{0}; i &amp;lt; num_elements; ++i)&lt;/p&gt;
&lt;h2 id=&#34;body-5&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;for (size_t i{0}; i &amp;lt; num_elements; ++i)
{
unitary_function_pass_by_std_function_value(
output_vector.at(i), input_vector.at(i), std_function_add_one);
}
std::chrono::steady_clock::time_point const
time_end_pass_by_std_function_value{std::chrono::steady_clock::now()};
auto const time_elapsed_pass_by_std_function_value{
std::chrono::duration_cast&lt;a class=&#34;link&#34; href=&#34;std::chrono::nanoseconds&#34; &gt;std::chrono::nanoseconds&lt;/a&gt;(
time_end_pass_by_std_function_value -&lt;/p&gt;
&lt;h2 id=&#34;text-2&#34;&gt;Text
&lt;/h2&gt;&lt;p&gt;time_end_pass_by_std_function_value -
time_start_pass_by_std_function_value)
.count()};
float const latency_pass_by_std_function_value{
time_elapsed_pass_by_std_function_value /
static_cast&lt;float&gt;(num_elements)};
std::cout &amp;laquo; &amp;ldquo;Latency Pass By Std Function Value: &amp;quot;
&amp;laquo; latency_pass_by_std_function_value &amp;laquo; &amp;quot; ns&amp;rdquo; &amp;laquo; std::endl;
assert(validate_vector_add_one(input_vector, output_vector));
reset_vector(output_vector);&lt;/p&gt;
&lt;h2 id=&#34;body-6&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;// Instead of passing the std::function by value, we can pass it by
// reference (pointer). In this case, object copying is eliminated. The
// performance is better than passing the std::function by value. However,
// the performance is still not as good as the vanilla way.
std::chrono::steady_clock::time_point const
time_start_pass_by_std_function_reference{
std::chrono::steady_clock::now()};
for (size_t i{0}; i &amp;lt; num_elements; ++i)&lt;/p&gt;
&lt;h2 id=&#34;text-3&#34;&gt;Text
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;std::chrono::steady_clock::now();&lt;/code&gt;
for (size_t i{0}; i &amp;lt; num_elements; ++i)
{
unitary_function_pass_by_std_function_reference(
output_vector.at(i), input_vector.at(i), std_function_add_one);
}
std::chrono::steady_clock::time_point const
time_end_pass_by_std_function_reference{
std::chrono::steady_clock::now()};
auto const time_elapsed_pass_by_std_function_reference{
std::chrono::duration_cast&lt;a class=&#34;link&#34; href=&#34;std::chrono::nanoseconds&#34; &gt;std::chrono::nanoseconds&lt;/a&gt;(&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Body
std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_std_function_reference -
            time_start_pass_by_std_function_reference)
            .count()};
    float const latency_pass_by_std_function_reference{
        time_elapsed_pass_by_std_function_reference /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Std Function Reference: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_std_function_reference &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;body-7&#34;&gt;Body
&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;&amp;lt; &amp;quot;ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;body-8&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;// &lt;code&gt;std::function&lt;/code&gt; is a general-purpose wrapper for function pointers,
// callable objects, and lambda functions. Because it&amp;rsquo;s general purpose,
// it’s not as efficient as a function pointer. In this case, we pass a
// function pointer to a function. The performance is better than passing
// the &lt;code&gt;std::function&lt;/code&gt; by reference.
std::chrono::steady_clock::time_point const
time_start_pass_by_function_pointer{std::chrono::steady_clock::now()};&lt;/p&gt;
&lt;h2 id=&#34;text-4&#34;&gt;Text
&lt;/h2&gt;&lt;p&gt;time_start_pass_by_function_pointer{std::chrono::steady_clock::now()};
for (size_t i{0}; i &amp;lt; num_elements; ++i)
{
unitary_function_pass_by_function_pointer(output_vector.at(i),
input_vector.at(i), &amp;amp;add_one);
}
std::chrono::steady_clock::time_point const
time_end_pass_by_function_pointer{std::chrono::steady_clock::now()};
auto const time_elapsed_pass_by_function_pointer{&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Body
auto const time_elapsed_pass_by_function_pointer{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_function_pointer -
            time_start_pass_by_function_pointer)
            .count()};
    float const latency_pass_by_function_pointer{
        time_elapsed_pass_by_function_pointer /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Function Pointer: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_function_pointer &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;body-9&#34;&gt;Body
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;&amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; latency_pass_by_function_pointer &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;body-10&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;// We can also pass a lambda function to a function.
// The compiler knows what function to call at compile time and can optimize
// the code. The performance is also better than passing the std::function
// by reference.
std::chrono::steady_clock::time_point const
time_start_pass_by_lambda_function{std::chrono::steady_clock::now()};
for (size_t i{0}; i &amp;lt; num_elements; ++i)
{
unitary_function_pass_by_lambda_function(&lt;/p&gt;
&lt;h2 id=&#34;text-5&#34;&gt;Text
&lt;/h2&gt;&lt;p&gt;for (size_t i{0}; i &amp;lt; num_elements; ++i)
{
unitary_function_pass_by_lambda_function(
output_vector.at(i), input_vector.at(i), lambda_function_add_one);
}
std::chrono::steady_clock::time_point const
time_end_pass_by_lambda_function{std::chrono::steady_clock::now()};
auto const time_elapsed_pass_by_lambda_function{
std::chrono::duration_cast&lt;a class=&#34;link&#34; href=&#34;std::chrono::nanoseconds&#34; &gt;std::chrono::nanoseconds&lt;/a&gt;(
time_end_pass_by_lambda_function -&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Main Body
time_end_pass_by_lambda_function -
            time_start_pass_by_lambda_function)
            .count();
float const latency_pass_by_lambda_function{
        time_elapsed_pass_by_lambda_function /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Lambda Function: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_lambda_function &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
assert(validate_vector_add_one(input_vector, output_vector));
reset_vector(output_vector);
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;body-11&#34;&gt;Body
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# The default optimization for the team is to enable O2, and the compiler selected was gcc13. Performance and execution times vary slightly between different versions of gcc, with higher versions resulting in better lambda performance.
# Function pointer size: 8
# std::function pointer size: 8
# std::function size: 32
# Vanilla Pass Latency: 0.418 ns
# Latency Pass By Std Function Value: 3.47 ns
# Latency Pass By Std Function Reference: 1.36 ns
# Latency Pass By Function Pointer: 0.396 ns
# Latency Pass By Lambda Function: 0.44 ns
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leimao.github.io/blog/CPP-Function-Call-Performance/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://leimao.github.io/blog/CPP-Function-Call-Performance/&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>How to Anti-Debug</title>
        <link>https://ttf248.life/en/p/program-anti-debug/</link>
        <pubDate>Tue, 23 Jan 2024 19:46:36 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/program-anti-debug/</guid>
        <description>&lt;p&gt;Suddenly, I was feeling the urge to browse for new wallpapers, sticking with my usual black series, with some areas colored in, and the desktop needing to display icons. Other color schemes would result in blurry icons.&lt;/p&gt;
&lt;p&gt;I stared at the assembly code, trying to figure it out, but couldn&amp;rsquo;t understand it. I tried throwing it to an &lt;code&gt;AI&lt;/code&gt;, explaining the instructions, but it failed to explain the context – clearly, this was a command used for a specific scenario. Regular code isn’t like that.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;AI&lt;/code&gt; was no match for a search engine at this point; its knowledge base of assembly language was insufficient.&lt;/p&gt;
&lt;h2 id=&#34;wallpaper&#34;&gt;Wallpaper
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/program-anti-debug/Snipaste_2024-01-23_19-50-53.png&#34;
	width=&#34;1020&#34;
	height=&#34;470&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Black Assembly Wallpaper&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;217&#34;
		data-flex-basis=&#34;520px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;assembly-code&#34;&gt;Assembly Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;PUSHFD
MOV DWORD PTR [ESP],0X100
POPFD
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Actual Application Scenario&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;bool IsDebugged()
{
    __try
    {
        __asm
        {
            pushfd
            mov dword ptr [esp], 0x100
            popfd
            nop
        }
        return true;
    }
    __except(GetExceptionCode() == EXCEPTION_SINGLE_STEP
        ? EXCEPTION_EXECUTE_HANDLER
        : EXCEPTION_CONTINUE_EXECUTION)
    {
        return false;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;explanation&#34;&gt;Explanation
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;TrapFlag&lt;/code&gt; is a flag bit in the register file. When this flag is set, it throws an exception &lt;code&gt;SINGLE_STEP&lt;/code&gt;. Because when we trace the code, this flag will be cleared by the debugger, so we won&amp;rsquo;t see this exception.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In actual testing, if you directly step over detecting functions, debugging will not be detected. Only when entering the detection function to execute will it be detected (based on research materials, yet to be verified in practice).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;Chinese related materials are based on the English articles from the website, which introduce many anti-debugging techniques.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://anti-debug.checkpoint.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://anti-debug.checkpoint.com/&lt;/a&gt; techniques/assembly.html&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://song-10.gitee.io/2021/08/08/Reverse-2021-08-08-anti-debug/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://song-10.gitee.io/2021/08/08/Reverse-2021-08-08-anti-debug/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>How to Download Focus News/CCTV Video Files</title>
        <link>https://ttf248.life/en/p/how-to-download-focus-interview-cctv-videos/</link>
        <pubDate>Tue, 23 Jan 2024 19:23:35 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/how-to-download-focus-interview-cctv-videos/</guid>
        <description>&lt;p&gt;Recently, someone asked how to download Focus Interview videos. My mind immediately went to the usual – eight or nine out of ten times it’s encrypted using an &lt;code&gt;m3u8&lt;/code&gt; method, and a bit of simple processing is all it takes.&lt;/p&gt;
&lt;h2 id=&#34;downloader&#34;&gt;Downloader
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/nilaoda/N_m3u8DL-CLI&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/nilaoda/N_m3u8DL-CLI&lt;/a&gt;
&lt;code&gt;m3u8 downloader&lt;/code&gt; is an open-source command-line m3u8/HLS/dash downloader that supports ordinary AES-128-CBC decryption, multi-threading, custom request headers, etc. Supports Simplified Chinese, Traditional Chinese and English. English Supported.&lt;/p&gt;
&lt;h2 id=&#34;browser-extensions&#34;&gt;Browser Extensions
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://microsoftedge.microsoft.com/addons/detail/ngjclnbcdbahekojpkhancmiobdahemb&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Live Stream Downloader&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;honeyed-confidence&#34;&gt;Honeyed Confidence
&lt;/h2&gt;&lt;p&gt;Getting the address, assuming it was solved, turned out to be nothing – unable to parse segments normally, query information, and discover that the official had processed the download address, requiring manual replacement of the &lt;code&gt;key&lt;/code&gt; parsed by the plugin into the links below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;https://newcntv.qcloudcdn.com/asp/hls/2000/0303000a/3/default/***********************/2000.m3u8
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As of January 2024, the address is still valid; if there are any changes in the future, analyze the webpage independently.
Historical Address Backup: &lt;code&gt;https://hlswx.cntv.kcdnvip.com/asp/hls/main/0303000a/3/default/一串字符/main.m3u8?maxbr=2000&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://jln.cn/post/517.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://jln.cn/post/517.html&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Bulk Modify SQL Server Database Disk File Permissions</title>
        <link>https://ttf248.life/en/p/bulk-modify-sqlserver-database-disk-permissions/</link>
        <pubDate>Tue, 23 Jan 2024 19:06:36 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/bulk-modify-sqlserver-database-disk-permissions/</guid>
        <description>&lt;p&gt;The company adjusted its security policies. Ultimately, ‘Mechanical Mini’ was relocated back home as a backup server, along with a full system reinstallation. Ubuntu switched to Windows Server; due to an irregular activation method – used in their own home environment – it seemed like it wouldn&amp;rsquo;t be activated, and that was fine. An unconventional activation triggered Microsoft’s detection (running normally for half a month), the server would automatically shut down after one hour of operation. After reviewing the system logs, it was discovered that this was due to using a pirated version.&lt;/p&gt;
&lt;p&gt;There wasn’t much they could do, so they reinstalled the system again, and SQL Server also needed to be reinstalled. It&amp;rsquo;s always quite frustrating dealing with these issues – strict file permission controls prevented them from successfully attaching the database.&lt;/p&gt;
&lt;h2 id=&#34;error-message&#34;&gt;Error Message
&lt;/h2&gt;&lt;p&gt;After the system reinstallation, &lt;code&gt;SqlServer&lt;/code&gt; may encounter error 5120, an operating system access denied error, when attaching a database.&lt;/p&gt;
&lt;h2 id=&#34;processing-script&#34;&gt;Processing Script
&lt;/h2&gt;&lt;p&gt;Previous link: &lt;a class=&#34;link&#34; href=&#34;https://ttf248.life/en/p/bulk-update-local-git-and-legacy-permissions/&#34; &gt;Batch Update Local Git Repository&lt;/a&gt;, it’s that familiar script all over again – let&amp;rsquo;s modify it to iterate through folders while also changing file permissions, currently using full editing privileges.
Most online tutorials instruct you to manually modify files; they only need to change a few files each time? I have batches of files to process, and manually handling them would drive me crazy.&lt;/p&gt;
&lt;h2 id=&#34;script-to-process&#34;&gt;Script to Process
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$currentUserName = [System.Security.Principal.WindowsIdentity]::GetCurrent().Name
[Console]::OutputEncoding = [System.Text.Encoding]::UTF8
$rootDirectory = &amp;quot;D:\data\2013_RujiaInfo&amp;quot;

Get-ChildItem -Path $rootDirectory -Recurse | ForEach-Object {
    $itemPath = $_.FullName
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;script-to-handle&#34;&gt;Script to Handle
&lt;/h2&gt;&lt;p&gt;if ($_ -is [System.IO.DirectoryInfo]) {
$icaclsResult = icacls $itemPath /setowner &amp;ldquo;$currentUserName&amp;rdquo; 2&amp;gt;&amp;amp;1
if ($LASTEXITCODE -eq 0) {
Write-Host &amp;ldquo;Successfully changed the owner of folder $itemPath to $currentUserName&amp;rdquo;
# Grant current user write permissions
Invoke-Expression &amp;ldquo;icacls &lt;code&gt;&amp;quot;$itemPath&lt;/code&gt;&amp;rdquo; /grant &lt;code&gt;&amp;quot;$($currentUserName):(OI)(CI)F&lt;/code&gt;&amp;quot;&amp;quot;
Write-Host &amp;ldquo;Granted $currentUserName edit permissions for the folder&amp;rdquo;
} else {
Write-Host &amp;ldquo;Failed to change the owner of folder $itemPath. Error message: $icaclsResult&amp;rdquo;
}
} else {&lt;/p&gt;
&lt;h2 id=&#34;processing-script-1&#34;&gt;Processing Script
&lt;/h2&gt;&lt;p&gt;Write-Host &amp;ldquo;Unable to change the owner of folder &amp;lsquo;$itemPath&amp;rsquo;. Error message: &amp;lsquo;$icaclsResult&amp;rsquo;&amp;rdquo;
}
} else {
$takeownResult = icacls $itemPath /setowner &amp;ldquo;$currentUserName&amp;rdquo; 2&amp;gt;&amp;amp;1
if ($LASTEXITCODE -eq 0) {
# Grant current user write permissions
Invoke-Expression &amp;ldquo;icacls &lt;code&gt;&amp;quot;$itemPath&lt;/code&gt;&amp;rdquo; /grant &lt;code&gt;&amp;quot;$($currentUserName):(F)&lt;/code&gt;&amp;quot;&amp;quot;
Write-Host &amp;ldquo;Granted $currentUserName edit file permissions&amp;rdquo;
} else {
Write-Host &amp;ldquo;Unable to change the owner of file &amp;lsquo;$itemPath&amp;rsquo;. Error message: &amp;lsquo;$takeownResult&amp;rsquo;&amp;rdquo;
}
}
}&lt;/p&gt;
&lt;h2 id=&#34;processing-script-2&#34;&gt;Processing Script
&lt;/h2&gt;</description>
        </item>
        <item>
        <title>Linux System Benchmark Test</title>
        <link>https://ttf248.life/en/p/linux-system-benchmark-test/</link>
        <pubDate>Tue, 09 Jan 2024 10:56:23 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-system-benchmark-test/</guid>
        <description>&lt;p&gt;Windows platform has RuMaster (Entertainment Master), which isn’t known for highly accurate data, but it still provides some reference. Of course, there are other professional benchmarking software as well. When it comes to Linux systems, there haven&amp;rsquo;t seemed to be particularly suitable benchmarking software encountered.&lt;/p&gt;
&lt;p&gt;Sysbench is a versatile benchmark testing tool that can be used to test CPU, memory, file I/O, thread performance, and more. You can use Sysbench to execute various performance testing tasks.&lt;/p&gt;
&lt;p&gt;I just happen to have three machines available for testing: the Mechanical Artist mini laptop, a small local host, an Alibaba Cloud Dev development cloud server, and a Huawei Cloud Dev server.&lt;/p&gt;
&lt;h2 id=&#34;installing-sysbench&#34;&gt;Installing Sysbench
&lt;/h2&gt;&lt;p&gt;On most Linux distributions, you can use the package manager to install Sysbench. For example, on CentOS 8, you can use the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo dnf install sysbench
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;sysbench-usage-examples&#34;&gt;Sysbench Usage Examples
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Testing CPU performance: &lt;code&gt;sysbench --test=cpu run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Testing memory read performance: &lt;code&gt;sysbench --test=memory run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Testing file I/O performance:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sysbench --test=fileio --file-test-mode=rndrw prepare
sysbench --test=fileio --file-test-mode=rndrw run
sysbench --test=fileio --file-test-mode=rndrw cleanup
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Testing multi-threaded performance: &lt;code&gt;sysbench --test=threads --num-threads=4 run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Testing MySQL database performance (adjust maximum connection number):&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sysbench-usage-examples-1&#34;&gt;Sysbench Usage Examples
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword --oltp-table-size=1000000 prepare
sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword --max-time=60 --oltp-read-only=off --oltp-test-mode=complex --max-requests=0 run
sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword cleanup
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;score-report&#34;&gt;Score Report
&lt;/h2&gt;&lt;meta http-equiv=&#34;Content-Type&#34; content=&#34;text/html; charset=utf-8&#34;&gt;&lt;link type=&#34;text/css&#34; rel=&#34;stylesheet&#34; href=&#34;resources/sheet.css&#34; &gt;
&lt;h2 id=&#34;score-report-1&#34;&gt;Score Report
&lt;/h2&gt;&lt;style type=&#34;text/css&#34;&gt;.ritz .waffle a { color: inherit; }.ritz .waffle .s0{background-color:#ffffff;text-align:left;color:#000000;font-family:&#39;Arial&#39;;font-size:10pt;vertical-align:bottom;white-space:nowrap;direction:ltr;padding:2px 3px 2px 3px;}&lt;/style&gt;&lt;div class=&#34;ritz grid-container&#34; dir=&#34;ltr&#34;&gt;&lt;table class=&#34;waffle&#34; cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th class=&#34;row-header freezebar-origin-ltr&#34;&gt;&lt;/th&gt;&lt;th id=&#34;0C0&#34; style=&#34;width:100px;&#34; class=&#34;column-headers-background&#34;&gt;A&lt;/th&gt;&lt;th id=&#34;0C1&#34;
&lt;h2 id=&#34;score-report-2&#34;&gt;Score Report
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Column A (id=&amp;ldquo;0C0&amp;rdquo; style=&amp;ldquo;width:100px;&amp;rdquo; class=&amp;ldquo;column-headers-background&amp;rdquo;)&lt;/th&gt;
&lt;th&gt;Column B (id=&amp;ldquo;0C1&amp;rdquo; style=&amp;ldquo;width:421px;&amp;rdquo; class=&amp;ldquo;column-headers-background&amp;rdquo;)&lt;/th&gt;
&lt;th&gt;Column C (id=&amp;ldquo;0C2&amp;rdquo; style=&amp;ldquo;width:398px;&amp;rdquo; class=&amp;ldquo;column-headers-background&amp;rdquo;)&lt;/th&gt;
&lt;th&gt;Column D (id=&amp;ldquo;0C3&amp;rdquo; style=&amp;ldquo;width:422px;&amp;rdquo; class=&amp;ldquo;column-headers-background&amp;rdquo;)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Row 1 &lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;1&lt;/div&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;score-report-3&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;class=&amp;ldquo;row-header-wrapper&amp;rdquo; style=&amp;ldquo;line-height: 20px&amp;rdquo;&amp;gt;1&lt;/div&gt;&lt;/th&gt;&lt;td&gt;&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Local Technician&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;阿里云 (Alibaba Cloud)&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;华为云 (Huawei Cloud)&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R1&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;2&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Configuration&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Information&lt;br&gt;  Operating System              Ubuntu 23.04&lt;br&gt;  Kernel                        Linux&lt;/p&gt;
&lt;h2 id=&#34;score-report-4&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;Information
Operating System              Ubuntu 23.04
Kernel                        Linux 6.2.0-36-generic x86_64
Model                         Machenike Machenike DT Computer
Motherboard                   Machenike Machenike DT Computer
BIOS                          American Megatrends International, LLC.
DB19V012&lt;/p&gt;
&lt;p&gt;CPU Information
Name                          Intel Core i7-12650H
Topology                      1 Processor, 10 Cores, 16 Threads
Identifier&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;i7-12650H
Topology: 1 Processor, 10 Cores, 16 Threads
Identifier: GenuineIntel Family 6 Model 154 Stepping 3
Base Frequency: 4.60 GHz
L1 Instruction Cache: 32.0 KB x 8
L1 Data Cache: 48.0 KB x 8
L2 Cache: 1.25 MB x 2
L3 Cache: 24.0 MB&lt;/p&gt;
&lt;p&gt;Memory Information:
Size: 62.6 GB&lt;/p&gt;
&lt;h2 id=&#34;score-report-5&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;Size                          62.6 GB&lt;/p&gt;
&lt;p&gt;System Information
Operating System              CentOS Stream 8
Kernel                        Linux 4.18.0-513.el8.x86_64 x86_64
Model                         Alibaba Cloud Alibaba Cloud ECS
Motherboard                   N/A
BIOS                          SeaBIOS 449e491&lt;/p&gt;
&lt;p&gt;CPU Information
Name                          Intel(R) Xeon(R) Platinum
Topology                      1 Processor, 1 Core, 2&amp;hellip;&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-1&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;Intel(R) Xeon(R) Platinum
Topology: 1 Processor, 1 Core, 2 Threads
Identifier: GenuineIntel Family 6 Model 85 Stepping 4
Base Frequency: 2.50 GHz
L1 Instruction Cache: 32.0 KB
L1 Data Cache: 32.0 KB
L2 Cache: 1.00 MB
L3 Cache: 33.0 MB&lt;/p&gt;
&lt;p&gt;Memory Information:
Size: 1.65 GB&lt;/p&gt;
&lt;h2 id=&#34;score-report-data&#34;&gt;Score Report Data
&lt;/h2&gt;&lt;p&gt;Information
Size 1.65 GB&lt;/p&gt;
&lt;p&gt;System Information
Operating System Ubuntu 22.04.1 LTS
Kernel Linux 5.15.0-60-generic x86_64
Model OpenStack Foundation OpenStack Nova
Motherboard N/A
BIOS SeaBIOS
rel-1.10.2-0-g5f4c7b1-20181220_000000-szxrtosci10000&lt;/p&gt;
&lt;p&gt;CPU Information
Name Intel(R) Xeon(R) Gold&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-2&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;Information:
Name                          Intel(R) Xeon(R) Gold 6278C CPU @ 2.60GHz
Topology                      1 Processor, 1 Core, 2 Threads
Identifier                    GenuineIntel Family 6 Model 85 Stepping 7
Base Frequency                2.60 GHz
L1 Instruction Cache          32.0 KB
L1 Data Cache                 32.0 KB
L2 Cache                      1.00 MB
L3 Cache                      35.8 MB&lt;/p&gt;
&lt;p&gt;Memory Information:
Size&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-3&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;L3 Cache                      35.8 MB&lt;br&gt;&lt;br&gt;Memory Information&lt;br&gt;  Size                          3.64 GB&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R2&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;3&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;CPU&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current&lt;/p&gt;
&lt;h2 id=&#34;score-report-6&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;with following options:
Number of threads: 1
Initializing random number generator from current time&lt;/p&gt;
&lt;p&gt;Prime numbers limit: 10000&lt;/p&gt;
&lt;p&gt;Initializing worker threads&amp;hellip;
Threads started!&lt;/p&gt;
&lt;p&gt;CPU speed:
events per second:  4032.48&lt;/p&gt;
&lt;p&gt;General statistics:
total time:                          10.0004s
total number of events:              40330&lt;/p&gt;
&lt;p&gt;Latency (ms):
min:                                    0.25
avg:&lt;/p&gt;
&lt;h2 id=&#34;score-report-7&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;min:                                    0.25&lt;br&gt;         avg:                                    0.25&lt;br&gt;         max:                                    0.73&lt;br&gt;         95th percentile:                        0.25&lt;br&gt;         sum:                                 9997.55&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           40330.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9975/0.00&lt;/p&gt;
&lt;p&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-4&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;class=&amp;ldquo;s0&amp;rdquo; dir=&amp;ldquo;ltr&amp;rdquo;&amp;gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  1062.51&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0008s&lt;br&gt;    total number of events:              10628&lt;br&gt;&lt;br&gt;Latency (ms):&lt;/p&gt;
&lt;h2 id=&#34;score-report-8&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;10.0008s &lt;br&gt;
total number of events: 10628 &lt;br&gt;&lt;br&gt;
Latency (ms):&lt;br&gt;
min: 0.91 &lt;br&gt;
avg: 0.94 &lt;br&gt;
max: 22.84 &lt;br&gt;
95th percentile: 1.06 &lt;br&gt;
sum: 9993.46 &lt;br&gt;&lt;br&gt;
Threads fairness:&lt;br&gt;
events (avg/stddev): 10628.0000/0.00 &lt;br&gt;
execution time (avg/stddev):&lt;/p&gt;
&lt;h2 id=&#34;score-report-9&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;events (avg/stddev):           10628.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9935/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  1125.56&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:&lt;/p&gt;
&lt;h2 id=&#34;score-report-10&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;speed:
events per second: 1125.56&lt;/p&gt;
&lt;p&gt;General statistics:
total time: 10.0005s
total number of events: 11258&lt;/p&gt;
&lt;p&gt;Latency (ms):
min: 0.86
avg: 0.89
max: 1.70
95th percentile: 0.99
sum: 9995.40&lt;/p&gt;
&lt;p&gt;Threads fairness:&lt;/p&gt;
&lt;h2 id=&#34;score-report-11&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;0.99 &lt;br&gt;         sum:                                 9995.40 &lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           11258.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9954/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R3&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;4&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Memory&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random&lt;/p&gt;
&lt;h2 id=&#34;run-test-report&#34;&gt;Run Test Report
&lt;/h2&gt;&lt;p&gt;dir=&amp;ldquo;ltr&amp;rdquo;&amp;gt;Running the test with the following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 101993199 (10198146.52 per second)&lt;br&gt;&lt;br&gt;99602.73 MiB transferred (9959.13 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:&lt;/p&gt;
&lt;h2 id=&#34;score-report-12&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;MiB transferred (9959.13 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              101993199&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                    0.03&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4059.50&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;score-report-13&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;0.00
sum:                                 4059.50
Threads fairness:&lt;br&gt;    events (avg/stddev):           101993199.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.0595/0.00&lt;/p&gt;
&lt;p&gt;Running the test with following options:
Number of threads: 1
Initializing random number generator from current time&lt;/p&gt;
&lt;p&gt;Running memory speed test with the following options:
block size: 1KiB
total size: 102400MiB
operation: write
scope:&lt;/p&gt;
&lt;h2 id=&#34;score-report-14&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 48418803 (4841.00 per second)&lt;br&gt;&lt;br&gt;47283.99 MiB transferred (4727.54 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              48418803&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:&lt;/p&gt;
&lt;h2 id=&#34;score-report-15&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;(ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                   25.26&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4578.95&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           48418803.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.5789/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of&lt;/p&gt;
&lt;h2 id=&#34;score-report-16&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;4.5789/0.00 &lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with the following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 57056904 (5704765.11 per second)&lt;br&gt;&lt;br&gt;55719.63 MiB transferred (5571.06 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General&lt;/p&gt;
&lt;h2 id=&#34;scoring-data-report&#34;&gt;Scoring Data Report
&lt;/h2&gt;&lt;p&gt;(5704765.11 per second)&lt;/p&gt;
&lt;p&gt;55719.63 MiB transferred (5571.06 MiB/sec)&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;General statistics:
total time:                          10.0001s
total number of events:              57056904&lt;/p&gt;
&lt;p&gt;Latency (ms):
min:                                    0.00
avg:                                    0.00
max:                                    0.06
95th percentile:                        0.00
sum:&lt;/p&gt;
&lt;h2 id=&#34;score-report-17&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;95th percentile:                        0.00&lt;br&gt;         sum:                                 4556.06&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           57056904.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.5561/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R4&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;5&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Disk&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 1.81 seconds&lt;/p&gt;
&lt;h2 id=&#34;score-report-18&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;class=&amp;ldquo;s0&amp;rdquo; dir=&amp;ldquo;ltr&amp;rdquo;&amp;gt;Hard Drive&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 1.81 seconds (1129.59 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with the following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-5&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      3373.41&lt;br&gt;    writes/s:                     2248.94&lt;br&gt;    fsyncs/s:                     7201.80&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  52.71&lt;br&gt;    written, MiB/s:&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-6&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;read, MiB/s:                  52.71&lt;br&gt;    written, MiB/s:               35.14&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0127s&lt;br&gt;    total number of events:              128288&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.08&lt;br&gt;         max:                                    5.14&lt;br&gt;         95th percentile:                        0.34&lt;br&gt;         sum:&lt;/p&gt;
&lt;h2 id=&#34;score-report-19&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;95th percentile: 0.34&lt;br&gt;         sum: 9977.78&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev): 128288.0000/0.00&lt;br&gt;    execution time (avg/stddev): 9.9778/0.00&lt;br&gt;&lt;br&gt;2147483648 bytes written in 19.29 seconds (106.16 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files,&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-7&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;Random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:&lt;/p&gt;
&lt;h2 id=&#34;score-report-20&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      1593.12&lt;br&gt;    writes/s:                     1062.08&lt;br&gt;    fsyncs/s:                     3406.64&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  24.89&lt;br&gt;    written, MiB/s:               16.60&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0164s&lt;br&gt;    total number of events:              60600&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:&lt;/p&gt;
&lt;h2 id=&#34;score-report-21&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;events: 60600&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min: 0.00&lt;br&gt;         avg: 0.16&lt;br&gt;         max: 31.32&lt;br&gt;         95th percentile: 0.54&lt;br&gt;         sum: 9956.30&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev): 60600.0000/0.00&lt;br&gt;    execution time (avg/stddev): 9.9563/0.00
bytes: 2147483648&lt;/p&gt;
&lt;h2 id=&#34;score-report-22&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;execution time (avg/stddev):   9.9563/0.00&lt;/p&gt;
&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 18.29 seconds (111.98 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100
&lt;h2 id=&#34;benchmark-data-report-8&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;Ratio for combined random IO test: 1.50 &lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      1665.88&lt;br&gt;    writes/s:                     1110.59&lt;br&gt;    fsyncs/s:                     3563.77&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  26.03&lt;br&gt;    written, MiB/s:&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-9&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;3563.77&lt;/p&gt;
&lt;p&gt;Throughput:
read, MiB/s:                  26.03
written, MiB/s:               17.35&lt;/p&gt;
&lt;p&gt;General statistics:
total time:                          10.0112s
total number of events:              63355&lt;/p&gt;
&lt;p&gt;Latency (ms):
min:                                    0.00
avg:                                    0.16
max:                                  205.01
95th percentile:                        0.78&lt;/p&gt;
&lt;h2 id=&#34;score-report-23&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;205.01&lt;br&gt;         95th percentile:                        0.78&lt;br&gt;         sum:                                 9972.64&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           63355.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9726/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R5&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;6&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Multi-threaded&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running&lt;/p&gt;
&lt;h2 id=&#34;score-report-24&#34;&gt;Score Report
&lt;/h2&gt;&lt;div style=&#34;width: 6vw&#34;&gt;6&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Multi-Thread&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with the following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0002s&lt;br&gt;    total number of events:              197956&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.16&lt;br&gt;         avg:
&lt;h2 id=&#34;score-report-25&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;(ms):&lt;br&gt;         min:                                    0.16&lt;br&gt;         avg:                                    0.20&lt;br&gt;         max:                                    0.34&lt;br&gt;         95th percentile:                        0.21&lt;br&gt;         sum:                                39970.47&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           49489.0000/5.70&lt;br&gt;    execution time (avg/stddev):   9.9926/0.00&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads:&lt;/p&gt;
&lt;h2 id=&#34;score-report-26&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;class=&amp;ldquo;s0&amp;rdquo; dir=&amp;ldquo;ltr&amp;rdquo;&amp;gt;Running the test with the following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0174s&lt;br&gt;    total number of events:              18360&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.57&lt;br&gt;         avg:                                    2.18&lt;br&gt;         max:&lt;/p&gt;
&lt;h2 id=&#34;score-report-27&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;0.57&lt;br&gt;         avg:                                    2.18&lt;br&gt;         max:                                   32.77&lt;br&gt;         95th percentile:                        2.61&lt;br&gt;         sum:                                40050.41&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           4590.0000/94.36&lt;br&gt;    execution time (avg/stddev):   10.0126/0.00&lt;/p&gt;
&lt;p&gt;Running the test with following options:
Number of threads: 4
Initializing random number generator from&lt;/p&gt;
&lt;h2 id=&#34;score-report-28&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;Test with the following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0004s&lt;br&gt;    total number of events:              28536&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.23&lt;br&gt;         avg:                                    1.40&lt;br&gt;         max:                                    3.56&lt;/p&gt;
&lt;h2 id=&#34;score-report-29&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;1.40 &lt;br&gt; max: 3.56 &lt;br&gt; 95th percentile: 1.47 &lt;br&gt; sum: 39975.16 &lt;br&gt;&lt;br&gt; Threads fairness:&lt;br&gt; events (avg/stddev): 7134.0000/39.87 &lt;br&gt; execution time (avg/stddev): 9.9938/0.01&lt;/p&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;Whether &lt;code&gt;ChatGPT&lt;/code&gt; is a good thing or not, the table above couldn’t be arranged according to previously mastered &lt;code&gt;Markdown&lt;/code&gt;, and failing to create a table would result in a poor display effect. Customizing the theme limited the maximum width of the page, so I adjusted the configuration of the pages accordingly, changing the width to percentage limits.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A simple method is to use tools like TablesGenerator to generate HTML tables (content complexity doesn’t suit this).&lt;/li&gt;
&lt;li&gt;Or you can write it in Google Docs and then download and save it as an HTML document, directly copy it into a blog (simple and direct, which was ultimately adopted).
Ensure that the config is enabled with unsafe configuration items, and give the page configuration width separately. In Hugo, you can set the width of a page individually. This can be achieved by adding custom parameters in the page’s Front Matter. Here&amp;rsquo;s an example: - In your Markdown page&amp;rsquo;s Front Matter section (typically at the beginning of the file), add a custom parameter, such as &lt;code&gt;custom_width&lt;/code&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;---
title: &amp;quot;My Page&amp;quot;
date: 2024-01-09
custom_width: &amp;quot;800px&amp;quot;  # Set width to 800 pixels
---

Content...
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;epilogue-1&#34;&gt;Epilogue
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;In your Hugo theme, find or create the corresponding single page template file (e.g., &lt;code&gt;layouts/_default/single.html&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Within the single page template, check if there is a &lt;code&gt;custom_width&lt;/code&gt; parameter in the page&amp;rsquo;s Front Matter and apply it to the relevant HTML elements, such as &lt;code&gt;div&lt;/code&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;{{ define &amp;quot;main&amp;quot; }}
  &amp;lt;div style=&amp;quot;max-width: {{ with .Params.custom_width }}{{ . }}{{ else }}100%{{ end }}; margin: 0 auto;&amp;quot;&amp;gt;
    {{ .Content }}
  &amp;lt;/div&amp;gt;
{{ end }}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, we&amp;rsquo;ve used inline styles (&lt;code&gt;style&lt;/code&gt; attribute) to set the &lt;code&gt;max-width&lt;/code&gt; property on the &lt;code&gt;div&lt;/code&gt; element, making it default to 100% when no &lt;code&gt;custom_width&lt;/code&gt; parameter is specified. &lt;code&gt;margin: 0 auto;&lt;/code&gt; is used to center the &lt;code&gt;div&lt;/code&gt; element.&lt;/p&gt;
&lt;h2 id=&#34;postscript&#34;&gt;Postscript
&lt;/h2&gt;&lt;p&gt;Please note that in actual applications, you may need to adjust the examples above based on your theme structure and CSS styling details. Ensure that when adjusting styles, you maintain consistency and readability of the theme.
Due to slight differences in the enabled theme, the site’s custom &lt;code&gt;CSS&lt;/code&gt; configuration was finally adjusted.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Git Disable HTTP Repository</title>
        <link>https://ttf248.life/en/p/git-disable-http-repositories/</link>
        <pubDate>Mon, 08 Jan 2024 21:22:04 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/git-disable-http-repositories/</guid>
        <description>&lt;p&gt;Updated habit software version, unsure which Git version to start from, prohibiting fetching code from &lt;code&gt;Http&lt;/code&gt; repositories.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;fatal: Unencrypted HTTP is not supported for GitLab. Ensure the repository remote URL is using HTTPS
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;background-introduction&#34;&gt;Background Introduction
&lt;/h2&gt;&lt;p&gt;Environment: Windows platform, I’ve always used Tiny Turtle to operate Git, and key configuration was also handled through it. I previously created a script to batch update local repositories.
Previous article link: &lt;a class=&#34;link&#34; href=&#34;https://ttf248.life/en/p/bulk-update-local-git-and-legacy-permissions/&#34; &gt;Batch Update Local Git Repository&lt;/a&gt;
Today when I went home to execute the code update, the previous error occurred, and the repository could no longer be updated normally. I was planning to use &lt;code&gt;Git&lt;/code&gt;’s configuration to continue using the &lt;code&gt;http&lt;/code&gt; protocol to update the repository, but I searched everywhere without finding the corresponding configuration item.
The simplest solution is of course to switch to the &lt;code&gt;ssh&lt;/code&gt; protocol to update the repository, as the &lt;code&gt;gitlab&lt;/code&gt; configured by the company will not provide the &lt;code&gt;https&lt;/code&gt; protocol in the short term.&lt;/p&gt;
&lt;h2 id=&#34;legacy-issues&#34;&gt;Legacy Issues
&lt;/h2&gt;&lt;p&gt;When writing the batch update local repository script previously, we originally intended to use &lt;code&gt;ssh&lt;/code&gt; to pull the repository and didn&amp;rsquo;t investigate thoroughly. The &lt;code&gt;git&lt;/code&gt; configuration information configured via TortoiseGit was not synchronized to the config file, resulting in a &amp;ldquo;permission denied&amp;rdquo; error when executing with the command line:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git pull # prompts that permission is denied and cannot update the repository normally
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Checking the key configuration using commands was correct: &lt;code&gt;ssh -T git@gitlab.yintech.net&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If you can successfully pull code with Git TortoiseGit, but receive a &amp;ldquo;key incorrect&amp;rdquo; error when using the &lt;code&gt;git pull&lt;/code&gt; command in the terminal, this may be because Git TortoiseGit is using PuTTY&amp;rsquo;s SSH key, while the terminal uses OpenSSH&amp;rsquo;s SSH key.
The keys configured in TortoiseGit do not come from the system . Here&amp;rsquo;s the English translation of the provided text:&lt;/p&gt;
&lt;p&gt;“When reading SSH folder key files, instead of configuring the path to the key file through the interface repository configuration, a useful tip is to pull the first repository with its configured key, allowing subsequent repositories to reuse that same key. After PuTTY loads the key, it doesn’t immediately exit; instead, it starts a proxy service.”&lt;/p&gt;
&lt;h2 id=&#34;legacy-issues-1&#34;&gt;Legacy Issues
&lt;/h2&gt;&lt;p&gt;By adjusting the global configuration and not using the system default &lt;code&gt;ssh&lt;/code&gt; configuration, this setup will have Git Bash use TortoisePlink for SSH operations. This configuration is suitable for situations where you are using PuTTY tools provided by TortoiseGit.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git config --global core.sshCommand &amp;quot;&#39;C:/Program Files/TortoiseGit/bin/TortoisePlink.exe&#39; -batch -ssh&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please modify the executable file path above to match your specific TortoiseGit installation location.  No need to add this path to the system environment variables due to the complete path configuration.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>AI Programming and Task Decomposition</title>
        <link>https://ttf248.life/en/p/ai-programming-and-task-decomposition/</link>
        <pubDate>Fri, 22 Dec 2023 08:44:26 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/ai-programming-and-task-decomposition/</guid>
        <description>&lt;p&gt;Two years ago, I added a copy function to the site, which took me half a day of tinkering. Ultimately, the rendering effect wasn&amp;rsquo;t quite satisfactory, and as a somewhat mediocre frontend developer, I didn’t plan on improving it – if it worked, it was good enough. This year, I used &lt;code&gt;AI&lt;/code&gt; to develop a mini-program, which has made me more familiar with frontend development. I refactored it (the &lt;code&gt;AI&lt;/code&gt; redesigned it).&lt;/p&gt;
&lt;p&gt;Insight: Breaking down tasks really helps; many small tasks are quite natural for the &lt;code&gt;AI&lt;/code&gt; to develop. For the closed mini-program, 75% of the code was provided by &lt;code&gt;AI&lt;/code&gt;, and multiple tasks were broken down and delivered, with manual assembly of project code.&lt;/p&gt;
&lt;h2 id=&#34;previous-context&#34;&gt;Previous Context
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://ttf248.github.io/post/2022/001/%E4%BB%A5%E4%B8%BA%E5%BE%88%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%8B%E6%83%85%E5%A2%9E%E5%8A%A0%E4%B8%80%E4%B8%AA%E4%BB%A3%E7%A0%81%E5%A4%8D%E5%88%B6%E6%8C%89%E9%92%AE/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Making simple things easier: Adding a code copy button&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;content&#34;&gt;Content
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;promot&lt;/strong&gt;: Design CSS and JavaScript code to locate webpage elements with the class &amp;ldquo;highlight&amp;rdquo;, and within that element&amp;rsquo;s container, add a copy button to enable copying the content. The first draft of the code was immediately problematic; generate a revised version that is essentially usable, but the copied content was incorrect, containing redundant text; further guidance led to optimizing the core color design, including which effects to incorporate.&lt;/p&gt;
&lt;p&gt;Having learned your specific requirements for button size and color, we can redesign the button styles to accommodate these demands.  Below is an adjusted CSS style sheet incorporating your provided color scheme and optimized for the button&amp;rsquo;s dimensions:&lt;/p&gt;
&lt;h2 id=&#34;content-1&#34;&gt;Content
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.copy-btn {
  position: absolute;
  top: 2px; /* Adjust position */
  right: 2px;
  padding: 3px 6px; /* Reduce size */
  font-size: 12px; /* Decrease font size */
  background-color: #8FD1E1; /* Button background color */
  color: #272822; /* Text color */
  border: 1px solid #272822; /* Border color */
  border-radius: 3px; /* Rounded corners */
  cursor: pointer;
  opacity: 0.7; /* Default semi-transparent */
  transition: opacity 0.3s ease, background-color 0.3s ease; /* Smooth transition effect */
}

.copy-btn:hover {
  opacity: 1; /* Unhide on hover */
  background-color: #A3D4E5; /* Background color on hover */
}

.highlight {
  position: relative;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;content-2&#34;&gt;Content
&lt;/h2&gt;&lt;p&gt;In this style, I’ve reduced the size and font size of the buttons to make them more refined. Additionally, the buttons have a semi-transparent default state that becomes opaque and has a slightly brighter background color when you hover over them, providing visual feedback. This design meets your color requirements while maintaining modern and user-friendly characteristics.&lt;/p&gt;
&lt;p&gt;I’ve also provided a simpler &lt;code&gt;JavaScript&lt;/code&gt; implementation:&lt;/p&gt;
&lt;h2 id=&#34;content-3&#34;&gt;Content
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;document.addEventListener(&#39;DOMContentLoaded&#39;, function() {
  // Find all elements with the class &#39;highlight&#39;
  const highlights = document.querySelectorAll(&#39;.highlight&#39;);

  highlights.forEach(function(highlight) {
    // Create a copy button
    const copyBtn = document.createElement(&#39;button&#39;);
    copyBtn.textContent = &#39;Copy&#39;;
    copyBtn.classList.add(&#39;copy-btn&#39;);

    // Append the button to each .highlight element
    highlight.appendChild(copyBtn);
  });
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;content-4&#34;&gt;Content
&lt;/h2&gt;&lt;p&gt;// Add the button to each element with the class &amp;ldquo;highlight&amp;rdquo;
highlight.appendChild(copyBtn);&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Add click event listener
copyBtn.addEventListener(&#39;click&#39;, function() {
  // Assuming the first &amp;lt;code&amp;gt; element under &amp;quot;.highlight&amp;quot; contains the code to copy
  const code = highlight.querySelector(&#39;code&#39;) ? highlight.querySelector(&#39;code&#39;).textContent : &#39;&#39;;
});
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Content

navigator.clipboard.writeText(code).then(() =&amp;gt; {
    // Display copy success message
    copyBtn.textContent = &#39;Copied!&#39;;
    setTimeout(() =&amp;gt; {
      copyBtn.textContent = &#39;Copy&#39;;
    }, 2000);
  }).catch(err =&amp;gt; {
    console.error(&#39;Copy failed: &#39;, err);
  });
});
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;While I had hoped to see a copy button added to the top-right corner of the code area, due to my lack of familiarity with frontend development, I was unable to accurately describe the functionality based on keywords and spent several rounds iterating with &lt;code&gt;AI&lt;/code&gt;. It remains to be seen what impact &lt;code&gt;AI&lt;/code&gt; will have on software development over time.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Cloud Servers and Script Kiddies</title>
        <link>https://ttf248.life/en/p/cloud-servers-and-script-kids/</link>
        <pubDate>Mon, 20 Nov 2023 15:08:53 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cloud-servers-and-script-kids/</guid>
        <description>&lt;p&gt;Taking advantage of the Singles Day promotion, Alibaba Cloud recently purchased a server: an economy-friendly version for 99 a year with low specifications, serving as a jumpstart machine to proxy home services – it’s quite decent. The promotion continues until 2026.&lt;/p&gt;
&lt;p&gt;Specifically, I chose a server in the Shanghai region to minimize latency when proxying my home machines. It runs Windows 11 and Windows Server 2022; the server version was deployed later. While using it, I suddenly received a &amp;ldquo;access denied&amp;rdquo; message, initially thinking it was due to a server update that would resolve itself. After waiting five minutes and trying again, the denial persisted. Searching for relevant error messages indicated that someone was attempting to log in, and because of too many incorrect password attempts, login was now blocked. - Previously, I had encountered scripts related to security attacks, and immediately thought of this. These logins were likely not normal behavior; someone was attacking the service, attempting a brute-force login to the server. The server’s firewall was overly simplistic – it hadn&amp;rsquo;t been configured with a whitelist, and it was proxying ports 3389 for two machines, exposing them publicly—much like bait in a fishpond. Now that we knew it was script kiddies attacking, things became much simpler: configure the firewall whitelist to only allow access from the company’s IP address and my home IP address to the proxy service.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;frps&lt;/code&gt; agent server previously had no configuration for running logs. Opening the logs was hilarious – proxy IPs from all over China were trying to log into my home server! Thankfully, there was one that was a server version, which made me realize the problem: otherwise, that Windows 11 machine would have been compromised eventually; the password settings are relatively simple.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;2023/11/17 16:51:14 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [101.43.98.211:50486]
2023/11/17 16:51:14 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [218.93.202.63:56970]
2023/11/17 16:51:14 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [222.179.106.174:60812]
2023/11/17 16:51:15 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [58.16.204.238:2839]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;2023/11/17 16:51:15 [I] [proxy.go:204] [639d8947325142ac] [host-remote] getting a user connection [124.223.47.24:50274]
2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] getting a user connection [43.248.128.22:55883]
2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] getting a user connection [43.143.53.138:56955]
2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] getting a user connection [43.228.7.250:61550]&lt;/p&gt;
&lt;p&gt;2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [125.76.228.9:55842]
2023/11/17 16:51:17 [I] [proxy.go:204] [4dfcc2259937dcb9] [winserver-remote] get a user connection [91.240.118.187:49326]
2023/11/17 16:51:17 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [91.240.118.187:49324]
2023/11/17 16:51:17 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [89.248.163.79:51712]&lt;/p&gt;
&lt;p&gt;2023/11/17 16:51:18 [I] [proxy.go:204] [639d8947325142ac] [host-remote] getting a user connection [218.63.75.24:62387]
2023/11/17 16:51:19 [I] [proxy.go:204] [639d8947325142ac] [host-remote] getting a user connection [103.186.109.227:51396]
2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] getting a user connection [116.233.234.104:51567]
2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] getting a user connection [222.187.193.202:51585]&lt;/p&gt;
&lt;p&gt;2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] getting a user connection from [59.48.98.42:57489]
2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] getting a user connection from [146.56.241.134:53558]
2023/11/17 16:51:21 [I] [proxy.go:204] [639d8947325142ac] [host-remote] getting a user connection from [222.179.106.174:30620]
2023/11/17 16:51:23 [I] [proxy.go:204] [639d8947325142ac] [host-remote] getting a user connection from [183.14.214.51:62128]&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As a side note, I checked the login logs for Linux services, excluding this machine from Alibaba Cloud, and a friend&amp;rsquo;s Huawei Cloud machine.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo grep &amp;quot;Failed password&amp;quot; /var/log/secure  CentOS series
sudo grep &amp;quot;Failed password&amp;quot; /var/log/auth.log  Ubuntu series
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Nov 16 04:46:34 aliyun-sh sshd[156625]: Failed password for root from 120.55.164.64 port 53410 ssh2
Nov 16 04:46:34 aliyun-sh sshd[156623]: Failed password for root from 111.16.215.122 port 36548 ssh2
Nov 16 04:46:58 aliyun-sh sshd[156630]: Failed password for invalid user share from 139.9.233.78 port 53872 ssh2
Nov 16 04:47:23 aliyun-sh sshd[156634]: Failed password for invalid user spark from 139.9.233.78 port 36134 ssh2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nov 16 04:47:26 aliyun-sh sshd[156636]: Failed password for root from 120.55.164.64 port 46142 ssh2
Nov 16 04:47:47 aliyun-sh sshd[156640]: Failed password for root from 111.16.215.122 port 42962 ssh2
Nov 16 04:48:24 aliyun-sh sshd[156652]: Failed password for root from 120.55.164.64 port 38868 ssh2
Nov 16 04:48:25 aliyun-sh sshd[156654]: Failed password for root from 111.16.215.122 port 46164 ssh2&lt;/p&gt;
&lt;p&gt;Nov 16 04:48:25 aliyun-sh sshd[156654]: Failed password for root from 111.16.215.122 port 46164 ssh2
Nov 16 04:48:39 aliyun-sh sshd[156657]: Failed password for invalid user test from 139.9.233.78 port 39386 ssh2
Nov 16 04:48:50 aliyun-sh sshd[156659]: Failed password for root from 111.16.215.122 port 38892 ssh2
Nov 16 04:48:53 aliyun-sh sshd[156662]: Failed password for root from 120.55.164.64 port 49348 ssh2&lt;/p&gt;
&lt;p&gt;Nov 16 04:48:53 aliyun-sh sshd[156662]: Failed password for root from 120.55.164.64 port 49348 ssh2
Nov 16 04:48:53 aliyun-sh sshd[156664]: Failed password for invalid user test from 139.9.233.78 port 49864 ssh2
Nov 16 04:50:02 aliyun-sh sshd[156672]: Failed password for root from 111.16.215.122 port 45294 ssh2
Nov 16 04:50:30 aliyun-sh sshd[156680]: Failed password for invalid user zabbix from 139.9.233.78 port 52206 ssh2&lt;/p&gt;
&lt;p&gt;Nov 16 04:50:50 aliyun-sh sshd[156683]: Failed password for root from 120.55.164.64 port 34820 ssh2
Nov 16 04:50:51 aliyun-sh sshd[156685]: Failed password for root from 111.16.215.122 port 58978 ssh2
Nov 16 04:51:18 aliyun-sh sshd[156689]: Failed password for root from 120.55.164.64 port 45306 ssh2
Nov 16 04:51:25 aliyun-sh sshd[156692]: Failed password for root from 111.16.215.122 port 33938 ssh2&lt;/p&gt;
&lt;p&gt;Huawei Cloud this machine has been running for a long time and is now entering the mid-stage of dictionary explosion, with various strange users starting to appear.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Nov 16 20:30:35 hecs-411458 sshd[182965]: Failed password for invalid user oeh from 39.129.9.180 port 26459 ssh2
Nov 16 20:32:17 hecs-411458 sshd[182967]: Failed password for invalid user dnu from 39.129.9.180 port 27079 ssh2
Nov 16 20:34:12 hecs-411458 sshd[182971]: Failed password for invalid user rq from 39.129.9.180 port 27742 ssh2
Nov 16 20:36:07 hecs-411458 sshd[182979]: Failed password for invalid user zw from 39.129.9.180 port 28415 ssh2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nov 16 20:37:59 hecs-411458 sshd[182981]: Failed password for invalid user egi from 39.129.9.180 port 29068 ssh2
Nov 16 20:39:52 hecs-411458 sshd[182984]: Failed password for invalid user bjb from 39.129.9.180 port 29723 ssh2
Nov 16 20:41:53 hecs-411458 sshd[182988]: Failed password for invalid user hna from 39.129.9.180 port 30375 ssh2
Nov 16 20:43:46 hecs-411458 sshd[182994]: Failed password for invalid user gar from 39.129.9.180 port 31036 ssh2&lt;/p&gt;
&lt;p&gt;Nov 16 20:45:40 hecs-411458 sshd[183003]: Failed password for invalid user mze from 39.129.9.180 port 31703 ssh2
Nov 16 20:47:35 hecs-411458 sshd[183007]: Failed password for invalid user tmh from 39.129.9.180 port 32381 ssh2
Nov 16 21:23:01 hecs-411458 sshd[183047]: Failed password for invalid user amax from 112.4.65.118 port 41188 ssh2
Nov 16 22:31:20 hecs-411458 sshd[183116]: Failed password for root from 211.228.203.123 port 60213 ssh2&lt;/p&gt;
&lt;p&gt;Nov 16 22:53:44 hecs-411458 sshd[183162]: Failed password for root from 112.132.249.164 port 39272 ssh2
Nov 17 11:44:26 hecs-411458 sshd[184811]: Failed password for invalid user jsh from 43.157.103.27 port 54608 ssh2
Nov 17 11:47:23 hecs-411458 sshd[184818]: Failed password for invalid user mrunal from 43.157.103.27 port 50448 ssh2
Nov 17 11:48:46 hecs-411458 sshd[184820]: Failed password for invalid user robertsheen from 43.157.103.27 port 50560 ssh2&lt;/p&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;Developing a self-hosted server requires setting up a whitelist for public Windows access, and on Linux systems, it’s recommended to disable password logins and enable key file login.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>- Batch update local Git repositories and resolve legacy permission issues.</title>
        <link>https://ttf248.life/en/p/bulk-update-local-git-and-legacy-permissions/</link>
        <pubDate>Thu, 19 Oct 2023 14:16:22 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/bulk-update-local-git-and-legacy-permissions/</guid>
        <description>&lt;p&gt;The projects within the team have dependencies on each other, and due to historical reasons, submodules haven’t been used to manage these project dependencies. Daily development requires manually updating the repository code one by one, otherwise various strange issues may arise.&lt;/p&gt;
&lt;p&gt;Referring to online resources, the structure is generally similar. A local manual repository directory (&lt;strong&gt;git_list.txt&lt;/strong&gt;) is maintained, and a script iterates through the directories to perform an update in one go. Before starting each project, this script needs to be executed.&lt;/p&gt;
&lt;h2 id=&#34;linux&#34;&gt;linux
&lt;/h2&gt;&lt;p&gt;create new file: batch_pull.sh&lt;/p&gt;
&lt;h2 id=&#34;linux-1&#34;&gt;Linux
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#!/bin/bash

echo &amp;quot;============ Updating Repository ===================&amp;quot;

# Check if git_list.txt exists
if [ ! -f &amp;quot;git_list.txt&amp;quot; ]; then
  echo &amp;quot;git_list.txt file does not exist! Please create and add the Git repository URLs to pull.&amp;quot;
  exit 1
else
  echo &amp;quot;============ Detected Git Repository List File ===================&amp;quot;
fi

# Read each URL from git_list.txt and execute the pull operation
while read -r url; do
  if [ -d &amp;quot;$url&amp;quot; ]; then
    cd &amp;quot;$url&amp;quot; || continue
    git pull
    cd ..
    echo &amp;quot;Pull $url completed!&amp;quot;
    echo &amp;quot;========================================&amp;quot;
  else
    echo &amp;quot;Directory $url does not exist, skipping pull.&amp;quot;
  fi
done &amp;lt; &amp;quot;git_list.txt&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;windows&#34;&gt;Windows
&lt;/h2&gt;&lt;p&gt;Create a new file: batch_pull.bat&lt;/p&gt;
&lt;h2 id=&#34;windows-1&#34;&gt;Windows
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-bat&#34;&gt;@echo off
chcp 65001 &amp;gt; nul
rem Enter the script directory
cd /d &amp;quot;%~dp0&amp;quot;

rem Check if git_list.txt exists
if not exist &amp;quot;git_list.txt&amp;quot; (
  echo git_list.txt file does not exist! Please create and add the Git repository URLs to pull.
  exit /b 1
) else (
  echo ============ Detected Git Repository List File =========
)

rem Read each URL from git_list.txt and execute the pull operation
for /f %%i in (git_list.txt) do (
  if exist &amp;quot;%%i&amp;quot; (
    pushd &amp;quot;%%i&amp;quot;
    git pull
    popd
    echo Pull %%i completed!
    echo ========================================
  ) else (
    echo Directory %%i does not exist, skipping pull.
  )
)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;legacy-issues&#34;&gt;Legacy Issues
&lt;/h3&gt;&lt;p&gt;Also handle the &lt;code&gt;git&lt;/code&gt; folder permission files encountered after reinstalling the system: &lt;strong&gt;Fatal error &amp;ldquo;unsafe repository (&amp;rsquo;/home/repon&amp;rsquo; is owned by someone else)&amp;rdquo;&lt;/strong&gt;.
Most suggestions found online originate from &lt;code&gt;stack overflow&lt;/code&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Add trust to the repository directory: &lt;code&gt;git config --global --add safe.directory /home/repon&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Manually modify the configuration file &lt;code&gt;.gitconfig&lt;/code&gt;, specifying the directory as trusted&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[safe]
    directory = /home/repon
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After using this method, repository updates are normal, but there are many warning messages displayed in the console every time &lt;code&gt;git pull&lt;/code&gt; is executed, indicating owner errors.&lt;/p&gt;
&lt;h3 id=&#34;reinstalling-the-operating-system-on-a-desktop-pc&#34;&gt;Reinstalling the Operating System on a Desktop PC
&lt;/h3&gt;&lt;p&gt;The machine hadn&amp;rsquo;t been reinstalled for a long time, and the system partition was filled with a massive amount of garbage files. There was no choice but to take some time to reinstall it. I ran into this permission issue again, and previous scripts wouldn’t run because the permissions were incomplete.&lt;/p&gt;
&lt;p&gt;Using the new approach, I simply added &lt;code&gt;*&lt;/code&gt;, which allows &lt;code&gt;git&lt;/code&gt; to automatically trust all directories.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git config --global --add safe.directory &amp;quot;*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;I suspect it&amp;rsquo;s a user permission issue, or perhaps everyone hasn’t gotten used to the fact that Windows also has similar commands like &lt;code&gt;chown&lt;/code&gt; for modifying folder owners. Of course, if you have only a few directories, you can manually modify the ownership as well. However, this work computer has domain information added, and I don&amp;rsquo;t know whether it&amp;rsquo;s an anomaly in the company’s domain deployment or whether there are anomalies in the local system settings. The user list couldn&amp;rsquo;t find the user used for login, so I finally handled it through command-line processing.&lt;/p&gt;
&lt;h3 id=&#34;reinstalling-the-operating-system&#34;&gt;Reinstalling the Operating System
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;# Get the current user&#39;s username
$currentUserName = [System.Security.Principal.WindowsIdentity]::GetCurrent().Name

# Set PowerShell&#39;s character encoding to UTF-8
[Console]::OutputEncoding = [System.Text.Encoding]::UTF8

# The root directory to change ownership for
$rootDirectory = &amp;quot;G:\workspace&amp;quot;  # Replace with the actual path
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;reinstalling-the-operating-system-on-a-desktop-pc-1&#34;&gt;Reinstalling the Operating System on a Desktop PC
&lt;/h3&gt;&lt;h1 id=&#34;check-if-its-a-file-or-a-folder&#34;&gt;Check if it&amp;rsquo;s a file or a folder
&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;if ($_ -is [System.IO.DirectoryInfo]) {
    # If it&#39;s a folder, use icacls to change ownership permissions
    $icaclsResult = icacls $itemPath /setowner &amp;quot;$currentUserName&amp;quot; 2&amp;gt;&amp;amp;1
    if ($LASTEXITCODE -eq 0) {
        Write-Host &amp;quot;Ownership of folder $itemPath has been changed to $currentUserName&amp;quot;
    } else {
        Write-Host &amp;quot;Unable to change ownership of folder $itemPath. Error message: $icaclsResult&amp;quot;
    }
} else {
    # If it&#39;s a file, use icacls to change ownership permissions
    $takeownResult = icacls $itemPath /setowner &amp;quot;$currentUserName&amp;quot; 2&amp;gt;&amp;amp;1
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;reinstalling-the-operating-system-on-a-desktop-pc-2&#34;&gt;Reinstalling the Operating System on a Desktop PC
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;$takeownResult = icacls $itemPath /setowner &amp;quot;$currentUserName&amp;quot; 2&amp;gt;&amp;amp;1
if ($LASTEXITCODE -eq 0) {
    # Write-Host &amp;quot;已更改文件 $itemPath 的所有者为 $currentUserName&amp;quot;
} else {
    Write-Host &amp;quot;无法更改文件 $itemPath 的所有者。错误信息: $takeownResult&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;reinstalling-the-operating-system-on-a-desktop-pc-3&#34;&gt;Reinstalling the Operating System on a Desktop PC
&lt;/h3&gt;&lt;p&gt;As expected, unexpected issues arose. The Chinese information output from the script execution was garbled, and attempts to set the console character encoding and adjust the script encoding resulted in gibberish. It’s highly likely that my brain wasn&amp;rsquo;t fully sober. I tried enabling the beta feature in Control Panel - Region - Language Settings, globally opening Unicode encoding, which resolved the script execution issues. However, several development software applications were unable to function properly. Looking back, I realized that adjusting the script file encoding to &lt;code&gt;gbk&lt;/code&gt; was the solution.&lt;/p&gt;
&lt;h2 id=&#34;resources&#34;&gt;Resources
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://ganzhixiong.com/p/f1b9f4fc/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ganzhixiong.com/p/f1b9f4fc/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://stackoverflow.com/questions/71901632/fatal-error-unsafe-repository-home-repon-is-owned-by-someone-else&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stackoverflow.com/questions/71901632/fatal-error-unsafe-repository-home-repon-is-owned-by-someone-else&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>WPF Learning Resources</title>
        <link>https://ttf248.life/en/p/wpf-learning-resources/</link>
        <pubDate>Tue, 17 Oct 2023 10:49:24 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/wpf-learning-resources/</guid>
        <description>&lt;p&gt;The potholes in the mini-program development haven’t been filled, and we’ve just dug a new one with &lt;strong&gt;WPF&lt;/strong&gt;. Recently, the company has been experiencing some turbulence, and remote collaboration communication is invariably less efficient than desired. So, we&amp;rsquo;ve taken on the development of client interfaces.&lt;/p&gt;
&lt;h2 id=&#34;wpf&#34;&gt;WPF
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/dotnet/desktop/wpf/introduction-to-wpf?view=netframeworkdesktop-4.8&amp;amp;preserve-view=true&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;WPF Microsoft Official Learning Resources&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/zh7791/p/11502696.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;WPF Basic Summary (Learning Suggestions)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://www.wpfsoft.com/introduction&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;WPF Chinese Website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/638815741&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;WPF Personal Summary and Learning Recommendations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;WPF&lt;/code&gt; interface design uses many concepts similar to web frontend design, striving to separate UI design from business logic as much as possible, which is the desired division of labor in internet companies.  I recently played with Mini Programs, and many concepts are common, making it relatively easy to get started. These are considered the &amp;ldquo;Dao&amp;rdquo; (path) in modern UI design – mastering basic framework concepts makes the road less prone to deviation.&lt;/p&gt;
&lt;h2 id=&#34;wpf-1&#34;&gt;WPF
&lt;/h2&gt;&lt;p&gt;For readers with previous &lt;code&gt;WinForm&lt;/code&gt; development experience, we recommend reading: &lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/zh7791/p/11502696.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;WPF Basic Summary (Learning Suggestions)&lt;/a&gt;. The article isn&amp;rsquo;t too long and is suitable for experienced readers to plan their learning path.&lt;/p&gt;
&lt;p&gt;For beginners, we recommend reading: &lt;a class=&#34;link&#34; href=&#34;http://www.wpfsoft.com/introduction&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;WPF Chinese Website&lt;/a&gt;, which introduces basic concepts, the history of development, and the logic of understanding underlying classes from scratch. This website is quite lucky – it was just released by the author in August this year, aimed at attracting readers to purchase courses, and its timing coincides with mine. If it&amp;rsquo;s a little later, I probably won’t have any chance.&lt;/p&gt;
&lt;p&gt;To get the most orthodox learning materials, of course, it’s the official Microsoft documentation, which is somewhat dry and requires patience for new readers. Classic e-books are also plentiful, and not particularly recommended. With a lot of work to do daily, there isn’t much time to sit down and read; it&amp;rsquo;s difficult to immediately immerse myself in reading. It’s more suitable to practice projects instead.&lt;/p&gt;
&lt;h2 id=&#34;c-and-net-release-history&#34;&gt;C# and .NET Release History
&lt;/h2&gt;&lt;p&gt;Regarding previous learning languages, there have been a number of new features released in recent years, and the versioning of syntax has been iterating annually.
&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/C_Sharp_%28programming_language%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://en.wikipedia.org/wiki/C_Sharp_(programming_language)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Official Learning Resources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/dotnet/csharp/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://learn.microsoft.com/zh-cn/dotnet/csharp/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/dotnet/core/tutorials/with-visual-studio?pivots=dotnet-7-0&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://learn.microsoft.com/zh-cn/dotnet/core/tutorials/with-visual-studio?pivots=dotnet-7-0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>ZeroTier SD</title>
        <link>https://ttf248.life/en/p/zero-tier-remote-lan/</link>
        <pubDate>Tue, 19 Sep 2023 04:58:03 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/zero-tier-remote-lan/</guid>
        <description>&lt;ul&gt;
&lt;li&gt;I recently got a &lt;code&gt;mini&lt;/code&gt; host for the office, thinking it would be convenient to configure an environment and have occasional access at home. I temporarily deployed internal network penetration using &lt;code&gt;frp&lt;/code&gt; – specifying port forwarding, which requires a public server with a connection quality dependent on its bandwidth. Instead of that, I experimented with a fresh &lt;code&gt;Zerotier&lt;/code&gt; virtual LAN, similar to a &lt;code&gt;VPN&lt;/code&gt;, where I created a virtual network card locally and all machines joined it into a single virtual network.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-is-zerotier&#34;&gt;What is ZeroTier
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;ZeroTier&lt;/code&gt; is a software-defined wide area network (SD-WAN) solution that allows users to create secure virtual networks between devices in different geographic locations. Through &lt;code&gt;ZeroTier&lt;/code&gt;, you can easily connect multiple computers, servers, and devices into a virtual, encrypted network – as if they were on the same local network. This can help developers and IT professionals securely share data and resources across different locations without complex network setups or VPN configurations.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ZeroTier Networks&lt;/strong&gt;: A ZeroTier Network is a virtual, global LAN that allows different devices to connect together over the internet, as if they were on the same physical network. This network can contain multiple subnets, with all devices connected together using ZeroTier technology. &lt;strong&gt;Planet Server:&lt;/strong&gt; The Planet Server is a key component of the Zerotier network. It’s global in scope, responsible for maintaining and managing the entire Zerotier network&amp;rsquo;s topology, routing information, and network state. The Planet Server acts as a central control center for the network, but does not directly transmit data. User devices need to connect to at least one Planet Server to participate in the Zerotier network.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;what-is-zerotier-1&#34;&gt;What is Zerotier
&lt;/h2&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;Relay Server:&lt;/strong&gt; A relay server is an auxiliary node in the Zerotier network that helps establish direct communication channels between devices. When devices cannot connect directly, they can use a relay server to transmit data. This helps improve network reachability and performance. Relay servers are typically located around the globe, acting as data transmission hubs.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In essence, Zerotier uses the assistance of planet servers and relay servers to allow devices to create virtual local networks globally, enabling secure and fast communication between devices. The planet server is responsible for global network management, while the relay server helps devices establish connection when needed.&lt;/p&gt;
&lt;h2 id=&#34;installation--deployment&#34;&gt;Installation &amp;amp; Deployment
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Visit the ZeroTier official website (&lt;a class=&#34;link&#34; href=&#34;https://www.zerotier.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.zerotier.com/&lt;/a&gt;) to obtain installation files and documentation.&lt;/li&gt;
&lt;li&gt;Download and install the ZeroTier One client according to your operating system. It supports Windows, macOS, Linux, and many other platforms.&lt;/li&gt;
&lt;li&gt;Launch the ZeroTier One client after installation.&lt;/li&gt;
&lt;li&gt;Register a ZeroTier account if you don&amp;rsquo;t already have one. You can create an account within the client.&lt;/li&gt;
&lt;li&gt;Log in with your ZeroTier account and create a new network. The network will have a unique 16-character ID, which you need to remember.&lt;/li&gt;
&lt;li&gt;Join this network on your device. You can either enter the network ID in the client or use the QR code scanning feature.&lt;/li&gt;
&lt;li&gt;Devices with the installed and configured ZeroTier client will be added to the same virtual network.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;installation-and-deployment-of-moon&#34;&gt;Installation and Deployment of Moon
&lt;/h2&gt;&lt;p&gt;Many domestic operators have banned &lt;code&gt;UDP&lt;/code&gt; tunneling, and the &lt;code&gt;frp&lt;/code&gt; service is stable due to using the &lt;code&gt;TCP&lt;/code&gt; protocol. The &lt;code&gt;Zerotier&lt;/code&gt; middle server deployment can also achieve similar effects, requiring firewall opening of &lt;code&gt;UDP 9993&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;curl -s https://install.zerotier.com/ | sudo bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Check installation success:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;zerotier-cli info
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Join the local network:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;zerotier-cli join network-id
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Create &lt;code&gt;moon&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd /var/lib/zerotier-one &amp;amp;&amp;amp; sudo zerotier-idtool initmoon identity.public &amp;gt; moon.json
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Edit the configuration file, adjust the &lt;code&gt;stableEndpoints&lt;/code&gt; nodes to &amp;ldquo;server public IP/9993&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Generate signature configuration, create the &lt;code&gt;moons.d&lt;/code&gt; folder, and move the previous files into it, then restart the service.&lt;/p&gt;
&lt;h2 id=&#34;installing-and-deploying-moon&#34;&gt;Installing and Deploying Moon
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo zerotier-idtool genmoon moon.json
mkdir moons.d &amp;amp;&amp;amp; mv 000000eb444ec0d8.moon moons.d/
systemctl restart zerotier-one.service
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Client nodes join the Moon server, ID taken from the ID field in the preceding JSON configuration file:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;zerotier-cli.bat orbit ztaddr ztaddr
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;installing-and-deploying-moon-1&#34;&gt;Installing and Deploying Moon
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Observe if new moon nodes appear, with IDs and information matching server configuration.
[root@idv-36f9d5 ~]# zerotier-cli listpeers
200 listpeers &amp;lt;ztaddr&amp;gt; &amp;lt;path&amp;gt; &amp;lt;latency&amp;gt; &amp;lt;version&amp;gt; &amp;lt;role&amp;gt;
200 listpeers 0cccb***** 35.236.*.*/64393;110;10726 327 1.6.3 LEAF
200 listpeers 3a46f***** 185.180.*.*/9993;110;757 -1 - PLANET
200 listpeers 3ed7c***** 39.97.*.*/9993;172;79 32 1.6.3 MOON
200 listpeers 4f838***** - -1 - LEAF
200 listpeers 62f86***** 50.7.*.*/9993;110;4796 351 - PLANET
200 listpeers 778cd***** 103.195.*.*/9993;5148;4887 253 - PLANET
200 listpeers 992fc***** 195.181.*.*/9993;10161;4921 226 - PLANET
200 listpeers 9d2b5***** - -1 - LEAF
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;installation-and-deployment-of-moon-1&#34;&gt;Installation and Deployment of Moon
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;On Windows, launch the terminal with administrator privileges and operate using the &lt;code&gt;zerotier-cli.bat&lt;/code&gt; command-line interface. On Linux, use the &lt;code&gt;zerotier-cli&lt;/code&gt; command. The &lt;code&gt;peers&lt;/code&gt; subcommand displays connections, while &lt;code&gt;listpeers&lt;/code&gt; shows all nodes, successfully indicating a successful join.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;uninstalling&#34;&gt;Uninstalling
&lt;/h2&gt;&lt;p&gt;How to uninstall on the &lt;code&gt;Windows&lt;/code&gt; platform is beyond the scope of this document, as it follows standard operating procedures – typically through the Control Panel. We will focus on the &lt;code&gt;Ubuntu&lt;/code&gt; instructions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Remove the zerotier-one service using dpkg:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo dpkg -P zerotier-one
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;Delete the zerotier-one directory, which stores the address information; deleting it will result in a new address upon reinstallation:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo rm -rf /var/lib/zerotier-one/
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;They were originally all decommissioned, arriving at the server location without suitable service nodes to act as proxy servers. Alibaba was focused on sales and provided development trial servers with low configurations, costing only 99 yuan per year and used for two years. The key factor was the bandwidth offered by the servers.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.wnark.com/archives/152.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.wnark.com/archives/152.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/Yogile/p/12642423.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.cnblogs.com/Yogile/p/12642423.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>VMware Virtual Machine Disk Space Optimization</title>
        <link>https://ttf248.life/en/p/vmware-virtual-machine-disk-space-optimization/</link>
        <pubDate>Wed, 21 Jun 2023 18:35:41 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/vmware-virtual-machine-disk-space-optimization/</guid>
        <description>&lt;p&gt;When installing a development system with VMware virtual machines, it’s generally recommended to pre-allocate a significant amount of disk space. Over time, the local disk space consumed by the VM will far exceed the actual size of its files.&lt;/p&gt;
&lt;h2 id=&#34;scenario-description&#34;&gt;Scenario Description
&lt;/h2&gt;&lt;p&gt;The &lt;code&gt;df -h&lt;/code&gt; command revealed that the current machine was using 60GB of disk space, and after deleting all snapshots and clone images, the local virtual machine still occupied significantly more than 60GB, further straining the already limited hard drive.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;When installing the virtual machine, do not select &amp;ldquo;pre-allocate disk.&amp;rdquo;&lt;/li&gt;
&lt;li&gt;The local hard drive where the virtual machine is stored must have sufficient free disk space greater than the currently used space of the virtual machine.&lt;/li&gt;
&lt;li&gt;If there isn&amp;rsquo;t enough space, consider temporarily moving the virtual machine to a portable hard drive, optimize the disk, and then migrate it back.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tools&#34;&gt;Tools
&lt;/h2&gt;&lt;p&gt;The official provides the &lt;code&gt;open-vm-tools&lt;/code&gt; package, which can be installed via yum or by installing the VMware-Tools image package.&lt;/p&gt;
&lt;h2 id=&#34;commands&#34;&gt;Commands
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;vmware-toolbox-cmd disk shrink /
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After execution, the virtual machine will automatically shut down, and the VMware host program will perform disk compression. The execution time depends on the volume of the virtual machine and the speed of the disk access.&lt;/p&gt;
&lt;p&gt;The effect is quite good; the disk space occupied by the virtual machine is essentially equal to the disk information as shown in &lt;code&gt;df -h&lt;/code&gt;.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Stable Diffusion – The Love, Hate, and Drama of Installing it from Scratch</title>
        <link>https://ttf248.life/en/p/stable-diffusion-zero-install-story/</link>
        <pubDate>Thu, 13 Apr 2023 00:23:54 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/stable-diffusion-zero-install-story/</guid>
        <description>&lt;p&gt;Domestic resources are basically all recommending &lt;strong&gt;Autumn Leaf&lt;/strong&gt;’s one-click deployment package, thinking that they are open-source projects based on &lt;code&gt;Python&lt;/code&gt;, so the deployment wouldn&amp;rsquo;t be complicated, let’s try to start from scratch.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I was messing around with AI-generated images and specifically changed my graphics card, a beginner version of the &lt;code&gt;3060 12g&lt;/code&gt;; the seven-year-old &lt;code&gt;960&lt;/code&gt; retired gracefully.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The core &lt;code&gt;pytorch cuda&lt;/code&gt; installation, which I previously encountered issues with when writing Python game helper scripts (I had installed it locally before), still presented problems – the &lt;code&gt;cuda&lt;/code&gt; encryption consistently failed to activate.&lt;/p&gt;
&lt;h2 id=&#34;to-do&#34;&gt;To Do
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Replan the article structure, first introduce PyTorch, version correspondence, and how to check versions.&lt;/li&gt;
&lt;li&gt;How to create a new virtual environment from scratch locally and deploy PyTorch.&lt;/li&gt;
&lt;li&gt;Translate the manuscript from scratch: &lt;a class=&#34;link&#34; href=&#34;https://stable-diffusion-art.com/install-windows/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stable-diffusion-art.com/install-windows/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Organize reference materials&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;steps&#34;&gt;Steps
&lt;/h2&gt;&lt;p&gt;Step-by-step installation tutorials in Chinese may not be readily available. If you search in English on &lt;code&gt;Google&lt;/code&gt;, you’ll find many similar tutorials starting from scratch. We introduce the need to install &lt;code&gt;git&lt;/code&gt; and then explain that we also need to install &lt;code&gt;python&lt;/code&gt;. Then, you go ahead and download the repository – simply double-clicking the script gets it running.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/AUTOMATIC1111/stable-diffusion-webui&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For detailed usage and FAQs, consult the &lt;code&gt;issues&lt;/code&gt; page: &lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki&lt;/a&gt;. I don’t know why no one explains what this repository is for. Actually, the name itself isn&amp;rsquo;t difficult to understand – it’s a graphical console that makes it easier for us to use.&lt;/p&gt;
&lt;h2 id=&#34;steps-1&#34;&gt;Steps
&lt;/h2&gt;&lt;p&gt;The repository also created an installation and startup script. It automatically identifies the current folder and checks for a &lt;code&gt;Python&lt;/code&gt; virtual environment. If one exists, it defaults to using the &lt;code&gt;python&lt;/code&gt; in the current path.&lt;/p&gt;
&lt;p&gt;For new users who are unfamiliar with the process, we recommend reviewing: &lt;a class=&#34;link&#34; href=&#34;https://stable-diffusion-art.com/install-windows/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stable-diffusion-art.com/install-windows/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;pytorch&#34;&gt;PyTorch
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/get-started/locally/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://pytorch.org/get-started/locally/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Don&amp;rsquo;t follow their steps directly to launch the script. Python uses &lt;code&gt;requirement&lt;/code&gt; files to install dependency libraries, which is just a minor issue. The core thing is your GPU version and driver version, which need to match PyTorch. Many people have discussed this relationship online – you can find it by searching.
Reference: &lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/weixin_40660408/article/details/129896700&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/weixin_40660408/article/details/129896700&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Creating a virtual environment is like creating an empty virtual environment, where you first execute the official script to install PyTorch within it.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -c &amp;quot;import torch; print(torch.version.cuda)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -c &amp;quot;import torch; print(torch.__version__, torch.cuda.is_available())&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;pytorch-1&#34;&gt;PyTorch
&lt;/h2&gt;&lt;p&gt;The following two scripts can check the CUDA version you need to install and also check if the installation was successful.
We don&amp;rsquo;t recommend fancy operations here; first, follow the logic on the official page to copy it over directly, and then just install it directly using pip. You’re likely to fail or not activate CUDA if you try to install directly with pip.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Don&amp;rsquo;t use messy folder names, as this could prevent PyTorch from working.
I went back and forth installing many times and even tried downloading the official installation files manually to upgrade to version 2.0 because the official documentation said it would be faster. - However, I hadn’t used it much before, and I wasn&amp;rsquo;t sure about the Python version and whether that was having an impact. I also reviewed the official documentation in between, which recommended using version 3.8. This created a small conflict because I had previously used a one-click installation package that contained version 3.10. Finally, I started from scratch by creating a new folder and setting up a virtual environment to ensure that Torch was successfully installed.&lt;/p&gt;
&lt;h2 id=&#34;pytorch-2&#34;&gt;PyTorch
&lt;/h2&gt;&lt;p&gt;Then, move the installed virtual environment into the web UI folder. At this point, running the script to install the other dependencies should resolve most of the issues.
After moving it, execute: &lt;code&gt;python -m pip install --upgrade --force-reinstall pip&lt;/code&gt; to fix Pip.
It might seem quite weird, but I’ve spent a lot of time messing around here because it couldn&amp;rsquo;t correctly recognize my Torch. To eliminate all potential interference, I thought it was best to install it first, then install the other dependency libraries.&lt;/p&gt;
&lt;h2 id=&#34;xformers&#34;&gt;Xformers
&lt;/h2&gt;&lt;p&gt;It is recommended to enable this, which can accelerate image generation and reduce memory usage. However, a side effect is that &lt;strong&gt;generated images tend to be less stable&lt;/strong&gt; with the same set of parameters.
&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;stable-diffusion-webui:Xformers&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/diffusers/optimization/xformers&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;huggingface optimization&lt;/a&gt;
| 100.00% | 2m 57.03s | 7440/10058 MiB | 12288/12288 MiB (100.0%) |&lt;/p&gt;
&lt;h2 id=&#34;xformers-1&#34;&gt;Xformers
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Optimization Ratio&lt;/th&gt;
&lt;th&gt;Time taken&lt;/th&gt;
&lt;th&gt;Torch active/reserved&lt;/th&gt;
&lt;th&gt;Sys VRAM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;51.02%&lt;/td&gt;
&lt;td&gt;1m 29.21s&lt;/td&gt;
&lt;td&gt;4547/7164 MiB&lt;/td&gt;
&lt;td&gt;9298/12288 MiB (75.67%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;xformers-2&#34;&gt;Xformers
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;(masterpiece), (best quality), (high detail), (realistic,)
Industrial age city, deep canyons in the middle, Chinese architectural streets, bazaars, bridges, (rainy days:1.2), (steampunk:0.8), Chinese architecture
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;xformers-3&#34;&gt;Xformers
&lt;/h2&gt;&lt;p&gt;Negative prompt: nsfw,((cowboy)),(((pubic))), ((((pubic_hair))))sketch, duplicate, ugly, huge eyes, text, logo, monochrome, worst face, (bad and mutated hands:1.3), (worst quality:2.0), (low quality:2.0), (blurry:2.0), horror, geometry, bad_prompt, (bad hands), (missing fingers), multiple limbs, bad anatomy, (interlocked fingers:1.2), Ugly Fingers, (extra digit and hands and fingers and legs and arms:1.4), crown braid, ((2girl)), (deformed fingers:1.2), (long fingers:1.2),succubus wings,horn,succubus&lt;/p&gt;
&lt;h2 id=&#34;xformers-4&#34;&gt;Xformers
&lt;/h2&gt;&lt;p&gt;crown braid, ((2girl)), (deformed fingers:1.2), (long fingers:1.2), succubus wings, horn, succubus horn, succubus hairstyle, (bad-artist-anime), bad-artist, bad hand, borrowed character, text focus, watermark, sample watermark, character watermark, lofter username, photo date watermark, movie poster, magazine cover, journal, cover, cover page, doujin cover, album cover, manga cover, brand name imitation, EasyNegative, Tights, silk stockings, shorts&lt;/p&gt;
&lt;h2 id=&#34;xformers-5&#34;&gt;Xformers
&lt;/h2&gt;&lt;p&gt;Steps: 35, Sampler: DPM adaptive, CFG scale: 5.5, Seed: 2223996555, Size: 1088x1088, Model hash: 543bcbc212, Model: base_Anything-V3.0-pruned, Clip skip: 2, ENSD: 31337&lt;/p&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;We didn’t recommend the one-click deployment package because it contained some settings that were customized by the author and differed from the official original configuration. If you are a beginner, you might not understand why those parameters are optimal; it&amp;rsquo;s best to start with the official package first. As you use it more and more, take time to read the official documentation, and you’ll learn which parameters need adjustment.&lt;/p&gt;
&lt;h2 id=&#34;choosing-a-graphics-card&#34;&gt;Choosing a Graphics Card
&lt;/h2&gt;&lt;p&gt;Following the cryptocurrency mining boom, graphics card prices have become relatively less high. When ordinary entry-level players are choosing between the &lt;code&gt;3060&lt;/code&gt; and &lt;code&gt;3060ti&lt;/code&gt;, they generally recommend the &lt;code&gt;12G&lt;/code&gt; version of the 3060 due to its larger VRAM, as it can generate larger resolution images. Why do you need a higher resolution? Because you can adjust the resolution when generating images, which will result in clearer and more detailed images. If you only want to generate small images, then &lt;code&gt;8G&lt;/code&gt; of VRAM is sufficient.&lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s also the &lt;strong&gt;upscaling&lt;/strong&gt; option – “High Definition Upscaling” – which enhances details and makes the image richer in detail, requiring more VRAM. Here’s a summary table of the single-precision (FP32), half-precision (FP16), and double-precision (FP64) floating-point compute capabilities for NVIDIA GeForce GTX 970, GeForce RTX 3060 Ti, GeForce RTX 3060, GeForce RTX 3080, and GeForce RTX 3080 Ti:&lt;/p&gt;
&lt;p&gt;| GeForce GTX 970 | 2014 | 3.49 | 87.2 | 0.109 |&lt;/p&gt;
&lt;h2 id=&#34;graphics-card-selection&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;graphics-card-selection-1&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;graphics-card-selection-2&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating Point Performance (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating Point Performance (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating Point Performance (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;graphics-card-selection-3&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;graphics-card-selection-4&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;p&gt;Excerpted from &lt;a class=&#34;link&#34; href=&#34;https://docs.google.com/spreadsheets/d/1Zlv4UFiciSgmJZncCujuXKHwc4BcxbjbSBg71-SdeNk/edit#gid=0&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;various graphics card performance test data&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;updates&#34;&gt;Updates
&lt;/h2&gt;&lt;p&gt;Every six months, I originally planned to revisit and refine the installation steps, and explain more basic concepts. However, I discovered that most people using AI image generation are simply adjusting parameters based on images provided by experts, or re-rendering existing images with formatting changes.&lt;/p&gt;
&lt;p&gt;I had previously attempted a project using AI to generate UI materials for mini programs, but after struggling for half a day, the results were unsatisfactory compared to just pulling resource images directly from the official mini program documentation.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Program optimization should not attempt to fight against hardware.</title>
        <link>https://ttf248.life/en/p/program-optimization-dont-fight-hardware/</link>
        <pubDate>Fri, 07 Apr 2023 16:30:15 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/program-optimization-dont-fight-hardware/</guid>
        <description>&lt;p&gt;&lt;code&gt;one loop thread&lt;/code&gt;, the time taken has already been at the &lt;strong&gt;microsecond&lt;/strong&gt; level, switching servers resulted in a backlog of up to 60,000 packets, to almost none.&lt;/p&gt;
&lt;p&gt;In single-threaded loop processing data scenarios, the CPU performance depends on factors such as clock frequency, cache size, and instruction set architecture. Generally, CPUs with higher clock frequencies, larger caches, and more advanced instruction set architectures perform better in single-threaded data processing.&lt;/p&gt;
&lt;h2 id=&#34;single-threaded&#34;&gt;Single-Threaded
&lt;/h2&gt;&lt;p&gt;Performance improvements aren&amp;rsquo;t always achieved by adding threads; it’s not necessary to overcomplicate things.  Refine the project workflow, identify time-consuming bottlenecks, and determine if a single thread can meet the requirements. Considering single-threaded approaches reduces complexity and minimizes potential issues.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It’s somewhat misguided to jump straight into discussing threading – it often indicates a flawed approach.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;events&#34;&gt;Events
&lt;/h2&gt;&lt;p&gt;Handling &lt;strong&gt;market data, latency-sensitive&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Spent the night working diligently to release a new optimized version, performing local API stripping and testing – the speed was acceptable at 42,000 TPS.&lt;/p&gt;
&lt;p&gt;Upon deployment to the server, TPS dropped dramatically to 21,000.  I went home to try it on my desktop, where TPS reached 79,000. This led me to suspect that the group’s service virtual machines might be experiencing some issues. Initially, I suspected CPU frequency differences between the server and my desktop – the biggest difference was in the CPU frequencies.&lt;/p&gt;
&lt;p&gt;Testing Server A&lt;/p&gt;
&lt;h2 id=&#34;event&#34;&gt;Event
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;processor : 7
vendor_id  : GenuineIntel
cpu family : 6
model      : 47
model name : Intel(R) Xeon(R) CPU E7-4807 @ 1.87GHz
stepping   : 2
microcode  : 0x34
cpu MHz    : 1866.733
cache size : 18432 KB
physical id: 1
siblings   : 4
core id    : 3
cpu cores  : 4
apicid     : 7
initial apicid: 7
fpu        : yes
fpu_exception: yes
cpuid level: 11
wp         : yes
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;event-1&#34;&gt;Event
&lt;/h2&gt;&lt;p&gt;apicid : 7
initial apicid : 7
fpu : yes
fpu_exception : yes
cpuid level : 11
wp : yes
flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss ht syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 cx16 sse4_1 sse4_2 popcnt aes hypervisor lahf_lm pti dtherm arat
bugs : clflush_monitor cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit&lt;/p&gt;
&lt;h2 id=&#34;events-1&#34;&gt;Events
&lt;/h2&gt;&lt;p&gt;bogomips : 3733.46
clflush size : 64
cache_alignment : 64
address sizes : 40 bits physical, 48 bits virtual
power management:&lt;/p&gt;
&lt;h2 id=&#34;event-2&#34;&gt;Event
&lt;/h2&gt;&lt;p&gt;Test Server B&lt;/p&gt;
&lt;h2 id=&#34;event-3&#34;&gt;Event
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;processor : 7
vendor_id  : GenuineIntel
cpu family : 6
model      : 63
model name : Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz
stepping   : 2
microcode  : 0x3c
cpu MHz    : 2599.998
cache size : 20480 KB
physical id: 14
siblings   : 1
core id    : 0
cpu cores  : 1
apicid     : 14
initial apicid: 14
fpu        : yes
fpu_exception: yes
cpuid level: 15
wp         : yes
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;event-4&#34;&gt;Event
&lt;/h2&gt;&lt;p&gt;fpu		: yes
fpu_exception	: yes
cpuid level	: 15
wp		: yes
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cpuid_fault epb pti fsgsbase smep xsaveopt cqm_llc cqm_occup_llc dtherm ida arat pln pts&lt;/p&gt;
&lt;h2 id=&#34;events-2&#34;&gt;Events
&lt;/h2&gt;&lt;p&gt;bugs		: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit
bogomips	: 5199.99
clflush size	: 64
cache_alignment	: 64
address sizes	: 40 bits physical, 48 bits virtual
power management:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
## Consulting OpenAI

Initially, let&#39;s consider the core count and base frequency. The Intel(R) Xeon(R) CPU E7-4807 @ 1.87GHz has 6 physical cores and 12 logical cores with a base frequency of 1.87GHz; while the Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz has 8 physical cores and 16 logical cores with a base frequency of 2.60GHz. Therefore, from the perspective of core count and base frequency, the E5-2640 v3 should be more advantageous in single-threaded data processing compared to the E7-4807.

Secondly, regarding cache size, the E7-4807 has a cache size of 12MB, while the E5-2640 v3 has a cache size of 20MB. Consequently, the E5-2640 v3 possesses a larger cache space, which can improve data access speed and cache hit rate.

Finally, concerning architecture, the E5-2640 v3 utilizes a more advanced Haswell architecture, while the E7-4807 employs an older Nehalem architecture.

## Consulting OpenAI

Therefore, considering the overall factors, in a single-threaded loop processing data scenarios, the E5-2640 v3 should outperform the E7-4807. However, specific performance differences will be influenced by various factors including data processing algorithms, memory bandwidth, system load, and so on, requiring analysis based on the specific problem.

## Hardware Specifications
[https://www.cpubenchmark.net/compare/3786.2vs2365.2/%5BDual-CPU%5D-Intel-Xeon-E7–4807-vs-%5BDual-CPU%5D-Intel-Xeon-E5-2640-v3](https://www.cpubenchmark.net/compare/3786.2vs2365.2/%5BDual-CPU%5D-Intel-Xeon-E7–4807-vs-%5BDual-CPU%5D-Intel-Xeon-E5-2640-v3)
| Price | Search Online  $78 - BUY |  |

## Hardware Specifications
| Specification | Xeon E7-4807 (LGA1567) | Xeon E5-2640 v3 (LGA2011-v3) |
|---|---|---|

## Hardware Specifications
| Specification | Xeon E7-4807 (LGA1567) | Xeon E5-2640 v3 (LGA2011-v3) |
|---|---|---|

## Hardware Specifications
| Specification | Xeon E7-4807 (LGA1567) | Xeon E5-2640 v3 (LGA2011-v3) |
|---|---|---|

## Hardware Specifications
| Specification | Xeon E7-4807 (LGA1567) | Xeon E5-2640 v3 (LGA2011-v3) |
|---|---|---|
| Turbo Speed | Not Supported | Up to 3.4 GHz |

## Hardware Specifications
| Specification | Xeon E7-4807 (LGA1567) | Xeon E5-2640 v3 (LGA2011-v3) |
|---|---|---|
| Number of Physical Cores | 6 (Threads: 12) | 8 (Threads: 16) |

## Hardware Specifications
| Specification | Xeon E7-4807 (LGA1567) | Xeon E5-2640 v3 (LGA2011-v3) |
|---|---|---|

## Hardware Specifications
| Specification | Xeon E7-4807 (LGA1567) | Xeon E5-2640 v3 (LGA2011-v3) |
|---|---|---|
| Max TDP | 95W x 2 | 90W x 2 |

## Hardware Specifications
| Specification | Xeon E7-4807 (LGA1567) | Xeon E5-2640 v3 (LGA2011-v3) |
|---|---|---|
| Yearly Running Cost | $34.68 | $32.85 |

## Hardware Specifications
| Specification | Xeon E7-4807 (LGA1567) | Xeon E5-2640 v3 (LGA2011-v3) |
|---|---|---|

## Hardware Specifications
| Specification | Xeon E7-4807 (LGA1567) | Xeon E5-2640 v3 (LGA2011-v3) |
|---|---|---|
| First Seen on Chart | Q3 2020 | Q3 2014 |

## Hardware Specifications
| Specification | Xeon E7-4807 (LGA1567) | Xeon E5-2640 v3 (LGA2011-v3) |
| --- | --- | --- |
| # of Samples | 1 | 46 |

## Hardware Specifications
| Specification | Xeon E7-4807 (LGA1567) | Xeon E5-2640 v3 (LGA2011-v3) |
|---|---|---|
| CPU Value | 69.1 | 225.6 |

## Hardware Specifications
| Specification | Xeon E7-4807 (LGA1567) | Xeon E5-2640 v3 (LGA2011-v3) |
|---|---|---|
| Single Thread Rating | 721 (-59.2%) | 1767 (0.0%) |

## Hardware Specifications
| Specification | Xeon E7-4807 (LGA1567) | Xeon E5-2640 v3 (LGA2011-v3) |
|---|---|---|
| CPU Mark | 6223 (-64.6%) | 17600 (0.0%) |&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Prompt Engineer</title>
        <link>https://ttf248.life/en/p/prompt-engineer/</link>
        <pubDate>Sun, 26 Mar 2023 20:46:53 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/prompt-engineer/</guid>
        <description>&lt;p&gt;Just as we needed to learn the techniques of searching engines back then, we also need to learn some techniques for communicating with &lt;code&gt;AI&lt;/code&gt;, providing reasonable and sufficient constraints, and efficiently obtaining the desired answers.&lt;/p&gt;
&lt;p&gt;If you look at it from a different angle, current &lt;code&gt;AI&lt;/code&gt; is like a very good student with excellent memory – it has the ability to memorize everything. What we need to do is learn how to communicate with &lt;code&gt;AI&lt;/code&gt; correctly, effectively, and precisely describe our needs to help &lt;code&gt;AI&lt;/code&gt; generate the expected results.&lt;/p&gt;
&lt;p&gt;##科普
The incredibly popular &lt;code&gt;AI&lt;/code&gt; – specifically &lt;code&gt;Generative Pre-Training&lt;/code&gt; – literally translates to generative pre-training. It’s a deep learning model that trains text generation based on internet-available data, used for tasks such as question answering, text summarization generation, machine translation, classification, code generation, and conversational AI. Currently, there have been various versions of models like GPT-1, GPT-2, GPT-3, and GPT-4, each larger and more powerful than the previous one.&lt;/p&gt;
&lt;h2 id=&#34;does-it-really-have-intelligence&#34;&gt;Does it Really Have Intelligence?
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Similarity is high, accuracy increases accordingly.&lt;/li&gt;
&lt;li&gt;Basic, repetitive tasks, after specific training, no longer require human intervention.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Generative AI is a technology that utilizes existing data such as text, audio, and images to create new content. It can be used for various tasks including text generation, speech synthesis, image generation, and dialogue systems. The logical reasoning of Generative AI depends on its training data and model structure. Generally, Generative AI can follow grammar, logic, and common sense to a certain extent, but it may also produce errors, biases, or unrealistic content. Therefore, the output of Generative AI requires human judgment and verification; it should not be blindly trusted or used.&lt;/p&gt;
&lt;h2 id=&#34;prompt-engineer&#34;&gt;Prompt Engineer
&lt;/h2&gt;&lt;p&gt;Time flows only forward, and people need to learn to adapt to the current. You can think of &lt;code&gt;AI&lt;/code&gt; as not intelligent, lacking logic, and frequently producing unusable code.&lt;/p&gt;
&lt;p&gt;If you shift your perspective, the current &lt;code&gt;AI&lt;/code&gt; is like a child with excellent memory – it has the ability to memorize after reading something repeatedly, much like copying homework. What we need to do is learn how to communicate correctly, effectively, and with &lt;code&gt;AI&lt;/code&gt;, precisely describing our needs to help &lt;code&gt;AI&lt;/code&gt; generate the desired results.&lt;/p&gt;
&lt;h2 id=&#34;dialogue-patterns&#34;&gt;Dialogue Patterns
&lt;/h2&gt;&lt;p&gt;Two years ago, when GitHub Copilot was released, no one could have imagined that two years later, OpenAI would appear out of nowhere, allowing humans to recognize the capabilities of large language models.&lt;/p&gt;
&lt;p&gt;Based on &lt;strong&gt;comment-based programming&lt;/strong&gt; and &lt;strong&gt;conversational programming&lt;/strong&gt;, the interaction logic is completely different. The dialogue pattern is friendly for novice users, and it’s crucial to mention NewBing providing follow-up prompts after each question. Microsoft is attempting to guide users to obtain more content from the AI knowledge base.&lt;/p&gt;
&lt;h2 id=&#34;lets-illustrate-with-an-example&#34;&gt;Let&amp;rsquo;s illustrate with an example
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Scenario:&lt;/strong&gt; A long high-speed train journey, coding is a good choice. With limited traffic, processing a few images, obtaining image materials, downloading software to process the images is a bit extravagant, and network conditions are not ideal.
&lt;strong&gt;Requirements:&lt;/strong&gt; There’s a batch of image materials with transparent backgrounds that will be used as navigation bars for small programs. The selected state is colored, and the unselected state is black and white. All the materials are in color, and they need to be preprocessed.
&lt;strong&gt;Prompt:&lt;/strong&gt; Write a Python code snippet to read all images from a folder, convert the images to black and white while maintaining the transparent background, save the images, optimize image quality, reduce file size, and simultaneously display the comparison of the file sizes before and after optimization in the console.&lt;/p&gt;
&lt;h2 id=&#34;lets-illustrate-with-an-example-1&#34;&gt;Let&amp;rsquo;s illustrate with an example
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Import necessary libraries
import os
import PIL
from PIL import Image
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;lets-illustrate-with-an-example-2&#34;&gt;Let&amp;rsquo;s illustrate with an example
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Define a function to convert images to black and white, maintain the transparent background, save the image, and return the file size.
def convert_and_save(image_file):
    # Open the image
    image = Image.open(image_file)
    # Get the image mode, if it&#39;s RGBA mode, it means there is a transparent background
    mode = image.mode
    if mode == &amp;quot;RGBA&amp;quot;:
        # Create a white background image with the same size as the image
        background = Image.new(&amp;quot;RGB&amp;quot;, image.size, (255, 255, 255))
        # Paste the original image onto the white background, ignoring transparent pixels
        background.paste(image, mask=image.split()[3])
        # Convert the composite image to grayscale mode
        gray_image = background.convert(&amp;quot;L&amp;quot;)
        # Convert the grayscale image back to RGBA mode to preserve the transparent background
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;lets-illustrate-with-an-example-3&#34;&gt;Let&amp;rsquo;s illustrate with an example
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;gray_image = background.convert(&amp;quot;L&amp;quot;)
        # Convert the grayscale image to RGBA mode to preserve the transparent background
        final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
    else:
        # If it&#39;s not in RGBA mode, directly convert the image to grayscale mode
        final_image = image.convert(&amp;quot;L&amp;quot;)
    # Get the original image file name and extension
    file_name, file_ext = os.path.splitext(image_file)
    # Define the new image file name, adding _bw suffix to indicate black and white
    new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # Save the new image, optimizing quality to reduce file size
    final_image.save(new_file_name, optimize=True)
    # Get the file sizes of the original and new images and return
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;lets-illustrate-with-an-example-4&#34;&gt;Let&amp;rsquo;s illustrate with an example
&lt;/h2&gt;&lt;h1 id=&#34;save-the-new-image-and-optimize-quality-reducing-file-size&#34;&gt;Save the new image and optimize quality, reducing file size
&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;final_image.save(new_file_name, optimize=True)
# Get the file sizes of the original and new images and return them
old_size = os.path.getsize(image_file)
new_size = os.path.getsize(new_file_name)
return old_size, new_size
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Example:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Define a folder path to store all images:
&lt;code&gt;folder_path = &amp;quot;images&amp;quot;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Iterate through all files in the folder:
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for file in os.listdir(folder_path):
  # Construct the full file path
  file_path = os.path.join(folder_path, file)
  # Check if it&#39;s an image file (based on extension; add or modify extensions as needed)
  if file_path.endswith((&amp;quot;.png&amp;quot;, &amp;quot;.jpg&amp;quot;, &amp;quot;.jpeg&amp;quot;, &amp;quot;.gif&amp;quot;)):
    # Call the function to convert and save the image, and get the file size
    old_size, new_size = convert_and_save(file_path)
    # Display the comparison of file sizes before and after optimization in the console
    print(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lets-illustrate-this-with-an-example&#34;&gt;Let&amp;rsquo;s illustrate this with an example:
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;AI&lt;/code&gt; quickly provided the answer, which looked very beautiful and worked well. Experienced program sources would find the following code not generic enough and unable to be deployed to production:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Parameters were fixed&lt;/li&gt;
&lt;li&gt;There were no log files; information was printed to the console&lt;/li&gt;
&lt;li&gt;The image processing task was suitable for a multi-threaded model&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;NewBing&lt;/code&gt; appeared, based on the prompt, selecting a question: &lt;strong&gt;What improvements can be made to this code?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The answer given this time was truly beyond expectations. General optimization measures that most programmers could think of were provided by &lt;code&gt;AI&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;This code may still have some areas for improvement, such as:

You could use the argparse library to allow users to specify the folder path and extension through command-line parameters instead of hardcoding them in the code.
``` You can use the logging library to record the program&#39;s runtime instead of directly printing to the console.
You can use try-except blocks to catch potential exceptions, such as file opening failures or image conversion failures, and handle them appropriately.
You can utilize the multiprocessing library to leverage multi-core processors and accelerate the image conversion and saving processes.

Friendly responses are considered, taking into account differences in the deployment environment and allowing for non-support of multi-processing.

## Let&#39;s illustrate with an example

```shell
Of course, I’m happy to help you modify your code. I added argparse, logging, and try-except statements, but I didn’t add the multiprocessing library because I wasn’t sure if your computer supported multi-core processing. The modified code is as follows:
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;lets-illustrate-with-an-example-5&#34;&gt;Let&amp;rsquo;s illustrate with an example
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Import necessary libraries
import argparse
import logging
import multiprocessing
import os

from PIL import Image
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;lets-illustrate-with-an-example-6&#34;&gt;Let&amp;rsquo;s illustrate with an example
&lt;/h2&gt;&lt;h1 id=&#34;define-a-function-to-convert-images-to-black-and-white-while-maintaining-the-transparent-background-save-the-image-and-return-the-file-size&#34;&gt;Define a function to convert images to black and white while maintaining the transparent background, save the image, and return the file size
&lt;/h1&gt;&lt;p&gt;def convert_and_save(image_file):
# Open the image
try:
image = Image.open(image_file)
except Exception as e:
logging.error(f&amp;quot;Failed to open {image_file}: {e}&amp;quot;)
return None, None
# Get the image mode; if it&amp;rsquo;s RGBA mode, it means there is a transparent background
mode = image.mode
if mode == &amp;ldquo;RGBA&amp;rdquo;:
# Create a white background image with the same size as the image
background = Image.new(&amp;ldquo;RGB&amp;rdquo;, image.size, (255, 255, 255))
# Paste the original image onto the white background, ignoring transparent pixels
background.paste(image, mask=image.split()[3])&lt;/p&gt;
&lt;h2 id=&#34;lets-illustrate-with-an-example-7&#34;&gt;Let&amp;rsquo;s illustrate with an example
&lt;/h2&gt;&lt;h1 id=&#34;paste-the-original-image-onto-a-white-background-ignoring-transparent-pixels&#34;&gt;Paste the original image onto a white background, ignoring transparent pixels:
&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;    background.paste(image, mask=image.split()[3])
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;convert-the-composite-image-to-grayscale-mode&#34;&gt;Convert the composite image to grayscale mode:
&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;    gray_image = background.convert(&amp;quot;L&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;convert-the-grayscale-image-back-to-rgba-mode-to-preserve-the-transparent-background&#34;&gt;Convert the grayscale image back to RGBA mode to preserve the transparent background:
&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;    final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;else:&lt;/p&gt;
&lt;h1 id=&#34;if-its-not-in-rgba-mode-simply-convert-the-image-to-grayscale&#34;&gt;If it&amp;rsquo;s not in RGBA mode, simply convert the image to grayscale:
&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;    final_image = image.convert(&amp;quot;L&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;get-the-original-images-filename-and-extension&#34;&gt;Get the original image&amp;rsquo;s filename and extension:
&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;file_name, file_ext = os.path.splitext(image_file)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;define-the-new-images-filename-adding-_bw-suffix-to-indicate-black-and-white&#34;&gt;Define the new image&amp;rsquo;s filename, adding &amp;ldquo;_bw&amp;rdquo; suffix to indicate black and white:
&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;save-the-new-image-optimizing-quality-to-reduce-file-size&#34;&gt;Save the new image, optimizing quality to reduce file size
&lt;/h1&gt;&lt;h2 id=&#34;lets-illustrate-this-with-an-example-1&#34;&gt;Let&amp;rsquo;s illustrate this with an example
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # Save the new image and optimize quality to reduce file size
    try:
        final_image.save(new_file_name, optimize=True)
    except Exception as e:
        logging.error(f&amp;quot;Failed to save {new_file_name}: {e}&amp;quot;)
        return None, None
    # Get the file sizes of the original and new images and return them
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return file_name, old_size, new_size
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;lets-illustrate-with-an-example-8&#34;&gt;Let&amp;rsquo;s illustrate with an example
&lt;/h2&gt;&lt;h1 id=&#34;define-a-function-to-parse-command-line-arguments-and-return-a-list-of-folder-paths-and-file-extensions&#34;&gt;Define a function to parse command-line arguments and return a list of folder paths and file extensions.
&lt;/h1&gt;&lt;p&gt;def parse_args():
# Create a parser object
parser = argparse.ArgumentParser(description=&amp;ldquo;Convert images to black and white and optimize quality.&amp;rdquo;)
# Add a required positional argument to represent the folder path
parser.add_argument(&amp;ldquo;folder_path&amp;rdquo;, help=&amp;ldquo;The path of the folder that contains the images.&amp;rdquo;)
# Add an optional argument to represent the list of extensions, defaulting to png, jpg, jpeg and gif
parser.add_argument(&amp;quot;-e&amp;quot;, &amp;ldquo;&amp;ndash;extensions&amp;rdquo;, nargs=&amp;quot;+&amp;quot;, default=[&amp;quot;.png&amp;quot;, &amp;ldquo;.jpg&amp;rdquo;, &amp;ldquo;.jpeg&amp;rdquo;, &amp;ldquo;.gif&amp;rdquo;], help=&amp;ldquo;The extensions of the image files.&amp;rdquo;)
# Parse command-line arguments and return the result object&lt;/p&gt;
&lt;h2 id=&#34;lets-illustrate-this-with-an-example-2&#34;&gt;Let&amp;rsquo;s illustrate this with an example
&lt;/h2&gt;&lt;h1 id=&#34;parse-command-line-arguments-and-return-the-result-object&#34;&gt;Parse command-line arguments and return the result object
&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;args = parser.parse_args()
return args.folder_path, args.extensions
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;lets-illustrate-with-an-example-9&#34;&gt;Let&amp;rsquo;s illustrate with an example
&lt;/h2&gt;&lt;h1 id=&#34;define-a-function-to-print-the-comparison-of-file-sizes-before-and-after-optimization&#34;&gt;Define a function to print the comparison of file sizes before and after optimization
&lt;/h1&gt;&lt;p&gt;def print_result(result):
# If the result is not empty, it indicates that the conversion and saving were successful
if result:
# Unpack the result into a tuple of filename and file size
if len(result) == 3:
file, old_size, new_size = result
# Display the comparison of file sizes before and after optimization in the console
logging.info(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)
else:
logging.info(f&amp;quot;{result}&amp;quot;)&lt;/p&gt;
&lt;h2 id=&#34;lets-illustrate-with-an-example-10&#34;&gt;Let&amp;rsquo;s illustrate with an example
&lt;/h2&gt;&lt;h1 id=&#34;configure-the-logger-to-output-logs-to-both-the-console-and-files-setting-the-log-level-to-info&#34;&gt;Configure the logger to output logs to both the console and files, setting the log level to INFO
&lt;/h1&gt;&lt;p&gt;logging.basicConfig(level=logging.INFO,
format=&amp;quot;%(asctime)s %(levelname)s %(message)s&amp;quot;,
handlers=[logging.StreamHandler(),
logging.FileHandler(&amp;ldquo;log.txt&amp;rdquo;)])&lt;/p&gt;
&lt;h1 id=&#34;call-the-function-to-get-the-folder-path-and-extension-list&#34;&gt;Call the function to get the folder path and extension list
&lt;/h1&gt;&lt;p&gt;folder_path, extensions = parse_args()&lt;/p&gt;
&lt;h2 id=&#34;lets-illustrate-with-an-example-11&#34;&gt;Let&amp;rsquo;s illustrate with an example
&lt;/h2&gt;&lt;h1 id=&#34;calling-a-function-to-get-the-folder-path-and-extension-list&#34;&gt;Calling a function to get the folder path and extension list
&lt;/h1&gt;&lt;p&gt;folder_path, extensions = parse_args()&lt;/p&gt;
&lt;p&gt;if &lt;strong&gt;name&lt;/strong&gt; == &amp;ldquo;&lt;strong&gt;main&lt;/strong&gt;&amp;rdquo;:
# Windows needs this function because Windows lacks the fork() function (this is not entirely accurate).
# Therefore, on Windows, fork() is simulated by creating a new process. The code running in this new process, which is what runs in the child process on Linux,
# Because this code must run in unrelated processes, it must be passed to them before execution.
# The way to pass it is to serialize it first and then send it through a pipe from the original process to the new process.
# Furthermore, the new process is notified that it must execute the code passed through the pipe by passing the &amp;ndash;multiprocessing-fork command line parameter to it.&lt;/p&gt;
&lt;h2 id=&#34;lets-illustrate-with-an-example-12&#34;&gt;Let&amp;rsquo;s illustrate with an example
&lt;/h2&gt;&lt;h1 id=&#34;create-a-process-pool-automatically-assigning-processes-based-on-the-number-of-computer-cores&#34;&gt;Create a process pool, automatically assigning processes based on the number of computer cores
&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;pool = multiprocessing.Pool()
# Create an empty list to store the result objects of asynchronous tasks
results = []
# Iterate through all files in the folder
for file in os.listdir(folder_path):
    # Construct the full file path
    file_path = os.path.join(folder_path, file)
    # Check if it&#39;s an image file, judging by the extension (you can modify the list of extensions as needed)
    if any(file_path.endswith(ext) for ext in extensions):
        # Call the function to convert and save the image, getting the file size, using asynchronous mode without blocking the main process
        result = pool.apply_async(convert_and_save, args=(file_path,), callback=print_result)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;lets-illustrate-with-an-example-13&#34;&gt;Let&amp;rsquo;s illustrate with an example
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;result = pool.apply_async(convert_and_save, args=(file_path,), callback=print_result)
            # Add the result object to the list
            results.append((file, result))
    # Close the process pool, no longer accepting new tasks
    pool.close()
    # Wait for all tasks to complete
    pool.join()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;Due to local development being on a &lt;code&gt;windows&lt;/code&gt; system, the first answer given by &lt;code&gt;AI&lt;/code&gt; did not include the &lt;code&gt;main&lt;/code&gt; function and also lacked &lt;code&gt;multiprocessing.freeze_support&lt;/code&gt;. The code was fixed after following up and encountering an error.
Just as learning the techniques of search engines required skill, we also need to learn how to communicate with &lt;code&gt;AI&lt;/code&gt;, providing reasonable and sufficient constraints to efficiently obtain the desired answers.
Note: &lt;strong&gt;If you are a programming beginner, if you still don&amp;rsquo;t understand certain parts of the code based on the given comments, please continue to ask related questions.&lt;/strong&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>WeChat Mini Program Background and Development Environment</title>
        <link>https://ttf248.life/en/p/wechat-mini-program-background-and-development-environment/</link>
        <pubDate>Fri, 24 Mar 2023 21:59:11 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/wechat-mini-program-background-and-development-environment/</guid>
        <description>&lt;p&gt;WeChat Mini Program Introduction and Development Preparation&lt;/p&gt;
&lt;h2 id=&#34;why-mini-programs-exist&#34;&gt;Why Mini Programs Exist
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Better Experience:&lt;/strong&gt; Slow web loading and blank screens; native app experience is faster.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Standards &amp;amp; Management:&lt;/strong&gt; For WeChat, it’s about access and management. Before mini programs were released, WeChat published an SDK called &lt;code&gt;Jssdk&lt;/code&gt; which opened up parts of the original WeChat capabilities: WeChat Pay, coupons. However, developers used web development languages to implement logic, bypassing some WeChat regulations. Mini Programs have their own dedicated description language.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-are-mini-programs&#34;&gt;What are Mini Programs?
&lt;/h2&gt;&lt;p&gt;Mini programs are applications that can be used without needing to download and install them. They realize the dream of having applications &lt;strong&gt;within easy reach&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Users can simply scan a QR code or search for an application to open it, which also embodies the concept of &lt;strong&gt;use-it-and-leave-it&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Users don’t have to worry about installing too many apps. Applications will be ubiquitous and available at any time, but &lt;strong&gt;without needing to install or uninstall&lt;/strong&gt; them.&lt;/p&gt;
&lt;h2 id=&#34;differences-between-mini-programs-and-mobile-applications&#34;&gt;Differences Between Mini Programs and Mobile Applications
&lt;/h2&gt;&lt;p&gt;No installation required, doesn’t occupy memory, easy to spread: QR code scanning, mini program cards, Search One Search (Sohu Search)&lt;/p&gt;
&lt;h2 id=&#34;what-mini-programs-can-do&#34;&gt;What Mini Programs Can Do
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Content Tools: Zhihu Hot Rankings, Weibo Hot Topics, Mobike Bikes, Today Headline, Tencent Maps, Tencent Translate&lt;/li&gt;
&lt;li&gt;Retail: Pinduoduo, JD Shopping, Mugujie, Daily Youxiansheng, Xiaomi Mall, Watsons&lt;/li&gt;
&lt;li&gt;Games: Jump Rope, Happy Mahjong, Happy Mahjong, Douyu Live Streaming, YY Live Streaming&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Course content is from 2018. Some application vendors have already gone bankrupt now.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;development-preparation&#34;&gt;Development Preparation
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Register a Mini Program Account: Simply fill in the information normally, and click the activation link on the email.&lt;/li&gt;
&lt;li&gt;Information Registration&lt;/li&gt;
&lt;li&gt;Log into the Mini Program Management Backstage&lt;/li&gt;
&lt;li&gt;Complete Mini Program Information&lt;/li&gt;
&lt;li&gt;Bind Developer: For individual developers, the administrator account is the logged-in WeChat account, and no additional binding operations are required.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Email has certain restrictions, requiring a new email; however, a QQ email can be applied with an alias, and the WeChat background will not verify it. After trying it out, the name of the mini program is quite troublesome. As soon as it involves trademarks, it’s prone to audit failure.&lt;/p&gt;
&lt;p&gt;Service categories can be selected and customized, and a Mini Program can add five categories.&lt;/p&gt;
&lt;p&gt;In the Settings section, you can view the Mini Program&amp;rsquo;s &lt;code&gt;ID&lt;/code&gt; information and also enable message push; with message push enabled, you can use the Message Template function.&lt;/p&gt;
&lt;h2 id=&#34;developer-tools-as-described-by-the-author&#34;&gt;Developer Tools (as described by the author)
&lt;/h2&gt;&lt;p&gt;Normal download and installation, with no special considerations – just a basic understanding. Simply enter in Guest Mode, and if you want to enable mobile debugging (i.e., view the mini-program development version on your phone), you need to log into the mini-program developer account, then click Settings, and switch to the specified mini-program’s &lt;code&gt;ID&lt;/code&gt; within Project Details.&lt;/p&gt;
&lt;h2 id=&#34;code-structure&#34;&gt;Code Structure
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;js: Interaction logic&lt;/li&gt;
&lt;li&gt;json: Data configuration&lt;/li&gt;
&lt;li&gt;wxml: UI elements&lt;/li&gt;
&lt;li&gt;wxss: UI styles&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Office migration, the servers are inaccessible.</title>
        <link>https://ttf248.life/en/p/office-move-server-inaccessible/</link>
        <pubDate>Sat, 11 Mar 2023 01:42:05 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/office-move-server-inaccessible/</guid>
        <description>&lt;p&gt;Administrative notice, office relocation from the second floor to the fifteenth floor – a standard, routine move of an individual workstation.&lt;/p&gt;
&lt;h2 id=&#34;design-sense&#34;&gt;Design Sense
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/office-move-server-inaccessible/20230311014537.png&#34;
	width=&#34;511&#34;
	height=&#34;916&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Office Building&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;55&#34;
		data-flex-basis=&#34;133px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;migration&#34;&gt;Migration
&lt;/h2&gt;&lt;p&gt;Closing up shop, packing everything away, a familiar route, a new workstation – adjusting computer cabling, finding a comfortable posture to start working.
(ÒωÓױ)! – Connecting the network cable, accessing the servers frequently used by the team, but it was inaccessible. I tried switching to wireless networking, and access became normal again. Initially, I thought it was a problem with the server’s IP address settings, the wired network at the new workstation wasn&amp;rsquo;t included in the firewall configuration, so adjusting it solved the issue; this subnet isn’t just one server – when trying to access other servers, they were all working normally. Gradually, confusion arose? Let professional people handle professional matters, and finally, a colleague from the operations department pinpointed the cause: This server was deployed with &lt;code&gt;docker&lt;/code&gt;, and the default network of the &lt;code&gt;docker0&lt;/code&gt; service conflicted with the wired network configuration of the office, causing data packets sent to it not to receive responses and being routed to the &lt;code&gt;docker&lt;/code&gt; service. Other servers didn’t deploy &lt;code&gt;docker&lt;/code&gt; services, so I use this one more frequently. Occasionally, I use containers to deploy some test services, and I didn&amp;rsquo;t expect to encounter this scenario. Looking back, considering the entire group is located in a single office building, it’s not strange that IT colleagues divided network segments using addresses starting with &lt;code&gt;172&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;docker0&#34;&gt;docker0
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# vim /etc/docker/daemon.json
{
    &amp;quot;bip&amp;quot;:&amp;quot;172.200.0.1/24&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Restart the service and switch to the new network; the server recovers normal access.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://yeasy.gitbook.io/docker_practice/advanced_network/docker0&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Docker From Beginner to Advanced - docker0&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Embedded Systems – Getting Started Part 1 – Technical Terms</title>
        <link>https://ttf248.life/en/p/embedded-entry-professional-terms/</link>
        <pubDate>Tue, 07 Mar 2023 13:42:36 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/embedded-entry-professional-terms/</guid>
        <description>&lt;p&gt;Here’s the English translation:&lt;/p&gt;
&lt;p&gt;“When I think of embedded systems, my mind immediately goes back to the 51 single-chip microcomputers and Texas Instruments we used in university labs.&lt;/p&gt;
&lt;p&gt;LPA3399Pro is a visual host developed on the HiSilicon RK3399Pro platform, designed for portable computing hosts that require extensive visual computation. It features an integrated NPU compute unit with 3.0 TOPS of processing power and supports various algorithm models.&lt;/p&gt;
&lt;p&gt;RV1109 is HiSilicon’s SoC for machine vision within its AI branch, featuring a standalone NPU. RV1109 provides 1TOPS of processing power.”&lt;/p&gt;
&lt;h2 id=&#34;system-on-chip&#34;&gt;System on Chip
&lt;/h2&gt;&lt;p&gt;SoC is an abbreviation for System on a Chip, meaning “system on a chip.” It’s a technology that integrates multiple electronic systems onto a single chip. This technology can significantly reduce the size and weight of electronic products while simultaneously improving performance and reducing power consumption.&lt;/p&gt;
&lt;p&gt;SoC (System on a Chip) and CPU (Central Processing Unit) are both important components of computer systems, but they have some differences between them.&lt;/p&gt;
&lt;p&gt;The CPU is the core processor in a computer system, responsible for executing program instructions. It typically only contains basic components such as arithmetic logic units, control units, and registers.&lt;/p&gt;
&lt;p&gt;SoC, on the other hand, integrates multiple electronic systems onto a single chip, including a CPU, as well as other components like memory, graphics processors, and input/output interfaces. This can significantly reduce the size and weight of electronic products while simultaneously improving performance and reducing power consumption. In essence, a CPU is a component of an SoC, while an SoC is a more complex and highly integrated electronic system.&lt;/p&gt;
&lt;h2 id=&#34;microcontroller-unit&#34;&gt;Microcontroller Unit
&lt;/h2&gt;&lt;p&gt;SoC (System on a Chip) and MCU (Microcontroller Unit) are technologies that integrate multiple electronic systems onto a single chip, but there are also some distinctions between them.&lt;/p&gt;
&lt;p&gt;An MCU is a microcontroller, typically containing a CPU, memory, input/output interfaces, and other basic components. It’s commonly used to control other electronic devices such as household appliances or automotive electronics systems.&lt;/p&gt;
&lt;p&gt;An SoC, on the other hand, integrates more electronic systems onto a single chip, in addition to the basic components of an MCU, it can also integrate other components like graphics processors and wireless communication modules. This significantly reduces the size and weight of electronic products while improving performance and reducing power consumption.&lt;/p&gt;
&lt;p&gt;In essence, an MCU is a simple microcontroller, whereas an SoC is a more complex and highly integrated electronic system.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>AI-assisted programming, the evolution of productivity</title>
        <link>https://ttf248.life/en/p/ai-assisted-programming-productivity-evolution/</link>
        <pubDate>Tue, 28 Feb 2023 17:05:17 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/ai-assisted-programming-productivity-evolution/</guid>
        <description>&lt;p&gt;“GitHub Copilot” was released less than two years ago, and “ChatGPT” has appeared. I don’t fully understand the underlying principles; I&amp;rsquo;ve been using them for a while. The two tools’ levels of assistance are completely different, but they have both achieved a significant increase in productivity.&lt;/p&gt;
&lt;p&gt;For things that are too complex, AI still can’t do it – after all, they lack logic, or they rely on patterns or fixed frameworks; the training data is sufficient, and AI’s effect is nine out of ten.&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;GitHub Copilot
&lt;/h2&gt;&lt;p&gt;When publishing, I looked at the official introduction’s “demo” and found it wasn&amp;rsquo;t very smart. After trying it out, it wasn’t great, so I gave up on it.&lt;/p&gt;
&lt;p&gt;Before 2022, when I had some free time, I switched to the new version to try it out, and the effect was already quite good. The only issue was that the speed in China was a bit slow, which was probably due to network reasons. For languages like &lt;code&gt;Python&lt;/code&gt;, the code generated based on comments was pretty good, and much faster than researching and writing code myself.&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;Github Copilot&lt;/code&gt; still focused on developers, i.e., from a development perspective when designing the product. You need to understand how programming works and guide AI assistance through comments gradually. &lt;code&gt;ChatGPT&lt;/code&gt; has moved to the next level, &lt;strong&gt;allowing non-experts to quickly get started&lt;/strong&gt;. With its conversational chat interface, you can simply pose questions, describe requirements, and ask for clarification if you don&amp;rsquo;t understand something. Here’s a translation of the provided text into English:&lt;/p&gt;
&lt;p&gt;“Let&amp;rsquo;s take an example to understand the concept of tokenization, but don&amp;rsquo;t know how to code it. We want to calculate the similarity between two strings:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Python tokenize and calculate the similarity between &amp;quot;Weitian Yuntong&amp;quot;, &amp;quot;LOGORY&amp;quot; and &amp;quot;Hefei Weitian Yuntong Information Technology Co., Ltd.&amp;quot;;
Before comparison, standardize the strings by converting English to lowercase;
If the second string contains the first string&#39;s starting character, truncate the second string to a length equal to the first string’s length.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hello, this is Bing. 😊&lt;/p&gt;
&lt;p&gt;According to online information 123, Python tokenization can be implemented using the jieba library. The jieba library supports three tokenization modes: precise mode, full-potential mode, and search engine mode. You can choose an appropriate mode based on your needs.” To compare the similarity of two strings, you first need to tokenize them and then calculate metrics such as word vectors or edit distance. You can use libraries like NumPy or SciPy for performing mathematical operations.&lt;/p&gt;
&lt;h2 id=&#34;chatgpt-1&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;To standardize string processing, converting to lowercase in English can be achieved using Python&amp;rsquo;s built-in &lt;code&gt;lower()&lt;/code&gt; function.
To extract the second string, you can use Python’s slicing operator [ ] to achieve this.
Below is a possible code example:&lt;/p&gt;
&lt;h2 id=&#34;chatgpt-2&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import jieba
import numpy as np
from scipy.spatial.distance import cosine

# Define two strings
str1 = &amp;quot;維天運通 LOGORY&amp;quot;
str2 = &amp;quot;合肥維天運通信息科技股份有限公司&amp;quot;

# Normalize strings, convert English to lowercase
str1 = str1.lower()
str2 = str2.lower()

# Find the position of the first character of str1 in str2
index = str2.find(str1[0])

# If found, slice str2
if index != -1:
    str2 = str2[index:index+len(str1)]

# Use jieba library to tokenize strings
words1 = list(jieba.cut(str1))
words2 = list(jieba.cut(str2))

# Calculate word vectors (using frequency as weights)
vector1 = np.zeros(len(words1))
vector2 = np.zeros(len(words1))
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;chatgpt-3&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;h1 id=&#34;calculate-the-word-vectors-of-two-strings-with-frequency-as-weight&#34;&gt;Calculate the word vectors of two strings (with frequency as weight)
&lt;/h1&gt;&lt;p&gt;vector1 = np.zeros(len(words1))
vector2 = np.zeros(len(words1))&lt;/p&gt;
&lt;p&gt;for i, word in enumerate(words1):
vector1[i] += 1  # Count the number of times each word appears in the first string
if word in words2:
vector2[i] += 1  # Count the number of times each word appears in the second string&lt;/p&gt;
&lt;h1 id=&#34;calculate-the-similarity-between-the-two-strings-using-cosine-distance-as-an-index&#34;&gt;Calculate the similarity between the two strings (using cosine distance as an index)
&lt;/h1&gt;&lt;p&gt;similarity = 1 - cosine(vector1, vector2)&lt;/p&gt;
&lt;p&gt;print(&amp;ldquo;The similarity between the two strings is:&amp;rdquo;, similarity)&lt;/p&gt;
&lt;h2 id=&#34;chatgpt-4&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Going Further – Consult the Execution Results. Congratulations, you’ve identified an issue! The result was hallucinated; it didn&amp;rsquo;t actually run the code, but will provide a good-looking response.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;example&#34;&gt;Example
&lt;/h3&gt;&lt;p&gt;Question: SQL statement to retrieve records from the product code table where the product code is within the range of 80000-89999.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;Hello, this is Bing. 😊

Based on search result 12, you can use the SQL BETWEEN operator to select values within a given range. The BETWEEN operator includes both the start and end values.

You need to first specify the table name and column name that you want to query, and then use the BETWEEN operator and the range values in the WHERE clause.

For example, if you want to retrieve records from the product code table where the product code is between 80000 and 89999, you can use the following statement:

SELECT * FROM product_code
WHERE code BETWEEN 80000 AND 89999;
Here, * represents selecting all columns 3.
``` If you only want to select specific columns, such as product name and price, you can separate them with commas like this:

SELECT name, price FROM product_code
WHERE code BETWEEN 80000 AND 89999;

Hopefully, this helps.

Please note that product codes are strings, and your code is incorrect.

### Example

```markdown
Sorry, I didn’t realize the product code was a string. If that’s the case, you need to add single quotes around both ends of the range values, as follows:

SELECT * FROM product_code
WHERE code BETWEEN &#39;80000&#39; AND &#39;89999&#39;;
Please forgive my mistake. 🙏
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Congratulations, it recognizes errors!&lt;/p&gt;
</description>
        </item>
        <item>
        <title>A Collection of Less Commonly Used Git Commands</title>
        <link>https://ttf248.life/en/p/less-common-git-commands-summary/</link>
        <pubDate>Fri, 17 Feb 2023 10:08:57 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/less-common-git-commands-summary/</guid>
        <description>&lt;p&gt;Less commonly used, but very useful &lt;code&gt;git&lt;/code&gt; commands&lt;/p&gt;
&lt;h3 id=&#34;reinstalling-the-system-caused-changes-to-folder-ownership-on-windows&#34;&gt;Reinstalling the system caused changes to folder ownership on &lt;code&gt;Windows&lt;/code&gt;.
&lt;/h3&gt;&lt;p&gt;The new version of &lt;code&gt;git&lt;/code&gt; has added security checks, prompting an unsafe state and preventing further operation.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git config --global --add safe.directory
git config --global --add safe.directory &amp;quot;*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;new-computer-saving-account-password-information&#34;&gt;New Computer Saving Account Password Information
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git config --global credential.helper store
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the saved information needs to be updated, first clear out the old credentials&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git config --system --unset credential.helper
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>- Compiler
- Callback Function
- Performance Testing</title>
        <link>https://ttf248.life/en/p/compiler-callback-performance-testing/</link>
        <pubDate>Wed, 15 Feb 2023 13:59:25 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/compiler-callback-performance-testing/</guid>
        <description>&lt;ul&gt;
&lt;li&gt;Last year, an SDK was designed to handle encapsulating certain events and provide a class interface externally. During service initialization, the caller implements the corresponding classes and passes the object pointer to the module.&lt;/li&gt;
&lt;li&gt;Familiarity with C11 piqued my curiosity, leading me to explore what would happen if these interfaces were implemented using lambda function objects instead of pure virtual function definitions. Compared to the traditional interface definition method, it seemed more flexible.&lt;/li&gt;
&lt;li&gt;The question arose: with two different syntaxes, which one is faster from a performance perspective? Not understanding compiler principles, I decided to try out some code to find out.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction
&lt;/h2&gt;&lt;p&gt;Online website, allowing you to select different compilers, compilation parameters, run code on the &lt;code&gt;linux&lt;/code&gt; platform, or view corresponding assembly code.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt; : Sometimes useful for technical verification; executing small snippets of code in a web browser is very convenient.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://godbolt.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://godbolt.org/&lt;/a&gt; : Using different colors to distinguish the corresponding assembly code for each line, it’s more convenient than using a local debugger.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;body&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;The Standards Committee established grammatical rules, and how these are implemented at the compilation level depends on each compiler vendor. It’s worth noting here that Microsoft&amp;rsquo;s compiler is quite powerful. Syntactic sugar isn’t a panacea; callback interfaces aren’t abundant, using &lt;code&gt;lambda&lt;/code&gt; expressions is more convenient and eliminates the need to define empty callback function interfaces. When callback interfaces become numerous, traditional virtual functions are advantageous for unifying business interface definitions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On the &lt;code&gt;windows&lt;/code&gt; platform, performance is nearly identical, with little difference.&lt;/li&gt;
&lt;li&gt;On the &lt;code&gt;linux&lt;/code&gt; platform, a comparison of virtual functions versus &lt;code&gt;lambda&lt;/code&gt; reveals a 1.35ns overhead in one instance.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In typical business system development, this level of performance degradation can be ignored; introducing &lt;code&gt;lambda&lt;/code&gt; brings more convenience to the design. This is particularly noticeable when dealing with multi-signal processing, where underlying event triggers are used, and functions are needed to handle log entries for input objects. When more business processing interfaces are needed, the underlying layer uses &lt;code&gt;vector&lt;/code&gt; to store &lt;code&gt;lambda&lt;/code&gt; objects. When an event is triggered, it iterates through them sequentially and calls them one by one, similar to Qt&amp;rsquo;s signals and slots. Logging, monitoring, Business 1, and Business 2 are completely decoupled from each other.&lt;/p&gt;
&lt;h2 id=&#34;code&#34;&gt;Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Counter: 1000000
Time: 3966us
Counter: 1000000
Time: 5316us
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;code-1&#34;&gt;Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;memory&amp;gt;
#include &amp;lt;functional&amp;gt;
#include &amp;lt;atomic&amp;gt;
#include &amp;lt;string&amp;gt;

std::atomic_int64_t counter = 0;

// Define callback interface
class UserInterface
{
public:
    virtual void name() = 0;
    virtual void full_name() = 0;
};

class User : public UserInterface
{
public:
    void name() {}
    void full_name() { counter++; }
};

void to_string(UserInterface* user)
{
    user-&amp;gt;name();
    user-&amp;gt;full_name();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Code
void to_string(UserInterface* user)
{
    user-&amp;gt;name();
    user-&amp;gt;full_name();
}

using name_handler = std::function&amp;lt;void()&amp;gt;;
using full_name_handler = std::function&amp;lt;void()&amp;gt;;

class Test
{
    name_handler name_;
    full_name_handler full_name_;

public:
    void set_name_handler(name_handler name)
    {
        name_ = name;
    }

    void set_full_name_handler(full_name_handler full_name)
    {
        full_name_ = full_name;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Code
void to_string() {
    name_();
    full_name_();
}
};

int main() {
    User user;

    auto start = std::chrono::high_resolution_clock::now();

    for (int i = 0; i &amp;lt; 1000000; i++) {
        to_string(&amp;amp;user);
    }

    auto end = std::chrono::high_resolution_clock::now();
    std::cout &amp;lt;&amp;lt; &amp;quot;Counter: &amp;quot; &amp;lt;&amp;lt; counter &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;Time: &amp;quot; &amp;lt;&amp;lt; std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(end - start).count() &amp;lt;&amp;lt; &amp;quot;us&amp;quot; &amp;lt;&amp;lt; std::endl;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Code
counter = 0;
auto name = []() {};
auto full_name = []() { counter++; };

Test test;
test.set_name_handler(name);
test.set_full_name_handler(full_name);

start = std::chrono::high_resolution_clock::now();

for (int i = 0; i &amp;lt; 1000000; i++)
{
    test.to_string();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;string&amp;gt;

int main() {
  auto start = std::chrono::high_resolution_clock::now();
  int counter = 0;

  for (int i = 0; i &amp;lt; 1000000; i++)
    {
        std::string test = &amp;quot;&amp;quot;;
    }

  auto end = std::chrono::high_resolution_clock::now();
  std::cout &amp;lt;&amp;lt; &amp;quot;Counter: &amp;quot; &amp;lt;&amp;lt; counter &amp;lt;&amp;lt; std::endl;
  std::cout &amp;lt;&amp;lt; &amp;quot;Time: &amp;quot; &amp;lt;&amp;lt; std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(end - start).count() &amp;lt;&amp;lt; &amp;quot;us&amp;quot; &amp;lt;&amp;lt; std::endl;

  return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;While researching, I came across similar code snippets &lt;a class=&#34;link&#34; href=&#34;https://gist.githubusercontent.com/benloong/8050171/raw/fa577ec923b460862078b8b40233a42a1c619eeb/functionperformance.cpp&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;functionperformance.cpp&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;epilogue-1&#34;&gt;Epilogue
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;memory&amp;gt;
#include &amp;lt;functional&amp;gt;

using namespace std;
using namespace std::chrono;

class Base
{
public:
    Base(){}
    virtual ~Base(){}
    virtual int func(int i) = 0;
};

class Derived : public Base
{
public:
    Derived(int base = 10) : base{base}
    {

    }
    ~Derived(){}

    virtual int func(int i)
    {
        return i*base;
    }
private:
    int base;
};

struct Func
{
    int base;
    int operator()(int i)
    {
        return i*base;
    }
    Func(int base) : base {base}
    {
    }
};
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;epilogue-2&#34;&gt;Epilogue
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;// Note: This is a translated version of the C++ code snippet.  The original Chinese text was &amp;quot;后记&amp;quot;.

int calculate(int i)
{
	return 10 * i;
}

int main()
{
	const int num = 10000;
	Base *p = new Derived{10};
	int total = 0;
	auto start = high_resolution_clock::now();
	for (int i = 0; i &amp;lt; num; ++i)
	{
		total += p-&amp;gt;func(i);
	}
	auto end = high_resolution_clock::now();
	std::cout&amp;lt;&amp;lt;&amp;quot;result: &amp;quot;&amp;lt;&amp;lt;total&amp;lt;&amp;lt;&amp;quot;\nvirtual call elapsed: \t&amp;quot;&amp;lt;&amp;lt;duration_cast&amp;lt;nanoseconds&amp;gt;(end-start).count()&amp;lt;&amp;lt;&amp;quot; nanoseconds.\n&amp;quot;&amp;lt;&amp;lt;std::endl;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;epilogue-3&#34;&gt;Epilogue
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;total = 0;
    start = high_resolution_clock::now();
    for (int i = 0; i &amp;lt; num; ++i)
    {
        total += calculate(i);
    }
    end = high_resolution_clock::now();
    std::cout &amp;lt;&amp;lt; &amp;quot;result: &amp;quot; &amp;lt;&amp;lt; total &amp;lt;&amp;lt; &amp;quot;\n&amp;quot;
              &amp;lt;&amp;lt; &amp;quot;direct function call elapsed: \t&amp;quot; &amp;lt;&amp;lt; duration_cast&amp;lt;nanoseconds&amp;gt;(end - start).count() &amp;lt;&amp;lt; &amp;quot; nanoseconds.\n&amp;quot;
              &amp;lt;&amp;lt; std::endl;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;epilogue-4&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;Func functor{10};
total = 0;
start = high_resolution_clock::now();
for (int i = 0; i &amp;lt; num; ++i)
{
total += functor(i);
}
end = high_resolution_clock::now();
std::cout&amp;laquo;&amp;ldquo;result: &amp;ldquo;&amp;laquo;total&amp;laquo;&amp;quot;\nfunctor call elapsed: \t&amp;rdquo;&amp;laquo;duration_cast&lt;nanoseconds&gt;(end-start).count()&amp;laquo;&amp;rdquo; nanoseconds.\n&amp;quot;&amp;laquo;std::endl;
int base = 10;
function&amp;lt;int(int)&amp;gt; lambda = [base](int i)
{
return i*base;
};
total = 0;
start = high_resolution_clock::now();
for (int i = 0; i &amp;lt; num; ++i)
{
total += lambda(i);
}&lt;/p&gt;
&lt;h2 id=&#34;epilogue-5&#34;&gt;Epilogue
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;auto start = high_resolution_clock::now();
    for (int i = 0; i &amp;lt; num; ++i)
    {
        total += lambda(i);
    }
    auto end = high_resolution_clock::now();
    std::cout &amp;lt;&amp;lt; &amp;quot;result: &amp;quot; &amp;lt;&amp;lt; total &amp;lt;&amp;lt; &amp;quot;\nlambda call elapsed: \t&amp;quot; &amp;lt;&amp;lt; duration_cast&amp;lt;nanoseconds&amp;gt;(end - start).count() &amp;lt;&amp;lt; &amp;quot; nanoseconds.\n&amp;quot; &amp;lt;&amp;lt; std::endl;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;epilogue-6&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;/*
test on mac mini i7 2.7GHz
clang++ -std=c++11 chronotest.cpp -O0
output:
result: 499950000
virtual call elapsed: 	43171 nanoseconds.&lt;/p&gt;
&lt;p&gt;result: 499950000
direct function call elapsed: 	31379 nanoseconds.&lt;/p&gt;
&lt;p&gt;result: 499950000
functor call elapsed: 	41497 nanoseconds.&lt;/p&gt;
&lt;h1 id=&#34;lambda-call-elapsed-207416-nanoseconds&#34;&gt;result: 499950000
lambda call elapsed: 	207416 nanoseconds.
&lt;/h1&gt;&lt;p&gt;clang++ -std=c++11 chronotest.cpp -O1
output:
result: 499950000
virtual call elapsed: 	26144 nanoseconds.&lt;/p&gt;
&lt;h2 id=&#34;epilogue-7&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;result: 499950000
direct function call elapsed: 	22384 nanoseconds.&lt;/p&gt;
&lt;p&gt;result: 499950000
functor call elapsed: 	33477 nanoseconds.&lt;/p&gt;
&lt;h1 id=&#34;lambda-call-elapsed-55799-nanoseconds&#34;&gt;result: 499950000
lambda call elapsed: 	55799 nanoseconds.
&lt;/h1&gt;&lt;p&gt;clang++ -std=c++11 chronotest.cpp -O2
result: 499950000
virtual call elapsed: 	22284 nanoseconds.&lt;/p&gt;
&lt;p&gt;result: 499950000
direct function call elapsed: 	36 nanoseconds.&lt;/p&gt;
&lt;p&gt;result: 499950000
functor call elapsed: 	30 nanoseconds.&lt;/p&gt;
&lt;h2 id=&#34;epilogue-8&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;result: 499950000
functor call elapsed: 	30 nanoseconds.&lt;/p&gt;
&lt;p&gt;result: 499950000
lambda call elapsed: 	28292 nanoseconds.&lt;/p&gt;
&lt;p&gt;===================================================
clang++ -std=c++11 chronotest.cpp -O3
result: 499950000
virtual call elapsed: 	18975 nanoseconds.&lt;/p&gt;
&lt;p&gt;result: 499950000
direct function call elapsed: 	29 nanoseconds.&lt;/p&gt;
&lt;p&gt;result: 499950000
functor call elapsed: 	30 nanoseconds.&lt;/p&gt;
&lt;h2 id=&#34;epilogue-9&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;result: 499950000
functor call elapsed: 30 nanoseconds.&lt;/p&gt;
&lt;h1 id=&#34;lambda-call-elapsed-22542-nanoseconds&#34;&gt;result: 499950000
lambda call elapsed: 22542 nanoseconds.
&lt;/h1&gt;&lt;p&gt;clang++ -std=c++11 chronotest.cpp -O4&lt;/p&gt;
&lt;p&gt;result: 499950000
virtual call elapsed: 22141 nanoseconds.&lt;/p&gt;
&lt;p&gt;result: 499950000
direct function call elapsed: 30 nanoseconds.&lt;/p&gt;
&lt;p&gt;result: 499950000
functor call elapsed: 30 nanoseconds.&lt;/p&gt;
&lt;p&gt;result: 499950000
lambda call elapsed: 22584 nanoseconds.
*/&lt;/p&gt;
&lt;h2 id=&#34;epilogue-10&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;We’ve added two new modes, regular functions and functors, providing a comparison of callback interfaces versus direct calls, with performance losses representing orders-of-magnitude differences. Functors perform close to functions, and sometimes even outperform them. The compilation aspect here was largely a knowledge blind spot; I suspected it was due to the access of variable addresses and the function being adjacent, which would benefit &lt;code&gt;CPU&lt;/code&gt; processing.&lt;/p&gt;
&lt;p&gt;Below is the &lt;code&gt;wandbox&lt;/code&gt; output:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;result: 499950000
virtual call elapsed: 6143 nanoseconds.

result: 499950000
direct function call elapsed: 30 nanoseconds.

result: 499950000
functor call elapsed: 31 nanoseconds.

result: 499950000
lambda call elapsed: 15134 nanoseconds.
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Host byte, network byte, observe directly through debugger</title>
        <link>https://ttf248.life/en/p/host-network-byte-order-debugger/</link>
        <pubDate>Tue, 10 Jan 2023 14:18:12 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/host-network-byte-order-debugger/</guid>
        <description>&lt;p&gt;Throughout the history of computer development, there has been no unified standard for data storage. There are two commonly used rules for byte arrangement. For example, if the low-order bits of a multi-digit number are placed at smaller addresses and the high-order bits are placed at larger addresses, it is referred to as little-endian; conversely, it is called big-endian. In network applications, byte order is a factor that must be considered because different machine types may adopt different standards of byte order, so they are all converted according to network standards.
According to reading habits, big-endian byte order is more consistent with the left-to-right reading order.&lt;/p&gt;
&lt;h2 id=&#34;processor-architecturehttpszhwikipediaorgwikie5ad97e88a82e5ba8f&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%AD%97%E8%8A%82%E5%BA%8F&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Processor Architecture&lt;/a&gt;
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Processors such as x86, MOS Technology 6502, Z80, VAX, and PDP-11 use little-endian byte order.&lt;/li&gt;
&lt;li&gt;Processors like Motorola 6800, Motorola 68000, PowerPC 970 use big-endian byte order.&lt;/li&gt;
&lt;li&gt;The byte order of processors such as ARM, PowerPC (excluding PowerPC 970), DEC Alpha, SPARC V9, MIPS, PA-RISC and IA64 is configurable.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;network-byte-order&#34;&gt;Network Byte Order
&lt;/h2&gt;&lt;p&gt;Network transmission generally uses big-endian byte order, also known as network byte order or network order. The IP protocol defines big-endian as the network byte order.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;Berkeley&lt;/code&gt; sockets API defined a set of conversion functions to convert 16 and 32-bit integers between network byte order and host byte order.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;arpa/inet.h&amp;gt;

uint32_t htonl(uint32_t hostlong); // Converts a uint32_t from host byte order to network byte order
uint16_t htons(uint16_t hostshort); // Converts a uint16_t from host byte order to network byte order
uint32_t ntohl(uint32_t netlong); // Converts a uint32_t from network byte order to host byte order
uint16_t ntohs(uint16_t netshort); // Converts a uint16_t from network byte order to host byte order
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If using &lt;code&gt;asio&lt;/code&gt; as the networking library, the built-in namespace provides cross-platform adapted function names:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;boost::asio::detail::socket_ops::network_to_host_long&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;network-ordering&#34;&gt;Network Ordering
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;boost::asio::detail::socket_ops::network_to_host_short&lt;/li&gt;
&lt;li&gt;boost::asio::detail::socket_ops::host_to_network_long&lt;/li&gt;
&lt;li&gt;boost::asio::detail::socket_ops::host_to_network_short&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;visual-studio-debugger&#34;&gt;Visual Studio Debugger
&lt;/h2&gt;&lt;p&gt;In debugging mode, select the Debug menu, Window, and checkmark the Memory window.  Within &lt;code&gt;Visual Studio&lt;/code&gt;, you can directly view data in memory using the debugger, as shown below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/host-network-byte-order-debugger/Snipaste_2023-01-10_14-44-00.png&#34;
	width=&#34;535&#34;
	height=&#34;147&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Debugger Menu&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;363&#34;
		data-flex-basis=&#34;873px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;ways-to-view-memory&#34;&gt;Ways to View Memory
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;The window directly outputs &amp;amp;variable name and jumps to the corresponding variable address.&lt;/li&gt;
&lt;li&gt;If the variable is originally a pointer, double-click on the variable to select it and drag it to the memory window to display the content at the corresponding address.&lt;/li&gt;
&lt;li&gt;If the variable is not a pointer, add it to the calculation window to obtain its address, then manually copy it to the memory window.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lets-illustrate-with-an-example&#34;&gt;Let&amp;rsquo;s illustrate with an example
&lt;/h3&gt;&lt;p&gt;Receive a data segment, stored in the &lt;code&gt;buffer&lt;/code&gt; object, convert network byte order to host byte order, resulting in &lt;code&gt;body_length&lt;/code&gt; being 30. The server allocates four bytes for transmitting this data.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;bool NetworkMessage::decode_header()
{
    // Convert network byte order to host byte order
    body_length_ = boost::asio::detail::socket_ops::network_to_host_long(*(int *)buffer_.data());
    return auto_reserve(body_length_);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Big-endian byte order&lt;/strong&gt;: Observing the content of &lt;code&gt;buffer_&lt;/code&gt; in the memory window.
&lt;img src=&#34;https://ttf248.life/p/host-network-byte-order-debugger/buffer_.png&#34;
	width=&#34;603&#34;
	height=&#34;318&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;buffer_&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;189&#34;
		data-flex-basis=&#34;455px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Little-endian byte order&lt;/strong&gt;: Observing the content of &lt;code&gt;body_length_&lt;/code&gt; in the memory window.
&lt;img src=&#34;https://ttf248.life/p/host-network-byte-order-debugger/body_length_.png&#34;
	width=&#34;581&#34;
	height=&#34;333&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;body_length_&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;174&#34;
		data-flex-basis=&#34;418px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>C11: sleep for vs yield</title>
        <link>https://ttf248.life/en/p/c11-sleep-for-vs-yield/</link>
        <pubDate>Tue, 20 Sep 2022 20:54:51 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/c11-sleep-for-vs-yield/</guid>
        <description>&lt;p&gt;While reviewing the code, &lt;code&gt;std::this_thread::yield()&lt;/code&gt; suddenly popped into my view, a syntax sugar from &lt;code&gt;C11&lt;/code&gt; that I’d used quite a bit, but hadn&amp;rsquo;t noticed before.&lt;/p&gt;
&lt;p&gt;I didn&amp;rsquo;t consult the manual; first, I thought it had something to do with asynchronous operations – the word was used in the coroutine implementation of the Boost library.  Clearly, it wasn&amp;rsquo;t related to coroutines; it’s about controlling logic within a regular thread.&lt;/p&gt;
&lt;h2 id=&#34;documentation&#34;&gt;Documentation
&lt;/h2&gt;&lt;h3 id=&#34;yield&#34;&gt;yield
&lt;/h3&gt;&lt;p&gt;The accuracy of this function depends on the implementation, particularly the OS scheduler mechanism and system state used. For example, the First-Come, First-Served (FCFS) real-time scheduler (Linux’s SCHED_FIFO) will suspend the current thread and place it at the end of the queue for other threads with the same priority that are ready to run (and has no effect if there are no other threads with the same priority).&lt;/p&gt;
&lt;h3 id=&#34;sleep_for&#34;&gt;sleep_for
&lt;/h3&gt;&lt;p&gt;Blocks the current thread&amp;rsquo;s execution for at least the specified &lt;code&gt;sleep_duration&lt;/code&gt;.
This function may block longer than &lt;code&gt;sleep_duration&lt;/code&gt; due to scheduling or resource contention delays.
The standard library recommends measuring durations using a monotonic clock. If implementing with system time instead, waiting times may be sensitive to clock adjustments.&lt;/p&gt;
&lt;h3 id=&#34;analysis&#34;&gt;Analysis
&lt;/h3&gt;&lt;p&gt;Both functions are designed to release the current thread and allow it to no longer occupy a thread, with the actual effect depending on the platform situation. I’m still a bit confused at this point, so let&amp;rsquo;s run the code to see the execution results.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ThinkPad laptop (Visual Studio Community 2022), Tencent Cloud S2 Standard Server (gcc8.5)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;analysis-1&#34;&gt;Analysis
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Execution Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First/us&lt;/th&gt;
&lt;th&gt;Second/us&lt;/th&gt;
&lt;th&gt;Third/us&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h3 id=&#34;analysis-2&#34;&gt;Analysis
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Execution Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First Time / us&lt;/th&gt;
&lt;th&gt;Second Time / us&lt;/th&gt;
&lt;th&gt;Third Time / us&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h3 id=&#34;analysis-3&#34;&gt;Analysis
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Execution Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First/us&lt;/th&gt;
&lt;th&gt;Second/us&lt;/th&gt;
&lt;th&gt;Third/us&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h3 id=&#34;analysis-4&#34;&gt;Analysis
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Execution Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First/us&lt;/th&gt;
&lt;th&gt;Second/us&lt;/th&gt;
&lt;th&gt;Third/us&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h3 id=&#34;analysis-5&#34;&gt;Analysis
&lt;/h3&gt;&lt;p&gt;From the running results, it’s not difficult to understand that due to differences in operating system implementations, the stability of high-precision sleep varies greatly. If you want high-precision sleep, using &lt;code&gt;yield&lt;/code&gt; is more appropriate.&lt;/p&gt;
&lt;p&gt;When the time precision is increased to &lt;code&gt;ms&lt;/code&gt;, the difference between them is no longer significant.&lt;/p&gt;
&lt;h3 id=&#34;analysis-6&#34;&gt;Analysis
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;thread&amp;gt;

// Suggest other threads run for a short period of &amp;quot;busy sleeping&amp;quot;
void little_sleep(std::chrono::microseconds us)
{
    auto start = std::chrono::high_resolution_clock::now();
    auto end = start + us;
    do {
        std::this_thread::yield();
    } while (std::chrono::high_resolution_clock::now() &amp;lt; end);
}

int main()
{
    auto start = std::chrono::high_resolution_clock::now();

    little_sleep(std::chrono::microseconds(100));
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;### Analysis
little_sleep(std::chrono::microseconds(100));
    std::this_thread::sleep_for(std::chrono::microseconds(100));

    auto elapsed = std::chrono::high_resolution_clock::now() - start;
    std::cout &amp;lt;&amp;lt; &amp;quot;waited for &amp;quot;
              &amp;lt;&amp;lt; std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(elapsed).count()
              &amp;lt;&amp;lt; &amp;quot; microseconds\n&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Linux Server, Reset MySQL Password</title>
        <link>https://ttf248.life/en/p/linux-server-reset-mysql-password/</link>
        <pubDate>Tue, 20 Sep 2022 14:27:35 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-server-reset-mysql-password/</guid>
        <description>&lt;p&gt;I had an idle Tencent Cloud server that was expiring at the end of the year and I hadn&amp;rsquo;t planned to renew it. So, I decided to deploy a MySQL database for development purposes. When reinstalling the system, I wanted to save time and chose a third-party image provided by Tencent Cloud, which already had MySQL installed. I thought the system should include a Readme file with information about the password and deployment path.&lt;/p&gt;
&lt;p&gt;The Tencent Cloud server was quickly reinstalled – it took about a minute – and notification said it was ready. When I logged in, &lt;code&gt;systemctl status mysql&lt;/code&gt; showed that the service was running. I started searching for the password but couldn&amp;rsquo;t find it, and I gradually began to panic.&lt;/p&gt;
&lt;p&gt;Then, I thought, since I had already accessed the server with root privileges, there must be a way to reset the password. I searched through documentation and found a forum post on Alibaba Cloud’s forum, continuing to tinker.&lt;/p&gt;
&lt;h2 id=&#34;reset-password&#34;&gt;Reset Password
&lt;/h2&gt;&lt;p&gt;Edit the configuration file &lt;code&gt;vim /etc/my.cnf&lt;/code&gt;, add the following configuration to the &lt;code&gt;mysqld&lt;/code&gt; node: &lt;code&gt;skip-grant-tables&lt;/code&gt;, and execute the command to restart the database: &lt;code&gt;systemctl restart mysql&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Then, log in directly to the data using &lt;code&gt;mysql&lt;/code&gt;, after which everything will proceed normally. To reset the &lt;code&gt;root&lt;/code&gt; user password and enable allowing remote login simultaneously:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;USE mysql;
UPDATE user SET authentication_string = password(&#39;pass&#39;) WHERE User = &#39;root&#39;;
GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;pass&#39; WITH GRANT OPTION;
FLUSH PRIVILEGES;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To revert the modified configuration file, restart the database, and you’re done.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://help.aliyun.com/document_detail/42520.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://help.aliyun.com/document_detail/42520.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>A Brief Overview of Automation Testing</title>
        <link>https://ttf248.life/en/p/automated-testing-overview/</link>
        <pubDate>Thu, 04 Aug 2022 11:39:18 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/automated-testing-overview/</guid>
        <description>&lt;p&gt;The investment in testing for financial trading systems far exceeded that of other systems, with tedious test steps repeatedly executed and a low &lt;code&gt;ROI&lt;/code&gt;. As projects and personnel changed, uncontrollable factors inevitably introduced, often resulting in modifications to A interface output fields impacting B interface results. With each version release, risk accumulated.&lt;/p&gt;
&lt;h2 id=&#34;theoretical-knowledge&#34;&gt;Theoretical Knowledge
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;How to Measure the Value of Automation?&lt;/strong&gt;
An automation testing ROI = (Manual Execution Time) * (Number of Runs) / (Development Cost + Maintenance Cost)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Which Features Should Be Automated?&lt;/strong&gt;
Frequently used features that are unlikely to change. Writing automated test code for this type of interface yields the highest returns.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Why Choose This Timing to Drive Automation Testing?&lt;/strong&gt;
Not appropriate near project launch – distant water doesn’t quench immediate thirst; automation is a long-term return model. It&amp;rsquo;s most suitable when the project is already in a &lt;strong&gt;production environment&lt;/strong&gt; and within a stable release cycle.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;framework-selection&#34;&gt;Framework Selection
&lt;/h2&gt;&lt;p&gt;Given the task of automation testing without prior practical experience, a typical starting point is to open a search engine and find tools and frameworks that can be used with the current system’s &lt;strong&gt;technology stack&lt;/strong&gt;, review the user manuals, and get started. If you can immediately find a suitable tool, congratulations, &lt;strong&gt;perfect start&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;Let me preface this by saying I might be wrong. After reviewing relevant materials, it&amp;rsquo;s not that these frameworks don’t exist; rather, they are too complex and consume excessive resources. For beginners, what’s needed is something small, streamlined, and concise. Consulting with colleagues in the testing group led to the suggestion of a &lt;code&gt;Python&lt;/code&gt; self-built framework – essentially, wrapping existing unit testing frameworks into an automated testing framework.&lt;/p&gt;
&lt;p&gt;Referencing the design thinking for this project: &lt;a class=&#34;link&#34; href=&#34;https://github.com/wintests/pytestDemo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/wintests/pytestDemo&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;why-use-a-framework&#34;&gt;Why Use a Framework?
&lt;/h2&gt;&lt;p&gt;Services have multiple different deployment environments – development, testing, and live testing environments. The purpose of a framework is to act as an abstraction layer, separating test cases and data. This allows for configuring different case data according to various environment configurations, and it also supports shared data.&lt;/p&gt;
&lt;p&gt;The core logic is focused on increasing the utilization of automation. When scenarios become more complex, the data between different environments is completely unrelated and has no bearing on each other. Simply add a &lt;code&gt;label&lt;/code&gt; tag when defining case data to specify the supported environment.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://time.geekbang.org/column/article/496850&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Best Value Automation Testing&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Why Do We Need to Learn a New Language?</title>
        <link>https://ttf248.life/en/p/why-learn-a-new-language/</link>
        <pubDate>Thu, 04 Aug 2022 11:27:30 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/why-learn-a-new-language/</guid>
        <description>&lt;p&gt;Starting from my academic years, I’ve been working with &lt;code&gt;C++&lt;/code&gt; for over ten years. So, why do I need to learn other programming languages?&lt;/p&gt;
&lt;p&gt;Work experience: Lacking experience in elegant module design, &lt;code&gt;C++&lt;/code&gt; syntax is freeform. Learning other languages helps guide me to write more elegant designs.&lt;/p&gt;
&lt;p&gt;I frequently use it when developing some tools. The same design principles apply to the design of low-level libraries and business modules.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Visual Studio Compilation Character Set [Converted]</title>
        <link>https://ttf248.life/en/p/visual-studio-character-set/</link>
        <pubDate>Thu, 04 Aug 2022 10:51:43 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/visual-studio-character-set/</guid>
        <description>&lt;p&gt;&lt;code&gt;C++&lt;/code&gt; cross-platform development. Commonly encountered on Chinese operating systems: &lt;code&gt;error C2001&lt;/code&gt;: constant string contains a newline character.&lt;/p&gt;
&lt;h2 id=&#34;visual-studio&#34;&gt;Visual Studio
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;cmake&lt;/code&gt; organizes project compilation scripts, generating a temporary solution under the &lt;code&gt;windows&lt;/code&gt; system for development. The reason for cross-platform compatibility is that the file encoding is chosen as &lt;code&gt;utf-8&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Reference materials thoroughly explain the causes of the problem from first principles.&lt;/p&gt;
&lt;p&gt;Regarding encoding, &lt;code&gt;MSVC&lt;/code&gt; has dedicated compilation options &lt;code&gt;/source-charset&lt;/code&gt; and &lt;code&gt;/execution-charset&lt;/code&gt;. The former indicates the encoding of the file itself, and the latter indicates what encoding the byte sequence within the compiled character array is. Encoding issues can generally be solved using these two options.&lt;/p&gt;
&lt;p&gt;For example, the &lt;code&gt;windows&lt;/code&gt; &lt;code&gt;cmd&lt;/code&gt; console defaults to displaying &lt;code&gt;gbk&lt;/code&gt; encoding, but since the code file itself is &lt;code&gt;utf-8&lt;/code&gt;, and it&amp;rsquo;s not convenient to directly change it to &lt;code&gt;gbk&lt;/code&gt; due to cross-platform considerations, we don’t include writing conversion code for different platforms here. On &lt;code&gt;Win10&lt;/code&gt;, you can set these two compilation options to &lt;code&gt;/source-charset:utf-8 /execution-charset:gbk&lt;/code&gt;, indicating that the compiler should read in with &lt;code&gt;UTF-8&lt;/code&gt; encoding and then convert it to &lt;code&gt;GBK&lt;/code&gt; for storage within the array. This allows direct use of &lt;code&gt;printf&lt;/code&gt; to display Chinese characters normally in the &lt;code&gt;cmd&lt;/code&gt; console.&lt;/p&gt;
&lt;h2 id=&#34;cmake-configuration-for-visual-studio&#34;&gt;CMake Configuration for Visual Studio
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cmake&#34;&gt;if(WIN32)
    message(STATUS &amp;quot;Configuring trade on WIN32&amp;quot;)
    set(CMAKE_CXX_FLAGS &amp;quot;${CMAKE_CXX_FLAGS} /source-charset:utf-8 /execution-charset:gbk&amp;quot;)
endif()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/146543940&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://zhuanlan.zhihu.com/p/146543940&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Quickly calculate folder size on the Windows platform</title>
        <link>https://ttf248.life/en/p/windows-platform-quick-folder-size-statistics/</link>
        <pubDate>Mon, 01 Aug 2022 19:54:18 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/windows-platform-quick-folder-size-statistics/</guid>
        <description>&lt;p&gt;The Linux platform is very simple: &lt;code&gt;du -sh *&lt;/code&gt; – just one line of code solves the problem. What about Windows? With many disks and a desire to clean up, with numerous files, the system’s built-in Resource Manager is too slow to calculate folder sizes, making you want to give up.&lt;/p&gt;
&lt;h2 id=&#34;everything&#34;&gt;Everything
&lt;/h2&gt;&lt;p&gt;For developers working on the &lt;code&gt;windows&lt;/code&gt; platform, you probably haven&amp;rsquo;t personally used &lt;code&gt;everything&lt;/code&gt;, and should at least have heard of it. Its search speed far exceeds that of the built-in file explorer. Given that system-level support for fast indexing exists, we can certainly find similar tools that build file indexes while also tracking file sizes.&lt;/p&gt;
&lt;h2 id=&#34;wiztree&#34;&gt;WizTree
&lt;/h2&gt;&lt;p&gt;Website: &lt;a class=&#34;link&#34; href=&#34;https://www.diskanalyzer.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.diskanalyzer.com/&lt;/a&gt;
Use the standard installation method or the green version to unzip and run.
It’s fast, with a wide variety of data display types – the left side features a tree diagram mode, the right side displays file types, and there&amp;rsquo;s also graphical visualization available at the bottom of the software.&lt;/p&gt;
&lt;h2 id=&#34;spacesniffer-update-2023-no-longer-maintained&#34;&gt;SpaceSniffer (Update 2023 No Longer Maintained)
&lt;/h2&gt;&lt;p&gt;Software Website: &lt;a class=&#34;link&#34; href=&#34;http://www.uderzo.it/main_products/space_sniffer/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://www.uderzo.it/main_products/space_sniffer/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The operation is very simple – select the corresponding drive letter, and the software will display folder sizes in a graphical way, with larger volumes resulting in larger matrices in the images.  Other operations are easily understood by simply clicking on them. It supports filtering files based on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;File size filter&lt;/li&gt;
&lt;li&gt;File date filter&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/windows-platform-quick-folder-size-statistics/space_sniffer.gif&#34;
	width=&#34;960&#34;
	height=&#34;540&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Basic Usage&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/windows-platform-quick-folder-size-statistics/advance.gif&#34;
	width=&#34;960&#34;
	height=&#34;540&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Advanced Usage&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://moe.best/software/spacesniffer.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://moe.best/software/spacesniffer.html&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>How to Copy Webpage Stylesheets (CSS): Element Inspector</title>
        <link>https://ttf248.life/en/p/how-to-copy-webpage-css-element-inspect/</link>
        <pubDate>Sun, 31 Jul 2022 23:36:48 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/how-to-copy-webpage-css-element-inspect/</guid>
        <description>&lt;p&gt;Static blog themes, the mainstream is based on foreign templates, modified and adjusted without much consideration for Chinese content layout.&lt;/p&gt;
&lt;h2 id=&#34;main-text&#34;&gt;Main Text
&lt;/h2&gt;&lt;p&gt;Half a month ago, I adjusted the blog’s stylesheet – as I’ve been developing backend services for many years, I’m a pure newbie in the frontend. After struggling with it for half a day, the design wasn&amp;rsquo;t very reasonable. Suddenly an idea struck me: I looked at the technical blogs I often read – infoq and OpenChina – and their layouts look really good. Could I borrow some of those? After reviewing the source files, I got lost trying to locate the relevant elements.&lt;/p&gt;
&lt;p&gt;Frontend developers might be laughing at this point… I didn’t understand how to locate the specified elements, but that&amp;rsquo;s okay; I have plenty of free time on weekends, so I stopped to think about it. It reminded me of when I wrote Python crawlers – I had used something similar before.&lt;/p&gt;
&lt;h3 id=&#34;element-inspection&#34;&gt;Element Inspection
&lt;/h3&gt;&lt;p&gt;That’s right, it’s the browser&amp;rsquo;s built-in element inspection tool – copying stylesheets, locating specific elements, all done in minutes. &lt;code&gt;selector&lt;/code&gt; to locate elements, &lt;code&gt;hugo&lt;/code&gt; to create a “user define css”&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Copy element&lt;/li&gt;
&lt;li&gt;Copy outerHTML&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Copy selector&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Copy JS path&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Copy styles&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Copy XPath&lt;/li&gt;
&lt;li&gt;Copy full XPath&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Editing Extremely Large Files on the Windows Platform: EmEditor (Text Editor)</title>
        <link>https://ttf248.life/en/p/windows-platform-edit-large-files-emeditor-text-editor/</link>
        <pubDate>Sun, 31 Jul 2022 23:21:24 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/windows-platform-edit-large-files-emeditor-text-editor/</guid>
        <description>&lt;p&gt;The Shanghai GuoAn database incident, which caused a huge stir within the black hacking circles, remains unclear whether it’s true or false. Let&amp;rsquo;s see what we remember in two years and look back on it then. Based on past experience, I updated a batch of local social engineering databases, and I came across a massive SQL file: 17.9G. A regular text editor couldn’t even preview it, let alone open it. Chatting with netizens, someone mentioned EmEditor.&lt;/p&gt;
&lt;h2 id=&#34;text&#34;&gt;Text
&lt;/h2&gt;&lt;p&gt;Website: &lt;a class=&#34;link&#34; href=&#34;https://www.emeditor.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.emeditor.com/&lt;/a&gt;
I took a look at it over the weekend and found it quite convenient. The design supports editing large files, and when sufficient memory is available, the entire file is loaded into memory, resulting in fast search and editing speeds. It also supports splitting files.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Adding a code copy button for seemingly simple things</title>
        <link>https://ttf248.life/en/p/add-copy-button-for-simple-task/</link>
        <pubDate>Fri, 25 Feb 2022 01:23:39 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/add-copy-button-for-simple-task/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;Spent four hours on this, and when I saw the sentence, it was hilarious. How could it have taken so long? Looking at the time afterward: three hours.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This was the first draft of the year 2022, and there wasn&amp;rsquo;t much to do – exactly as the title said. (At that time, I was still very young), I thought simply copying &lt;a class=&#34;link&#34; href=&#34;https://ouuan.github.io/post/from-hexo-to-hugo/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;作业&lt;/a&gt; would be enough, putting it in my favorites folder, and dragging it out for over a month before finally remembering the task.
When migrating to &lt;code&gt;hugo&lt;/code&gt;, I always felt that the plugins were too few, couldn&amp;rsquo;t copy code, which made copying notes from Evernote to the blog very cumbersome, seriously hindering my momentum with my casual blog.&lt;/p&gt;
&lt;h2 id=&#34;foreword&#34;&gt;Foreword
&lt;/h2&gt;&lt;p&gt;First, carefully read the original author’s draft, read it through completely and flip through their introduction. Wow, I encountered a big shot – Tsinghua University undergraduate, has been exposed to computers early on. Let&amp;rsquo;s see, they&amp;rsquo;re just cool. First, let&amp;rsquo;s browse this blog; I can’t remember what I’m supposed to do. Also, check out the author’s &lt;code&gt;Github&lt;/code&gt; repository – this modified ‘even’ theme is much prettier than now and has more features. Let’s get started, first merge the relevant code into the current one.
&lt;img src=&#34;https://ttf248.life/p/add-copy-button-for-simple-task/2022-02-25-02-08-19.png&#34;
	width=&#34;215&#34;
	height=&#34;150&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;143&#34;
		data-flex-basis=&#34;344px&#34;
	
&gt; &lt;img src=&#34;https://ttf248.life/p/add-copy-button-for-simple-task/2022-02-25-02-08-40.png&#34;
	width=&#34;217&#34;
	height=&#34;167&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;129&#34;
		data-flex-basis=&#34;311px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;new-features-view-article-history-associate-submission-records&#34;&gt;New Features: View Article History, Associate Submission Records
&lt;/h3&gt;&lt;p&gt;The effect is still good, and you can experience it by dragging it to the end of the article.&lt;/p&gt;
&lt;p&gt;Before taking action, I didn’t carefully examine the author&amp;rsquo;s original repository history, assuming a simple merge would fix everything.  Ultimately, I merged a huge amount of code with numerous conflicts and N times of rework, mindless overwrite, all of which were frontend and rendering template codes, using mine as the standard.
Repository address: &lt;a class=&#34;link&#34; href=&#34;https://github.com/TianlongXiang/hugo-theme-even&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/TianlongXiang/hugo-theme-even&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A Chinese pitfall:  &lt;code&gt;git&lt;/code&gt; doesn’t adjust this parameter, it will cause the generated link to not get the current article&amp;rsquo;s &lt;code&gt;commit hash&lt;/code&gt;, leading to history link generation failure. When generating the complete historical record of the article, you also need to modify the automatic integration script, and remember to pull the entire historical record of the current repository.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[feat: Attempt to pull the full GitHub repository to dynamically update the last modification record of the article](&lt;a class=&#34;link&#34; href=&#34;https://github.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;new-features-view-article-history-associate-submission-records-1&#34;&gt;New Features: View Article History, Associate Submission Records
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/TianlongXiang/TianlongXiang.github.io/commit/1b5d719966737f16a8c67880370dc2722adea0b3&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;chore: Path contains Chinese, Hugo GitInfo needs to enable this setting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;name: Build Github
run: git config --global core.quotePath false &amp;amp;&amp;amp; hugo -b &amp;quot;https://www.xiangtianlong.com/&amp;quot; -d &amp;quot;github_public&amp;quot; &amp;amp;&amp;amp; ls
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;styling-adjustments&#34;&gt;Styling Adjustments
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Adjust website content width, the previous design was suitable for both mobile and desktop devices; in reality, no one actually viewed it on their phones, and I personally view it on my computer.&lt;/li&gt;
&lt;li&gt;The directory bar should support automatic expansion/contraction.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;body&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;Referenced &lt;code&gt;ouuan&lt;/code&gt;’s code records for half an hour or so, and still couldn&amp;rsquo;t quite understand how to increase the copy button.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Time travel, a month later, it came back to this matter again&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;text&#34;&gt;Text
&lt;/h2&gt;&lt;p&gt;Since I didn’t understand this assignment, I switched to copying from another one – it was always easier to understand that way. The results of my searches were surprisingly helpful; there was a forum post on the official &lt;code&gt;hugo&lt;/code&gt; website detailing how to add a copy button. Going over there to check it out, the logic was clear. It was baffling when I returned to the site and saw that the code blocks generated by &lt;code&gt;even&lt;/code&gt; differed from the descriptions in the documentation – this part was quite complicated. So, here’s a simple record of it.&lt;/p&gt;
&lt;p&gt;Because I don&amp;rsquo;t really understand front-end development, I use my browser’s “Inspect” tool to analyze the code and rely on the style information on the right side to slowly figure things out; I didn’t understand &lt;code&gt;JavaScript&lt;/code&gt;, so I added some logs to the console. There were many things I didn’t understand at first. Taking a deep breath and carefully sorting through and breaking down the logic, you can always find a solution.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;The &lt;code&gt;pre&lt;/code&gt; node has multiple instances; here it refers to a single code block, with the theme rendering line numbers automatically, resulting in a duplicate output when copying.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;I wanted to disable the theme&amp;rsquo;s built-in code highlighting, but I’m unfamiliar with the settings for this theme.&lt;/li&gt;
&lt;li&gt;I consulted the &lt;code&gt;hugo&lt;/code&gt; website for resources and read some materials, gaining a partial understanding that there is a &lt;code&gt;markup&lt;/code&gt; setting to control code highlighting.&lt;/li&gt;
&lt;li&gt;Adjusting the configuration file didn’t work; the rendering was still different from what I expected.&lt;/li&gt;
&lt;li&gt;I discovered this set of settings &lt;code&gt;pygmentsOptions&lt;/code&gt; and continued to consult documentation, adjusting the settings, starting by removing line numbers.&lt;/li&gt;
&lt;li&gt;I configured a custom &lt;code&gt;css&lt;/code&gt; stylesheet and a custom &lt;code&gt;js&lt;/code&gt; script.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;body-1&#34;&gt;Body
&lt;/h2&gt;&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;Since I’ve been handling so much, my brain suddenly remembered seeing a color palette that looked good recently, so I&amp;rsquo;m going to change the button styles: Let’s go with Chinese-style sky blue.&lt;/li&gt;
&lt;/ol&gt;
&lt;img class=&#34;special-img-class&#34; style=&#34;width:20%&#34; src=&#34;2022-02-25-02-01-22.png&#34; /&gt;
&lt;img class=&#34;special-img-class&#34; style=&#34;width:20%&#34; src=&#34;2022-02-25-02-01-33.png&#34; /&gt;
ouuan spent four hours on this, and when I saw this sentence, I even thought it was funny. How could it take so long? When I finally looked at the time: it was only three hours.
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://ouuan.github.io/post/from-hexo-to-hugo/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ouuan.github.io/post/from-hexo-to-hugo/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://gohugobrasil.netlify.app/content-management/syntax-highlighting/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://gohugobrasil.netlify.app/content-management/syntax-highlighting/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://gohugo.io/getting-started/configuration-markup#highlight&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://gohugo.io/getting-started/configuration-markup#highlight&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;reference-links&#34;&gt;Reference Links
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.dannyguo.com/blog/how-to-add-copy-to-clipboard-buttons-to-code-blocks-in-hugo/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.dannyguo.com/blog/how-to-add-copy-to-clipboard-buttons-to-code-blocks-in-hugo/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Chaos Engineering</title>
        <link>https://ttf248.life/en/p/chaos-engineering/</link>
        <pubDate>Wed, 28 Jul 2021 14:35:07 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/chaos-engineering/</guid>
        <description>&lt;p&gt;A pattern of disruption to test system stability.&lt;/p&gt;
&lt;h2 id=&#34;main-text&#34;&gt;Main Text
&lt;/h2&gt;&lt;p&gt;The domestic internet industry is always fond of playing with new things, often introducing terms that most people wouldn&amp;rsquo;t be able to guess what they are.&lt;/p&gt;
&lt;p&gt;After reading some articles, this definition specifically for the early stages of Chaos Engineering is relatively easy to accept:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Early exploration of Chaos Engineering has actually been ongoing within the industry, previously existing under the guise of fault testing and disaster recovery exercises. As microservice architectures continue to develop and distributed systems grow ever larger, Chaos Engineering has begun to emerge and gain increasing importance. Following Netflix’s formal proposal of the Chaos Engineering concept, related theories have also rapidly enriched. Netflix&amp;rsquo;s practices have also demonstrated the significant impact Chaos Engineering has on stability.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;reference-links&#34;&gt;Reference Links
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.infoq.cn/article/gsqtykoa3uvrtqi1kkmo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ByteDance Chaos Engineering Practices Summary&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Kubernetes paused pod</title>
        <link>https://ttf248.life/en/p/kubernetes-pause-pod/</link>
        <pubDate>Mon, 12 Jul 2021 11:23:09 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/kubernetes-pause-pod/</guid>
        <description>&lt;p&gt;Deployment controllers implement a crucial function within a Kubernetes cluster: the ability to horizontally scale and shrink Pods. This capability was essential for traditional cloud-era platforms.&lt;/p&gt;
&lt;p&gt;Encountering a business scenario where you need to modify data in a database, restarting Pod nodes after adjustments. However, during Pod operation, table fields are continuously modified, requiring temporary pausing of application updates to tables, adjusting the data, and then restoring the Pod.&lt;/p&gt;
&lt;p&gt;Besides abruptly deleting the Deployment, are there other ways to achieve a similar pause effect?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubectl scale --replicas=0 deployment/&amp;lt;your-deployment&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before seeing the answer, many people might have thought that simply operating processes was the way to go, stuck in the mindset of directly manipulating business processes instead of realizing the solution.&lt;/p&gt;
&lt;h2 id=&#34;reference-links&#34;&gt;Reference Links
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://stackoverflow.com/questions/54821044/how-to-stop-pause-a-pod-in-kubernetes&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;How to Stop/Pause a Pod in Kubernetes&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Docker Basics, Intermediate, and Advanced</title>
        <link>https://ttf248.life/en/p/docker-two-three-things/</link>
        <pubDate>Thu, 21 Jan 2021 09:26:07 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/docker-two-three-things/</guid>
        <description>&lt;p&gt;Having worked with CentOS for many years, content may not apply to macOS or Ubuntu users in some cases.&lt;/p&gt;
&lt;p&gt;You can refer to the documentation from Tsinghua University for installation guidance: &lt;a class=&#34;link&#34; href=&#34;https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation
&lt;/h2&gt;&lt;p&gt;Due to unknown mysterious forces, installing Docker domestically is recommended to set the cloud vendor&amp;rsquo;s repository address. Here we recommend using &lt;strong&gt;Alibaba Cloud&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;set-repository-source-address&#34;&gt;Set Repository Source Address
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum install yum-utils device-mapper-persistent-data lvm2 &amp;amp;&amp;amp; \
sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;deploy-the-latest-version&#34;&gt;Deploy the Latest Version
&lt;/h3&gt;&lt;p&gt;Docker is a commonly used background service, we recommend setting it to start on boot. The following command applies to CentOS 7:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo yum install -y docker-ce docker-ce-cli containerd.io &amp;amp;&amp;amp; systemctl enable --now docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;deploying-a-specific-version&#34;&gt;Deploying a Specific Version
&lt;/h3&gt;&lt;p&gt;The releases of &lt;code&gt;kubernetes&lt;/code&gt; and &lt;code&gt;docker&lt;/code&gt; are not fully synchronized. If you need to deploy &lt;code&gt;kubernetes&lt;/code&gt; subsequently, refer to the &lt;code&gt;kubernetes&lt;/code&gt; deployment instructions and install a specific version of &lt;code&gt;docker&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum list docker-ce --showduplicates | sort -r
sudo yum install -y docker-ce-18.09.2-3.el7 docker-ce-cli-18.09.2-3.el7 containerd.io-18.09.2-3.el7 &amp;amp;&amp;amp; systemctl enable --now docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;adding-docker-permissions-for-regular-users&#34;&gt;Adding Docker Permissions for Regular Users
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo usermod -aG docker ${USER}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;uninstall&#34;&gt;Uninstall
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo yum erase -y docker-ce docker-ce-cli containerd.io
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;everyday-use&#34;&gt;Everyday Use
&lt;/h2&gt;&lt;h3 id=&#34;mirror-acceleration&#34;&gt;Mirror Acceleration
&lt;/h3&gt;&lt;p&gt;There’s still an unknown mysterious force that causes slow image pulls. At this time, domestic cloud vendors have emerged and provided many acceleration services, which are still recommended – &lt;strong&gt;Alibaba Cloud&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The acceleration addresses can be managed by you registering an Alibaba Cloud account; this service is free. Alibaba Cloud also offers a free image build service.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cat &amp;gt; /etc/docker/daemon.json &amp;lt;&amp;lt;EOF
{
  &amp;quot;registry-mirrors&amp;quot;: [
    &amp;quot;https://docker.nju.edu.cn&amp;quot;,
    &amp;quot;https://mirror.baidubce.com&amp;quot;,
    &amp;quot;https://docker.m.daocloud.io&amp;quot;,
    &amp;quot;https://docker.mirrors.sjtug.sjtu.edu.cn&amp;quot;
  ]
}
EOF
systemctl daemon-reload &amp;amp;&amp;amp; \
systemctl restart docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;recommended-control-panels&#34;&gt;Recommended Control Panels
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker volume create portainer_data &amp;amp;&amp;amp; \
docker run -d --name=portainer --restart=always -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:2.20.3-alpine
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;frequently-used-image-pull-list&#34;&gt;Frequently Used Image Pull List
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker pull rancher/rancher:stable &amp;amp;&amp;amp; docker pull portainer/portainer-ce:2.0.1 &amp;amp;&amp;amp; \
docker pull centos:7 &amp;amp;&amp;amp; docker pull ubuntu:20.04 &amp;amp;&amp;amp; docker pull ubuntu:18.04 &amp;amp;&amp;amp; \
docker pull redis:5 &amp;amp;&amp;amp; docker pull redis:6 &amp;amp;&amp;amp; \
docker pull alpine:3.11 &amp;amp;&amp;amp; docker pull busybox:1.32 &amp;amp;&amp;amp; \
docker pull rabbitmq:3.7-management &amp;amp;&amp;amp; \
docker pull mariadb:10.2 &amp;amp;&amp;amp; \
docker pull nginx:1.18 &amp;amp;&amp;amp; docker pull nginx:1.19 &amp;amp;&amp;amp; \
docker pull mysql:5.6 &amp;amp;&amp;amp; docker pull mysql:8 &amp;amp;&amp;amp; \
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;frequently-used-image-pull-list-1&#34;&gt;Frequently Used Image Pull List
&lt;/h3&gt;&lt;p&gt;docker pull mysql:5.6 &amp;amp;&amp;amp; docker pull mysql:8 &amp;amp;&amp;amp; &lt;br&gt;
docker pull elasticsearch:6.8.11 &amp;amp;&amp;amp; docker pull logstash:6.8.11 &amp;amp;&amp;amp; docker pull kibana:6.8.11 &amp;amp;&amp;amp; &lt;br&gt;
docker pull zookeeper:3.4 &amp;amp;&amp;amp; &lt;br&gt;
docker pull influxdb:1.7 &amp;amp;&amp;amp; docker pull grafana/grafana:7.3.1 &amp;amp;&amp;amp; &lt;br&gt;
docker pull percona:8 &amp;amp;&amp;amp; docker pull percona:5.6 &amp;amp;&amp;amp; &lt;br&gt;
docker pull cloverzrg/frps-docker:0.34.3 &amp;amp;&amp;amp; docker pull cloverzrg/frpc-docker:0.34.3&lt;/p&gt;
&lt;h3 id=&#34;common-command-combinations&#34;&gt;Common Command Combinations
&lt;/h3&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.docker.com/engine/reference/commandline/docker/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://docs.docker.com/engine/reference/commandline/docker/&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;View container running status, append the &lt;code&gt;format&lt;/code&gt; parameter to view detailed container information, without focusing on image information:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker ps --format &amp;quot;{{.Names}}: {{.Ports}}: {{.Size}}&amp;quot;
#portainer: 0.0.0.0:8000-&amp;gt;8000/tcp, 0.0.0.0:9000-&amp;gt;9000/tcp: 0B (virtual 172MB)
#influxdb: 0.0.0.0:8086-&amp;gt;8086/tcp: 183B (virtual 311MB)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;Stop all containers with a single command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker stop $(docker ps -a -q)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Delete all images with a single command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;dokcer rmi $(docker images -a -q)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;Export image&lt;/p&gt;
&lt;h3 id=&#34;common-combination-commands&#34;&gt;Common Combination Commands
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker save &amp;lt;IMAGE NAME&amp;gt;:&amp;lt;IMAGE TAG&amp;gt; &amp;gt; -o XXX.tar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Export image and compress&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker save &amp;lt;IMAGE NAME&amp;gt;:&amp;lt;IMAGE TAG&amp;gt; | gzip &amp;gt; XXX.tar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Import image&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker load -i XXX.tar
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Linux Setup JMeter Test Environment</title>
        <link>https://ttf248.life/en/p/linux-setup-jmeter-testing-environment/</link>
        <pubDate>Tue, 22 Dec 2020 10:12:50 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-setup-jmeter-testing-environment/</guid>
        <description>&lt;p&gt;The author has a strong interest in hardware and used JMeter to conduct load testing, documenting the process of deploying JMeter, InfluxDB, and Grafana on CentOS 7. They shared installation and command usage for JMeter, InfluxDB’s features and Docker installation method, as well as simple deployment and configuration for Grafana. They summarized experience and references related to high-performance programming patterns.&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background
&lt;/h2&gt;&lt;p&gt;As widely known, I have a very strong interest in hardware. By chance, the test team was using &lt;code&gt;JMeter&lt;/code&gt; to perform load tests and discovered that performance wasn&amp;rsquo;t improving. As a curious individual, I decisively took action to see how the company conducted its testing. There’s also a small story: at some point in the distant past, I read a post on OpenChina about how to create more impressive-looking performance test graphs – after observing &lt;code&gt;Windows&lt;/code&gt; versions execute tests and achieving visualized &lt;code&gt;TPS&lt;/code&gt; data display, what&amp;rsquo;s the use of configuring a web panel?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Thinking is all well and good, but you have to try it yourself to understand.
Don’t use GUI mode for load testing! only for Test creation and Test debugging.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;background-1&#34;&gt;Background
&lt;/h2&gt;&lt;p&gt;Officially, it’s recommended to obtain test reports via the command line and display them using a GUI, which introduces data errors.  I don&amp;rsquo;t have deep knowledge of JMeter – at least I found a reason to tinker with a &lt;code&gt;Linux&lt;/code&gt; version console panel. The openchinese post’s core component deployment isn’t friendly; you need to follow their WeChat channel to download the required files, and as a millennial, of course I used &lt;code&gt;Docker&lt;/code&gt; instead. Basically, my server is located domestically, and accessing the overseas source addresses is very slow – at least using an image service, Alibaba Cloud has a free acceleration.&lt;/p&gt;
&lt;p&gt;Regarding &lt;code&gt;docker&lt;/code&gt; installation and deployment, this will not be elaborated on here; please refer to previous articles for recommendations.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;The following content focuses on two main areas: setting up the basic test environment components and a simple explanation of each component.&lt;/p&gt;
&lt;h2 id=&#34;jmeter&#34;&gt;JMeter
&lt;/h2&gt;&lt;p&gt;Apache JMeter is a Java-based load testing tool developed by the Apache Software Foundation. It’s used to perform stress tests on software, initially designed for web application testing but later expanded to other testing domains. It can be used to test static and dynamic resources such as static files, Java microservices, CGI scripts, Java objects, databases, FTP servers, etc. JMeter can simulate massive loads from various stress categories onto servers, networks, or objects to test their strength and analyze overall performance. Furthermore, JMeter can perform functional/regression testing on applications by creating scripts with assertions to validate that your program returns the expected results. To maximize flexibility, JMeter allows using regular expressions to create assertions. Apache JMeter can be used to perform performance testing of static and dynamic resources (files, Servlets, Perl scripts, Java objects, databases and queries, FTP servers, etc.). It can be used to simulate heavy loads on servers, networks, or objects to test their strength or analyze overall performance under different stress types. You can use it for graphical analysis of performance metrics or for large concurrent load testing of your server/script/object.&lt;/p&gt;
&lt;h3 id=&#34;jmeter-deployment-on-centos7&#34;&gt;Jmeter Deployment on CentOS7
&lt;/h3&gt;&lt;p&gt;Install the &lt;code&gt;JDK&lt;/code&gt; runtime environment, download the &lt;code&gt;Jmeter&lt;/code&gt; installation package:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum install java-1.8.0-openjdk -y &amp;amp;&amp;amp; \
wget https://mirrors.bfsu.edu.cn/apache//jmeter/binaries/apache-jmeter-5.4.tgz &amp;amp;&amp;amp; tar -xf apache-jmeter-5.4.tgz
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Configure environment variables:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export JMETER_HOME=$HOME/jmeter/apache-jmeter-5.4
export PATH=$JMETER_HOME/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;jmeter-commands&#34;&gt;JMeter Commands
&lt;/h3&gt;&lt;p&gt;Finally, it will be connected to the &lt;code&gt;Grafana&lt;/code&gt; dashboard, and you don&amp;rsquo;t need to input the &lt;code&gt;-l&lt;/code&gt; parameter to observe data in the &lt;code&gt;web&lt;/code&gt; console.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;jmeter -n -t /tmp/order-500-10s.jmx -l /tmp/jmeter-order-report-20200109/order-500-10s.jtl
# Generally, don&#39;t use test results and test reports to simplify the command
jmeter -n -t /tmp/order-500-10s.jmx
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;influxdb&#34;&gt;InfluxDB
&lt;/h2&gt;&lt;p&gt;InfluxDB is an open-source distributed time series database written in Go. It requires no external dependencies. The database is now primarily used for storing large volumes of timestamped data such as DevOps monitoring data, app metrics, IoT sensor data, and real-time analytics data.&lt;/p&gt;
&lt;h3 id=&#34;influxdb-features&#34;&gt;InfluxDB Features
&lt;/h3&gt;&lt;p&gt;InfluxDB’s features can be summarized into the following 9 aspects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Schema-less (Schemaless):&lt;/strong&gt; Can accommodate an arbitrary number of columns;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Metric Retention Time Setting:&lt;/strong&gt;  Allows setting retention times for metrics;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Support for Time-Related Functions:&lt;/strong&gt; Supports functions related to time (such as min, max, sum, count, mean, median, etc.) for convenient statistical analysis;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Storage Policy Support:&lt;/strong&gt; Can be used for data deletion and modification (InfluxDB does not provide direct methods for deleting or modifying data);&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Continuous Query Support:&lt;/strong&gt;  Automatically scheduled sets of queries that run continuously, combined with storage policies to reduce InfluxDB’s system footprint;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Native HTTP Support:&lt;/strong&gt; Built-in HTTP API;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Support for Similar SQL Syntax:&lt;/strong&gt; Supports a syntax similar to SQL;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Support for Setting Replica Count in Clusters:&lt;/strong&gt; Allows setting the number of replicas for data within clusters;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Support for Periodic Data Sampling:&lt;/strong&gt;  Allows sampling data periodically and writing it to another measurement, facilitating granular data storage.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;influxdb-docker-installation&#34;&gt;InfluxDB Docker Installation
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mkdir influxdb &amp;amp;&amp;amp; cd influxdb &amp;amp;&amp;amp; \
docker run -p 8086:8086 -d --name influxdb -v $PWD:/var/lib/influxdb influxdb:1.7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;docker exec -it influxdb /bin/bash&lt;/code&gt; enters the container, executes commands, and manually creates a database&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;root@bce0a55bbc72:/# influx
Connected to http://localhost:8086 version 1.7.10
InfluxDB shell version: 1.7.10
&amp;gt; Execute commands in the interactive shell
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;influxdb-database-and-user-creation&#34;&gt;InfluxDB Database and User Creation
&lt;/h3&gt;&lt;p&gt;Create database: &lt;code&gt;create database jmeter_t2&lt;/code&gt;
View databases: &lt;code&gt;show databases&lt;/code&gt;
Switch to database: &lt;code&gt;use jmeter_t2&lt;/code&gt;
Create user: &lt;code&gt;create user &amp;quot;admin&amp;quot; with password &#39;admin&#39; with all privileges&lt;/code&gt;
View users: &lt;code&gt;show users&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;&amp;gt; show users
user  admin
----  -----
admin true
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the user permissions for &lt;code&gt;admin&lt;/code&gt; are displayed as &lt;code&gt;true&lt;/code&gt;, the database setup is complete.&lt;/p&gt;
&lt;h2 id=&#34;grafana&#34;&gt;Grafana
&lt;/h2&gt;&lt;p&gt;When writing test cases, it was found that the effect of chart visualization is not very necessary; the &lt;code&gt;tps&lt;/code&gt; data from the interface can be observed when executed in the command line, and more importantly, we wanted to know the internal timing of the program.&lt;/p&gt;
&lt;p&gt;A simple deployment of the &lt;code&gt;grafana&lt;/code&gt; console panel and importing a configuration file to connect with &lt;code&gt;InfluxDB&lt;/code&gt; was performed. The console supports filtering test results through tags; generally, only one &lt;code&gt;InfluxDB&lt;/code&gt; database needs to be configured:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Application Name&lt;/li&gt;
&lt;li&gt;Test Case Name&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/linux-setup-jmeter-testing-environment/Snipaste_2021-03-09_19-44-22.png&#34;
	width=&#34;861&#34;
	height=&#34;357&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;grafana&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;241&#34;
		data-flex-basis=&#34;578px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -d --name=grafana -p 3000:3000 grafana/grafana:7.3.1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Due to the sampling interval in the web version, the calculated &lt;code&gt;TPS&lt;/code&gt; and related values do not match the aggregated report from &lt;code&gt;JMeter&lt;/code&gt;. Please refer to this link: &lt;a class=&#34;link&#34; href=&#34;https://www.vinsguru.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.vinsguru.com/jmeter-real-time-results-influxdb-grafana/&lt;/a&gt; ## Grafana&lt;/p&gt;
&lt;p&gt;When writing test cases, it was found that the chart visualization effect is not very necessary; the &lt;code&gt;tps&lt;/code&gt; data from the interface can be observed when executed in the command line, and more importantly, we wanted to know the internal timing of the program.&lt;/p&gt;
&lt;p&gt;A simple deployment of the &lt;code&gt;grafana&lt;/code&gt; console panel and importing a configuration file to connect with &lt;code&gt;InfluxDB&lt;/code&gt; was performed. The console supports filtering test results through tags; generally, only one &lt;code&gt;InfluxDB&lt;/code&gt; database needs to be configured:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Application Name&lt;/li&gt;
&lt;li&gt;Test Case Name&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/linux-setup-jmeter-testing-environment/Snipaste_2021-03-09_19-44-22.png&#34;
	width=&#34;861&#34;
	height=&#34;357&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;grafana&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;241&#34;
		data-flex-basis=&#34;578px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -d --name=grafana -p 3000:3000 grafana/grafana:7.3.1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Due to the sampling interval in the web version, the calculated &lt;code&gt;TPS&lt;/code&gt; and related values do not match the &lt;code&gt;JMeter&lt;/code&gt; aggregated report. Please refer to this link: &lt;a class=&#34;link&#34; href=&#34;https://www.vinsguru.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.vinsguru.com/jmeter-real-time-results-influxdb-grafana/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;High-performance program patterns invariably are one-loop thread; any locks, enqueueing, and dequeueing will cause unnecessary performance loss.&lt;/li&gt;
&lt;li&gt;The time spent on core business logic is greater than the time spent introducing other code; concurrency can effectively improve efficiency only when the core latency is sufficiently large; otherwise, it’s best to be cautious about introducing other code.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://my.oschina.net/u/4617935/blog/4680856&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;JMeter Series - JMeter + Grafana + InfluxDB Real-time Monitoring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://hub.docker.com/_/influxdb&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;InfluxDB Official Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://hub.docker.com/r/grafana/grafana&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Grafana Official Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://jmeter.apache.org/download_jmeter.cgi&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;JMeter Website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/@jasonli.studio/to-install-apache-jmeter-in-centos7-294bc72a97ba&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;To Install Apache JMeter in CentOS7&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Red Hat and CentOS Lifecycle</title>
        <link>https://ttf248.life/en/p/redhat-centos-lifecycle/</link>
        <pubDate>Tue, 21 Jul 2020 20:02:35 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/redhat-centos-lifecycle/</guid>
        <description>&lt;p&gt;Production environment operating systems, with Red Hat and CentOS being the mainstream choices. The documentation includes links to two system lifecycles and shares experience upgrading from CentOS 8 to CentOS Stream 8.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction
&lt;/h2&gt;&lt;p&gt;In the current domestic environment, Red Hat and CentOS are the mainstream choices for production environments. After experiencing the retirement of Red Hat 6 two years ago, this record specifically documents the official website links for the lifecycles of these two systems.&lt;/p&gt;
&lt;h2 id=&#34;main-content&#34;&gt;Main Content
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://access.redhat.com/support/policy/updates/errata&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Red Hat Enterprise Linux Life Cycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://wiki.centos.org/zh/About/Product&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CentOS Product Specifications&lt;/a&gt;
Red Hat Enterprise Linux (RHEL) and CentOS are the mainstream choices for enterprise servers. RHEL provides stable support and update cycles, suitable for enterprise applications. CentOS as RHEL&amp;rsquo;s community edition, offers similar functionality and stability but without official support.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;follow-up&#34;&gt;Follow-up
&lt;/h2&gt;&lt;p&gt;When publishing this article, I didn’t expect to update it two years later. Just a few days ago, I upgraded my daily virtual machine from CentOS 8 to CentOS 8 Stream. I can&amp;rsquo;t say much about what to choose in production – I prefer to keep the latest version in my local environment.&lt;/p&gt;
&lt;p&gt;CentOS 8 Stream is a rolling release version that offers faster updates and new features than traditional CentOS, making it suitable for development and testing environments.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Building PCs</title>
        <link>https://ttf248.life/en/p/computer-assembly/</link>
        <pubDate>Sat, 18 Jul 2020 14:33:46 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/computer-assembly/</guid>
        <description>&lt;p&gt;The author has long had an interest in building computers from a young age, and began to delve into hardware assembly after university. They recommended websites for comparing hardware performance and offered purchasing suggestions, including CPU, solid-state drives, hard disk drives, and memory frequencies. They also shared their experience and advice regarding hardware selection and important considerations.&lt;/p&gt;
&lt;h3 id=&#34;wonder--unspeakable&#34;&gt;Wonder – Unspeakable
&lt;/h3&gt;&lt;p&gt;Ever since I was young, I’ve dreamed of building my own computer, but unfortunately, economic conditions didn&amp;rsquo;t allow it. Finally, after a lot of hard work, I managed to get to university, and I configured a laptop for portability. If I had to pinpoint the exact time when I started thinking about assembling computers, it would be when I first visited the library in my hometown. After all, it was a sizable city-level library, with not only an electronic reading room (which I never actually went to – supposedly you were charged by the hour), but also a magazine reading room, where I browsed magazines like “Popular Science” and “Computer News.” For someone who had limited exposure to computers, these magazines were practically divine科普资料 (scientific explanation materials). - When I read about players doing dungeons, I started thinking about getting my own computer and going to pull monsters myself as the main damage dealer. Seeing the use of black technology, I fantasized about following the instructions in the book and achieving the described effect (regarding the use of hacking tools). Although my high school studies were heavy, with my limited understanding at the time, reading and playing were both necessary – it was a truly innocent and carefree experience. I would make an excuse to go to the library to read, and when nothing else to do, I’d carry a small bag and walk there; the city wasn&amp;rsquo;t that big, so I usually walked to the library.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When I got there, I enjoyed the air conditioning while reading novels, comics, and game magazines, occasionally even reading some serious books.&lt;/li&gt;
&lt;li&gt;It’s easy for older people to forget things, and the initial spark came from visiting the library. I don&amp;rsquo;t even remember the computer my relatives assembled during middle school – I have no idea what it was used for.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;wonder--unspeakable-1&#34;&gt;Wonder – Unspeakable
&lt;/h3&gt;&lt;p&gt;Upon entering junior high school, the school offered introductory computer training, and later I transferred schools, where I also gained some exposure to concepts in computer competitions. After reaching high school, I qualified for NOIP once. Speaking of which, we must mention the power of our alumni; the high school’s computer building was donated by alumni and included a computer teaching room plus a library. Back then, it was also the initial wave of China&amp;rsquo;s internet boom. School leaders supported participation in computer competitions as well, considering that several senior classmates had been admitted to key universities through computer science.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I have never reflected on my relationship with computers like this before. It’s no wonder that after graduating, I resolutely switched from automation to the computer industry – the seed had already been planted, and it was simply a matter of an insider not realizing it. Having encountered many things from a young age, I thought I was very skilled, but in reality, I only understood the superficial aspects; my biggest advantage was that initial passion.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;hardware-assembly&#34;&gt;Hardware Assembly
&lt;/h3&gt;&lt;p&gt;Browse sites like Carda, Chiphell, and Zhihu’s computer assembly forums to get a newbie relatively simple list of components they would need for their own machine. After 2019, when purchasing CPUs with limited financial resources, AMD is preferred for higher performance.&lt;/p&gt;
&lt;p&gt;I recommend a commonly used hardware performance comparison website: &lt;a class=&#34;link&#34; href=&#34;https://cpu.userbenchmark.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://cpu.userbenchmark.com/&lt;/a&gt;. For pricing, it can be compared to the US versions available on Xianyu (a Chinese online marketplace). True experts can go to Xianyu to find secondhand items, which can save a lot of money. If you’re not very familiar with this, I don&amp;rsquo;t recommend buying from Xianyu; I purchased fake memory, although I haven&amp;rsquo;t found any problems using it so far, and I’m not entirely sure about it – the model and specifications don’t match at all.&lt;/p&gt;
&lt;h4 id=&#34;sn550-vs-sn750&#34;&gt;SN550 VS SN750
&lt;/h4&gt;&lt;p&gt;The difference between the SN550 1TB and the SN750 1TB is that they consistently read and write slower by a factor of two – one reads at 850MB, while the other reads at 1.6GB. However, for everyday use, there’s no noticeable difference because both support 4K equally. Of course, this refers to the 1TB SN550; speeds are significantly slower in sequential read/write operations with the 500G and 250G versions. In my opinion, if you&amp;rsquo;re not a spendthrift, buying the SN550 is sufficient – my main reason for not purchasing it wasn’t its sequential read/write speed, but rather that it only comes in a 1TB capacity, while the SN750 offers 2TB. For me, considering I don’t want to expand further, the motherboard&amp;rsquo;s M.2 NVMe interface is more valuable than these SSD differences.&lt;/p&gt;
&lt;p&gt;Based on consensus from online users, purchasing a converter board – a B150 motherboard can also support M.2 interfaces for SSDs.&lt;/p&gt;
&lt;h4 id=&#34;hard-disk-drive-selection&#34;&gt;Hard Disk Drive Selection
&lt;/h4&gt;&lt;p&gt;Currently, the prices of hard disk drives are relatively stable. For users with large storage needs, it is necessary to select a suitable mechanical hard drive. We recommend enterprise-grade hard drives for users who frequently download resources. Common ones include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Western Blue Discs&lt;/li&gt;
&lt;li&gt;Seagate Exos&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Large capacity mechanical hard drives should be partitioned, and frequent download operations should be fixed on a specific partition. If bad sectors appear later, they can be concentrated in one partition, and the current partition can be discarded, which can effectively extend the lifespan of the mechanical hard drive.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Seagate series &lt;a class=&#34;link&#34; href=&#34;https://www.seagate.com/cn/zh/enterprise-storage/exos-drives/exos-e-drives/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;official introduction&lt;/a&gt;
&lt;img src=&#34;https://ttf248.life/SeagateExos1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Seagate Enterprise Hard Drive Overview&#34;
	
	
&gt;
&lt;img src=&#34;https://ttf248.life/SeagateExos2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Seagate Enterprise Hard Drive Overview&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;memory-frequency&#34;&gt;Memory Frequency
&lt;/h4&gt;&lt;p&gt;From a daily usage perspective, frequency will not have a significant impact on performance.
&lt;img src=&#34;https://ttf248.life/memory.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Memory timing&#34;
	
	
&gt; &lt;img src=&#34;https://ttf248.life/yan_yu_memory.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Yan Yu memory&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;Memory timings (also known as RAM timings or SDRAM timings) are four parameters that describe the performance of Synchronous Dynamic Random Access Memory (SDRAM): CL, TRCD, TRP, andTRAS, measured in clock cycles. They are typically written as four numbers separated by hyphens, such as 7-8-8-24. The fourth parameter (RAS) is often omitted, and sometimes a fifth parameter is added: Command rate (command rate), usually 2T or 1T, also written as 2N or 1N. These parameters specify the latency (delay time) that affects the speed of random access memory. Lower numbers generally indicate better performance. The final element determining system performance is the actual latency time, typically measured in nanoseconds. When converting memory timing to actual latency, it’s crucial to note that it’s measured in clock cycles. Without knowing the clock cycle time, you cannot determine if one set of numbers is faster than another.&lt;/p&gt;
&lt;h4 id=&#34;memory-frequency-1&#34;&gt;Memory Frequency
&lt;/h4&gt;&lt;p&gt;For example, the clock frequency of DDR3-2000 memory is 1000 MHz, with a clock cycle of 1 ns. Based on this 1 ns clock, a CL7 value gives an absolute latency of 7 ns. A faster DDR3-2666 (clocking at 1333 MHz, with each cycle 0.75 ns) might use a larger CL9 to produce a shorter absolute latency of 6.75 ns.
Modern DIMMs include a Serial Presence Detect (SPD) ROM chip containing recommended memory timings for auto-configuration. The PC&amp;rsquo;s BIOS may allow users to adjust timings to improve performance (with the risk of instability), or in some cases, increase stability (such as using suggested timings).
Note: Memory bandwidth is measured as throughput and is typically limited by transfer rate rather than latency. By interleaving multiple internal banks of SDRAM, it’s possible to transmit data at peak rates continuously. - This may increase bandwidth at the cost of increased latency. Specifically, each new generation of DDR memory has a higher transfer rate, but absolute latency hasn&amp;rsquo;t changed significantly, particularly with the first-generation products on the market, which often exhibit longer delays than their predecessors.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Even with increased memory latency, increasing memory bandwidth can improve the performance of multi-processor or multi-threaded computer systems. Higher bandwidth will also boost the performance of integrated graphics cards that don’t have dedicated video memory.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;memory_timing_parameter_explanation.png&#34; &gt;Memory Timing Parameter Explanation&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;references&#34;&gt;References
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Memory_time_series_parameter&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Memory Time Series Parameter Explanation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Website Acceleration and Domain Settings</title>
        <link>https://ttf248.life/en/p/website-acceleration-and-domain-setup/</link>
        <pubDate>Sat, 20 Jun 2020 10:36:27 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/website-acceleration-and-domain-setup/</guid>
        <description>&lt;p&gt;Due to slow access to GitHub Pages from within the country, the author applied for a personal domain and purchased CDN acceleration services from a domestic cloud host provider. During the configuration process, the author encountered an issue where the www subdomain could not be accessed, which was ultimately resolved by deleting the generic domain DNS record and setting up a second-level domain separately. The author also shared the principles and configuration experience of CDN acceleration, as well as their attempts and lessons learned using reverse proxy with Nginx.&lt;/p&gt;
&lt;h3 id=&#34;background&#34;&gt;Background
&lt;/h3&gt;&lt;p&gt;The website is hosted on GitHub Pages, and due to some well-known reasons, accessing GitHub Pages internally can be slow. Therefore, I applied for a personal domain name and purchased CDN acceleration services from a domestic cloud host provider. When configuring the acceleration service, I thought about my development machine, which deployed Docker, frp, k8s, and other services – all of these had accompanying dashboards. Following the principle of not wasting anything, I configured several reverse proxies and assigned them secondary domain names.&lt;/p&gt;
&lt;p&gt;When I was happily using the secondary domain names, I suddenly discovered that the www subdomain could no longer be accessed. In Aliyun, I configured DNS to resolve both &lt;a class=&#34;link&#34; href=&#34;https://www.xiangtianlong.com&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;www.xiangtianlong.com&lt;/a&gt; and xiangtianlong.com, and before enabling CDN acceleration, both domains were working normally. When configuring CDN acceleration, due to a large number of second-level domains, we enabled wildcard domain rules and unified routing them to the development machine. As a result, the ‘www’ second-level domain also went down – yes, you read that right, the ‘www’ prefix is indeed a second-level domain. The actual website is deployed on GitHub Pages, and the development machine has no cached website information.&lt;/p&gt;
&lt;p&gt;As for why the site wasn&amp;rsquo;t deployed to the development machine, it was because it was a static blog, paired with GitHub’s action to automatically integrate publishing – seriously delicious!&lt;/p&gt;
&lt;h3 id=&#34;domain&#34;&gt;Domain
&lt;/h3&gt;&lt;p&gt;Non-professional web development, the understanding of domains does not involve SEO or cross-origin issues. As a blog site, a bare domain easily highlights the blogger&amp;rsquo;s site, such as myself who uses Chinese pinyin as my domain name, and given that mobile access is now more prevalent, it’s preferable to input fewer characters.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Keyboard shortcuts can be used on desktop to avoid entering “www” and “com”.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;cdn&#34;&gt;CDN
&lt;/h3&gt;&lt;p&gt;I&amp;rsquo;ve used both Alibaba Cloud and Tencent Cloud, and it’s easy for newcomers to get started. Tencent Cloud also has dedicated video explanations of the related concepts. The principle of CDN acceleration is similar to that of a JD.com warehouse: new products are pre-distributed to warehouses across China, and when delivery requests are triggered, they&amp;rsquo;re distributed locally.&lt;/p&gt;
&lt;p&gt;Origin Return Address: The address where original website resources are stored.&lt;/p&gt;
&lt;p&gt;Cache file settings: Using F12 in the browser’s developer console to analyze static and dynamic resources.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;All 0 days validity&lt;/li&gt;
&lt;li&gt;&lt;code&gt;.php;.jsp;.asp;.aspx&lt;/code&gt; 0 days validity&lt;/li&gt;
&lt;li&gt;&lt;code&gt;.jpg;.png;.js;.css;.woff2&lt;/code&gt; 1 day validity&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Tencent Cloud configuration rules:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You can configure up to 10 cache expiration rules.&lt;/li&gt;
&lt;li&gt;The priority of multiple cache expiration rules is bottom-first.&lt;/li&gt;
&lt;li&gt;Cache expiration time can be set up to a maximum of 365 days.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;miserable-confession&#34;&gt;Miserable Confession
&lt;/h3&gt;&lt;p&gt;I had never used Nginx before, assuming I could understand reverse proxy configuration by simply searching for websites. The result was quite chaotic; I struggled for half a day without even getting a 302 redirect to work. So, I decided to take a brute-force approach – deleting wildcard domain resolution patterns in DNS and setting up individual second-level domains. Suddenly, I noticed that Alibaba Cloud DNS had a &amp;ldquo;Display URL Redirect&amp;rdquo; feature, which I tried, and wouldn&amp;rsquo;t you know it, this was exactly what I wanted as a 302 redirect.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I set up the first second-level domain normally, and then when I tried to set up the second one, it didn’t work; I almost lost my mind. After waiting for a while, it suddenly started working – apparently, Alibaba Cloud DNS sometimes has its own &amp;ldquo;mood swings.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;references&#34;&gt;References
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.zhihu.com/question/20414602&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Why are more and more website domain names not prefixed with &amp;ldquo;www&amp;rdquo;?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cloudxns.net/Support/detail/id/918.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;What&amp;rsquo;s the difference between domains with and without &amp;ldquo;www&amp;rdquo;?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://gythialy.github.io/Docker-nginx-reverse-proxy/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Docker Nginx Reverse Proxy Setup&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Blog IDE Environment and Ramblings</title>
        <link>https://ttf248.life/en/p/blog-ide-environment-and-ramblings/</link>
        <pubDate>Tue, 31 Mar 2020 13:54:27 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/blog-ide-environment-and-ramblings/</guid>
        <description>&lt;p&gt;This article introduces the basic concepts of Markdown and its applications in various software, recommends using VSCode as an IDE, and lists recommended plugins. The author shares their experience switching from Hexo to Hugo, emphasizing Hugo’s flexibility and customization capabilities. Finally, it provides some suggestions for quickly getting started with new technologies and shares a trick for resolving the issue of Hugo theme styles not updating.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction
&lt;/h2&gt;&lt;h3 id=&#34;markdown&#34;&gt;Markdown
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;A lightweight markup language that allows people to write documents in an easy-to-read and -write plain text format.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;markdown-1&#34;&gt;Markdown
&lt;/h3&gt;&lt;p&gt;Detailed Markdown syntax will not be elaborated upon in this document. We recommend an ebook, &lt;a class=&#34;link&#34; href=&#34;https://markdown-zh.readthedocs.io/en/latest/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;click here&lt;/a&gt;. Many software applications on the market now support MD as a writing format. The csdn blog system has launched an online editor that supports MD syntax; the default article when first using it is an introduction to MD syntax, which I think is quite good. Evernote added support for MD notes in 2018, with various MD markers available in the shortcut bar, making it almost as easy to use as editing a regular article, and the overall interaction process is friendly to beginners.&lt;/p&gt;
&lt;h3 id=&#34;ide-recommendations&#34;&gt;IDE Recommendations
&lt;/h3&gt;&lt;p&gt;When writing this article, it’s already 2020 – you’ve undoubtedly heard of VS Code, after all, anyone thinking about using Git Page to build a blog system is an industry professional. In the early years, Sublime and Atom were also good choices. With two years of promotion from the open-source community, VS Code has developed rapidly and has gradually become the preferred choice for newcomers.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The relationship between Microsoft’s giant and the open-source community has successfully transitioned into a honeymoon phase: embracing open source. Our company has also actively introduced the Java ecosystem in recent two years, meaning that in business development, Java&amp;rsquo;s ecosystem is now truly fragrant domestically.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;vs-code-plugin-recommendations&#34;&gt;VS Code Plugin Recommendations
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/blog-ide-environment-and-ramblings/2020-03-31-14-07-17.png&#34;
	width=&#34;310&#34;
	height=&#34;306&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Plugin List&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;101&#34;
		data-flex-basis=&#34;243px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;All plugins have their own Readme files, introducing basic usage, core functions, and some authors even provide dynamic effect demonstration images.
&lt;code&gt;Paste Image&lt;/code&gt;, combined with Hugo&amp;rsquo;s image plugin method, is very convenient for importing images.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Don’t remember the shortcuts, open the VS Code shortcut management menu, search for “md”, read it several times; review it again to look at the plugin usage instructions.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;hugo&#34;&gt;Hugo
&lt;/h2&gt;&lt;p&gt;I switched from Hexo to Hugo, as I love tinkering – it’s just my nature! Ultimately, I couldn&amp;rsquo;t resist the urge to quietly write articles.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Hugo supports placing images and Markdown documents in a single folder.&lt;/li&gt;
&lt;li&gt;The Academic theme supports various article styles in its design.&lt;/li&gt;
&lt;li&gt;Various convenient customization extensions.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;academic&#34;&gt;academic
&lt;/h2&gt;&lt;p&gt;The default website is &lt;code&gt;exampleSite&lt;/code&gt;, and menu imports are done using the &lt;code&gt;#component&lt;/code&gt; method, it’s recommended to use &lt;code&gt;url&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The URL pattern allows navigation links to jump to a single page instead of scrolling on the homepage – this is purely a matter of personal preference.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Style options: Notebooks, Speeches, eBooks&lt;/li&gt;
&lt;li&gt;Flexibility: Custom overall style, custom CSS styles&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This theme&amp;rsquo;s Chinese support isn’t very complete; primarily from a visual perspective, the font sizes don’t align well with Chinese reading habits. The Hexo development team is largely comprised of Chinese developers, which is an advantage over Hugo in this regard. However, it’s rewarding to do things yourself and customize – browser element auditing. When you locate an element, to find out the CSS style name you need to modify, you click &lt;strong&gt;Insert Style Rule Below&lt;/strong&gt;, even with nested CSS layers, it can easily get the node name.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Introduce &lt;code&gt;custom.css&lt;/code&gt;](https://sourcethemes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;academic-1&#34;&gt;academic
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Built-in syntax highlighting settings, &lt;a class=&#34;link&#34; href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/#highlighting-options.&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;official link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h2&gt;&lt;p&gt;The kids are complaining again, you’re talking so vaguely and not providing any details.&lt;/p&gt;
&lt;p&gt;What I want to say is that with these things, you have enough to work with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Official Manuals&lt;/li&gt;
&lt;li&gt;Plugin Documentation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When quickly getting started with new technologies, it&amp;rsquo;s recommended to first read the official website documentation, &lt;strong&gt;skim reading&lt;/strong&gt; – not aiming for full comprehension in one go, but at least having a general idea. Search engine results may not always be consistent with the latest version and could potentially mislead you. Similarly, flipping through a new book is best done by first looking at the table of contents to understand what the author intends to cover; sometimes it’s beneficial to read the introduction, particularly in translated foreign works where the translator&amp;rsquo;s preface often encompasses the core content of the book.&lt;/p&gt;
&lt;h2 id=&#34;easter-eggs&#34;&gt;Easter Eggs
&lt;/h2&gt;&lt;p&gt;Switching the Hugo Academic built-in style and publishing to the site, the style did not change when accessed. A clever little buddy already thought of it – clearing local browser cache could solve the problem.  It was then that I, with my ingenuity, used Developer Mode (F12) and switched to &lt;code&gt;network&lt;/code&gt;, checking “disable cache” and refreshed – and it worked!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/blog-ide-environment-and-ramblings/2020-03-31-14-27-15.png&#34;
	width=&#34;399&#34;
	height=&#34;142&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;network&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;280&#34;
		data-flex-basis=&#34;674px&#34;
	
&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>Automatic System Switchover</title>
        <link>https://ttf248.life/en/p/auto-integration-system-switch/</link>
        <pubDate>Sun, 29 Mar 2020 02:11:33 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/auto-integration-system-switch/</guid>
        <description>&lt;p&gt;Use GitHub Actions to automatically deploy your Hugo blog to GitHub Pages and Gitee.&lt;/p&gt;
&lt;h4 id=&#34;background-introduction&#34;&gt;Background Introduction
&lt;/h4&gt;&lt;p&gt;Yesterday while updating the blog, I discovered that the travis service was unavailable. Upon checking the travis webpage, I noticed the progress was stuck during source code retrieval, and a flash of insight occurred – I thought about GitHub’s previously launched action service.&lt;/p&gt;
&lt;p&gt;Due to being busy at the time and also needing to apply for access to use action, it has now officially gone live. With some free weekend time, I decided to try out a new toy?&lt;/p&gt;
&lt;p&gt;Official documentation can be found by entering the website yourself; this article won&amp;rsquo;t provide further reprints. If you’ve used Kubernetes before, you’ll find that the action YAML file configuration is very similar.&lt;/p&gt;
&lt;p&gt;Regarding introductory tutorials or Chinese introduction materials, I recommend searching for &lt;strong&gt;阮一峰’s blog&lt;/strong&gt;. There are two articles – the first introduces the basic syntax, and the second provides a practical case study.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;#### Content

Knowledge Points Needed:
- GitHub Secrets
- Action Syntax
Core jobs utilize existing components to complete tasks, and pushing to the domestic Gitee repository is achieved using commands. This command implementation is somewhat brute-force, involving forceful pushes and mirroring the logic previously used with Travis.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Content

```yaml
name: github pages and gitee pages

on:
  push:
    branches:
      - hugo

jobs:
  deploy:
    runs-on: ubuntu-18.04
    steps:
      - uses: actions/checkout@v2
        with:
          submodules: true

      - name: Setup Hugo
        uses: peaceiris/actions-hugo@v2
        with:
          hugo-version: &#39;latest&#39;
          extended: true
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;#### Content
- name: Build Github and Gitee ## Single step can only write one run command
    run: hugo -b &amp;quot;https://www.xiangtianlong.com/&amp;quot; -d &amp;quot;github_public&amp;quot; &amp;amp;&amp;amp; hugo -b &amp;quot;https://www.xiangtianlong.com/&amp;quot; -d &amp;quot;gitee_public&amp;quot; &amp;amp;&amp;amp; ls

  - name: Deploy Github
    uses: peaceiris/actions-gh-pages@v3
    with:
      github_token: ${{ secrets.BLOG_TOKEN }}
      publish_dir: ./github_public
      publish_branch: master
      cname: xiangtianlong.com
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;#### Content
- name: Deploy Gitee
    run: cd ./gitee_public &amp;amp;&amp;amp; git init &amp;amp;&amp;amp; git config user.name &amp;quot;TianlongXiang&amp;quot; &amp;amp;&amp;amp; git config user.email &amp;quot;tianlongxiang51@gmail.com&amp;quot; &amp;amp;&amp;amp; git add . &amp;amp;&amp;amp; git commit -m &amp;quot;Update TianlongXiang&#39;s Blog&amp;quot; &amp;amp;&amp;amp; git push --force &amp;quot;https://xiangtianlong:${{ secrets.GITEE_PASSWORD }}@gitee.com/xiangtianlong/xiangtianlong.git&amp;quot; master:master
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h4&gt;&lt;p&gt;Based on the actions provided by the official market, currently there are quite a few supported playstyles. After building the Docker image, it’s no longer dependent on services offered by Docker Hub.&lt;/p&gt;
&lt;p&gt;Reviewing the Hugo issues, using GitHub Actions to automatically deploy Git Pages results in the final published website needing to be on the master branch. If deployed from another branch, the settings interface will prompt an error indicating that the deployed website has syntax problems.&lt;/p&gt;
&lt;p&gt;This is simply because Hugo’s source files are located on the master branch, and GitHub treats it as the Jelly blog&amp;rsquo;s source code for detection, unable to check and resolve any errors resulting in the error message.&lt;/p&gt;
&lt;p&gt;The solution is straightforward: move Hugo source files to another branch and publish static files to the master branch.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Standard Library Container Memory Allocators: allocator</title>
        <link>https://ttf248.life/en/p/standard-library-container-memory-allocator/</link>
        <pubDate>Mon, 30 Dec 2019 13:26:19 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/standard-library-container-memory-allocator/</guid>
        <description>&lt;p&gt;A custom allocator can improve performance, increase memory utilization efficiency, and address the issue of frequent, small memory allocations.&lt;/p&gt;
&lt;h4 id=&#34;antecedent&#34;&gt;Antecedent
&lt;/h4&gt;&lt;p&gt;Recently, I&amp;rsquo;ve been working on the development of network data packets, requiring frequent allocation and release of small blocks of memory. Initially, I considered using a memory pool, reviewing several existing ones and discovering this:
&lt;a class=&#34;link&#34; href=&#34;https://github.com/cacay/MemoryPool&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/cacay/MemoryPool&lt;/a&gt;
When looking at the interface, I was quite puzzled by how the memory pool&amp;rsquo;s implementation was a bit strange. The &lt;code&gt;MemoryPool&lt;/code&gt; implementation logic involves allocating fixed-size memory blocks. Having reviewed Boost’s memory pool interface, it provides a template that is instantiated when used. Fortunately, this library already had an article describing it, mentioning the concept of an &lt;code&gt;allocator&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;#### [wiki](https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_(C%2B%2B))

In C++ programming, an allocator is a key component of the C++ standard library. The C++ library defines various data structures commonly referred to as &amp;quot;containers&amp;quot; (such as linked lists, sets, etc.). A common feature of these containers is that their size can be changed at runtime; therefore, dynamic memory allocation is necessary to achieve this. The allocator is used to handle memory allocation and deallocation requests made by the containers. In other words, the allocator encapsulates the low-level details of memory management for standard template library (STL) containers. By default, the C++ standard library uses its built-in generic allocator, but programmers can customize allocators to replace it as needed.
``` The allocator was originally invented by Alexander Stepanov as part of the C++ Standard Template Library (STL) as a way to “make the library more flexible and independent of the underlying data model,” allowing programmers to use custom pointer and reference types within the library. However, when the STL was incorporated into the C++ standard, the C++ standards committee realized that full abstraction of the data model would lead to unacceptable performance penalties. To compromise, restrictions on allocators in the standard became much stricter, and as a result, the degree to which allocators can be customized is now greatly limited compared to Stepanov’s original vision.

```markdown
#### [wiki](https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_(C%2B%2B))
Although customization of the allocator is limited, it is still often necessary to use a custom allocator in many cases, typically for encapsulating access to different types of memory spaces (such as shared memory and reclaimed memory), or for improving performance when using memory pools. Furthermore, from the perspectives of memory usage and execution time, introducing a dedicated allocator for programs that frequently perform small amounts of memory allocation can also be beneficial.
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;usage-requirementshttpszhwikipediaorgwikie58886e9858de599a8_c2b2b&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Usage Requirements&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;Defining custom allocators primarily aims to improve performance. Utilizing a dedicated custom allocator can enhance program performance, or improve memory usage efficiency, or both [4][8]. The default allocator uses the &lt;code&gt;new&lt;/code&gt; operator to allocate storage [Reference 5], which often leverages the C language heap allocation function (malloc()) [9]. Because heap allocation functions are typically optimized for occasional large memory allocations, the default allocator generally performs well when allocating memory for containers that require a single large memory allocation, such as vectors and doubly-ended queues [8]. However, when using the default allocator to allocate memory for associative containers with linked lists or bidirectional linked lists – which frequently require allocating small amounts of memory – it is typically inefficient [4][9].&lt;/p&gt;
&lt;h4 id=&#34;usage-requirementshttpsenwikipediaorgwikipool_allocation_c2b2b&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Pool_allocation_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Usage Requirements&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;In short, this section (…)(like) is a “I Have a Dream” speech for the allocator. Before the dream comes true, programmers concerned with portability will be limited to (using) stateless custom allocators.
—Scott Meyers, &lt;em&gt;Effective STL&lt;/em&gt;
Given this, in this case, memory pools are often used to address frequent, small allocations [8]. Unlike the default “on-demand allocation” method, when using a memory pool allocator, the program pre-allocates large blocks of memory (referred to as the “memory pool”) upfront.  Then, when requesting memory, the custom allocator simply returns a pointer to an available block within the pool. Unlike object deconstruction, where memory is not actually released, this release is deferred until the lifecycle of the memory pool ends [Note 1][8].&lt;/p&gt;
&lt;h4 id=&#34;usage-requirementshttpszhwikipediaorgwikie58886e9858de599a8_c2b2b-1&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Usage Requirements&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;On the topic of &amp;ldquo;Custom Allocators,&amp;rdquo; numerous C++ experts and authors have participated in discussions, such as Scott Meyers&amp;rsquo; &lt;em&gt;Effective STL&lt;/em&gt; and Andrei Alexandrescu’s &lt;em&gt;Modern C++ Design&lt;/em&gt;, which both mention it. Meyers observed that if one requires all instances of a particular type &lt;code&gt;T&lt;/code&gt;’s allocator to be equal, then the portable allocator instance must not contain state. Although the C++ standard encourages library implementers to support stateful allocators [Ref 4], Meyers called this paragraph “(seemingly) a wonderful idea,” but it is almost nonsense, and he considered the allocator restrictions “too strict” [4]. For example, STL’s list allows the splice method, meaning a node from one list object A can be directly inserted into another list object B. This requires that the memory allocated by A’s allocator is released by B’s allocator, thereby deducing that A and B’s allocator instances must be equal. Meyer’s conclusion is that allocators should be defined as types using static methods. For example, according to the C++ standard, an allocator must provide a class template other that implements the rebind method.&lt;/p&gt;
&lt;h4 id=&#34;usage-requirementshttpszhwikipediaorgwikie58886e9858de599a8_c2b2b-2&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Usage Requirements&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;Additionally, in &lt;em&gt;The C++ Programming Language&lt;/em&gt; by Bjarne Stroustrup, he states “&amp;lsquo;strict allocation to avoid different information for each object,&amp;rsquo; this is clearly not an issue” (roughly), and notes that most allocators don’t need state, or even perform better when there is no state. He proposes three custom allocator use cases: a pool-based allocator, a shared memory allocator, and a garbage collector allocator, and demonstrates an implementation using an internal memory pool to quickly allocate/deallocate small amounts of memory. However, he also notes that such optimization may already be achieved in the sample allocator he provides [3].
Another use for custom allocators is debugging memory-related errors [10]. To achieve this, you can write a memory allocator that allocates additional memory when allocating, and uses it to store debugging information. This allocator not only ensures that memory is allocated/deallocated by the same type of allocator, but also provides some protection against cache overflows [11].&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Computer on Uncle Xiang&#39;s Notebook</title>
        <link>https://ttf248.life/en/categories/computer/</link>
        <description>Recent content in Computer on Uncle Xiang&#39;s Notebook</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Mon, 02 Jun 2025 07:41:32 +0800</lastBuildDate><atom:link href="https://ttf248.life/en/categories/computer/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>GitHub Pages Easter Egg: Deploying Multiple Pages</title>
        <link>https://ttf248.life/en/p/github-pages-easter-egg-deploy-multiple-sites/</link>
        <pubDate>Wed, 28 May 2025 02:55:54 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/github-pages-easter-egg-deploy-multiple-sites/</guid>
        <description>&lt;p&gt;Recently, my biological clock has been a bit off, still messing around with GitHub Pages deployments at nearly 2 AM.&lt;/p&gt;
&lt;p&gt;I went to eat after work, and I just wanted to sleep as soon as I finished eating. After eating, I came back around 8:30 PM, feeling drowsy, I thought about taking a nap, and then fell asleep immediately. When I woke up, it was already nearly 2 AM.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Categories that haven&amp;rsquo;t even launched yet: AI Study Group&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;facepalm&#34;&gt;Facepalm
&lt;/h2&gt;&lt;p&gt;Yesterday we said there wouldn&amp;rsquo;t be much frontend development, but today it’s not frontend – it’s the experience of UI/UX.&lt;/p&gt;
&lt;h2 id=&#34;project&#34;&gt;Project
&lt;/h2&gt;&lt;p&gt;Please join our old friend, &lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/ai-coding-demo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/ai-coding-demo&lt;/a&gt;.
That’s the original self-selected stock project – we&amp;rsquo;re restructuring the overall project structure, and all subsequent AI programming content will be housed within this project.&lt;/p&gt;
&lt;h2 id=&#34;deploying-multiple-pages&#34;&gt;Deploying Multiple Pages
&lt;/h2&gt;&lt;p&gt;The project is hosted domestically at [https://cnb.cool/ttf248/ai-coding-demo]. Due to well-known reasons, pages cannot be published within China, so we need to publish them on GitHub outside of the country.&lt;/p&gt;
&lt;p&gt;The blog is published on this external GitHub. I haven&amp;rsquo;t tried it before, and also, the current project I’m working on isn’t a traditional blog site; it simply contains a lot of documentation layered with several static HTML design mockups.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/github-pages-easter-egg-deploy-multiple-sites/20250528030230.png&#34;
	width=&#34;798&#34;
	height=&#34;530&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;pages&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;150&#34;
		data-flex-basis=&#34;361px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;That’s right – this page is where I first discovered that deploying multiple pages using Pages doesn&amp;rsquo;t affect the blog’s publication, but instead adds a new path under the blog’s domain name.&lt;/p&gt;
&lt;p&gt;[https://ttf248.life/ai-coding-demo/](https://ttf248.&lt;/p&gt;
&lt;h2 id=&#34;ai-study-group&#34;&gt;AI Study Group
&lt;/h2&gt;&lt;p&gt;Yesterday, I created a new category and thought about using AI to learn many computer courses, such as algorithms and LeetCode practice problems.
Each learning record is published on the blog to form a knowledge base. A new category was created: AI Study Group.
Now it seems that different courses require creating separate projects, and all learning notes are written in the project&amp;rsquo;s Readme.md file.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Old problems, the flamboyant beauty of blossoming flowers (a reference to a famous Chinese poem).</title>
        <link>https://ttf248.life/en/p/old-ailment-stunning-flowers/</link>
        <pubDate>Mon, 26 May 2025 23:54:12 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/old-ailment-stunning-flowers/</guid>
        <description>&lt;p&gt;For many years, I’ve focused on backend development, and recently started to explore &lt;code&gt;AI&lt;/code&gt; programming while dipping my toes into some frontend-related content. However, during this period of tinkering, I gradually realized I was falling back into an old habit – being dazzled by shiny new things. I constantly try to use &lt;code&gt;AI&lt;/code&gt; to create a frontend interface, but in reality, these attempts haven’t provided much practical benefit for my current work and are actually diverting my attention.&lt;/p&gt;
&lt;h2 id=&#34;ai-use-cases&#34;&gt;AI Use Cases
&lt;/h2&gt;&lt;p&gt;In small projects, AI tools can truly shine, particularly when writing independent functions with low coupling to the system and simple business logic. These tasks typically have clear inputs and outputs, and rely less on context – making them well-suited for the current capabilities of AI-assisted programming.&lt;/p&gt;
&lt;p&gt;However, when facing complex system architectures or deep business logic, the limitations of AI become increasingly apparent. It may generate code that appears reasonable but is actually detached from the project’s real needs, or even introduce potential issues that are difficult to debug. In these scenarios, AI is best suited as an assistive tool rather than a fully autonomous code generator. We need to conduct rigorous review and testing of any generated code to ensure it meets actual requirements.&lt;/p&gt;
&lt;h2 id=&#34;errors-and-the-cost-of-learning&#34;&gt;Errors and the Cost of Learning
&lt;/h2&gt;&lt;p&gt;While attempting to generate frontend code using AI, I encountered numerous challenges. As frontend development isn&amp;rsquo;t my area of expertise, troubleshooting often proved time-consuming and frustrating. Even after adjusting prompts to have the AI rewrite the code, it was difficult to avoid the appearance of some low-level errors. This iterative process not only wasted time but also highlighted that my current focus should be on backend business logic rather than exploring unfamiliar domains.&lt;/p&gt;
&lt;p&gt;Looking back at the project completed over the weekend, I’m more confident that focusing on backend development and user interaction logic, implementing functionality through a console, is the most efficient approach currently. Perhaps systematically learning frontend knowledge would be a better strategy when I have more time and energy.&lt;/p&gt;
&lt;h2 id=&#34;frontend-learning-plan&#34;&gt;Frontend Learning Plan
&lt;/h2&gt;&lt;p&gt;The frontend technology stack is complex and diverse, so it’s unrealistic to quickly master it. I plan to first choose a framework, such as Vue.js or React.js, and deeply learn its core concepts and usage methods. Only after becoming familiar with the fundamentals will I attempt to use AI to generate frontend code, which can effectively avoid errors and wasted time caused by unfamiliarity.&lt;/p&gt;
&lt;p&gt;In short, the focus for this stage should be on backend development, steadily building up my core skills. Once the timing is right, I’ll explore the combination of frontend and AI – potentially yielding greater rewards.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Claude4 released, attempting to develop: Hugo tags, hyperlink translation assistant</title>
        <link>https://ttf248.life/en/p/claude-4-release-and-experimentation-hugo-tags-hyperlink-translation-assistant/</link>
        <pubDate>Sat, 24 May 2025 03:05:31 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/claude-4-release-and-experimentation-hugo-tags-hyperlink-translation-assistant/</guid>
        <description>&lt;p&gt;This site is developed using Hugo, but I’ve always used Chinese titles, which results in less friendly generated article links. In simpler terms, when shared, they don&amp;rsquo;t look as good because the Chinese characters are escaped into formats like %E4%BD%A0%E5%A5%BD within the links. While you can solve this by setting a slug, it’s tedious to do manually every time.&lt;/p&gt;
&lt;p&gt;Therefore, I decided to try using Claude4 to develop a translation assistant that automatically converts Chinese titles to English slugs and adds hyperlinks within the articles. This would eliminate the need for manual setup.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Claude4 is amazing – its contextual understanding has significantly improved, as has its efficiency in handling complex tasks.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;project-address&#34;&gt;Project Address
&lt;/h2&gt;&lt;p&gt;Domestic Project Address: &lt;a class=&#34;link&#34; href=&#34;https://cnb.cool/ttf248/hugo-content-suite&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://cnb.cool/ttf248/hugo-content-suite&lt;/a&gt;
International Project Address: &lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/hugo-content-suite&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/hugo-content-suite&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;code-implementation&#34;&gt;Code Implementation
&lt;/h2&gt;&lt;p&gt;Let&amp;rsquo;s first discuss the implementation approach: We need to scan all articles, extract tag information and article titles, and then call the local large model (such as gemma-3-12b-it) for translation.&lt;/p&gt;
&lt;p&gt;In actual development, Claude4 showcased several significant advantages compared to previous generation large models. Due to the diverse functional requirements, Claude4 automatically designed an interactive menu, comprehensively considering various usage scenarios. For example, in tag processing, Claude4 not only supports tag statistics and analysis but also includes classification statistics, and can even detect &lt;strong&gt;unlabeled articles&lt;/strong&gt;. Furthermore, it provides &lt;strong&gt;preview&lt;/strong&gt; and tag page generation functionalities.&lt;/p&gt;
&lt;p&gt;Whether it’s integrating with the local large model, adding translation caches, or performing large-scale code refactoring, Claude4 completes everything in one go, with almost no issues. Despite the project’s small scale, it incorporates many minor features. In previous development cycles with large models, there was often a tendency to forget earlier content; however, Claude 4 performed exceptionally well, &lt;strong&gt;virtually eliminating context loss&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In short, its intelligence has increased, and we plan to switch to Claude 4 for more development work as our primary coding model.&lt;/p&gt;
&lt;h2 id=&#34;translation-cache&#34;&gt;Translation Cache
&lt;/h2&gt;&lt;p&gt;This approach, besides reducing the number of calls to large models, is quite efficient when running a 12b model locally – it doesn’t waste much time. However, if you need to call the large model every time, it will still be somewhat slow. Secondly, to fix the connections within articles, if a full update operation is executed and the article title is very long, there&amp;rsquo;s occasionally a situation where the two translated results differ, causing the link to change – which is quite awkward.&lt;/p&gt;
&lt;h2 id=&#34;feature-optimization&#34;&gt;Feature Optimization
&lt;/h2&gt;&lt;p&gt;The entire project was handed over to &lt;code&gt;Claude4&lt;/code&gt; to analyze the space for optimization and generate the following recommendations:&lt;/p&gt;
&lt;p&gt;Reviewed the code, which had no issues whatsoever. For example, the configuration files were reviewed, and the original code’s configurations were converted into default configurations. When reading the configuration file, if a corresponding configuration file did not exist, a default configuration file would be automatically generated to avoid user operational errors. Here&amp;rsquo;s the English translation of the provided text:&lt;/p&gt;
&lt;p&gt;“Requirements: When translating, dynamically calculate the current translation efficiency, estimate remaining time, and output relevant information to the console. Currently, we’re obtaining the character count of the article, the number of characters translated per line, the time taken, and fitting a calculation for the translation time of every 100 characters. Simultaneously, we&amp;rsquo;re calculating the estimated remaining translation time.&lt;/p&gt;
&lt;p&gt;The code is complete, but the effect isn’t satisfactory, so I ask AI to provide a new design solution:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Provide multiple efficiency calculation methods: real-time efficiency, average efficiency, and sliding window efficiency&lt;/li&gt;
&lt;li&gt;Improve display format: progress bar, segmented statistics, dynamic refresh&lt;/li&gt;
&lt;li&gt;Add more useful metrics: API call counts, success rates.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After completing the code, we discovered a new surprise – translation efficiency statistics were flooding the console in real time, but without endless scrolling.” Here&amp;rsquo;s the English translation of the provided text:&lt;/p&gt;
&lt;p&gt;“Requirements: When translating, dynamically calculate the current translation efficiency, estimate remaining time, and output relevant information to the console. Currently, we’re obtaining the character count of the article, the number of characters translated per line, the time taken, and fitting a calculation for the translation time of every 100 characters. Simultaneously, we&amp;rsquo;re calculating the estimated remaining translation time.&lt;/p&gt;
&lt;p&gt;The code is complete, but the results aren’t satisfactory, so I’m asking AI to provide a new design solution:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Provide multiple efficiency calculation methods: real-time efficiency, average efficiency, and sliding window efficiency&lt;/li&gt;
&lt;li&gt;Improve display format: progress bars, segmented statistics, and dynamic refresh&lt;/li&gt;
&lt;li&gt;Add more useful metrics: API call counts, success rates, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After completing the code, we discovered a new surprise – translation efficiency statistics were flooding the console in real time, but without requiring endless scrolling.”&lt;/p&gt;
&lt;h3 id=&#34;performance-statistics-menu&#34;&gt;Performance Statistics Menu
&lt;/h3&gt;&lt;p&gt;The newly added &lt;strong&gt;Performance Statistics Menu&lt;/strong&gt;, which I myself designed, isn&amp;rsquo;t as well-designed as this one.&lt;/p&gt;
&lt;p&gt;📊 Performance Statistics:
🔄 Translation Count: 360
⚡ Cache Hit Rate: 1.4% (5/365)
⏱️ Average Translation Time: 315.927234ms
📁 File Operations: 73
❌ Error Count: 0&lt;/p&gt;
&lt;h3 id=&#34;progress-bar-display&#34;&gt;Progress Bar Display
&lt;/h3&gt;&lt;p&gt;The newly added &lt;strong&gt;Progress Bar Display&lt;/strong&gt;, detailed progress, elapsed time, and estimated remaining time.
Please select function (0-13): 10
🔍 Collecting translation target&amp;hellip;
📄 Cached file loaded, containing 0 translation records
📊 Translation cache statistics:
🏷️ Total tags: 229
📝 Total articles: 131
✅ Cached: 0
🔄 To be translated: 360&lt;/p&gt;
&lt;h3 id=&#34;progress-bar-display-1&#34;&gt;Progress Bar Display
&lt;/h3&gt;&lt;p&gt;Confirm full translation cache generation? (y/n): y
🚀 Generating full translation cache&amp;hellip;
📄 Loaded cache file, containing 0 translation records
🔍 Checking translations in cache&amp;hellip;
🔄 Need to translate 360 new tags
[░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 5/360 (1.4%) - Time taken: 3s - Estimated remaining: 3m8s
💾 Saved cache file, containing 5 translation records
[█░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 10/360 (2. 8%) - Time taken: 6s - Estimated remaining: 3m28s 💾 Cache file saved, containing 10 translation records
[██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 15/360 (4.2%) - Time taken: 9s - Estimated remaining: 3m30s 💾 Cache file saved, containing 15 translation records&lt;/p&gt;
&lt;h3 id=&#34;progress-bar-display-2&#34;&gt;Progress Bar Display
&lt;/h3&gt;&lt;p&gt;[██████████████████████████████████] 20/360 (5.6%) - Time Elapsed: 13s - Estimated Remaining: 3m36s💾 Cache file saved, containing 20 translation records
[████████████████████████████████░░] 25/360 (6.9%) - Time Elapsed: 16s - Estimated Remaining: 3m33s💾 Cache file saved, containing 25 translation records
[██████████████████████████████████] 30/360 (8. (3%) - Time taken: 19s - Estimated remaining: 3m30s [████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 35/360 (9.7%) - Time taken: 22s - Estimated remaining: 3m25s [████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░]&lt;/p&gt;
&lt;h3 id=&#34;progress-bar&#34;&gt;Progress Bar
&lt;/h3&gt;&lt;hr&gt;
</description>
        </item>
        <item>
        <title>Merge the Pull Request into the Repository of the Fork</title>
        <link>https://ttf248.life/en/p/merge-pullrequest-to-fork-repository/</link>
        <pubDate>Wed, 07 May 2025 18:44:03 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/merge-pullrequest-to-fork-repository/</guid>
        <description>&lt;p&gt;&lt;code&gt;github-readme-stats&lt;/code&gt; is a GitHub profile statistics generator that allows users to display various statistics and charts within their GitHub profiles. It offers multiple customization options to tailor it to user needs.&lt;/p&gt;
&lt;p&gt;I manage my repository habits by grouping them by project; GitHub doesn&amp;rsquo;t support repository grouping, so I have to achieve this by splitting repositories across different organizations. The latest branch of &lt;code&gt;github-readme-stats&lt;/code&gt; cannot support statistics for repositories spanning different organizations; I forked a branch and merged the corresponding code.&lt;/p&gt;
&lt;h2 id=&#34;final-result&#34;&gt;Final Result
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://github-readme-stats-chi-one-17.vercel.app/api?username=ttf248&amp;amp;hide_title=true&amp;amp;show_icons=true&amp;amp;hide=contribs&amp;amp;line_height=24&amp;amp;include_all_commits=true&amp;amp;count_private=true&amp;amp;bg_color=0000&amp;amp;text_color=8A919F&amp;amp;locale=cn&amp;amp;role=OWNER,COLLABORATOR,ORGANIZATION_MEMBER&amp;amp;timstamp=1746608356&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;GitHub Stats&#34;
	
	
&gt;
&lt;img src=&#34;https://github-readme-stats-chi-one-17.vercel.app/api/top-langs/?username=ttf248&amp;amp;hide_title=true&amp;amp;hide=html,javascript,css&amp;amp;layout=compact&amp;amp;bg_color=0000&amp;amp;text_color=8A919F&amp;amp;locale=cn&amp;amp;role=OWNER,COLLABORATOR,ORGANIZATION_MEMBER&amp;amp;timstamp=1746608356&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Top Languages&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;pull-request-original-address&#34;&gt;Pull Request Original Address
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/anuraghazra/github-readme-stats/pull/2459&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Adds the ability to include data from organization repositories&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;merging-a-pull-request-into-your-forked-repository&#34;&gt;Merging a Pull Request into Your Forked Repository
&lt;/h2&gt;&lt;p&gt;To merge a &lt;strong&gt;Pull Request (PR)&lt;/strong&gt; into your &lt;strong&gt;forked repository&lt;/strong&gt;, there are several ways to do this, depending on whether you want to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Merge the PR from the &lt;strong&gt;upstream repository&lt;/strong&gt; into your fork, or&lt;/li&gt;
&lt;li&gt;Merge a PR from another person’s fork into your fork, or&lt;/li&gt;
&lt;li&gt;Merge a PR that was opened on your fork (e.g., someone forked and created a PR for you)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I&amp;rsquo;ll first give you a common scenario: &lt;strong&gt;You have forked a repository and want to merge a PR from the upstream into your fork&lt;/strong&gt;.  Here’s the workflow below 👇&lt;/p&gt;
&lt;h3 id=&#34;-method-one-command-line-most-universal&#34;&gt;✅ Method One: Command Line (Most Universal)
&lt;/h3&gt;&lt;h4 id=&#34;step-1-clone-your-own-fork&#34;&gt;Step 1: Clone your own fork
&lt;/h4&gt;&lt;h4 id=&#34;step-2-add-upstream-original-repository-address&#34;&gt;Step 2: Add upstream (original repository address)
&lt;/h4&gt;&lt;h4 id=&#34;step-3-fetch-the-upstream-pr-branch&#34;&gt;Step 3: Fetch the Upstream PR Branch
&lt;/h4&gt;&lt;p&gt;Find the PR number you want to merge, such as PR #123.
You can then checkout the code for that PR like this:&lt;/p&gt;
&lt;h4 id=&#34;step-4-switch-and-merge-branches&#34;&gt;Step 4: Switch and Merge Branches
&lt;/h4&gt;&lt;p&gt;If everything is working correctly, you can push your changes to your forked GitHub repository:&lt;/p&gt;
&lt;h3 id=&#34;-method-two-github-web-interface-simple-but-limited&#34;&gt;✅ Method Two: GitHub Web Interface (Simple but Limited)
&lt;/h3&gt;&lt;p&gt;If you see a PR on GitHub’s web interface that is against the upstream repository, you can:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Navigate to the PR page.&lt;/li&gt;
&lt;li&gt;Click “&lt;strong&gt;Commits&lt;/strong&gt;” or “&lt;strong&gt;Files changed&lt;/strong&gt;” in the top-right corner to see which branch this PR is based on.&lt;/li&gt;
&lt;li&gt;On your fork page, create a new branch and then manually cherry-pick the PR’s commit (requires Git knowledge).&lt;/li&gt;
&lt;li&gt;Or, click “&lt;strong&gt;Open in GitHub Desktop&lt;/strong&gt;” and use the GUI tool to merge.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;-if-someone-has-created-a-fork-and-submitted-a-pr-to-it-simply-navigate-to-the-pr-page-click-the-merge-pull-request-button-and-youre-done&#34;&gt;🚀 If someone has created a fork and submitted a PR to it, simply navigate to the PR page, click the &amp;ldquo;&lt;strong&gt;Merge pull request&lt;/strong&gt;&amp;rdquo; button, and you’re done.
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;Would you like me to walk you through it step-by-step based on your specific scenario (e.g., PR link, whether you&amp;rsquo;re using a web interface or command line)? Or, please provide the link and I can analyze the simplest approach for you.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Commit messages in Git’s history</title>
        <link>https://ttf248.life/en/p/git-modify-commit-message/</link>
        <pubDate>Wed, 07 May 2025 18:38:31 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/git-modify-commit-message/</guid>
        <description>&lt;p&gt;Script to batch modify Git history commit author information, rewriting the Git history records using &lt;code&gt;git filter-branch&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The script you provided is used to batch modify the author information in the Git repository history. The overall approach is correct, but using an array (like &lt;code&gt;OLD_EMAILS=(&amp;quot;...&amp;quot;)&lt;/code&gt;) within the &lt;code&gt;git filter-branch&lt;/code&gt; &lt;code&gt;--env-filter&lt;/code&gt; might cause compatibility issues because some shell environments (such as &lt;code&gt;/bin/sh&lt;/code&gt;) do not support array syntax.&lt;/p&gt;
&lt;p&gt;To improve compatibility, it&amp;rsquo;s recommended to replace the array with a string separated by spaces and iterate through each old email address using a &lt;code&gt;for&lt;/code&gt; loop. Here’s an example of the modified script:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is highly recommended to back up your repository before executing this script to prevent any unforeseen issues. - This operation will rewrite Git history, modifying commit author information and may cause the commit hash values to change.&lt;/li&gt;
&lt;li&gt;If you have already pushed your changes to a remote repository, you need to use a forced push:
Please exercise caution when using forced pushes, especially in collaborative projects, to avoid impacting others.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Count all unique authors&amp;rsquo; email addresses in the repository&lt;/p&gt;</description>
        </item>
        <item>
        <title>Feeling bored and wanting to design a Chinese ink wash style theme.</title>
        <link>https://ttf248.life/en/p/chinese-ink-style-theme/</link>
        <pubDate>Tue, 08 Apr 2025 03:42:47 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/chinese-ink-style-theme/</guid>
        <description>&lt;p&gt;I’ve gotten tired of staring at colorful, cluttered homepages and suddenly want to go for a minimalist style, designing a Chinese ink wash theme.&lt;/p&gt;
&lt;p&gt;Because the current stylesheet is heavily customized, with specific styles configured to override the default theme styles for different elements.&lt;/p&gt;
&lt;p&gt;Without refactoring, I tried using AI directly to generate a new theme, and the results were very unstable.  Coincidentally, I also encountered a queue for trae claude large language model switching to vscode agent mode, which resulted in even worse effects – the generated output had no design sense whatsoever.&lt;/p&gt;
&lt;p&gt;Ultimately, it comes down to the fact that I don’t fully understand front-end development and can&amp;rsquo;t effectively break down tasks and hand them over to AI.&lt;/p&gt;</description>
        </item>
        <item>
        <title>No coding, design and develop a self-selected stock module.</title>
        <link>https://ttf248.life/en/p/no-code-design-develop-custom-stock-module/</link>
        <pubDate>Thu, 27 Feb 2025 23:20:39 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/no-code-design-develop-custom-stock-module/</guid>
        <description>&lt;ul&gt;
&lt;li&gt;Last month, we experimented with cursor, but due to the limitations of the free quota, we didn&amp;rsquo;t develop overly complex features; we just did some basic testing. We discovered then that Byte also released similar products, both using the same large models – Claude-3.5 – at their core.
Byte’s product is called Trae, initially launched in the Mac version and finally released its Windows version in February of this year. Big companies are good because you can freely “white嫖” (literally translates to &amp;ldquo;free grab&amp;rdquo;) without paying; you get unlimited use of Claude-3.5. The performance of this model is quite impressive.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Ultimately, we got stuck on the development of candlestick charts. As I don’t understand React at all, I had to give up. To continue developing, I would need to supplement my knowledge of front-end basics, breaking down the task into smaller, more manageable pieces instead of directly giving me a large task: developing candlestick charts.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;issues-found&#34;&gt;Issues Found
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Due to the limited training data caused by using foreign AI models and Vue3 + Element-Plus, React was chosen as the frontend framework.&lt;/li&gt;
&lt;li&gt;There may be occasional syntax errors requiring manual fixes.&lt;/li&gt;
&lt;li&gt;Solutions for some complex problems require manual guidance.&lt;/li&gt;
&lt;li&gt;Code structure optimization requires manual instruction.&lt;/li&gt;
&lt;li&gt;The most time-consuming part was packaging the frontend code into a container, due to my zero experience with &lt;code&gt;.env.production&lt;/code&gt; and &lt;code&gt;tsconfig.json&lt;/code&gt;, I had no concept of these either; I sought help from community members along the way to sort out the corresponding logic. There are significant differences between the development and build modes in frontend development, and the checks performed on the code. Backend database and service container scripts were completed in a total of five minutes.
&lt;strong&gt;Currently, AI primarily improves development efficiency. Having a foundation is best; it won’t solve all problems for you.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;repository-address&#34;&gt;Repository Address
&lt;/h2&gt;&lt;p&gt;As the title indicates, this time we&amp;rsquo;re going to chat with AI without actually coding and see what we can achieve.  Let’s take a look at the final outcome.&lt;/p&gt;
&lt;p&gt;Repository Address: &lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/trae-demo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/trae-demo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For detailed usage instructions, please refer to the README.md file in the repository.&lt;/p&gt;
&lt;p&gt;The repository contains numerous submission records, most of which are dialogues between me and Trae, as well as my testing of Trae’s functionalities, with notes on whether manual intervention was required to implement each feature.&lt;/p&gt;
&lt;h2 id=&#34;prompt&#34;&gt;Prompt
&lt;/h2&gt;&lt;p&gt;Project is created from scratch, below is the project prompt:&lt;/p&gt;
&lt;h2 id=&#34;ui-and-interaction-optimization&#34;&gt;UI and Interaction Optimization
&lt;/h2&gt;&lt;p&gt;The design of the front-end interface relies entirely on Grok. We initially created a prototype within Trae, but it lacked aesthetics. Because the model used has strong coding capabilities but weaker other abilities, we need to use Grok to optimize the front-end UI.&lt;/p&gt;
&lt;p&gt;By taking screenshots of the current interface and uploading them to Grok, we can obtain numerous optimization suggestions at once. We then manually evaluate these suggestions and copy them into Trae to execute and observe the results of the optimizations.&lt;/p&gt;
&lt;h3 id=&#34;technology-stack&#34;&gt;Technology Stack
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Frontend: React + TypeScript&lt;/li&gt;
&lt;li&gt;Backend: Golang + Gin + GORM&lt;/li&gt;
&lt;li&gt;Database: PostgreSQL 17&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;system-architecture&#34;&gt;System Architecture
&lt;/h2&gt;&lt;h2 id=&#34;backend-architecture&#34;&gt;Backend Architecture
&lt;/h2&gt;&lt;p&gt;The backend utilizes the Gin framework (Go) to implement RESTful APIs, with the following key modules:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Database Module&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Utilizes GORM as an ORM framework&lt;/li&gt;
&lt;li&gt;Supports database connection configuration via environment variables&lt;/li&gt;
&lt;li&gt;Automatically performs database schema migrations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Routing Module&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;RESTful API design&lt;/li&gt;
&lt;li&gt;A unified error handling mechanism&lt;/li&gt;
&lt;li&gt;Built-in request logging&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cross-Origin Handling&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Supports cross-origin requests from local development environments&lt;/li&gt;
&lt;li&gt;Configurable CORS policies&lt;/li&gt;
&lt;li&gt;Supports cookie-based cross-origin access&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;frontend-architecture&#34;&gt;Frontend Architecture
&lt;/h2&gt;&lt;p&gt;The frontend was built using React + TypeScript, implementing the following features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stock list display&lt;/li&gt;
&lt;li&gt;Watchlist management&lt;/li&gt;
&lt;li&gt;Real-time quote data display&lt;/li&gt;
&lt;li&gt;Error handling mechanism&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Protobuf Zero Value Pitfall: When Default Values Become an Invisible Killer of Business Logic</title>
        <link>https://ttf248.life/en/p/protobuf-zero-value-traps/</link>
        <pubDate>Thu, 20 Feb 2025 15:26:51 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/protobuf-zero-value-traps/</guid>
        <description>&lt;p&gt;The US stock market has three trading sessions: pre-market, live market, and post-market. The logic for pushing data – whether it’s full data streams or numerical increments – is optimized to conserve bandwidth (sending as little data as possible). Initially, only the full dataset is sent once, and subsequent transmissions are incremental updates of all fields.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Why not use the optimal solution? This involves multiple project teams, some of which have been live for many years. As we’re a new integration, we can only strive for compatibility.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;a-series-of-issues&#34;&gt;A Series of Issues
&lt;/h2&gt;&lt;p&gt;Just from the summary, it might seem like there aren&amp;rsquo;t any problems, but once the system architecture is brought in, a series of issues arise. Immediately after resolving the previous issue, a new one emerged – this problem was caused by the prior one.&lt;/p&gt;
&lt;h3 id=&#34;unable-to-identify-trading-intervals&#34;&gt;Unable to Identify Trading Intervals
&lt;/h3&gt;&lt;p&gt;The market phase is defined in &lt;code&gt;protobuf&lt;/code&gt; as 0, but because it’s received via incremental push, the business side cannot effectively determine whether this ‘0’ represents the default value or a genuine business value.&lt;/p&gt;
&lt;p&gt;In simpler terms: Each time a &amp;lsquo;0&amp;rsquo; is received, it’s impossible to discern whether it’s the new market phase setting or the &lt;code&gt;protobuf&lt;/code&gt; default value.&lt;/p&gt;
&lt;h3 id=&#34;introducing-optional&#34;&gt;Introducing Optional
&lt;/h3&gt;&lt;p&gt;Since protobuf release 3.15, proto3 supports using the optional keyword (just as in proto2) to provide presence information for a scalar field.&lt;/p&gt;
&lt;p&gt;The group’s communication protocol is based on &lt;code&gt;protobuf&lt;/code&gt;, but due to historical reasons, the version selected was older and did not support the &lt;code&gt;optional&lt;/code&gt; keyword. As you know, because we introduced &lt;code&gt;protobuf&lt;/code&gt; from the ground up, publishing the project as a static library, this resulted in needing to upgrade the entire build chain, which was a very high cost.&lt;/p&gt;
&lt;h3 id=&#34;gcc-version-issues&#34;&gt;GCC Version Issues
&lt;/h3&gt;&lt;p&gt;After painstakingly devising a solution, we planned to release two different underlying versions to control the propagation of dependencies for the new &lt;code&gt;protobuf&lt;/code&gt; version as much as possible. However, during compilation, we discovered that the &lt;code&gt;gcc&lt;/code&gt; version was too low and did not support the new features of &lt;code&gt;protobuf&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The commonly used server types within our team are CentOS7 and CentOS8. The default &lt;code&gt;gcc&lt;/code&gt; version on CentOS7 is 4.8, while the default &lt;code&gt;gcc&lt;/code&gt; version on CentOS8 is 8.3. Since the new features of &lt;code&gt;protobuf&lt;/code&gt; require a &lt;code&gt;gcc&lt;/code&gt; version of 7.4 or higher, CentOS7 could not support it.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://gcc.gnu.org/bugzilla/show_bug.cgi?id=82461&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Bug 82461 - [7 Regression] Temporary required for brace-initializing (non-literal-type) member variable&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Ultimately, after a lot of troubleshooting, we moved the deployments of related services and the compilation server to CentOS8, resolving this issue.&lt;/p&gt;
&lt;h2 id=&#34;reasonable-enumeration&#34;&gt;Reasonable Enumeration
&lt;/h2&gt;&lt;p&gt;Reviewing the entire problem, there’s a simpler and more efficient solution: adjust the enumeration definition to start numbering from 1 instead of 0. This effectively distinguishes between default values and business values, avoiding all the aforementioned issues.&lt;/p&gt;
&lt;h3 id=&#34;why-starting-from-1-is-more-reasonable&#34;&gt;Why Starting from 1 is More Reasonable?
&lt;/h3&gt;&lt;p&gt;In &lt;code&gt;protobuf&lt;/code&gt;, enum types have a default value fixed to 0. If we define meaningful business values as 0 (e.g., &amp;ldquo;Market Open&amp;rdquo;), in incremental pushes, the business side cannot determine whether the received 0 is a business value or an unset default value.  If instead, we defined the enum starting from 1, 0 could be retained as a meaningless default value or “Unknown” state, resolving the issue neatly.&lt;/p&gt;
&lt;p&gt;Recommended Practice:
When designing &lt;code&gt;protobuf&lt;/code&gt; enums, always define 0 as a meaningless default value (e.g., &lt;code&gt;UNKNOWN&lt;/code&gt; or &lt;code&gt;RESERVED&lt;/code&gt;).
Assign actual business values starting from 1 to ensure they are distinguished from the default value of 0.&lt;/p&gt;
&lt;p&gt;With this small adjustment, we not only resolved the issue of identifying trading hours but also provided a valuable lesson for future protocol design.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Background Service TCP Communication Anomaly Troubleshooting</title>
        <link>https://ttf248.life/en/p/backend-service-tcp-communication-troubleshooting/</link>
        <pubDate>Fri, 14 Feb 2025 22:54:13 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/backend-service-tcp-communication-troubleshooting/</guid>
        <description>&lt;p&gt;Business Model: The backend service establishes a connection with the group’s market data gateway using TCP. Each time a connection is established, it must first send an authorization request and then continuously send heartbeat packages to maintain the connection status.&lt;/p&gt;
&lt;p&gt;However, one day, an alert message was received indicating that the service had disconnected. After carefully examining the logs, it was discovered that the backend service was continuously sending heartbeat packages, but the other party did not respond at all, yet the connection remained open.&lt;/p&gt;
&lt;h2 id=&#34;on-site-summary&#34;&gt;On-Site Summary
&lt;/h2&gt;&lt;p&gt;I was originally working late in the office to advance project progress when an alarm message suddenly popped up in our work group. At first glance, I thought it was just a recurring issue – likely due to network timeouts causing heartbeat failures, leading to service disconnection. However, after careful log examination, the actual situation turned out to be different. The backend had already sent authorization messages, but they hadn&amp;rsquo;t received any response; meanwhile, heartbeat packets were continuously being sent, yet the other party never replied with any heartbeat data. After in-depth analysis of the logs, several key issues were revealed:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Authorization message without response: This was likely due to the other system being in the process of restarting, which prevented the authorization message from being processed promptly.&lt;/li&gt;
&lt;li&gt;Sending heartbeat data despite unsuccessful authorization: Upon investigation, it was found that this was a logical flaw in the program’s logic. - The judgment logic of the heartbeat sending function has a defect; it only checks the connection status but misses verifying the authorization status.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;If the service can disconnect, a reconnection mechanism can be triggered to resend the authorization message.&lt;/li&gt;
&lt;li&gt;Currently, there’s one remaining issue that urgently needs to be resolved: why doesn&amp;rsquo;t the service disconnect?  Solving this problem requires more in-depth and detailed troubleshooting work.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;analyzing-network-packets&#34;&gt;Analyzing Network Packets
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;tcpdump&lt;/code&gt; is a very powerful network packet capture tool that can be used to capture network packets. By analyzing network packets, we can gain a more intuitive understanding of the details of network communication. Here, we can use &lt;code&gt;tcpdump&lt;/code&gt; to capture network packets for further analysis.
&lt;img src=&#34;https://ttf248.life/p/backend-service-tcp-communication-troubleshooting/20250220151952.png&#34;
	width=&#34;1126&#34;
	height=&#34;202&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;tcpdump&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;557&#34;
		data-flex-basis=&#34;1337px&#34;
	
&gt;
Analyzing the data in the diagram, I see that the heartbeat is constantly sending normally, and the other server hasn&amp;rsquo;t responded with any data, but it has sent an &lt;code&gt;ACK&lt;/code&gt;, which prevents the connection from actively disconnecting.&lt;/p&gt;
&lt;h2 id=&#34;common-flag-bit-explanation&#34;&gt;Common Flag Bit Explanation
&lt;/h2&gt;&lt;p&gt;In the TCP protocol, &lt;code&gt;PSH&lt;/code&gt; (Push) and &lt;code&gt;ACK&lt;/code&gt; (Acknowledgment) are two important flag bits used to control data transmission and traffic confirmation, respectively. Their functions are as follows:&lt;/p&gt;
&lt;h3 id=&#34;1-psh-push-flag&#34;&gt;&lt;strong&gt;1. PSH (Push Flag)&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Function:&lt;/strong&gt; The &lt;code&gt;PSH&lt;/code&gt; flag’s purpose is to &lt;strong&gt;request that the receiver immediately push data from the buffer to the upper layer application&lt;/strong&gt; (rather than waiting for the buffer to fill). This means that once a data segment with the &lt;code&gt;PSH&lt;/code&gt; flag is received, the receiver will process and transmit it as quickly as possible to the application, rather than storing it in an operating system buffer.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Typical Scenarios:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;HTTP/HTTPS Requests:&lt;/strong&gt; Clients setting the &lt;code&gt;PSH&lt;/code&gt; when sending requests (e.g., &lt;code&gt;GET /index.html&lt;/code&gt;) to ensure immediate response from the server.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SSH Protocol:&lt;/strong&gt; Each keystroke triggers &lt;code&gt;PSH&lt;/code&gt;, ensuring real-time transmission of input characters.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Real-Time Communication:&lt;/strong&gt; Low-latency scenarios like video streaming or online games may use &lt;code&gt;PSH&lt;/code&gt; to reduce latency. - &lt;strong&gt;Note:&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PSH&lt;/code&gt; is not mandatory; the receiver can choose to ignore this flag (but must still process the data correctly).&lt;/li&gt;
&lt;li&gt;The sender may not set &lt;code&gt;PSH&lt;/code&gt;; in this case, the receiver will determine when to push data based on its own buffering policy.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-ack-acknowledgment-flag&#34;&gt;&lt;strong&gt;2. ACK (Acknowledgment Flag)&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Function:&lt;/strong&gt; The ACK flag indicates that the preceding data segment has been &lt;strong&gt;received correctly&lt;/strong&gt;. Each ACK contains an acknowledgment number (Acknowledgment Number), representing the expected next byte sequence number. It is the core mechanism of TCP reliable transmission.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Working Principle:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;When the sender transmits a data segment, it carries the expected ACK value from the receiver (e.g., &lt;code&gt;ACK = Sequence Number + Data Length&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Upon receiving the data, the receiver generates an ACK message to confirm the received byte sequence number.&lt;/li&gt;
&lt;li&gt;The sender only retransmits unacknowledged data after receiving the corresponding ACK.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Example:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;If the sender transmits a data segment with sequence numbers &lt;code&gt;100~199&lt;/code&gt;, then the expected ACK from the receiver should be &lt;code&gt;200&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-combination-of-psh-and-ack&#34;&gt;&lt;strong&gt;3. Combination of PSH and ACK&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;In the TCP header, &lt;code&gt;PSH&lt;/code&gt; and &lt;code&gt;ACK&lt;/code&gt; can appear simultaneously, commonly seen in the following scenarios:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;HTTP Request Response&lt;/strong&gt;:
When a client sends a &lt;code&gt;POST&lt;/code&gt; request (including data), it sets both &lt;code&gt;PSH&lt;/code&gt; and &lt;code&gt;ACK&lt;/code&gt; (to acknowledge previous responses).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Command Transmission after SSH Handshake&lt;/strong&gt;:
After the client enters a command, it sends a data segment with both &lt;code&gt;PSH&lt;/code&gt; and &lt;code&gt;ACK&lt;/code&gt; to ensure that the command is immediately transmitted and processed by the server.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;4-other-flagged-associations&#34;&gt;&lt;strong&gt;4. Other Flagged Associations&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Flag&lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Brief Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;SYN&lt;/td&gt;
&lt;td&gt;Synchronize&lt;/td&gt;
&lt;td&gt;Initiate connection (three-way handshake)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;4-other-flagged-associations-1&#34;&gt;&lt;strong&gt;4. Other Flagged Associations&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Flag&lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Brief Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;FIN&lt;/td&gt;
&lt;td&gt;End&lt;/td&gt;
&lt;td&gt;Graceful connection closure&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;4-other-flagged-associations-2&#34;&gt;&lt;strong&gt;4. Other Flagged Associations&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Flag&lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Brief Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;RST&lt;/td&gt;
&lt;td&gt;Reset&lt;/td&gt;
&lt;td&gt;Forcefully terminates the connection (exceptional circumstances)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;4-other-flagged-associations-3&#34;&gt;&lt;strong&gt;4. Other Flagged Associations&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Flag&lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Brief Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;URG&lt;/td&gt;
&lt;td&gt;Urgent&lt;/td&gt;
&lt;td&gt;Marks an urgent pointer (rarely used)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;4-other-flagged-associations-4&#34;&gt;&lt;strong&gt;4. Other Flagged Associations&lt;/strong&gt;
&lt;/h3&gt;&lt;h3 id=&#34;summary&#34;&gt;Summary
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PSH&lt;/strong&gt; focuses on &lt;strong&gt;data arriving at the application layer as quickly as possible&lt;/strong&gt;, reducing latency.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ACK&lt;/strong&gt; focuses on &lt;strong&gt;reliable data transmission&lt;/strong&gt;, avoiding packet loss or out-of-order delivery.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The two work together to balance TCP protocol efficiency and reliability.&lt;/p&gt;</description>
        </item>
        <item>
        <title>ollama local deployment of deepseek-R1</title>
        <link>https://ttf248.life/en/p/ollama-local-deployment-deepseek-r1/</link>
        <pubDate>Fri, 07 Feb 2025 22:41:02 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/ollama-local-deployment-deepseek-r1/</guid>
        <description>&lt;p&gt;Ollama is an open-source AI tool designed to enable users to run and deploy large language models (LLMs) locally. Its goal is to provide a convenient and efficient way for developers to use models like GPT on their local machines without relying on cloud services. Ollama supports multiple models and focuses on optimizing performance, allowing even resource-constrained devices to smoothly run these models.&lt;/p&gt;
&lt;p&gt;Through Ollama, users can utilize text-based AI applications and interact with locally deployed models without concerns about data privacy or high API usage fees. You can invoke different models via a command-line interface (CLI) for tasks such as natural language processing and question answering. &amp;gt; ollama is suitable for trying out different models, and after testing the Windows version, it couldn&amp;rsquo;t fully leverage the hardware’s performance – this may be due to the Windows version. When deploying 32b parameter models with low memory and GPU load, the response speed is very slow.&lt;/p&gt;
&lt;h2 id=&#34;hardware-overview&#34;&gt;Hardware Overview
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Operating System: Windows 11&lt;/li&gt;
&lt;li&gt;CPU: i7-10700K&lt;/li&gt;
&lt;li&gt;Memory: 40GB&lt;/li&gt;
&lt;li&gt;Graphics Card: RTX 3060 12GB&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;environment-setup&#34;&gt;Environment Setup
&lt;/h2&gt;&lt;p&gt;Add the following system environment variables for easier use:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_MODELS=E:\ollama&lt;/code&gt;&lt;/strong&gt;
This variable specifies the location where Ollama models are stored. &lt;code&gt;E:\ollama&lt;/code&gt; is a folder path indicating that all local model files will be stored in this directory. Ollama will load and use the language models you download or deploy based on this path. You can store your model files in another location by simply changing this path.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_HOST=127.0.0.1:8000&lt;/code&gt;&lt;/strong&gt;
This environment variable sets the host and port for the Ollama service.
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;127.0.0.1&lt;/code&gt; is the localhost address, meaning the Ollama service will only listen for requests from the local machine.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;8000&lt;/code&gt; is the specified port number, indicating that the Ollama service will wait for and process requests on port 8000.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;environment-setup-1&#34;&gt;Environment Setup
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_ORIGINS=*&lt;/code&gt;&lt;/strong&gt;
This environment variable controls which origins are allowed to access the Ollama service.
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;*&lt;/code&gt; indicates that any origin (i.e., all domains and IP addresses) can access the Ollama service. This is typically used in development and debugging environments, where production environments usually specify stricter origin control, limiting only specific domains or IPs to access your service to improve security.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;deepseek-r1-model-deployment&#34;&gt;deepseek-R1 Model Deployment
&lt;/h2&gt;&lt;p&gt;ollama installation is straightforward, so we won&amp;rsquo;t detail it here.&lt;/p&gt;
&lt;p&gt;Post-installation verification:&lt;/p&gt;
&lt;p&gt;Deploy the model, referring to the official model page and selecting the appropriate parameter version: &lt;code&gt;ollama run deepseek-r1:14b&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The 14b parameter version effectively remembers conversation context; smaller parameter versions cannot retain context. The 32b parameter version is very sluggish when deployed locally and hasn&amp;rsquo;t been further tested.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ollama.com/library/deepseek-r1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.ollama.com/library/deepseek-r1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/x18990027/article/details/145368094&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/x18990027/article/details/145368094&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>PowerShell 7 and Persistent Settings Command-Line Prediction View</title>
        <link>https://ttf248.life/en/p/powershell-7-persisting-settings-command-line-prediction-view/</link>
        <pubDate>Fri, 07 Feb 2025 22:19:12 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/powershell-7-persisting-settings-command-line-prediction-view/</guid>
        <description>&lt;p&gt;“I’d gotten used to using zsh on Linux, and when I was writing a blog post the other day, I suddenly realized that PowerShell 7 also supports persistent command-line prediction views, so I tried it out. It turned out to be pretty useful after all.”&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“I don&amp;rsquo;t know what I did to enable this feature, but it just appeared—that’s all.”&lt;/p&gt;
&lt;/blockquote&gt;
e&gt;
&lt;h2 id=&#34;powershell-7-a-powerful-tool-across-platforms&#34;&gt;PowerShell 7: A Powerful Tool Across Platforms
&lt;/h2&gt;&lt;h3 id=&#34;cross-platform-features&#34;&gt;Cross-Platform Features
&lt;/h3&gt;&lt;p&gt;PowerShell 7 breaks down platform limitations, allowing you to perform enterprise-level server management on Windows systems, system administration in Linux environments, or daily development tasks on macOS – all with a unified PowerShell 7 tool. This significantly increases productivity and reduces the learning curve and operational complexity associated with platform differences.&lt;/p&gt;
&lt;h3 id=&#34;powerful-features&#34;&gt;Powerful Features
&lt;/h3&gt;&lt;p&gt;It possesses powerful scripting capabilities, supporting object-oriented programming, functions, modules, and other advanced programming features. Through PowerShell 7, users can easily operate the file system, create, delete, copy, move, and perform other operations on files and folders; it can access and modify the registry to deeply adjust system configurations; it can manage processes and services to effectively monitor and control the system&amp;rsquo;s running status. Furthermore, PowerShell 7 can interact with various Windows and non-Windows technologies, such as user and permission management in Active Directory and resource allocation and management on the Azure cloud platform.&lt;/p&gt;
&lt;h3 id=&#34;open-source-ecosystem&#34;&gt;Open Source Ecosystem
&lt;/h3&gt;&lt;p&gt;PowerShell 7 is open source, a feature that allows developers and enthusiasts worldwide to actively participate in its development and improvement. A large number of open-source modules and tools are constantly emerging, enriching the functionality and application scenarios of PowerShell 7. Users can find suitable modules within the open-source community to extend the capabilities of PowerShell 7 or contribute their own code to drive the development of the entire community.&lt;/p&gt;
&lt;h3 id=&#34;compatibility-and-stability&#34;&gt;Compatibility and Stability
&lt;/h3&gt;&lt;p&gt;PowerShell 7 maintains compatibility with older versions of PowerShell while introducing many new features and improvements. These enhancements not only improve performance but also increase stability, allowing users to complete various tasks more smoothly and reducing disruptions caused by software failures.&lt;/p&gt;
&lt;h2 id=&#34;enable-command-line-prediction-view&#34;&gt;Enable Command-Line Prediction View
&lt;/h2&gt;&lt;p&gt;Within the many useful features of PowerShell 7, the &lt;code&gt;Set-PSReadLineOption -PredictionViewStyle ListView&lt;/code&gt; command is a practical tool that enhances the user&amp;rsquo;s command-line input experience.&lt;/p&gt;
&lt;p&gt;While the command itself isn’t necessary to achieve auto-completion, it only provides in-line completion; once enabled, it allows for prediction view, displaying all possible completion options in a list format. Users can then select the desired option using the up and down arrow keys, thereby improving the accuracy and efficiency of command input.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/powershell-7-persisting-settings-commandline-prediction-view/20250207222546.png&#34;
	width=&#34;814&#34;
	height=&#34;205&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;powershell7&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;397&#34;
		data-flex-basis=&#34;952px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;methods-to-make-commands-persistent&#34;&gt;Methods to Make Commands Persistent
&lt;/h2&gt;&lt;p&gt;To ensure that the &lt;code&gt;Set-PSReadLineOption -PredictionViewStyle ListView&lt;/code&gt; command takes effect every time PowerShell starts, we can add it to PowerShell&amp;rsquo;s profile. A PowerShell profile is a special script that automatically executes its commands when PowerShell launches.&lt;/p&gt;
&lt;h3 id=&#34;determine-configuration-file-path&#34;&gt;Determine Configuration File Path
&lt;/h3&gt;&lt;p&gt;In PowerShell, we can use the &lt;code&gt;$PROFILE&lt;/code&gt; variable to view the path of the configuration file. If the file does not exist under that path, the user can manually create it.&lt;/p&gt;
&lt;h3 id=&#34;open-configuration-file&#34;&gt;Open Configuration File
&lt;/h3&gt;&lt;p&gt;Use a text editor, such as the powerful Notepad++ or the lightweight Visual Studio Code, to open the file corresponding to the configuration file path obtained through the &lt;code&gt;$PROFILE&lt;/code&gt; variable.&lt;/p&gt;
&lt;h3 id=&#34;add-command&#34;&gt;Add Command
&lt;/h3&gt;&lt;p&gt;In the opened configuration file, add the command &lt;code&gt;Set-PSReadLineOption -PredictionViewStyle ListView&lt;/code&gt;. Ensure that the command is written accurately to guarantee that the configuration file takes effect correctly when executed.&lt;/p&gt;
&lt;h3 id=&#34;save-configuration&#34;&gt;Save Configuration
&lt;/h3&gt;&lt;p&gt;After adding the command, save the configuration file and close the text editor. At this point, the configuration file contains the commands we want to execute every time PowerShell starts.&lt;/p&gt;
&lt;h3 id=&#34;verification-settings&#34;&gt;Verification Settings
&lt;/h3&gt;&lt;p&gt;Close the current PowerShell window and restart PowerShell. In the newly launched PowerShell, when entering commands, the command-line input prediction view style should already be displayed in list view according to our settings, indicating that our settings have been successfully applied.&lt;/p&gt;
&lt;p&gt;Through these steps, we not only gained a deeper understanding of the powerful features and characteristics of PowerShell 7 but also learned how to use the command-line input prediction view style to enhance the user experience, and how to make these settings persistent. We hope this knowledge can help you operate PowerShell 7 more confidently and efficiently complete various system management and automation tasks.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/PowerShell/PowerShell/releases&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/PowerShell/PowerShell/releases&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.v2ex.com/t/911909&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.v2ex.com/t/911909&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Mastering atop: A Comprehensive Guide to Monitoring Linux System Metrics – Installation, Configuration, and Usage</title>
        <link>https://ttf248.life/en/p/using-atop-to-monitor-linux-system-metrics-installation-configuration-and-usage-guide/</link>
        <pubDate>Thu, 06 Feb 2025 22:48:55 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/using-atop-to-monitor-linux-system-metrics-installation-configuration-and-usage-guide/</guid>
        <description>&lt;p&gt;In Linux system administration, real-time and comprehensive monitoring of system resources and process status is crucial. The atop tool, as a powerful monitoring utility, helps us easily achieve this goal. This article will provide a detailed introduction on how to install, configure, and use the atop monitoring tool in a Linux instance.&lt;/p&gt;
&lt;h2 id=&#34;i-atop-tool-introduction&#34;&gt;I. atop Tool Introduction
&lt;/h2&gt;&lt;p&gt;atop is a tool specifically designed for monitoring Linux system resources and processes. It records the activity of systems and processes, and reports on the running status of all processes. The data collected by this tool covers resource usage such as CPU, memory, disk, and network, as well as process states. It can also save the data in log files to disk. For each process, we can obtain key information such as CPU utilization, memory growth, disk usage, priority, username, status, and exit code. Furthermore, through the atop configuration file, we can customize parameters such as logging collection frequency, log file storage path, and rotation strategy.&lt;/p&gt;
&lt;h2 id=&#34;ii-installing-the-atop-tool&#34;&gt;II. Installing the atop Tool
&lt;/h2&gt;&lt;p&gt;The installation method for atop varies slightly depending on the Linux distribution. The following provides an introduction based on common operating systems:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Alibaba Cloud Linux 3/2, CentOS 7/8, Fedora, Rocky Linux 9:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Execute the installation command: &lt;code&gt;sudo yum install -y atop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ubuntu / Debian:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Update the software source list: &lt;code&gt;sudo apt update&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Execute the installation command: &lt;code&gt;sudo apt install -y atop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;CentOS Stream 9:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download and install: &lt;code&gt;sudo wget https://www.atoptool.nl/download/atop-2.11.0-1.el9.x86_64.rpm &amp;amp;&amp;amp; sudo rpm -i atop-2.11.0-1.el9.x86_64.rpm&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;ii-installing-the-atop-tool-1&#34;&gt;II. Installing the atop Tool
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;openSUSE&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;Execute the installation command: &lt;code&gt;sudo zypper install -y atop atop-daemon&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;
If your distribution is not listed above, you can visit the official atop website for installation information.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;iii-configuring-monitoring-cycle-and-log-retention-time&#34;&gt;III. Configuring Monitoring Cycle and Log Retention Time
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Configuration File Location:&lt;/strong&gt; In Alibaba Cloud Linux 3/2, CentOS 7/8, and Fedora systems, the atop configuration file is &lt;code&gt;/etc/sysconfig/atop&lt;/code&gt;; in Ubuntu, Debian, and openSUSE systems, the configuration file is &lt;code&gt;/etc/default/atop&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Default Configuration Parameter Explanation&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;LOGOPTS&lt;/code&gt;: Controls logging options for log files, defaults to empty.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LOGINTERVAL&lt;/code&gt;: Monitoring cycle, default is 600 seconds. To collect historical logs for tracking issues, it’s recommended to adjust this frequency based on actual needs.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LOGGENERATIONS&lt;/code&gt;: Log retention time, default is 28 days.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LOGPATH&lt;/code&gt;: Log file storage path, defaults to &lt;code&gt;/var/log/atop&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;iii-configure-monitoring-cycle-and-log-retention-time&#34;&gt;III. Configure Monitoring Cycle and Log Retention Time
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Configuration Steps&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Execute the command to open the configuration file:
&lt;ul&gt;
&lt;li&gt;In Alibaba Cloud Linux 3/2, CentOS 7/8, Fedora systems: &lt;code&gt;sudo vim /etc/sysconfig/atop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;In Ubuntu, Debian, openSUSE, CentOS Stream 9, Rocky Linux 9 systems: &lt;code&gt;sudo vim /etc/default/atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Press ‘i’ to enter edit mode and adjust the configuration parameters according to your needs. For example, change the monitoring cycle to 30 seconds, set the log retention time to 7 days, and maintain the default log path:&lt;/li&gt;
&lt;li&gt;Press ‘Esc’ to return to normal editing mode, type &lt;code&gt;:wq&lt;/code&gt; to save and exit.&lt;/li&gt;
&lt;li&gt;Restart the atop service to apply the configuration: &lt;code&gt;sudo systemctl restart atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;four-using-atop-tool&#34;&gt;Four. Using atop Tool
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Common Commands:&lt;/strong&gt; In interactive command mode, the following common commands are available:
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;g&lt;/code&gt;: Return to the default comprehensive output view.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;c&lt;/code&gt;: Display the complete command line for each process.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;m&lt;/code&gt;: Sort processes by memory usage in descending order.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;d&lt;/code&gt;: Sort processes by disk usage in descending order.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;a&lt;/code&gt;: Sort processes by overall resource usage in descending order.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;n&lt;/code&gt;: Sort processes by network usage in descending order.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;t&lt;/code&gt;: Jump to the next monitoring collection point.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;T&lt;/code&gt;: Jump to the previous monitoring collection point.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;b&lt;/code&gt;: Specify a timestamp in the format &lt;code&gt;YYYYMMDDhhmm&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;four-using-the-atop-tool&#34;&gt;Four. Using the atop Tool
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Resource Monitoring Field Meanings&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;atop&lt;/strong&gt;: Hostname, sampling date and time point.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PRC&lt;/strong&gt;: Overall process running status, including kernel state and user state runtime, total process count, number of processes in different states, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CPU&lt;/strong&gt;: Overall CPU usage, the sum of the numbers is &lt;code&gt;N*100%&lt;/code&gt; (N is the number of CPU cores), including the proportion of time for kernel state, user state, interrupt, idle, and disk I/O waiting.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CPL&lt;/strong&gt;: CPU load status, such as the average number of processes in the queue over 1 minute, 5 minutes, and 15 minutes, context switch times, and interrupt occurrences.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MEM&lt;/strong&gt;: Memory usage, including total physical memory, free memory, page cache memory, file cache memory, and kernel occupied memory, etc. - &lt;strong&gt;SWP:&lt;/strong&gt; Swap space utilization, including total swap area and available swap space size.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PAG:&lt;/strong&gt; Virtual memory page situation, such as inbound and outbound memory page numbers.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DSK:&lt;/strong&gt; Disk usage, with each disk device corresponding to a column, displaying device identifier, busy time proportion, read/write request quantity.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NET:&lt;/strong&gt; Network status, showcasing transport layer TCP and UDP, IP layer, and receive and send packet sizes for each active port.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;four-using-the-atop-tool-1&#34;&gt;Four. Using the atop Tool
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;View Real-time System Metrics&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;View system metrics every 5 seconds: &lt;code&gt;atop 5&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View system metrics from the last 30 intervals (each interval is 10 seconds) after the current time: &lt;code&gt;atop -M 10 30&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View system metrics from the last 10 minutes (10 intervals, each interval is 60 seconds), and write the results to a file: &lt;code&gt;atop -M 60 10 &amp;gt; /log/atop.mem&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;View Historical Metric Logs&lt;/strong&gt;: After atop starts, collected records are stored by default in the &lt;code&gt;/var/log/atop&lt;/code&gt; directory. When viewing, be sure to specify the date of the log file must exist, otherwise it will error. - View daily historical metrics log: &lt;code&gt;atop -r&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View yesterday&amp;rsquo;s historical metrics log: &lt;code&gt;atop -r y&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View historical metrics log for a specific date, such as November 6, 2024: &lt;code&gt;atop -r 20241106&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View historical metrics log from a specific date and time, such as starting from November 6, 2024, 14:00: &lt;code&gt;atop -r 20241106 -b 14:00&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View historical metrics log for a specified time range on a specific date, such as from November 5, 2024, 00:04 to 00:08: &lt;code&gt;atop -r 20241105 -b 00:04 -e 00:08&lt;/code&gt; ## Four. Using the atop Tool&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;View Real-time System Metrics&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;View system metrics every 5 seconds: &lt;code&gt;atop 5&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View system metrics from the last 30 intervals (each interval is 10 seconds) after the current time: &lt;code&gt;atop -M 10 30&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View system metrics from the last 10 minutes (10 intervals, each interval is 60 seconds), and write the results to a file: &lt;code&gt;atop -M 60 10 &amp;gt; /log/atop.mem&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;View Historical Metric Logs&lt;/strong&gt;: After atop starts, collected records are stored by default in the &lt;code&gt;/var/log/atop&lt;/code&gt; directory. When viewing, be sure to specify the log file for the desired date; otherwise, an error will occur.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;four-using-the-atop-tool-2&#34;&gt;Four. Using the atop Tool
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;View System Activity Report&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;View the CPU utilization report for the current system over 1 minute (12 times, with an interval of 5 seconds): &lt;code&gt;atopsar -c 5 12&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View the memory metrics report for a specified time period during the day, such as 18:00 to 18:01: &lt;code&gt;atopsar -m -b 18:00 -e 18:01&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View the memory metrics report for a specified date and time period, such as November 5, 2024 from 18:00 to 18:01: &lt;code&gt;atopsar -m -r 20241105 -b 18:00 -e 18:01&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;five-other-operations&#34;&gt;Five. Other Operations
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Configure Daily Log Rotation Policy&lt;/strong&gt;: If you want to generate a daily &lt;code&gt;atop&lt;/code&gt; metric log file, you can perform the following actions:
&lt;ul&gt;
&lt;li&gt;(Optional) Adjust monitoring period, log retention time, and log storage path according to your needs.&lt;/li&gt;
&lt;li&gt;Execute the command to enable and start the services related to daily log rotation: &lt;code&gt;sudo systemctl enable --now atop atopacct atop-rotate.timer&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;If your business has more complex requirements for log processing, you can also combine it with &lt;code&gt;logrotate&lt;/code&gt; or custom scripts to implement log management.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;five-other-operations-1&#34;&gt;Five. Other Operations
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Load the optional netatop kernel module:&lt;/strong&gt; If you need to monitor network usage, you can install the netatop module (the module is not installed by default in atop). As an example on Alibaba Cloud Linux 3:
&lt;ul&gt;
&lt;li&gt;Install the kernel development package and the software environment required for compiling: &lt;code&gt;sudo yum install -y kernel-devel dkms elfutils-libelf-devel&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Download the latest version of netatop source code to a specified directory: &lt;code&gt;cd /usr/src/ &amp;amp;&amp;amp; sudo wget https://www.atoptool.nl/download/netatop-3.2.2.tar.gz --no-check-certificate&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Extract the source code and enter the source code directory: &lt;code&gt;sudo tar -zxvf netatop-3.2.2.tar.gz &amp;amp;&amp;amp; cd netatop-3.2.2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Build and install the module and daemon based on the source code: &lt;code&gt;sudo make &amp;amp;&amp;amp; sudo make install&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the netatop service: &lt;code&gt;sudo systemctl start netatop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v-other-operations&#34;&gt;V. Other Operations
&lt;/h2&gt;&lt;p&gt;The atop tool is powerful and flexible to use. By installing, configuring, and using it properly, we can better understand the running status of our Linux system and promptly identify and resolve potential issues. We hope this article will help everyone take Linux system monitoring to a new level.&lt;/p&gt;
&lt;h2 id=&#34;vi-references&#34;&gt;VI. References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.atoptool.nl/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;atop official website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://help.aliyun.com/zh/ecs/use-cases/use-the-atop-tool-to-monitor-linux-system-metrics#99e53d0198euu&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Installation, configuration, and usage of the atop monitoring tool&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Visual Studio loading a mismatched PDB file</title>
        <link>https://ttf248.life/en/p/visual-studio-loading-unmatched-pdb-files/</link>
        <pubDate>Thu, 23 Jan 2025 20:04:33 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/visual-studio-loading-unmatched-pdb-files/</guid>
        <description>&lt;p&gt;When debugging programs under Windows using Visual Studio, if the PDB file does not match the executable file, Visual Studio will display &amp;ldquo;Unable to load symbol file.&amp;rdquo; The program crashes and generates a crash dump. If it&amp;rsquo;s an mismatched PDB file, Visual Studio cannot smoothly enter the crash site.&lt;/p&gt;
&lt;h2 id=&#34;what-is-a-pdb-file&#34;&gt;What is a PDB File?
&lt;/h2&gt;&lt;p&gt;A PDB file is a debugging information file created by Microsoft, used for debugging programs. It contains information such as the symbol table, source code filenames, line numbers, and other debugging data. A PDB file can be generated during program compilation to aid in debugging.&lt;/p&gt;
&lt;h2 id=&#34;windbg-debugging&#34;&gt;WinDbg Debugging
&lt;/h2&gt;&lt;p&gt;WinDbg is a debugging tool from Microsoft that can be used to debug Windows programs. WinDbg can load mismatched PDB files, but this requires manual loading. The &lt;code&gt;.reload /f /i&lt;/code&gt; command forces the loading of mismatched PDB files.&lt;/p&gt;
&lt;p&gt;However, WinDbg is less convenient to use than Visual Studio, so we want Visual Studio to also be able to load mismatched PDB files.&lt;/p&gt;
&lt;h2 id=&#34;visual-studio-cannot-load-matching-pdb-files&#34;&gt;Visual Studio Cannot Load Matching PDB Files
&lt;/h2&gt;&lt;p&gt;Source code is now generally managed through Git, allowing you to find the corresponding version of the code and recompile it to generate a matching PDB file. Why can&amp;rsquo;t it load? The main reason is that metadata doesn’t match.&lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s a small tool that can modify metadata based on EXE file information to generate a new PDB file, enabling Visual Studio to load it.&lt;/p&gt;
&lt;p&gt;Chkmatch Download Address: &lt;a class=&#34;link&#34; href=&#34;https://www.debuginfo.com/tools/chkmatch.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.debuginfo.com/tools/chkmatch.html&lt;/a&gt;
Site Cache Address: &lt;a class=&#34;link&#34; href=&#34;chkmatch.zip&#34; &gt;chkmatch.zip&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;using-chkmatch&#34;&gt;Using chkmatch
&lt;/h2&gt;&lt;p&gt;First, perform the check operation to analyze the cause of mismatches and prompt an error indicating signature mismatch.
Then, execute the modify operation to ensure that the pdb file matches the executable file.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://stackoverflow.com/questions/38147487/forcing-to-load-unmatched-symbols-in-visual-studio-2015-debugger&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;forcing-to-load-unmatched-symbols-in-visual-studio-2015-debugger&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Cursor AI Programming IDE Trial</title>
        <link>https://ttf248.life/en/p/cursor-ai-programming-ide-trial/</link>
        <pubDate>Thu, 23 Jan 2025 19:30:13 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cursor-ai-programming-ide-trial/</guid>
        <description>&lt;p&gt;It seems like another year has passed, and the biggest change at work is a significantly increased involvement of AI. Previously, switching between different development languages required developers to be familiar with various language-specific API interfaces. Now, these basic code snippets can all be generated by AI, which is a huge blessing for developers.&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;As early as 2023, I’ve written two simple introductory articles about it. Now it&amp;rsquo;s been 25 years – how to put this… I haven’t felt a significant improvement. It still needs to develop its own cognition, be able to reasonably break down tasks, and, of course, most importantly, identify whether AI-generated code contains bugs.&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;Github Copilot
&lt;/h2&gt;&lt;p&gt;It was a long time ago, but I saw some information saying that Singapore deployed the server and it’s available for use in China. No longer need to maintain a VPN for extended periods. Of course, you still need to connect to a VPN when logging in, but this VPN only needs to be used during login, and then you can turn it off.&lt;/p&gt;
&lt;p&gt;In daily use, Github Copilot is also heavily relied upon. This plugin can be directly used in VS Code and Visual Studio without switching between the two applications. Compared to ChatGPT, Github Copilot provides better support for projects, a more user-friendly interaction, and allows you to feed partial local files to it – &lt;strong&gt;“training” the AI&lt;/strong&gt; – so that the generated code is more aligned with your project.&lt;/p&gt;
&lt;h2 id=&#34;cursor-ai&#34;&gt;Cursor AI
&lt;/h2&gt;&lt;p&gt;Recently I’ve come across a new AI programming IDE, Cursor AI. This IDE is based on Github Copilot, but it&amp;rsquo;s more intelligent and can help you create files directly.
I gave it a quick try and found it to be pretty good, however, its understanding of existing projects isn’t quite there yet. When dealing with large local project files, or major refactoring, optimization, and adjustments, developers still need to &lt;strong&gt;break down tasks&lt;/strong&gt;.
Here&amp;rsquo;s an example: Switching to Cursor’s engineering mode, inputting the following content: “Create a personal resume webpage, supporting multiple different styles switching, and remember to populate some personal information for data display.”
After several back-and-forths (&lt;strong&gt;pulling&lt;/strong&gt;), you can obtain the following webpage. Of course, this webpage is relatively simple, but it’s still quite good for beginners. ## Cursor AI
Recently I’ve come across a new AI programming IDE, Cursor AI. This IDE is based on Github Copilot, but it&amp;rsquo;s more intelligent and can help you create files directly.
I gave it a quick try and found it to be pretty good, however, its understanding of existing projects isn’t quite there yet. When dealing with large local project files, or major refactoring, optimization, and adjustments, developers still need to &lt;strong&gt;break down tasks&lt;/strong&gt;.
Here&amp;rsquo;s an example: Switching to Cursor’s engineering mode, inputting the following content: “Create a personal resume webpage, supporting multiple different styles switching, and remember to fill in some personal information for data display.”
After several back-and-forths, you can obtain the following webpage. Of course, this webpage is relatively simple, but it&amp;rsquo;s still quite good for beginners.&lt;/p&gt;
&lt;h2 id=&#34;cursor-ai-1&#34;&gt;Cursor AI
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://ttf248.life/cursor/index.html&#34; &gt;Resume&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>C&#43;&#43; Bitwise Operations Fundamentals: Bitwise Extraction and Flag Setting</title>
        <link>https://ttf248.life/en/p/cpp-bitwise-operations-basics-flags/</link>
        <pubDate>Fri, 17 Jan 2025 02:23:56 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-bitwise-operations-basics-flags/</guid>
        <description>&lt;p&gt;In actual C++ development, bitwise operations are a common technique, especially when dealing with system states, flags, or control bits. Bitwise operations can provide highly efficient solutions. This article will illustrate how to use bitwise operations to retrieve and set specific flags through an example.&lt;/p&gt;
&lt;h3 id=&#34;bitwise-operations-fundamentals&#34;&gt;Bitwise Operations Fundamentals
&lt;/h3&gt;&lt;p&gt;In computers, data is stored in binary bits (0 and 1). Bitwise operations are operations performed on these binary bits. C++ provides several commonly used bitwise operators:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Bitwise AND (&amp;amp;)&lt;/strong&gt;: Used to check if a particular bit is set to 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise OR (|)&lt;/strong&gt;: Used to set a particular bit to 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise XOR (^)&lt;/strong&gt;: Used to flip a particular bit.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise NOT (~)&lt;/strong&gt;: Inverts all the bits.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Left Shift (&amp;laquo;)&lt;/strong&gt;: Shifts all the bits to the left by a specified number of positions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Right Shift (&amp;raquo;)&lt;/strong&gt;: Shifts all the bits to the right by a specified number of positions.
In this example, we need to perform a series of bitwise operations on an &lt;code&gt;unsigned short&lt;/code&gt; variable &lt;code&gt;wInfo&lt;/code&gt; to represent different states using various flags.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;requirement-analysis&#34;&gt;Requirement Analysis
&lt;/h3&gt;&lt;p&gt;Based on the description, we have a 16-bit flag to represent different states. These states are represented by various binary bits, with each binary bit corresponding to a specific meaning. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;bit0&lt;/strong&gt;: Failure status&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bit1&lt;/strong&gt;: Compression status&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bit2&lt;/strong&gt;: Incremental status&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bit3&lt;/strong&gt;: Presence of subsequent packets&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bit5&lt;/strong&gt;: Normal request or cancellation&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;using-bitwise-operations&#34;&gt;Using Bitwise Operations
&lt;/h3&gt;&lt;p&gt;We will use bitwise operations to set and retrieve these flags. Specifically:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Bitwise AND:&lt;/strong&gt; Retrieve the value of a particular bit (0 or 1).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise OR:&lt;/strong&gt; Set a particular bit to 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitwise XOR:&lt;/strong&gt; Set a particular bit to 0.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We first define an &lt;code&gt;unsigned short&lt;/code&gt; type variable &lt;code&gt;wInfo&lt;/code&gt; to store these flags. Then, we use bitwise operations to check and set the corresponding flags.&lt;/p&gt;
&lt;h3 id=&#34;c-example-code&#34;&gt;C++ Example Code
&lt;/h3&gt;&lt;p&gt;Execute the code, recommended for old friends: &lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;code-explanation&#34;&gt;Code Explanation
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Flag Definition&lt;/strong&gt;: Use shift operations (&lt;code&gt;1 &amp;lt;&amp;lt; n&lt;/code&gt;) to define each flag bit. For example, &lt;code&gt;1 &amp;lt;&amp;lt; 0&lt;/code&gt; corresponds to &lt;code&gt;bit0&lt;/code&gt;, &lt;code&gt;1 &amp;lt;&amp;lt; 1&lt;/code&gt; corresponds to &lt;code&gt;bit1&lt;/code&gt;, and so on. This way, we allocate a unique binary position for each flag.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Check a Bit&lt;/strong&gt;: The &lt;code&gt;isBitSet&lt;/code&gt; function uses the bitwise AND operation (&lt;code&gt;wInfo &amp;amp; bitMask&lt;/code&gt;) to check if a specific flag is set to 1. If the bit is 1, the function returns &lt;code&gt;true&lt;/code&gt;, otherwise it returns &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Set a Bit&lt;/strong&gt;: The &lt;code&gt;setBit&lt;/code&gt; function uses the bitwise OR operation (&lt;code&gt;wInfo |= bitMask&lt;/code&gt;) to set a specific flag bit to 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clear a Bit&lt;/strong&gt;: The &lt;code&gt;clearBit&lt;/code&gt; function uses the bitwise AND operation (&lt;code&gt;wInfo &amp;amp;= ~bitMask&lt;/code&gt;) to clear a specific flag bit to 0.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary
&lt;/h3&gt;&lt;p&gt;Through bitwise operations, we can efficiently handle multiple state flags. This technique is particularly useful in practical development. For example, in embedded development, network protocols, and system status management scenarios, bit flags are often used to represent multiple binary states, saving space and improving efficiency.&lt;/p&gt;
&lt;p&gt;We hope this blog post helps you understand how to use bitwise operations in C++ to perform bitwise selection and setting, and mastering these skills is very helpful for writing efficient and maintainable code!&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Upgrading from a desktop to a 2.5G network card, accelerating local area network connectivity.</title>
        <link>https://ttf248.life/en/p/desktop-upgrade-to-25g-network-card-accelerate-lan-interconnection/</link>
        <pubDate>Fri, 10 Jan 2025 00:37:52 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/desktop-upgrade-to-25g-network-card-accelerate-lan-interconnection/</guid>
        <description>&lt;p&gt;Desktop hardware three-in-one, in the previous text we mentioned PCIe adapter for solid state drives, where did the old SSDs go? Of course they weren&amp;rsquo;t wasted – if they were damaged, they were disassembled and installed on the newly purchased ‘MechMaker Mini-3765H’ (bought a year ago).&lt;/p&gt;
&lt;p&gt;This new machine has powerful hardware specifications: 2.5G dual network interfaces, PCIe4.0, WiFi6.&lt;/p&gt;
&lt;p&gt;Recently I moved house and my room doesn&amp;rsquo;t have a dedicated router for networking, so the machines are connected via wireless networks. The ASUS motherboard desktop’s wireless card performance wasn’t great, or perhaps it was the router’s wireless access, which resulted in slow upload speeds between local networks, leading to poor network speeds between the machines. I purchased a 2.5G NIC and installed it on the desktop.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;At this point, all the slots on the motherboard are full: graphics card, wireless card, 2.5G NIC, PCIe adapter for solid state drives.&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;network-instructions&#34;&gt;Network Instructions
&lt;/h2&gt;&lt;p&gt;Both machines connect to the internet using their original wireless network cards, but are directly connected via Ethernet cables between the two ends, with both sides equipped with 2.5G network cards.  The specifics of how to connect the Ethernet cables between the two machines aren&amp;rsquo;t detailed here – there are many tutorials available online; just remember to disable your firewall. You can select either machine as the gateway.&lt;/p&gt;
&lt;h2 id=&#34;two-subnet-speed-testing&#34;&gt;Two Subnet Speed Testing
&lt;/h2&gt;&lt;h3 id=&#34;router-lan&#34;&gt;Router LAN
&lt;/h3&gt;&lt;h3 id=&#34;direct-lan&#34;&gt;Direct LAN
&lt;/h3&gt;&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://wutongsuimeng.github.io/post/%E7%BB%99hugo%E6%B7%BB%E5%8A%A0mermaid%E6%94%AF%E6%8C%81/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Adding Mermaid Support to Hugo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>ASUS Z490 motherboard has too many disks, resulting in intermittent disk unrecognition.</title>
        <link>https://ttf248.life/en/p/asus-motherboard-z490-too-many-disks-intermittent-disk-recognition/</link>
        <pubDate>Fri, 10 Jan 2025 00:08:51 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/asus-motherboard-z490-too-many-disks-intermittent-disk-recognition/</guid>
        <description>&lt;p&gt;Continuing from the previous text, an issue suddenly arose where the wireless network card was unable to be recognized. Before rebuilding the partitions, I had also researched other solutions online, such as: removing the motherboard battery and disconnecting power for fifteen minutes; upgrading to the latest version of the BOIS driver, but all attempts were unsuccessful.&lt;/p&gt;
&lt;p&gt;Thinking there were still tasks to complete, I switched to a limited network, pulling a web across from the living room into the room. At this point, even the wired network was unable to be recognized. I resorted to the ultimate solution – reinstalling the system, which resulted in partition loss during the boot process. If the issue had persisted continuously, I wouldn’t have spent so much time troubleshooting it; the ASUS disk conflict is intermittent, triggered by unstable system restarts.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Last week, I purchased a new 2TB solid-state drive from长江存储 (Changjiang Storage), an M.2 interface drive, and the machine never rebooted until yesterday when I shut it down once.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/asus-z490-motherboard-disk-recognition-issues/20250110002801.png&#34;
	width=&#34;553&#34;
	height=&#34;322&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Family photo of a disk&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;171&#34;
		data-flex-basis=&#34;412px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;reinstalling-the-system&#34;&gt;Reinstalling the System
&lt;/h2&gt;&lt;p&gt;It’s been almost two years since I last reinstalled the system, and my C drive is running out of space. Windows keeps having old issues, and various software likes to store things on C: Drive. So, I decided to reinstall the system. After reinstalling the system, the network card issue was resolved, and I restored my daily development environment the next day. While preparing to create a system backup, a new problem arose: after restarting the system, the boot partition disappeared.&lt;/p&gt;
&lt;p&gt;Following the steps in the previous article, I rebuilt the boot partition; however, it wasn’t stable, and the partition would sometimes fail to load upon restart. I started to wonder if the chassis was malfunctioning when I realized that the hard drive cable was loose, but after several checks, there were no issues.&lt;/p&gt;
&lt;h2 id=&#34;memory-retrieval&#34;&gt;Memory Retrieval
&lt;/h2&gt;&lt;p&gt;Many years ago, this machine had once been equipped with a solid-state drive; it was like buying a new PCIE converter (plugged into the graphics card slot) instead of directly installing the hard drive onto the motherboard. This time, it’s installed directly on the motherboard, which may be due to an issue with the motherboard.
&lt;img src=&#34;https://ttf248.life/p/asus-z490-motherboard-disk-recognition-issues/20250110002148.png&#34;
	width=&#34;325&#34;
	height=&#34;545&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Solid State Converter&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;59&#34;
		data-flex-basis=&#34;143px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;motherboard-manual&#34;&gt;Motherboard Manual
&lt;/h2&gt;&lt;p&gt;The motherboard manual has issues, with the labeled SATA port positions differing from the actual positions. Due to a large number of disks, all ports are populated with hard drives, with older SSDs utilizing SATA ports. According to the manual, there is a conflict between the ports. However, after testing, this conflict was found to be unstable and would trigger, causing the corresponding disk to fail to load – specifically, as it’s the system disk, the bootloader is also located on that disk, resulting in boot loader failure during system startup.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/asus-z490-motherboard-disk-recognition-issues/20250110002401.png&#34;
	width=&#34;807&#34;
	height=&#34;847&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Z490&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;95&#34;
		data-flex-basis=&#34;228px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;solutions&#34;&gt;Solutions
&lt;/h2&gt;&lt;p&gt;Reinstall the solid state drive onto a PCIe adapter, at this point, the SATA ports on the motherboard will no longer conflict, and the system starts up normally.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Exploring the Mysteries of ESP Partitions, GPT Partitions Table, and the Synergy with Windows Operating Systems</title>
        <link>https://ttf248.life/en/p/exploring-esp-gpt-and-windows-cooperation/</link>
        <pubDate>Thu, 09 Jan 2025 23:58:20 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/exploring-esp-gpt-and-windows-cooperation/</guid>
        <description>&lt;p&gt;Yesterday after work, I followed the usual routine of booting up my desktop computer. The system started normally but couldn&amp;rsquo;t load the wireless network card. I thought it might be loose, so I disassembled it and reinstalled the wireless card. That’s when things went really wrong – the system simply wouldn’t boot, and the boot loader failed.&lt;/p&gt;
&lt;p&gt;It had been a long time since I’d messed around with a desktop computer, and partitioning and booting felt a bit unfamiliar. I used DisGenius to create a blank partition (usually partitioned at the beginning of the disk) and assigned it as an ESP partition (defaulting to 300M). Then, within the PE system, I rebuilt the boot, and relevant information could be found online.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/esp-partitioning-gpt-windows-cooperation/20250110000433.png&#34;
	width=&#34;330&#34;
	height=&#34;269&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;New ESP Partition&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;122&#34;
		data-flex-basis=&#34;294px&#34;
	
&gt;
&lt;img src=&#34;https://ttf248.life/p/esp-partitioning-gpt-windows-cooperation/20250110000509.png&#34;
	width=&#34;433&#34;
	height=&#34;355&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;You can remove the MSR partition&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;121&#34;
		data-flex-basis=&#34;292px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;In the world of computer storage, the ESP partition, GPT partition table, and Windows operating system are closely linked, each playing a unique and crucial role in supporting the system’s stable operation and efficient management. However, before delving into their intricacies, we must acknowledge the “pioneers” – the MBR partition table format – that flowed through the history of computer partitioning. It mirrored subsequent technologies, further highlighting the evolution of technology. Today, let’s explore their inner connections and nuances in detail.&lt;/p&gt;
&lt;h2 id=&#34;i-mbr-partition-table--the-foundation-of-traditional-hard-disk-partitioning&#34;&gt;I. MBR Partition Table – The “Foundation” of Traditional Hard Disk Partitioning
&lt;/h2&gt;&lt;p&gt;MBR, which stands for Master Boot Record, has existed since the early days of personal computers and has dominated the hard disk partitioning landscape for decades.&lt;/p&gt;
&lt;h3 id=&#34;1-basic-architecture&#34;&gt;1. Basic Architecture
&lt;/h3&gt;&lt;p&gt;It is located in the first sector of the hard disk, which is sector 0, occupying 512 bytes of space. These 512 bytes are primarily divided into three parts: firstly, the boot program code, responsible for loading the operating system&amp;rsquo;s boot loader during computer startup, typically 446 bytes; secondly, the disk partition table, occupying 64 bytes, which can define up to 4 main partitions, with each partition describing 16 bytes of information, recording the starting head, sector, and cylinder of the partition, as well as key parameters such as partition type and size; and finally, the last 2 bytes are the MBR end marker &amp;ldquo;55 AA&amp;rdquo;, used to identify this sector as a valid MBR.&lt;/p&gt;
&lt;h3 id=&#34;2-historical-achievements-and-limitations&#34;&gt;2. Historical Achievements and Limitations
&lt;/h3&gt;&lt;p&gt;In the early days, MBR partition tables fully met the storage needs of relatively simple personal computers. It allowed operating systems to seamlessly recognize hard disk partitions, enabling orderly data storage and retrieval. However, as times evolved, its limitations became increasingly apparent. Firstly, limited by a 64-byte partition table space, it could only define a maximum of 4 primary partitions. To create more partitions, complex methods such as extended partitions and logical partitions had to be used, which complicated disk management. Secondly, its maximum support was only 2TB of hard drives, which seemed inadequate in the face of today’s large-capacity drives routinely measuring several TB or even tens of TB – this became a bottleneck that constrained further development of storage technology.&lt;/p&gt;
&lt;h2 id=&#34;ii-esp-partition--the-systems-invisible-boot-key&#34;&gt;II. ESP Partition – The System’s “Invisible Boot Key”
&lt;/h2&gt;&lt;p&gt;ESP, which stands for EFI System Partition, is a special partition required by computers based on the UEFI (Unified Extensible Firmware Interface) standard.&lt;/p&gt;
&lt;h3 id=&#34;1-functional-features&#34;&gt;1. Functional Features
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Boot Loader&lt;/strong&gt;: When the computer starts up, UEFI firmware first searches for the ESP partition on the hard drive and reads the boot loader (such as Windows Boot Manager) stored within it, thereby launching the operating system. This is like a precise key that opens the door to system startup; without it, the system would be lost and confused during startup, not knowing where to go.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Storage Driver&lt;/strong&gt;: The ESP partition also stores some driver programs necessary for the boot process to ensure that hardware devices (such as hard disk controllers, graphics cards, etc.) function normally in the early stages of booting, laying the foundation for the smooth takeover of the operating system.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-space-requirements-and-formatting&#34;&gt;2. Space Requirements and Formatting
&lt;/h3&gt;&lt;p&gt;Typically, ESP partition sizes should range from 100MB to 500MB, with an allocation of around 200MB generally sufficient for basic needs. Its file system format must be FAT32, as UEFI firmware can only recognize FAT32 formatting to read boot files, ensuring compatibility and cross-platform support.&lt;/p&gt;
&lt;h2 id=&#34;three-gpt-partition-table--the-hard-drives-smart-manager&#34;&gt;Three. GPT Partition Table – The Hard Drive’s “Smart Manager”
&lt;/h2&gt;&lt;p&gt;GPT (GUID Partition Table), also known as the Globally Unique Identifier Partition Table, is a new partitioning scheme designed to replace the traditional MBR partition table.&lt;/p&gt;
&lt;h3 id=&#34;1-advantages-demonstrated&#34;&gt;1. Advantages Demonstrated
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Large Capacity Support:&lt;/strong&gt; In this era of exploding data, large-capacity hard drives are emerging one after another. GPT partition tables break the MBR&amp;rsquo;s 2TB capacity limit, theoretically enabling support for up to 9.4ZB (zettabytes – 1ZB = 1024 EB, 1EB = 1024 PB, 1PB = 1024 TB) of ultra-large storage space, providing possibilities for storing massive amounts of data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Numerous Partition Numbers:&lt;/strong&gt; Unlike MBR which can only partition a maximum of 4 primary partitions, GPT allows the creation of up to 128 partitions, giving users and system administrators great flexibility whether it’s partitioning multiple systems partitions, data partitions, or reserving partitions for special purposes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;High Reliability:&lt;/strong&gt; The GPT partition table employs redundancy backup mechanisms, storing partition table information in both the head and tail of the hard drive.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-structural-analysis&#34;&gt;2. Structural Analysis
&lt;/h3&gt;&lt;p&gt;The GPT partition table consists of multiple components, including a protected MBR (maintained as a small portion of the traditional BIOS structure for compatibility with legacy BIOS and not used for actual partition management), a GPT header (storing basic information about the GPT partition table such as partition table version, number of partitions, partition table size, etc.), and a partition entry array (each partition entry details key information such as the starting sector, ending sector, partition type GUID, and unique identifier for each partition). These structures work together to precisely plan and manage disk space.&lt;/p&gt;
&lt;h2 id=&#34;four-windows-operating-system--the-users-digital-interaction-heaven&#34;&gt;Four. Windows Operating System – The User’s “Digital Interaction Heaven”
&lt;/h2&gt;&lt;p&gt;Windows, as the world’s most widely used operating system, builds a friendly bridge between people and computer hardware.&lt;/p&gt;
&lt;h3 id=&#34;1-fusion-of-esp-and-gpt-partition-tables&#34;&gt;1. Fusion of ESP and GPT Partition Tables
&lt;/h3&gt;&lt;p&gt;During Windows system installation based on UEFI booting, the installer automatically creates an ESP (Extensible Firmware Interface) partition and deploys boot files to it. Simultaneously, the hard drive is initialized with a GPT (GUID Partition Table) partition scheme, dividing it into system reserved partitions (used for storing critical system files, similar to the system boot file area in traditional BIOS), Windows system partitions (where the core system files are installed), and other user-defined data partitions. The Windows system relies on the GPT partition table to precisely identify each partition, enabling seamless booting through the ESP partition, and ensuring a smooth boot and usage experience.&lt;/p&gt;
&lt;h3 id=&#34;2-system-management-and-optimization-based-on&#34;&gt;2. System Management and Optimization Based on
&lt;/h3&gt;&lt;p&gt;During operation, Windows fully utilizes the advantages of the GPT partition table for disk management. For example, in the Disk Management tool, it can easily identify GPT partitions, allowing users to create, delete, format, and adjust partition sizes – meeting different data storage needs at various stages. Furthermore, processes such as system updates and software installations are closely related to partition layouts.  A rational partition plan helps improve system performance and stability, and reduces issues caused by insufficient disk space or partition confusion.&lt;/p&gt;
&lt;h2 id=&#34;v-practical-tips-maintenance-and-troubleshooting&#34;&gt;V. Practical Tips: Maintenance and Troubleshooting
&lt;/h2&gt;&lt;p&gt;Now that you understand their close relationship, daily maintenance and troubleshooting have a clear process to follow.&lt;/p&gt;
&lt;h3 id=&#34;1-disk-space-management&#34;&gt;1. Disk Space Management
&lt;/h3&gt;&lt;p&gt;Regularly check ESP partition space to avoid running out of space due to installing too many startup-related software, which can affect system boot. For data partitions under GPT partitions, plan storage appropriately, promptly clean up unnecessary files, and prevent a single partition from filling up to impact system operation.&lt;/p&gt;
&lt;h3 id=&#34;2-troubleshooting-startup-failures&#34;&gt;2. Troubleshooting Startup Failures
&lt;/h3&gt;&lt;p&gt;If the system fails to start, first check if the ESP (EFI System Partition) is damaged or files are missing. You can use the startup repair tool built into the UEFI firmware, or enter the Windows recovery environment using an installation media to rebuild the boot files of the ESP partition. If you suspect a GPT partition table failure, use a professional disk utility (such as DiskGenius) to check the integrity of the partition table and attempt to repair it by restoring backup partition information.&lt;/p&gt;
&lt;p&gt;The ESP partition, GPT partition table, and Windows operating system are like a precise team working together, each playing its part to create a stable and efficient computer usage environment for us. Understanding them deeply not only helps us handle system installation and maintenance with confidence but also allows us to understand the underlying logic of computer operation and explore the digital world.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Deeply understand GCC, GLIBC, and C&#43;&#43; program compatibility issues</title>
        <link>https://ttf248.life/en/p/deep-understanding-gcc-glibc-cpp-compatibility-issues/</link>
        <pubDate>Mon, 06 Jan 2025 19:51:16 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/deep-understanding-gcc-glibc-cpp-compatibility-issues/</guid>
        <description>&lt;p&gt;In the C++ development field, GCC and GLIBC are two indispensable key elements, and compatibility issues after program release often trouble developers. This article will delve into their essence, explore the root causes of compatibility problems, and investigate coping strategies.&lt;/p&gt;
&lt;h2 id=&#34;i-gcc-a-powerful-compiler-cornerstone&#34;&gt;I. GCC: A Powerful Compiler Cornerstone
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Definition and Function&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;GCC, or GNU Compiler Collection, is a suite of open-source compilers developed by the GNU project. It’s far from a typical compiler; it supports a wide range of programming languages including C, C++, Objective - C, Fortran, Ada, and Go, providing a one-stop solution for cross-language development.&lt;/li&gt;
&lt;li&gt;Taking C++ as an example, when we write a source file containing complex features like classes, templates, and function overloading, GCC can translate the advanced C++ code into low-level machine instructions that can be understood and executed by the system. This process involves multiple fine-grained stages such as lexical analysis, syntax analysis, semantic analysis, optimization, and code generation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;i-gcc-a-powerful-compiler-foundation&#34;&gt;I. GCC: A Powerful Compiler Foundation
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Compilation Process Details&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Preprocessing Stage:&lt;/strong&gt; GCC first performs preprocessing operations on the source file. During this stage, it handles all preprocessor directives starting with &lt;code&gt;#&lt;/code&gt;, such as &lt;code&gt;#include&lt;/code&gt; instructions. These instructions embed the entire content of specified header files (e.g., &lt;code&gt;&amp;lt;iostream&amp;gt;&lt;/code&gt; for C++ input/output stream operations) into the corresponding locations in the source file, allowing programs to use functions, classes, and other resources declared in those headers; macro definitions using &lt;code&gt;#define&lt;/code&gt; are also expanded and replaced during this stage, such as &lt;code&gt;#define PI 3.14159&lt;/code&gt;.  Every occurrence of &lt;code&gt;PI&lt;/code&gt; in the source file is then replaced with &lt;code&gt;3.14159&lt;/code&gt;. After preprocessing, the source file undergoes an initial &amp;ldquo;expansion.&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compilation Stage:&lt;/strong&gt; The preprocessed file enters the compilation stage, where GCC converts the source file into assembly language code based on the C++ language standard. It carefully checks the code structure, ensuring that class inheritance and polymorphism implementations are correct, as well as that function call parameters match. Upon detecting errors that violate the grammatical semantics, it immediately reports them and terminates the compilation process. For example, if the parameter list in a function declaration does not match its definition, GCC will accurately pinpoint the issue.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;i-gcc-a-powerful-compiler-cornerstone-1&#34;&gt;I. GCC: A Powerful Compiler Cornerstone
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Assembly Stage:&lt;/strong&gt; The assembler converts the assembly code generated in the previous step into machine code, producing object files with a &lt;code&gt;.o&lt;/code&gt; extension. These object files contain binary instructions that can be directly executed by the machine, but they cannot run independently because a complete program is typically composed of multiple modules, and function and variable references between these modules have not yet been resolved.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Linking Stage:&lt;/strong&gt; This is the final sprint to generate an executable file. The linker integrates multiple object files as well as required libraries (static or dynamic) together. For example, when using container classes from the C++ Standard Template Library, linking requires finding the corresponding library implementation code to ensure that the program can correctly call functions of objects like &lt;code&gt;vector&lt;/code&gt; and &lt;code&gt;list&lt;/code&gt; at runtime, ultimately generating a complete executable program.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ii-glibc-the-backbone-of-c-program-execution&#34;&gt;II. GLIBC: The Backbone of C++ Program Execution
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Nature and Function&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;GLIBC, or the GNU C Library, is a concrete implementation of the C standard library within the GNU ecosystem. Although its name emphasizes C, C++ programs heavily rely on it as well, because C++ inherits its foundational elements. It provides a vast array of basic functions, such as those for memory management – &lt;code&gt;malloc&lt;/code&gt; (dynamic memory allocation) and &lt;code&gt;free&lt;/code&gt; (memory deallocation) – which are indispensable when creating dynamic arrays and objects in C++, as well as string manipulation functions like &lt;code&gt;strcpy&lt;/code&gt; (string copy) and &lt;code&gt;strcat&lt;/code&gt; (string concatenation). Even though C++ has a more advanced &lt;code&gt;string&lt;/code&gt; class, these functions are still frequently used at the underlying level when interacting with C code or striving for extreme performance, as well as in early C++ development and scenarios where simplicity is paramount.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;ii-glibc-the-backbone-of-c-program-execution-1&#34;&gt;II. GLIBC: The Backbone of C++ Program Execution
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Collaboration with the Operating System&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;GLIBC acts as a crucial bridge between the operating system and applications. In Linux systems, when a C++ program initiates a system call – such as opening a file (using the &lt;code&gt;open&lt;/code&gt; function, which relies on GLIBC’s implementation), GLIBC encapsulates the program&amp;rsquo;s request in a manner conforming to the operating system kernel’s specifications and passes it to the kernel for processing. Upon completion by the kernel, GLIBC returns the results to the application. This allows applications to utilize various system resources – such as file systems, networks, and process management – without needing to delve into the complex details of the underlying system call interfaces.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;iii-compatibility-issues-after-c-program-deployment-an-analysis&#34;&gt;III. Compatibility Issues After C++ Program Deployment: An Analysis
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Compatibility Dilemmas Triggered by Differences in GLIBC Version&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Different Linux distributions often feature different versions of GLIBC. When a C++ program is compiled in a newer GLIBC environment, it may unknowingly utilize certain new function features or rely on optimized function implementations introduced in that version. For example, a newer GLIBC version has improved the memory allocation algorithm; the program frequently utilizes this new algorithm to enhance performance during runtime. Once this program is deployed on a lower-version GLIBC system, it may encounter issues such as failing to find the corresponding function (because the older version did not introduce it) or abnormal function behavior (the old implementation logic differs from the new one), leading to program crashes or incorrect results.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;iii-compatibility-issues-after-c-program-publishing-an-analysis&#34;&gt;III. Compatibility Issues After C++ Program Publishing: An Analysis
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Compatibility Risks Due to Compiler Differences&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Even when using the same GCC compiler, differences between different versions of GCC in terms of code generation, standard library support, and implementation details for C++ features can lead to compatibility issues. Newer GCC versions may have full support for the latest C++ standards (such as new feature modules in C++20 like coroutines), and if a program uses these advanced features and is compiled under an older GCC version, the compiler will error out due to its inability to recognize these new syntax structures. Even without syntax errors, different GCC versions have different optimization strategies, which can lead to significant differences in machine code generated in terms of execution efficiency and memory usage. In performance-critical scenarios, this can cause programs to behave differently in different environments. - &lt;strong&gt;Challenges Posed by Architectural Differences&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;C++ programs may need to run on different hardware system architectures, such as x86, ARM, and PowerPC. These architectures have unique instruction sets, memory layouts, and data alignment requirements. For example, a structure data layout that runs correctly on an x86 architecture might cause memory access exceptions on an ARM architecture due to differing alignment rules, leading to program errors. Furthermore, GCC generates significantly different machine code when compiling for various architectures; if the program contains hardcoded architectural-specific instructions or assumptions, it will inevitably fail during cross-architecture execution.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;four-strategies-for-addressing-compatibility-issues&#34;&gt;Four. Strategies for Addressing Compatibility Issues
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Utilization of Static Link Libraries&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Consider using static link libraries, packaging the code of libraries that your program depends on (such as GLIBC) directly into the executable file. This eliminates the need for the target system’s specific GLIBC version at runtime, effectively preventing issues caused by GLIBC version mismatches. However, static linking will significantly increase the size of the executable file, requiring a trade-off in resource-constrained scenarios.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Containerized Deployment&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Leveraging containerization technologies like Docker, encapsulate your C++ program and its required runtime environment (including specific versions of GCC, GLIBC, etc.) within an independent container. Regardless of the underlying operating system to which it is deployed, the container maintains consistency with the development environment, ensuring that the program runs as expected and greatly simplifies cross-environment deployment complexity. - &lt;strong&gt;Compatibility Testing and Continuous Integration&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Establish a comprehensive compatibility testing system, covering different GLIBC versions, GCC versions, and common system architectures. During the software development process, use continuous integration tools to perform automated testing on multiple environments regularly. Once compatibility issues are identified, they are promptly fixed, eliminating potential problems at their earliest stages and ensuring stability after program deployment.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;four-strategies-for-addressing-compatibility-issues-1&#34;&gt;Four. Strategies for Addressing Compatibility Issues
&lt;/h2&gt;&lt;p&gt;As a summary, a deep understanding of the workings of GCC and GLIBC, accurately identifying the root causes of C++ compatibility issues, and flexibly applying appropriate strategies are essential skills for every C++ developer to build robust, cross-platform applications. Only in this way can our C++ works run smoothly within diverse technological ecosystems.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Windows Built-in Disk Cleanup Tool: Storage</title>
        <link>https://ttf248.life/en/p/windows-disk-cleanup-storage/</link>
        <pubDate>Mon, 06 Jan 2025 19:29:45 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/windows-disk-cleanup-storage/</guid>
        <description>&lt;p&gt;I’m not sure from what version it started, but in Windows 11, the Disk Cleanup tool has been significantly improved and become much smarter.&lt;/p&gt;
&lt;p&gt;The key is that it&amp;rsquo;s an official tool, so it won’t accidentally delete files, won’t have ads, won’t have pop-ups, won’t have background processes, or any unnecessary elements.&lt;/p&gt;
&lt;p&gt;You can access the Disk Cleanup tool in Windows 11 by going to &lt;code&gt;Settings&lt;/code&gt; - &lt;code&gt;System&lt;/code&gt; - &lt;code&gt;Storage&lt;/code&gt; - &lt;code&gt;Temporary Files&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/windows-disk-cleanup-storage/20250106194453.png&#34;
	width=&#34;1041&#34;
	height=&#34;775&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Storage Interface&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;134&#34;
		data-flex-basis=&#34;322px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;For regular users, simply selecting “Clean Recommendations” is sufficient; the system will provide suggestions based on your usage.&lt;/p&gt;
&lt;p&gt;As a developer, I have many temporary files on my disk, so I choose &amp;ldquo;Temporary Files,&amp;rdquo; which contains items like Visual Studio temporary files and Windows Update temporary files, etc.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/windows-disk-cleanup-storage/Snipaste_2024-12-19_13-39-51.png&#34;
	width=&#34;465&#34;
	height=&#34;980&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Temporary Files&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;47&#34;
		data-flex-basis=&#34;113px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Docker Domestic Mirror Proxy Failed</title>
        <link>https://ttf248.life/en/p/docker-domestic-mirror-failure/</link>
        <pubDate>Sat, 04 Jan 2025 18:29:25 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/docker-domestic-mirror-failure/</guid>
        <description>&lt;p&gt;Deploying Docker on domestic servers, after deployment, if the company doesn’t provide a registry center, the first thing developers need to do is configure a domestic registry acceleration address. It&amp;rsquo;s lucky that today there was a server configured with a registry acceleration address, but when pulling images, it kept failing to pull.&lt;/p&gt;
&lt;p&gt;Error response from daemon: “Get &lt;a class=&#34;link&#34; href=&#34;https://registry-1.docker.io/v2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://registry-1.docker.io/v2/&lt;/a&gt;”: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)&lt;/p&gt;
&lt;!-- 20250106 – Two days after, all servers were restored, and this issue didn’t even make the news. All domestic registry proxies went down --&gt;
&lt;h2 id=&#34;troubleshooting-and-repair-attempts&#34;&gt;Troubleshooting and Repair Attempts
&lt;/h2&gt;&lt;p&gt;Initially, we attempted to switch to alternative mirror acceleration addresses, hoping to resolve the issue. However, as expected, the problem persisted.&lt;/p&gt;
&lt;p&gt;Subsequently, we began modifying the local DNS configuration in an attempt to find a breakthrough at the network parsing level. Unfortunately, after some debugging, the fault remained.&lt;/p&gt;
&lt;p&gt;At this point, the stability of the local network was heavily questioned, so we decisively switched to a mobile hotspot, attempting to bypass potential local network faults. However, the result was discouraging – there were no signs of improvement.&lt;/p&gt;
&lt;h2 id=&#34;problem-propagation&#34;&gt;Problem Propagation
&lt;/h2&gt;&lt;p&gt;We currently have &lt;strong&gt;a few servers deployed domestically&lt;/strong&gt; with Docker environments, and all of them failed to successfully pull the image. We initially hoped to find an alternative solution, but we found that they all consistently failed with identical error messages, indicating that the issue isn&amp;rsquo;t isolated to a single device.&lt;/p&gt;
&lt;p&gt;Further investigation revealed that the image proxy seemingly malfunctioned instantaneously. In this critical moment, we quickly switched to a machine outside of the country, and thankfully, image pulls were restored at this location. This suggests that the problem is highly likely related to the domestic network links or associated configurations.&lt;/p&gt;
&lt;h2 id=&#34;strategy-adjustment-circumventing-solutions&#34;&gt;Strategy Adjustment: Circumventing Solutions
&lt;/h2&gt;&lt;p&gt;Given that direct image pulling routes within China have been heavily restricted, while foreign mirrors remain accessible, to expedite project progress, we’ve decided to employ a circumvention tactic. Initially, we switched to foreign servers to successfully pull the required images, subsequently pushing them to domestic mirror repositories to establish a “data bridge.”&lt;/p&gt;
&lt;p&gt;At the same time, we synchronized modifications to the Dockerfile files, replacing image addresses with those adapted for the Chinese environment and then rebuilt the images, ultimately achieving successful deployment.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>CentOS 8 Stream EOL</title>
        <link>https://ttf248.life/en/p/centos-8-stream-eol/</link>
        <pubDate>Sat, 16 Nov 2024 23:24:50 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/centos-8-stream-eol/</guid>
        <description>&lt;p&gt;&lt;code&gt;CentOS Stream&lt;/code&gt; is the upstream open-source development platform prior to Red Hat’s &lt;code&gt;Linux&lt;/code&gt; distribution.&lt;/p&gt;
&lt;p&gt;I first noticed the open-source operating system lifecycle &lt;a class=&#34;link&#34; href=&#34;https://ttf248.life/en/p/redhat-centos-lifecycle/&#34; &gt;redhat and centos life cycle&lt;/a&gt; had ended, and I was wondering what was going on? Besides security issues, dnf wasn’t working, and I recently encountered failures when installing tools – checking the repository sources revealed that &lt;code&gt;CentOS 8 Stream&lt;/code&gt; had reached its end of life.&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;centos-stream-introduction&#34;&gt;CentOS Stream Introduction
&lt;/h2&gt;&lt;h3 id=&#34;positioning-and-roles&#34;&gt;Positioning and Roles
&lt;/h3&gt;&lt;p&gt;CentOS Stream sits between Fedora Linux (upstream development) and RHEL (Red Hat Enterprise Linux, downstream development), acting as a bridge.&lt;/p&gt;
&lt;p&gt;It can be considered a version for experiencing the latest Red Hat-based Linux features, suitable for those who want to try out new things.&lt;/p&gt;
&lt;h3 id=&#34;origins-and-background&#34;&gt;Origins and Background
&lt;/h3&gt;&lt;p&gt;Over time, Red Hat began to seek more effective ways to develop its enterprise-grade Linux platform, leading to the launch of CentOS Stream.&lt;/p&gt;
&lt;p&gt;CentOS 8 ended maintenance at the end of 2021, and CentOS Stream continued to be updated as its successor, becoming the future direction of the CentOS project.&lt;/p&gt;
&lt;h3 id=&#34;features-and-advantages&#34;&gt;Features and Advantages
&lt;/h3&gt;&lt;p&gt;CentOS Stream is a rolling release Linux distribution that provides faster updates. It offers greater transparency and more opportunities for community, partner, and customer participation, allowing users to contribute to Red Hat Enterprise Linux (RHEL) more quickly and directly.
The content of CentOS Stream is software that Red Hat intends to include in the next stable version of RHEL, therefore it provides a stable ABI/API for developers and testers within the community.&lt;/p&gt;
&lt;h3 id=&#34;use-cases-and-target-users&#34;&gt;Use Cases and Target Users
&lt;/h3&gt;&lt;p&gt;CentOS Stream is suitable for those CentOS users who want to continue receiving the latest Linux feature updates, as well as developers and partners who wish to participate in Red Hat Enterprise Linux development.&lt;/p&gt;
&lt;p&gt;It also aims to help community members, Red Hat partners, and others fully leverage innovative open-source software in a more stable and predictable Linux ecosystem.&lt;/p&gt;
&lt;h2 id=&#34;end-of-lifehttpsendoflifedatecentos-stream&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://endoflife.date/centos-stream&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;End of Life&lt;/a&gt;
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Release&lt;/th&gt;
&lt;th&gt;Released&lt;/th&gt;
&lt;th&gt;Active Support&lt;/th&gt;
&lt;th&gt;Security Support&lt;/th&gt;
&lt;th&gt;Latest&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;3 years ago (15 Sep 2021)&lt;/td&gt;
&lt;td&gt;Ends in 2 years and 6 months (31 May 2027)&lt;/td&gt;
&lt;td&gt;Ends in 2 years and 6 months (31 May 2027)&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;end-of-lifehttpsendoflifedatecentos-stream-1&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://endoflife.date/centos-stream&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;End of Life&lt;/a&gt;
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Release&lt;/th&gt;
&lt;th&gt;Released&lt;/th&gt;
&lt;th&gt;Active Support&lt;/th&gt;
&lt;th&gt;Security Support&lt;/th&gt;
&lt;th&gt;Latest&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;5 years ago (24 Sep 2019)&lt;/td&gt;
&lt;td&gt;Ended 5 months and 3 weeks ago (31 May 2024)&lt;/td&gt;
&lt;td&gt;Ended 5 months and 3 weeks ago (31 May 2024)&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;solutions&#34;&gt;Solutions
&lt;/h2&gt;&lt;p&gt;Rather than bothering with upgrades, we opted for the long-term support version of &lt;code&gt;Ubuntu 24.04&lt;/code&gt;.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Hugo Module Customizing Theme: Explanation of Approach</title>
        <link>https://ttf248.life/en/p/hugo-module-custom-theme-ideas/</link>
        <pubDate>Fri, 15 Nov 2024 22:01:17 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/hugo-module-custom-theme-ideas/</guid>
        <description>&lt;p&gt;Reviewing the historical commit logs, the site has undergone numerous theme switches. Each theme switch involved some custom modifications, and this is where I’m documenting the approach to customizing themes. My &lt;code&gt;Github&lt;/code&gt; repository briefly maintained the even theme, but due to my obsessive-compulsive tendencies, I resisted upgrading the &lt;code&gt;hugo&lt;/code&gt; compiler to the latest version, which rendered the even theme incompatible, so I switched back to the &lt;code&gt;stack&lt;/code&gt; theme.&lt;/p&gt;
&lt;h2 id=&#34;hugos-modularity&#34;&gt;Hugo&amp;rsquo;s Modularity
&lt;/h2&gt;&lt;p&gt;When we talk about modularity, many people think of things like Nginx modules and IDEA plugins. Typically, I can upload various modules to satisfy my specific needs. The reason everyone likes this kind of module is that it’s incredibly flexible – you don’t have to put in too much effort to meet your own requirements. Often, even though the overall concepts are similar, there are always subtle differences. This highlights the complexity of software, not just technically, but also from a business perspective. Most often, we face business complexity. This is precisely where the saying “it’s like crossing a river and climbing a mountain” – “隔行如隔山” – is best illustrated. Today, not only the internet industry and the financial sector, even traditional manufacturing has adopted information systems to help with production and management. Here’s the English translation of the provided text:&lt;/p&gt;
&lt;p&gt;“Similarly, even within the same industry, different companies will have variations in their leave systems. However, Hugo&amp;rsquo;s modules differ somewhat from what people typically expect – they aren’t organized based on functionality to meet specific differentiation needs. Instead, they are primarily structured around directory hierarchies to identify and recognize identical structures.”&lt;/p&gt;
&lt;p&gt;Resource link: &lt;a class=&#34;link&#34; href=&#34;https://medium.com/@sunwei.xyz/07-hugo%E6%9E%B6%E6%9E%84-hugo%E7%9A%84%E6%A8%A1%E5%9D%97-8ef5a520a822&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;07. Hugo Architecture — Hugo Modules&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;hugos-modularization&#34;&gt;Hugo&amp;rsquo;s Modularization
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;git submodule&lt;/code&gt; still works, but we don’t recommend using it. Maintaining them can be quite troublesome if the themes used are updated; they should be managed as separate Git repositories.&lt;/p&gt;
&lt;h2 id=&#34;theme-modification-logichttpsstackjimmycaicomguidemodify-theme&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://stack.jimmycai.com/guide/modify-theme&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Theme Modification Logic&lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;Once you’ve grasped the foundational concepts of modularization, understanding custom themes becomes much simpler. Hugo themes are currently assembled from multiple different modules. To modify a single module, locate its corresponding template file and make the changes directly.&lt;/p&gt;
&lt;p&gt;Excerpted from the official &lt;code&gt;stack&lt;/code&gt; documentation:&lt;/p&gt;
&lt;p&gt;Using this method, there will be no files under the &lt;code&gt;themes&lt;/code&gt; directory.  To modify the theme, you will need to copy the file you want to modify to the same directory under the &lt;code&gt;layouts&lt;/code&gt; directory.&lt;/p&gt;
&lt;h2 id=&#34;theme-modification-logichttpsstackjimmycaicomguidemodify-theme-1&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://stack.jimmycai.com/guide/modify-theme&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Theme Modification Logic&lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;For example, in order to modify the &lt;code&gt;themes/hugo-theme-stack/layouts/partials/head/custom.html&lt;/code&gt; file, you will need to copy it to &lt;code&gt;layouts/partials/head/custom.html&lt;/code&gt; and modify it there (copy the code from the theme&amp;rsquo;s repository). The same applies to the &lt;code&gt;assets&lt;/code&gt; and &lt;code&gt;static&lt;/code&gt; directories.&lt;/p&gt;
&lt;h2 id=&#34;how-to-find-template-files&#34;&gt;How to Find Template Files
&lt;/h2&gt;&lt;h3 id=&#34;conventional-approach&#34;&gt;Conventional Approach
&lt;/h3&gt;&lt;p&gt;Review the source files of the topic, understand its design rationale, identify the corresponding template file, and modify it.&lt;/p&gt;
&lt;h3 id=&#34;bruteforce-approach&#34;&gt;Bruteforce Approach
&lt;/h3&gt;&lt;p&gt;As I don’t have a deep understanding of frontend code, sometimes I resort to a brute-force approach, such as opening the corresponding page directly in the browser, finding the areas I want to modify, and using “Inspect Element” to pinpoint the &lt;code&gt;css name&lt;/code&gt;, then searching the source code for the relevant file, copying it into the site directory, and making changes.&lt;/p&gt;
&lt;h2 id=&#34;tips&#34;&gt;Tips
&lt;/h2&gt;&lt;p&gt;The official setup provides a default file for customizing styles. To modify specific areas, we can split them into multiple files and import them using &lt;code&gt;custom.scss&lt;/code&gt;. This approach allows for better management of style files.
&lt;img src=&#34;https://ttf248.life/p/hugo-module-customizing-themes-ideas/image.png&#34;
	width=&#34;141&#34;
	height=&#34;375&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;37&#34;
		data-flex-basis=&#34;90px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;summarize-modified-content-6h&#34;&gt;Summarize Modified Content (6h)
&lt;/h2&gt;&lt;p&gt;It’s now the first year of AI coding, and the detailed content will not be pasted here for brevity; instead, we simply list some of the modifications made to this site, such as adjusting the copy button styles, reconfiguring the code block styles, and ChatGPT can be easily handled.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Overall: Global text style, adopting the previous display style that merged &lt;code&gt;even&lt;/code&gt; with &lt;code&gt;info cn&lt;/code&gt;, which is friendly to Chinese&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Homepage: Added mouse interaction animation to the right navigation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Homepage: New article summaries are added (a time-consuming task, achieved using a clever workaround)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Scroll Bar: Improved the styling of the scroll bar&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Code Blocks: Introduced &lt;code&gt;highlight.&lt;/code&gt;. - JavaScript code highlighting plugin, beautify code block styles&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Article details: Some content is a reprint, with new original author information display and original link display&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Archived page: Top category image, remove the theme&amp;rsquo;s color mask, display the original image&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Archived page: Added a statistical display panel for classification by year&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Archived page: Two-column layout display ## Summarize Modified Content (6h)
It’s now the first year of AI coding, and the detailed content will not be pasted here for brevity; instead, we simply list some of the modifications made to this site, such as adjusting the copy button styles, reconfiguring the code block styles, and ChatGPT can be easily handled.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Overall: Global text style, adopting the display style previously used by merging &lt;code&gt;even&lt;/code&gt; with &lt;code&gt;info cn&lt;/code&gt;, which is friendly to Chinese&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Homepage: Added mouse interaction animation to the right navigation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Homepage: New article added summary preview (took quite a while, implemented using a clever trick)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Scroll Bar: Beautified the scroll bar’s styling&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Code Blocks: Introduced &lt;code&gt;highlight.&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;summarize-modified-content-6h-1&#34;&gt;Summarize Modified Content (6h)
&lt;/h2&gt;&lt;p&gt;The &lt;code&gt;stack&lt;/code&gt; theme component reuse rate is very high, which has led to a significant amount of time being spent adding summary previews to new homepage articles.  I modified the corresponding component, and this resulted in changes to the article’s detail page, leading to redundant display of the main content. I wasn&amp;rsquo;t very familiar with &lt;code&gt;golang templates&lt;/code&gt;, so it took up a lot of time.  I struggled to get parameters passed between components, and ultimately resolved this by taking a shortcut: introducing a &lt;code&gt;JavaScript&lt;/code&gt; script independently on the homepage and using custom special variables to implement the summary preview.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Sometimes high component reuse rates can also be a problem, leading to changes in one place affecting other places. Therefore, when modifying themes, you must pay attention not to disrupt existing logic.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments
&lt;/h3&gt;&lt;p&gt;This guy&amp;rsquo;s modifications are more refined: &lt;a class=&#34;link&#34; href=&#34;https://blog.reincarnatey.net/2024/0719-better-waline/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.reincarnatey.net/2024/0719-better-waline/&lt;/a&gt;
&lt;del&gt;This site simply enabled the &lt;code&gt;Waline&lt;/code&gt; comment system, as the &lt;code&gt;stack&lt;/code&gt; theme defaults to supporting &lt;code&gt;Waline&lt;/code&gt;. Just configure it in the &lt;code&gt;config.toml&lt;/code&gt; file.&lt;/del&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Recommend contacting via email on the homepage, this site does not open the comments section&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>Linux backend services handling large volumes of string data – performance is slow.</title>
        <link>https://ttf248.life/en/p/linux-backend-slow-string-processing/</link>
        <pubDate>Wed, 13 Nov 2024 19:42:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-backend-slow-string-processing/</guid>
        <description>&lt;p&gt;In the history of C++ development projects, we utilized a custom protocol for communication, which employed a two-dimensional array pattern. When processing large volumes of data, the protocol required iterating through the arrays and performing serialization operations to generate logs. Due to its low efficiency, this resulted in noticeable lag or stuttering within the system under heavy load, as reported by the business departments.&lt;/p&gt;
&lt;h2 id=&#34;problem-identification&#34;&gt;Problem Identification
&lt;/h2&gt;&lt;p&gt;When troubleshooting the issue, we first performed a performance analysis of the system and found that CPU utilization increased significantly when processing large amounts of data, and system response times became longer. Through analyzing the system logs, we identified numerous serialization operations, which were inefficient when handling two-dimensional arrays, leading to a decline in system performance.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;pstack&lt;/code&gt; tool captured thread information for the service, pinpointing that the log threads spent most of their time processing string concatenation.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is today&amp;rsquo;s focus: different accumulation methods have significant efficiency differences. Historically, the code used the &lt;code&gt;+&lt;/code&gt; operator, which frequently creates temporary objects and is very inefficient. You know it’s bad, but you don’t know &lt;em&gt;how&lt;/em&gt; bad it is.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;demo-verification&#34;&gt;Demo Verification
&lt;/h2&gt;&lt;p&gt;Based on the project code, we extracted the business logic and wrote a simple demo to verify the efficiency issues of string concatenation. We compiled and ran it in &lt;code&gt;Release&lt;/code&gt; mode using the &lt;code&gt;vs2022&lt;/code&gt; compiler under &lt;code&gt;windows&lt;/code&gt; and the &lt;code&gt;gcc8.5&lt;/code&gt; compiler under &lt;code&gt;linux&lt;/code&gt;, comparing the efficiencies.&lt;/p&gt;
&lt;h3 id=&#34;key-points-explanation&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;p&gt;The project utilized Method Four, and before obtaining test data, the reader should consider which method is most efficient and which is least efficient. I was quite surprised by the results.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Method 1 (&lt;code&gt;+=&lt;/code&gt; Concatenation)&lt;/strong&gt;: Directly concatenates each field using &lt;code&gt;+=&lt;/code&gt; to a string.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 2 (&lt;code&gt;std::ostringstream&lt;/code&gt; Concatenation)&lt;/strong&gt;: Uses a stream (&lt;code&gt;std::ostringstream&lt;/code&gt;) to concatenate fields, which is more efficient, especially when dealing with large amounts of data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 3 (Pre-allocated &lt;code&gt;+=&lt;/code&gt; Concatenation)&lt;/strong&gt;: Pre-allocates enough memory for the string using &lt;code&gt;reserve&lt;/code&gt; to reduce the overhead of memory reallocation and improve performance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method 4 (&lt;code&gt;bodys = bodys + body + &amp;quot;\n&amp;quot;&lt;/code&gt;)&lt;/strong&gt;: Each concatenation creates a new temporary string object, leading to performance degradation, especially with large-scale concatenations due to the allocation and copying of a new memory space each time.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Referring to the results, we can see that this method was selected as the least efficient.&lt;/p&gt;
&lt;p&gt;Furthermore, let&amp;rsquo;s analyze the optimization efficiency of different platform compilers – Microsoft’s &lt;code&gt;visual studio&lt;/code&gt; remains consistently excellent, with high string optimization efficiency, while the &lt;code&gt;gcc&lt;/code&gt; compiler lags somewhat in this regard.&lt;/p&gt;
&lt;h3 id=&#34;key-points-explanation-1&#34;&gt;Key Points Explanation
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;The code executes on different machines, and the two datasets do not have a direct comparison; instead, differences can be compared between various splicing methods.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;complete-code&#34;&gt;Complete Code
&lt;/h2&gt;</description>
        </item>
        <item>
        <title>C&#43;&#43; Lambda Expression Parameter Lifetimes</title>
        <link>https://ttf248.life/en/p/cpp-lambda-parameter-lifetime/</link>
        <pubDate>Wed, 13 Nov 2024 19:23:02 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-lambda-parameter-lifetime/</guid>
        <description>&lt;p&gt;In C++, lambda expressions are a convenient way to create anonymous functions that can capture external variables and use them within their bodies. This makes lambdas a flexible programming tool. However, the lifetime of parameters in a lambda expression is an aspect that requires careful attention, especially when capturing and passing parameters.&lt;/p&gt;
&lt;h3 id=&#34;1-lambda-expression-parameter-lifetime&#34;&gt;1. Lambda Expression Parameter Lifetime
&lt;/h3&gt;&lt;p&gt;The lifetime of parameters in a lambda expression is typically the same as that of other C++ functions. Parameters exist while the function is being called, and their lifetime ends when the function call terminates. However, due to the possibility of lambdas capturing external variables, the parameter&amp;rsquo;s lifetime is also affected by how it’s captured.&lt;/p&gt;
&lt;h3 id=&#34;2-capturing-the-relationship-with-parameter-lifecycles&#34;&gt;2. Capturing the Relationship with Parameter Lifecycles
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;#### 2.1 Capturing External Variables

C++ lambda expressions allow external variables to be captured in two ways:

- **Capture by Value:** When capturing by value, the value of the external variable is copied into the lambda, and the lifetime of the copy is controlled by the lifetime of the lambda.
- **Capture by Reference:** When capturing by reference, a reference to the external variable is retained, and the lambda&#39;s reference points to the original external variable. The lifetime depends on the external variable.

For captured variables, the lifetimes are as follows:

- **Capture by Value:** When capturing, the value of the external variable is copied into the lambda; when the lambda’s lifetime ends, the copy is destroyed.
- **Capture by Reference:** The lambda holds a reference to the external variable, and **the external variable must be valid before it is used within the lambda, otherwise undefined behavior results.**
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;22-lambda-parameters&#34;&gt;2.2 Lambda Parameters
&lt;/h4&gt;&lt;p&gt;Lambda parameters are similar to regular function parameters; their lifetime is limited to the lambda function body. That is, lambda parameters are created when the lambda is called and their lifetime ends when the lambda call completes.
In this example, &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; are the parameters of the lambda expression, they are created when the lambda is called and destroyed when the lambda executes.&lt;/p&gt;
&lt;h3 id=&#34;3-lifecycle-issues-when-capturing-external-variables&#34;&gt;3. Lifecycle Issues When Capturing External Variables
&lt;/h3&gt;&lt;h4 id=&#34;31-whether-captured-variables-are-valid-outside-lambda&#34;&gt;3.1 Whether Captured Variables Are Valid Outside Lambda
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Value Capture:&lt;/strong&gt; Even if the external variable is destroyed after the lambda call, the lambda internally holds a copy of the external variable. Therefore, the copy within the lambda can be safely used even if the external variable no longer exists.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reference Capture:&lt;/strong&gt; If the captured variable is a reference to the external variable, the lambda&amp;rsquo;s access to that reference depends on the lifecycle of the external variable. If the external variable is destroyed before the lambda executes, a dangling reference issue will occur, leading to undefined behavior.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;It’s important to ensure that the external variables are valid when the lambda executes if the execution order of the lambda is not deterministic.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>Win11 Logitech G431 Headset Driver Installation</title>
        <link>https://ttf248.life/en/p/win11-logitech-g431-headphone-driver-installation/</link>
        <pubDate>Wed, 05 Jun 2024 07:20:17 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/win11-logitech-g431-headphone-driver-installation/</guid>
        <description>&lt;p&gt;Picking up where we left off, I discovered that GitHub had an update, which was a little exciting. The customer service representative said the issue with the driver not loading properly was resolved. However, after going through all the troubleshooting – reinstalling and uninstalling – it still wasn&amp;rsquo;t working correctly.&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background
&lt;/h2&gt;&lt;p&gt;Continuing to contact customer service to inquire about a resolution, I was informed that an engineer could provide remote assistance. However, the engineer’s working hours coincided exactly with my own, leaving me with no option but to abandon the effort. Reviewing the documentation from the previous troubleshooting issue, I decided to attempt a manual driver installation.&lt;/p&gt;
&lt;h2 id=&#34;obtaining-driver-installation-packages&#34;&gt;Obtaining Driver Installation Packages
&lt;/h2&gt;&lt;p&gt;Logitech does not provide separate driver installation packages for devices. How can I obtain the driver files?&lt;/p&gt;
&lt;p&gt;In conjunction with the system image package left over from the previous system reinstallation, we can reinstall the system once in a local virtual machine, and then deploy a clean copy of Ghub in the pure system, inserting the headset device into the virtual machine to find the driver path and copy it out.&lt;/p&gt;
&lt;p&gt;Relevant paths:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C:\ProgramData\LGHUB&lt;/li&gt;
&lt;li&gt;C:\Windows\System32\DriverStore\FileRepository\logi_audio.inf_amd64_010b035044e24be4&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;device-manager&#34;&gt;Device Manager
&lt;/h2&gt;&lt;p&gt;The focus is on how to find the second path – let’s first briefly outline how to manually manage driver files in a Windows 11 system. This content &lt;strong&gt;is identified using the method of controlling variables by repeatedly plugging and unplugging devices, analyzing device information within Device Manager inside a virtual machine, and identifying three drivers that need to be handled for headphones.&lt;/strong&gt; Two of these drivers are system-provided, while one is provided by Logitech.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/win11-logitech-g431-headphone-driver-installation/20240605073331.png&#34;
	width=&#34;433&#34;
	height=&#34;904&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Driver Manager&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;47&#34;
		data-flex-basis=&#34;114px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;In the second driver shown in the image, it’s provided by Logitech.  Let&amp;rsquo;s analyze the current driver program for the device and then search all driver paths within the virtual machine. Of course, you first need to find files starting with “logi,” and then compare the files – this will allow you to pinpoint the location of the driver folder, copy the entire folder, and you’ll have the driver installation package.&lt;/p&gt;
&lt;h2 id=&#34;installing-the-driver&#34;&gt;Installing the Driver
&lt;/h2&gt;&lt;p&gt;In the device manager interface, click: Update driver, then click: Browse my computer to find drivers, and you’ll arrive at the following interface:&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/win11-logitech-g431-headphone-driver-installation/20240605074130.png&#34;
	width=&#34;528&#34;
	height=&#34;381&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Driver Installation&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;138&#34;
		data-flex-basis=&#34;332px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Of course, when you open it, you&amp;rsquo;ll only see one driver – the standard USB driver. Select &amp;ldquo;Install from disk&amp;rdquo; and the path is the folder we copied earlier. After installation, you’ll be able to add Logitech-specific drivers in the dropdown list. Switch the device driver to the newly installed driver.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/win11-logitech-g431-headphone-driver-installation/20240605074208.png&#34;
	width=&#34;593&#34;
	height=&#34;423&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Disk Installation&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;140&#34;
		data-flex-basis=&#34;336px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;human-anatomy-device-driven&#34;&gt;Human Anatomy Device-Driven
&lt;/h2&gt;&lt;p&gt;These driver files are provided by the system. You only need to check if there is an exclamation mark preceding the device driver name. If there is, enter the Driver Selection interface, randomly switch to a different type of driver, and then revert it back to restore normal operation.&lt;/p&gt;
&lt;h2 id=&#34;completed&#34;&gt;Completed
&lt;/h2&gt;&lt;p&gt;The headphone microphone volume has been restored to normal, and the familiar in-ear functionality has returned.
&lt;img src=&#34;https://ttf248.life/p/win11-logitech-g431-headphone-driver-installation/20240605074823.png&#34;
	width=&#34;485&#34;
	height=&#34;739&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Side Noise&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;65&#34;
		data-flex-basis=&#34;157px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Logitech Headset Driver Installation Failed</title>
        <link>https://ttf248.life/en/p/logitech-headset-driver-installation-failed/</link>
        <pubDate>Fri, 31 May 2024 21:46:12 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/logitech-headset-driver-installation-failed/</guid>
        <description>&lt;p&gt;If you completely don&amp;rsquo;t understand these things, contacting official customer service first will also avoid wasting several hours.&lt;/p&gt;
&lt;h2 id=&#34;main-text&#34;&gt;Main Text
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/logitech-headphone-driver-installation-failure/20240531220709.png&#34;
	width=&#34;693&#34;
	height=&#34;489&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;GHUB&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;141&#34;
		data-flex-basis=&#34;340px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Recently, the C drive of my desktop computer used for development was running out of space, so I took out a 256GB semi-retired solid state hard drive to use as the C drive. Unfortunately, I kept messing around with it. Since moving to Shanghai, I&amp;rsquo;ve been busy with various things, and last week I finally had time to reinstall the system.&lt;/p&gt;
&lt;p&gt;The system reinstallation went smoothly, and installing daily software and deploying development environments didn’t encounter any problems. A few days later, I planned to relax and play a few games when I realized that the drivers for my mouse and headphones hadn&amp;rsquo;t been installed. Both devices are Logitech products, so I downloaded the GHUB software, which can automatically identify hardware and install drivers.&lt;/p&gt;
&lt;p&gt;However, an unexpected event occurred. The mouse driver installed successfully, but the headphone driver kept displaying &amp;ldquo;Loading&amp;hellip;&amp;rdquo; I suspect it may be incompatibility between the latest version of Windows 11 and Logitech’s drivers, causing the installation to fail. Therefore, I began searching for information and attempting manual driver installations, but the problem persisted.&lt;/p&gt;
&lt;p&gt;Let me briefly explain the roles of these two drivers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The mouse driver primarily focuses on adjusting mouse movement speed and other functions. I rarely use macros; I simply restore previously remembered parameters.&lt;/li&gt;
&lt;li&gt;The headphone driver mainly handles the microphone functionality (earphone mic), which is very useful during team voice calls, allowing me to hear my own voice. Although there’s a similar listening function in the system&amp;rsquo;s microphone settings, it doesn’t perform as well as the driver implementation.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;main-text-1&#34;&gt;Main Text
&lt;/h2&gt;&lt;p&gt;Despite my repeated attempts, the headset driver consistently failed to load properly. Today, I finally thought of reaching out to customer service to inquire about the situation and see if there were any solutions. Customer service informed me that their servers had recently experienced an issue, leading to abnormal driver downloads. They are currently addressing this problem and asked me not to worry; the issue should be resolved after the next update.&lt;/p&gt;
&lt;p&gt;Although the headset driver issue hasn’t been resolved yet, at least I now know the cause, and I hope the problem can be fixed as soon as possible.&lt;/p&gt;
&lt;h2 id=&#34;mouse-driver-settings&#34;&gt;Mouse Driver Settings
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/logitech-headphone-driver-installation-failure/20240531220930.png&#34;
	width=&#34;1024&#34;
	height=&#34;768&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;G502&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;
&lt;img src=&#34;https://ttf248.life/p/logitech-headphone-driver-installation-failure/20240531220903.png&#34;
	width=&#34;1024&#34;
	height=&#34;768&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;G502&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Python Dictionary Storage of Custom Objects: The Importance of References vs. Deep Copies</title>
        <link>https://ttf248.life/en/p/python-dictionary-custom-objects-reference-vs-deepcopy/</link>
        <pubDate>Fri, 22 Mar 2024 01:08:05 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/python-dictionary-custom-objects-reference-vs-deepcopy/</guid>
        <description>&lt;p&gt;In Python programming, a dictionary is a very powerful data structure that allows us to associate key-value pairs and efficiently search and manipulate these data. When we try to store custom objects in a dictionary, we often encounter a key concept: In Python, object assignment is actually reference assignment, not a deep copy of the object itself. This means that when you put a custom object into a dictionary, the dictionary stores a reference to that object, rather than a brand new copy of the object.&lt;/p&gt;
&lt;h2 id=&#34;basic-example-of-storing-custom-objects&#34;&gt;Basic Example of Storing Custom Objects
&lt;/h2&gt;&lt;p&gt;Let&amp;rsquo;s assume we have a simple &lt;code&gt;Person&lt;/code&gt; class:
In this example, the &lt;code&gt;people_dict&lt;/code&gt; dictionary now contains an item with a key &lt;code&gt;&amp;quot;alice&amp;quot;&lt;/code&gt; whose value is a reference to a &lt;code&gt;Person&lt;/code&gt; type object named &lt;code&gt;p1&lt;/code&gt;. If we modify the attributes of &lt;code&gt;p1&lt;/code&gt;:
Then when accessing this object through the dictionary, we find that its age has also been updated:
This is because the dictionary does not store independent copies of the &lt;code&gt;Person&lt;/code&gt; objects, but rather references pointing to the same memory address.&lt;/p&gt;
&lt;h2 id=&#34;deep-copy-vs-shallow-copy&#34;&gt;Deep Copy vs. Shallow Copy
&lt;/h2&gt;&lt;p&gt;This referencing behavior can lead to unexpected results when dealing with nested data structures or custom objects. For example, if a custom object contains mutable attributes (such as lists or another custom object), directly storing such an object in a dictionary and modifying it will affect the object obtained through the dictionary.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solution: Deep Copy&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To avoid problems caused by shared state, sometimes we need to ensure that the dictionary stores a complete copy of the object, rather than a reference. Python provides the &lt;code&gt;copy&lt;/code&gt; module&amp;rsquo;s &lt;code&gt;deepcopy&lt;/code&gt; function to achieve this goal:&lt;/p&gt;
&lt;p&gt;In summary, when using dictionaries in Python to store custom objects, be sure to note that by default they store object references.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Why does a newly installed gigabit fiber to the home (FTTH) connection only test at 100 Mbps?</title>
        <link>https://ttf248.life/en/p/new-gigabit-fiber-slow-speed/</link>
        <pubDate>Mon, 18 Mar 2024 00:29:02 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/new-gigabit-fiber-slow-speed/</guid>
        <description>&lt;p&gt;Want your home network to be lightning fast? The key is understanding cable selection, optical terminals (ONTs), and router configuration, as well as those seemingly insignificant details. This blog post will guide you through easily learning how to build a gigabit network using six types of cables, and how to ensure your network speed isn&amp;rsquo;t restricted by simple device checks and configurations. Let’s explore together and make your home network fly!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/gigabit-fiber-slow-speed/image.png&#34;
	width=&#34;1001&#34;
	height=&#34;590&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Manual Repair&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;169&#34;
		data-flex-basis=&#34;407px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;chapter-1-an-in-depth-analysis-of-network-transmission-media&#34;&gt;Chapter 1: An In-Depth Analysis of Network Transmission Media
&lt;/h2&gt;&lt;p&gt;When discussing achieving gigabit network access, the carrier that supports high-speed information transmission – cables – plays a crucial role. Below we will provide detailed interpretations of Cat5, Cat6, and Cat7 cables.&lt;/p&gt;
&lt;h3 id=&#34;1-five-category-cables-cat5&#34;&gt;1. &lt;strong&gt;Five-Category Cables (CAT5)&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;CAT5 cables, also known as CAT5, are an earlier and more widely adopted type of twisted pair cable. Each pair of wire pairs is designed with a precise helical structure to reduce crosstalk. It’s primarily used for 10/100Mbps Fast Ethernet, with a maximum transmission frequency of approximately 100MHz. While it was once widely applied, CAT5 cables cannot meet current demands for gigabit and even higher speeds due to physical limitations.&lt;/p&gt;
&lt;h3 id=&#34;2-six-category-cables-cat6&#34;&gt;2. &lt;strong&gt;Six-Category Cables (CAT6)&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;With the development of technology, six-category cables have emerged. Compared to five-category cables, six-cable materials adopted stricter manufacturing standards and more advanced structural designs, significantly improving anti-interference capability and transmission efficiency, supporting data transfer rates up to 1Gbps, and with a transmission distance of up to 100 meters under ideal conditions, which perfectly meets the access requirements of Gigabit networks.&lt;/p&gt;
&lt;h3 id=&#34;3-seven-category-cables-cat7&#34;&gt;3. &lt;strong&gt;Seven-Category Cables (CAT7)&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;Seven-category cables represent the current cutting edge of twisted pair cabling technology. It not only offers a significant leap in transmission rates, theoretically supporting speeds up to 10Gbps, but also incorporates a complete shielding system, including shielding between each pair and overall external shielding, which greatly reduces external electromagnetic interference and near-end crosstalk, ensuring data transmission stability and accuracy. However, CAT7 cables are primarily used for future 10 Gigabit Ethernet or specific high-requirement scenarios.&lt;/p&gt;
&lt;p&gt;When setting up a gigabit home network environment, choosing six-category cables is the most economical and efficient choice to fully unleash the potential of the gigabit fiber optic.  Furthermore, ensuring that all connection cables meet quality standards and strictly adhering to standard wiring practices are also important aspects in guaranteeing network performance.&lt;/p&gt;
&lt;h2 id=&#34;chapter-two-deep-dive-into-core-network-devices--the-impact-of-optical-cat-光猫-and-router-lan-port-bandwidth&#34;&gt;Chapter Two: Deep Dive into Core Network Devices – The Impact of Optical Cat (光猫) and Router LAN Port Bandwidth
&lt;/h2&gt;&lt;h3 id=&#34;the-importance-of-optical-cat-ont-and-its-lan-port-bandwidth&#34;&gt;The Importance of Optical Cat (ONT) and its LAN Port Bandwidth
&lt;/h3&gt;&lt;p&gt;An Optical Cat, or Optical Network Terminal (ONT), is the core device for home broadband access. Its function is to convert optical signals from fiber optic cables into digital signals for use by home network devices. For users with gigabit fiber connections, whether the ONT supports gigabit transmission is particularly important. If the ONT’s WAN port only supports 100 Mbps, even if the incoming fiber rate is high, it will be limited to 100 Mbps due to this bottleneck. Similarly, the ONT&amp;rsquo;s LAN port also needs to have a gigabit output capability; otherwise, routers or other devices connected to it cannot obtain the true gigabit rate.&lt;/p&gt;
&lt;h3 id=&#34;the-role-of-bandwidth-on-router-lan-ports&#34;&gt;The Role of Bandwidth on Router LAN Ports
&lt;/h3&gt;&lt;p&gt;The router’s LAN ports are responsible for distributing the data received to various terminal devices. When a router&amp;rsquo;s LAN port is only 100 Mbps, even if other devices are configured well, it can only achieve 100 Mbps local network communication. Therefore, when building a Gigabit home network, it’s important to ensure that the router’s WAN port can receive 1 Gbps data and that the LAN ports also provide data output capabilities at the Gigabit level, so that all smart devices in your home can enjoy the smooth experience brought by high-speed networks.&lt;/p&gt;
&lt;p&gt;Furthermore, it&amp;rsquo;s worth noting that some older or low-end routers may have a LAN port automatic negotiation mechanism, which means that even if the router itself supports 1 Gbps, it may be downgraded to a 100 Mbps mode due to cable issues, device compatibility, and other reasons. Therefore, correctly configuring router parameters, enabling forced gigabit mode, and pairing it with a gigabit switch or direct device are key steps in achieving a full gigabit network. After upgrading to gigabit fiber, be sure to check and replace with gigabit optical switches and gigabit routers to ensure all device interfaces meet gigabit standards.&lt;/p&gt;
&lt;h2 id=&#34;chapter-three-the-hidden-mystery--how-a-broken-subline-impacts-gigabit-network-speed&#34;&gt;Chapter Three: The Hidden Mystery – How a Broken Subline Impacts Gigabit Network Speed
&lt;/h2&gt;&lt;h3 id=&#34;line-fault-and-network-performance-degradation&#34;&gt;Line Fault and Network Performance Degradation
&lt;/h3&gt;&lt;p&gt;During the speed tests, the network consistently maintained a connection without any apparent disconnects. As it was a newly deployed broadband for residential use, the distribution box was cluttered with equipment, and the technician frequently adjusted the optical transceiver and power outlet positions. This occasionally resulted in speed test results reaching gigabit speeds.&lt;/p&gt;
&lt;p&gt;Based on the previous information, we had already analyzed and troubleshooted network cable types and optical transceiver LAN port speeds. Ultimately, the culprit was discovered to be a broken brown sub-cable within the network cable itself.&lt;/p&gt;
&lt;p&gt;The cause of the break: When the technician installed the crystal head, he applied a little too much force, causing one of the sub-cables to break in half. It wasn&amp;rsquo;t completely severed, and subsequent adjustments to the optical transceiver position caused it to eventually break completely.&lt;/p&gt;
&lt;h3 id=&#34;six-category-cable-lines-function-analysis&#34;&gt;Six Category Cable Lines Function Analysis
&lt;/h3&gt;&lt;p&gt;Six category cables adhere to the TIA/EIA-568-B standard and contain eight twisted pairs of wires, color-coded as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;White Orange / Orange&lt;/li&gt;
&lt;li&gt;White Green / Green&lt;/li&gt;
&lt;li&gt;White Blue / Blue&lt;/li&gt;
&lt;li&gt;White Brown / Brown&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Under the Gigabit Ethernet (1000BASE-T) standard, these eight lines consist of four pairs working simultaneously, with the following division of labor:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The White Orange and Orange pair of wires (1&amp;amp;2) is used for transmitting data (Tx+/-);&lt;/li&gt;
&lt;li&gt;The White Green and Green pair of wires (3&amp;amp;6) is used for receiving data (Rx+/-);&lt;/li&gt;
&lt;li&gt;The White Blue and Blue pair of wires (4&amp;amp;5) and the White Brown and Brown pair of wires (7&amp;amp;8) were not originally primary in Gigabit Ethernet, but may be enabled in certain advanced applications (such as some PoE power delivery or future technology expansions). In traditional 100 Mbps networks, only four lines – 1, 2, 3, and 6 – could be used.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;impact-of-breakaway-pairs-on-network-speed&#34;&gt;Impact of Breakaway Pairs on Network Speed
&lt;/h3&gt;&lt;p&gt;In the above scenarios, if a brown sub-cable (i.e., brown or brown-white wire) breaks, theoretically it will cause speed degradation in gigabit networks, as gigabit networks require all four pairs of wires to transmit bidirectionally simultaneously to achieve full speed. However, due to home network devices often having auto-negotiation features, when a cable issue is detected, they will revert to a lower operating rate that functions normally, which is the megabit mode. This explains why even with a broken sub-cable, the network can remain connected and operate at megabit speeds.&lt;/p&gt;
&lt;p&gt;In short, while a broken brown sub-cable does not affect the basic operation of a megabit network, it can become a key limiting factor for network speed in gigabit environments. Until a thorough diagnosis and repair is conducted, the full potential of gigabit fiber cannot be truly realized. This also serves as a reminder that we should not overlook any potential network infrastructure issues when encountering similar situations – even seemingly minor connection glitches can become hidden obstacles to a high-speed networking experience.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>WPF UI Thread Blocking Issues and Solutions</title>
        <link>https://ttf248.life/en/p/wpf-ui-thread-and-freezing-issues-solutions/</link>
        <pubDate>Tue, 12 Mar 2024 07:12:21 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/wpf-ui-thread-and-freezing-issues-solutions/</guid>
        <description>&lt;p&gt;When developing desktop applications, particularly when using the Windows Presentation Foundation (WPF) framework to build rich client applications, properly handling the user interface (UI) thread is crucial for ensuring the application’s smoothness and responsiveness. The UI thread, also known as the main thread, is the core thread responsible for processing window and control events, layout calculations, and rendering the UI. Any interaction with UI elements should be executed on the UI thread; this is a fundamental principle followed by WPF and most other GUI frameworks.&lt;/p&gt;
&lt;h2 id=&#34;what-is-the-ui-thread&#34;&gt;What is the UI Thread?
&lt;/h2&gt;&lt;p&gt;The UI thread is created by the operating system when a WPF application starts and initializes the main application window. It’s the only thread within the application that can directly access and modify the state of UI components. This means all user interactions, such as button clicks, text box input, and window size changes, are processed in this thread context. Furthermore, WPF&amp;rsquo;s dependency property system, data binding mechanism, and layout logic are all synchronized on the UI thread.&lt;/p&gt;
&lt;h2 id=&#34;screen-freezing-phenomenon-and-its-causes&#34;&gt;Screen Freezing Phenomenon and Its Causes
&lt;/h2&gt;&lt;p&gt;When the UI thread is heavily occupied or blocked for an extended period, such as when performing time-consuming calculations, loading large amounts of data, database queries, or other I/O-intensive tasks, it becomes unable to promptly respond to user interaction requests. This results in the UI freezing – what we commonly refer to as “stuttering” or “freezing.” In this situation, users will noticeably feel the application’s lag and lack of smoothness, and in severe cases, an &amp;ldquo;Application Not Responding&amp;rdquo; (ANR) warning may appear.&lt;/p&gt;
&lt;h2 id=&#34;two-basic-rules-for-the-ui-thread&#34;&gt;Two Basic Rules for the UI Thread
&lt;/h2&gt;&lt;p&gt;To avoid the above scenarios, WPF developers should adhere to the following two key rules:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Do not perform time-consuming operations on the UI thread:&lt;/strong&gt; Any operation that could cause the UI thread to block should be moved to a background thread as much as possible to ensure the UI thread can promptly respond to user input and render screen changes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Do not directly update UI elements from non-UI threads:&lt;/strong&gt; Due to WPF’s security mechanism design, only the UI thread has permission to modify UI elements. Attempting to change UI state directly from another thread will throw an exception. Therefore, even if a background thread completes calculations or data preparation, you must use appropriate cross-thread communication mechanisms to display the results on the UI.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;solutions-asynchronous-programming-and-thread-safe-updates&#34;&gt;Solutions: Asynchronous Programming and Thread-Safe Updates
&lt;/h2&gt;&lt;p&gt;To execute time-consuming tasks while maintaining UI fluency, WPF provides various asynchronous programming models and tools to assist developers in achieving this goal:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Dispatcher Object:&lt;/strong&gt; The WPF Dispatcher class allows you to schedule work items into the UI thread&amp;rsquo;s task queue for execution. You can use the &lt;code&gt;Dispatcher.Invoke&lt;/code&gt; or &lt;code&gt;Dispatcher.BeginInvoke&lt;/code&gt; methods to safely update the UI from a background thread.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;async/await Keywords:&lt;/strong&gt; Leveraging C#’s asynchronous features, you can write asynchronous methods and utilize the &lt;code&gt;await&lt;/code&gt; keyword within them to wait for background tasks to complete, automatically returning to the UI thread to execute subsequent UI update code upon completion.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;case-studies&#34;&gt;Case Studies
&lt;/h2&gt;&lt;h3 id=&#34;use-the-dispatcherinvoke-method-to-update-ui&#34;&gt;Use the &lt;code&gt;Dispatcher.Invoke&lt;/code&gt; Method to Update UI
&lt;/h3&gt;&lt;h3 id=&#34;using-the-asyncawait-keyword-with-taskrun&#34;&gt;Using the &lt;code&gt;async/await&lt;/code&gt; keyword with &lt;code&gt;Task.Run&lt;/code&gt;
&lt;/h3&gt;</description>
        </item>
        <item>
        <title>Upgrading the GCC version caused program crashes: hidden issues due to code non-compliance.</title>
        <link>https://ttf248.life/en/p/upgrade-gcc-version-causes-program-crash-code-irregularities/</link>
        <pubDate>Sun, 10 Mar 2024 23:19:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/upgrade-gcc-version-causes-program-crash-code-irregularities/</guid>
        <description>&lt;p&gt;In the same business code scenario, the program compiled and ran normally in a CentOS 7 environment. However, when switching to CentOS 8 and using an updated version of GCC for compilation, the program crashed. It’s worth noting that the issue only occurs in &lt;strong&gt;Release mode&lt;/strong&gt;, while &lt;strong&gt;Debug mode&lt;/strong&gt; does not exhibit any problems. This is the first time we&amp;rsquo;ve encountered a situation like this; after three days of investigation, we finally identified the root cause.&lt;/p&gt;
&lt;h3 id=&#34;problem-identification&#34;&gt;Problem Identification
&lt;/h3&gt;&lt;p&gt;After investigation, the root cause of the issue was &lt;strong&gt;the function lacked a return value&lt;/strong&gt;. In Release mode, new versions of GCC perform more optimizations, which caused an unknown logic to occur within the function that originally did not have an explicit return value during execution, leading to a crash. Our conclusion is that &lt;strong&gt;compiler warnings should not be ignored, especially in legacy projects where some warnings may be dismissed, but it’s also important to avoid suppressing all warnings.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;environment-details&#34;&gt;Environment Details
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CentOS 7 GCC Version:&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CentOS 8 GCC Version:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;crash-phenomena&#34;&gt;Crash Phenomena
&lt;/h3&gt;&lt;p&gt;When analyzing the stack trace of a program crash, the following stack information was observed:
This stack doesn&amp;rsquo;t appear intuitive; the crash function’s stack information displays as a ‘??’, which makes troubleshooting the issue even more complex.&lt;/p&gt;
&lt;h3 id=&#34;code-example&#34;&gt;Code Example
&lt;/h3&gt;&lt;p&gt;To better understand the issue, here is a minimal code example that reproduces the crash:
The &lt;code&gt;test()&lt;/code&gt; function in this code clearly does not explicitly return a value, and its return type is &lt;code&gt;int&lt;/code&gt;. According to the C++ standard, when a function is declared as an &lt;code&gt;int&lt;/code&gt; type, it must have a return value, otherwise it may lead to undefined behavior.&lt;/p&gt;
&lt;h3 id=&#34;compilation-warnings&#34;&gt;Compilation Warnings
&lt;/h3&gt;&lt;p&gt;In our project, the CMake script suppresses many compiler warnings, including the following:&lt;/p&gt;
&lt;p&gt;This warning indicates that the &lt;code&gt;test()&lt;/code&gt; function does not return a value, which is the root cause of the problem. Newer versions of GCC (such as 8.5.0) may perform unstable optimizations on this undefined behavior when optimizing code, potentially leading to program crashes.&lt;/p&gt;
&lt;h3 id=&#34;assembly-code-differences&#34;&gt;Assembly Code Differences
&lt;/h3&gt;&lt;p&gt;To explain the differences in GCC compiler optimization behavior, we compared assembly code generated by different versions of GCC:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GCC 4.8.5 Generated Assembly Code:&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The assembly code is relatively verbose and includes logic for handling standard output streams (such as &lt;code&gt;std::cout&lt;/code&gt;). This indicates that the compiler performed more conservative optimizations, not optimizing excessively for the missing return value issue in the &lt;code&gt;test()&lt;/code&gt; function, possibly to avoid a crash.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GCC 8.5.0 Generated Assembly Code:&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The new version of GCC performed more optimizations, reducing the code volume. However, this optimization may have resulted in undefined behavior when executing a function without a return value, leading to program crashes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h3&gt;&lt;p&gt;Through this troubleshooting process, we deeply realized that in C++, &lt;strong&gt;function return values must be explicit&lt;/strong&gt;, especially when functions are declared as &lt;code&gt;int&lt;/code&gt;, a return value must be provided. When upgrading from older versions of compilers to newer GCC versions, more optimization and stricter warning mechanisms may arise. Therefore, we recommend not suppressing all warnings during compilation, but rather selectively addressing them, particularly common issues such as function return values and type matching.
Ultimately, by adding a return value to the &lt;code&gt;test()&lt;/code&gt; function, the problem was resolved, and the program returned to normal operation.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>VMware Virtual Machine CPU Resource Usage Anomaly</title>
        <link>https://ttf248.life/en/p/vmware-virtual-machine-cpu-resource-usage-anomaly/</link>
        <pubDate>Sun, 10 Mar 2024 22:14:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/vmware-virtual-machine-cpu-resource-usage-anomaly/</guid>
        <description>&lt;p&gt;Background: The business system, running in Windows version, is deployed locally and consumes approximately 5% of CPU resources. The Linux version of the business system, deployed within a VMware-installed CentOS8 environment, exhibits abnormal resource consumption.&lt;/p&gt;
&lt;h2 id=&#34;problem-description&#34;&gt;Problem Description
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Host Machine: Windows 10 Enterprise&lt;/li&gt;
&lt;li&gt;VMware: 17.5&lt;/li&gt;
&lt;li&gt;Virtual Machine: CentOS8
The virtual machine resource allocation is &lt;code&gt;4C8GB&lt;/code&gt;, running the business system. The business system is deployed in the Linux system within the virtual machine, and the internal top command observes system resource usage. CPU utilization is not high, while the external Windows system&amp;rsquo;s Task Manager shows very high CPU resource consumption. Examining processes reveals that the VMware process consumes a large amount of CPU resources.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+
|         Windows           |
|                           |
|   +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+  |
|   |      VMware        |  |
|   |      Program       |  |
|   +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+  |
|                           |
+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&lt;/p&gt;
&lt;h2 id=&#34;key-concepts&#34;&gt;Key Concepts
&lt;/h2&gt;&lt;p&gt;Troubleshooting this issue wasn’t smooth, as the root cause wasn&amp;rsquo;t the business system itself but rather issues with the virtual machine. How to shift thinking from conventional business code to system load, then from abnormal load data to pinpoint a soft interrupt, and finally arrive at the critical point – what factors affect VMware soft interrupt efficiency? This article will first introduce various concepts and then provide solutions.&lt;/p&gt;
&lt;h3 id=&#34;hyper-v&#34;&gt;Hyper-V
&lt;/h3&gt;&lt;p&gt;The virtualization technology for Windows operating systems underwent a significant transformation. When Microsoft initially released WSL, enabling the Hyper-V service would prevent VMware virtual machines from working simultaneously. It wasn&amp;rsquo;t until subsequent versions that VMware could be compatible with the Hyper-V service.&lt;/p&gt;
&lt;h3 id=&#34;system-load&#34;&gt;System Load
&lt;/h3&gt;&lt;p&gt;In Linux systems, &amp;ldquo;load&amp;rdquo; refers to the number of processes that are currently running or waiting to be executed. The load is typically represented by three numbers, which represent the average number of processes in the run queue over 1 minute, 5 minutes, and 15 minutes, respectively. These numbers can be viewed by running the &lt;code&gt;uptime&lt;/code&gt; command or the &lt;code&gt;top&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;Specifically, these three numbers represent:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;1-minute load:&lt;/strong&gt; The average number of processes in the run queue over the past 1 minute.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;5-minute load:&lt;/strong&gt; The average number of processes in the run queue over the past 5 minutes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;15-minute load:&lt;/strong&gt; The average number of processes in the run queue over the past 15 minutes.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The meaning of the load is the number of processes waiting to be executed within the system. - If this number exceeds the logical CPU count of the system, it indicates a high system load, meaning many processes are waiting for processor resources. This can lead to sluggish performance or unresponsiveness, depending on the severity of the load and the configuration and performance of the system.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ideally, the load should remain within the logical CPU count range to optimize system performance. If the load consistently exceeds the CPU count, further analysis of processes within the system may be necessary to identify the cause of the high load and take appropriate measures to adjust resource allocation or optimize process execution.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;analyzing-load---mpstat&#34;&gt;Analyzing Load - mpstat
&lt;/h3&gt;&lt;p&gt;The &lt;code&gt;mpstat&lt;/code&gt; command is used to report multiple statistics for a single or multiple processors, including average load, CPU utilization, interrupts, and context switches. Within the &lt;code&gt;sysstat&lt;/code&gt; package, &lt;code&gt;mpstat&lt;/code&gt; is a valuable tool for analyzing system load conditions.  Below are the steps involved in performing load analysis using &lt;code&gt;mpstat&lt;/code&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Install sysstat:&lt;/strong&gt;
If &lt;code&gt;sysstat&lt;/code&gt; is not already installed on your system, use your system&amp;rsquo;s package manager to install it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Run mpstat:&lt;/strong&gt;
Use the &lt;code&gt;mpstat&lt;/code&gt; command to view CPU usage and load. By default, &lt;code&gt;mpstat&lt;/code&gt; displays CPU utilization averages once per second. You can adjust the output frequency by specifying an interval. - For example, to run &lt;code&gt;mpstat&lt;/code&gt; at a rate of one frequency per second, you can use the following command: &lt;code&gt;mpstat -P ALL 2&lt;/code&gt;, where &lt;code&gt;irq&lt;/code&gt; represents resource utilization.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Analyze Output&lt;/strong&gt;:
The output of &lt;code&gt;mpstat&lt;/code&gt; includes CPU utilization for each CPU, as well as the system&amp;rsquo;s average load. Pay particular attention to the average load and the utilization of each CPU to understand the system’s workload. If the load is high, you can further analyze which processes are causing it, and whether there are any performance bottlenecks.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;analyze-load---mpstat&#34;&gt;Analyze Load - mpstat
&lt;/h3&gt;&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;Combine with Other Tools&lt;/strong&gt;:
In addition to &lt;code&gt;mpstat&lt;/code&gt;, you can also use tools like &lt;code&gt;sar&lt;/code&gt;, &lt;code&gt;pidstat&lt;/code&gt;, and &lt;code&gt;iostat&lt;/code&gt; to comprehensively analyze system performance. By combining the outputs of multiple tools, you can gain a more complete understanding of the system&amp;rsquo;s load situation and identify the root causes of performance issues.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;interrupt&#34;&gt;Interrupt
&lt;/h3&gt;&lt;p&gt;This section doesn&amp;rsquo;t elaborate on the content too much,
Recommended: &lt;a class=&#34;link&#34; href=&#34;https://www.codedump.info/post/20200522-sgfap-softirq/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;System Guide for Application Developers - CPU Part - Soft Interrupt&lt;/a&gt;
Frequent triggering of soft interrupts will also be reflected in system load.&lt;/p&gt;
&lt;h2 id=&#34;troubleshooting&#34;&gt;Troubleshooting
&lt;/h2&gt;&lt;p&gt;Considering that analysis solely from the CPU perspective couldn’t pinpoint the issue, should we start to suspect that the system had become abnormal? It might be due to high load on the Linux operating system, causing VMware to consume excessive CPU resources. By using &lt;code&gt;mpstat&lt;/code&gt; to analyze local virtual machines, we found that &lt;code&gt;irq&lt;/code&gt; utilization was abnormally high, approaching 25% per core, while in normal circumstances, when business processes were idle, &lt;code&gt;irq&lt;/code&gt; should have been around 5%.&lt;/p&gt;
&lt;p&gt;In a colleague’s development environment within the group, his CentOS 7 deployment on VMware showed normal resource usage. Conversely, in the Shanghai development environment, although also running on VMware, we couldn&amp;rsquo;t directly observe the host machine’s CPU resource situation. At this point, we faced multiple variables: the VMware virtual machines, the Linux operating system, and the GCC version. - Analyzing the test environment, the Shenzhen test environment is deployed on physical machines running low versions of GCC compiled services. It’s also running on CentOS 8. Interestingly, &lt;code&gt;irq&lt;/code&gt; usage remained normal within the Shenzhen environment.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;To investigate potential issues introduced by the GCC version, we deployed programs compiled with a higher version of GCC to the Shenzhen environment for testing, which also yielded no problems.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The issue seemed to become clearer as we began to suspect that there might be an operating system problem. After all, CentOS 8 is no longer officially supported. Even after redeploying clean CentOS 7 and CentOS 8 instances, the problem persisted.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;troubleshooting-1&#34;&gt;Troubleshooting
&lt;/h2&gt;&lt;p&gt;At this point, we began to suspect the only unknown factor – VMware virtual machine software. Suddenly, a flash of insight occurred; we thought of Hyper-V technology. Could Hyper-V have been enabled previously but not completely disabled, causing this issue? After all, soft interrupts are also implemented through virtualization software. Do different virtualization technologies have bugs? These questions deserve in-depth consideration and investigation.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h2&gt;&lt;p&gt;Following Microsoft’s official documentation, after completely disabling the Hyper-V service on the machine, VMware recovered normal operation on the host. This finally resolved the issue. As initially stated, this experience was convoluted and arduous, requiring comprehensive analysis and judgment. It was also our first time troubleshooting and pinpointing the problem to the virtual machine level.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/troubleshoot/windows-client/application-management/virtualization-apps-not-work-with-hyper-v&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://learn.microsoft.com/zh-cn/troubleshoot/windows-client/application-management/virtualization-apps-not-work-with-hyper-v&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>C&#43;&#43; Programming Traps: A Detailed Explanation of Program Crashes Caused by Improper Use of `std::map`</title>
        <link>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</link>
        <pubDate>Sun, 10 Mar 2024 22:03:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</guid>
        <description>e&gt;
&lt;h2 id=&#34;body&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;In the C++ standard library, &lt;code&gt;std::map&lt;/code&gt; is an associative container that stores elements in ascending order based on their keys (key), and provides efficient keyword lookup functionality. However, novice developers sometimes find themselves in trouble due to a misunderstanding of the behavior of the square bracket operator &lt;code&gt;[]&lt;/code&gt; within &lt;code&gt;std::map&lt;/code&gt;. In fact, when using &lt;code&gt;[]&lt;/code&gt; to access a non-existent key, &lt;code&gt;std::map&lt;/code&gt; inserts a new key-value pair, and the default constructor will be used to initialize the value type associated with that key.&lt;/p&gt;
&lt;p&gt;Although this code does not directly cause the program to crash, this implicit insertion behavior can lead to unexpected side effects in certain situations, such as resource leaks or changes inconsistent with expectations. Worse still, concurrent access to uninitialized memory regions in a multithreaded environment can even cause the program to crash. To prevent such issues, it is recommended to use the &lt;code&gt;std::map::find()&lt;/code&gt; or &lt;code&gt;std::map::count()&lt;/code&gt; methods to check if a key exists, or to explicitly insert elements using the &lt;code&gt;std::map::insert()&lt;/code&gt; method.&lt;/p&gt;
&lt;p&gt;If the map container internally stores objects of pointer types, the automatic insertion behavior will save an uninitialized pointer, and any call to this pointer will cause the program to crash.&lt;/p&gt;</description>
        </item>
        <item>
        <title>pstack troubleshoot a hung process</title>
        <link>https://ttf248.life/en/p/pstack-troubleshooting-process-hang/</link>
        <pubDate>Sat, 24 Feb 2024 23:55:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/pstack-troubleshooting-process-hang/</guid>
        <description>&lt;p&gt;In software development and operations, deadlocked processes are frequently encountered. This situation can lead to performance degradation or service unavailability. This article introduces how to use the pstack tool to troubleshoot deadlocked process issues by analyzing process stack information to identify the root cause and resolve it.&lt;/p&gt;
&lt;p&gt;Background: A child service within the risk control system experienced a deadlocked state, resulting in the unavailability of the risk control service. Due to the lack of service availability monitoring, the deadlocked process situation was not detected in a timely manner, leading to system unavailability.&lt;/p&gt;
&lt;h2 id=&#34;text&#34;&gt;Text
&lt;/h2&gt;&lt;p&gt;A hung process refers to a process that has stopped responding but hasn&amp;rsquo;t exited. This situation can be caused by various reasons, such as deadlocks, resource exhaustion, or exceptions. To resolve these issues, we can use the &lt;code&gt;pstack&lt;/code&gt; tool to analyze the process’s stack information and identify the root cause.&lt;/p&gt;
&lt;h2 id=&#34;steps&#34;&gt;Steps
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;pstack&lt;/code&gt; is a commonly used tool, often provided alongside &lt;code&gt;gdb&lt;/code&gt; (GNU Debugger). You can install it using the following commands:&lt;/p&gt;
&lt;p&gt;Obtain Process ID: First, we need to obtain the process ID (PID) of the zombie process. We can use the &lt;code&gt;ps&lt;/code&gt; command to list all processes and find the process ID that needs to be investigated.&lt;/p&gt;
&lt;p&gt;Use the &lt;code&gt;pstack&lt;/code&gt; tool to analyze the process stack. Once you have obtained the process ID, you can use the &lt;code&gt;pstack&lt;/code&gt; tool to retrieve the stack information for that process. Run the following command:&lt;/p&gt;
&lt;p&gt;This will output the stack information for the process, displaying the sequence of function calls currently being executed. By analyzing this information, you can identify where the process is stuck and thus pinpoint the problem.&lt;/p&gt;
&lt;p&gt;Analyze Stack Information: By viewing the stack information, you can find the cause of the process becoming a zombie. You may discover deadlock situations, infinite loops, or other abnormal conditions.&lt;/p&gt;
&lt;h2 id=&#34;case-study&#34;&gt;Case Study
&lt;/h2&gt;&lt;p&gt;Simple demo: after the main function starts, a child thread is created and the actual function enters a dead loop, causing the program to fail to terminate normally and enter a state of false death.&lt;/p&gt;
&lt;p&gt;Running the program and executing the pstack results shows:
You can see that the reason for the process being in a false death state is due to the dead loop; the main thread enters the dead loop, the child thread cannot exit, leading to the process being in a false death state.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>C&#43;&#43; Function Call Latency</title>
        <link>https://ttf248.life/en/p/cpp-function-call-timing/</link>
        <pubDate>Wed, 24 Jan 2024 14:11:33 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-function-call-timing/</guid>
        <description>&lt;p&gt;Designed a行情 SDK, implementing different callback function implementations, and performed an extensive test. Recently I&amp;rsquo;ve been looking into C++ function programming, where functions have become first-class citizens, flowing within the program internally – what’s the difference in performance?&lt;/p&gt;
&lt;p&gt;Previous article link: &lt;a class=&#34;link&#34; href=&#34;https://ttf248.life/en/p/compiler-callback-function-performance-testing/&#34; &gt;Compiler, Callback Functions, Performance Testing&lt;/a&gt;
&lt;code&gt;leimao&lt;/code&gt;大佬 also did similar tests, so I borrowed their code.&lt;/p&gt;
&lt;h2 id=&#34;main-content&#34;&gt;Main Content
&lt;/h2&gt;&lt;p&gt;The execution platform remains our old friend, &lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leimao.github.io/blog/CPP-Function-Call-Performance/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://leimao.github.io/blog/CPP-Function-Call-Performance/&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>How to Anti-Debug</title>
        <link>https://ttf248.life/en/p/program-how-to-anti-debug/</link>
        <pubDate>Tue, 23 Jan 2024 19:46:36 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/program-how-to-anti-debug/</guid>
        <description>&lt;p&gt;A sudden urge to browse for new wallpapers, sticking with the familiar black series, with some areas colored and the rest remaining black. The desktop needs to display icons, but other color schemes result in them appearing blurry.&lt;/p&gt;
&lt;p&gt;I stared at the assembly code, trying to figure it out, but couldn&amp;rsquo;t understand it. I tried throwing it to an &lt;code&gt;AI&lt;/code&gt;, explaining the instructions, but it failed to explain the context – clearly, this was a command used for a specific scenario. Regular code isn’t like that.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;AI&lt;/code&gt; was no match for a search engine at this point; its knowledge base of assembly language was insufficient.&lt;/p&gt;
&lt;h2 id=&#34;wallpaper&#34;&gt;Wallpaper
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/program-anti-debug/Snipaste_2024-01-23_19-50-53.png&#34;
	width=&#34;1020&#34;
	height=&#34;470&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Black Assembly Wallpaper&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;217&#34;
		data-flex-basis=&#34;520px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;assembly-code&#34;&gt;Assembly Code
&lt;/h2&gt;&lt;p&gt;Practical Applications&lt;/p&gt;
&lt;h2 id=&#34;explanation&#34;&gt;Explanation
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;TrapFlag&lt;/code&gt; is a flag bit in the register file that, when set, triggers an exception &lt;code&gt;SINGLE_STEP&lt;/code&gt;. Because if we trace the code, this flag will be cleared by the debugger, and we won&amp;rsquo;t see the exception.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In actual testing, if you directly step over detecting functions, debugging will not be detected. Only when entering the detection function to execute will it be detected (based on research materials, but yet to be verified in practice).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;Chinese related materials are based on the English articles from the website, which introduce many anti-debugging techniques.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://anti-debug.checkpoint.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://anti-debug.checkpoint.com/&lt;/a&gt; techniques/assembly.html&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://song-10.gitee.io/2021/08/08/Reverse-2021-08-08-anti-debug/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://song-10.gitee.io/2021/08/08/Reverse-2021-08-08-anti-debug/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>How to Download Focus News/CCTV Video Files</title>
        <link>https://ttf248.life/en/p/how-to-download-focus-interview-cctv-video-files/</link>
        <pubDate>Tue, 23 Jan 2024 19:23:35 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/how-to-download-focus-interview-cctv-video-files/</guid>
        <description>&lt;p&gt;Recently, someone asked how to download Focus Interview videos. My mind immediately went to the usual – eight or nine out of ten times it’s encrypted using an &lt;code&gt;m3u8&lt;/code&gt; method, and a bit of simple processing is all it takes.&lt;/p&gt;
&lt;h2 id=&#34;downloader&#34;&gt;Downloader
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/nilaoda/N_m3u8DL-CLI&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/nilaoda/N_m3u8DL-CLI&lt;/a&gt;
&lt;code&gt;m3u8 downloader&lt;/code&gt; is an open-source command-line m3u8/HLS/dash downloader that supports ordinary AES-128-CBC decryption, multi-threading, custom request headers, etc. Supports Simplified Chinese, Traditional Chinese and English. English Supported.&lt;/p&gt;
&lt;h2 id=&#34;browser-extensions&#34;&gt;Browser Extensions
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://microsoftedge.microsoft.com/addons/detail/ngjclnbcdbahekojpkhancmiobdahemb&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Live Stream Downloader&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;honeyed-confidence&#34;&gt;Honeyed Confidence
&lt;/h2&gt;&lt;p&gt;Getting the address, assuming it was solved, turned out to be nothing – unable to parse segments normally, query information, and discovered that the official party had processed the download address, requiring manual replacement of the &lt;code&gt;key&lt;/code&gt; parsed by the plugin into the following links.&lt;/p&gt;
&lt;p&gt;As of January 2024, the address is still valid for testing; if there are any changes in the future, analyze the webpage independently.
Historical Address Backup: &lt;code&gt;https://hlswx.cntv.kcdnvip.com/asp/hls/main/0303000a/3/default/一串字符/main.m3u8?maxbr=2000&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://jln.cn/post/517.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://jln.cn/post/517.html&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Bulk Modify SQL Server Database Disk File Permissions</title>
        <link>https://ttf248.life/en/p/bulk-modify-sqlserver-database-disk-file-permissions/</link>
        <pubDate>Tue, 23 Jan 2024 19:06:36 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/bulk-modify-sqlserver-database-disk-file-permissions/</guid>
        <description>&lt;p&gt;The company adjusted its security policies. Ultimately, ‘Mechanical Mini’ was relocated back home as a backup server, along with a full system reinstallation. Ubuntu switched to Windows Server; due to an irregular activation method – used at home – it seemed like it wouldn&amp;rsquo;t be activated, and that was fine. An unconventional activation triggered Microsoft’s detection (running normally for half a month), the server would automatically shut down after running for one hour. After reviewing the system logs, it was discovered that this was due to using a pirated version.&lt;/p&gt;
&lt;p&gt;There wasn’t much else to do, so the system was reinstalled again, and SQL Server also needed to be reinstalled – it&amp;rsquo;s always a bit frustrating. File permission management is strict, making it impossible to attach databases normally.&lt;/p&gt;
&lt;h2 id=&#34;error-message&#34;&gt;Error Message
&lt;/h2&gt;&lt;p&gt;After the system reinstallation, &lt;code&gt;SqlServer&lt;/code&gt; may encounter error 5120, an operating system access denied error, when attaching a database.&lt;/p&gt;
&lt;h2 id=&#34;processing-script&#34;&gt;Processing Script
&lt;/h2&gt;&lt;p&gt;Previous link: &lt;a class=&#34;link&#34; href=&#34;https://ttf248.life/en/p/bulk-update-local-git-repository-and-legacy-permission-issues/&#34; &gt;Batch Update Local Git Repository&lt;/a&gt;, it’s that familiar script all over again – let&amp;rsquo;s modify it to iterate through folders while also changing file permissions, currently using full editing privileges.
Most online tutorials instruct you to manually modify files; they only need to change a few files each time? I have batches of files to process, and manually handling them would drive me crazy.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Linux System Benchmark Test</title>
        <link>https://ttf248.life/en/p/linux-system-benchmark-test/</link>
        <pubDate>Tue, 09 Jan 2024 10:56:23 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-system-benchmark-test/</guid>
        <description>&lt;p&gt;Windows platform has RuMaster (Entertainment Master), which isn’t known for highly accurate data, but it still provides some reference. Of course, there are other professional benchmarking software options as well. When it comes to Linux systems, there hasn&amp;rsquo;t seemed to be a particularly suitable benchmarking software available.&lt;/p&gt;
&lt;p&gt;Sysbench is a versatile benchmark testing tool that can be used to test CPU, memory, file I/O, thread performance, and more. You can use Sysbench to execute various performance testing tasks.&lt;/p&gt;
&lt;p&gt;I currently have three machines available for testing: the Mechanical Artist mini laptop, a local small host machine, an Alibaba Cloud Dev development cloud server, and a Huawei Cloud Dev server.&lt;/p&gt;
&lt;h2 id=&#34;installing-sysbench&#34;&gt;Installing Sysbench
&lt;/h2&gt;&lt;p&gt;On most Linux distributions, you can install Sysbench using a package manager. For example, on CentOS 8, you can use the following command to install it&lt;/p&gt;
&lt;h2 id=&#34;sysbench-usage-examples&#34;&gt;Sysbench Usage Examples
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Testing CPU performance: &lt;code&gt;sysbench --test=cpu run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Testing memory read performance: &lt;code&gt;sysbench --test=memory run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Testing file I/O performance:&lt;/li&gt;
&lt;li&gt;Testing multi-threaded performance: &lt;code&gt;sysbench --test=threads --num-threads=4 run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Testing MySQL database performance (adjust maximum connections as needed):&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;score-report&#34;&gt;Score Report
&lt;/h2&gt;&lt;meta http-equiv=&#34;Content-Type&#34; content=&#34;text/html; charset=utf-8&#34;&gt;&lt;link type=&#34;text/css&#34; rel=&#34;stylesheet&#34; href=&#34;resources/sheet.css&#34; &gt;
&lt;h2 id=&#34;score-report-1&#34;&gt;Score Report
&lt;/h2&gt;&lt;style type=&#34;text/css&#34;&gt;.ritz .waffle a { color: inherit; }.ritz .waffle .s0{background-color:#ffffff;text-align:left;color:#000000;font-family:&#39;Arial&#39;;font-size:10pt;vertical-align:bottom;white-space:nowrap;direction:ltr;padding:2px 3px 2px 3px;}&lt;/style&gt;&lt;div class=&#34;ritz grid-container&#34; dir=&#34;ltr&#34;&gt;&lt;table class=&#34;waffle&#34; cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th class=&#34;row-header freezebar-origin-ltr&#34;&gt;&lt;/th&gt;&lt;th id=&#34;0C0&#34; style=&#34;width:100px;&#34; class=&#34;column-headers-background&#34;&gt;A&lt;/th&gt;&lt;th id=&#34;0C1&#34;
&lt;h2 id=&#34;score-report-2&#34;&gt;Score Report
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Column A (id=&amp;ldquo;0C0&amp;rdquo; style=&amp;ldquo;width:100px;&amp;rdquo; class=&amp;ldquo;column-headers-background&amp;rdquo;)&lt;/th&gt;
&lt;th&gt;Column B (id=&amp;ldquo;0C1&amp;rdquo; style=&amp;ldquo;width:421px;&amp;rdquo; class=&amp;ldquo;column-headers-background&amp;rdquo;)&lt;/th&gt;
&lt;th&gt;Column C (id=&amp;ldquo;0C2&amp;rdquo; style=&amp;ldquo;width:398px;&amp;rdquo; class=&amp;ldquo;column-headers-background&amp;rdquo;)&lt;/th&gt;
&lt;th&gt;Column D (id=&amp;ldquo;0C3&amp;rdquo; style=&amp;ldquo;width:422px;&amp;rdquo; class=&amp;ldquo;column-headers-background&amp;rdquo;)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Row 1 (style=&amp;ldquo;height: 20px&amp;rdquo;&amp;gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;1&lt;/div&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;score-report-3&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;class=&amp;ldquo;row-header-wrapper&amp;rdquo; style=&amp;ldquo;line-height: 20px&amp;rdquo;&amp;gt;1&lt;/div&gt;&lt;/th&gt;&lt;td&gt;&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Local Technician&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Alibaba Cloud&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Huawei Cloud&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R1&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;2&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Configuration&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Information&lt;br&gt;  Operating System              Ubuntu 23.04&lt;br&gt;  Kernel                        Linux&lt;/p&gt;
&lt;h2 id=&#34;score-report-4&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;Information
Operating System              Ubuntu 23.04
Kernel                        Linux 6.2.0-36-generic x86_64
Model                         Machenike Machenike DT Computer
Motherboard                   Machenike Machenike DT Computer
BIOS                          American Megatrends International, LLC.
DB19V012&lt;/p&gt;
&lt;p&gt;CPU Information
Name                          Intel Core i7-12650H
Topology                      1 Processor, 10 Cores, 16 Threads
Identifier&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;i7-12650H
Topology: 1 Processor, 10 Cores, 16 Threads
Identifier: GenuineIntel Family 6 Model 154 Stepping 3
Base Frequency: 4.60 GHz
L1 Instruction Cache: 32.0 KB x 8
L1 Data Cache: 48.0 KB x 8
L2 Cache: 1.25 MB x 2
L3 Cache: 24.0 MB&lt;/p&gt;
&lt;p&gt;Memory Information:
Size: 62.6 GB&lt;/p&gt;
&lt;h2 id=&#34;score-report-5&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;Size                          62.6 GB&lt;/p&gt;
&lt;p&gt;System Information
Operating System              CentOS Stream 8
Kernel                        Linux 4.18.0-513.el8.x86_64 x86_64
Model                         Alibaba Cloud Alibaba Cloud ECS
Motherboard                   N/A
BIOS                          SeaBIOS 449e491&lt;/p&gt;
&lt;p&gt;CPU Information
Name                          Intel(R) Xeon(R) Platinum
Topology                      1 Processor, 1 Core, 2&lt;/p&gt;
&lt;h2 id=&#34;score-report-6&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;Intel(R) Xeon(R) Platinum&lt;br&gt; Topology: 1 Processor, 1 Core, 2 Threads&lt;br&gt; Identifier: GenuineIntel Family 6 Model 85 Stepping 4&lt;br&gt; Base Frequency: 2.50 GHz&lt;br&gt; L1 Instruction Cache: 32.0 KB&lt;br&gt; L1 Data Cache: 32.0 KB&lt;br&gt; L2 Cache: 1.00 MB&lt;br&gt; L3 Cache: 33.0 MB&lt;br&gt;&lt;br&gt;Memory Information&lt;br&gt; Size: 1.65 GB&lt;/p&gt;
&lt;h2 id=&#34;score-report-data&#34;&gt;Score Report Data
&lt;/h2&gt;&lt;p&gt;Information
Size 1.65 GB&lt;/p&gt;
&lt;p&gt;System Information
Operating System Ubuntu 22.04.1 LTS
Kernel Linux 5.15.0-60-generic x86_64
Model OpenStack Foundation OpenStack Nova
Motherboard N/A
BIOS SeaBIOS
rel-1.10.2-0-g5f4c7b1-20181220_000000-szxrtosci10000&lt;/p&gt;
&lt;p&gt;CPU Information
Name Intel(R) Xeon(R) Gold&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-1&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;Information:
Name                          Intel(R) Xeon(R) Gold 6278C CPU @ 2.60GHz
Topology                      1 Processor, 1 Core, 2 Threads
Identifier                    GenuineIntel Family 6 Model 85 Stepping 7
Base Frequency                2.60 GHz
L1 Instruction Cache          32.0 KB
L1 Data Cache                 32.0 KB
L2 Cache                      1.00 MB
L3 Cache                      35.8 MB&lt;/p&gt;
&lt;p&gt;Memory Information:
Size&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-2&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;L3 Cache                      35.8 MB&lt;br&gt;&lt;br&gt;Memory Information&lt;br&gt;  Size                          3.64 GB&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R2&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;3&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;CPU&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current&lt;/p&gt;
&lt;h2 id=&#34;score-report-7&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;with following options:
Number of threads: 1
Initializing random number generator from current time&lt;/p&gt;
&lt;p&gt;Prime numbers limit: 10000&lt;/p&gt;
&lt;p&gt;Initializing worker threads&amp;hellip;
Threads started!&lt;/p&gt;
&lt;p&gt;CPU speed:
events per second:  4032.48&lt;/p&gt;
&lt;p&gt;General statistics:
total time:                          10.0004s
total number of events:              40330&lt;/p&gt;
&lt;p&gt;Latency (ms):
min:                                    0.25
avg:&lt;/p&gt;
&lt;h2 id=&#34;score-report-8&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;min:                                    0.25&lt;br&gt;         avg:                                    0.25&lt;br&gt;         max:                                    0.73&lt;br&gt;         95th percentile:                        0.25&lt;br&gt;         sum:                                 9997.55&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           40330.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9975/0.00&lt;/p&gt;
&lt;p&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-3&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;class=&amp;ldquo;s0&amp;rdquo; dir=&amp;ldquo;ltr&amp;rdquo;&amp;gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  1062.51&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0008s&lt;br&gt;    total number of events:              10628&lt;br&gt;&lt;br&gt;Latency (ms):&lt;/p&gt;
&lt;h2 id=&#34;score-report-9&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;10.0008s &lt;br&gt; total number of events: 10628 &lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt; min: 0.91 &lt;br&gt; avg: 0.94 &lt;br&gt; max: 22.84 &lt;br&gt; 95th percentile: 1.06 &lt;br&gt; sum: 9993.46 &lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt; events (avg/stddev): 10628.0000/0.00 &lt;br&gt; execution time (avg/stddev):&lt;/p&gt;
&lt;h2 id=&#34;score-report-10&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;events (avg/stddev):           10628.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9935/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  1125.56&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:&lt;/p&gt;
&lt;h2 id=&#34;score-report-11&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;speed:
events per second: 1125.56&lt;/p&gt;
&lt;p&gt;General statistics:
total time: 10.0005s
total number of events: 11258&lt;/p&gt;
&lt;p&gt;Latency (ms):
min: 0.86
avg: 0.89
max: 1.70
95th percentile: 0.99
sum: 9995.40&lt;/p&gt;
&lt;p&gt;Threads fairness:&lt;/p&gt;
&lt;h2 id=&#34;score-report-12&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;0.99 &lt;br&gt;         sum:                                 9995.40 &lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           11258.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9954/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R3&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;4&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Memory&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random&lt;/p&gt;
&lt;h2 id=&#34;run-test-report&#34;&gt;Run Test Report
&lt;/h2&gt;&lt;p&gt;dir=&amp;ldquo;ltr&amp;rdquo;&amp;gt;Running the test with the following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 101993199 (10198146.52 per second)&lt;br&gt;&lt;br&gt;99602.73 MiB transferred (9959.13 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:&lt;/p&gt;
&lt;h2 id=&#34;score-report-13&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;MiB transferred (9959.13 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              101993199&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                    0.03&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4059.50&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;score-report-14&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;0.00
sum:                                 4059.50
Threads fairness:&lt;br&gt;    events (avg/stddev):           101993199.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.0595/0.00&lt;/p&gt;
&lt;p&gt;Running the test with following options:
Number of threads: 1
Initializing random number generator from current time&lt;/p&gt;
&lt;p&gt;Running memory speed test with the following options:
block size: 1KiB
total size: 102400MiB
operation: write
scope:&lt;/p&gt;
&lt;h2 id=&#34;score-report-15&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 48418803 (4841.00 per second)&lt;br&gt;&lt;br&gt;47283.99 MiB transferred (4727.54 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              48418803&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:&lt;/p&gt;
&lt;h2 id=&#34;score-report-16&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;(ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                   25.26&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4578.95&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           48418803.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.5789/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of&lt;/p&gt;
&lt;h2 id=&#34;score-report-17&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;4.5789/0.00 &lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with the following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 57056904 (5704765.11 per second)&lt;br&gt;&lt;br&gt;55719.63 MiB transferred (5571.06 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General&lt;/p&gt;
&lt;h2 id=&#34;scoring-data-report&#34;&gt;Scoring Data Report
&lt;/h2&gt;&lt;p&gt;(5704765.11 per second)&lt;/p&gt;
&lt;p&gt;55719.63 MiB transferred (5571.06 MiB/sec)&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;General statistics:
total time:                          10.0001s
total number of events:              57056904&lt;/p&gt;
&lt;p&gt;Latency (ms):
min:                                    0.00
avg:                                    0.00
max:                                    0.06
95th percentile:                        0.00
sum:&lt;/p&gt;
&lt;h2 id=&#34;score-report-18&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;95th percentile:                        0.00&lt;br&gt;         sum:                                 4556.06&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           57056904.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.5561/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R4&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;5&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Disk&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 1.81 seconds&lt;/p&gt;
&lt;h2 id=&#34;score-report-19&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;class=&amp;ldquo;s0&amp;rdquo; dir=&amp;ldquo;ltr&amp;rdquo;&amp;gt;Hard Drive&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 1.81 seconds (1129.59 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with the following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-4&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      3373.41&lt;br&gt;    writes/s:                     2248.94&lt;br&gt;    fsyncs/s:                     7201.80&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  52.71&lt;br&gt;    written, MiB/s:&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-5&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;read, MiB/s:                  52.71&lt;br&gt;    written, MiB/s:               35.14&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0127s&lt;br&gt;    total number of events:              128288&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.08&lt;br&gt;         max:                                    5.14&lt;br&gt;         95th percentile:                        0.34&lt;br&gt;         sum:&lt;/p&gt;
&lt;h2 id=&#34;score-report-20&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;95th percentile: 0.34&lt;br&gt;         sum: 9977.78&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev): 128288.0000/0.00&lt;br&gt;    execution time (avg/stddev): 9.9778/0.00&lt;br&gt;&lt;br&gt;2147483648 bytes written in 19.29 seconds (106.16 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files,&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-6&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;Random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:&lt;/p&gt;
&lt;h2 id=&#34;score-report-21&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      1593.12&lt;br&gt;    writes/s:                     1062.08&lt;br&gt;    fsyncs/s:                     3406.64&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  24.89&lt;br&gt;    written, MiB/s:               16.60&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0164s&lt;br&gt;    total number of events:              60600&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:&lt;/p&gt;
&lt;h2 id=&#34;score-report-22&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;events: 60600&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min: 0.00&lt;br&gt;         avg: 0.16&lt;br&gt;         max: 31.32&lt;br&gt;         95th percentile: 0.54&lt;br&gt;         sum: 9956.30&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev): 60600.0000/0.00&lt;br&gt;    execution time (avg/stddev): 9.9563/0.00
bytes: 2147483648&lt;/p&gt;
&lt;h2 id=&#34;score-report-23&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;execution time (avg/stddev):   9.9563/0.00&lt;/p&gt;
&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 18.29 seconds (111.98 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100
&lt;h2 id=&#34;benchmark-data-report-7&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;Ratio for combined random IO test: 1.50 &lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      1665.88&lt;br&gt;    writes/s:                     1110.59&lt;br&gt;    fsyncs/s:                     3563.77&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  26.03&lt;br&gt;    written, MiB/s:&lt;/p&gt;
&lt;h2 id=&#34;benchmark-data-report-8&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;p&gt;3563.77&lt;/p&gt;
&lt;p&gt;Throughput:
read, MiB/s:                  26.03
written, MiB/s:               17.35&lt;/p&gt;
&lt;p&gt;General statistics:
total time:                          10.0112s
total number of events:              63355&lt;/p&gt;
&lt;p&gt;Latency (ms):
min:                                    0.00
avg:                                    0.16
max:                                  205.01
95th percentile:                        0.78&lt;/p&gt;
&lt;h2 id=&#34;score-report-24&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;205.01&lt;br&gt;         95th percentile:                        0.78&lt;br&gt;         sum:                                 9972.64&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           63355.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9726/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R5&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;6&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Multi-threaded&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running&lt;/p&gt;
&lt;h2 id=&#34;score-report-25&#34;&gt;Score Report
&lt;/h2&gt;&lt;div style=&#34;width: 6vw&#34;&gt;6&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Multi-threaded&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with the following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0002s&lt;br&gt;    total number of events:              197956&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.16&lt;br&gt;         avg:
&lt;h2 id=&#34;score-report-26&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;(ms):&lt;br&gt;         min:                                    0.16&lt;br&gt;         avg:                                    0.20&lt;br&gt;         max:                                    0.34&lt;br&gt;         95th percentile:                        0.21&lt;br&gt;         sum:                                39970.47&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           49489.0000/5.70&lt;br&gt;    execution time (avg/stddev):   9.9926/0.00&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads:&lt;/p&gt;
&lt;h2 id=&#34;score-report-27&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;class=&amp;ldquo;s0&amp;rdquo; dir=&amp;ldquo;ltr&amp;rdquo;&amp;gt;Running the test with the following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0174s&lt;br&gt;    total number of events:              18360&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.57&lt;br&gt;         avg:                                    2.18&lt;br&gt;         max:&lt;/p&gt;
&lt;h2 id=&#34;score-report-28&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;0.57&lt;br&gt;         avg:                                    2.18&lt;br&gt;         max:                                   32.77&lt;br&gt;         95th percentile:                        2.61&lt;br&gt;         sum:                                40050.41&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           4590.0000/94.36&lt;br&gt;    execution time (avg/stddev):   10.0126/0.00&lt;/p&gt;
&lt;p&gt;Running the test with following options:
Number of threads: 4
Initializing random number generator from&lt;/p&gt;
&lt;h2 id=&#34;score-report-29&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;Test with the following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads&amp;hellip;&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0004s&lt;br&gt;    total number of events:              28536&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.23&lt;br&gt;         avg:                                    1.40&lt;br&gt;         max:                                    3.56&lt;/p&gt;
&lt;h2 id=&#34;score-report-30&#34;&gt;Score Report
&lt;/h2&gt;&lt;p&gt;1.40 &lt;br&gt; max: 3.56 &lt;br&gt; 95th percentile: 1.47 &lt;br&gt; sum: 39975.16 &lt;br&gt;&lt;br&gt; Threads fairness:&lt;br&gt; events (avg/stddev): 7134.0000/39.87 &lt;br&gt; execution time (avg/stddev): 9.9938/0.01&lt;/p&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;Whether &lt;code&gt;ChatGPT&lt;/code&gt; is a good thing or not, the table above couldn’t be arranged according to previously mastered &lt;code&gt;Markdown&lt;/code&gt;, and failing to create a table would result in a poor display effect. Customizing the theme limited the maximum width of the page, so I adjusted the configuration of the pages accordingly, changing the width to percentage limits.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A simple method is to use tools like TablesGenerator to generate HTML tables (content complexity doesn’t suit this).&lt;/li&gt;
&lt;li&gt;Or you can write it in Google Docs and then download and save it as an HTML document, directly copy it into a blog (simple and direct, which was ultimately adopted).
Ensure that the config is enabled with unsafe configuration items, and give the page configuration width separately. In Hugo, you can set the width of a page individually. This can be achieved by adding custom parameters in the page’s Front Matter. Here&amp;rsquo;s an example: In your Markdown page&amp;rsquo;s Front Matter section (typically at the beginning of the file), add a custom parameter, such as &lt;code&gt;custom_width&lt;/code&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;In your Hugo theme, find or create the corresponding single-page template file (e.g., &lt;code&gt;layouts/_default/single.html&lt;/code&gt;).&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;epilogue-1&#34;&gt;Epilogue
&lt;/h2&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Within a single-page template, check the Front Matter of the page for the &lt;code&gt;custom_width&lt;/code&gt; parameter and apply it to the corresponding HTML elements, such as &lt;code&gt;div&lt;/code&gt;:
In this example, we used inline styles (&lt;code&gt;style&lt;/code&gt; attribute) to set the &lt;code&gt;max-width&lt;/code&gt; property on the &lt;code&gt;div&lt;/code&gt; element, making its width default to 100% when the &lt;code&gt;custom_width&lt;/code&gt; parameter is not specified.  &lt;code&gt;margin: 0 auto;&lt;/code&gt; is used to center the &lt;code&gt;div&lt;/code&gt; element.
Please note that in actual use, you may need to adjust the above example based on your theme structure and CSS styling details. Ensure that when adjusting styles, you maintain consistency and readability within your theme.
Due to slight variations in the enabled theme, the site&amp;rsquo;s custom &lt;code&gt;CSS&lt;/code&gt; configuration was finally adjusted.&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>Git Disable HTTP Repository</title>
        <link>https://ttf248.life/en/p/git-disable-http-repositories/</link>
        <pubDate>Mon, 08 Jan 2024 21:22:04 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/git-disable-http-repositories/</guid>
        <description>&lt;p&gt;Update the habit of software version, unknown from which version of &lt;code&gt;Git&lt;/code&gt; to start, prohibit pulling code from &lt;code&gt;Http&lt;/code&gt; repository.&lt;/p&gt;
&lt;h2 id=&#34;background-introduction&#34;&gt;Background Introduction
&lt;/h2&gt;&lt;p&gt;Environment: Windows platform, I’ve always used Little Turtle to operate Git, and key configuration was also handled through it. I previously created a script to batch update local repositories.
Previous article link: &lt;a class=&#34;link&#34; href=&#34;https://ttf248.life/en/p/bulk-update-local-git-repository-and-legacy-permission-issues/&#34; &gt;Batch Update Local Git Repository&lt;/a&gt;
Today when executing the code update at home, the previous error occurred, and the repository could no longer be updated normally. I was planning to use &lt;code&gt;Git&lt;/code&gt;’s configuration to continue using the &lt;code&gt;http&lt;/code&gt; protocol to update the repository, but I searched everywhere without finding the corresponding configuration item.
The simplest solution is of course to switch to the &lt;code&gt;ssh&lt;/code&gt; protocol to update the repository, as the &lt;code&gt;gitlab&lt;/code&gt; configured by the company will not provide the &lt;code&gt;https&lt;/code&gt; protocol in the short term.&lt;/p&gt;
&lt;h2 id=&#34;legacy-issues&#34;&gt;Legacy Issues
&lt;/h2&gt;&lt;p&gt;When writing the batch update local repository script previously, we initially planned to use &lt;code&gt;ssh&lt;/code&gt; to pull the repository and didn&amp;rsquo;t thoroughly investigate why. The &lt;code&gt;git&lt;/code&gt; configuration information configured via TortoiseGit was not synchronized to the config file, resulting in errors when executing through the command line.&lt;/p&gt;
&lt;p&gt;Checking key configurations with commands like &lt;code&gt;ssh -T git@gitlab.yintech.net&lt;/code&gt; were correct. If you can successfully pull code using Git Small Turtle (TortoiseGit), but receive a &amp;ldquo;key incorrect&amp;rdquo; error when using the &lt;code&gt;git pull&lt;/code&gt; command, this might be because TortoiseGit is using PuTTY&amp;rsquo;s SSH key while the command line uses OpenSSH&amp;rsquo;s SSH key.&lt;/p&gt;
&lt;p&gt;The keys configured in TortoiseGit do not come from the system . Here’s the English translation of the provided text:&lt;/p&gt;
&lt;p&gt;“When reading a secret key file via SSH folder, it instead uses the interface repository configuration to independently configure the path of the key file. A useful trick is to pull the first repository with its configured key, allowing subsequent repositories to reuse that same key. After PuTTY loads the key, it doesn’t immediately exit but starts a proxy service. By adjusting global settings and not using the system&amp;rsquo;s default &lt;code&gt;ssh&lt;/code&gt; configuration, Git Bash will use TortoisePlink for SSH operations. This configuration is suitable when using the PuTTY tool provided by TortoiseGit.”&lt;/p&gt;
&lt;h2 id=&#34;legacy-issues-1&#34;&gt;Legacy Issues
&lt;/h2&gt;&lt;p&gt;Please modify the execution file path in the above configuration to match your specific Mini Turtle path. Due to the complete path configured, no need to add the path to the system environment variables.&lt;/p&gt;</description>
        </item>
        <item>
        <title>AI Programming and Task Decomposition</title>
        <link>https://ttf248.life/en/p/ai-programming-and-task-decomposition/</link>
        <pubDate>Fri, 22 Dec 2023 08:44:26 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/ai-programming-and-task-decomposition/</guid>
        <description>&lt;p&gt;Two years ago, I added a copy function to the site, which took me half a day of tinkering. Ultimately, the rendering effect wasn&amp;rsquo;t quite satisfactory, and as a somewhat mediocre frontend developer, I didn’t plan on improving it – if it worked, it was good enough. This year, I used &lt;code&gt;AI&lt;/code&gt; to develop a mini-program, which has made me more familiar with frontend development. I refactored it (the &lt;code&gt;AI&lt;/code&gt; redesigned it).&lt;/p&gt;
&lt;p&gt;Realization: Breaking down tasks really helps; many small tasks are quite natural for the &lt;code&gt;AI&lt;/code&gt; to develop. For the closed mini-program, 75% of the code was provided by &lt;code&gt;AI&lt;/code&gt;, broken down into multiple tasks delivered, and manually assembled the project code.&lt;/p&gt;
&lt;h2 id=&#34;previous-context&#34;&gt;Previous Context
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://ttf248.github.io/post/2022/001/%E4%BB%A5%E4%B8%BA%E5%BE%88%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%8B%E6%83%85%E5%A2%9E%E5%8A%A0%E4%B8%80%E4%B8%AA%E4%BB%A3%E7%A0%81%E5%A4%8D%E5%88%B6%E6%8C%89%E9%92%AE/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Making simple things easier: Adding a code copy button&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;main-text&#34;&gt;Main Text
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;promot&lt;/strong&gt;: Design CSS and JavaScript code to locate webpage elements with the class &amp;ldquo;highlight&amp;rdquo;, and add a copy button within its container, enabling copy-to-clipboard functionality.&lt;/p&gt;
&lt;p&gt;The first draft of the code was immediately problematic; I regenerated it, making it largely usable, but the copied content was incorrect, containing redundant text. Further guidance led to optimizing the core color design and specifying desired effects.&lt;/p&gt;
&lt;p&gt;Having learned your specific requirements for button size and color, we redesigned the button styles to accommodate these demands.  Below is an adjusted CSS style that incorporates your provided color scheme and optimizes the button&amp;rsquo;s dimensions:&lt;/p&gt;
&lt;p&gt;Within this style, I reduced the button’s size and font size to create a more refined look. “Simultaneously, the button’s default state is semi-transparent. When hovering over the button, it becomes opaque and the background color slightly brightens to provide visual feedback. This design meets your color requirements while maintaining a modern and user-friendly aesthetic.&lt;/p&gt;
&lt;p&gt;A simpler &lt;code&gt;JavaScript&lt;/code&gt; implementation has also been provided:”&lt;/p&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;While I had hoped to see a copy button added to the top-right corner of the code area, due to my lack of familiarity with front-end development and an inability to accurately describe the functionality based on keywords and “AI,” I spent several rounds chasing after it without achieving the desired outcome.&lt;/p&gt;
&lt;p&gt;It remains to be seen what impact “AI” will have on software development as time goes on.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Cloud Servers and Script Kiddies</title>
        <link>https://ttf248.life/en/p/cloud-servers-and-script-kids/</link>
        <pubDate>Mon, 20 Nov 2023 15:08:53 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cloud-servers-and-script-kids/</guid>
        <description>&lt;p&gt;Taking advantage of the Singles Day promotion, Alibaba Cloud recently purchased a server: an economy-friendly version for 99 a year with low specifications, serving as a jumpstart machine to proxy home services – which is quite good. The promotion continues until 2026.&lt;/p&gt;
&lt;p&gt;Specifically, I chose a server in the Shanghai region to minimize latency when proxying my home machines. It runs Windows 11 and Windows Server 2022; the server version was deployed later. While using it, I suddenly received a &amp;ldquo;access denied&amp;rdquo; message, initially thinking it was due to a server update that would resolve itself. After waiting five minutes and trying again, the denial persisted. Searching for related error messages indicated that someone was attempting to log in, and because of too many incorrect password attempts, login was now blocked. - Previously, I had encountered scripts related to security attacks, and immediately thought of this. These logins were likely not normal behavior; someone was attacking the service, attempting a brute-force login to the server. The server’s firewall was overly simplistic – it wasn&amp;rsquo;t configured with a whitelist, and it proxied ports 3389 for two machines, exposing them publicly—much like bait in a fishpond. Now that we knew it was script kiddies attacking, things became much simpler: configure the firewall whitelist to only allow access from the company’s IP address and my home IP address to the proxy service.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;frps&lt;/code&gt; agent server previously had no configuration for running logs. Opening the logs was hilarious – all the proxy IPs across the country were trying to log into my home server. Thankfully, there was one that was a server version, which made me realize the problem: otherwise, that Windows 11 machine would have been compromised eventually; the password settings are relatively simple.&lt;/p&gt;
&lt;p&gt;Also, I checked out the login logs for Linux services – aside from this Alibaba Cloud machine, there’s also a friend&amp;rsquo;s Huawei Cloud machine. This Huawei Cloud machine has been running for a long time and is already in the middle of dictionary cracking; various strange users have started to appear.&lt;/p&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;Developing a self-hosted server requires setting up a whitelist for public Windows access, and on Linux systems, it’s recommended to disable password logins and enable key file login.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>- Batch update local Git repositories and resolve legacy permission issues.</title>
        <link>https://ttf248.life/en/p/bulk-update-local-git-repository-and-legacy-permission-issues/</link>
        <pubDate>Thu, 19 Oct 2023 14:16:22 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/bulk-update-local-git-repository-and-legacy-permission-issues/</guid>
        <description>&lt;p&gt;The projects within the team have dependencies on each other, and due to historical reasons, submodules haven’t been used to manage these project dependencies. Daily development requires manually updating the repository code one by one, otherwise various strange issues may arise.&lt;/p&gt;
&lt;p&gt;Referring to online resources, the structure is generally similar. A local manual repository directory (&lt;strong&gt;git_list.txt&lt;/strong&gt;) is maintained, and a script iterates through the directories to perform an update in one go. Before starting each project, this script needs to be executed.&lt;/p&gt;
&lt;h2 id=&#34;linux&#34;&gt;linux
&lt;/h2&gt;&lt;p&gt;create new file: batch_pull.sh&lt;/p&gt;
&lt;h2 id=&#34;windows&#34;&gt;Windows
&lt;/h2&gt;&lt;p&gt;Create a new file: batch_pull.bat&lt;/p&gt;
&lt;h3 id=&#34;historical-issues&#34;&gt;Historical Issues
&lt;/h3&gt;&lt;p&gt;Also addressed the &lt;code&gt;git&lt;/code&gt; folder permission files encountered after reinstalling the system: &lt;strong&gt;Fatal error &amp;ldquo;unsafe repository (&amp;rsquo;/home/repon&amp;rsquo; is owned by someone else)&amp;rdquo;&lt;/strong&gt;
Most suggested solutions online originate from &lt;code&gt;stack overflow&lt;/code&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Add trust to the repository directory: &lt;code&gt;git config --global --add safe.directory /home/repon&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Manually modify the configuration file &lt;code&gt;.gitconfig&lt;/code&gt;, specifying the directory to add trust
After using these methods, repository updates were normal, but numerous warning messages appeared in the console every time &lt;code&gt;git pull&lt;/code&gt; was executed, indicating owner errors.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;reinstalling-the-system-on-a-desktop-machine&#34;&gt;Reinstalling the System on a Desktop Machine
&lt;/h3&gt;&lt;p&gt;The machine hadn&amp;rsquo;t been reinstalled for a long time, and the system partition was filled with a massive amount of garbage files, leaving me no choice but to take some time to reinstall it. I ran into this permission issue again, and previous scripts wouldn’t run because the permissions were incomplete.&lt;/p&gt;
&lt;p&gt;Using the new approach, I simply added &lt;code&gt;*&lt;/code&gt;, which automatically trusts all directories for &lt;code&gt;git&lt;/code&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;I suspect it&amp;rsquo;s a user permission issue, or perhaps everyone hasn&amp;rsquo;t gotten used to the fact that Windows also has similar commands like &lt;code&gt;chown&lt;/code&gt; to modify folder owners. Of course, if you have only a few directories, you can manually change the owner. However, this work computer has domain information added, and I’m not sure whether it’s due to an anomaly in the company&amp;rsquo;s deployed domain or an abnormality in the local system settings. In the user list, I couldn’t find the user used for login. Finally, I resolved it by processing through the command line.  Running the &lt;code&gt;change_ower.ps1&lt;/code&gt; PowerShell script with administrator privileges. ps1&lt;code&gt;，remember to adjust the script file encoding to &lt;/code&gt;gbk&lt;code&gt;, for Chinese operating systems, otherwise it will be garbled. Unexpected situations still appeared, the Chinese information output by the script was garbled, trying to set the console character encoding, adjusting the script encoding, all outputs were garbled, my brain must have been pretty messed up, try enabling Control Panel-Region-Language Settings beta function, globally enable Unicode encoding, the script executed normally, several development software could not work properly, I will review the materials later and realized that adjusting the script file encoding to &lt;/code&gt;gbk` ### Reinstalling the System on a Desktop Machine
The machine, which hadn&amp;rsquo;t been reinstalled for a long time, had an explosion of garbage system files, leaving me with no choice but to take some time and reinstall it. I ran into this permission issue again, and previous scripts wouldn’t run because the permissions were incomplete.&lt;/p&gt;
&lt;p&gt;Using the new approach, I simply added &lt;code&gt;*&lt;/code&gt;, which automatically trusts all directories for &lt;code&gt;git&lt;/code&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;I suspect it&amp;rsquo;s a user permission issue, or perhaps everyone hasn&amp;rsquo;t gotten used to the fact that Windows also has similar commands like &lt;code&gt;chown&lt;/code&gt; to modify folder owners. Of course, if your directories are few in number, you can manually change the owner as well. However, this work computer has domain information added, and I’m not sure whether it’s due to an anomaly in the company&amp;rsquo;s deployed domain or some abnormality in the local system settings. In the user list, I couldn’t find the user used for login, so I finally handled it through command-line processing.  Administrator permissions were used to execute the &lt;code&gt;change_ower.powershell&lt;/code&gt; script.&lt;/p&gt;
&lt;h2 id=&#34;resources&#34;&gt;Resources
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://ganzhixiong.com/p/f1b9f4fc/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ganzhixiong.com/p/f1b9f4fc/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://stackoverflow.com/questions/71901632/fatal-error-unsafe-repository-home-repon-is-owned-by-someone-else&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stackoverflow.com/questions/71901632/fatal-error-unsafe-repository-home-repon-is-owned-by-someone-else&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>WPF Learning Resources</title>
        <link>https://ttf248.life/en/p/wpf-learning-resources/</link>
        <pubDate>Tue, 17 Oct 2023 10:49:24 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/wpf-learning-resources/</guid>
        <description>&lt;p&gt;The potholes in the mini-program development haven’t been filled, and we’ve just dug a new one with &lt;strong&gt;WPF&lt;/strong&gt;. Recently, the company has been experiencing some turbulence, and remote collaboration communication is invariably less efficient than desired. So, we&amp;rsquo;ve taken on the development of client interfaces.&lt;/p&gt;
&lt;h2 id=&#34;wpf&#34;&gt;WPF
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/dotnet/desktop/wpf/introduction-to-wpf?view=netframeworkdesktop-4.8&amp;amp;preserve-view=true&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;WPF Microsoft Official Learning Resources&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/zh7791/p/11502696.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;WPF Basic Summary (Learning Suggestions)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://www.wpfsoft.com/introduction&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;WPF Chinese Website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/638815741&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;WPF Personal Summary and Learning Recommendations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;WPF&lt;/code&gt; interface design utilizes many concepts similar to web frontend design, striving to isolate UI design from business logic as much as possible, which is the desired division of labor in internet companies.  Having recently dabbled with Mini Programs, many concepts are universal and made learning relatively easy. These can be considered the &amp;ldquo;way&amp;rdquo; in modern UI design; mastering basic framework concepts makes the path less prone to deviation.&lt;/p&gt;
&lt;h2 id=&#34;wpf-1&#34;&gt;WPF
&lt;/h2&gt;&lt;p&gt;For readers with previous &lt;code&gt;WinForm&lt;/code&gt; development experience, we recommend reading: &lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/zh7791/p/11502696.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;WPF Basic Summary (Learning Suggestions)&lt;/a&gt;. The article isn&amp;rsquo;t too long and is suitable for experienced readers to plan their learning path.&lt;/p&gt;
&lt;p&gt;For beginners, we recommend reading: &lt;a class=&#34;link&#34; href=&#34;http://www.wpfsoft.com/introduction&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;WPF Chinese Website&lt;/a&gt;, which introduces basic concepts, the history of development, and the logic of understanding underlying classes from scratch. This website is quite lucky – it was just released by the author in August this year, aimed at attracting readers to purchase courses, and its timing coincides with mine. If it&amp;rsquo;s a little later, I probably won’t have any chance.&lt;/p&gt;
&lt;p&gt;To get the most orthodox learning materials, of course, it’s the official Microsoft documentation, which is somewhat dry and requires patience for new readers. Classic e-books are also plentiful, and not particularly recommended. With a lot of work to do daily, there isn’t much time to sit down and read; it&amp;rsquo;s difficult to immediately immerse myself in reading. It’s more suitable to practice projects instead.&lt;/p&gt;
&lt;h2 id=&#34;c-and-net-release-history&#34;&gt;C# and .NET Release History
&lt;/h2&gt;&lt;p&gt;Regarding previous learning languages, there have been a number of new features released in recent years, with version updates to the syntax occurring annually.
&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/C_Sharp_%28programming_language%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://en.wikipedia.org/wiki/C_Sharp_(programming_language)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Official Learning Resources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/dotnet/csharp/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://learn.microsoft.com/zh-cn/dotnet/csharp/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/dotnet/core/tutorials/with-visual-studio?pivots=dotnet-7-0&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://learn.microsoft.com/zh-cn/dotnet/core/tutorials/with-visual-studio?pivots=dotnet-7-0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>ZeroTier SD</title>
        <link>https://ttf248.life/en/p/zero-tier-remote-lan/</link>
        <pubDate>Tue, 19 Sep 2023 04:58:03 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/zero-tier-remote-lan/</guid>
        <description>&lt;ul&gt;
&lt;li&gt;I recently got a &lt;code&gt;mini&lt;/code&gt; host for the office, thinking it would be convenient to configure an environment and have occasional access at home. I temporarily deployed internal network penetration using &lt;code&gt;frp&lt;/code&gt; – specifying port forwarding, which requires a public server with a connection quality dependent on its bandwidth. Instead, I experimented with a fresh &lt;code&gt;Zerotier&lt;/code&gt; virtual LAN, similar to a &lt;code&gt;VPN&lt;/code&gt;, where I created a virtual network card locally, and all machines joined into that virtual network.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-is-zerotier&#34;&gt;What is ZeroTier
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;ZeroTier&lt;/code&gt; is a software-defined wide area network (SD-WAN) solution that allows users to create secure virtual networks between devices in different geographic locations. Through &lt;code&gt;ZeroTier&lt;/code&gt;, you can easily connect multiple computers, servers, and devices into a virtual, encrypted network – as if they were on the same local network. This can help programmers and IT professionals securely share data and resources across different locations without complex network setups and VPN configurations.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ZeroTier Networks&lt;/strong&gt;: A ZeroTier Network is a virtual, global LAN that allows different devices to connect together over the internet, as if they were on the same physical network. This network can contain multiple subnets, with all devices connected together using ZeroTier technology. &lt;strong&gt;Planet Server:&lt;/strong&gt; The Planet Server is a key component of the Zerotier network. It’s global in scope, responsible for maintaining and managing the entire Zerotier network&amp;rsquo;s topology, routing information, and network state. The Planet Server acts as a central control center for the network, but does not directly transmit data. User devices need to connect to at least one Planet Server to participate in the Zerotier network.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;what-is-zerotier-1&#34;&gt;What is Zerotier
&lt;/h2&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;Relay Server:&lt;/strong&gt; A relay server is an auxiliary node within the Zerotier network, used to help devices establish direct communication channels. When devices cannot connect directly, they can use a relay server to transmit data. This helps improve network reachability and performance. Relay servers are typically located around the globe, acting as data transmission hubs.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In essence, Zerotier utilizes the assistance of planet servers and relay servers to enable devices to create virtual local networks globally, facilitating secure and fast communication between devices. The planet server is responsible for global network management, while the relay server helps establish connection links when needed.&lt;/p&gt;
&lt;h2 id=&#34;installation--deployment&#34;&gt;Installation &amp;amp; Deployment
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Visit the ZeroTier official website (&lt;a class=&#34;link&#34; href=&#34;https://www.zerotier.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.zerotier.com/&lt;/a&gt;) to obtain installation files and documentation.&lt;/li&gt;
&lt;li&gt;Download and install the ZeroTier One client according to your operating system. It supports Windows, macOS, Linux, and many other platforms.&lt;/li&gt;
&lt;li&gt;Launch the ZeroTier One client after installation.&lt;/li&gt;
&lt;li&gt;Register a ZeroTier account if you don&amp;rsquo;t already have one. You can create an account within the client.&lt;/li&gt;
&lt;li&gt;Log in with your ZeroTier account and create a new network. The network will have a unique 16-character ID, which you need to remember.&lt;/li&gt;
&lt;li&gt;Join this network on your device. You can either enter the network ID in the client or use the QR code scanning feature.&lt;/li&gt;
&lt;li&gt;Devices with the installed and configured ZeroTier client will be added to the same virtual network.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;installation-and-deployment-of-moon&#34;&gt;Installation and Deployment of Moon
&lt;/h2&gt;&lt;p&gt;Many domestic operators have banned UDP tunneling, and the frp service is stable due to using the TCP protocol. Zerotier deployment can also achieve similar effects by deploying a relay server, requiring firewall opening of UDP port 9993.&lt;/p&gt;
&lt;p&gt;Verify installation success
Join the local network
Create &lt;code&gt;moon&lt;/code&gt;
Edit the configuration file, adjust the &lt;code&gt;stableEndpoints&lt;/code&gt; nodes to &amp;ldquo;server public IP/9993&amp;rdquo;
Generate signature configurations, create the &lt;code&gt;moons.d&lt;/code&gt; folder, and move the previous files into it; restart the service.&lt;/p&gt;
&lt;p&gt;Client nodes join the moon server, taking the ID from the JSON configuration file&amp;rsquo;s &lt;code&gt;id&lt;/code&gt; field.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On Windows platforms, launch the terminal with administrator privileges and operate using the zerotier-cli.bat command-line tool.&lt;/li&gt;
&lt;li&gt;On Linux platforms, operate using the zerotier-cli tool.&lt;/li&gt;
&lt;li&gt;Use the &lt;code&gt;peers&lt;/code&gt; subcommand to view connections, and &lt;code&gt;listpeers&lt;/code&gt; to view all nodes. Normal display of the &lt;code&gt;moon&lt;/code&gt; node indicates successful joining.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;uninstalling&#34;&gt;Uninstalling
&lt;/h2&gt;&lt;p&gt;How to uninstall on the &lt;code&gt;Windows&lt;/code&gt; platform is beyond the scope of this document, as it follows standard operating procedures – typically through the Control Panel. We will focus on &lt;code&gt;Ubuntu&lt;/code&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Remove the zerotier-one service using dpkg.&lt;/li&gt;
&lt;li&gt;Delete the zerotier-one folder, which stores the address information; deleting it will result in a new address being generated upon reinstallation.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;They were originally all decommissioned, arriving at the server location without suitable service nodes to act as proxy servers. Alibaba was focused on sales and provided development trial servers with low configurations, costing only 99 yuan per year and used for two years. The key factor was the bandwidth offered by the servers.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.wnark.com/archives/152.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.wnark.com/archives/152.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/Yogile/p/12642423.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.cnblogs.com/Yogile/p/12642423.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>VMware Virtual Machine Disk Space Optimization</title>
        <link>https://ttf248.life/en/p/vmware-virtual-disk-space-optimization/</link>
        <pubDate>Wed, 21 Jun 2023 18:35:41 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/vmware-virtual-disk-space-optimization/</guid>
        <description>&lt;p&gt;When installing a development system with VMware virtual machines, it’s generally recommended to pre-allocate a significant amount of disk space. Over time, the local disk space consumed by the VM will far exceed the actual size of the files contained within it.&lt;/p&gt;
&lt;h2 id=&#34;scenario-description&#34;&gt;Scenario Description
&lt;/h2&gt;&lt;p&gt;The &lt;code&gt;df -h&lt;/code&gt; command revealed that the current machine was using 60GB of disk space, and after deleting all snapshots and clone images, the local virtual machine still occupied significantly more than 60GB, further straining the already limited hard drive.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;When installing the virtual machine, do not select &amp;ldquo;pre-allocate disk.&amp;rdquo;&lt;/li&gt;
&lt;li&gt;The local storage drive for the virtual machine must have sufficient free disk space greater than the currently used space of the VM.&lt;/li&gt;
&lt;li&gt;If there is insufficient space, consider temporarily moving the VM to an external hard drive, optimize the disk, and then migrate it back.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tools&#34;&gt;Tools
&lt;/h2&gt;&lt;p&gt;The official provides the &lt;code&gt;open-vm-tools&lt;/code&gt; package, which can be installed via yum or by installing the VMware-Tools image package.&lt;/p&gt;
&lt;h2 id=&#34;commands&#34;&gt;Commands
&lt;/h2&gt;&lt;p&gt;After execution, the virtual machine will automatically shut down. The VMware host program will perform disk compression, and the execution time depends on the volume of the virtual machine and the speed of disk access.&lt;/p&gt;
&lt;p&gt;The effect is quite good; the disk space occupied by the virtual machine is essentially equal to the disk information obtained from &lt;code&gt;df -h&lt;/code&gt;.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Stable Diffusion – The Love, Hate, and Drama of Installing it from Scratch</title>
        <link>https://ttf248.life/en/p/stable-diffusion-zero-install-saga/</link>
        <pubDate>Thu, 13 Apr 2023 00:23:54 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/stable-diffusion-zero-install-saga/</guid>
        <description>&lt;p&gt;Domestic resources are basically all recommending &lt;strong&gt;Autumn Leaf&lt;/strong&gt;’s one-click deployment package, thinking that they are open-source projects based on &lt;code&gt;Python&lt;/code&gt;, so the deployment wouldn&amp;rsquo;t be very complicated, let’s try to start from scratch.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I was messing around with AI-generated images and specifically changed my graphics card, a beginner version of the &lt;code&gt;3060 12g&lt;/code&gt;; the venerable &lt;code&gt;960&lt;/code&gt; served its seven years and retired in glory.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The core &lt;code&gt;pytorch cuda&lt;/code&gt; installation, which I previously encountered issues with when writing Python game helper scripts (I had installed it locally before), still presented problems – the &lt;code&gt;cuda&lt;/code&gt; encryption consistently failed to activate.&lt;/p&gt;
&lt;h2 id=&#34;to-do&#34;&gt;To Do
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Replan the article structure, first introduce PyTorch, version correspondence, and how to check versions.&lt;/li&gt;
&lt;li&gt;How to create a new virtual environment from scratch locally and deploy PyTorch.&lt;/li&gt;
&lt;li&gt;Translate the manuscript from scratch: &lt;a class=&#34;link&#34; href=&#34;https://stable-diffusion-art.com/install-windows/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stable-diffusion-art.com/install-windows/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Organize reference materials&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;steps&#34;&gt;Steps
&lt;/h2&gt;&lt;p&gt;Step-by-step installation tutorials in Chinese may not be readily available. When you search in English on &lt;code&gt;Google&lt;/code&gt;, you’ll find many similar tutorials starting from scratch. We introduce the need to install &lt;code&gt;git&lt;/code&gt; and then explain the need to install &lt;code&gt;python&lt;/code&gt;. Then, you go ahead and download the repository – simply double-clicking the script gets it running.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/AUTOMATIC1111/stable-diffusion-webui&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For detailed usage and troubleshooting, consult the &lt;code&gt;issues&lt;/code&gt;, &lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki&lt;/a&gt;. I don’t know why no one explains what this repository is for. In fact, the name itself makes it pretty clear – it&amp;rsquo;s a graphical console that makes it easier to use.&lt;/p&gt;
&lt;h2 id=&#34;steps-1&#34;&gt;Steps
&lt;/h2&gt;&lt;p&gt;The repository also created an installation and startup script. It automatically identifies the current folder and checks for a &lt;code&gt;Python&lt;/code&gt; virtual environment. If one exists, it defaults to using the &lt;code&gt;python&lt;/code&gt; in the current path.&lt;/p&gt;
&lt;p&gt;For new users who are unfamiliar with the process, we recommend reviewing: &lt;a class=&#34;link&#34; href=&#34;https://stable-diffusion-art.com/install-windows/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stable-diffusion-art.com/install-windows/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;pytorch&#34;&gt;PyTorch
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/get-started/locally/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://pytorch.org/get-started/locally/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Don&amp;rsquo;t follow their steps directly to launch the script. Python uses &lt;code&gt;requirement&lt;/code&gt; files to install dependency libraries – this is just a minor issue. The core thing is your GPU version and driver version, which need to match PyTorch. Many people have discussed the corresponding relationship online; you can find it by searching.
Reference: &lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/weixin_40660408/article/details/129896700&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/weixin_40660408/article/details/129896700&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Creating a virtual environment is like creating an empty virtual environment, where you first execute the official script to install PyTorch within it.
You can use the above two scripts to check the CUDA version you need to install and also verify whether the installation was successful. - It’s not recommended to use fancy operations here. First, copy over according to the logic of the official page, and then just install it directly. Using pip to install will likely fail or won&amp;rsquo;t activate CUDA.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The key point is that don’t put random characters in your folder paths, as this could prevent PyTorch from working.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;pytorch-1&#34;&gt;PyTorch
&lt;/h2&gt;&lt;p&gt;I went through a lot of trial and error installing it repeatedly, even trying to download the official installation files and manually install them. I was hoping to upgrade to version 2.0 because the official documentation said it would be faster. However, I hadn&amp;rsquo;t used it much before, and I wasn’t sure about the impact of Python versions on it. In between, I also reviewed the official documentation, which recommended using version 3.8. This created a small conflict since I had previously used a one-click installation package that included version 3.10. Finally, I started from scratch by creating a new folder and a virtual environment to ensure that PyTorch was installed successfully. Then, I moved this installed virtual environment into the web UI folder. At that point, when running the script to install the other dependencies, all the dependency issues were resolved. Afterwards, you need to execute: &lt;code&gt;python -m pip install --upgrade --force-reinstall pip&lt;/code&gt; to fix pip. It might seem a bit strange, but I’ve spent quite a while troubleshooting this. I realized it couldn&amp;rsquo;t correctly identify my torch, so I thought it best to install it first before installing other dependency libraries to eliminate all potential interference.&lt;/p&gt;
&lt;h2 id=&#34;xformers&#34;&gt;Xformers
&lt;/h2&gt;&lt;p&gt;It is recommended to enable this, which can accelerate image generation and reduce memory usage. However, a side effect is that &lt;strong&gt;generated images tend to be less stable&lt;/strong&gt; with the same set of parameters.
&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;stable-diffusion-webui:Xformers&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/diffusers/optimization/xformers&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;huggingface optimization&lt;/a&gt;
| 100.00% | 2m 57.03s | 7440/10058 MiB | 12288/12288 MiB (100.0%) |&lt;/p&gt;
&lt;h2 id=&#34;xformers-1&#34;&gt;Xformers
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Optimization Ratio&lt;/th&gt;
&lt;th&gt;Time taken&lt;/th&gt;
&lt;th&gt;Torch active/reserved&lt;/th&gt;
&lt;th&gt;Sys VRAM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;51.02%&lt;/td&gt;
&lt;td&gt;1m 29.21s&lt;/td&gt;
&lt;td&gt;4547/7164 MiB&lt;/td&gt;
&lt;td&gt;9298/12288 MiB (75.67%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;We didn’t recommend the one-click deployment package because it contained some settings that were customized by the author and differed from the official, out-of-the-box configuration. If you&amp;rsquo;re a beginner, you might not understand why those parameters are optimal; it’s best to start with the official package first. As you use it more and more, take time to read the official documentation, and you’ll learn which parameters need adjustment.&lt;/p&gt;
&lt;h2 id=&#34;choosing-a-graphics-card&#34;&gt;Choosing a Graphics Card
&lt;/h2&gt;&lt;p&gt;Following the cryptocurrency mining boom, graphics card prices have become relatively more reasonable. When choosing between the RTX 3060 and RTX 3060 Ti for entry-level players, it’s generally recommended to opt for the version with larger VRAM – specifically the ‘12G’ models. This is because they can generate images at higher resolutions. Why do you need a higher resolution? Because you can adjust the resolution during generation, resulting in clearer and more detailed images. If you&amp;rsquo;re primarily generating smaller images, then 8GB of VRAM will suffice.&lt;/p&gt;
&lt;p&gt;There’s also the &lt;strong&gt;Super Resolution Upscaling&lt;/strong&gt; option, which enhances details and makes the image richer. This feature also requires more VRAM. Here’s a summary table of the single-precision (FP32), half-precision (FP16), and double-precision (FP64) floating-point compute capabilities for NVIDIA GeForce GTX 970, GeForce RTX 3060 Ti, GeForce RTX 3060, GeForce RTX 3080, and GeForce RTX 3080 Ti:&lt;/p&gt;
&lt;p&gt;| GeForce GTX 970 | 2014 | 3.49 | 87.2 | 0.109 |&lt;/p&gt;
&lt;h2 id=&#34;graphics-card-selection&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;graphics-card-selection-1&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;graphics-card-selection-2&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;graphics-card-selection-3&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating-Point Compute Capability (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;graphics-card-selection-4&#34;&gt;Graphics Card Selection
&lt;/h2&gt;&lt;p&gt;Excerpted from &lt;a class=&#34;link&#34; href=&#34;https://docs.google.com/spreadsheets/d/1Zlv4UFiciSgmJZncCujuXKHwc4BcxbjbSBg71-SdeNk/edit#gid=0&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;various graphics card performance test data&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;updates&#34;&gt;Updates
&lt;/h2&gt;&lt;p&gt;Every six months, I originally planned to revisit and refine the installation steps, and explain more basic concepts. However, I discovered that most people using AI image generation are simply adjusting parameters based on images provided by experts, or re-rendering existing images with formatting changes.&lt;/p&gt;
&lt;p&gt;I had previously attempted a project using AI to generate UI assets for mini programs, but after struggling for half a day, the results were unsatisfactory compared to just pulling resource images directly from the official mini program documentation.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Program optimization should not attempt to fight against hardware.</title>
        <link>https://ttf248.life/en/p/program-optimization-dont-fight-hardware/</link>
        <pubDate>Fri, 07 Apr 2023 16:30:15 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/program-optimization-dont-fight-hardware/</guid>
        <description>&lt;p&gt;&lt;code&gt;one loop thread&lt;/code&gt;, the time has already been at the &lt;strong&gt;microsecond&lt;/strong&gt; level, changing servers from a maximum of six ten thousand packets accumulated to almost none.&lt;/p&gt;
&lt;p&gt;In single-threaded looping scenarios processing data, CPU performance depends on factors such as clock frequency, cache size, and instruction set architecture. Generally, CPUs with higher clock frequencies, larger caches, and more advanced instruction set architectures perform better in single-threaded data processing.&lt;/p&gt;
&lt;h2 id=&#34;single-threaded&#34;&gt;Single-Threaded
&lt;/h2&gt;&lt;p&gt;Performance improvements aren’t always achieved by adding threads; it’s not necessary to overcomplicate things.  Refine the project workflow, identify time-consuming bottlenecks, and determine if a single thread can meet the requirements. Considering single-threaded approaches reduces complexity and minimizes potential issues.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It&amp;rsquo;s somewhat misguided to jump straight into suggesting threading – it tends to be a bit of an overreaction.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;events&#34;&gt;Events
&lt;/h2&gt;&lt;p&gt;Handling &lt;strong&gt;market data, latency-sensitive&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Spent the night working diligently to release a new optimized version, performing local API stripping for testing, and the speed was acceptable: tps: 42,000.&lt;/p&gt;
&lt;p&gt;Upon deployment to the server, the TPS dropped dramatically to: 21,000.  I went home to try it on my desktop, resulting in: tps: 79,000. This led me to suspect that our internal service virtual machines might be experiencing some issues. Initially, I suspected CPU frequency differences between the server and my desktop. The biggest difference was the CPU frequency – the desktop had a higher frequency than the test server.&lt;/p&gt;
&lt;p&gt;Test Server A
Test Server B&lt;/p&gt;
&lt;h2 id=&#34;consulting-openai&#34;&gt;Consulting OpenAI
&lt;/h2&gt;&lt;p&gt;Initially, let&amp;rsquo;s consider the core count and base frequency. The Intel(R) Xeon(R) CPU E7-4807 @ 1.87GHz has 6 physical cores and 12 logical cores with a base frequency of 1.87GHz; while the Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz has 8 physical cores and 16 logical cores with a base frequency of 2.60GHz. Therefore, from the perspective of core count and base frequency, the E5-2640 v3 should be more advantageous in single-threaded data processing compared to the E7-4807.&lt;/p&gt;
&lt;p&gt;Secondly, regarding cache size, the E7-4807 has a cache size of 12MB, while the E5-2640 v3 has a cache size of 20MB. Consequently, the E5-2640 v3 possesses a larger cache space, which can improve data access speed and cache hit rate.&lt;/p&gt;
&lt;p&gt;Finally, concerning architecture, the E5-2640 v3 utilizes a more advanced Haswell architecture, while the E7-4807 employs an older Nehalem architecture.&lt;/p&gt;
&lt;h2 id=&#34;consulting-openai-1&#34;&gt;Consulting OpenAI
&lt;/h2&gt;&lt;p&gt;Therefore, considering the overall factors, in a single-threaded loop processing data scenarios, the E5-2640 v3 should outperform the E7-4807. However, specific performance differences will be influenced by various factors including data processing algorithms, memory bandwidth, system load, and so on, requiring analysis based on the specific problem.&lt;/p&gt;
&lt;h2 id=&#34;hardware-specifications&#34;&gt;Hardware Specifications
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cpubenchmark.net/compare/3786.2vs2365.2/%5BDual-CPU%5D-Intel-Xeon-E7%e2%80%934807-vs-%5BDual-CPU%5D-Intel-Xeon-E5-2640-v3&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.cpubenchmark.net/compare/3786.2vs2365.2/%5BDual-CPU%5D-Intel-Xeon-E7–4807-vs-%5BDual-CPU%5D-Intel-Xeon-E5-2640-v3&lt;/a&gt;
| Price | Search Online  $78 - BUY |  |&lt;/p&gt;
&lt;h2 id=&#34;hardware-specifications-1&#34;&gt;Hardware Specifications
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Specification&lt;/th&gt;
&lt;th&gt;Xeon E7-4807 (LGA1567)&lt;/th&gt;
&lt;th&gt;Xeon E5-2640 v3 (LGA2011-v3)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;hardware-specifications-2&#34;&gt;Hardware Specifications
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Specification&lt;/th&gt;
&lt;th&gt;Xeon E7-4807 (LGA1567)&lt;/th&gt;
&lt;th&gt;Xeon E5-2640 v3 (LGA2011-v3)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;hardware-specifications-3&#34;&gt;Hardware Specifications
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Specification&lt;/th&gt;
&lt;th&gt;Xeon E7-4807 (LGA1567)&lt;/th&gt;
&lt;th&gt;Xeon E5-2640 v3 (LGA2011-v3)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;hardware-specifications-4&#34;&gt;Hardware Specifications
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Specification&lt;/th&gt;
&lt;th&gt;Xeon E7-4807 (LGA1567)&lt;/th&gt;
&lt;th&gt;Xeon E5-2640 v3 (LGA2011-v3)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Turbo Speed&lt;/td&gt;
&lt;td&gt;Not Supported&lt;/td&gt;
&lt;td&gt;Up to 3.4 GHz&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;hardware-specifications-5&#34;&gt;Hardware Specifications
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Specification&lt;/th&gt;
&lt;th&gt;Xeon E7-4807 (LGA1567)&lt;/th&gt;
&lt;th&gt;Xeon E5-2640 v3 (LGA2011-v3)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Number of Physical Cores&lt;/td&gt;
&lt;td&gt;6 (Threads: 12)&lt;/td&gt;
&lt;td&gt;8 (Threads: 16)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;hardware-specifications-6&#34;&gt;Hardware Specifications
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Specification&lt;/th&gt;
&lt;th&gt;Xeon E7-4807 (LGA1567)&lt;/th&gt;
&lt;th&gt;Xeon E5-2640 v3 (LGA2011-v3)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;hardware-specifications-7&#34;&gt;Hardware Specifications
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Specification&lt;/th&gt;
&lt;th&gt;Xeon E7-4807 (LGA1567)&lt;/th&gt;
&lt;th&gt;Xeon E5-2640 v3 (LGA2011-v3)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Max TDP&lt;/td&gt;
&lt;td&gt;95W x 2&lt;/td&gt;
&lt;td&gt;90W x 2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;hardware-specifications-8&#34;&gt;Hardware Specifications
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Specification&lt;/th&gt;
&lt;th&gt;Xeon E7-4807 (LGA1567)&lt;/th&gt;
&lt;th&gt;Xeon E5-2640 v3 (LGA2011-v3)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Yearly Running Cost&lt;/td&gt;
&lt;td&gt;$34.68&lt;/td&gt;
&lt;td&gt;$32.85&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;hardware-specifications-9&#34;&gt;Hardware Specifications
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Specification&lt;/th&gt;
&lt;th&gt;Xeon E7-4807 (LGA1567)&lt;/th&gt;
&lt;th&gt;Xeon E5-2640 v3 (LGA2011-v3)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h2 id=&#34;hardware-specifications-10&#34;&gt;Hardware Specifications
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Specification&lt;/th&gt;
&lt;th&gt;Xeon E7-4807 (LGA1567)&lt;/th&gt;
&lt;th&gt;Xeon E5-2640 v3 (LGA2011-v3)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;First Seen on Chart&lt;/td&gt;
&lt;td&gt;Q3 2020&lt;/td&gt;
&lt;td&gt;Q3 2014&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;hardware-specifications-11&#34;&gt;Hardware Specifications
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Specification&lt;/th&gt;
&lt;th&gt;Xeon E7-4807 (LGA1567)&lt;/th&gt;
&lt;th&gt;Xeon E5-2640 v3 (LGA2011-v3)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;# of Samples&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;46&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;hardware-specifications-12&#34;&gt;Hardware Specifications
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Specification&lt;/th&gt;
&lt;th&gt;Xeon E7-4807 (LGA1567)&lt;/th&gt;
&lt;th&gt;Xeon E5-2640 v3 (LGA2011-v3)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;CPU Value&lt;/td&gt;
&lt;td&gt;69.1&lt;/td&gt;
&lt;td&gt;225.6&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;hardware-specifications-13&#34;&gt;Hardware Specifications
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Specification&lt;/th&gt;
&lt;th&gt;Xeon E7-4807 (LGA1567)&lt;/th&gt;
&lt;th&gt;Xeon E5-2640 v3 (LGA2011-v3)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Single Thread Rating&lt;/td&gt;
&lt;td&gt;721 (-59.2%)&lt;/td&gt;
&lt;td&gt;1767 (0.0%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;hardware-specifications-14&#34;&gt;Hardware Specifications
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Specification&lt;/th&gt;
&lt;th&gt;Xeon E7-4807 (LGA1567)&lt;/th&gt;
&lt;th&gt;Xeon E5-2640 v3 (LGA2011-v3)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;CPU Mark&lt;/td&gt;
&lt;td&gt;6223 (-64.6%)&lt;/td&gt;
&lt;td&gt;17600 (0.0%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
        </item>
        <item>
        <title>Prompt Engineer</title>
        <link>https://ttf248.life/en/p/prompt-engineer/</link>
        <pubDate>Sun, 26 Mar 2023 20:46:53 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/prompt-engineer/</guid>
        <description>&lt;p&gt;Just as we needed to learn the techniques of searching engines back then, we also need to learn some techniques for communicating with &lt;code&gt;AI&lt;/code&gt;, providing reasonable and sufficient constraints, and efficiently obtaining the answers we need.&lt;/p&gt;
&lt;p&gt;If you look at it from a different angle, current &lt;code&gt;AI&lt;/code&gt; is like a very good student with excellent memory – it has the ability to memorize everything. What we need to do is learn how to communicate with &lt;code&gt;AI&lt;/code&gt; correctly, effectively, and precisely describe our needs to help &lt;code&gt;AI&lt;/code&gt; generate the expected results.&lt;/p&gt;
&lt;p&gt;##科普
The incredibly popular &lt;code&gt;AI&lt;/code&gt; – specifically &lt;code&gt;Generative Pre-Training&lt;/code&gt; – literally translates to generative pre-training. It’s a deep learning model that trains text generation based on internet-available data, used for tasks like question answering, text summarization generation, machine translation, classification, code generation, and conversational AI. Currently, there have been various versions of models such as GPT-1, GPT-2, GPT-3, and GPT-4, each larger and more powerful than the previous one.&lt;/p&gt;
&lt;h2 id=&#34;does-it-really-have-intelligence&#34;&gt;Does it Really Have Intelligence?
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Similarity is high, accuracy increases accordingly.&lt;/li&gt;
&lt;li&gt;Basic, repetitive tasks, after specific training, no longer require human intervention.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Generative AI is a technology that utilizes existing data such as text, audio, and images to create new content. It can be used for various tasks including text generation, speech synthesis, image generation, and dialogue systems. The logical reasoning of Generative AI depends on its training data and model structure. Generally, Generative AI can follow grammar, logic, and common sense to a certain extent, but it may also produce errors, biases, or unrealistic content. Therefore, the output of Generative AI requires human judgment and verification; it should not be blindly trusted or used.&lt;/p&gt;
&lt;h2 id=&#34;prompt-engineer&#34;&gt;Prompt Engineer
&lt;/h2&gt;&lt;p&gt;Time flows only forward, and people need to learn to adapt to the current. You can think of &lt;code&gt;AI&lt;/code&gt; as not intelligent, lacking logic, and often producing unusable code.&lt;/p&gt;
&lt;p&gt;If you shift your perspective, the current &lt;code&gt;AI&lt;/code&gt; is like a child with excellent memory – it has the ability to memorize after reading something repeatedly, much like copying homework. What we need to do is learn how to communicate correctly, effectively, and with &lt;code&gt;AI&lt;/code&gt;, precisely describing our needs to help &lt;code&gt;AI&lt;/code&gt; generate the desired results.&lt;/p&gt;
&lt;h2 id=&#34;dialogue-patterns&#34;&gt;Dialogue Patterns
&lt;/h2&gt;&lt;p&gt;Two years ago, when GitHub Copilot was released, no one could have imagined that two years later, OpenAI would appear out of nowhere, allowing humans to recognize the capabilities of large language models.&lt;/p&gt;
&lt;p&gt;Based on &lt;strong&gt;comment-based programming&lt;/strong&gt; and &lt;strong&gt;conversational programming&lt;/strong&gt;, the interaction logic is completely different. The dialogue pattern offers a user-friendly experience for novice users, and it’s essential to mention NewBing providing follow-up prompts after each question. Microsoft is attempting to guide users to obtain more content from the AI knowledge base.&lt;/p&gt;
&lt;h2 id=&#34;lets-illustrate-with-an-example&#34;&gt;Let&amp;rsquo;s illustrate with an example
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Scenario:&lt;/strong&gt; A long high-speed train journey, and coding is a good choice. With limited traffic, processing a few images, obtaining image materials, downloading software to process the images is a bit extravagant, and network conditions aren’t ideal.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt; There’s a batch of image materials with transparent backgrounds that need to be used as navigation bars for small programs. The selected state is colored, and the unselected state is black and white. The materials are all in color, and they need to be preprocessed. &lt;strong&gt;Prompt:&lt;/strong&gt; Write a Python code to read all images from a folder, convert them to black and white while maintaining the transparent background, optimize image quality, reduce file size, and display the before-and-after file size comparison in the console.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;AI&lt;/code&gt; quickly provided an answer that looked very beautiful and worked well; an experienced programming source would find the code less generic and unable to be deployed into production:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Parameters were fixed.&lt;/li&gt;
&lt;li&gt;There were no log files, all information was printed to the console.&lt;/li&gt;
&lt;li&gt;The image processing task was suitable for a multi-threaded model.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;NewBing&lt;/code&gt; appeared, based on the prompt, choosing a question: &lt;strong&gt;What improvements can be made to this code?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This time, the answer was honest and completely exceeded expectations; typical optimization measures that programmers would think of were all provided by &lt;code&gt;AI&lt;/code&gt;, and corresponding suggestions were given.&lt;/p&gt;
&lt;p&gt;A friendly response was given, considering there are differences in the deployment environment, it allowed for not supporting multi-processes. ## Let&amp;rsquo;s illustrate with an example&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Scenario:&lt;/strong&gt; A long high-speed train journey, coding is a good choice. With limited traffic, processing a few images, obtaining image materials, downloading software to process the images is a bit extravagant, and network conditions aren’t ideal.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt; There’s a batch of image materials with transparent backgrounds intended for use as navigation bars in small programs. The selected state is colored, and the unselected state is black and white. The materials are all in color, and they need to be preprocessed.&lt;/p&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;Due to local development being on a &lt;code&gt;windows&lt;/code&gt; system, the first answer given by &lt;code&gt;AI&lt;/code&gt; did not include the &lt;code&gt;main&lt;/code&gt; function and lacked &lt;code&gt;multiprocessing.freeze_support&lt;/code&gt;. The code was fixed after following up and encountering an error.
Just as learning search engine techniques required effort, we also need to learn how to communicate with &lt;code&gt;AI&lt;/code&gt;, providing reasonable and sufficient constraints to efficiently obtain the desired answers.
Note: &lt;strong&gt;If you are a programming beginner, if you still don&amp;rsquo;t understand certain parts of the code based on the given comments, please continue to ask related questions.&lt;/strong&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>WeChat Mini Program Background and Development Environment</title>
        <link>https://ttf248.life/en/p/wechat-mini-program-background-and-development-environment/</link>
        <pubDate>Fri, 24 Mar 2023 21:59:11 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/wechat-mini-program-background-and-development-environment/</guid>
        <description>&lt;p&gt;WeChat Mini Program Introduction and Development Preparation&lt;/p&gt;
&lt;h2 id=&#34;why-mini-programs-exist&#34;&gt;Why Mini Programs Exist
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Better Experience:&lt;/strong&gt; Slow web loading and blank screens; native app experience with faster loading.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Standards &amp;amp; Management:&lt;/strong&gt; For WeChat, onboarding and management
Before mini programs were released, WeChat published an SDK called &lt;code&gt;Jssdk&lt;/code&gt;, which opened up parts of the original WeChat capabilities: WeChat Pay, coupons. However, developers used web development languages to develop logic, bypassing some WeChat regulations. Mini Programs have their own description language.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-are-mini-programs&#34;&gt;What are Mini Programs?
&lt;/h2&gt;&lt;p&gt;Mini programs are applications that can be used without needing to download and install them. They realize the dream of having applications &lt;strong&gt;within easy reach&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Users can open an application simply by scanning a QR code or searching for it. This also reflects the concept of &lt;strong&gt;use-it-and-leave-it&lt;/strong&gt; – users don’t have to worry about installing too many apps. Applications will be ubiquitous and available at any time, but they &lt;strong&gt;don&amp;rsquo;t require installation or uninstallation&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;differences-between-mini-programs-and-mobile-applications&#34;&gt;Differences Between Mini Programs and Mobile Applications
&lt;/h2&gt;&lt;p&gt;No installation required, doesn&amp;rsquo;t occupy memory, easy to spread: QR code scanning, mini program cards, Search One Search (Sohu Search)&lt;/p&gt;
&lt;h2 id=&#34;what-mini-programs-can-do&#34;&gt;What Mini Programs Can Do
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Content Tools: Zhihu Hot Rankings, Weibo Hot Topics, Mobike Bikes, Today Headline, Tencent Maps, Tencent Translate&lt;/li&gt;
&lt;li&gt;Retail: Pinduoduo, JD.com Shopping, Mugujie, Daily Fresh, Xiaomi Mall, Watsons&lt;/li&gt;
&lt;li&gt;Games: Jump Rope, Happy Mahjong, Happy Mahjong, Douyu Live Streaming, YY Live Streaming&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Course content is from 2018; some application vendors have already gone bankrupt now.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;development-preparation&#34;&gt;Development Preparation
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Register a Mini Program Account: Simply fill in the information normally, and click the activation link on the email.&lt;/li&gt;
&lt;li&gt;Information Registration&lt;/li&gt;
&lt;li&gt;Log into the Mini Program Management Backstage&lt;/li&gt;
&lt;li&gt;Complete Mini Program Information&lt;/li&gt;
&lt;li&gt;Bind Developer: For individual developers, use the WeChat account you’re logged in with as the administrator account; no additional binding is required.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Email has certain restrictions – it needs a new email, but you can apply aliases for QQ emails, and the WeChat background will not verify them. After trying this, the name of the mini program is quite troublesome. As soon as it involves trademarks, it’s prone to audit failure.&lt;/p&gt;
&lt;p&gt;You can select service categories and also add custom ones; a Mini Program can add five categories.&lt;/p&gt;
&lt;p&gt;In Settings, you can view the Mini Program&amp;rsquo;s &lt;code&gt;ID&lt;/code&gt; information and enable message push; with message push enabled, you can use the Message Template function.&lt;/p&gt;
&lt;h2 id=&#34;developer-tools-as-described-by-the-author&#34;&gt;Developer Tools (as described by the author)
&lt;/h2&gt;&lt;p&gt;Normal download and installation, with no special considerations – just a basic understanding. Simply enter in Guest Mode, and if you want to enable mobile debugging (i.e., view the mini-program development version on your phone), you need to log into the mini-program developer account, then click Settings, and switch to the specified mini-program’s &lt;code&gt;ID&lt;/code&gt; within Project Details.&lt;/p&gt;
&lt;h2 id=&#34;code-structure&#34;&gt;Code Structure
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;js: Interaction logic&lt;/li&gt;
&lt;li&gt;json: Data configuration&lt;/li&gt;
&lt;li&gt;wxml: UI elements&lt;/li&gt;
&lt;li&gt;wxss: UI styles&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Office migration, the servers are inaccessible.</title>
        <link>https://ttf248.life/en/p/office-migration-server-unavailable/</link>
        <pubDate>Sat, 11 Mar 2023 01:42:05 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/office-migration-server-unavailable/</guid>
        <description>&lt;p&gt;Administrative notice, office relocation from the second floor to the fifteenth floor – a standard, routine desk move.&lt;/p&gt;
&lt;h2 id=&#34;design-sense&#34;&gt;Design Sense
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/office-move-server-inaccessible/20230311014537.png&#34;
	width=&#34;511&#34;
	height=&#34;916&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Office Building&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;55&#34;
		data-flex-basis=&#34;133px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;migration&#34;&gt;Migration
&lt;/h2&gt;&lt;p&gt;Closing up shop, packing everything away, a familiar route, a new workstation – adjusting computer cabling, finding a comfortable posture to start working.
(ÒωÓױ)! – Connecting the network cable, accessing the frequently used servers for the team, but they were inaccessible. I tried switching to wireless networking, and access was normal again. Initially, I thought it was a problem with the server’s IP address settings, the wired network at the new workstation wasn&amp;rsquo;t included in the firewall configuration, so adjusting it resolved the issue; this subnet isn’t just one server – when trying to access other servers, they were all working normally. Gradually, confusion arose? Let professional people handle professional matters, and finally, a colleague from the operations department pinpointed the cause: This server was deployed with &lt;code&gt;docker&lt;/code&gt;, and the default network of the &lt;code&gt;docker0&lt;/code&gt; service conflicted with the wired network configuration of the office, causing data packets sent to it to not receive responses and being routed to the &lt;code&gt;docker&lt;/code&gt; service. Other servers didn’t deploy &lt;code&gt;docker&lt;/code&gt; services, so I use this one more frequently. Occasionally, I use containers to deploy some test services, and I didn&amp;rsquo;t expect to encounter this scenario. Looking back, considering the entire group is located in a single office building, it’s not strange that IT colleagues divided network segments using addresses starting with &lt;code&gt;172&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;docker0&#34;&gt;docker0
&lt;/h2&gt;&lt;p&gt;Restart the service, switch to a new network, and the server recovers normal access.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://yeasy.gitbook.io/docker_practice/advanced_network/docker0&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Docker from Beginner to Advanced - docker0&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Embedded Systems – Getting Started Part 1 – Technical Terms</title>
        <link>https://ttf248.life/en/p/embedded-introduction-professional-terms/</link>
        <pubDate>Tue, 07 Mar 2023 13:42:36 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/embedded-introduction-professional-terms/</guid>
        <description>&lt;p&gt;Here&amp;rsquo;s the English translation of the provided text:&lt;/p&gt;
&lt;p&gt;“When I think of embedded systems, my mind immediately goes back to the 51-pin single-chip microcomputers and Texas Instruments we used in university labs.&lt;/p&gt;
&lt;p&gt;LPA3399Pro is a visual host developed on the HiSilicon RK3399Pro platform, designed for portable computing hosts that require extensive visual processing. It features an integrated NPU (Neural Processing Unit) with 3.0 TOPS (Tera Operations Per Second) of compute power and supports various algorithm models.&lt;/p&gt;
&lt;p&gt;RV1109 is HiSilicon’s SoC (System on Chip) within its machine vision branch of artificial intelligence, featuring a dedicated NPU. RV1109 provides 1TOPS (Tera Operations Per Second) of compute power.”&lt;/p&gt;
&lt;h2 id=&#34;system-on-chip&#34;&gt;System on Chip
&lt;/h2&gt;&lt;p&gt;SoC is an abbreviation for System on a Chip, meaning “system on a chip.” It’s a technology that integrates multiple electronic systems onto a single chip. This technology can significantly reduce the size and weight of electronic products while simultaneously improving performance and reducing power consumption.&lt;/p&gt;
&lt;p&gt;SoC (System on a Chip) and CPU (Central Processing Unit) are both important components of computer systems, but they have some differences between them.&lt;/p&gt;
&lt;p&gt;The CPU is the core processor in a computer system, responsible for executing program instructions. It typically only contains basic components such as arithmetic logic units, control units, and registers.&lt;/p&gt;
&lt;p&gt;SoC, on the other hand, integrates multiple electronic systems onto a single chip, including a CPU, as well as other components such as memory, graphics processors, and input/output interfaces. This can significantly reduce the size and weight of electronic products while simultaneously improving performance and reducing power consumption. In essence, a CPU is a component of an SoC, while an SoC is a more complex and highly integrated electronic system.&lt;/p&gt;
&lt;h2 id=&#34;microcontroller-unit&#34;&gt;Microcontroller Unit
&lt;/h2&gt;&lt;p&gt;SoC (System on a Chip) and MCU (Microcontroller Unit) are technologies that integrate multiple electronic systems onto a single chip, but there are also some differences between them.&lt;/p&gt;
&lt;p&gt;An MCU is a microcontroller, typically containing a CPU, memory, input/output interfaces, and other basic components. It’s commonly used to control other electronic devices, such as household appliances and automotive electronics systems.&lt;/p&gt;
&lt;p&gt;An SoC, on the other hand, integrates more electronic systems onto a single chip, in addition to the basic components of an MCU, it can also integrate other components like graphics processors and wireless communication modules. This significantly reduces the size and weight of electronic products while improving performance and reducing power consumption.&lt;/p&gt;
&lt;p&gt;In essence, an MCU is a simple microcontroller, whereas an SoC is a more complex and highly integrated electronic system.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>AI-assisted programming, the evolution of productivity</title>
        <link>https://ttf248.life/en/p/ai-assisted-programming-productivity-evolution/</link>
        <pubDate>Tue, 28 Feb 2023 17:05:17 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/ai-assisted-programming-productivity-evolution/</guid>
        <description>&lt;p&gt;“GitHub Copilot” was released less than two years ago, and “ChatGPT” appeared shortly after. I don’t fully understand the underlying principles, but I&amp;rsquo;ve used them for a while. The two tools differ completely in their level of assistance, but they have both significantly increased productivity.&lt;/p&gt;
&lt;p&gt;For things that are too complex, AI still can’t do it – after all, they lack logic, or operate on established patterns or fixed frameworks. If the training data is sufficient, AI can achieve nine out of ten results.&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;GitHub Copilot
&lt;/h2&gt;&lt;p&gt;When released, the demo on the official website wasn&amp;rsquo;t very smart, so I tried it and didn’t find it useful, so I gave up.&lt;/p&gt;
&lt;p&gt;Before 2022, when I had some free time, I switched to the new version to try it out, and the effect was already quite good; however, the speed in China was a bit slow, which was probably due to network issues. For languages like &lt;code&gt;Python&lt;/code&gt;, the code generated based on comments was pretty good, and much faster than researching and writing code myself.&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;Github Copilot&lt;/code&gt; still focuses on developers, i.e., from a development perspective when designing the product. You need to understand how to program and gradually guide AI assistance through comments.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ChatGPT&lt;/code&gt; has moved to the next level, &lt;strong&gt;allowing non-programmers to quickly get started&lt;/strong&gt;. The conversational chat interface design allows you to simply ask questions, describe requirements, and ask for clarification if you don&amp;rsquo;t understand.&lt;/p&gt;
&lt;p&gt;Let’s take a simple example: You know about tokenization but don’t know how to code it; you want to calculate the similarity of strings:&lt;/p&gt;
&lt;p&gt;Hello, this is Bing. 😊&lt;/p&gt;
&lt;p&gt;Based on online information 123, Python tokenization can be implemented using the jieba library. The jieba library supports three tokenization modes: precise mode, full mode, and search engine mode. You can choose the appropriate mode based on your needs. To compare the similarity of two strings, you first need to tokenize them and then calculate their word vectors or edit distance metrics. You can use libraries like NumPy or SciPy for mathematical operations.&lt;/p&gt;
&lt;p&gt;To standardize string processing, convert English strings to lowercase using Python&amp;rsquo;s built-in &lt;code&gt;lower()&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;To slice the second string, you can use Python’s slicing operator [].&lt;/p&gt;
&lt;p&gt;Here is a possible code example:&lt;/p&gt;
&lt;h2 id=&#34;chatgpt-1&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Going Further – Consult the Execution Results. Congratulations, you’ve identified an issue! The result was hallucinated; it did not actually run the code, but will provide a good-looking response.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;example&#34;&gt;Example
&lt;/h3&gt;&lt;p&gt;Question: SQL statement to retrieve records from the product code table where the product code falls within the range 80000-89999.
Follow-up question: Negate it: The product code is a string, your code is wrong.
Congratulations, it will misidentify.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>A Collection of Less Commonly Used Git Commands</title>
        <link>https://ttf248.life/en/p/git-less-common-commands-summary/</link>
        <pubDate>Fri, 17 Feb 2023 10:08:57 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/git-less-common-commands-summary/</guid>
        <description>&lt;p&gt;Less commonly used, but very useful &lt;code&gt;git&lt;/code&gt; commands&lt;/p&gt;
&lt;h3 id=&#34;reinstalling-the-system-caused-changes-to-folder-ownership-on-windows&#34;&gt;Reinstalling the system caused changes to folder ownership on &lt;code&gt;Windows&lt;/code&gt;.
&lt;/h3&gt;&lt;p&gt;The new version of &lt;code&gt;git&lt;/code&gt; has increased security checks, prompting an unsafe message and preventing further operation.&lt;/p&gt;
&lt;h3 id=&#34;new-computer-account-password-information&#34;&gt;New Computer Account Password Information
&lt;/h3&gt;&lt;p&gt;If the information saved needs to be updated, first clear out the old credentials.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>- Compiler
- Callback Function
- Performance Testing</title>
        <link>https://ttf248.life/en/p/compiler-callback-function-performance-testing/</link>
        <pubDate>Wed, 15 Feb 2023 13:59:25 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/compiler-callback-function-performance-testing/</guid>
        <description>&lt;ul&gt;
&lt;li&gt;Last year, an SDK was designed to handle encapsulating certain events and provide a class interface externally. During service initialization, the caller implements the corresponding classes and passes the object pointer to the module.&lt;/li&gt;
&lt;li&gt;Familiarity with C11 piqued my curiosity, leading me to explore what would happen if these interfaces were implemented using lambda function objects instead of the traditional pure virtual function definition method. Compared to the latter, it seemed more flexible.&lt;/li&gt;
&lt;li&gt;The question arose: with two different syntaxes, which one would be faster from a performance perspective? Not understanding compiler principles, I decided to try out some code to find out.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction
&lt;/h2&gt;&lt;p&gt;Online website, allowing you to select different compilers, compilation parameters, run code on the &lt;code&gt;linux&lt;/code&gt; platform, or view corresponding assembly code.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt; : Sometimes useful for technical validation; executing small code snippets in a web browser is very convenient.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://godbolt.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://godbolt.org/&lt;/a&gt; : Using different colors to distinguish the corresponding assembly code for each line, it’s more convenient than using a local debugger.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;body&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;The Standards Committee established grammatical rules, and how these are implemented at the compilation level depends on each compiler vendor. It’s worth noting here that Microsoft&amp;rsquo;s compiler is quite powerful. Syntactic sugar isn’t a panacea; callback interfaces aren’t abundant, using &lt;code&gt;lambda&lt;/code&gt; expressions is more convenient and eliminates the need to define empty callback function interfaces. When callback interfaces become numerous, traditional virtual functions are advantageous for unifying business interface definitions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On the &lt;code&gt;windows&lt;/code&gt; platform, performance is nearly identical, with little difference.&lt;/li&gt;
&lt;li&gt;On the &lt;code&gt;linux&lt;/code&gt; platform, a comparison of virtual functions versus &lt;code&gt;lambda&lt;/code&gt; reveals a 1.35ns overhead in one instance.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In typical business system development, this level of performance degradation can be ignored; introducing &lt;code&gt;lambda&lt;/code&gt; brings greater convenience to the design. This is particularly noticeable when dealing with multi-signal processing, where underlying event triggers are used, and the handling functions for logging objects entering and exiting the system. When more business processing interfaces are needed, the underlying layer uses &lt;code&gt;vector&lt;/code&gt; to store &lt;code&gt;lambda&lt;/code&gt; objects. When an event is triggered, it iterates through them sequentially and calls them one by one, similar to Qt&amp;rsquo;s signals and slots. Logging, monitoring, Business 1, and Business 2 are completely decoupled from each other.&lt;/p&gt;
&lt;h2 id=&#34;code&#34;&gt;Code
&lt;/h2&gt;&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;p&gt;While researching, I came across similar code snippets &lt;a class=&#34;link&#34; href=&#34;https://gist.githubusercontent.com/benloong/8050171/raw/fa577ec923b460862078b8b40233a42a1c619eeb/functionperformance.cpp&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;functionperformance.cpp&lt;/a&gt;.
It included two additional modes: regular functions and functors, providing an interface callback approach and direct call comparison. The performance loss was a difference of orders of magnitude, with functors performing close to functions, sometimes even outperforming them.  The compilation principles were a knowledge blind spot for me; I suspected it was due to the access of variable addresses being adjacent to the function, which would benefit &lt;code&gt;CPU&lt;/code&gt; processing.
I&amp;rsquo;ve included the results from running in &lt;code&gt;wandbox&lt;/code&gt;.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Host byte, network byte, observe directly through debugger</title>
        <link>https://ttf248.life/en/p/host-order-network-order-debugger-observation/</link>
        <pubDate>Tue, 10 Jan 2023 14:18:12 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/host-order-network-order-debugger-observation/</guid>
        <description>&lt;p&gt;Throughout the history of computer development, there has been no unified standard for data storage. There are two commonly used rules for byte arrangement. For example, if the low-order bits of a multi-digit number are placed at smaller addresses and the high-order bits are placed at larger addresses, it is referred to as little-endian; conversely, it is called big-endian. In network applications, byte order is a factor that must be considered because different types of machines may adopt different standards, so they are all converted according to the network standard.
According to reading habits, big-endian byte order is more consistent with the left-to-right reading order.&lt;/p&gt;
&lt;h2 id=&#34;processor-architecturehttpszhwikipediaorgwikie5ad97e88a82e5ba8f&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%AD%97%E8%8A%82%E5%BA%8F&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Processor Architecture&lt;/a&gt;
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Processors such as x86, MOS Technology 6502, Z80, VAX, and PDP-11 use little-endian byte order.&lt;/li&gt;
&lt;li&gt;Processors like Motorola 6800, Motorola 68000, PowerPC 970 use big-endian byte order.&lt;/li&gt;
&lt;li&gt;The byte order of processors such as ARM, PowerPC (excluding PowerPC 970), DEC Alpha, SPARC V9, MIPS, PA-RISC and IA64 is configurable.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;network-byte-order&#34;&gt;Network Byte Order
&lt;/h2&gt;&lt;p&gt;Network transmission generally uses big-endian order, also known as network byte order or network order. The IP protocol defines big-endian as the network byte order.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;Berkeley&lt;/code&gt; sockets API defined a set of conversion functions to convert 16 and 32-bit integers between network byte order and host byte order.&lt;/p&gt;
&lt;p&gt;If using &lt;code&gt;asio&lt;/code&gt; as a networking library, its internal namespaces contain cross-platform adapted function names:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;boost::asio::detail::socket_ops::network_to_host_long&lt;/li&gt;
&lt;li&gt;boost::asio::detail::socket_ops::network_to_host_short&lt;/li&gt;
&lt;li&gt;boost::asio::detail::socket_ops::host_to_network_long&lt;/li&gt;
&lt;li&gt;boost::asio::detail::socket_ops::host_to_network_short&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;visual-studio-debugger&#34;&gt;Visual Studio Debugger
&lt;/h2&gt;&lt;p&gt;In debugging mode, select the Debug menu, Window, and checkmark the Memory window.  Within &lt;code&gt;Visual Studio&lt;/code&gt;, you can directly view data in memory using the debugger, as shown below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/host-network-byte-order-debugger/Snipaste_2023-01-10_14-44-00.png&#34;
	width=&#34;535&#34;
	height=&#34;147&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Debugger Menu&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;363&#34;
		data-flex-basis=&#34;873px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;ways-to-view-memory&#34;&gt;Ways to View Memory
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;The window directly outputs &amp;amp;variable name and jumps to the corresponding variable address.&lt;/li&gt;
&lt;li&gt;If the variable is originally a pointer, double-click on the variable to select it and drag it to the memory window to display the content at the corresponding address.&lt;/li&gt;
&lt;li&gt;If the variable is not a pointer, add it to the calculation window to obtain its address, then manually copy it to the memory window.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lets-illustrate-with-an-example&#34;&gt;Let&amp;rsquo;s illustrate with an example
&lt;/h3&gt;&lt;p&gt;Receive a piece of data and store it in the &lt;code&gt;buffer&lt;/code&gt; object, convert network byte order to host byte order, resulting in &lt;code&gt;body_length&lt;/code&gt; being equal to 30. The server allocates four bytes for transmitting this data.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Big-Endian Byte Order&lt;/strong&gt;: Observing the content of &lt;code&gt;buffer_&lt;/code&gt; in the memory window
&lt;img src=&#34;https://ttf248.life/p/host-network-byte-order-debugger/buffer_.png&#34;
	width=&#34;603&#34;
	height=&#34;318&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;buffer_&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;189&#34;
		data-flex-basis=&#34;455px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Little-Endian Byte Order&lt;/strong&gt;: Observing the content of &lt;code&gt;body_length_&lt;/code&gt; in the memory window
&lt;img src=&#34;https://ttf248.life/p/host-network-byte-order-debugger/body_length_.png&#34;
	width=&#34;581&#34;
	height=&#34;333&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;body_length_&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;174&#34;
		data-flex-basis=&#34;418px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>C11: sleep for vs yield</title>
        <link>https://ttf248.life/en/p/c11-sleep-for-vs-yield/</link>
        <pubDate>Tue, 20 Sep 2022 20:54:51 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/c11-sleep-for-vs-yield/</guid>
        <description>&lt;p&gt;While reviewing the code, &lt;code&gt;std::this_thread::yield()&lt;/code&gt; suddenly popped into my view, a syntax sugar from &lt;code&gt;C11&lt;/code&gt; that I’d used quite a bit, but hadn&amp;rsquo;t noticed before.&lt;/p&gt;
&lt;p&gt;I didn&amp;rsquo;t consult the manual; first, I thought it had something to do with asynchronous operations – the word was used in the coroutine implementation of the Boost library.  Clearly, it wasn’t related to coroutines; it’s about controlling logic within a regular thread.&lt;/p&gt;
&lt;h2 id=&#34;documentation&#34;&gt;Documentation
&lt;/h2&gt;&lt;h3 id=&#34;yield&#34;&gt;yield
&lt;/h3&gt;&lt;p&gt;The accuracy of this function depends on the implementation, particularly the OS scheduler mechanism and system state used. For example, the First-Come, First-Served (FCFS) real-time scheduler (Linux’s SCHED_FIFO) will suspend the current thread and place it at the end of the queue for other threads with the same priority that are ready to run (and has no effect if there are no other threads with the same priority).&lt;/p&gt;
&lt;h3 id=&#34;sleep_for&#34;&gt;sleep_for
&lt;/h3&gt;&lt;p&gt;Blocks the current thread&amp;rsquo;s execution for at least the specified &lt;code&gt;sleep_duration&lt;/code&gt;.
This function may block longer than &lt;code&gt;sleep_duration&lt;/code&gt; due to scheduling or resource contention delays.
The standard library recommends measuring durations using a monotonic clock. If implementing with system time instead, the wait time may be sensitive to clock adjustments.&lt;/p&gt;
&lt;h3 id=&#34;analysis&#34;&gt;Analysis
&lt;/h3&gt;&lt;p&gt;Both functions are designed to release the current thread and its associated resources, with the actual effect depending on the platform. I’m still a bit unclear at this point, so let&amp;rsquo;s run the code to see the execution results.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ThinkPad laptop (Visual Studio Community 2022), Tencent Cloud S2 Standard Server (gcc8.5)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;analysis-1&#34;&gt;Analysis
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Execution Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First/us&lt;/th&gt;
&lt;th&gt;Second/us&lt;/th&gt;
&lt;th&gt;Third/us&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h3 id=&#34;analysis-2&#34;&gt;Analysis
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Execution Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First Time / us&lt;/th&gt;
&lt;th&gt;Second Time / us&lt;/th&gt;
&lt;th&gt;Third Time / us&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h3 id=&#34;analysis-3&#34;&gt;Analysis
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Execution Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First/us&lt;/th&gt;
&lt;th&gt;Second/us&lt;/th&gt;
&lt;th&gt;Third/us&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h3 id=&#34;analysis-4&#34;&gt;Analysis
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Execution Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First/us&lt;/th&gt;
&lt;th&gt;Second/us&lt;/th&gt;
&lt;th&gt;Third/us&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h3 id=&#34;analysis-5&#34;&gt;Analysis
&lt;/h3&gt;&lt;p&gt;From the running results, it’s not difficult to understand that due to differences in operating system implementations, the stability of high-precision sleep varies greatly. If you want high-precision sleep, using &lt;code&gt;yield&lt;/code&gt; is more appropriate.&lt;/p&gt;
&lt;p&gt;When the time precision is increased to &lt;code&gt;ms&lt;/code&gt;, the difference between them is no longer significant.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Linux Server, Reset MySQL Password</title>
        <link>https://ttf248.life/en/p/linux-server-reset-mysql-password/</link>
        <pubDate>Tue, 20 Sep 2022 14:27:35 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-server-reset-mysql-password/</guid>
        <description>&lt;p&gt;I had an idle Tencent Cloud server that was expiring at the end of the year and I hadn&amp;rsquo;t planned to renew it. So, I decided to deploy a MySQL database for development purposes. When reinstalling the system, I wanted to save time and chose a third-party image provided by Tencent Cloud, which already had MySQL installed. I thought the system should include a Readme file or similar documentation explaining the password and deployment path.&lt;/p&gt;
&lt;p&gt;The Tencent Cloud server reinstalled very quickly, taking about a minute. Once logged in, &lt;code&gt;systemctl status mysql&lt;/code&gt; showed that the service was running. I started searching for the password but couldn&amp;rsquo;t find it anywhere, and I began to panic.&lt;/p&gt;
&lt;p&gt;Then, I thought, since I had already accessed the server with root privileges, there must be a way to reset the password. I searched through documentation and found a forum post on Alibaba Cloud’s forum, continuing to tinker.&lt;/p&gt;
&lt;h2 id=&#34;reset-password&#34;&gt;Reset Password
&lt;/h2&gt;&lt;p&gt;Edit the configuration file &lt;code&gt;vim /etc/my.cnf&lt;/code&gt;, adding the following configuration to the &lt;code&gt;mysqld&lt;/code&gt; node: &lt;code&gt;skip-grant-tables&lt;/code&gt;, then execute the command to restart the database: &lt;code&gt;systemctl restart mysql&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Next, log in directly to the data using &lt;code&gt;mysql&lt;/code&gt;, and then proceed with normal operations. To reset the &lt;code&gt;root&lt;/code&gt; user password and enable allowing remote login, revert the modified configuration file, restart the database, and you’re done.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://help.aliyun.com/document_detail/42520.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://help.aliyun.com/document_detail/42520.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>A Brief Overview of Automated Testing</title>
        <link>https://ttf248.life/en/p/shallow-discussion-on-automation-testing/</link>
        <pubDate>Thu, 04 Aug 2022 11:39:18 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/shallow-discussion-on-automation-testing/</guid>
        <description>&lt;p&gt;The investment in testing for financial trading systems far exceeds that of other systems, with cumbersome test steps repeatedly executed and a low &lt;code&gt;ROI&lt;/code&gt;. As projects and personnel change, uncontrollable factors inevitably introduce more issues; a common scenario involves modifying a field output from Interface A, which then impacts the results of Interface B. With each release, risk accumulates.&lt;/p&gt;
&lt;h2 id=&#34;theoretical-knowledge&#34;&gt;Theoretical Knowledge
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;How to Measure the Value of Automation?&lt;/strong&gt;
An automation testing ROI = (Manual Execution Time) * (Number of Runs) / (Development Cost + Maintenance Cost)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Which Features Should Be Automated?&lt;/strong&gt;
Frequently used features that are unlikely to change. Writing automated test code for this type of interface yields the highest returns.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Why Choose This Timing to Drive Automation Testing?&lt;/strong&gt;
Not appropriate near project launch – distant water doesn’t quench immediate thirst; automation is a long-term return model. Most suitable when the project is already in &lt;strong&gt;production environment&lt;/strong&gt; and within a stable release cycle.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;framework-selection&#34;&gt;Framework Selection
&lt;/h2&gt;&lt;p&gt;Given the task of automation testing without prior practical experience, a typical starting point is to open a search engine and find tools and frameworks that can be used with the current system’s &lt;strong&gt;technology stack&lt;/strong&gt;, review the user manuals, and get started. If you can immediately find a suitable tool, congratulations, &lt;strong&gt;perfect start&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;Let me preface this by saying I might be wrong. After reviewing relevant materials, it&amp;rsquo;s not about whether it doesn&amp;rsquo;t exist; rather, the frameworks themselves are too complex and consume excessive resources. For beginners, what’s needed is something small, streamlined, and concise. Consulting with colleagues in the testing group led to the suggestion of a &lt;code&gt;Python&lt;/code&gt; self-built framework – essentially, wrapping existing unit testing frameworks into an automated testing framework.&lt;/p&gt;
&lt;p&gt;Referencing the design thinking for this project: &lt;a class=&#34;link&#34; href=&#34;https://github.com/wintests/pytestDemo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/wintests/pytestDemo&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;why-use-a-framework&#34;&gt;Why Use a Framework?
&lt;/h2&gt;&lt;p&gt;Services have multiple different deployment environments – development, testing, and live testing. The purpose of a framework is to act as an abstraction layer, separating test cases and data. This allows for configuring different case data based on the specific environment configuration, and also supports shared data.&lt;/p&gt;
&lt;p&gt;The core logic is focused on increasing the utilization of automation. When scenarios become more complex, the data between different environments is completely unrelated – there’s no connection whatsoever. Simply add a &lt;code&gt;label&lt;/code&gt; tag when defining case data to specify the supported environment.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://time.geekbang.org/column/article/496850&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Best Value Automation Testing&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Why Do We Need to Learn a New Language?</title>
        <link>https://ttf248.life/en/p/why-learn-a-new-language/</link>
        <pubDate>Thu, 04 Aug 2022 11:27:30 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/why-learn-a-new-language/</guid>
        <description>&lt;p&gt;Starting from my academic years, I’ve been working with &lt;code&gt;C++&lt;/code&gt; for over ten years. So, why do I need to learn other programming languages?&lt;/p&gt;
&lt;p&gt;Work experience: Lacking experience in elegant module design, &lt;code&gt;C++&lt;/code&gt; syntax is freeform. Learning other languages helps me guide the development of more elegant designs.&lt;/p&gt;
&lt;p&gt;I often use them when writing some tools. The design principles for low-level libraries and business modules are also becoming clearer.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Visual Studio Compilation Character Set [Converted]</title>
        <link>https://ttf248.life/en/p/visual-studio-compilation-character-set-translation/</link>
        <pubDate>Thu, 04 Aug 2022 10:51:43 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/visual-studio-compilation-character-set-translation/</guid>
        <description>&lt;p&gt;&lt;code&gt;C++&lt;/code&gt; cross-platform development. Commonly encountered on Chinese operating systems: &lt;code&gt;error C2001&lt;/code&gt;: constant contains a newline character&lt;/p&gt;
&lt;h2 id=&#34;visual-studio&#34;&gt;Visual Studio
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;cmake&lt;/code&gt; organizes project compilation scripts, generating a temporary solution under the &lt;code&gt;windows&lt;/code&gt; system for development. The reason for cross-platform compatibility is that the file encoding is chosen as &lt;code&gt;utf-8&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Reference materials thoroughly explained the causes of the problem from first principles.&lt;/p&gt;
&lt;p&gt;Regarding encoding, &lt;code&gt;MSVC&lt;/code&gt; has dedicated compilation options &lt;code&gt;/source-charset&lt;/code&gt; and &lt;code&gt;/execution-charset&lt;/code&gt;. The former indicates the encoding of the file itself, and the latter indicates what encoding the byte sequence within the compiled character array is. Encoding issues can generally be solved using these two options.&lt;/p&gt;
&lt;p&gt;For example, the &lt;code&gt;windows&lt;/code&gt; &lt;code&gt;cmd&lt;/code&gt; console defaults to displaying &lt;code&gt;gbk&lt;/code&gt; encoding, but since the code file itself is &lt;code&gt;utf-8&lt;/code&gt;, and it&amp;rsquo;s not convenient to directly change it to &lt;code&gt;gbk&lt;/code&gt; due to cross-platform considerations, we wouldn’t include writing conversion code for different platforms here. On &lt;code&gt;Win10&lt;/code&gt;, you can set these two compilation options to &lt;code&gt;/source-charset:utf-8 /execution-charset:gbk&lt;/code&gt;, indicating that the compiler should read in with &lt;code&gt;UTF-8&lt;/code&gt; encoding and then convert it to &lt;code&gt;GBK&lt;/code&gt; for storage within the array. This allows direct use of &lt;code&gt;printf&lt;/code&gt; to display Chinese characters normally in the &lt;code&gt;cmd&lt;/code&gt; console.&lt;/p&gt;
&lt;h2 id=&#34;cmake-for-visual-studio-setup&#34;&gt;CMake for Visual Studio Setup
&lt;/h2&gt;&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/146543940&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://zhuanlan.zhihu.com/p/146543940&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Quickly calculate folder size on the Windows platform</title>
        <link>https://ttf248.life/en/p/windows-platform-quick-folder-size-statistics/</link>
        <pubDate>Mon, 01 Aug 2022 19:54:18 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/windows-platform-quick-folder-size-statistics/</guid>
        <description>&lt;p&gt;The Linux platform is very simple: &lt;code&gt;du -sh *&lt;/code&gt; – just one line of code solves the problem. What about Windows? With many disks and a desire to clean up, with numerous files, the system’s built-in Resource Manager is too slow to calculate folder sizes, making you want to give up.&lt;/p&gt;
&lt;h2 id=&#34;everything&#34;&gt;Everything
&lt;/h2&gt;&lt;p&gt;For developers working on the &lt;code&gt;windows&lt;/code&gt; platform, you probably haven&amp;rsquo;t personally used &lt;code&gt;everything&lt;/code&gt;, and should at least have heard of it. Its search speed far exceeds that of the built-in file explorer. Given that system-level support for fast indexing exists, we can certainly find similar tools that build file indexes while also tracking file sizes.&lt;/p&gt;
&lt;h2 id=&#34;wiztree&#34;&gt;WizTree
&lt;/h2&gt;&lt;p&gt;Website: &lt;a class=&#34;link&#34; href=&#34;https://www.diskanalyzer.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.diskanalyzer.com/&lt;/a&gt;
Use the standard installation method or the green version to unzip and run.
It’s fast, with a wide variety of data display types – the left side features a tree diagram mode, the right side displays file types, and there&amp;rsquo;s also graphical visualization available at the bottom of the software.&lt;/p&gt;
&lt;h2 id=&#34;spacesniffer-update-2023-no-longer-maintained&#34;&gt;SpaceSniffer (Update 2023 No Longer Maintained)
&lt;/h2&gt;&lt;p&gt;Software Website: &lt;a class=&#34;link&#34; href=&#34;http://www.uderzo.it/main_products/space_sniffer/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://www.uderzo.it/main_products/space_sniffer/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The operation is very simple – select the corresponding drive letter, and the software will display folder sizes in a graphical way, with larger volumes resulting in larger matrices in the images.  Other operations are easily understood by simply clicking on them. It supports inputting filter conditions for files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;File size filtering&lt;/li&gt;
&lt;li&gt;File date filtering&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/windows-platform-quick-folder-size-statistics/space_sniffer.gif&#34;
	width=&#34;960&#34;
	height=&#34;540&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Basic Usage&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/windows-platform-quick-folder-size-statistics/advance.gif&#34;
	width=&#34;960&#34;
	height=&#34;540&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Advanced Usage&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://moe.best/software/spacesniffer.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://moe.best/software/spacesniffer.html&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>How to Copy Webpage Stylesheets (CSS): Element Inspector</title>
        <link>https://ttf248.life/en/p/how-to-copy-webpage-css-element-inspection/</link>
        <pubDate>Sun, 31 Jul 2022 23:36:48 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/how-to-copy-webpage-css-element-inspection/</guid>
        <description>&lt;p&gt;Static blog themes, the mainstream is based on foreign templates, modified and adjusted without much consideration for Chinese content layout.&lt;/p&gt;
&lt;h2 id=&#34;main-text&#34;&gt;Main Text
&lt;/h2&gt;&lt;p&gt;About half a month ago, I adjusted the blog’s stylesheet – as I’ve been developing backend services for many years, I’m a pure newbie in frontend. After struggling with it for half a day, the design wasn&amp;rsquo;t very reasonable. Suddenly an idea struck me: I looked at the technical blogs I often read – infoq and OpenChina – and their layouts look really good. Could I borrow some of those? After reviewing the source files, I got lost trying to locate the relevant elements.&lt;/p&gt;
&lt;p&gt;Frontend developers might be laughing at this point… I didn’t understand how to locate the specified elements, but that&amp;rsquo;s okay; I have plenty of free time on weekends, so I stopped to think about it. It reminded me of when I wrote Python crawlers – I had used something similar then.&lt;/p&gt;
&lt;h3 id=&#34;element-inspection&#34;&gt;Element Inspection
&lt;/h3&gt;&lt;p&gt;That’s right, it’s the built-in element inspection tool in the browser – copying style sheets, locating specific elements, all done in minutes. &lt;code&gt;selector&lt;/code&gt; to locate elements, &lt;code&gt;hugo&lt;/code&gt; to create a ‘user define css’&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Copy element&lt;/li&gt;
&lt;li&gt;Copy outerHTML&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Copy selector&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Copy JS path&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Copy styles&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Copy XPath&lt;/li&gt;
&lt;li&gt;Copy full XPath&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Editing Extremely Large Files on the Windows Platform: EmEditor (Text Editor)</title>
        <link>https://ttf248.life/en/p/windows-platform-editing-large-files-emeditor-text-editor/</link>
        <pubDate>Sun, 31 Jul 2022 23:21:24 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/windows-platform-editing-large-files-emeditor-text-editor/</guid>
        <description>&lt;p&gt;The Shanghai GuoAn database incident, which caused a huge stir within the black hacking circles, remains unclear whether it’s true or false. Let&amp;rsquo;s see what we remember in two years and look back on it then. Based on past experience, I updated a batch of local social engineering databases, and I came across a massive SQL file: 17.9G. A standard text editor couldn’t even preview it, let alone open it. Chatting with netizens, someone mentioned EmEditor.&lt;/p&gt;
&lt;h2 id=&#34;text&#34;&gt;Text
&lt;/h2&gt;&lt;p&gt;Website: &lt;a class=&#34;link&#34; href=&#34;https://www.emeditor.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.emeditor.com/&lt;/a&gt;
I took a look at it over the weekend and found it quite convenient. The design supports editing large files, and when sufficient memory is available, the entire file is loaded into memory, resulting in fast search and editing speeds. It also supports splitting files.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Adding a code copy button – seemingly simple things</title>
        <link>https://ttf248.life/en/p/add-code-copy-button/</link>
        <pubDate>Fri, 25 Feb 2022 01:23:39 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/add-code-copy-button/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;Spent four hours trying to figure this out, and when I saw the sentence, it was hilarious. How could it have taken so long? When I finally looked at the time, it was only three hours.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This was the first draft of the year 2022, and it wasn&amp;rsquo;t complicated – exactly as the title said. (At that time, I was still very young), I thought simply copying &lt;a class=&#34;link&#34; href=&#34;https://ouuan.github.io/post/from-hexo-to-hugo/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;作业&lt;/a&gt; would be enough, putting it in my favorites folder, and dragging it out for over a month before finally remembering the task.&lt;/p&gt;
&lt;p&gt;When migrating to &lt;code&gt;hugo&lt;/code&gt;, I always felt that the plugins were too few, couldn&amp;rsquo;t copy code, which made copying notes from Evernote to the blog very cumbersome, seriously hindering my motivation for writing a casual blog.&lt;/p&gt;
&lt;h2 id=&#34;foreword&#34;&gt;Foreword
&lt;/h2&gt;&lt;p&gt;First, carefully read the original author’s draft, read it through completely and flip through the author&amp;rsquo;s introduction. Wow, I encountered a big shot – Tsinghua University undergraduate, has been exposed to computers early on. Let’s see, just a facade, let’s take a look at this blog first, completely forgot what he was supposed to do. Also browse the author’s &lt;code&gt;Github&lt;/code&gt; repository, this modified ‘even’ theme is much more beautiful than now and has many new features, let&amp;rsquo;s get started, first merge the related code into the current one.
&lt;img src=&#34;https://ttf248.life/p/add-copy-button-for-simple-task/2022-02-25-02-08-19.png&#34;
	width=&#34;215&#34;
	height=&#34;150&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;143&#34;
		data-flex-basis=&#34;344px&#34;
	
&gt; &lt;img src=&#34;https://ttf248.life/p/add-copy-button-for-simple-task/2022-02-25-02-08-40.png&#34;
	width=&#34;217&#34;
	height=&#34;167&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;129&#34;
		data-flex-basis=&#34;311px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;new-features-view-article-history-associate-submission-records&#34;&gt;New Features: View Article History, Associate Submission Records
&lt;/h3&gt;&lt;p&gt;The effect is still good, and you can experience it by dragging it to the end of the article.&lt;/p&gt;
&lt;p&gt;Before taking action, I didn’t carefully examine the author&amp;rsquo;s original repository history, assuming a simple merge would fix everything. In the end, I merged a huge amount of code with numerous conflicts and N times of mindless overwriting – all of which were frontend and rendering template codes. I took the version I needed as the standard.&lt;/p&gt;
&lt;p&gt;Repository address: &lt;a class=&#34;link&#34; href=&#34;https://github.com/TianlongXiang/hugo-theme-even&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/TianlongXiang/hugo-theme-even&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A Chinese pitfall: if &lt;code&gt;git&lt;/code&gt; doesn’t adjust this parameter, the generated one won&amp;rsquo;t get the current article’s &lt;code&gt;commit hash&lt;/code&gt;, causing the history link generation to fail. When generating the complete historical record of the article, you also need to modify the automatic integration script and remember to pull the entire historical record of the current repository.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[feat: Attempt to pull the full GitHub repository to dynamically update the last modification record of the article](&lt;a class=&#34;link&#34; href=&#34;https://github.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;new-features-view-article-history-associate-submission-records-1&#34;&gt;New Features: View Article History, Associate Submission Records
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/TianlongXiang/TianlongXiang.github.io/commit/1b5d719966737f16a8c67880370dc2722adea0b3&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;chore: Path contains Chinese, Hugo GitInfo needs to enable this setting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;style-adjustments&#34;&gt;Style Adjustments
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Adjust website content width, the previous design was suitable for both mobile and desktop devices; in reality, no one actually viewed it on their phones, and I personally view it on my computer.&lt;/li&gt;
&lt;li&gt;The directory bar supports automatic expansion/collapse.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;body&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;Referenced the &lt;code&gt;ouuan&lt;/code&gt; code records for half an hour and still couldn&amp;rsquo;t quite understand how to increase the copy button.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Time travel, a month later, it came back to this matter again&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;body-1&#34;&gt;Body
&lt;/h2&gt;&lt;p&gt;Since I didn’t understand this assignment, I switched to copying from another one – it&amp;rsquo;s always easier to understand when you copy. The results of my searches were surprisingly helpful; a post on the official &lt;code&gt;hugo&lt;/code&gt; forum mentioned how to add a copy button. Going there to check, the logic was clear. It was baffling until I returned to the site and saw that the styling generated by &lt;code&gt;even&lt;/code&gt; differed from the description in the documentation – this part was quite complicated. I’m just going to record it simply.&lt;/p&gt;
&lt;p&gt;Because I don&amp;rsquo;t really understand front-end development, when I don&amp;rsquo;t know something, I open my browser’s “Inspect” tool and analyze the code, relying on the style information on the right side to slowly figure out the logic; I didn’t understand &lt;code&gt;JavaScript&lt;/code&gt;, so I added some logs to the console. There were many things I didn’t understand at first. Taking a deep breath and carefully sorting through and breaking down the logic, you can always find a solution.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;The &lt;code&gt;pre&lt;/code&gt; node has multiple instances; here it refers to a single code block, which the theme rendered with line numbers, resulting in two copies when the copy button is used.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;I wanted to disable the theme&amp;rsquo;s built-in code highlighting, but I’m unfamiliar with these theme settings.&lt;/li&gt;
&lt;li&gt;I consulted the &lt;code&gt;hugo&lt;/code&gt; website for resources and read a bit, learning that there’s a &lt;code&gt;markup&lt;/code&gt; setting to control code highlighting.&lt;/li&gt;
&lt;li&gt;Adjusting the configuration file didn’t work; the rendering was different from what I expected.&lt;/li&gt;
&lt;li&gt;I discovered this set of settings &lt;code&gt;pygmentsOptions&lt;/code&gt; and continued to consult documentation, adjusting the settings, starting by removing line numbers.&lt;/li&gt;
&lt;li&gt;I configured a custom &lt;code&gt;css&lt;/code&gt; stylesheet and a custom &lt;code&gt;js&lt;/code&gt; script.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;body-2&#34;&gt;Body
&lt;/h2&gt;&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;Since I’ve been doing so much, my brain suddenly thought of a color palette I saw recently that looked good, and changed the button styles: Let&amp;rsquo;s go with Chinese-style sky blue.&lt;/li&gt;
&lt;/ol&gt;
&lt;img class=&#34;special-img-class&#34; style=&#34;width:20%&#34; src=&#34;2022-02-25-02-01-22.png&#34; /&gt;
&lt;img class=&#34;special-img-class&#34; style=&#34;width:20%&#34; src=&#34;2022-02-25-02-01-33.png&#34; /&gt;
ouuan spent four hours on this, and when I saw that sentence, I even thought it was funny. How could it take so long? When I looked at the time, it was only three hours.
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://ouuan.github.io/post/from-hexo-to-hugo/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ouuan.github.io/post/from-hexo-to-hugo/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://gohugobrasil.netlify.app/content-management/syntax-highlighting/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://gohugobrasil.netlify.app/content-management/syntax-highlighting/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://gohugo.io/getting-started/configuration-markup#highlight&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://gohugo.io/getting-started/configuration-markup#highlight&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;reference-links&#34;&gt;Reference Links
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.dannyguo.com/blog/how-to-add-copy-to-clipboard-buttons-to-code-blocks-in-hugo/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.dannyguo.com/blog/how-to-add-copy-to-clipboard-buttons-to-code-blocks-in-hugo/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>chaos-engineering</title>
        <link>https://ttf248.life/en/p/chaos-engineering/</link>
        <pubDate>Wed, 28 Jul 2021 14:35:07 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/chaos-engineering/</guid>
        <description>&lt;p&gt;A pattern of disruption to test system stability.&lt;/p&gt;
&lt;h2 id=&#34;main-text&#34;&gt;Main Text
&lt;/h2&gt;&lt;p&gt;The domestic internet industry is always fond of playing with new things, often introducing terms that most people wouldn’t be able to guess what they are.
After reading some articles, this definition specifically for the early stages of Chaos Engineering is relatively easy to accept:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Early exploration of Chaos Engineering has actually been ongoing within the industry, previously existing under the guise of fault testing and disaster recovery exercises. As microservice architectures continue to develop and distributed systems grow increasingly vast, Chaos Engineering has begun to emerge and gain increasing importance. Following Netflix’s formal proposal of the Chaos Engineering concept, related theories have also rapidly enriched. Netflix&amp;rsquo;s practices have also demonstrated the significant impact Chaos Engineering has on stability.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;reference-links&#34;&gt;Reference Links
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.infoq.cn/article/gsqtykoa3uvrtqi1kkmo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ByteDance Chaos Engineering Practices Summary&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>kubernetes-pause-pod</title>
        <link>https://ttf248.life/en/p/kubernetes-pause-pod/</link>
        <pubDate>Mon, 12 Jul 2021 11:23:09 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/kubernetes-pause-pod/</guid>
        <description>&lt;p&gt;The Deployment controller implements a crucial function within a Kubernetes cluster: the ability to horizontally scale and shrink Pods. This capability was essential for traditional cloud-era platforms.&lt;/p&gt;
&lt;p&gt;Encountering a business scenario where you need to modify data in a database, restarting Pod nodes after adjustments. However, during Pod operation, table fields are continuously being updated, requiring temporary pausing of application updates to the tables, restoring the Pod after adjusting the data.&lt;/p&gt;
&lt;p&gt;Besides brute force deletion of the Deployment, are there other ways to achieve a similar pause effect?&lt;/p&gt;
&lt;p&gt;Before seeing the answer, many people might not have realized it, and upon seeing the answer, they would smile knowingly, their brains hadn&amp;rsquo;t twisted, and their thinking remained stuck in the era of directly operating processes, thinking about directly manipulating business processes.&lt;/p&gt;
&lt;h2 id=&#34;reference-links&#34;&gt;Reference Links
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://stackoverflow.com/questions/54821044/how-to-stop-pause-a-pod-in-kubernetes&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;How to Stop/Pause a Pod in Kubernetes&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>docker-two-three-things</title>
        <link>https://ttf248.life/en/p/docker-two-three-things/</link>
        <pubDate>Thu, 21 Jan 2021 09:26:07 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/docker-two-three-things/</guid>
        <description>&lt;p&gt;Having worked with CentOS for many years, content may not apply to macOS or Ubuntu users in some cases.&lt;/p&gt;
&lt;p&gt;You can refer to the documentation from Tsinghua University for installation guidance: &lt;a class=&#34;link&#34; href=&#34;https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation
&lt;/h2&gt;&lt;p&gt;Due to unknown mysterious forces, domestic Docker installation is recommended to set the cloud vendor&amp;rsquo;s repository address. Here we recommend using &lt;strong&gt;Alibaba Cloud&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;set-repository-source-address&#34;&gt;Set Repository Source Address
&lt;/h3&gt;&lt;h3 id=&#34;deploy-the-latest-version&#34;&gt;Deploy the Latest Version
&lt;/h3&gt;&lt;p&gt;Docker is a commonly used background service, recommended to be set as startup on boot. The current command applies to CentOS 7.&lt;/p&gt;
&lt;h3 id=&#34;deploying-a-specific-version&#34;&gt;Deploying a Specific Version
&lt;/h3&gt;&lt;p&gt;The releases of &lt;code&gt;kubernetes&lt;/code&gt; and &lt;code&gt;docker&lt;/code&gt; are not fully synchronized. If you need to deploy &lt;code&gt;kubernetes&lt;/code&gt; subsequently, please refer to the &lt;code&gt;kubernetes&lt;/code&gt; deployment instructions and install a specific version of &lt;code&gt;docker&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;add-docker-permissions-for-regular-users&#34;&gt;Add Docker Permissions for Regular Users
&lt;/h3&gt;&lt;h3 id=&#34;uninstall&#34;&gt;Uninstall
&lt;/h3&gt;&lt;h2 id=&#34;everyday-use&#34;&gt;Everyday Use
&lt;/h2&gt;&lt;h3 id=&#34;mirror-acceleration&#34;&gt;Mirror Acceleration
&lt;/h3&gt;&lt;p&gt;There’s still an unknown mysterious force causing slow image pulls. At this time, domestic cloud vendors have emerged and provided many acceleration services, which are still recommended – &lt;strong&gt;Alibaba Cloud&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;You can manage your own registered Alibaba Cloud account to obtain this service, which is free. Alibaba Cloud also offers a free image build service.&lt;/p&gt;
&lt;h3 id=&#34;recommended-dashboards&#34;&gt;Recommended Dashboards
&lt;/h3&gt;&lt;h3 id=&#34;common-mirror-image-collection&#34;&gt;Common Mirror Image Collection
&lt;/h3&gt;&lt;h3 id=&#34;common-command-combinations&#34;&gt;Common Command Combinations
&lt;/h3&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.docker.com/engine/reference/commandline/docker/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://docs.docker.com/engine/reference/commandline/docker/&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;View container running status, append the &lt;code&gt;format&lt;/code&gt; parameter to view detailed container information, without focusing on image information.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Stop all containers with one click
Delete all images with one click&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Export Image
Export Image and Compress
Import Image&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Linux Setup JMeter Test Environment</title>
        <link>https://ttf248.life/en/p/linux-setup-jmeter-testing-environment/</link>
        <pubDate>Tue, 22 Dec 2020 10:12:50 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-setup-jmeter-testing-environment/</guid>
        <description>&lt;p&gt;The author has a strong interest in hardware and used JMeter to conduct load testing, documenting the process of deploying JMeter, InfluxDB, and Grafana on CentOS 7. They shared installation and command usage for JMeter, InfluxDB’s features and Docker installation method, as well as simple deployment and configuration for Grafana. They summarized experience and references related to high-performance programming patterns.&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background
&lt;/h2&gt;&lt;p&gt;As widely known, I have a strong interest in hardware. While the test team was using &lt;code&gt;JMeter&lt;/code&gt; to perform load tests and discovered that performance wasn&amp;rsquo;t improving, as a curious individual, I decisively took action to investigate how the company conducted its testing. There’s also a little story: at some point in the distant past, I had read a post on OpenChina detailing how to create more impressive-looking performance test graphs – having visualized &lt;code&gt;TPS&lt;/code&gt; data during tests for the &lt;code&gt;Windows&lt;/code&gt; version. Furthermore, what&amp;rsquo;s the use of setting up a web panel?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Thinking is one thing; actually trying it out reveals the truth.
Don’t use GUI mode for load testing! Only for Test creation and Test debugging.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;background-1&#34;&gt;Background
&lt;/h2&gt;&lt;p&gt;Officially, it’s recommended to obtain test reports via the command line and display them with a GUI, which introduces data errors.  I don&amp;rsquo;t have deep knowledge of JMeter – at least I found a reason to tinker with a &lt;code&gt;Linux&lt;/code&gt; version console panel. The openchinese post’s core component deployment isn’t friendly; you need to follow their WeChat channel to download the required files, and as a millennial, of course I used &lt;code&gt;Docker&lt;/code&gt; instead. Basically, my server is located domestically, and accessing the overseas source addresses is very slow – at least using an image service like Alibaba Cloud has a free acceleration.&lt;/p&gt;
&lt;p&gt;Regarding the installation and deployment of &lt;code&gt;docker&lt;/code&gt;, this will not be detailed here; please refer to previous articles for recommendations.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;The following content focuses on two main areas: setting up the basic test environment components and a simple explanation of each component.&lt;/p&gt;
&lt;h2 id=&#34;jmeter&#34;&gt;JMeter
&lt;/h2&gt;&lt;p&gt;Apache JMeter is a Java-based load testing tool developed by the Apache Software Foundation. It’s used to perform load testing on software, initially designed for web application testing but later expanded to other testing domains. It can be used to test static and dynamic resources such as static files, Java microservices, CGI scripts, Java objects, databases, FTP servers, etc. JMeter can simulate massive loads from various stress categories onto servers, networks, or objects to assess their strength and analyze overall performance. Furthermore, JMeter can perform functional/regression testing on applications by creating scripts with assertions to validate that your program returns the expected results. To maximize flexibility, JMeter allows the use of regular expressions to create assertions. Apache JMeter can be used to perform performance testing of static and dynamic resources (files, Servlets, Perl scripts, Java objects, databases and queries, FTP servers, etc.). It can be used to simulate heavy loads on servers, networks, or objects to test their strength or analyze overall performance under different stress types. You can use it for graphical analysis of performance metrics or for large concurrent load testing of your server/script/object.&lt;/p&gt;
&lt;h3 id=&#34;jmeter-deployment-on-centos7&#34;&gt;JMeter Deployment on CentOS7
&lt;/h3&gt;&lt;p&gt;Install the &lt;code&gt;JDK&lt;/code&gt; runtime environment, download the &lt;code&gt;JMeter&lt;/code&gt; installation package, and configure environment variables.&lt;/p&gt;
&lt;h3 id=&#34;jmeter-commands&#34;&gt;JMeter Commands
&lt;/h3&gt;&lt;p&gt;Finally, it will be connected to the &lt;code&gt;Grafana&lt;/code&gt; dashboard, and you don&amp;rsquo;t need to input the &lt;code&gt;-l&lt;/code&gt; parameter; you can observe data in the &lt;code&gt;web&lt;/code&gt; console.&lt;/p&gt;
&lt;h2 id=&#34;influxdb&#34;&gt;InfluxDB
&lt;/h2&gt;&lt;p&gt;InfluxDB is an open-source distributed time series database written in Go. It requires no external dependencies. The database is now primarily used for storing large volumes of timestamped data, such as DevOps monitoring data, app metrics, IoT sensor data, and real-time analytics data.&lt;/p&gt;
&lt;h3 id=&#34;influxdb-features&#34;&gt;InfluxDB Features
&lt;/h3&gt;&lt;p&gt;InfluxDB’s features can be summarized into the following 9 aspects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Schema-less (Schemaless):&lt;/strong&gt; Can accommodate an arbitrary number of columns;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Metric Retention Time Setting:&lt;/strong&gt;  Allows setting retention times for metrics;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Support for Time-Related Functions:&lt;/strong&gt; Supports functions related to time (such as min, max, sum, count, mean, median, etc.) for convenient statistical analysis;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Storage Policy Support:&lt;/strong&gt; Can be used for data deletion and modification (InfluxDB does not provide direct methods for deleting or modifying data);&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Continuous Query Support:&lt;/strong&gt;  Automatically scheduled sets of queries that run continuously, combined with storage policies to reduce InfluxDB’s system footprint;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Native HTTP Support:&lt;/strong&gt; Built-in HTTP API;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Support for SQL-like Syntax:&lt;/strong&gt; Supports a syntax similar to SQL;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Support for Setting Data Replication Count in Clusters:&lt;/strong&gt; Allows setting the number of replicas for data within clusters;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Support for Periodic Sampling of Data:&lt;/strong&gt;  Writes data to another measurement, facilitating granular data storage.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;influxdb-docker-installation&#34;&gt;InfluxDB Docker Installation
&lt;/h3&gt;&lt;p&gt;&lt;code&gt;docker exec -it influxdb /bin/bash&lt;/code&gt; to enter the container and execute commands, manually creating a database.&lt;/p&gt;
&lt;h3 id=&#34;influxdb-database-and-user-creation&#34;&gt;InfluxDB Database and User Creation
&lt;/h3&gt;&lt;p&gt;Create database: &lt;code&gt;create database jmeter_t2&lt;/code&gt;
View databases: &lt;code&gt;show databases&lt;/code&gt;
Switch to database: &lt;code&gt;use jmeter_t2&lt;/code&gt;
Create user: &lt;code&gt;create user &amp;quot;admin&amp;quot; with password &#39;admin&#39; with all privileges&lt;/code&gt;
View users: &lt;code&gt;show users&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If the user permissions for &lt;code&gt;admin&lt;/code&gt; are displayed as &lt;code&gt;true&lt;/code&gt;, the database setup is complete.&lt;/p&gt;
&lt;h2 id=&#34;grafana&#34;&gt;Grafana
&lt;/h2&gt;&lt;p&gt;When writing test cases, it was found that the chart visualization effect is not really necessary; the &lt;code&gt;tps&lt;/code&gt; data from the interface can be observed when executed from the command line. The primary goal is to understand the internal latency of the program.&lt;/p&gt;
&lt;p&gt;A simple deployment of the Grafana console panel and importing a configuration file to connect with InfluxDB was performed.&lt;/p&gt;
&lt;p&gt;The console supports filtering test results by tags, generally requiring only configuring one &lt;code&gt;InfluxDB&lt;/code&gt; database:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Application Name&lt;/li&gt;
&lt;li&gt;Test Case Name&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/linux-setup-jmeter-testing-environment/Snipaste_2021-03-09_19-44-22.png&#34;
	width=&#34;861&#34;
	height=&#34;357&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;grafana&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;241&#34;
		data-flex-basis=&#34;578px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Due to the sampling interval in the web version, the calculated &lt;code&gt;TPS&lt;/code&gt; and related values are inconsistent with the JMeter aggregated report. Please refer to the following link: &lt;a class=&#34;link&#34; href=&#34;https://www.vinsguru.com/jmeter-real-time-results-influxdb-grafana/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.vinsguru.com/jmeter-real-time-results-influxdb-grafana/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The documentation also describes how to customize the &lt;code&gt;listeners&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;High-performance program patterns invariably are one-loop thread; any locks, enqueueing, and dequeueing will cause unnecessary performance loss.&lt;/li&gt;
&lt;li&gt;The time spent on core business logic is greater than the time spent introducing other code; concurrency can effectively improve efficiency only when the core latency is sufficiently large; otherwise, it’s best to be cautious about introducing other code.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://my.oschina.net/u/4617935/blog/4680856&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;JMeter Series - JMeter + Grafana + InfluxDB Real-time Monitoring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://hub.docker.com/_/influxdb&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;InfluxDB Official Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://hub.docker.com/r/grafana/grafana&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Grafana Official Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://jmeter.apache.org/download_jmeter.cgi&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;JMeter Website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/@jasonli.studio/to-install-apache-jmeter-in-centos7-294bc72a97ba&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;To Install Apache JMeter in CentOS7&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Red Hat and CentOS Lifecycle</title>
        <link>https://ttf248.life/en/p/redhat-centos-lifecycle/</link>
        <pubDate>Tue, 21 Jul 2020 20:02:35 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/redhat-centos-lifecycle/</guid>
        <description>&lt;p&gt;Production environment operating systems, with Red Hat and CentOS being the mainstream choices. The documentation includes links to two system lifecycles and shares experience upgrading from CentOS 8 to CentOS Stream 8.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction
&lt;/h2&gt;&lt;p&gt;In the current domestic environment, Red Hat and CentOS are the mainstream choices for production online operating systems. After experiencing the retirement of Red Hat 6 two years ago, this record specifically documents the official website links for the lifecycles of these two systems.&lt;/p&gt;
&lt;h2 id=&#34;main-content&#34;&gt;Main Content
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://access.redhat.com/support/policy/updates/errata&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Red Hat Enterprise Linux Life Cycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://wiki.centos.org/zh/About/Product&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CentOS Product Specifications&lt;/a&gt;
Red Hat Enterprise Linux (RHEL) and CentOS are the mainstream choices for enterprise servers. RHEL provides stable support and update cycles, suitable for enterprise applications. CentOS as RHEL&amp;rsquo;s community edition, offers similar features and stability but without official support.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;follow-up&#34;&gt;Follow-up
&lt;/h2&gt;&lt;p&gt;When publishing this article, I didn’t expect to update it two years later. Just a few days ago, I upgraded my daily virtual machine from CentOS 8 to CentOS 8 Stream. I can&amp;rsquo;t say much about what to choose in production – I prefer to keep the latest version in my local environment.&lt;/p&gt;
&lt;p&gt;CentOS 8 Stream is a rolling release version that offers faster updates and new features than traditional CentOS, making it suitable for development and testing environments.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Building PCs</title>
        <link>https://ttf248.life/en/p/computer-assembly-tips/</link>
        <pubDate>Sat, 18 Jul 2020 14:33:46 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/computer-assembly-tips/</guid>
        <description>&lt;p&gt;The author has long had an interest in building computers from a young age, and began to delve into hardware assembly after university. They recommended websites for comparing hardware performance and offered purchasing suggestions, including CPU, solid-state drives, hard disk drives, and memory frequencies. They also shared their experience and advice regarding hardware selection and important considerations.&lt;/p&gt;
&lt;h3 id=&#34;wonder--unspeakable&#34;&gt;Wonder – Unspeakable
&lt;/h3&gt;&lt;p&gt;Ever since I was young, I’d dreamed of building my own computer, but unfortunately, economic conditions didn&amp;rsquo;t allow it. Finally, after a lot of hard work, I managed to get to university, and I configured a laptop for portability. If I had to pinpoint the exact time when I started thinking about assembling computers, it would be when I began browsing the library in my hometown. After all, it was a sizable city-level library, with not only an electronic reading room (which I never actually visited – supposedly you were charged by the hour), but also a magazine reading room, where I discovered magazines like &lt;em&gt;Popular Science&lt;/em&gt; and &lt;em&gt;PC Magazine&lt;/em&gt;. For someone who had limited exposure to computers, these were practically divine科普资料 (scientific explanation/learning materials). - When I read about players tackling dungeons, I started thinking about getting my own computer and going to pull monsters myself as the main damage dealer. Seeing the use of black technology, I fantasized about following the instructions in the book and achieving the described effect (regarding the use of hacking tools). Although my high school studies were heavy, with my limited understanding at the time, reading and playing were both necessary – it was a truly innocent and carefree experience. I would make an excuse to go to the library to read, and when nothing else to do, I’d carry a small bag and walk there; the city wasn&amp;rsquo;t that big, so I usually walked to the library.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When I got there, I enjoyed the air conditioning while reading novels, comics, and game magazines, occasionally even delving into more serious books.&lt;/li&gt;
&lt;li&gt;It’s easy for older people to forget things, and the initial spark of the library experience wasn&amp;rsquo;t a surprise. Years later, I couldn’t remember the computer my relatives had assembled during their time – I didn’t know what it was used for.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;wonder--unspeakable-1&#34;&gt;Wonder – Unspeakable
&lt;/h3&gt;&lt;p&gt;Upon entering junior high school, the school offered introductory computer training, and later I transferred schools, where I also gained some exposure to concepts in computer competitions. After reaching high school, I qualified for NOIP once. Speaking of which, we must mention the power of our alumni; the high school’s computer building was donated by alumni and included a computer teaching room plus a library. Back then, it was also the initial wave of China&amp;rsquo;s internet boom. School leaders supported participation in computer competitions as well, considering that several senior classmates had been admitted to key universities through computer science.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I have never reflected on my relationship with computers like this before. It’s no wonder that after graduating, I resolutely switched from automation to the computer industry – the seed had already been planted, and it was simply a matter of an insider not realizing it. Having encountered many things from a young age, I thought I was very skilled, but in reality, I only understood the superficial aspects; my biggest advantage was the initial passion.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;hardware-assembly&#34;&gt;Hardware Assembly
&lt;/h3&gt;&lt;p&gt;Browse sites like Carda, Chiphell, and Zhihu’s computer assembly forums to get a newbie relatively simple list of components they would need for their own machine. After 2019, when purchasing CPUs with limited financial resources, AMD is the preferred choice for higher performance.&lt;/p&gt;
&lt;p&gt;I recommend a commonly used hardware performance comparison website: &lt;a class=&#34;link&#34; href=&#34;https://cpu.userbenchmark.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://cpu.userbenchmark.com/&lt;/a&gt;. For pricing, you can compare it to the US versions available on Xianyu (a Chinese online marketplace). True experts can go to Xianyu to find secondhand items, which can be significantly cheaper. If you’re not very familiar with this, I don&amp;rsquo;t recommend buying from Xianyu; I purchased fake memory, although I haven&amp;rsquo;t found any issues using it so far, and I’m not entirely sure about its specifications – the model and parameters don’t match at all.&lt;/p&gt;
&lt;h4 id=&#34;sn550-vs-sn750&#34;&gt;SN550 VS SN750
&lt;/h4&gt;&lt;p&gt;The difference between the SN550 1TB and the SN750 1TB is that they consistently read and write slower by a factor of two – one reads at 850MB, while the other reads at 1.6GB. However, for everyday use, there’s no noticeable difference because both support 4K equally. Of course, I&amp;rsquo;m referring to the 1TB capacity SN550; speeds are significantly slower in sequential read/write operations for the 500G and 250G versions. In my opinion, if you&amp;rsquo;re not a spendthrift, buying the SN550 is sufficient – my main reason for not purchasing it wasn’t its sequential read/write speed, but rather that it only comes in a 1TB capacity, while the SN750 offers 2TB. For me, considering I don’t want to expand further, my motherboard&amp;rsquo;s M.2 NVMe interface is more valuable than these SSD differences.&lt;/p&gt;
&lt;p&gt;Based on consensus from online users, purchasing a conversion board – such as the B150 motherboard – can also support M.2 SSDs.&lt;/p&gt;
&lt;h4 id=&#34;hard-disk-drive-selection&#34;&gt;Hard Disk Drive Selection
&lt;/h4&gt;&lt;p&gt;Currently, the prices of hard disk drives are relatively stable. For users with large storage needs, it is necessary to select a suitable mechanical hard drive. We recommend enterprise-grade hard drives for users who frequently download resources. Common ones include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Western Blue Discs&lt;/li&gt;
&lt;li&gt;Seagate Exos&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Large capacity mechanical hard drives should be partitioned, and frequent download operations should be fixed on a specific partition. If bad sectors appear later, they can be concentrated in one partition, and the current partition can be discarded, which can effectively extend the lifespan of the mechanical hard drive.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Seagate series &lt;a class=&#34;link&#34; href=&#34;https://www.seagate.com/cn/zh/enterprise-storage/exos-drives/exos-e-drives/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;official introduction&lt;/a&gt;
&lt;img src=&#34;https://ttf248.life/Seagate_Exos1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Seagate Enterprise Hard Drive Overview&#34;
	
	
&gt;
&lt;img src=&#34;https://ttf248.life/Seagate_Exos2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Seagate Enterprise Hard Drive Overview&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;memory-frequency&#34;&gt;Memory Frequency
&lt;/h4&gt;&lt;p&gt;From a daily usage perspective, frequency doesn&amp;rsquo;t have a significant impact on performance.
&lt;img src=&#34;https://ttf248.life/memory.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Memory timing&#34;
	
	
&gt; &lt;img src=&#34;https://ttf248.life/yan_yu_memory.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Yan Yu memory&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;Memory timings (also known as RAM timings) are four parameters that describe the performance of Synchronous Dynamic Random Access Memory (SDRAM): CL, TRCD, TRP, andTRAS, measured in clock cycles. They are typically written as four numbers separated by hyphens, such as 7-8-8-24. The fourth parameter (RAS) is often omitted, and sometimes a fifth parameter is added: Command rate (command rate), usually 2T or 1T, also written as 2N or 1N. These parameters specify the latency (delay time) that affects the speed of random access memory. Lower numbers generally indicate better performance. The final determining element for system performance is the actual latency time, typically measured in nanoseconds. When converting memory timing to actual latency, it’s crucial to note that it’s measured in clock cycles. Without knowing the clock cycle time, you cannot determine if one set of numbers is faster than another.&lt;/p&gt;
&lt;h4 id=&#34;memory-frequency-1&#34;&gt;Memory Frequency
&lt;/h4&gt;&lt;p&gt;For example, the clock frequency of DDR3-2000 memory is 1000 MHz, with a clock cycle of 1 ns. Based on this 1 ns clock, a CL7 value gives an absolute latency of 7 ns. A faster DDR3-2666 (clocking at 1333 MHz, with each cycle 0.75 ns) might use a larger CL9 to produce a shorter absolute latency of 6.75 ns.
Modern DIMMs include a Serial Presence Detect (SPD) ROM chip containing recommended memory timings for auto-configuration. The PC&amp;rsquo;s BIOS may allow users to adjust timings to improve performance (with the risk of instability), or in some cases, increase stability (such as using suggested timings).
Note: Memory bandwidth is measured as throughput and is typically limited by transfer rate rather than latency. By interleaving multiple internal banks of SDRAM, it’s possible to transmit data at peak rates continuously. - This may increase bandwidth at the cost of increased latency. Specifically, each new generation of DDR memory has a higher transfer rate but with no significant change in absolute latency, particularly for the initial batches of new products from the market, which often exhibit longer delays than previous generations.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Even with increased memory latency, increasing memory bandwidth can improve the performance of multi-processor or multi-threaded computer systems. Higher bandwidth will also boost the performance of integrated graphics cards that do not have dedicated video memory.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;memory_timing_parameter_explanation.png&#34; &gt;Memory Timing Parameter Explanation&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;references&#34;&gt;References
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Memory_time_series_parameter&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Memory Time Series Parameter Explanation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Website Acceleration and Domain Settings</title>
        <link>https://ttf248.life/en/p/website-acceleration-and-domain-setup/</link>
        <pubDate>Sat, 20 Jun 2020 10:36:27 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/website-acceleration-and-domain-setup/</guid>
        <description>&lt;p&gt;Due to slow access to GitHub Pages from within the country, the author applied for a personal domain and purchased CDN acceleration services from a domestic cloud host provider. During configuration, the author encountered an issue where the www subdomain could not be accessed, which was ultimately resolved by deleting the generic domain DNS record and setting up a second-level domain separately. The author also shared the principles and configuration experience of CDN acceleration, as well as attempts and lessons learned using Nginx reverse proxy.&lt;/p&gt;
&lt;h3 id=&#34;background&#34;&gt;Background
&lt;/h3&gt;&lt;p&gt;The website is hosted on GitHub Pages, and due to some well-known reasons, accessing GitHub Pages internally can be slow. Therefore, I applied for a personal domain name and purchased CDN acceleration services from a domestic cloud host provider. When configuring the acceleration service, I thought about my development machine, which deployed Docker, frp, k8s, and other services – all of these had accompanying dashboards. Following the principle of not wasting anything, I configured several reverse proxies, all with second-level domain names.&lt;/p&gt;
&lt;p&gt;When I was happily using the second-level domain names, I suddenly discovered that the www subdomain could no longer be accessed. In Aliyun, I configured DNS to resolve both &lt;a class=&#34;link&#34; href=&#34;https://www.xiangtianlong.com&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;www.xiangtianlong.com&lt;/a&gt; and xiangtianlong.com, and before enabling CDN acceleration, both domains were working normally. When configuring CDN acceleration, due to a large number of second-level domains, we enabled wildcard domain rules and unified routing them to the development machine. As a result, the ‘www’ second-level domain also went down – yes, you read that right, the ‘www’ prefix is indeed a second-level domain. The actual website is deployed on GitHub Pages, and the development machine has no cached website information.&lt;/p&gt;
&lt;p&gt;As for why the site wasn&amp;rsquo;t deployed to the development machine, it was because it was a static blog, paired with GitHub’s provided action that automatically integrates publishing – seriously delicious!&lt;/p&gt;
&lt;h3 id=&#34;domain&#34;&gt;Domain
&lt;/h3&gt;&lt;p&gt;Non-professional web development, the understanding of domains does not involve SEO or cross-origin issues. As a blog site, a bare domain easily highlights the blogger&amp;rsquo;s site, such as myself who uses Chinese Pinyin as my domain name, and given that mobile access is now more prevalent, it’s preferable to input fewer characters.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Keyboard shortcuts can be used on desktop to avoid entering “www” and “com”.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;cdn&#34;&gt;CDN
&lt;/h3&gt;&lt;p&gt;I&amp;rsquo;ve used both Alibaba Cloud and Tencent Cloud, and it’s easy for newcomers to get started. Tencent Cloud also has separate video explanations of the related concepts. The principle of CDN acceleration is similar to that of a JD.com warehouse: new products are shipped in advance to warehouses across China, and when delivery requests are triggered, they are distributed locally.&lt;/p&gt;
&lt;p&gt;Origin Address: The address where the original website resources are stored.&lt;/p&gt;
&lt;p&gt;Cache file settings: Using F12 in your browser’s developer console to analyze static and dynamic resources.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;All 0 days validity&lt;/li&gt;
&lt;li&gt;&lt;code&gt;.php;.jsp;.asp;.aspx&lt;/code&gt; 0 days validity&lt;/li&gt;
&lt;li&gt;&lt;code&gt;.jpg;.png;.js;.css;.woff2&lt;/code&gt; 1 day validity&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Tencent Cloud configuration rules:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You can configure up to 10 cache expiration rules.&lt;/li&gt;
&lt;li&gt;The priority of multiple cache expiration rules is bottom-first.&lt;/li&gt;
&lt;li&gt;Cache expiration time can be set up to a maximum of 365 days.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;miserable-confession&#34;&gt;Miserable Confession
&lt;/h3&gt;&lt;p&gt;I had never used Nginx before, assuming I could figure out reverse proxy configuration by simply searching for website information. The result was quite chaotic; I struggled for half a day without even getting a 302 redirect to work. So, I decided to take a brute-force approach – deleting wildcard domain resolution patterns in DNS and setting up individual second-level domains. Suddenly, I noticed that Alibaba Cloud DNS had a &amp;ldquo;Display URL Redirect&amp;rdquo; feature, which worked perfectly as a 302 redirect.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;After setting the first second-level domain normally, when I tried to set the second one, it didn&amp;rsquo;t work, and I almost lost my mind.  I waited for a while, and then it suddenly started working – apparently, Alibaba Cloud DNS sometimes has hiccups with its DNS propagation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;references&#34;&gt;References
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.zhihu.com/question/20414602&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Why are more and more website domain names not prefixed with &amp;ldquo;www&amp;rdquo;?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cloudxns.net/Support/detail/id/918.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;What&amp;rsquo;s the difference between domains with and without “www”?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://gythialy.github.io/Docker-nginx-reverse-proxy/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Docker Nginx Reverse Proxy Setup&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Blog IDE Environment and Ramblings</title>
        <link>https://ttf248.life/en/p/blog-ide-environment-and-ramblings/</link>
        <pubDate>Tue, 31 Mar 2020 13:54:27 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/blog-ide-environment-and-ramblings/</guid>
        <description>&lt;p&gt;This article introduces the basic concepts of Markdown and its applications in various software, recommends using VSCode as an IDE, and lists recommended plugins. The author shares their experience switching from Hexo to Hugo, emphasizing Hugo’s flexibility and customization capabilities. Finally, it provides some suggestions for quickly getting started with new technologies and shares a trick for resolving the issue of Hugo theme styles not updating.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction
&lt;/h2&gt;&lt;h3 id=&#34;markdown&#34;&gt;Markdown
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;A lightweight markup language that allows people to write documents in an easy-to-read and -write plain text format.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;markdown-1&#34;&gt;Markdown
&lt;/h3&gt;&lt;p&gt;Detailed Markdown syntax will not be elaborated upon in this document. We recommend an ebook, &lt;a class=&#34;link&#34; href=&#34;https://markdown-zh.readthedocs.io/en/latest/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;click here&lt;/a&gt;. Many software applications on the market now support MD as a writing format. The csdn blog system has launched an online editor that supports MD syntax; the first time you use it, there is a default introduction article about MD syntax, which I think is quite good. iNotes added support for MD notes in 2018, with various MD markers in the shortcut bar, and it&amp;rsquo;s almost as easy to use as editing a regular article. The overall interaction process is friendly to beginners.&lt;/p&gt;
&lt;h3 id=&#34;ide-recommendations&#34;&gt;IDE Recommendations
&lt;/h3&gt;&lt;p&gt;When writing this article, it’s already 2020 – you’ve undoubtedly heard of VS Code, after all, anyone thinking about using Git Page to build a blog system is an industry professional. In the early years, Sublime and Atom were also good choices. With two years of promotion from the open-source community, VS Code has developed rapidly and has gradually become the preferred choice for newcomers.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The relationship between Microsoft’s giant and the open-source community has successfully transitioned into a honeymoon phase: embracing open source. Our company has also actively introduced the Java ecosystem in recent two years, meaning that in business development, Java&amp;rsquo;s ecosystem is currently very fragrant domestically.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;vs-code-plugin-recommendations&#34;&gt;VS Code Plugin Recommendations
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/blog-ide-environment-and-ramblings/2020-03-31-14-07-17.png&#34;
	width=&#34;310&#34;
	height=&#34;306&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Plugin List&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;101&#34;
		data-flex-basis=&#34;243px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;All plugins have their own Readme files, introducing basic usage, core functions, and some authors even provide dynamic effect demonstration images.
&lt;code&gt;Paste Image&lt;/code&gt;, combined with Hugo&amp;rsquo;s image plugin method, is very convenient for importing images.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Don’t remember the shortcuts, open the VS Code shortcut management menu, search for “md”, read it several times; review it again to look at the plugin usage instructions.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;hugo&#34;&gt;Hugo
&lt;/h2&gt;&lt;p&gt;I switched from Hexo to Hugo, as I love tinkering – it’s just my nature! Ultimately, I couldn&amp;rsquo;t resist the urge to quietly write articles.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Hugo supports placing images and Markdown documents in a single folder.&lt;/li&gt;
&lt;li&gt;The Academic theme supports various article styles in its design.&lt;/li&gt;
&lt;li&gt;Various convenient customization extensions.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;academic&#34;&gt;academic
&lt;/h2&gt;&lt;p&gt;The default website is &lt;code&gt;exampleSite&lt;/code&gt;, and menu introduction uses the &lt;code&gt;#component&lt;/code&gt; method, it’s recommended to use &lt;code&gt;url&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The URL pattern allows navigation links to jump to a single page instead of scrolling on the homepage – this is purely a matter of personal preference.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Styles: Notebooks, Speeches, eBooks&lt;/li&gt;
&lt;li&gt;Flexibility: Customization of overall style and custom CSS styles.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This theme’s Chinese support isn&amp;rsquo;t very complete; primarily from a visual perspective, the font sizes don’t align well with Chinese reading habits. The Hexo development team is largely comprised of Chinese developers, which is an advantage over Hugo in this regard. However, it’s rewarding to do things yourself and customize – browser element auditing. When you locate an element, to find out the CSS style name you need to modify, click &lt;strong&gt;Insert Style Rule Below&lt;/strong&gt; on the sidebar, even with nested CSS layers, you can easily get the node name.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Introduce &lt;code&gt;custom.css&lt;/code&gt;](https://sourcethemes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;academic-1&#34;&gt;academic
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Built-in syntax highlighting settings, &lt;a class=&#34;link&#34; href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/#highlighting-options.&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;official link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h2&gt;&lt;p&gt;The kids are complaining again, saying you talk in such a vague and unclear way, without mentioning any details.&lt;/p&gt;
&lt;p&gt;What I want to say is that with these things, you have enough to work with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Official Manuals&lt;/li&gt;
&lt;li&gt;Plugin Documentation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When quickly getting started with new technologies, it’s recommended to first read the official website documentation, &lt;strong&gt;scanning through&lt;/strong&gt; – not necessarily reading it cover to cover, but at least having a general idea. Search engine results may not always be consistent with the latest version and could potentially mislead you. Similarly, when reviewing a new book, start by looking at the table of contents to understand what the author intends to discuss; sometimes, reading the introduction first is beneficial, especially with translated foreign books where the translator’s preface often covers the core content of the book.&lt;/p&gt;
&lt;h2 id=&#34;easter-eggs&#34;&gt;Easter Eggs
&lt;/h2&gt;&lt;p&gt;Switching the Hugo Academic built-in style and theme, publishing to the site, and accessing it did not result in a change of style. A clever teammate already figured this out – clearing the local browser cache resolved the issue.  It was then that I, with my ingenuity, used Developer Mode (F12), switched to &lt;code&gt;network&lt;/code&gt;, checked “disable cache,” refreshed, and voila!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/blog-ide-environment-and-ramblings/2020-03-31-14-27-15.png&#34;
	width=&#34;399&#34;
	height=&#34;142&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;network&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;280&#34;
		data-flex-basis=&#34;674px&#34;
	
&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>Automatic System Switchover</title>
        <link>https://ttf248.life/en/p/auto-integration-system-switch/</link>
        <pubDate>Sun, 29 Mar 2020 02:11:33 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/auto-integration-system-switch/</guid>
        <description>&lt;p&gt;Use GitHub Actions to automatically deploy your Hugo blog to GitHub Pages and Gitee.&lt;/p&gt;
&lt;h4 id=&#34;background-introduction&#34;&gt;Background Introduction
&lt;/h4&gt;&lt;p&gt;Yesterday while updating the blog, I discovered that the travis service was unavailable. Upon checking the travis webpage, I noticed the progress was stuck during source code retrieval, and a flash of inspiration hit me – I thought about GitHub’s previously launched action service.&lt;/p&gt;
&lt;p&gt;At the time, I was quite busy, and also needed to apply to use action. Now that it has officially gone live, I have some free time over the weekend and wanted to try out a new toy?&lt;/p&gt;
&lt;p&gt;Official documentation can be found by entering the website yourself; this article will not do much more copying and pasting. If you’ve used Kubernetes before, you&amp;rsquo;ll find that the action YAML file configuration is very similar.&lt;/p&gt;
&lt;p&gt;Regarding introductory tutorials or Chinese introduction materials, I recommend searching for &lt;strong&gt;阮一峰’s blog&lt;/strong&gt;. There are two articles – the first introduces the basic syntax, and the second provides a practical case study.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;#### Content

Knowledge Points Needed
- GitHub Secrets
- Action Syntax
The core job uses existing components to complete the task, and pushing to the domestic Gitee is implemented using commands. This command approach is quite brute force, as it performs forceful pushes, inheriting the logic used with Travis.
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;epilogue&#34;&gt;Epilogue
&lt;/h4&gt;&lt;p&gt;Based on the actions provided by the official market, currently there are quite a few supported playstyles. After building a Docker image, it’s no longer dependent on services offered by Docker Hub.&lt;/p&gt;
&lt;p&gt;Reviewing the Hugo issues, using GitHub Actions to automatically deploy Git Pages results in the final published website needing to be on the master branch. If deployed from another branch, the settings interface will prompt an error indicating that the deployed webpage has syntax problems.&lt;/p&gt;
&lt;p&gt;This is simply because Hugo’s source files are located on the master branch, and GitHub treats it as the Jelly blog&amp;rsquo;s source code for detection, unable to check and resolve any errors resulting in the error message.&lt;/p&gt;
&lt;p&gt;The solution is straightforward: move Hugo source files to another branch and publish static files to the master branch.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Standard Library Container Memory Allocators: allocator</title>
        <link>https://ttf248.life/en/p/standard-library-container-memory-allocator/</link>
        <pubDate>Mon, 30 Dec 2019 13:26:19 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/standard-library-container-memory-allocator/</guid>
        <description>&lt;p&gt;A custom allocator can improve performance, increase memory utilization efficiency, and address the issue of frequent, small memory allocations.&lt;/p&gt;
&lt;h4 id=&#34;antecedent&#34;&gt;Antecedent
&lt;/h4&gt;&lt;p&gt;Recently, I&amp;rsquo;ve been working on the development of network data packets, requiring frequent allocation and release of small blocks of memory. Initially, I considered using a memory pool, reviewing several existing ones and discovering this:
&lt;a class=&#34;link&#34; href=&#34;https://github.com/cacay/MemoryPool&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/cacay/MemoryPool&lt;/a&gt;
When looking at the interface, I was quite puzzled by how the memory pool&amp;rsquo;s implementation was a bit strange. The &lt;code&gt;MemoryPool&lt;/code&gt; implementation logic involves allocating fixed-size memory spaces. Having reviewed Boost’s memory pool interface, it provides a template that is instantiated when used. Fortunately, this library already had an article describing it, mentioning the concept of ‘allocator’.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;#### [wiki](https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_(C%2B%2B))

In C++ programming, an allocator is a key component of the C++ standard library. The C++ library defines various data structures commonly referred to as &amp;quot;containers&amp;quot; (such as linked lists, sets, etc.). A common feature of these containers is that their size can be changed at runtime; therefore, dynamic memory allocation becomes necessary to achieve this. The allocator is used to handle container requests for memory allocation and deallocation. In other words, the allocator encapsulates the low-level details of memory management for standard template library (STL) containers. By default, the C++ standard library uses its built-in generic allocator; however, programmers can customize allocators to replace it as needed.
``` The allocator was originally invented by Alexander Stepanov as part of the C++ Standard Template Library (STL) as a way to “make the library more flexible and independent of the underlying data model,” allowing programmers to use custom pointer and reference types within the library. However, when the STL was incorporated into the C++ standard, the C++ standards committee realized that full abstraction of the data model would lead to unacceptable performance penalties. To compromise, restrictions on allocators in the standard became much stricter, and as a result, the degree to which allocators can be customized is now greatly limited compared to Stepanov’s original vision.

```markdown
#### [wiki](https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_(C%2B%2B))
Although customization of the allocator is limited, it is still often necessary to use a custom allocator in many cases, typically for encapsulating access methods to different types of memory spaces (such as shared memory and reclaimed memory), or for improving performance when using memory pools. In addition, from the perspective of memory usage and execution time, introducing a dedicated allocator for programs that frequently perform small amounts of memory allocation will also benefit.
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;usage-requirementshttpszhwikipediaorgwikie58886e9858de599a8_c2b2b&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Usage Requirements&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;Defining custom allocators primarily aims to improve performance. Utilizing a dedicated custom allocator can enhance program performance, or improve memory usage efficiency, or both [4][8]. The default allocator uses the &lt;code&gt;new&lt;/code&gt; operator to allocate storage [Reference 5], which often leverages the C language heap allocation function (malloc()) [9]. Because heap allocation functions are typically optimized for infrequent large memory allocations, the default allocator generally performs well when allocating memory for containers that require a single large memory allocation, such as vectors and doubly-ended queues [8]. However, when using the default allocator to allocate memory for associative containers with linked lists or bidirectional linked lists – which frequently require allocating small amounts of memory – performance is typically very low [4][9].&lt;/p&gt;
&lt;h4 id=&#34;usage-requirementshttpsenwikipediaorgwikimemory_pool_c2b2b&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Memory_pool_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Usage Requirements&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;In short, this section (…)(like) is a “I Have a Dream” speech for the allocator. Before the dream comes true, programmers concerned with portability will be limited to (using) stateless custom allocators.
—Scott Meyers, &lt;em&gt;Effective STL&lt;/em&gt;
Given this, in this case, memory pools are often used to address frequent, small allocations [8]. Unlike the default “on-demand allocation” method, when using a memory pool allocator, the program pre-allocates large blocks of memory (referred to as the “memory pool”) upfront.  Then, when requesting memory, the custom allocator simply returns a pointer to an available block within the pool. Unlike object deconstruction, no actual memory is released; instead, the release is deferred until the lifecycle of the memory pool ends [Note 1][8].&lt;/p&gt;
&lt;h4 id=&#34;usage-requirementshttpszhwikipediaorgwikie58886e9858de599a8_c2b2b-1&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Usage Requirements&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;On the topic of &amp;ldquo;Custom Allocators,&amp;rdquo; numerous C++ experts and authors have participated in discussions, such as Scott Meyers&amp;rsquo; &lt;em&gt;Effective STL&lt;/em&gt; and Andrei Alexandrescu’s &lt;em&gt;Modern C++ Design&lt;/em&gt;, which both mention it. Meyers observed that if one requires all instances of a particular type &lt;code&gt;T&lt;/code&gt;’s allocator to be equal, then the portable allocator instance must not contain state. Although the C++ standard encourages library implementers to support stateful allocators [Ref 4], Meyers called this paragraph “(seemingly) a wonderful idea,” but it is almost empty rhetoric, and considered the allocator restrictions “too strict” [4]. For example, STL’s list allows the splice method, meaning a node from one list object A can be directly inserted into another list object B. This requires that the memory allocated by A’s allocator is released by B’s allocator, thereby deducing that A and B’s allocator instances must be equal. Meyer’s conclusion is that allocators should be defined as types using static methods. For example, according to the C++ standard, an allocator must provide a class template other that implements the rebind method.&lt;/p&gt;
&lt;h4 id=&#34;usage-requirementshttpszhwikipediaorgwikie58886e9858de599a8_c2b2b-2&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Usage Requirements&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;Additionally, in &lt;em&gt;The C++ Programming Language&lt;/em&gt; by Bjarne Stroustrup, he states “&amp;lsquo;strict allocation to avoid different information for each object,&amp;rsquo; this is clearly not a problem’ (roughly), and points out that most allocators don&amp;rsquo;t need state, or even perform better when there is no state. He proposes three use cases for custom allocators: pool-based allocator, shared memory allocator, and garbage collector, and demonstrates an implementation of an allocator which utilizes an internal memory pool to quickly allocate/deallocate small amounts of memory. However, he also notes that such optimization may already be present in the sample allocator he provides [3].
Another use for custom allocators is debugging memory-related errors [10]. To achieve this, you can write a memory allocator that allocates additional memory when allocating, and uses it to store debugging information. This allocator not only ensures that memory is allocated/deallocated by the same type of allocator, but also provides some protection against cache overflows [11].&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>

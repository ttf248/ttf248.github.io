<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Computer on Uncle Xiang&#39;s Notebook</title>
        <link>https://ttf248.life/en/categories/computer/</link>
        <description>Recent content in Computer on Uncle Xiang&#39;s Notebook</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Wed, 28 May 2025 09:47:38 +0800</lastBuildDate><atom:link href="https://ttf248.life/en/categories/computer/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>GitHub Pages Easter Egg: Deploying Multiple Pages</title>
        <link>https://ttf248.life/en/p/github-pages-easter-egg-deploy-multiple-sites/</link>
        <pubDate>Wed, 28 May 2025 02:55:54 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/github-pages-easter-egg-deploy-multiple-sites/</guid>
        <description>&lt;p&gt;My sleep schedule has been messed up lately; I was still working on deploying my Github Pages at 2 AM&lt;/p&gt;
&lt;p&gt;After finishing my extra shift, I went to eat, and just after eating, I felt sleepy. I returned around 8:30, feeling drowsy, so I thought I&amp;rsquo;d doze off for a bit, but ended up falling asleep directly. I woke up at over 2 AM.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Short-lived category: AI Study Group&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;expose-hypocrisy-debunking-prove-wrong&#34;&gt;Expose hypocrisy; debunking; prove wrong
&lt;/h2&gt;&lt;p&gt;We said yesterday we wouldn&amp;rsquo;t mess with the frontend, but today we&amp;rsquo;re focusing on the UI/UX experience instead&lt;/p&gt;
&lt;h2 id=&#34;project&#34;&gt;Project
&lt;/h2&gt;&lt;p&gt;We&amp;rsquo;d like to invite our old friend, &lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/ai-coding-demo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/ai-coding-demo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s right, itâ€™s the original self-selected stock project. The entire project structure is being refactored, and all subsequent AI programming content will be placed under this project.&lt;/p&gt;
&lt;h2 id=&#34;deploy-multiple-pages&#34;&gt;Deploy multiple Pages
&lt;/h2&gt;&lt;p&gt;The project is currently hosted domestically at &lt;a class=&#34;link&#34; href=&#34;https://cnb.cool/ttf248/ai-coding-demo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://cnb.cool/ttf248/ai-coding-demo&lt;/a&gt;. Due to well-known restrictions, publishing pages isn&amp;rsquo;t supported within China, so we need to publish it on a foreign GitHub.&lt;/p&gt;
&lt;p&gt;The blog is published on GitHub. I haven&amp;rsquo;t tried it, but it&amp;rsquo;s for publishing multiple projects as pages. Also, the current project isn&amp;rsquo;t a traditional blog site; it just contains lots of documentation and several static HTML designs.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/github-pages-easter-egg-deploy-multiple-sites/20250528030230.png&#34;
	width=&#34;798&#34;
	height=&#34;530&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;pages&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;150&#34;
		data-flex-basis=&#34;361px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s right, I discovered that deploying multiple projects as Pages doesn&amp;rsquo;t affect blog publishing; instead, it adds a new path under the blog&amp;rsquo;s domain&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://ttf248.life/ai-coding-demo/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ttf248.life/ai-coding-demo/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Seeing this, I can&amp;rsquo;t help but exclaim &amp;ldquo;perfect!&amp;rdquo;&lt;/p&gt;
&lt;h2 id=&#34;ai-study-group&#34;&gt;AI Study Group
&lt;/h2&gt;&lt;p&gt;I created a new category yesterday, thinking of using AI to learn many computer science courses, such as algorithms and LeetCode practice questions&lt;/p&gt;
&lt;p&gt;Each learning record will be published on my blog, forming a knowledge base. A new category has been created: AI Study Group.&lt;/p&gt;
&lt;p&gt;For each course, create a new project and document your learning notes in the project&amp;rsquo;s Readme.md file&lt;/p&gt;</description>
        </item>
        <item>
        <title>Old habits, dazzling flowers captivate the eyes</title>
        <link>https://ttf248.life/en/p/old-ailment-stunning-flowers/</link>
        <pubDate>Mon, 26 May 2025 23:54:12 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/old-ailment-stunning-flowers/</guid>
        <description>&lt;p&gt;Having focused on backend development for many years, I recently started exploring &lt;strong&gt;&lt;em&gt;italicized and bolded&lt;/em&gt;&lt;/strong&gt; frontend interfaces to implement one, but in reality, these attempts haven&amp;rsquo;t been particularly helpful for my current work and have instead scattered my focus&lt;/p&gt;
&lt;h2 id=&#34;applicable-scenarios-for-ai&#34;&gt;Applicable scenarios for AI
&lt;/h2&gt;&lt;p&gt;AI tools can be particularly effective in small projects, especially when writing functions that are independent, have low system coupling, and feature simple business logic. These tasks typically involve clear inputs and outputs with limited context dependencies, making them well-suited for current AI-assisted programming capabilities.&lt;/p&gt;
&lt;p&gt;However, AI&amp;rsquo;s limitations become apparent when dealing with complex system architectures or deep business logic. It may generate code that appears reasonable but is actually detached from the projectâ€™s actual needs, and even introduce potential issues difficult to debug. In these scenarios, AI is better suited as an assistive tool rather than a fully relied-upon code generator. We need to rigorously review and test the generated code to ensure it meets practical requirements.&lt;/p&gt;
&lt;h2 id=&#34;the-cost-of-mistakes-and-learning&#34;&gt;The Cost of Mistakes and Learning
&lt;/h2&gt;&lt;p&gt;While attempting to generate frontend code using AI, I encountered numerous challenges. As frontend isn&amp;rsquo;t my area of expertise, troubleshooting issues proved time-consuming and draining. Even with prompt adjustments for AI rewrites, low-level errors were difficult to avoid. This repeated trial and error not only wasted time but also highlighted that my efforts are better focused on the backendâ€™s business logic rather than exploring unfamiliar territory.&lt;/p&gt;
&lt;p&gt;Reflecting on the project completed this weekend, I&amp;rsquo;m even more convinced that focusing on backend development and user interaction logic, implementing functionality through the console, is currently the most efficient approach. Systematically learning frontend knowledge later, when I have more time and energy, might be a better strategy.&lt;/p&gt;
&lt;h2 id=&#34;frontend-learning-plan&#34;&gt;Frontend learning plan
&lt;/h2&gt;&lt;p&gt;The front-end tech stack is complex and diverse, making it unrealistic to quickly master. I plan to focus on one framework initially, such as Vue.js or React.js, and deeply learn its core concepts and usage. Only after gaining a solid understanding of the fundamentals should I attempt AI-assisted code generation for the front-end, to effectively avoid errors and wasted time due to unfamiliarity.&lt;/p&gt;
&lt;p&gt;For now, the focus should remain on backend development and steadily building core skills. Explore the combination of frontend and AI when the time is right; that may yield greater rewards.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Claude4 released, attempting development: Hugo tag, hyperlink translation assistant</title>
        <link>https://ttf248.life/en/p/claude-4-release-and-experimentation-hugo-tags-hyperlink-translation-assistant/</link>
        <pubDate>Sat, 24 May 2025 03:05:31 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/claude-4-release-and-experimentation-hugo-tags-hyperlink-translation-assistant/</guid>
        <description>&lt;p&gt;This site is built with Hugo, but I&amp;rsquo;ve been using Chinese titles, which results in unfriendly URLs. To put it simply, when shared, they don&amp;rsquo;t look good because Chinese characters are encoded as things like %E4%BD%A0%E5%A5%BD. While slugs can fix this, manually setting them each time is too much trouble.&lt;/p&gt;
&lt;p&gt;So, today I tried using Claude4 to develop a translation assistant that automatically converts Chinese titles into English slugs and adds hyperlinks within articles. This would eliminate the need for manual setup.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Claude 4 is excellent; its ability to understand context and handle complex tasks has been significantly improved&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;project-address&#34;&gt;Project address
&lt;/h2&gt;&lt;p&gt;Domestic project address: &lt;a class=&#34;link&#34; href=&#34;https://cnb.cool/ttf248/hugo-content-suite&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://cnb.cool/ttf248/hugo-content-suite&lt;/a&gt;
Overseas project address: &lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/hugo-content-suite&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/hugo-content-suite&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;code-implementation&#34;&gt;Code implementation
&lt;/h2&gt;&lt;p&gt;Here&amp;rsquo;s the translation: First, let me outline the approach: We need to scan all articles, extract tag information and article titles, then call a local large language model (like gemma-3-12b-it) for translation&lt;/p&gt;
&lt;p&gt;In practical development, compared to previous generations of large models, this feature provides unlabeled article previews and generates tab pages&lt;/p&gt;
&lt;p&gt;Regardless of whether it involves connecting to local large models, adding translation caches, or conducting extensive code refactoring, &lt;strong&gt;the system rarely forgets context&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In short, with improved intelligence, we&amp;rsquo;re preparing to switch to &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; for more development work as our primary coding model&lt;/p&gt;
&lt;h2 id=&#34;translation-cache&#34;&gt;Translation cache
&lt;/h2&gt;&lt;p&gt;This approach, aside from reducing large model calls, offers good efficiency when running a 12b model locally without causing delays. However, repeatedly calling the large model can still be slow. Secondly, to maintain article links, full updates sometimes produce inconsistent results due to long titles, leading to link changes â€“ which is quite awkward.&lt;/p&gt;
&lt;h2 id=&#34;feature-optimization&#34;&gt;Feature optimization
&lt;/h2&gt;&lt;p&gt;The entire project was handed over to [someone], resulting in these suggestions after analyzing areas for optimization:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;é…ç½®å¤–ç½®åŒ– - æé«˜å¯ç»´æŠ¤æ€§å’Œçµæ´»æ€§
ç»“æ„åŒ–æ—¥å¿— - ä¾¿äºé—®é¢˜æ’æŸ¥å’Œç›‘æ§
æ€§èƒ½ç›‘æ§ - äº†è§£ç³»ç»Ÿè¿è¡ŒçŠ¶å†µ
ç”¨æˆ·ä½“éªŒ - è¿›åº¦æ¡ç­‰è§†è§‰åé¦ˆ
é”™è¯¯å¤„ç† - æ›´å®Œå–„çš„å¼‚å¸¸å¤„ç†æœºåˆ¶
ä»£ç ç»„ç»‡ - æ›´æ¸…æ™°çš„æ¨¡å—åˆ’åˆ†
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The code review was completed and everything looks good. For example, the configuration file now automatically generates a default if one doesn&amp;rsquo;t exist when reading it, converting the original codeâ€™s settings to defaults â€“ this prevents user errors.&lt;/p&gt;
&lt;h3 id=&#34;heading&#34;&gt;
&lt;/h3&gt;&lt;p&gt;Requirements: While translating the main text, dynamically calculate the current translation efficiency, estimate the remaining time, and output relevant information to the console. This includes tracking the number of characters obtained from the article, the number of characters translated per line, the elapsed time, a fitted calculation for the translation time per 100 characters, and an estimated remaining translation time for the entire article.&lt;/p&gt;
&lt;p&gt;The code is done, but I&amp;rsquo;m not very satisfied with the results, so I asked AI to provide new design suggestions&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Offers multiple efficiency calculation methods: real-time efficiency, average efficiency, sliding window efficiency&lt;/li&gt;
&lt;li&gt;Improved display methods: progress bar, segmented statistics, dynamic refresh&lt;/li&gt;
&lt;li&gt;Add more useful metrics: API call count, success rate, etc&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After completing the code, I discovered a new surprise â€“ real-time statistics on translation efficiency are displayed without mindless scrolling&lt;/p&gt;
&lt;p&gt;Translating body text to English.
Detected 53 lines needing translation
Translating 354 characters.
Completed (3.1s) | API call #1
Completed (1.5s) | API call #2
Completed (0.9s) | API call #3
Completed (0.2s) | API call #4
Completed
Completed
Completed (0.2s) | API call #7
Progress: 13.2% (7/53) | Characters 12.9% (925/7163) 114.6 characters/second
Efficiency: Real-time 76.4 | Average 117.9 | Recent 109.0 | Stage 113.6 characters/second ğŸ“Š
Success Rate: 100.0% (7/7) | Remaining: 46 lines, 7 seconds] 9.4% Translation of 110 charactersâ€¦
Estimated remaining: 55s | Estimated completion: 10:19 8s | 11.3% | Translating 114 charactersâ€¦
Processing speed: 3211.3 lines/minute | Total time: 8s] 13.2% Translated 16 charactersâ€¦
Stage 1/6 [â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 15.1% Translating 166 charactersâ€¦&lt;/p&gt;
&lt;p&gt;I haven&amp;rsquo;t written much control programs before, curious about how itâ€™s implemented, so I looked at the code&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;// æ¸…å±å¹¶é‡æ–°æ˜¾ç¤º (åŠ¨æ€åˆ·æ–°æ•ˆæœ)
if translationCount &amp;gt; 1 {
 Â  fmt.Print(&amp;quot;\033[6A\033[K&amp;quot;) // ä¸Šç§»6è¡Œå¹¶æ¸…é™¤
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;performance-statistics-menu&#34;&gt;Performance Statistics Menu
&lt;/h3&gt;&lt;p&gt;This new &lt;strong&gt;æ€§èƒ½ç»Ÿè®¡èœå•&lt;/strong&gt;, which I designed myself, might not even be this well-designed&lt;/p&gt;
&lt;p&gt;Performance Statistics:
Translation count: 360
Cache hit rate: 1.4% (5/365)
Average translation time: 315.927234ms
File Operations: 73
Incorrect attempts: 0&lt;/p&gt;
&lt;h3 id=&#34;progress-bar-display&#34;&gt;Progress bar display
&lt;/h3&gt;&lt;p&gt;New &lt;strong&gt;è¿›åº¦æ¡æ˜¾ç¤º&lt;/strong&gt;, detailed progress, time spent, estimated remaining time&lt;/p&gt;
&lt;p&gt;Please select function (0-13): 10
Collecting translation target.
Cached file loaded, containing 0 translation records&lt;/p&gt;
&lt;p&gt;Translation cache statistics:
Total labels: 229
Total articles: 131
Cached: 0 items
360 items need translating&lt;/p&gt;
&lt;p&gt;Confirm generating full translation cache? (y/n): y
Generating full translation cache.
Cached file loaded, containing 0 translation records
Checking cached translations.
Need to translate 360 new tags
5/360 (1.4%) - Time taken: 3s - Estimated remaining: 3m8sğŸ’¾ Saved cache file, containing 5 translation records
10/360 (2.8%) - Time taken: 6s - Estimated remaining time: 3m28sğŸ’¾ Saved cache file, containing 10 translation records
15/360 (4.2%) - Time taken: 9s - Estimated remaining: 3m30sğŸ’¾ Saved cache file, containing 15 translation records
20/360 (5.6%) - Time elapsed: 13s - Estimated remaining: 3m36sğŸ’¾ Saved cache file, containing 20 translation records
25/360 (6.9%) - Time taken: 16s - Estimated remaining time: 3m33sğŸ’¾ Saved cache file, containing 25 translation records
30/360 (8.3%) - Time elapsed: 19s - Estimated remaining: 3m30sğŸ’¾ Saved cache file, containing 30 translation records
Saved cache file, containing 35 translation records&lt;/p&gt;
&lt;hr&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;=== Hugo åšå®¢ç®¡ç†å·¥å…· ===

ğŸš€ æ ¸å¿ƒåŠŸèƒ½
  1. ä¸€é”®å¤„ç†å…¨éƒ¨ (å®Œæ•´åšå®¢å¤„ç†æµç¨‹)

ğŸ“ å†…å®¹ç®¡ç†
  2. ç”Ÿæˆæ ‡ç­¾é¡µé¢
  3. ç”Ÿæˆæ–‡ç« Slug
  4. ç¿»è¯‘æ–‡ç« ä¸ºå¤šè¯­è¨€ç‰ˆæœ¬

ğŸ’¾ ç¼“å­˜ç®¡ç†
  5. æŸ¥çœ‹ç¼“å­˜çŠ¶æ€
  6. ç”Ÿæˆå…¨é‡ç¿»è¯‘ç¼“å­˜
  7. æ¸…ç©ºç¿»è¯‘ç¼“å­˜

  0. é€€å‡ºç¨‹åº
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Merge Pull Request into forked repository</title>
        <link>https://ttf248.life/en/p/merge-pullrequest-to-fork-repository/</link>
        <pubDate>Wed, 07 May 2025 18:44:03 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/merge-pullrequest-to-fork-repository/</guid>
        <description>&lt;p&gt;&lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; is a GitHub profile statistics generator that allows users to display various statistics and charts on their GitHub profiles. It offers multiple customization options to suit user needs.&lt;/p&gt;
&lt;p&gt;I manage my warehouse by project groups. GitHub doesn&amp;rsquo;t support grouped repositories, so I had to use separate organizations. The latest branch couldnâ€™t handle cross-organization repository statistics, so I forked a branch and merged the corresponding code.&lt;/p&gt;
&lt;h2 id=&#34;final-effect&#34;&gt;Final effect
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://github-readme-stats-chi-one-17.vercel.app/api?username=ttf248&amp;amp;hide_title=true&amp;amp;show_icons=true&amp;amp;hide=contribs&amp;amp;line_height=24&amp;amp;include_all_commits=true&amp;amp;count_private=true&amp;amp;bg_color=0000&amp;amp;text_color=8A919F&amp;amp;locale=cn&amp;amp;role=OWNER,COLLABORATOR,ORGANIZATION_MEMBER&amp;amp;timstamp=1746608356&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;GitHub Stats&#34;
	
	
&gt;
&lt;img src=&#34;https://github-readme-stats-chi-one-17.vercel.app/api/top-langs/?username=ttf248&amp;amp;hide_title=true&amp;amp;hide=html,javascript,css&amp;amp;layout=compact&amp;amp;bg_color=0000&amp;amp;text_color=8A919F&amp;amp;locale=cn&amp;amp;role=OWNER,COLLABORATOR,ORGANIZATION_MEMBER&amp;amp;timstamp=1746608356&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Top Languages&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;original-pull-request-link&#34;&gt;Original Pull Request Link
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/anuraghazra/github-readme-stats/pull/2459&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Adds the ability to include data from organization repositories&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;merge-pull-request-into-forked-repository&#34;&gt;Merge Pull Request into forked repository
&lt;/h2&gt;&lt;p&gt;There are several ways to merge a [BLANK_0] into your [BLANK_1], depending on what you want to achieve&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Merge the PR from &lt;strong&gt;ä¸Šæ¸¸ï¼ˆupstreamï¼‰ä»“åº“&lt;/strong&gt; into your fork, or&lt;/li&gt;
&lt;li&gt;Merge a PR from another person&amp;rsquo;s fork into your own fork, or&lt;/li&gt;
&lt;li&gt;Merge a pull request opened on your fork (e.g., someone created a PR from their fork of yours)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here&amp;rsquo;s the translation: Iâ€™ll give you a very common scenario: &lt;strong&gt;ä½  fork äº†ä¸€ä¸ªä»“åº“ï¼Œæƒ³æŠŠä¸Šæ¸¸çš„æŸä¸ª PR åˆå¹¶åˆ°ä½ çš„ fork&lt;/strong&gt;. The operating procedure is as follows ğŸ‘‡:&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;method-1-command-line-method-most-universal&#34;&gt;Method 1: Command-line method (most universal)
&lt;/h3&gt;&lt;h4 id=&#34;step-1-clone-your-own-fork&#34;&gt;Step 1: Clone your own fork
&lt;/h4&gt;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/ä½ çš„ç”¨æˆ·å/ä»“åº“å.git
cd ä»“åº“å
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;step-2-add-upstream-original-repository-address&#34;&gt;Step 2: Add upstream (original repository address)
&lt;/h4&gt;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git remote add upstream https://github.com/åŸä½œè€…ç”¨æˆ·å/ä»“åº“å.git
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;step-3-fetch-the-upstream-pr-branch&#34;&gt;Step 3: Fetch the upstream PR branch
&lt;/h4&gt;&lt;p&gt;Find the PR number you want to merge, for example, PR #123&lt;/p&gt;
&lt;p&gt;You can pull the code for this PR like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git fetch upstream pull/123/head:pr-123
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;step-4-switch-and-merge-branches&#34;&gt;Step 4: Switch and merge branches
&lt;/h4&gt;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git checkout main    # æˆ–è€…ä½ è‡ªå·±çš„ç›®æ ‡åˆ†æ”¯
git merge pr-123
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If everything is normal, you can push to your forked GitHub repository&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git push origin main
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h3 id=&#34;method-two-github-web-interface-simple-but-limited&#34;&gt;Method Two: GitHub Web Interface (Simple but Limited)
&lt;/h3&gt;&lt;p&gt;If you see a pull request on GitHub that is against an upstream repository, you can:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to that PR page&lt;/li&gt;
&lt;li&gt;Click the &amp;ldquo;&lt;em&gt;&lt;strong&gt;Commits&lt;/strong&gt;&lt;/em&gt;&amp;rdquo; or &amp;ldquo;&lt;em&gt;&lt;strong&gt;Files changed&lt;/strong&gt;&lt;/em&gt;&amp;rdquo; in the upper right corner to see which branch this PR is based on&lt;/li&gt;
&lt;li&gt;On your forked repository, create a new branch and manually cherry-pick the PR&amp;rsquo;s commits (requires some Git knowledge)&lt;/li&gt;
&lt;li&gt;Or click &amp;ldquo;&lt;strong&gt;Open in GitHub Desktop&lt;/strong&gt;&amp;rdquo; to merge using a GUI tool&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id=&#34;if-someone-has-submitted-a-pull-request-for-your-fork&#34;&gt;If someone has submitted a pull request for your fork
&lt;/h3&gt;&lt;p&gt;Simply go to the PR page and click the &amp;ldquo;&lt;strong&gt;Merge pull request&lt;/strong&gt;&amp;rdquo; button&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Would you like me to walk you through it step-by-step, based on your current situation (e.g., a PR link, whether you&amp;rsquo;re using the web interface or command line)? Or, you can provide a specific link, and Iâ€™ll help you analyze the simplest approach&lt;/p&gt;</description>
        </item>
        <item>
        <title>Commit messages in Git history</title>
        <link>https://ttf248.life/en/p/git-modify-commit-message/</link>
        <pubDate>Wed, 07 May 2025 18:38:31 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/git-modify-commit-message/</guid>
        <description>&lt;p&gt;This script is used to batch modify author information in Git history, rewriting commit records using &lt;code&gt;git filter-branch&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The provided script for batch modifying author information in Git repository history is conceptually correct, but (does not support array syntax)&lt;/p&gt;
&lt;p&gt;To improve compatibility, it is recommended to replace the array with a space-separated string and iterate through each old email address using &lt;code&gt;for&lt;/code&gt;. Here&amp;rsquo;s an example of the modified script:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/sh

git filter-branch --env-filter &#39;
OLD_EMAILS=&amp;quot;TianlongXiang51@gmail.com nick@qq.com tianlongxiang51@gmail.com&amp;quot;
CORRECT_NAME=&amp;quot;tianlong.xiang&amp;quot;
CORRECT_EMAIL=&amp;quot;tianlong.xiang@foxmail.com&amp;quot;

for OLD_EMAIL in $OLD_EMAILS
do
    if [ &amp;quot;$GIT_COMMITTER_EMAIL&amp;quot; = &amp;quot;$OLD_EMAIL&amp;quot; ]
    then
        export GIT_COMMITTER_NAME=&amp;quot;$CORRECT_NAME&amp;quot;
        export GIT_COMMITTER_EMAIL=&amp;quot;$CORRECT_EMAIL&amp;quot;
    fi
    if [ &amp;quot;$GIT_AUTHOR_EMAIL&amp;quot; = &amp;quot;$OLD_EMAIL&amp;quot; ]
    then
        export GIT_AUTHOR_NAME=&amp;quot;$CORRECT_NAME&amp;quot;
        export GIT_AUTHOR_EMAIL=&amp;quot;$CORRECT_EMAIL&amp;quot;
    fi
done
&#39; --tag-name-filter cat -- --branches --tags
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Before running this script, it is recommended to back up your repository to prevent unexpected issues&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;This operation will rewrite Git history, modify commit author information, and may cause changes to commit hashes&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you have already pushed changes to the remote repository, you need to use a force push&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git push --force --tags origin &#39;refs/heads/*&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Use force pushes cautiously, especially in collaborative projects, to avoid impacting others&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;List all unique author email addresses in the warehouse statistics&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git log --format=&#39;%an &amp;lt;%ae&amp;gt;&#39; | sort -u
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Feeling bored, wanting to design a Chinese ink-wash style theme</title>
        <link>https://ttf248.life/en/p/chinese-ink-style-theme/</link>
        <pubDate>Tue, 08 Apr 2025 03:42:47 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/chinese-ink-style-theme/</guid>
        <description>&lt;p&gt;I&amp;rsquo;m tired of colorful, flashy homepages; I suddenly want to go for a minimalist style and design a Chinese ink-wash theme&lt;/p&gt;
&lt;p&gt;The stylesheets have been heavily modified, with specific styles configured for different elements to override the theme&amp;rsquo;s default styling&lt;/p&gt;
&lt;p&gt;Without refactoring, attempting to directly generate a new theme using AI results in very unstable outcomes&lt;/p&gt;
&lt;p&gt;Coincidentally, I also encountered a queue for the Trae Claude large language model. Switching to VS Code agent mode resulted in very poor performance; the modifications lacked any design sense.&lt;/p&gt;
&lt;p&gt;Ultimately, it&amp;rsquo;s because I don&amp;rsquo;t understand frontend well enough to effectively break down tasks for AI&lt;/p&gt;</description>
        </item>
        <item>
        <title>Design and develop a customizable stock selection module (without coding)</title>
        <link>https://ttf248.life/en/p/no-code-design-develop-custom-stock-module/</link>
        <pubDate>Thu, 27 Feb 2025 23:20:39 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/no-code-design-develop-custom-stock-module/</guid>
        <description>&lt;p&gt;We tested Cursor last month, but due to free tier limitations, we didn&amp;rsquo;t develop complex features, just simple testing. We noticed that ByteDance also released a similar product at the time, both using the same underlying large language model: Claude-3.5.&lt;/p&gt;
&lt;p&gt;ByteDance&amp;rsquo;s product, Trae, initially launched a Mac version and finally released a Windows version this February. Big company products are just good â€“ you can use them for free without paying, with unlimited access to Claude-3.5, which is a very impressive model.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Ultimately, development stalled on the K-line chart due to my limited knowledge of React. To continue, I need to supplement my frontend skills and break down tasks into smaller steps instead of tackling a large project like developing a K-line chart directly.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;issues-found&#34;&gt;Issues found
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Due to insufficient training data for Vue3 + Element-Plus due to reliance on foreign AI models, we chose React as the frontend framework&lt;/li&gt;
&lt;li&gt;There may be occasional grammatical errors that require manual correction&lt;/li&gt;
&lt;li&gt;Some complex problems require human guidance for solutions&lt;/li&gt;
&lt;li&gt;Code structure optimization requires human guidance&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The most time-consuming part was packaging the frontend code into a container. As someone with zero experience, I had no understanding of this process; I only managed to grasp the logic with help from others. There&amp;rsquo;s a significant difference in how frontend development checks code between dev and build modes. The database and service containers for the backend took about five minutes combined.&lt;/p&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/p&gt;
&lt;h2 id=&#34;warehouse-address&#34;&gt;Warehouse address
&lt;/h2&gt;&lt;p&gt;As the title suggests, we&amp;rsquo;re skipping the coding and directly discussing with AI to design and develop a custom stock selection module. Letâ€™s see what kind of results we can achieve.&lt;/p&gt;
&lt;p&gt;Warehouse address: &lt;a class=&#34;link&#34; href=&#34;https://github.com/ttf248/trae-demo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ttf248/trae-demo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Detailed usage instructions can be found in the repository&amp;rsquo;s README.md file&lt;/p&gt;
&lt;p&gt;The repository contains numerous submission records, mostly conversations between me and Trae, along with my tests of various features for him. Notes indicate whether manual intervention was required to implement the corresponding functionality.&lt;/p&gt;
&lt;h2 id=&#34;prompt&#34;&gt;Prompt
&lt;/h2&gt;&lt;p&gt;This project was created from scratch. Here&amp;rsquo;s the prompt for the project:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;åŸºäºé¡¹ç›®åŸå‹å›¾ï¼Œå¼€å‘åŠŸèƒ½ï¼šè‡ªé€‰è‚¡ï¼Œéœ€è¦æ”¯æŒåˆçº¦çš„æ–°å¢ã€åˆ é™¤ã€ä¿®æ”¹ã€æŸ¥è¯¢ã€‚è‡ªé€‰è‚¡ç•Œé¢éœ€è¦å±•ç¤ºåŸºç¡€çš„è¡Œæƒ…æ•°æ®ã€‚æ”¯æŒå¤šä¸ªä¸åŒçš„å¸‚åœºåˆ‡æ¢ã€‚

å‰ç«¯ï¼šreact
åç«¯ï¼šgolang gin gorm
æ•°æ®åº“ï¼šPostgreSQL

æœåŠ¡ç«¯éœ€è¦æ”¯æŒè·¨åŸŸè¯·æ±‚ï¼ŒåŒæ—¶éœ€è¦è€ƒè™‘æ•°æ®çš„æ ¡éªŒå’Œé”™è¯¯å¤„ç†ï¼Œå¦‚æœåç«¯æœåŠ¡ä¸å¯ç”¨ï¼Œå‰ç«¯éœ€è¦å‘Šè­¦æç¤ºã€‚

åç«¯éœ€è¦å±•ç¤ºè¯·æ±‚å’Œåº”ç­”çš„æ—¥å¿—ï¼›å‰ç«¯ä¹Ÿæ‰“å°é€šè®¯çš„æ—¥å¿—ï¼Œæ–¹ä¾¿æ’æŸ¥é—®é¢˜ã€‚
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;ui-and-interaction-optimization&#34;&gt;UI and interaction optimization
&lt;/h2&gt;&lt;p&gt;The frontend design is entirely dependent on Grok. We initially created a prototype within Trae, but it lacked aesthetic appeal. Due to the model&amp;rsquo;s strong coding capabilities and weaker overall abilities, we need to use Grok to optimize the frontend UI.&lt;/p&gt;
&lt;p&gt;By taking screenshots of the current interface, uploading them to Grok, and having it help us optimize the UI, we can potentially receive numerous optimization suggestions. We will then manually evaluate these suggestions and copy them into Trae for execution, observing the results.&lt;/p&gt;
&lt;h3 id=&#34;technology-stack&#34;&gt;Technology stack
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Frontend: React + TypeScript&lt;/li&gt;
&lt;li&gt;Backend: Golang + Gin + GORM&lt;/li&gt;
&lt;li&gt;Database: PostgreSQL 17&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;system-architecture&#34;&gt;System architecture
&lt;/h2&gt;&lt;h2 id=&#34;backend-architecture&#34;&gt;Backend architecture
&lt;/h2&gt;&lt;p&gt;The backend is implemented using Go&amp;rsquo;s Gin framework for a RESTful API, with modules including:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Use GORM as an ORM framework&lt;/li&gt;
&lt;li&gt;Supports environment variable configuration for database connections&lt;/li&gt;
&lt;li&gt;Automatically migrate database tables&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;RESTful API Design&lt;/li&gt;
&lt;li&gt;Unified error handling mechanism&lt;/li&gt;
&lt;li&gt;Built-in request logging&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Support cross-domain for local development environments&lt;/li&gt;
&lt;li&gt;Configurable CORS policy&lt;/li&gt;
&lt;li&gt;Support cross-domain cookies&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;frontend-architecture&#34;&gt;Frontend Architecture
&lt;/h2&gt;&lt;p&gt;Built with React + TypeScript, achieving:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stock list display&lt;/li&gt;
&lt;li&gt;Self-selected stock management&lt;/li&gt;
&lt;li&gt;Market Data Display&lt;/li&gt;
&lt;li&gt;Error message mechanism&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Protobuf Zero-Value Trap: When Defaults Become Silent Killers of Business Logic</title>
        <link>https://ttf248.life/en/p/protobuf-zero-value-traps/</link>
        <pubDate>Thu, 20 Feb 2025 15:26:51 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/protobuf-zero-value-traps/</guid>
        <description>&lt;p&gt;US stocks have three trading periods: pre-market, intra-market, and post-market. The data push logic (to minimize bandwidth usage) sends the full dataset once initially, then pushes incremental updates for all subsequent fields.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Why not use the optimal solution? It involves different project teams, some of which have been live for many years. We are newly integrated, so we can only try to maintain compatibility.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;a-series-of-questions&#34;&gt;A series of questions
&lt;/h2&gt;&lt;p&gt;Looking at the abstract alone, there might not seem to be a problem. However, bringing this system architecture into the problem-solving process has triggered a series of issues. Just as one issue was resolved, another arose, stemming from the previous ones.&lt;/p&gt;
&lt;h3 id=&#34;unable-to-identify-trading-period&#34;&gt;Unable to identify trading period
&lt;/h3&gt;&lt;p&gt;Whether the in-memory stage is defined as the default value or the actual business value&lt;/p&gt;
&lt;p&gt;A simple understanding: Receiving a 0 each time makes it impossible to determine whether it&amp;rsquo;s a new quote setting or the default value of Protobuf&lt;/p&gt;
&lt;h3 id=&#34;introduce-optional&#34;&gt;Introduce optional
&lt;/h3&gt;&lt;p&gt;Since protobuf release 3.15, proto3 supports using the optional keyword (just as in proto2) to give a scalar field presence information&lt;/p&gt;
&lt;p&gt;The internal communication protocol is based on &lt;code&gt;protobuf&lt;/code&gt;BOLD_3&lt;code&gt;optional&lt;/code&gt;BOLD_4&lt;code&gt;protobuf&lt;/code&gt;, and the project&amp;rsquo;s underlying implementation uses a static library, which requires upgrading the entire compilation chain. This cost is very high.&lt;/p&gt;
&lt;h3 id=&#34;gcc-version-issue&#34;&gt;GCC version issue
&lt;/h3&gt;&lt;p&gt;After much deliberation, we devised a plan to release two different versions at the underlying level, aiming to carefully control new features&lt;/p&gt;
&lt;p&gt;Commonly used server types within the group: CentOS 7, CentOS 8. The default version of CentOS 7 is above 7.4, so CentOS 7 is not supported.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://gcc.gnu.org/bugzilla/show_bug.cgi?id=82461&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Bug 82461 - [7 Regression] Temporary required for brace-initializing (non-literal-type) member variable&lt;/a&gt;ã€‚&lt;/p&gt;
&lt;p&gt;After some troubleshooting, moving the related services and compilation server to CentOS 8 resolved the issue&lt;/p&gt;
&lt;h2 id=&#34;reasonable-enumeration&#34;&gt;Reasonable Enumeration
&lt;/h2&gt;&lt;p&gt;Looking back at the entire issue, there&amp;rsquo;s a simpler and more efficient solution: adjust the enumeration definition to start numbering from 1 instead of 0. This effectively distinguishes default values from business values, avoiding the aforementioned series of problems.&lt;/p&gt;
&lt;h3 id=&#34;why-is-starting-from-1-more-reasonable&#34;&gt;Why is starting from 1 more reasonable?
&lt;/h3&gt;&lt;p&gt;In C++, the default value of an enumeration type is fixed at 0. If we define a meaningful business value as 0 (e.g., &amp;ldquo;in-plate&amp;rdquo;), the downstream system cannot determine whether the received 0 represents a business value or an unset default value during incremental push. However, if enumerations are defined starting from 1, 0 can be reserved for a meaningless default value or an &amp;ldquo;unknown&amp;rdquo; state, resolving the issue.&lt;/p&gt;
&lt;p&gt;Suggested practices:&lt;/p&gt;
&lt;p&gt;When designing Protobuf enums, always define 0 as a meaningless default value
Assign actual business values starting from 1, ensuring distinction from the default value of 0&lt;/p&gt;
&lt;p&gt;This small adjustment not only resolved the trading period identification issue but also provided a valuable lesson for future protocol design&lt;/p&gt;</description>
        </item>
        <item>
        <title>Troubleshooting TCP Communication Anomalies in Backend Services</title>
        <link>https://ttf248.life/en/p/backend-service-tcp-communication-troubleshooting/</link>
        <pubDate>Fri, 14 Feb 2025 22:54:13 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/backend-service-tcp-communication-troubleshooting/</guid>
        <description>&lt;p&gt;Business model: The backend service establishes a connection with the group&amp;rsquo;s market gateway via TCP. Each connection requires an initial authorization request, followed by continuous heartbeat packets to maintain connection status.
However, one day, an alert about a service disconnection was received. After carefully checking the logs, it was discovered that the backend service continuously sent heartbeat packets, but there was no response from the other party, yet the connection never disconnected.&lt;/p&gt;
&lt;h2 id=&#34;brief-overview&#34;&gt;Brief Overview
&lt;/h2&gt;&lt;p&gt;I was working late at the office, pushing forward project progress, when an alert suddenly popped up in our work group. At first glance, I thought it was just a network timeout causing heartbeat failures and service disconnections. However, after carefully checking the logs, the situation proved to be different. The backend had sent authorization login messages, but received no response. Meanwhile, heartbeats continued to be sent, yet there was no reply whatsoever. In-depth analysis of the logs revealed several key issues:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Authorization message failed due to no response: This is likely because the other system is restarting, preventing timely processing of the authorization message&lt;/li&gt;
&lt;li&gt;The heartbeat data was sent despite unsuccessful authorization. Investigation revealed a flaw in the program logic: the heartbeat sending function&amp;rsquo;s judgment logic is defective, only checking connection status but omitting authorization status verification.&lt;/li&gt;
&lt;li&gt;If the service can disconnect, it will trigger a reconnection mechanism to resend authorization messages&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Currently, one last critical issue remains: why the connection has not been disconnected. Resolving this requires more in-depth and detailed troubleshooting.&lt;/p&gt;
&lt;h2 id=&#34;analyze-network-packets&#34;&gt;Analyze network packets
&lt;/h2&gt;&lt;p&gt;To capture network packets for further analysis&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/backend-service-tcp-communication-troubleshooting/20250220151952.png&#34;
	width=&#34;1126&#34;
	height=&#34;202&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;tcpdump&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;557&#34;
		data-flex-basis=&#34;1337px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Analyzing the data in the graph, I can see that the heartbeat was consistently being sent, but no data was received from the other server. However, it provided &lt;code&gt;ACK&lt;/code&gt;, which prevented the connection from disconnecting automatically.&lt;/p&gt;
&lt;h2 id=&#34;common-flag-explanations&#34;&gt;Common Flag Explanations
&lt;/h2&gt;&lt;p&gt;In the TCP protocol, &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;ï¼ˆPushï¼‰å’Œ &lt;strong&gt;INLINE_CODE_1&lt;/strong&gt; (Acknowledgments) are two important flags used to control data transmission and flow confirmation. Their functions are as follows:&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;1-pshpush-flag&#34;&gt;&lt;strong&gt;1. PSHï¼ˆPush Flagï¼‰&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;åŠŸèƒ½&lt;/strong&gt;:
Request that the receiver immediately push the data from the buffer to the upper-layer application&amp;rsquo;s data segment, processing and forwarding it as quickly as possible rather than storing it in the operating system buffer&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;å…¸å‹åœºæ™¯&lt;/strong&gt;:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Clients expect immediate responses from the server when sending requests (e.g., ping)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Each keyboard input triggers &lt;code&gt;PSH&lt;/code&gt;, ensuring real-time character transmission&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Low-latency scenarios such as video streaming and online games may use &lt;em&gt;edge computing&lt;/em&gt; to reduce latency&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;æ³¨æ„&lt;/strong&gt;:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;This flag is not mandatory; the recipient can choose to ignore it (but should still process the data normally)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The sender may not set &lt;code&gt;PSH&lt;/code&gt;, in which case the receiver will decide when to push data based on its own buffering strategy&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;2-ackacknowledgment-flag&#34;&gt;&lt;strong&gt;2. ACKï¼ˆAcknowledgment Flagï¼‰&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;åŠŸèƒ½&lt;/strong&gt;:
Confirmation that the preceding data segment has been correctly received (indicated by the expected next byte sequence number). It is a core mechanism for reliable transmission in TCP.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;å·¥ä½œåŸç†&lt;/strong&gt;:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When sending a data segment, the sender will carry the expected recipient&amp;rsquo;s (ID)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Upon receiving the data, the receiver generates an acknowledgment segment confirming the received sequence number&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The sender will only retransmit unacknowledged data after receiving the corresponding confirmation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ç¤ºä¾‹&lt;/strong&gt;:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If the sender sent sequence number 5, 6, and 7&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If the recipient does not receive confirmation from the sender regarding retransmission&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;please-provide-the-chinese-text-you-want-me-to-translate-i-am-ready-when-you-are&#34;&gt;Please provide the Chinese text you want me to translate. I am ready when you are!
&lt;/h3&gt;&lt;p&gt;INLINE_CODE_0__ å’Œ &lt;strong&gt;INLINE_CODE_1&lt;/strong&gt; can occur simultaneously in a TCP message, commonly seen in the following scenarios:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;HTTP è¯·æ±‚å“åº”&lt;/strong&gt;:
The client sends (confirmation of the previous response)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-plaintext&#34;&gt;Client â†’ Server: SYN, ACK=1 â†’ å»ºç«‹è¿æ¥
Client â†’ Server: PSH, ACK=1, æ•°æ® â†’ å‘é€è¯·æ±‚æ•°æ®
Server â†’ Client: PSH, ACK=æ•°æ®é•¿åº¦+1 â†’ è¿”å›å“åº”
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;SSH æ¡æ‰‹åä¼ è¾“å‘½ä»¤&lt;/strong&gt;:
After the client enters a command, it sends a data segment with &lt;code&gt;PSH&lt;/code&gt;BOLD_2&lt;code&gt;ACK&lt;/code&gt; to ensure immediate transmission and processing by the server&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;please-provide-the-chinese-text-you-want-me-to-translate-i-am-ready-when-you-are-1&#34;&gt;Please provide the Chinese text you want me to translate. I am ready when you are!
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Flag&lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Brief Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Synchronization&lt;/td&gt;
&lt;td&gt;Establish Connection (Three-Way Handshake)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;FIN&lt;/td&gt;
&lt;td&gt;End&lt;/td&gt;
&lt;td&gt;Gracefully close connection&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Reset&lt;/td&gt;
&lt;td&gt;Force connection termination (abnormal situation)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;URG&lt;/td&gt;
&lt;td&gt;Emergency&lt;/td&gt;
&lt;td&gt;Marks emergency pointer (rarely used)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id=&#34;please-provide-the-chinese-text-you-want-me-to-translate-i-am-ready-when-you-are-2&#34;&gt;Please provide the Chinese text you want me to translate. I am ready when you are!
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Focusing on stability, reducing latency&lt;/li&gt;
&lt;li&gt;The focus is on reliability, avoiding dropped or out-of-order packets&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;They work together to balance the efficiency and reliability of the TCP protocol&lt;/p&gt;</description>
        </item>
        <item>
        <title>Deploy DeepSeek-R1 locally</title>
        <link>https://ttf248.life/en/p/ollama-local-deployment-deepseek-r1/</link>
        <pubDate>Fri, 07 Feb 2025 22:41:02 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/ollama-local-deployment-deepseek-r1/</guid>
        <description>&lt;p&gt;Ollama is an open-source AI tool designed to enable users to run and deploy large language models (LLMs) locally. It aims to provide a convenient and efficient way for developers to use models like GPT on their local machines without relying on cloud services. Ollama supports various models and focuses on optimizing performance so that even resource-constrained devices can run them smoothly.&lt;/p&gt;
&lt;p&gt;With Ollama, users can utilize text-based AI applications and interact with locally deployed models without concerns about data privacy or high API usage fees. You can call different models through a command-line interface (CLI) for tasks like natural language processing and question answering.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Ollama is good for trying out different models. The Windows version doesn&amp;rsquo;t fully utilize hardware performance, likely due to Windows itself. The Linux version might be better. Deploying a 32B parameter model results in slow responses even with low memory and GPU load.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;hardware-overview&#34;&gt;Hardware Overview
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Operating system: win11&lt;/li&gt;
&lt;li&gt;CPUï¼ši7-10700K&lt;/li&gt;
&lt;li&gt;Memory: 40GB&lt;/li&gt;
&lt;li&gt;Graphics card: RTX 3060 12GB&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;environment-setup&#34;&gt;Environment Setup
&lt;/h2&gt;&lt;p&gt;Added system environment variable for future use&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_MODELS=E:\ollama&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
This variable specifies the storage path for Ollama models. &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; is a folder path where all local model files are stored. Ollama loads and uses your downloaded or deployed language models based on this path. You can store the model files in other locations by changing this path.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_HOST=127.0.0.1:8000&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
This environment variable sets the host and port for the Ollama service&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;127.0.0.1&lt;/code&gt; is a local address (localhost), meaning that the Ollama service will only listen for requests from the local machine&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; is the designated port number, indicating that the Ollama service will listen for and process requests on port 8000. You can change the port number as needed, but ensure it&amp;rsquo;s not occupied by another application.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_ORIGINS=*&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
This environment variable controls which sources of requests are allowed to access the Ollama service&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; indicates that any origin (i.e., all domains and IP addresses) is allowed to access the Ollama service. This is typically used in development and debugging environments; in production, more restrictive source control is usually specified to limit access to specific domains or IPs for enhanced security.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;deepseek-r1-model-deployment&#34;&gt;DeepSeek-R1 Model Deployment
&lt;/h2&gt;&lt;p&gt;Ollama installation is straightforward; details are omitted here&lt;/p&gt;
&lt;p&gt;Post-installation verification&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core&amp;gt;ollama -v
ollama version is 0.5.11
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Model deployment, refer to the official model page and select the corresponding parameters for the model: &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A 14B parameter model effectively remembers conversation context; smaller versions do not. The 32B parameter version is too slow for local deployment, so further testing was not conducted.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ollama.com/library/deepseek-r1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.ollama.com/library/deepseek-r1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/x18990027/article/details/145368094&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/x18990027/article/details/145368094&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>PowerShell 7 and Persistent Settings Command-Line Prediction View</title>
        <link>https://ttf248.life/en/p/powershell-7-persisting-settings-command-line-prediction-view/</link>
        <pubDate>Fri, 07 Feb 2025 22:19:12 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/powershell-7-persisting-settings-command-line-prediction-view/</guid>
        <description>&lt;p&gt;Having been accustomed to zsh on Linux, I recently discovered that PowerShell 7 also supports persistent settings for command-line prediction views. I tried it out and found it quite useful.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Not sure what action was taken, but this feature is enabled â€“ it just appeared&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In today&amp;rsquo;s diverse operating system environment, system administrators and developers are seeking a cross-platform, efficient, and powerful tool to meet their needs for system management and automation. PowerShell 7 is such a highly anticipated tool, offering robust scripting capabilities and enabling operation across Windows, Linux, and macOS, bringing unprecedented convenience to users.&lt;/p&gt;
&lt;h2 id=&#34;powershell-7-a-powerful-cross-platform-tool&#34;&gt;PowerShell 7: A Powerful Cross-Platform Tool
&lt;/h2&gt;&lt;h3 id=&#34;cross-platform-features&#34;&gt;Cross-platform features
&lt;/h3&gt;&lt;p&gt;PowerShell 7 removes platform limitations, allowing users to utilize a single tool for enterprise-level server management on Windows, system administration in Linux environments, or everyday development tasks on macOS. This significantly improves work efficiency and reduces learning costs and operational complexity caused by platform differences.&lt;/p&gt;
&lt;h3 id=&#34;powerful-features&#34;&gt;Powerful features
&lt;/h3&gt;&lt;p&gt;It features robust scripting capabilities, supporting object-oriented programming, functions, and modules. With PowerShell 7, users can easily manage the file system (creating, deleting, copying, moving files and folders), access and modify the registry for in-depth system configuration, and manage processes and services for effective monitoring and control. Furthermore, PowerShell 7 integrates with various Windows and non-Windows technologies, such as user and permission management in Active Directory and resource provisioning and management on Azure cloud platforms.&lt;/p&gt;
&lt;h3 id=&#34;open-source-ecosystem&#34;&gt;Open-source ecosystem
&lt;/h3&gt;&lt;p&gt;PowerShell 7 is open-source, enabling global developers and enthusiasts to actively participate in its development and improvement. A wealth of open-source modules and tools are constantly emerging, enriching PowerShell 7&amp;rsquo;s functionality and applications. Users can find suitable modules within the open-source community to extend PowerShell 7â€™s capabilities or contribute their own code to advance the entire community.&lt;/p&gt;
&lt;h3 id=&#34;compatibility-and-stability&#34;&gt;Compatibility and Stability
&lt;/h3&gt;&lt;p&gt;PowerShell 7 introduces numerous new features and improvements while maintaining compatibility with older PowerShell versions. These enhancements boost performance, increase stability, and allow users to complete tasks more smoothly, reducing interruptions due to software issues.&lt;/p&gt;
&lt;h2 id=&#34;open-command-line-prediction-view&#34;&gt;Open command-line prediction view
&lt;/h2&gt;&lt;p&gt;Among PowerShell 7&amp;rsquo;s many useful features, the &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; command is a practical tool that enhances the userâ€™s command-line experience&lt;/p&gt;
&lt;p&gt;Without enabling the command, inline auto-completion is available. Enabling it provides predictive suggestions in a list format, allowing users to select options with arrow keys, improving accuracy and efficiency of command input.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/powershell-7-persisting-settings-command-line-prediction-view/20250207222546.png&#34;
	width=&#34;814&#34;
	height=&#34;205&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;powershell7&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;397&#34;
		data-flex-basis=&#34;952px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;how-to-make-commands-persistent&#34;&gt;How to make commands persistent
&lt;/h2&gt;&lt;p&gt;To ensure a command takes effect each time PowerShell starts, you can add it to the PowerShell profile. The PowerShell profile is a special script that automatically executes its commands when PowerShell launches.&lt;/p&gt;
&lt;h3 id=&#34;confirm-configuration-file-path&#34;&gt;Confirm configuration file path
&lt;/h3&gt;&lt;p&gt;In PowerShell, we can use the &lt;code&gt;$_&lt;/code&gt; variable to view the configuration file path. If the file does not exist at that path, the user can create it manually.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;echo $PROFILE
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;open-configuration-file&#34;&gt;Open configuration file
&lt;/h3&gt;&lt;p&gt;Open the file corresponding to the configuration file path obtained through the &lt;code&gt;__INLINE_CODE_0&lt;/code&gt; variable using a text editor, such as the powerful Notepad++ or the lightweight Visual Studio Code&lt;/p&gt;
&lt;h3 id=&#34;add-command&#34;&gt;Add command
&lt;/h3&gt;&lt;p&gt;Add the &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; command to the open configuration file. Ensure the command is written accurately to guarantee it takes effect when the configuration file is executed.&lt;/p&gt;
&lt;h3 id=&#34;save-configuration-file&#34;&gt;Save configuration file
&lt;/h3&gt;&lt;p&gt;After adding the command, save the configuration file and close the text editor. The configuration file now includes the commands we want to execute each time PowerShell starts.&lt;/p&gt;
&lt;h3 id=&#34;verification-settings&#34;&gt;Verification Settings
&lt;/h3&gt;&lt;p&gt;Close the current PowerShell window and restart it. In the newly launched PowerShell, when entering commands, the command-line input prediction view should display in a list format, indicating that our settings have taken effect successfully.&lt;/p&gt;
&lt;p&gt;Through these steps, we not only gained a deeper understanding of PowerShell 7&amp;rsquo;s powerful features and capabilities but also learned how to enhance the user experience by setting command-line input prediction views and ensuring these settings persist. We hope this knowledge helps you use PowerShell 7 more confidently and efficiently to complete various system management and automation tasks.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/PowerShell/PowerShell/releases&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/PowerShell/PowerShell/releases&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.v2ex.com/t/911909&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.v2ex.com/t/911909&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Monitoring Linux System Metrics with atop: A Complete Guide to Installation, Configuration, and Usage</title>
        <link>https://ttf248.life/en/p/using-atop-to-monitor-linux-system-metrics-installation-configuration-and-usage-guide/</link>
        <pubDate>Thu, 06 Feb 2025 22:48:55 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/using-atop-to-monitor-linux-system-metrics-installation-configuration-and-usage-guide/</guid>
        <description>&lt;p&gt;Real-time and comprehensive monitoring of system resources and process status is crucial in Linux system maintenance. The atop tool, as a powerful monitoring utility, can help us achieve this goal easily. This article will detail how to install, configure, and use the atop monitoring tool on a Linux instance.&lt;/p&gt;
&lt;h2 id=&#34;introduction-to-atop-tool&#34;&gt;Introduction to atop tool
&lt;/h2&gt;&lt;p&gt;Atop is a tool dedicated to monitoring Linux system resources and processes. It records system and process activity, reporting on the status of all running processes. Data collected includes resource usage (CPU, memory, disk, network) and process states, which can be saved as log files. For each process, we obtain key information such as CPU utilization, memory growth, disk usage, priority, username, status, and exit code. Furthermore, through the Atop configuration file, users can customize parameters like logging frequency, storage path, and rotation policy.&lt;/p&gt;
&lt;h2 id=&#34;installing-atop-tool&#34;&gt;Installing atop tool
&lt;/h2&gt;&lt;p&gt;Installation methods for atop vary slightly across different Linux distributions; the following explanation uses a common operating system as an example&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Alibaba Cloud Linux 3/2ã€CentOS 7/8ã€Fedoraã€Rocky Linux 9&lt;/strong&gt;ï¼š&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Execute installation command:&lt;/li&gt;
&lt;li&gt;Start atop service:&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;Ubuntu / Debian&lt;/strong&gt;ï¼š&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Update software source list:&lt;/li&gt;
&lt;li&gt;Execute installation command:&lt;/li&gt;
&lt;li&gt;Start atop service:&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;CentOS Stream 9&lt;/strong&gt;ï¼š&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Download and install:&lt;/li&gt;
&lt;li&gt;Start atop service:&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;openSUSE&lt;/strong&gt;ï¼š&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Execute installation command:&lt;/li&gt;
&lt;li&gt;Start atop service:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If your operating system distribution is not listed above, please visit the atop official website for installation information&lt;/p&gt;
&lt;h2 id=&#34;configure-monitoring-cycle-and-log-retention-time&#34;&gt;Configure monitoring cycle and log retention time
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;In Alibaba Cloud Linux 3/2, CentOS 7/8, and Fedora systems, the atop configuration file is __ï¼›åœ¨Ubuntuã€Debianå’ŒopenSUSEç³»ç»Ÿä¸­ï¼Œé…ç½®æ–‡ä»¶æ˜¯__INLINE_CODE_1&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Used to control log file recording options; defaults to empty&lt;/li&gt;
&lt;li&gt;Monitoring cycle, default 600 seconds. To collect historical logs for troubleshooting, adjust this frequency as needed.&lt;/li&gt;
&lt;li&gt;Log retention period, default 28 days&lt;/li&gt;
&lt;li&gt;It appears you&amp;rsquo;ve provided a string of formatting codes rather than actual Chinese text. Without the Chinese characters, I cannot translate. Please provide the Chinese text you want translated.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Execute command to open configuration file:&lt;/li&gt;
&lt;li&gt;On Alibaba Cloud Linux 3/2, CentOS 7/8, and Fedora systems:&lt;/li&gt;
&lt;li&gt;In Ubuntu, Debian, openSUSE, CentOS Stream 9, Rocky Linux 9 systems:&lt;/li&gt;
&lt;li&gt;Enter edit mode by pressing &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;, then adjust the configuration parameters as needed. For example, change the monitoring cycle to 30 seconds, set the log retention time to 7 days, and keep the default log path:&lt;/li&gt;
&lt;li&gt;Press, save, and exit editing&lt;/li&gt;
&lt;li&gt;Restarting the atop service applies the configuration&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;LOGOPTS=&amp;quot;&amp;quot;
LOGINTERVAL=30
LOGGENERATIONS=7
LOGPATH=/var/log/atop 
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;using-the-atop-tool&#34;&gt;Using the atop tool
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;The following are common commands in interactive command mode:&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Switch back to the default combined output view&lt;/li&gt;
&lt;li&gt;Display the full command line of processes&lt;/li&gt;
&lt;li&gt;Sort by process memory usage in descending order&lt;/li&gt;
&lt;li&gt;Sort processes by disk usage in descending order&lt;/li&gt;
&lt;li&gt;Sort by process resource utilization in descending order&lt;/li&gt;
&lt;li&gt;Sort by process network usage in descending order&lt;/li&gt;
&lt;li&gt;Go to the next monitoring point&lt;/li&gt;
&lt;li&gt;Go to the previous monitoring point&lt;/li&gt;
&lt;li&gt;It appears you&amp;rsquo;ve provided a string of formatting codes rather than actual Chinese text. Without the Chinese characters, I cannot translate. Please provide the Chinese text you want translated.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Hostname, information sampling date and time&lt;/li&gt;
&lt;li&gt;Overall process runtime information, including kernel and user space execution time, total number of processes, and the count of processes in different states&lt;/li&gt;
&lt;li&gt;Overall CPU utilization, the sum of values for each field equals &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; (N being the number of CPU cores), including kernel time, user time, interrupts, idle time, and wait for disk I/O&lt;/li&gt;
&lt;li&gt;CPU load information, such as the average number of processes in the run queue over the past 1, 5, and 15 minutes, context switch count, and interrupt occurrence count&lt;/li&gt;
&lt;li&gt;Memory usage, including total physical memory, idle memory, page cache memory, file cache memory, and kernel occupied memory&lt;/li&gt;
&lt;li&gt;Swap space usage, including total swap area and free swap space size&lt;/li&gt;
&lt;li&gt;Virtual memory paging information, such as page swap in and swap out counts&lt;/li&gt;
&lt;li&gt;Disk usage, with each disk device represented by a column, displaying device identifier, busy time ratio, and read/write request count&lt;/li&gt;
&lt;li&gt;Network conditions, displaying receive and send packet sizes for TCP/UDP, IP layer, and active network interfaces&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Check system metrics every 5 seconds&lt;/li&gt;
&lt;li&gt;Check system metrics within the next 5 minutes (30 times, 10-second intervals): &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Check system metrics 10 minutes after the current time (10 times, with 60-second intervals) and write the results to a file: &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;After &lt;strong&gt;æŸ¥çœ‹å†å²æŒ‡æ ‡æ—¥å¿—&lt;/strong&gt; starts, log records are saved by default in the &lt;code&gt;/var/log/atop&lt;/code&gt; directory. When viewing, ensure the log file for the specified date exists, otherwise an error will occur.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;View daily history indicator logs&lt;/li&gt;
&lt;li&gt;View yesterday&amp;rsquo;s historical metric logs:&lt;/li&gt;
&lt;li&gt;View historical metric logs for a specified date, such as November 6, 2024&lt;/li&gt;
&lt;li&gt;View historical indicator logs from a specified time within a designated date range, such as from 2:00 PM on November 6, 2024&lt;/li&gt;
&lt;li&gt;View historical indicator logs for a specified date and time period, such as from 00:04 to 00:08 on November 5, 2024&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;View the CPU utilization report for the current system over 1 minute (12 times, with 5-second intervals): &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;View memory indicator reports for a specified time period on a given day, such as 18:00 to 18:01&lt;/li&gt;
&lt;li&gt;View memory metrics reports for specified dates and time periods, such as 6:00 PM to 6:01 PM on November 5, 2024&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;other-operations&#34;&gt;Other Operations
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;To generate an atop index log file daily, you can do the following:&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Adjust monitoring cycle, log retention time, and log storage path as needed&lt;/li&gt;
&lt;li&gt;Start the daily log rotation service and enable it to start automatically at boot&lt;/li&gt;
&lt;li&gt;If the business has more complex requirements for log processing, it can be combined with logrotate or custom scripts to implement log management&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;If network usage monitoring is required, you can install the netatop module (which is not installed by default in atop). For example, using Alibaba Cloud Linux 3 system:&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Install the kernel development package and software environment required for compilation&lt;/li&gt;
&lt;li&gt;Download the latest version of netatop source code to the designated directory&lt;/li&gt;
&lt;li&gt;Unzip the source code and enter the source directory: &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Build and install modules and daemons from source code&lt;/li&gt;
&lt;li&gt;Start netatop service:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The atop tool is powerful and flexible. With proper installation, configuration, and usage, we can better understand the status of a Linux system, promptly identify and resolve potential issues. We hope this article helps everyone improve their Linux system monitoring skills.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Loading mismatched PDB files in Visual Studio</title>
        <link>https://ttf248.life/en/p/visual-studio-loading-unmatched-pdb-files/</link>
        <pubDate>Thu, 23 Jan 2025 20:04:33 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/visual-studio-loading-unmatched-pdb-files/</guid>
        <description>&lt;p&gt;When debugging a program in Visual Studio on Windows, if the PDB file doesn&amp;rsquo;t match the executable, youâ€™ll receive a &amp;ldquo;Failed to load symbol file&amp;rdquo; error. Program crashes and resulting dump files will also fail to allow smooth entry into the crash scene if the PDB is mismatched.&lt;/p&gt;
&lt;h2 id=&#34;what-is-a-pdb-file&#34;&gt;What is a pdb file?
&lt;/h2&gt;&lt;p&gt;PDB files are debugging information files created by Microsoft, used for program debugging. They contain information such as symbol tables, source file names, and line numbers. PDB files are generated during compilation to aid in debugging.&lt;/p&gt;
&lt;h2 id=&#34;debugging-with-windbg&#34;&gt;Debugging with WinDbg
&lt;/h2&gt;&lt;p&gt;WinDbg is a debugging tool from Microsoft that can be used to debug Windows programs. WinDbg can load mismatched PDB files, but requires manual loading. The __INLINE_CODE_0 command can force the loading of mismatched PDB files.&lt;/p&gt;
&lt;p&gt;However, WinDbg is less convenient than Visual Studio, so we want Visual Studio to also load mismatched PDB files&lt;/p&gt;
&lt;h2 id=&#34;visual-studio-loading-mismatched-pdb-file&#34;&gt;Visual Studio loading mismatched PDB file
&lt;/h2&gt;&lt;p&gt;Source code is now typically managed using Git, allowing you to easily find corresponding versions, recompile them, and generate the associated PDB files. Why can&amp;rsquo;t they be loaded? Primarily due to metadata mismatches.&lt;/p&gt;
&lt;p&gt;A small tool can modify metadata, generate a new PDB file based on executable information, allowing Visual Studio to load it&lt;/p&gt;
&lt;p&gt;Download address for chkmatch: &lt;a class=&#34;link&#34; href=&#34;https://www.debuginfo.com/tools/chkmatch.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.debuginfo.com/tools/chkmatch.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Site cache address: &lt;a class=&#34;link&#34; href=&#34;chkmatch.zip&#34; &gt;chkmatch.zip&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;ChkMatch utility can be used to check whether an executable and debug information file match. It can also be used to enforce matching between an executable and debug information file, if they are compatible.

For more information about debug information matching and related issues, see this article.

Supported debug information formats: DBG, PDB 2.0, PDB 7.0.

chkmatch [-c ExeFile DebugInfoFile ] |
         [-m ExeFile DebugInfoFile]
-c
Check matching between the executable and the debug information file.
-m
Make the executable and the debug information file match.
ExeFile
The name of the executable file.
DebugInfoFile
The name of the debug information file.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;use-chkmatch&#34;&gt;Use chkmatch
&lt;/h2&gt;&lt;p&gt;First, perform a verification check, analyze the reason for the mismatch, and prompt that the signature does not match&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\tianlong.xiang\Downloads\chkmatch&amp;gt;ChkMatch.exe -c &amp;quot;D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe&amp;quot; E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb
ChkMatch - version 1.0
Copyright (C) 2004 Oleg Starodumov
http://www.debuginfo.com/


Executable: D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe
Debug info file: E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb

Executable:
TimeDateStamp: c26d9be3
Debug info: 2 ( CodeView )
TimeStamp: f86b0a4f  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 122  RVA: 001cdc44  FileOffset: 001cbe44
CodeView format: RSDS
Signature: {428c9b95-39a3-4a8d-a8e5-7be453684757}  Age: 1
PdbFile: D:\stock_UAT\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\obj\Release\YinTrade.Main.pdb
Debug info: 16 ( Unknown )
TimeStamp: 00000000  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 0  RVA: 00000000  FileOffset: 00000000

Debug information file:
Format: PDB 7.00
Signature: {06fae08e-c0a2-4f3d-9c7c-dfc684445dd1}  Age: 1

Result: Unmatched (reason: Signature mismatch)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then perform modification operations to match the PDB file with the EXE file&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\tianlong.xiang\Downloads\chkmatch&amp;gt;ChkMatch.exe -m &amp;quot;D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe&amp;quot; E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb
ChkMatch - version 1.0
Copyright (C) 2004 Oleg Starodumov
http://www.debuginfo.com/


Executable: D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe
Debug info file: E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb

Executable:
TimeDateStamp: c26d9be3
Debug info: 2 ( CodeView )
TimeStamp: f86b0a4f  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 122  RVA: 001cdc44  FileOffset: 001cbe44
CodeView format: RSDS
Signature: {428c9b95-39a3-4a8d-a8e5-7be453684757}  Age: 1
PdbFile: D:\stock_UAT\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\obj\Release\YinTrade.Main.pdb
Debug info: 16 ( Unknown )
TimeStamp: 00000000  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 0  RVA: 00000000  FileOffset: 00000000

Debug information file:
Format: PDB 7.00
Signature: {06fae08e-c0a2-4f3d-9c7c-dfc684445dd1}  Age: 1

Writing to the debug information file...
Result: Success.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://stackoverflow.com/questions/38147487/forcing-to-load-unmatched-symbols-in-visual-studio-2015-debugger&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;forcing-to-load-unmatched-symbols-in-visual-studio-2015-debugger&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Cursor AI programming IDE trial</title>
        <link>https://ttf248.life/en/p/cursor-ai-programming-ide-trial/</link>
        <pubDate>Thu, 23 Jan 2025 19:30:13 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cursor-ai-programming-ide-trial/</guid>
        <description>&lt;p&gt;Another year has passed. The biggest change at work is the noticeably increased involvement of AI. Previously, switching between different development languages required developers to be familiar with various APIs. Now, these basic code snippets can be generated by AI â€“ a great boon for developers.&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;Back in 2023, I revised two introductory articles. Now it&amp;rsquo;s 2025, and frankly, there hasnâ€™t been a significant improvement. It still requires developing one&amp;rsquo;s own understanding, being able to reasonably break down tasks, and most importantly, identifying bugs in AI-generated code.&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;Github copilot
&lt;/h2&gt;&lt;p&gt;I can&amp;rsquo;t recall the exact date, but I saw information stating that Singapore has deployed servers for domestic use. This means we no longer need to constantly use a VPN; only a VPN is required for login, after which it can be turned off.&lt;/p&gt;
&lt;p&gt;I use Github Copilot more often; this plugin can be used directly in VS Code and Visual Studio without switching between programs. Compared to ChatGPT, Github Copilot offers better project support and a friendlier interface. You can feed it portions of local files &lt;strong&gt;to generate code that aligns with your project.&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;cursor-ai&#34;&gt;Cursor AI
&lt;/h2&gt;&lt;p&gt;I recently saw a new AI programming IDE, Cursor AI. This IDE is based on GitHub Copilot, but it&amp;rsquo;s even more intelligent and can help you create files directly.&lt;/p&gt;
&lt;p&gt;It feels pretty good after a quick try, but my understanding of the existing project is still not enough. When dealing with many local project files and large-scale refactoring and optimization, I still need &lt;strong&gt;å¼€å‘è€…æ‹†åˆ†ä»»åŠ¡&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Switch to curso&amp;rsquo;s engineering mode, enter: Create a personal resume webpage with support for multiple style switching. Remember to fill in some personal information for data display.&lt;/p&gt;
&lt;p&gt;After a few tries, you&amp;rsquo;ll be able to get the following webpage. Of course, itâ€™s still quite simple, but itâ€™s pretty good for beginners.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Currently, registered users can enjoy 150 free trials of the premium API; paid users are limited to 5000 calls&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/p&gt;</description>
        </item>
        <item>
        <title>C&#43;&#43; Bitwise Operations Fundamentals: Bit Extraction and Flag Setting</title>
        <link>https://ttf248.life/en/p/cpp-bitwise-operations-basics-flags/</link>
        <pubDate>Fri, 17 Jan 2025 02:23:56 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-bitwise-operations-basics-flags/</guid>
        <description>&lt;p&gt;In practical C++ development, bitwise operations are a common technique, particularly when handling system states, flags, or control bits. This article will explain how to use bitwise operations to get and set specific flag bits through an example.&lt;/p&gt;
&lt;h3 id=&#34;basic-operating-concepts&#34;&gt;Basic operating concepts
&lt;/h3&gt;&lt;p&gt;In computers, data is stored as binary digits (bits) of 0 and 1. Bitwise operations are operations performed on these bits. C++ has several common bitwise operators:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Checks if a bit is 1&lt;/li&gt;
&lt;li&gt;Sets a specific bit to 1&lt;/li&gt;
&lt;li&gt;Used to invert a bit&lt;/li&gt;
&lt;li&gt;Reverse all bits&lt;/li&gt;
&lt;li&gt;Shift all bits several positions to the left&lt;/li&gt;
&lt;li&gt;Shift all bits right by several positions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this case, we need to perform a series of bit operations on a &lt;strong&gt;bold&lt;/strong&gt; &lt;em&gt;italicized&lt;/em&gt; value to represent different states using various flag bits&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;flowchart LR
    A[åŸå§‹æ•°å€¼: 00010000] --&amp;gt; B[å·¦ç§»: 00010000 &amp;lt;&amp;lt; 1]
    B --&amp;gt; C[ç»“æœ: 00100000]
    C --&amp;gt; D[å³ç§»: 00100000 &amp;gt;&amp;gt; 1]
    D --&amp;gt; E[ç»“æœ: 00010000]

    subgraph å·¦ç§»æ“ä½œ
        direction LR
        A --&amp;gt; B --&amp;gt; C
    end

    subgraph å³ç§»æ“ä½œ
        direction LR
        C --&amp;gt; D --&amp;gt; E
    end
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;requirements-analysis&#34;&gt;Requirements Analysis
&lt;/h3&gt;&lt;p&gt;According to the description in the question, we have a 16-bit flag used to represent different states. These states are represented by various binary bits, each corresponding to a specific meaning. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Whether it failed&lt;/li&gt;
&lt;li&gt;Is it compressed?&lt;/li&gt;
&lt;li&gt;Incremental?&lt;/li&gt;
&lt;li&gt;Is there a follow-up package?&lt;/li&gt;
&lt;li&gt;Normal request or logout&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;implement-using-bitwise-operations&#34;&gt;Implement using bitwise operations
&lt;/h3&gt;&lt;p&gt;We will use bit operations to set and get these flag bits. Specifically:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Get the value of a single bit (0 or 1)&lt;/li&gt;
&lt;li&gt;Set a bit to 1&lt;/li&gt;
&lt;li&gt;Set a bit to 0&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We first define a flag to store these flags. Then, we use bit operations to check and set the corresponding flags.&lt;/p&gt;
&lt;h3 id=&#34;c-example-code&#34;&gt;C++ example code
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;bitset&amp;gt;

// å®šä¹‰æ ‡å¿—ä½å¸¸é‡
const unsigned short BIT_0_FAIL = 1 &amp;lt;&amp;lt; 0;    // bit0 æ˜¯å¦å¤±è´¥
const unsigned short BIT_1_COMPRESSED = 1 &amp;lt;&amp;lt; 1; // bit1 æ˜¯å¦å‹ç¼©
const unsigned short BIT_2_INCREMENT = 1 &amp;lt;&amp;lt; 2;  // bit2 æ˜¯å¦å¢é‡
const unsigned short BIT_3_HAS_MORE = 1 &amp;lt;&amp;lt; 3;   // bit3 æ˜¯å¦æœ‰åç»­åŒ…
const unsigned short BIT_5_CANCEL = 1 &amp;lt;&amp;lt; 5;     // bit5 æ­£å¸¸è¯·æ±‚(0)æˆ–æ³¨é”€(1)

// æ£€æŸ¥æŸä¸€ä½æ˜¯å¦ä¸º1
bool isBitSet(unsigned short wInfo, unsigned short bitMask) {
    return (wInfo &amp;amp; bitMask) != 0;
}

// è®¾ç½®æŸä¸€ä½ä¸º1
void setBit(unsigned short&amp;amp; wInfo, unsigned short bitMask) {
    wInfo |= bitMask;
}

// æ¸…é™¤æŸä¸€ä½ï¼ˆè®¾ç½®ä¸º0ï¼‰
void clearBit(unsigned short&amp;amp; wInfo, unsigned short bitMask) {
    wInfo &amp;amp;= ~bitMask;
}

int main() {
    // å‡è®¾wInfoçš„åˆå§‹å€¼ä¸º0
    unsigned short wInfo = 0;

    // è®¾ç½®bit0ï¼ˆå¤±è´¥æ ‡å¿—ï¼‰
    setBit(wInfo, BIT_0_FAIL);
    
    // è®¾ç½®bit1ï¼ˆå‹ç¼©æ ‡å¿—ï¼‰
    setBit(wInfo, BIT_1_COMPRESSED);
    
    // æ‰“å°wInfoçš„äºŒè¿›åˆ¶å€¼
    std::cout &amp;lt;&amp;lt; &amp;quot;wInfo (in binary): &amp;quot; &amp;lt;&amp;lt; std::bitset&amp;lt;16&amp;gt;(wInfo) &amp;lt;&amp;lt; std::endl;

    // æ£€æŸ¥å„ä¸ªæ ‡å¿—ä½
    std::cout &amp;lt;&amp;lt; &amp;quot;bit0 (æ˜¯å¦å¤±è´¥): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_0_FAIL) ? &amp;quot;æ˜¯&amp;quot; : &amp;quot;å¦&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit1 (æ˜¯å¦å‹ç¼©): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_1_COMPRESSED) ? &amp;quot;æ˜¯&amp;quot; : &amp;quot;å¦&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit2 (æ˜¯å¦å¢é‡): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_2_INCREMENT) ? &amp;quot;æ˜¯&amp;quot; : &amp;quot;å¦&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit3 (æ˜¯å¦æœ‰åç»­åŒ…): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_3_HAS_MORE) ? &amp;quot;æ˜¯&amp;quot; : &amp;quot;å¦&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit5 (æ˜¯å¦æ³¨é”€): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_5_CANCEL) ? &amp;quot;æ˜¯&amp;quot; : &amp;quot;å¦&amp;quot;) &amp;lt;&amp;lt; std::endl;

    // æ¸…é™¤bit1ï¼ˆå‹ç¼©æ ‡å¿—ï¼‰
    clearBit(wInfo, BIT_1_COMPRESSED);
    
    // æ‰“å°æ›´æ–°åçš„wInfo
    std::cout &amp;lt;&amp;lt; &amp;quot;Updated wInfo (in binary): &amp;quot; &amp;lt;&amp;lt; std::bitset&amp;lt;16&amp;gt;(wInfo) &amp;lt;&amp;lt; std::endl;

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Run code, recommended by an old friend: &lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;wInfo (in binary): 0000000000000011
bit0 (æ˜¯å¦å¤±è´¥): æ˜¯
bit1 (æ˜¯å¦å‹ç¼©): æ˜¯
bit2 (æ˜¯å¦å¢é‡): å¦
bit3 (æ˜¯å¦æœ‰åç»­åŒ…): å¦
bit5 (æ˜¯å¦æ³¨é”€): å¦
Updated wInfo (in binary): 0000000000000001
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;code-explanation&#34;&gt;Code explanation
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Using bitwise operations (shifting, ANDing, ORing, XORing, etc.), we assign each flag a unique binary position&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The bolded and italicized elements are not part of the translation. Here&amp;rsquo;s the translation: It is a matter of great importance.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set the specific flag bit to 1&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To set a specific flag bit to 0&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary
&lt;/h3&gt;&lt;p&gt;Bit manipulation allows for efficient handling of multiple status flags. This technique is particularly useful in practical development, such as embedded systems, network protocols, and system state management, where bit flags are often used to represent multiple binary states, saving space and improving efficiency.&lt;/p&gt;
&lt;p&gt;This blog post aims to help you understand how to use bitwise operations in C++ for bit manipulation and setting. Mastering these skills is very helpful for writing efficient and maintainable code!&lt;/p&gt;</description>
        </item>
        <item>
        <title>Upgraded desktop PC to a 2.5G network card, accelerating local area network connections</title>
        <link>https://ttf248.life/en/p/desktop-upgrade-to-25g-network-card-accelerate-lan-interconnection/</link>
        <pubDate>Fri, 10 Jan 2025 00:37:52 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/desktop-upgrade-to-25g-network-card-accelerate-lan-interconnection/</guid>
        <description>&lt;p&gt;The desktop hardware upgrades continue â€“ we mentioned the PCIe adapter for solid-state drives in a previous article. Where did the old SSDs go? They weren&amp;rsquo;t wasted; they were removed and installed in the new computer I bought (a year ago).&lt;/p&gt;
&lt;p&gt;The new machine has impressive hardware specs: 2.5G dual network ports, PCIe 4.0, and WiFi 6&lt;/p&gt;
&lt;p&gt;Recently moved, and the room lacks a dedicated router for networking. Devices connect via wireless network. The ASUS motherboard desktop&amp;rsquo;s wireless card performance is lacking, possibly due to router wireless access or slow upload speeds between local networks, resulting in poor speed between machines. A new 2.5G NIC was purchased and installed in the desktop.&lt;/p&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/p&gt;
&lt;h2 id=&#34;network-instructions&#34;&gt;Network Instructions
&lt;/h2&gt;&lt;p&gt;The machines still use the original wireless network cards for internet access, but are directly connected with a network cable. Both ends have 2.5G network cards. How to connect them via Ethernet is widely documented online; remember to disable firewalls and designate one machine as the gateway.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TD;
    A[æœºå™¨1&amp;lt;br&amp;gt;IP: 192.168.4.1&amp;lt;br&amp;gt;å­ç½‘æ©ç : 255.255.255.0&amp;lt;br&amp;gt;é»˜è®¤ç½‘å…³: - &amp;lt;br&amp;gt;è‡ªåŠ¨è·å–DNS] --&amp;gt;|ç½‘çº¿ç›´è¿ï¼ˆ2.5Gï¼‰| B[æœºå™¨2&amp;lt;br&amp;gt;IP: 192.168.4.2&amp;lt;br&amp;gt;å­ç½‘æ©ç : 255.255.255.0&amp;lt;br&amp;gt;é»˜è®¤ç½‘å…³: 192.168.4.1&amp;lt;br&amp;gt;è‡ªåŠ¨è·å–DNS];
    A --&amp;gt;|æ— çº¿ç½‘å¡| Internet;
    B --&amp;gt;|æ— çº¿ç½‘å¡| Internet;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;speed-test-between-two-networks&#34;&gt;Speed test between two networks
&lt;/h2&gt;&lt;h3 id=&#34;router-local-area-network&#34;&gt;Router local area network
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core\Desktop\iperf-3.1.3-win32&amp;gt;iperf3.exe -c 192.168.3.237
Connecting to host 192.168.3.237, port 5201
[  4] local 192.168.3.122 port 1656 connected to 192.168.3.237 port 5201
[ ID] Interval           Transfer     Bandwidth
[  4]   0.00-1.00   sec  9.17 MBytes  76.7 Mbits/sec
[  4]   1.00-2.00   sec  9.91 MBytes  83.2 Mbits/sec
[  4]   2.00-3.00   sec  8.74 MBytes  73.3 Mbits/sec
[  4]   3.00-4.00   sec  10.2 MBytes  85.2 Mbits/sec
[  4]   4.00-5.00   sec  9.23 MBytes  77.1 Mbits/sec
[  4]   5.00-6.00   sec  8.80 MBytes  73.9 Mbits/sec
[  4]   6.00-7.01   sec  8.00 MBytes  66.8 Mbits/sec
[  4]   7.01-8.00   sec  7.69 MBytes  64.9 Mbits/sec
[  4]   8.00-9.01   sec  9.72 MBytes  81.1 Mbits/sec
[  4]   9.01-10.01  sec  7.63 MBytes  63.6 Mbits/sec
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bandwidth
[  4]   0.00-10.01  sec  89.0 MBytes  74.6 Mbits/sec                  sender
[  4]   0.00-10.01  sec  89.0 MBytes  74.6 Mbits/sec                  receiver

iperf Done.
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;direct-lan-connection&#34;&gt;Direct LAN connection
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core\Desktop\iperf-3.1.3-win32&amp;gt;iperf3.exe -c 192.168.4.1
Connecting to host 192.168.4.1, port 5201
[  4] local 192.168.4.2 port 1524 connected to 192.168.4.1 port 5201
[ ID] Interval           Transfer     Bandwidth
[  4]   0.00-1.01   sec   178 MBytes  1.48 Gbits/sec
[  4]   1.01-2.00   sec   204 MBytes  1.72 Gbits/sec
[  4]   2.00-3.00   sec   214 MBytes  1.80 Gbits/sec
[  4]   3.00-4.00   sec   229 MBytes  1.92 Gbits/sec
[  4]   4.00-5.00   sec   202 MBytes  1.69 Gbits/sec
[  4]   5.00-6.00   sec   213 MBytes  1.79 Gbits/sec
[  4]   6.00-7.00   sec   230 MBytes  1.93 Gbits/sec
[  4]   7.00-8.00   sec   192 MBytes  1.61 Gbits/sec
[  4]   8.00-9.00   sec   220 MBytes  1.84 Gbits/sec
[  4]   9.00-10.00  sec   230 MBytes  1.93 Gbits/sec
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bandwidth
[  4]   0.00-10.00  sec  2.06 GBytes  1.77 Gbits/sec                  sender
[  4]   0.00-10.00  sec  2.06 GBytes  1.77 Gbits/sec                  receiver

iperf Done.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Occasional disk recognition issues due to too many disks installed on ASUS Z490 motherboards</title>
        <link>https://ttf248.life/en/p/asus-motherboard-z490-too-many-disks-intermittent-disk-recognition/</link>
        <pubDate>Fri, 10 Jan 2025 00:08:51 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/asus-motherboard-z490-too-many-disks-intermittent-disk-recognition/</guid>
        <description>&lt;p&gt;Following on from the previous discussion, I encountered an issue where the wireless network card was not being recognized. Before rebuilding the partitions, I also researched other solutions online, such as removing the motherboard battery and disconnecting power for fifteen minutes; or upgrading to the latest BIOS driverâ€”but all of these proved problematic.&lt;/p&gt;
&lt;p&gt;Thinking there were still things to deal with, I switched to a limited network and ran the ethernet cable from the living room to the room. Then the problem reappeared â€“ the wired network wasn&amp;rsquo;t recognized either. I tried a drastic measure: reinstalling the system, which resulted in a missing partition error. If this had been happening consistently, I wouldnâ€™t have bothered troubleshooting for so long. This ASUS disk conflict seems intermittent and triggered by unstable system restarts.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Last week, a new disk was added to the desktop â€“ a 2TB solid-state drive from Yangtze Memory (YMTC), M.2 interface. The machine hasn&amp;rsquo;t been restarted since then until it was shut down yesterday.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;h2 id=&#34;reinstall-system&#34;&gt;Reinstall system
&lt;/h2&gt;&lt;p&gt;It&amp;rsquo;s been two years since I last reinstalled the system. The C drive is full, and Windows has its usual issues â€“ various software likes to store things on the C drive. So, I decided to reinstall the system. After reinstalling, the network card issue was resolved, and I restored my development environment the next day. Just as I was preparing a system backup, a new problem arose: the boot partition is missing after restarting the system.&lt;/p&gt;
&lt;p&gt;Following the steps from the previous article, I rebuilt the boot partition, but it&amp;rsquo;s unstable. It might not load after a reboot. I initially suspected issues with the case, then checked the hard drive cable connections several times, but everything seems fine.&lt;/p&gt;
&lt;h2 id=&#34;memory-revival&#34;&gt;Memory revival
&lt;/h2&gt;&lt;p&gt;Many years ago, this machine had an SSD installed using a PCIe adapter (plugged into the graphics card slot) instead of directly connecting it to the motherboard. This time, installing it directly on the motherboard might indicate a motherboard issue.&lt;/p&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;h2 id=&#34;motherboard-manual&#34;&gt;Motherboard manual
&lt;/h2&gt;&lt;p&gt;The motherboard manual contains an error: the labeled SATA port locations do not match the actual locations. With multiple disks installed in all available ports (many of which are older SSDs using SATA), and according to the manual, there&amp;rsquo;s a conflict between these ports. Testing revealed this conflict is triggered intermittently, causing the affected disk to fail to load. This is problematic as itâ€™s the system disk with the boot files, resulting in boot failures.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/asus-motherboard-z490-too-many-disks-intermittent-disk-recognition/20250110002401.png&#34;
	width=&#34;807&#34;
	height=&#34;847&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Z490&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;95&#34;
		data-flex-basis=&#34;228px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;solution&#34;&gt;Solution
&lt;/h2&gt;&lt;p&gt;Reinstalling the solid-state drive on the PCIe adapter resolves conflicts with the motherboard&amp;rsquo;s SATA ports, allowing the system to boot normally&lt;/p&gt;</description>
        </item>
        <item>
        <title>Unveiling the Secrets of ESP Partition, GPT Partition Table, and the Windows Operating Systems Collaboration</title>
        <link>https://ttf248.life/en/p/exploring-esp-gpt-and-windows-cooperation/</link>
        <pubDate>Thu, 09 Jan 2025 23:58:20 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/exploring-esp-gpt-and-windows-cooperation/</guid>
        <description>&lt;p&gt;Yesterday, after work, I got home and turned on my desktop. The system booted normally, but the wireless network card failed to load. Thinking the card might be loose, I opened the case and reinstalled it. This made things much worse; now the system won&amp;rsquo;t boot at all, and the bootloader has failed.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s been a while since I worked with desktop computers, so partitioning feels a bit unfamiliar. I used DisGenius to create a new blank partition (usually at the beginning of the disk) and allocated it as an ESP partition (defaulting to 300M). Then, I rebuilt the boot from within the PE system. Relevant information can be found online.&lt;/p&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;In the world of computer storage, ESP partitions, GPT partition tables, and Windows operating systems are closely linked, each playing a unique and crucial role in supporting stable system operation and efficient management. Before delving into them, however, it&amp;rsquo;s necessary to mention the &amp;ldquo;pioneer&amp;rdquo; in the history of computer partitioning â€“ the MBR partition table format. It reflects the evolution of technology by contrasting with later innovations. Today, letâ€™s explore their intrinsic connections and intricacies.&lt;/p&gt;
&lt;h2 id=&#34;mbr-partition-table--the-foundation-of-traditional-disk-partitioning&#34;&gt;MBR Partition Table â€“ The &amp;ldquo;Foundation&amp;rdquo; of Traditional Disk Partitioning
&lt;/h2&gt;&lt;p&gt;MBR, short for Master Boot Record, has existed since the early days of personal computers and dominated the hard drive partitioning field for decades&lt;/p&gt;
&lt;h3 id=&#34;basic-architecture&#34;&gt;Basic architecture
&lt;/h3&gt;&lt;p&gt;It is located in the first sector of the hard drive, also known as sector 0, and occupies 512 bytes. These 512 bytes are primarily divided into three parts: firstly, the boot program code, responsible for loading the operating system&amp;rsquo;s boot loader during computer startup, typically 446 bytes; secondly, the disk partition table, occupying 64 bytes, which can define up to 4 primary partition entries, each entry using 16 bytes to record parameters such as starting head, sector, cylinder, and partition type and size; finally, the last 2 bytes are the MBR termination flag &amp;ldquo;55 AA&amp;rdquo;, used to identify this sector as a valid MBR.&lt;/p&gt;
&lt;h3 id=&#34;historical-achievements-and-limitations&#34;&gt;Historical achievements and limitations
&lt;/h3&gt;&lt;p&gt;Initially, the MBR partition table adequately met the relatively simple storage needs of personal computers. It allowed operating systems to smoothly recognize hard drive partitions for orderly data storage and retrieval. However, as technology evolved, its limitations became increasingly apparent. On one hand, constrained by a 64-byte partition table space, it could only support a maximum of four primary partitions; creating more required the use of extended and logical partitions, adding complexity to disk management. On the other hand, with a maximum capacity of only 2TB, it struggled to keep pace with today&amp;rsquo;s high-capacity drivesâ€”often several terabytes or even dozensâ€”becoming a bottleneck for further storage technology development.&lt;/p&gt;
&lt;h2 id=&#34;esp-partition--the-systems-invisible-boot-key&#34;&gt;ESP Partition â€“ The System&amp;rsquo;s &amp;ldquo;Invisible Boot Key&amp;rdquo;
&lt;/h2&gt;&lt;p&gt;ESP, short for EFI System Partition, is a special partition required on computers using the UEFI (Unified Extensible Firmware Interface) standard&lt;/p&gt;
&lt;h3 id=&#34;features&#34;&gt;Features
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;When a computer powers on, the UEFI firmware first locates the ESP partition on the hard drive and reads the boot loader stored there (such as Windows Boot Manager), thereby initiating the operating system. It&amp;rsquo;s like a precise key that unlocks the gateway to system startup; without it, the system would be lost and confused at boot time.&lt;/li&gt;
&lt;li&gt;The ESP partition also stores essential drivers needed during system startup, ensuring that hardware devices (such as disk controllers and graphics cards) function correctly in the early boot phase, laying the foundation for the subsequent operating system to take over smoothly&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;space-requirements-and-format&#34;&gt;Space requirements and format
&lt;/h3&gt;&lt;p&gt;Typically, the ESP partition is recommended to be between 100MB and 500MB; allocating around 200MB usually suffices for basic needs. Its file system format must be FAT32 because UEFI firmware can only recognize this format for reading boot files, ensuring compatibility and cross-platform support.&lt;/p&gt;
&lt;h2 id=&#34;gpt-partition-table--the-smart-manager-of-your-hard-drive&#34;&gt;GPT Partition Table â€“ The &amp;ldquo;Smart Manager&amp;rdquo; of Your Hard Drive
&lt;/h2&gt;&lt;p&gt;GPT (GUID Partition Table), or Global Unique Identifier Partition Table, is a new partitioning scheme designed to replace traditional MBR partition tables&lt;/p&gt;
&lt;h3 id=&#34;advantages-revealed&#34;&gt;Advantages revealed
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;In today&amp;rsquo;s era of data explosion, high-capacity hard drives are constantly emerging. The GPT partition table overcomes the 2TB capacity limitation of MBR and theoretically supports up to 9.4 ZB (Zettabytes) â€“ an extremely large storage space enabling massive data storage.&lt;/li&gt;
&lt;li&gt;Unlike MBR, which limits partitioning to a maximum of four primary partitions, GPT allows for up to 128 partitions, providing users and system administrators with great flexibilityâ€”whether it&amp;rsquo;s dividing multiple system or data partitions, or reserving partitions for specific purposes&lt;/li&gt;
&lt;li&gt;The GPT partition table utilizes a redundant backup mechanism, storing partition information in both the hard drive header and tail. This allows the system to automatically recover from another backup if one partition table is damaged, significantly reducing the risk of data loss due to partition table failure and ensuring data security.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;structural-analysis&#34;&gt;Structural Analysis
&lt;/h3&gt;&lt;p&gt;The GPT partition table consists of several parts, including a protective MBR (retained for BIOS compatibility but not used for actual partitioning), a GPT header (storing basic information about the partition table, such as version, number of partitions, and table size), and an array of partition entries (each entry detailing key information like start/end sectors, GUID type, and unique identifier). These structures work together to precisely plan and manage disk space.&lt;/p&gt;
&lt;h2 id=&#34;windows-operating-system--a-digital-interaction-space-for-users&#34;&gt;Windows Operating System â€“ A &amp;ldquo;Digital Interaction Space&amp;rdquo; for Users
&lt;/h2&gt;&lt;p&gt;Windows, a widely used operating system worldwide, builds a user-friendly bridge between people and computer hardware&lt;/p&gt;
&lt;h3 id=&#34;integration-with-esp-partitions-and-gpt-partition-tables&#34;&gt;Integration with ESP partitions and GPT partition tables
&lt;/h3&gt;&lt;p&gt;During the Windows installation process on UEFI-based systems, the installer automatically creates an EFI System Partition (ESP) and deploys boot files to it. The hard drive is initialized with a GPT partition table, creating a system reserved partition (similar to the system boot file area in traditional BIOS), a Windows system partition (where core system files are installed), and other user-defined data partitions. Windows relies on the GPT partition table to accurately identify each partition, enabling smooth startup through the ESP, ensuring seamless integration for a fluid user experience.&lt;/p&gt;
&lt;h3 id=&#34;system-management-and-optimization-foundation&#34;&gt;System management and optimization foundation
&lt;/h3&gt;&lt;p&gt;Windows leverages the advantages of GPT partition tables for disk management during operation. For example, the Disk Management tool can easily identify GPT partitions, allowing users to conveniently create, delete, format, and resize them â€“ meeting diverse data storage needs at different stages. System updates, software installations, and other processes are also closely related to the partition layout; a well-planned partitioning scheme helps improve system performance and stability, reducing issues caused by insufficient disk space or partition confusion.&lt;/p&gt;
&lt;h2 id=&#34;practical-tips-maintenance-and-troubleshooting&#34;&gt;Practical Tips: Maintenance and Troubleshooting
&lt;/h2&gt;&lt;p&gt;Understanding their close relationship makes daily maintenance and troubleshooting much more systematic&lt;/p&gt;
&lt;h3 id=&#34;disk-space-management&#34;&gt;Disk space management
&lt;/h3&gt;&lt;p&gt;Regularly check the ESP partition space to avoid issues caused by insufficient space due to excessive startup items or software installations, which can affect system boot. For data partitions under GPT, plan storage effectively and promptly clear unnecessary files to prevent full partitions from impacting system operation.&lt;/p&gt;
&lt;h3 id=&#34;troubleshoot-startup-issues&#34;&gt;Troubleshoot startup issues
&lt;/h3&gt;&lt;p&gt;If the system fails to boot, first check the ESP partition for corruption or missing files. You can use the UEFI firmware&amp;rsquo;s built-in startup repair tool or enter a Windows recovery environment using the installation media to rebuild the ESP partitionâ€™s boot files. If you suspect a GPT partition table failure, use professional disk tools (such as DiskGenius) to check the integrity of the partition table and attempt to repair/restore backup partition information to recover lost partitions.&lt;/p&gt;
&lt;p&gt;ESP partitions, GPT partition tables, and the Windows operating system work like a precise team, each playing their part to create a stable and efficient computing environment. Understanding them not only helps us confidently install and maintain systems but also allows us to grasp the underlying logic of computers and navigate the digital world with ease. Reflecting on the rise and fall of the MBR partition table further highlights the power of technological progress, which drives storage technology forward to meet ever-increasing data storage demands.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Understanding GCC, GLIBC, and C&#43;&#43; Program Compatibility Issues</title>
        <link>https://ttf248.life/en/p/deep-understanding-gcc-glibc-cpp-compatibility-issues/</link>
        <pubDate>Mon, 06 Jan 2025 19:51:16 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/deep-understanding-gcc-glibc-cpp-compatibility-issues/</guid>
        <description>&lt;p&gt;In C++ development, GCC and GLIBC are essential components, and compatibility issues after program release often trouble developers. This article will delve into their nature, explore the root causes of compatibility problems, and discuss corresponding solutions.&lt;/p&gt;
&lt;h2 id=&#34;i-gcc-a-powerful-compiler-foundation&#34;&gt;I. GCC: A Powerful Compiler Foundation
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;GCC, the GNU Compiler Collection, is an open-source compiler suite developed by the GNU project. It&amp;rsquo;s far more than a typical compiler; it supports numerous mainstream languages including C, C++, Objective-C, Fortran, Ada, and Go, providing a one-stop solution for cross-language development.&lt;/li&gt;
&lt;li&gt;Taking C++ as an example, when we write a source file containing complex features such as classes, templates, and function overloading, GCC can convert the high-level C++ code into instruction sequences that the underlying machine can understand and execute, based on C++&amp;rsquo;s strict syntax and semantic rules. This process involves multiple fine-grained stages including lexical analysis, syntactic analysis, semantic analysis, optimization, and code generation.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;GCC first preprocesses the source file. During this process, it handles all directives, and after preprocessing, the source file is initially expanded.&lt;/li&gt;
&lt;li&gt;After preprocessing, the file enters the compilation stage. GCC, based on the C++ language standard, converts the source file into assembly code. It carefully checks the code structure, ensuring correct class inheritance, polymorphism implementation, and function call parameter matching. If any errors violating syntax or semantics are detected, it will promptly report them and terminate the compilation process. For example, if there is a mismatch between the function declaration and definition&amp;rsquo;s parameter list, GCC will precisely indicate the issue.&lt;/li&gt;
&lt;li&gt;The assembler converts the assembly code generated in the previous step into machine code, producing a target file with a &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; extension. These target files contain binary instructions that can be directly executed by the machine, but they cannot run independently because a complete program typically consists of multiple modules with unresolved function and variable references.&lt;/li&gt;
&lt;li&gt;This is the final sprint to generate an executable file. The linker integrates multiple object files and required library files (static or dynamic libraries). For example, when using container classes from the C++ Standard Template Library, the linker needs to find the corresponding library implementation code to ensure that functions like __INLINE_CODE_0__BOLD_3&lt;code&gt;list&lt;/code&gt; can be correctly called at runtime, ultimately generating a complete executable program.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ii-glibc-the-backbone-behind-c-program-execution&#34;&gt;II. GLIBC: The Backbone Behind C++ Program Execution
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;GLIBC, or the GNU C Library, is a specific implementation of the C standard library within the GNU ecosystem. Although its name highlights C, C++ programs are equally reliant on it, as C++ inherits much from C&amp;rsquo;s foundation. It provides a vast array of fundamental functions, such as those for memory management, and frequently appears in early C++ development and scenarios demanding high performance and conciseness.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;GLIBC acts as a crucial bridge between the operating system and applications. In Linux systems, when a C++ program makes a system callâ€”for example, to open a file (using a function that relies on GLIBC implementation)â€”GLIBC encapsulates the program&amp;rsquo;s request in the manner specified by the operating system kernel, passes it to the kernel, and returns the result to the application after the kernel has processed it. This allows applications to use various system resourcesâ€”such as file systems, networks, and process managementâ€”without needing to understand the complex details of the underlying system call interfaces.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;compatibility-issues-after-c-program-release&#34;&gt;Compatibility Issues After C++ Program Release
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Different Linux distributions often use different versions of GLIBC. When a C++ program is compiled in a high-version GLIBC environment, it may inadvertently utilize new functions or rely on optimized implementations introduced in that version. For example, newer GLIBC versions improve memory allocation algorithms, and programs frequently leverage these improvements for performance gains. If such a program is ported to a system with an older GLIBC version, it may encounter missing function errors (because the function wasn&amp;rsquo;t introduced in the older version) or abnormal function behavior (due to discrepancies between old and new implementations), leading to crashes or incorrect results.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Even when using the same GCC compiler, different versions exhibit variations in code generation, standard library support, and implementation details of C++ features. Newer GCC versions may offer complete support for the latest C++ standards (e.g., modules and coroutines in C++20). Compiling programs utilizing these advanced features with older GCC versions can result in errors due to unrecognized syntax; even without syntactic errors, differing optimization strategies across GCC versions can lead to significantly different machine code performanceâ€”affecting execution efficiency and memory usageâ€”potentially causing vastly different behavior in demanding scenarios.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;C++ programs may need to run on different hardware architectures, such as x86, ARM, and PowerPC. These architectures have their own unique instruction sets, memory layouts, and data alignment requirements. For example, a structure&amp;rsquo;s data storage layout that runs correctly on the x86 architecture can cause abnormal memory access and program errors on the ARM architecture due to different alignment rules. Furthermore, GCC generates significantly different machine code when compiling for different architectures; if the program contains hardcoded architecture-specific instructions or assumptions, cross-architecture runtime failures are inevitable.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;strategies-for-addressing-compatibility-issues&#34;&gt;Strategies for Addressing Compatibility Issues
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Consider using a static library, which packages the program&amp;rsquo;s dependencies (e.g., GLIBC) directly into the executable file. This eliminates runtime dependency on specific GLIBC versions, effectively preventing issues caused by version mismatches. However, static linking significantly increases the executable size and requires weighing the pros and cons in scenarios with limited storage resources.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;By leveraging containerization technologies like Docker, the C++ program and its required runtime environment (including specific versions of GCC, GLIBC, etc.) are encapsulated within a standalone container. This ensures consistent execution environments regardless of the underlying operating system, simplifying cross-environment deployment significantly.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Establish a comprehensive compatibility testing system covering various GLIBC versions, GCC versions, and common system architectures. Through continuous integration tools, conduct regular automated testing in multiple environments during development. Address any compatibility issues promptly to eliminate potential risks early on and ensure stability upon release.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thoroughly understanding the workings of GCC and GLIBC, accurately identifying the root causes of C++ compatibility issues, and skillfully applying solutions are essential skills for every C++ developer aiming to build robust, cross-platform applications. Only then can our C++ works navigate diverse technical ecosystems smoothly.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Disk Cleanup tool (built into Windows): Storage</title>
        <link>https://ttf248.life/en/p/windows-disk-cleanup-storage/</link>
        <pubDate>Mon, 06 Jan 2025 19:29:45 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/windows-disk-cleanup-storage/</guid>
        <description>&lt;p&gt;Starting from which version I am not sure, but in &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;, the Disk Cleanup tool has been significantly improved and become more intelligent&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s an official tool, so it wonâ€™t delete files by mistake, display ads, pop-ups, background processes, or any unnecessary elements&lt;/p&gt;
&lt;p&gt;To open the Disk Cleanup tool&lt;/p&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;p&gt;Ordinary users can choose &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;; the system will provide suggestions based on your usage&lt;/p&gt;
&lt;p&gt;As a developer, I have many temporary files on my disk, so I chose to delete those temporary files&lt;/p&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Docker domestic image proxy failure</title>
        <link>https://ttf248.life/en/p/docker-domestic-mirror-failure/</link>
        <pubDate>Sat, 04 Jan 2025 18:29:25 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/docker-domestic-mirror-failure/</guid>
        <description>&lt;p&gt;Deploying Docker on domestic servers. If the company doesn&amp;rsquo;t provide an image registry, developers must first configure a domestic mirror acceleration address. Today, I configured a mirror acceleration address on a server, but it consistently fails to pull images.&lt;/p&gt;
&lt;p&gt;Error message:&lt;/p&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/p&gt;
&lt;h2 id=&#34;troubleshooting-and-repair-attempts&#34;&gt;Troubleshooting and Repair Attempts
&lt;/h2&gt;&lt;p&gt;Initially, I attempted to switch to an alternative mirror address hoping to resolve the issue, but it proved ineffective; the problem persists&lt;/p&gt;
&lt;p&gt;Immediately, I began modifying the local DNS configuration, attempting to find a breakthrough at the network resolution level; unfortunately, after some debugging, the fault persisted&lt;/p&gt;
&lt;p&gt;The local network&amp;rsquo;s stability is now questionable, so I switched to my phoneâ€™s hotspot to bypass potential issues. However, the problem persists unchanged â€“ a frustrating result.&lt;/p&gt;
&lt;h2 id=&#34;problems-spreading&#34;&gt;Problems spreading
&lt;/h2&gt;&lt;p&gt;We have several servers available, all with Docker environments installed. Attempting to pull images from them proved unsuccessful; the error messages were identical across all devices, indicating a systemic issue rather than a problem with a single server.&lt;/p&gt;
&lt;p&gt;Further investigation revealed that the mirror proxy appeared to have failed instantly. Switching quickly to an overseas machine proved successful, and thankfully, image pulling resumed normally. This suggests the issue likely lies within the domestic network link or related configurations.&lt;/p&gt;
&lt;h2 id=&#34;strategic-adjustment-circumventing-solutions&#34;&gt;Strategic adjustment: Circumventing solutions
&lt;/h2&gt;&lt;p&gt;To overcome obstacles in accessing domestic images, and with foreign mirrors accessible, we&amp;rsquo;ve decided on a workaround to expedite project progress. We will first switch to a foreign server to pull the necessary images, then push them to a domestic mirror repository, effectively creating a &amp;ldquo;data bridge.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Meanwhile, the Dockerfile was modified to replace the image address with one suitable for domestic environments, and the image was rebuilt and successfully deployed&lt;/p&gt;</description>
        </item>
        <item>
        <title>CentOS 8 Stream EOL</title>
        <link>https://ttf248.life/en/p/centos-8-stream-eol/</link>
        <pubDate>Sat, 16 Nov 2024 23:24:50 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/centos-8-stream-eol/</guid>
        <description>&lt;p&gt;An upstream open-source development platform prior to release
First noticed the open-source operating system lifecycle&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It&amp;rsquo;s expired, what&amp;rsquo;s the problem? Besides security issues, DNF isn&amp;rsquo;t working. I noticed it failed when I recently installed a tool, and checking the mirror source revealed that it has expired.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;introduction-to-centos-stream&#34;&gt;Introduction to CentOS Stream
&lt;/h2&gt;&lt;h3 id=&#34;positioning-and-role&#34;&gt;Positioning and Role
&lt;/h3&gt;&lt;p&gt;CentOS Stream sits between Fedora Linux (upstream development) and RHEL (downstream development), acting as a bridge&lt;/p&gt;
&lt;p&gt;It can be seen as a version for experiencing the latest Red Hat Enterprise Linux features, suitable for early adopters&lt;/p&gt;
&lt;h3 id=&#34;birth-and-background&#34;&gt;Birth and Background
&lt;/h3&gt;&lt;p&gt;As time passed, Red Hat began seeking more effective ways to develop its enterprise-level Linux platform and launched CentOS Stream&lt;/p&gt;
&lt;p&gt;After CentOS 8 reached its end-of-life in late 2021, CentOS Stream continued to receive updates as its successor and has become the future direction of the CentOS project&lt;/p&gt;
&lt;h3 id=&#34;features-and-advantages&#34;&gt;Features and Advantages
&lt;/h3&gt;&lt;p&gt;CentOS Stream is a rolling-release Linux distribution offering faster updates. It provides greater transparency and opportunities for community, partner, and customer involvement, allowing users to contribute to Red Hat Enterprise Linux more quickly and directly.&lt;/p&gt;
&lt;p&gt;The content of CentOS Stream is software that Red Hat intends to include in a future stable version of RHEL, providing a stable ABI/API for community members for development and testing&lt;/p&gt;
&lt;h3 id=&#34;use-cases--target-users&#34;&gt;Use Cases &amp;amp; Target Users
&lt;/h3&gt;&lt;p&gt;CentOS Stream is suitable for CentOS users who want to continue receiving the latest Linux feature updates, as well as developers and partners who wish to participate in Red Hat Enterprise Linux development&lt;/p&gt;
&lt;p&gt;It also aims to help community members, Red Hat partners, and others fully leverage innovative open-source programs within a more stable and predictable Linux ecosystem&lt;/p&gt;
&lt;h2 id=&#34;please-provide-the-chinese-text-you-want-me-to-translate-i-am-ready-when-you-are-just-paste-the-text-here&#34;&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Release&lt;/th&gt;
&lt;th&gt;Released&lt;/th&gt;
&lt;th&gt;Active Support&lt;/th&gt;
&lt;th&gt;Security Support&lt;/th&gt;
&lt;th&gt;Latest&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;3 years ago (15 Sep 2021)&lt;/td&gt;
&lt;td&gt;Ends in 2 years and 6 months (31 May 2027)&lt;/td&gt;
&lt;td&gt;Ends in 2 years and 6 months (31 May 2027)&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;5 years ago (24 Sep 2019)&lt;/td&gt;
&lt;td&gt;Ended 5 months and 3 weeks ago (31 May 2024)&lt;/td&gt;
&lt;td&gt;Ended 5 months and 3 weeks ago (31 May 2024)&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;solution&#34;&gt;Solution
&lt;/h2&gt;&lt;p&gt;Opted for a long-term support (LTS) version to avoid the hassle of upgrades&lt;/p&gt;</description>
        </item>
        <item>
        <title>Customizing Hugo Themes with Modules: An Explanation of Ideas</title>
        <link>https://ttf248.life/en/p/hugo-module-custom-theme-ideas/</link>
        <pubDate>Fri, 15 Nov 2024 22:01:17 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/hugo-module-custom-theme-ideas/</guid>
        <description>&lt;p&gt;The site has switched themes many times, with custom modifications made each time. Here&amp;rsquo;s a record of the ideas behind customizing my themes.&lt;/p&gt;
&lt;h2 id=&#34;hugos-modules&#34;&gt;Hugo&amp;rsquo;s Modules
&lt;/h2&gt;&lt;p&gt;When people think of modularity, they often consider things like Nginx modules or IDEA plugins. Typically, it allows me to meet my differentiated needs by uploading certain modules. The popularity of this approach stems from its flexibility â€“ it easily satisfies individual requirements without much effort. Often, while the overall functionality is similar, there are always some subtle differences. This highlights the complexity of software, which includes not only technical complexities but also business complexities. Most often, we face business complexities. This perfectly illustrates the saying &amp;ldquo;like a mountain between different professions.&amp;rdquo; Nowadays, modularity isn&amp;rsquo;t just used in the internet industry; itâ€™s adopted by finance and even traditional manufacturing to support enterprise production and management through information systems. Even for something as simple as a leave request system, companies within the same industry can have significant differences.&lt;/p&gt;
&lt;p&gt;This module differs from what people typically expectâ€”it&amp;rsquo;s not organized by function to meet diverse needs, but rather based on directory structure to identify common patterns&lt;/p&gt;
&lt;p&gt;Data link: &lt;a class=&#34;link&#34; href=&#34;https://medium.com/@sunwei.xyz/07-hugo%E6%9E%B6%E6%9E%84-hugo%E7%9A%84%E6%A8%A1%E5%9D%97-8ef5a520a822&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;07. Hugoæ¶æ„ â€” Hugoçš„æ¨¡å—&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[[imports]]
path = &amp;quot;github.com/CaiJimmy/hugo-theme-stack/v3&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This method still works, but is not recommended in this article. If the theme has been updated, maintaining it will be more complicated and require a separate Git repository for management.&lt;/p&gt;
&lt;h2 id=&#34;please-provide-the-chinese-text-you-want-me-to-translate-i-am-ready-when-you-are-just-paste-the-text-here&#34;&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.
&lt;/h2&gt;&lt;p&gt;With a foundational understanding of modularity, grasping custom themes becomes much easier. Current themes are also assembled from multiple different modules; to modify one, simply locate the corresponding template file and make your changes.&lt;/p&gt;
&lt;p&gt;Extracted from official documentation:&lt;/p&gt;
&lt;p&gt;Using this method, there won&amp;rsquo;t be any file under &lt;code&gt;themes&lt;/code&gt; directory. In order to modify the theme, you will have to copy the file you want to modify to the same directory under &lt;code&gt;layouts&lt;/code&gt; directory.&lt;/p&gt;
&lt;p&gt;For example, in order to modify the &lt;code&gt;themes/hugo-theme-stack/layouts/partials/head/custom.html&lt;/code&gt; file, you will have to copy it to &lt;code&gt;layouts/partials/head/custom.html&lt;/code&gt; and modify it there (copy the code from theme&amp;rsquo;s repository). The same applies to &lt;code&gt;assets&lt;/code&gt; and &lt;code&gt;static&lt;/code&gt; directoriesã€‚&lt;/p&gt;
&lt;h2 id=&#34;how-to-find-the-template-file&#34;&gt;How to find the template file
&lt;/h2&gt;&lt;h3 id=&#34;orthodox-approach&#34;&gt;Orthodox approach
&lt;/h3&gt;&lt;p&gt;Examine the theme&amp;rsquo;s source files, understand its design, locate the relevant template files, and make your changes&lt;/p&gt;
&lt;h3 id=&#34;brute-force-approach&#34;&gt;Brute force approach
&lt;/h3&gt;&lt;p&gt;As I&amp;rsquo;m not very familiar with front-end code, I sometimes use a brute-force approach: opening the relevant page in my browser, locating what needs modification, searching for it using &lt;code&gt;å®¡æŸ¥å…ƒç´ &lt;/code&gt;çš„æ–¹å¼ï¼Œå®šä½åˆ°__INLINE_CODE_1__ within the theme source code, finding the corresponding file, copying it to the site directory, and then making changes&lt;/p&gt;
&lt;h2 id=&#34;little-tips&#34;&gt;Little tips
&lt;/h2&gt;&lt;p&gt;The platform provides a default file for custom styling. We can split the modifications into multiple files and use &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; to import them, which allows for better style management.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/hugo-module-custom-theme-ideas/image.png&#34;
	width=&#34;141&#34;
	height=&#34;375&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;37&#34;
		data-flex-basis=&#34;90px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;summary-of-changes-6h&#34;&gt;Summary of Changes (6h)
&lt;/h2&gt;&lt;p&gt;Anything is easily manageable now&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Overall: Global text style, maintains the display style of previous &lt;code&gt;even&lt;/code&gt; èåˆ &lt;strong&gt;INLINE_CODE_1&lt;/strong&gt;, and is friendly to Chinese&lt;/li&gt;
&lt;li&gt;Homepage: Add mouse interaction animation to the right navigation&lt;/li&gt;
&lt;li&gt;Homepage: Article summaries added (implementation was quick, using a shortcut method)&lt;/li&gt;
&lt;li&gt;Scrollbar: Styled the appearance of the scrollbar&lt;/li&gt;
&lt;li&gt;The code highlighting plugin &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; has been introduced to style code blocks&lt;/li&gt;
&lt;li&gt;Partial content is reprinted; original author and link information have been added&lt;/li&gt;
&lt;li&gt;Archive page: Remove the theme&amp;rsquo;s color overlay from the top category image, displaying the original image&lt;/li&gt;
&lt;li&gt;Archive page: Added statistical display panel categorized by year&lt;/li&gt;
&lt;li&gt;Archive page: Two-column layout&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The script uses custom special variables to achieve summary previews&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Sometimes, excessive code reuse can also be a problem, leading to changes in one area affecting others. Therefore, when modifying the theme, be sure to avoid disrupting existing logic.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;comments-section&#34;&gt;Comments section
&lt;/h3&gt;&lt;p&gt;This guy&amp;rsquo;s revisions are more complete: &lt;a class=&#34;link&#34; href=&#34;https://blog.reincarnatey.net/2024/0719-better-waline/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.reincarnatey.net/2024/0719-better-waline/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;STRIKE_11&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Recommended homepage, email contact. This site does not have a comments section.&lt;/p&gt;
&lt;/blockquote&gt;</description>
        </item>
        <item>
        <title>Slow efficiency when processing large string data in Linux backend services</title>
        <link>https://ttf248.life/en/p/linux-backend-slow-string-processing/</link>
        <pubDate>Wed, 13 Nov 2024 19:42:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-backend-slow-string-processing/</guid>
        <description>&lt;p&gt;In past C++ development projects, we used a custom protocol for communication that employed a two-dimensional array structure. Due to inefficient traversal and serialization of this array when handling large amounts of data, the system experienced noticeable lag under high load, prompting feedback from the business department regarding these slowdowns.&lt;/p&gt;
&lt;h2 id=&#34;issue-identification&#34;&gt;Issue identification
&lt;/h2&gt;&lt;p&gt;During troubleshooting, we first performed a performance analysis of the system. We found that CPU usage increased significantly and response times lengthened when processing large amounts of data. Analyzing system logs revealed numerous serialization operations, which were inefficient when handling two-dimensional arrays, leading to decreased system performance.&lt;/p&gt;
&lt;p&gt;The tool&amp;rsquo;s thread analysis revealed that the logging thread spends most of its time string concatenation&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The key takeaway today is that different accumulation methods have vastly different efficiencies. Legacy code used the &lt;code&gt;__INLINE_CODE_0&lt;/code&gt; operator, which frequently creates temporary objects and is very inefficientâ€”the kind of inefficiency you know is bad but don&amp;rsquo;t realize just how bad it is.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;demo-verification&#34;&gt;Demo verification
&lt;/h2&gt;&lt;p&gt;We extracted the business logic based on the project code and created a simple demo to verify the efficiency of string concatenation. We compared the efficiency while compiling and running it in &lt;code&gt;windows&lt;/code&gt; ä¸‹çš„ &lt;code&gt;vs2022&lt;/code&gt; ç¼–è¯‘å™¨ï¼Œ&lt;strong&gt;INLINE_CODE_2&lt;/strong&gt; ä¸‹çš„ &lt;strong&gt;INLINE_CODE_3&lt;/strong&gt; ç¼–è¯‘å™¨ï¼Œ&lt;strong&gt;INLINE_CODE_4&lt;/strong&gt; mode.&lt;/p&gt;
&lt;h3 id=&#34;key-points&#34;&gt;Key points
&lt;/h3&gt;&lt;p&gt;The project uses method four. Before receiving the test data, readers can first consider which approach is most efficient and which is least efficient. I was still surprised by the results.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Concatenate each field directly into a string&lt;/li&gt;
&lt;li&gt;Using streams (concatenating) to join each field is more efficient, especially when dealing with large amounts of data&lt;/li&gt;
&lt;li&gt;Pre-allocating sufficient memory for strings reduces the overhead of memory reallocation, thereby improving performance&lt;/li&gt;
&lt;li&gt;Creating a new temporary string object for each concatenation degrades performance, especially during large-scale concatenations, as it involves repeated memory allocation and copying&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Based on the results, the project selected the least efficient method&lt;/p&gt;
&lt;p&gt;Furthermore, let&amp;rsquo;s analyze the optimization efficiency of different platforms&amp;rsquo; compilers. Microsoft&amp;rsquo;s compiler falls short in this regard.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Running the code on different machines makes direct comparison of the data meaningless; instead, compare the differences between different concatenation methods&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;windows å¹³å°ä¸‹çš„ vs2022 ç¼–è¯‘å™¨

----------------------------------------
Data Generation Time: 0.054 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.053 seconds.
+ ostringstream Data merging took: 0.054 seconds.
+ Pre-reserved Data merging took: 0.045 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 16.108 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;linux å¹³å°ä¸‹çš„ gcc8.5 ç¼–è¯‘å™¨
----------------------------------------
Data Generation Time: 0.108 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.100 seconds.
+ ostringstream Data merging took: 0.083 seconds.
+ Pre-reserved Data merging took: 0.057 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 29.298 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code&#34;&gt;Complete code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;random&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;sstream&amp;gt;
#include &amp;lt;iomanip&amp;gt;

typedef std::vector&amp;lt;std::string&amp;gt; DataRow;
typedef std::vector&amp;lt;DataRow&amp;gt; DataGroup;

struct ResponsePackage
{
    std::string ErrorInfo;
    DataRow Head;
    std::string ClientId;
    std::string UUID;
    std::string MsgID;
    std::string SessionID;
    std::string ExtraInfo1;
    std::string ExtraInfo2;
    DataGroup DataBody;
};

// Generate specified length of random string
std::string generateRandomString(size_t length)
{
    const char charset[] = &amp;quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&amp;quot;;
    const size_t max_index = sizeof(charset) - 1;
    std::string random_string;
    random_string.reserve(length);

    std::random_device rd;
    std::mt19937 generator(rd());
    std::uniform_int_distribution&amp;lt;&amp;gt; distribution(0, max_index);

    for (size_t i = 0; i &amp;lt; length; ++i)
    {
        random_string += charset[distribution(generator)];
    }

    return random_string;
}

void create_large_string()
{
    // Example request package with 50 fields
    ResponsePackage requestPackage;

    requestPackage.Head = {
        &amp;quot;Field1&amp;quot;, &amp;quot;Field2&amp;quot;, &amp;quot;Field3&amp;quot;, &amp;quot;Field4&amp;quot;, &amp;quot;Field5&amp;quot;,
        &amp;quot;Field6&amp;quot;, &amp;quot;Field7&amp;quot;, &amp;quot;Field8&amp;quot;, &amp;quot;Field9&amp;quot;, &amp;quot;Field10&amp;quot;,
        &amp;quot;Field11&amp;quot;, &amp;quot;Field12&amp;quot;, &amp;quot;Field13&amp;quot;, &amp;quot;Field14&amp;quot;, &amp;quot;Field15&amp;quot;,
        &amp;quot;Field16&amp;quot;, &amp;quot;Field17&amp;quot;, &amp;quot;Field18&amp;quot;, &amp;quot;Field19&amp;quot;, &amp;quot;Field20&amp;quot;,
        &amp;quot;Field21&amp;quot;, &amp;quot;Field22&amp;quot;, &amp;quot;Field23&amp;quot;, &amp;quot;Field24&amp;quot;, &amp;quot;Field25&amp;quot;,
        &amp;quot;Field26&amp;quot;, &amp;quot;Field27&amp;quot;, &amp;quot;Field28&amp;quot;, &amp;quot;Field29&amp;quot;, &amp;quot;Field30&amp;quot;,
        &amp;quot;Field31&amp;quot;, &amp;quot;Field32&amp;quot;, &amp;quot;Field33&amp;quot;, &amp;quot;Field34&amp;quot;, &amp;quot;Field35&amp;quot;,
        &amp;quot;Field36&amp;quot;, &amp;quot;Field37&amp;quot;, &amp;quot;Field38&amp;quot;, &amp;quot;Field39&amp;quot;, &amp;quot;Field40&amp;quot;,
        &amp;quot;Field41&amp;quot;, &amp;quot;Field42&amp;quot;, &amp;quot;Field43&amp;quot;, &amp;quot;Field44&amp;quot;, &amp;quot;Field45&amp;quot;,
        &amp;quot;Field46&amp;quot;, &amp;quot;Field47&amp;quot;, &amp;quot;Field48&amp;quot;, &amp;quot;Field49&amp;quot;, &amp;quot;Field50&amp;quot;
    };

    requestPackage.ClientId = &amp;quot;ClientID&amp;quot;;
    requestPackage.UUID = &amp;quot;UUID&amp;quot;;
    requestPackage.MsgID = &amp;quot;MsgID&amp;quot;;
    requestPackage.SessionID = &amp;quot;SessionID&amp;quot;;
    requestPackage.ExtraInfo1 = &amp;quot;ExtraInfo1&amp;quot;;
    requestPackage.ExtraInfo2 = &amp;quot;ExtraInfo2&amp;quot;;

    // Start timing for data generation
    auto start_gen = std::chrono::high_resolution_clock::now();

    // Generate 10,000 rows of data, each with 50 fields
    for (size_t i = 0; i &amp;lt; 10000; ++i)
    {
        DataRow dataRow(50, &amp;quot;This is a test string&amp;quot;);
        requestPackage.DataBody.push_back(dataRow);
    }

    // End timing for data generation
    auto end_gen = std::chrono::high_resolution_clock::now();
    std::chrono::duration&amp;lt;double&amp;gt; duration_gen = end_gen - start_gen;

    // Display result generation time
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Generation Time: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_gen.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    // Data merging using different methods
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Performance:\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    {
        // Method 1: Using &#39;+=&#39; string concatenation
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys(&amp;quot;&amp;quot;);
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (+=) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 2: Using ostringstream
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::ostringstream bodys;
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::ostringstream body;
            body &amp;lt;&amp;lt; &amp;quot;This is a test string&amp;quot;;
            for (auto&amp;amp; item : vec)
            {
                body &amp;lt;&amp;lt; item &amp;lt;&amp;lt; &amp;quot; &amp;quot;;
            }
            bodys &amp;lt;&amp;lt; body.str() &amp;lt;&amp;lt; &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ ostringstream Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 3: Pre-allocated memory
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys;
        bodys.reserve(1000 * 50 * 20); // Pre-allocate enough memory
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            body.reserve(50 * 20); // Pre-allocate memory for each row
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Pre-reserved Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 4: Using &#39;bodys = bodys + body + &amp;quot;\n&amp;quot;&#39;
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys(&amp;quot;&amp;quot;);
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            for (auto&amp;amp; item : vec)
            {
                body = body + item + &amp;quot; &amp;quot;; // Note the use of &#39;body = body + item&#39;
            }
            bodys = bodys + body + &amp;quot;\n&amp;quot;; // Again, using &#39;bodys = bodys + body&#39;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (bodys = bodys + body + \&amp;quot;\\n\&amp;quot;) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Complete.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;
}

int main()
{
    try
    {
        create_large_string();
    }
    catch (const std::exception&amp;amp; e)
    {
        std::cerr &amp;lt;&amp;lt; &amp;quot;Caught exception: &amp;quot; &amp;lt;&amp;lt; e.what() &amp;lt;&amp;lt; std::endl;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\nProgram finished.\n&amp;quot;;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Lambda expression parameter lifetime in C&#43;&#43;</title>
        <link>https://ttf248.life/en/p/cpp-lambda-parameter-lifetime/</link>
        <pubDate>Wed, 13 Nov 2024 19:23:02 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-lambda-parameter-lifetime/</guid>
        <description>&lt;p&gt;In C++, lambda expressions are convenient anonymous functions that can capture external variables and use them internally. This makes lambdas a flexible programming tool. However, the lifecycle of lambda expression parameters is an aspect requiring special attention, particularly when capturing and passing arguments.&lt;/p&gt;
&lt;h3 id=&#34;lambda-expression-parameter-lifecycle&#34;&gt;Lambda expression parameter lifecycle
&lt;/h3&gt;&lt;p&gt;The lifetime of lambda expression parameters generally mirrors that of other C++ functions. Parameters exist during the function call and end when the call completes. However, due to potential capture of external variables, parameter lifetimes can also be affected by the capturing method.&lt;/p&gt;
&lt;h3 id=&#34;the-relationship-between-capture-and-parameter-lifecycle&#34;&gt;The relationship between capture and parameter lifecycle
&lt;/h3&gt;&lt;h4 id=&#34;capturing-external-variables&#34;&gt;Capturing External Variables
&lt;/h4&gt;&lt;p&gt;C++ lambda expressions allow capturing external variables in two ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;By value capture, the values of external variables are copied into the lambda, and the lifecycle of these copies is controlled by the lambda&amp;rsquo;s lifecycle&lt;/li&gt;
&lt;li&gt;Through capturing references, external variable references are preserved; lambda&amp;rsquo;s references point to the original external variables, and their lifecycle depends on the external variables&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int x = 10;
auto lambda_by_value = [x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };  // æ•è·xçš„å‰¯æœ¬
auto lambda_by_reference = [&amp;amp;x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };  // æ•è·xçš„å¼•ç”¨

lambda_by_value();  // æ‰“å°10
lambda_by_reference();  // æ‰“å°10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The lifecycle of captured variables is as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When a variable is captured, its value is copied into the lambda; when the lambda&amp;rsquo;s lifecycle ends, this copy is destroyed&lt;/li&gt;
&lt;li&gt;Lambda functions hold references to external variables&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;lambda-parameters&#34;&gt;Lambda Parameters
&lt;/h4&gt;&lt;p&gt;Lambda parameters are similar to regular function parameters, with a lifecycle limited to the lambda function body. They are created upon lambda invocation and terminate when the invocation is complete.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;auto lambda = [](int a, int b) {
    std::cout &amp;lt;&amp;lt; a + b &amp;lt;&amp;lt; std::endl;
};
lambda(5, 10);  // aå’Œbåœ¨è¿™é‡Œæ˜¯lambdaçš„å‚æ•°
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, &lt;code&gt;a&lt;/code&gt;BOLD_2&lt;code&gt;b&lt;/code&gt; are the parameters of the lambda expression; they are created when the lambda is called and destroyed after it finishes executing&lt;/p&gt;
&lt;h3 id=&#34;lifecycle-issues-when-capturing-external-variables&#34;&gt;Lifecycle issues when capturing external variables
&lt;/h3&gt;&lt;h4 id=&#34;whether-captured-variables-are-valid-outside-of-the-lambda&#34;&gt;Whether captured variables are valid outside of the lambda
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Even if external variables are destroyed after a lambda call, the lambda internally still holds a copy of those variables. Therefore, the internal copy can be used safely, even if the external variables no longer exist.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int x = 10;
auto lambda = [x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };
x = 20;  // x åœ¨lambdaè°ƒç”¨åä¿®æ”¹
lambda();  // æ‰“å°10ï¼Œæ•è·çš„æ˜¯xçš„å‰¯æœ¬
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;If a lambda captures a reference to an external variable, access to that reference within the lambda depends on the lifetime of the external variable. If the external variable is destroyed before the lambda executes, it can lead to a dangling reference and undefined behavior.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int x = 10;
auto lambda = [&amp;amp;x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };
x = 20;  // x åœ¨lambdaè°ƒç”¨å‰ä¿®æ”¹
lambda();  // æ‰“å°20ï¼Œæ•è·çš„æ˜¯xçš„å¼•ç”¨
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;It&amp;rsquo;s crucial to ensure that captured external variables remain valid when the lambda is executed if the order of execution for lambdas is uncertain&lt;/p&gt;
&lt;/blockquote&gt;</description>
        </item>
        <item>
        <title>Installing Win11 Logitech G431 Headset Drivers</title>
        <link>https://ttf248.life/en/p/win11-logitech-g431-headphone-driver-installation/</link>
        <pubDate>Wed, 05 Jun 2024 07:20:17 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/win11-logitech-g431-headphone-driver-installation/</guid>
        <description>&lt;p&gt;Picking up where we left off, I came back to find an update for Ghub. It was a little exciting that the customer service issue of not being able to load properly seemed to be resolved. However, after a lot of troubleshooting â€“ reinstalling and uninstalling â€“ it still doesn&amp;rsquo;t work correctly.&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background
&lt;/h2&gt;&lt;p&gt;I contacted customer service for a solution, but was told an engineer could provide remote assistance. Unfortunately, their working hours are the same as mine, so I had to give up. Now I&amp;rsquo;m reviewing previous troubleshooting records and preparing to manually install the driver.&lt;/p&gt;
&lt;h2 id=&#34;get-the-driver-installation-package&#34;&gt;Get the driver installation package
&lt;/h2&gt;&lt;p&gt;How can I obtain the driver files since Logitech doesn&amp;rsquo;t provide standalone driver installation packages?&lt;/p&gt;
&lt;p&gt;Using the system image installation package left over from the previous system reinstall, we can reinstall the system in a local virtual machine. In a clean environment, deploy Ghub separately, integrate the headset device into the virtual machine, locate the driver path, and copy it out.&lt;/p&gt;
&lt;p&gt;Related paths:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C:\ProgramData\LGHUB&lt;/li&gt;
&lt;li&gt;C:\Windows\System32\DriverStore\FileRepository\logi_audio.inf_amd64_010b035044e24be4&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;device-manager&#34;&gt;Device Manager
&lt;/h2&gt;&lt;p&gt;The key is how to find the second path. Let&amp;rsquo;s briefly review how to manually manage driver files in Windows 11. This area covers two system-provided drivers and one from Logitech.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;The second driver in the image is from Logitech. We analyze the current device drivers, searching all driver paths within the virtual machine. First, you need to find files starting with &amp;ldquo;logi,&amp;rdquo; then compare them. You&amp;rsquo;ll be able to locate the driver file; copy the entire folder and youâ€™ll have the installation package.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;install-driver&#34;&gt;Install driver
&lt;/h2&gt;&lt;p&gt;While still in Device Manager, click &amp;ldquo;Update Driver,&amp;rdquo; then &amp;ldquo;Browse my computer for drivers.&amp;rdquo; This will take you to the following screen:&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;When you open it, you&amp;rsquo;ll only see one drive â€“ a standard USB drive. Choose &amp;ldquo;Install from disk&amp;rdquo; and select the folder we copied earlier. After installation, a Logitech-specific driver will appear in the dropdown list; switch the device driver to this newly installed one.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;anatomy-equipment-drivers&#34;&gt;Anatomy equipment drivers
&lt;/h2&gt;&lt;p&gt;The drivers for this device are provided by the system. You only need to check if there&amp;rsquo;s an exclamation mark next to the driver; if so, enter the driver selection interface and switch to a different type of driver before switching back to restore normal functionality.&lt;/p&gt;
&lt;h2 id=&#34;completed&#34;&gt;Completed
&lt;/h2&gt;&lt;p&gt;The headphone microphone volume is back to normal, and the familiar ear monitoring function has returned&lt;/p&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Logitech headset driver installation failed</title>
        <link>https://ttf248.life/en/p/logitech-headset-driver-installation-failed/</link>
        <pubDate>Fri, 31 May 2024 21:46:12 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/logitech-headset-driver-installation-failed/</guid>
        <description>&lt;p&gt;If you didn&amp;rsquo;t understand these things, you wouldn&amp;rsquo;t waste hours troubleshooting; you would contact customer service immediately&lt;/p&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/logitech-headset-driver-installation-failed/20240531220709.png&#34;
	width=&#34;693&#34;
	height=&#34;489&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;GHUB&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;141&#34;
		data-flex-basis=&#34;340px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Recently, the C drive on my home desktop computer ran out of space. I allocated a 256GB SSD for it, but have been having issues with it frequently. Since moving to Shanghai, I&amp;rsquo;ve been busy with various matters, and finally found time last week to reinstall the operating system.&lt;/p&gt;
&lt;p&gt;The system reinstall went smoothly, and installing everyday software and setting up the development environment presented no issues. A few days later, intending to relax with some games, I realized the drivers for my mouse and headset weren&amp;rsquo;t installed yet. Both devices are Logitech, so I downloaded GHUB, which automatically recognized the hardware and installed the drivers.&lt;/p&gt;
&lt;p&gt;However, an unexpected issue occurred. The mouse driver installed smoothly, but the headset driver continuously displayed &amp;ldquo;Loading.&amp;rdquo; I suspect incompatibility between the latest version of Windows 11 and Logitech&amp;rsquo;s drivers caused the installation failure. I then began searching for information and attempting to manually install the driver, but the problem persisted.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s the translation: Simply put, what is the function of each deviceâ€™s driver?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The mouse driver mainly adjusts functions like movement speed. I rarely use macros; restoring previously saved parameters is sufficient.&lt;/li&gt;
&lt;li&gt;The driver primarily functions for headphone monitoring, which is very useful during team voice communication as it allows me to hear my own voice. While the system&amp;rsquo;s microphone settings offer a similar feature, the driver implementation works better.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Despite repeated attempts, the headphones&amp;rsquo; drivers consistently failed to load. Today, I finally thought to contact customer service for assistance and see if there was a solution. Customer service informed me that their servers have recently been experiencing issues, causing abnormal driver downloads. They are working on resolving this issue and advised me to wait until the next update when the problem should be fixed.&lt;/p&gt;
&lt;p&gt;Although the headphone driver issue hasn&amp;rsquo;t been resolved yet, we at least know the cause, and hope it can be fixed soon&lt;/p&gt;
&lt;h2 id=&#34;mouse-driver-settings&#34;&gt;Mouse driver settings
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/logitech-headset-driver-installation-failed/20240531220930.png&#34;
	width=&#34;1024&#34;
	height=&#34;768&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;G502&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/logitech-headset-driver-installation-failed/20240531220903.png&#34;
	width=&#34;1024&#34;
	height=&#34;768&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;G502&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>Storing Custom Objects in Python Dictionaries: The Importance of References vs. Deep Copies</title>
        <link>https://ttf248.life/en/p/python-dictionary-custom-objects-reference-vs-deepcopy/</link>
        <pubDate>Fri, 22 Mar 2024 01:08:05 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/python-dictionary-custom-objects-reference-vs-deepcopy/</guid>
        <description>&lt;p&gt;In Python programming, dictionaries are a powerful data structure that allows us to associate key-value pairs and efficiently find and manipulate this data. When storing custom objects in a dictionary, we encounter a crucial concept: object assignment in Python is actually reference assignment, not a deep copy of the object itself. This means that when a custom object is placed into a dictionary, the dictionary stores a reference to that object, rather than a brand new copy.&lt;/p&gt;
&lt;h2 id=&#34;storing-custom-objects---basic-example&#34;&gt;Storing Custom Objects - Basic Example
&lt;/h2&gt;&lt;p&gt;Suppose we have a simple ____ class:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Person:
    def __init__(self, name, age):
        self.name = name
        self.age = age

# åˆ›å»ºä¸€ä¸ª Person å¯¹è±¡
p1 = Person(&amp;quot;Alice&amp;quot;, 30)

# å°†å¯¹è±¡å­˜å‚¨åˆ°å­—å…¸ä¸­
people_dict = {}
people_dict[&amp;quot;alice&amp;quot;] = p1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, the attributes of &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; å­—å…¸ç°åœ¨åŒ…å«ä¸€ä¸ªé”®ä¸º &lt;strong&gt;INLINE_CODE_1&lt;/strong&gt; çš„é¡¹ï¼Œå…¶å€¼æ˜¯å¯¹ &lt;strong&gt;INLINE_CODE_2&lt;/strong&gt; ç±»å‹çš„ &lt;code&gt;p1&lt;/code&gt; å¯¹è±¡çš„å¼•ç”¨ã€‚å¦‚æœæˆ‘ä»¬ä¿®æ”¹ &lt;code&gt;p1&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;p1.age = 31
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When accessing this object through the dictionary, we find that its age has also been updated&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(people_dict[&amp;quot;alice&amp;quot;].age)  # è¾“å‡ºï¼š31
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is because the dictionary stores references to the same memory address, not independent copies of the objects&lt;/p&gt;
&lt;h2 id=&#34;the-difference-between-deep-copy-and-shallow-copy&#34;&gt;The difference between deep copy and shallow copy
&lt;/h2&gt;&lt;p&gt;This referencing behavior can lead to unexpected results when dealing with nested data structures or custom objects. For example, modifying an object directly stored in a dictionaryâ€”especially if it contains mutable attributes like lists or other custom objectsâ€”will affect the object retrieved through the dictionary.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Address:
    def __init__(self, street, city):
        self.street = street
        self.city = city

class Person:
    def __init__(self, name, age, address):
        self.name = name
        self.age = age
        self.address = address

address = Address(&amp;quot;Main St.&amp;quot;, &amp;quot;Springfield&amp;quot;)
p1 = Person(&amp;quot;Bob&amp;quot;, 40, address)
people_dict[&amp;quot;bob&amp;quot;] = p1

# ä¿®æ”¹åŸå§‹åœ°å€å¯¹è±¡
address.city = &amp;quot;Shelbyville&amp;quot;

# å­—å…¸ä¸­çš„äººçš„åœ°å€ä¹Ÿå˜äº†
print(people_dict[&amp;quot;bob&amp;quot;].address.city)  # è¾“å‡ºï¼šShelbyville
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/p&gt;
&lt;p&gt;To avoid problems caused by this shared state, sometimes we need to ensure that the dictionary stores a complete copy of an object, rather than a reference. Python provides the &lt;code&gt;copy()&lt;/code&gt; function to achieve this goal:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import copy

# ä½¿ç”¨æ·±æ‹·è´å­˜å‚¨å¯¹è±¡
people_dict[&amp;quot;bob_deepcopy&amp;quot;] = copy.deepcopy(p1)

# æ­¤æ—¶å³ä½¿ä¿®æ”¹åŸå§‹åœ°å€å¯¹è±¡ï¼Œæ·±æ‹·è´çš„å¯¹è±¡ä¸ä¼šå—å½±å“
address.city = &amp;quot;Capital City&amp;quot;
print(people_dict[&amp;quot;bob&amp;quot;].address.city)  # è¾“å‡ºï¼šCapital City
print(people_dict[&amp;quot;bob_deepcopy&amp;quot;].address.city)  # è¾“å‡ºï¼šShelbyville
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When using dictionaries to store custom objects in Python, be mindful that object references are stored by default. For situations requiring independent state, use deep copying to avoid unexpected data changes due to shared references.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Why is the speed only 100 Mbps despite having newly installed gigabit fiber?</title>
        <link>https://ttf248.life/en/p/new-gigabit-fiber-slow-speed/</link>
        <pubDate>Mon, 18 Mar 2024 00:29:02 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/new-gigabit-fiber-slow-speed/</guid>
        <description>&lt;p&gt;Want lightning-fast home internet? It all comes down to choosing the right network cable, configuring your ONT and router, and paying attention to those subtle details. This blog will guide you through creating a gigabit network with Cat6 cables and how to ensure optimal speed through simple device checks and configurations. Let&amp;rsquo;s explore together and boost your home internet!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;chapter-1-in-depth-analysis-of-network-transmission-media&#34;&gt;Chapter 1: In-depth Analysis of Network Transmission Media
&lt;/h2&gt;&lt;p&gt;When discussing achieving gigabit network access, the carrierâ€”network cablesâ€”plays a crucial role in transmitting high-speed information. The following provides a detailed explanation of Cat 5, Cat 6, and Cat 7 cables.&lt;/p&gt;
&lt;h3 id=&#34;the-provided-text-is-empty-please-provide-the-chinese-text-you-want-me-to-translate&#34;&gt;The provided text is empty. Please provide the Chinese text you want me to translate.
&lt;/h3&gt;&lt;p&gt;Category 5 Ethernet cable, also known as CAT5, is an early type of twisted-pair cabling that uses a precise spiral structure to reduce crosstalk. It&amp;rsquo;s primarily suitable for 10/100Mbps Fast Ethernet with a maximum transmission frequency of approximately 100MHz. While widely used in the past, it cannot meet current demands for gigabit and higher speeds due to physical limitations.&lt;/p&gt;
&lt;h3 id=&#34;heading&#34;&gt;
&lt;/h3&gt;&lt;p&gt;With technological advancements, Cat6 cabling emerged. Compared to Cat5 cabling, Cat6 utilizes stricter manufacturing standards and more advanced structural designs, significantly improving interference resistance and transmission efficiency. It supports transfer rates up to 1Gbps and can achieve a distance of 100 meters under ideal conditions â€“ perfectly meeting the access requirements for Gigabit networks.&lt;/p&gt;
&lt;h3 id=&#34;3&#34;&gt;3
&lt;/h3&gt;&lt;p&gt;Category 7 cabling represents the pinnacle of current twisted-pair technology. It offers a significant increase in transmission rates, theoretically supporting up to 10Gbps, and incorporates a complete shielding systemâ€”shielding for each pair of wires as well as overall outer shieldingâ€”to greatly reduce external electromagnetic interference and near-end crosstalk, ensuring data transmission stability and accuracy. However, Category 7 cabling is primarily intended for future 10 Gigabit Ethernet or specific high-demand applications.&lt;/p&gt;
&lt;p&gt;When building a Gigabit home network, using Cat6 cabling is the most economical and efficient choice to fully leverage the potential of Gigabit fiber. Ensuring all connection cables are of qualified quality and strictly following standard wiring practices are also crucial for network performance.&lt;/p&gt;
&lt;h2 id=&#34;chapter-2-delving-into-network-core-devices--the-impact-of-optical-network-terminal-ont-and-router-lan-port-bandwidth&#34;&gt;Chapter 2: Delving into Network Core Devices â€“ The Impact of Optical Network Terminal (ONT) and Router LAN Port Bandwidth
&lt;/h2&gt;&lt;h3 id=&#34;the-importance-of-the-optical-network-terminal-ont-and-its-lan-port-bandwidth&#34;&gt;The importance of the optical network terminal (ONT) and its LAN port bandwidth
&lt;/h3&gt;&lt;p&gt;The Optical Network Terminal (ONT), also known as an optical modem, is the core device for home broadband access. Its function is to convert the light signal from fiber optic cables into digital signals for use by home network devices. For gigabit fiber users, it&amp;rsquo;s crucial that the ONT supports gigabit transmission. If the ONTâ€™s WAN port only supports 100 Mbps, even with a higher-speed fiber connection, the speed will be limited to 100 Mbps due to this bottleneck. Similarly, the ONTâ€™s LAN port also needs to have gigabit output capabilities; otherwise, routers or other connected devices won&amp;rsquo;t achieve true gigabit speeds.&lt;/p&gt;
&lt;h3 id=&#34;the-role-of-bandwidth-for-router-lan-ports&#34;&gt;The role of bandwidth for router LAN ports
&lt;/h3&gt;&lt;p&gt;The router&amp;rsquo;s LAN port distributes received data to terminal devices. When the LAN port is limited to Gigabit, even with well-configured devices, network communication will be restricted to a 100Mbps speed. Therefore, when building a Gigabit home network, ensure the routerâ€™s WAN port can receive Gigabit data and that its LAN port also offers Gigabit output capabilities so all smart devices can enjoy a smooth experience thanks to high-speed networking.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s important to note that some older or lower-end routers may have a LAN port auto-negotiation mechanism. This means they might operate in 100Mbps mode instead of Gigabit, even if the router itself supports it, due to factors like cabling or device compatibility. Therefore, correctly configuring router parameters, enabling forced Gigabit mode, and using a Gigabit switch or direct connection are crucial steps for achieving a full Gigabit network.&lt;/p&gt;
&lt;p&gt;After upgrading to fiber optic internet, be sure to check and replace your optical network terminal (ONT) and router with gigabit-compatible devices to ensure all interfaces meet the gigabit standard&lt;/p&gt;
&lt;h2 id=&#34;chapter-3-the-hidden-mystery--how-a-broken-sub-thread-impacts-gigabit-network-speed&#34;&gt;Chapter 3: The Hidden Mystery â€“ How a Broken Sub-Thread Impacts Gigabit Network Speed
&lt;/h2&gt;&lt;h3 id=&#34;subnet-cable-failure-and-network-performance-degradation&#34;&gt;Subnet cable failure and network performance degradation
&lt;/h3&gt;&lt;p&gt;The network remained connected throughout the speed test, with no apparent disconnections. As this is a newly installed broadband connection, the utility box is cluttered and adjustments to the optical network terminal&amp;rsquo;s cabling and power outlet placement occasionally result in speeds reaching gigabit levels.&lt;/p&gt;
&lt;p&gt;Based on previous data, we analyzed and eliminated potential issues such as network cable model and optical modem LAN port speed, ultimately discovering that a broken brown internal wire within the network cable was the culprit&lt;/p&gt;
&lt;p&gt;The cable broke because the installer pulled on it too hard when installing the crystal head, partially severing a wire. Subsequent movement while adjusting the optical network terminal&amp;rsquo;s location eventually caused it to break completely.&lt;/p&gt;
&lt;h3 id=&#34;functionality-of-eight-wires-in-six-categories-of-network-cables&#34;&gt;Functionality of Eight Wires in Six Categories of Network Cables
&lt;/h3&gt;&lt;p&gt;Six-category network cables follow the TIA/EIA-568-B standard, consisting of eight twisted pairs with the following color coding:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;White Orange / Orange&lt;/li&gt;
&lt;li&gt;White-green / Green&lt;/li&gt;
&lt;li&gt;Blue / Light Blue&lt;/li&gt;
&lt;li&gt;Brown&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Under Gigabit Ethernet (1000BASE-T) standards, these eight wires operate with four pairs working simultaneously, each with a specific function&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;These wires (1 &amp;amp; 2), labeled white-orange and orange, are used for data transmission (Tx+/â€“)&lt;/li&gt;
&lt;li&gt;These wires (3 &amp;amp; 6) â€“ white/green and green â€“ are used for data reception (Rx+/â€“)&lt;/li&gt;
&lt;li&gt;These pairs of wiresâ€”white-blue and blue (4&amp;amp;5) and white-brown and brown (7&amp;amp;8)â€”are not typically used in Gigabit Ethernet, but may be enabled in certain advanced applications like partial PoE power or future technology extensions. In traditional 100Mbps networks, only the four wires 1, 2, 3, and 6 are required.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;the-impact-of-broken-chains-on-network-speed&#34;&gt;The impact of broken chains on network speed
&lt;/h3&gt;&lt;p&gt;In the described scenario, if a brown sub-line (brown or brown-white) is broken, it can theoretically reduce speed in a Gigabit network because Gigabit networks require simultaneous bidirectional transmission on all four pairs of wires to achieve full speed. However, due to the auto-negotiation feature often found in home network devices, when a cable issue is detected, they will revert to a lower, functional rate â€“ typically 100Mbps. This explains why the connection remains active and operates at 100Mbps even with one sub-line broken.&lt;/p&gt;
&lt;p&gt;In short, while a single broken brown fiber strand doesn&amp;rsquo;t affect basic gigabit network operation, it can be a key factor limiting speed in a terabit environment. Only through thorough diagnosis and repair can the full potential of the terabit fiber be realized. This serves as a reminder that we shouldnâ€™t overlook any potential network infrastructure issues, even seemingly minor faults that don&amp;rsquo;t impact basic connectivity, as they may become hidden obstacles to high-speed network performance.&lt;/p&gt;</description>
        </item>
        <item>
        <title>UI Thread Issues and Solutions in WPF</title>
        <link>https://ttf248.life/en/p/wpf-ui-thread-and-freezing-issues-solutions/</link>
        <pubDate>Tue, 12 Mar 2024 07:12:21 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/wpf-ui-thread-and-freezing-issues-solutions/</guid>
        <description>&lt;p&gt;Correctly handling the user interface (UI) thread is crucial for ensuring application smoothness and responsiveness, especially when developing desktop applications and building rich client applications using the Windows Presentation Foundation (WPF) framework. The UI thread, also known as the main thread, is the core thread responsible for processing window and control events, layout calculations, and rendering the interface. All interactions with UI elements should be performed on the UI thread; this is a fundamental principle followed by WPF and most other GUI frameworks.&lt;/p&gt;
&lt;h2 id=&#34;what-is-the-ui-thread&#34;&gt;What is the UI thread?
&lt;/h2&gt;&lt;p&gt;The UI thread is created and initialized by the operating system when a WPF application starts, and it&amp;rsquo;s the only thread that can directly access and modify the state of UI components. All user interactionsâ€”such as button clicks, text box input, and window resizingâ€”are handled within this threadâ€™s context. Furthermore, WPFâ€™s dependency property system, data binding mechanism, and layout logic all execute synchronously on the UI thread.&lt;/p&gt;
&lt;h2 id=&#34;lag-and-its-causes&#34;&gt;Lag and its causes
&lt;/h2&gt;&lt;p&gt;When the UI thread is occupied or blocked for an extended periodâ€”for example, due to lengthy calculations, large data loads, database queries, or other I/O-intensive tasksâ€”it can fail to respond promptly to user interactions, resulting in a frozen interface (freeze), commonly known as &amp;ldquo;lag.&amp;rdquo; This causes noticeable application latency and sluggishness; severe cases may trigger an â€œApplication Not Respondingâ€ (ANR) warning&lt;/p&gt;
&lt;h2 id=&#34;two-basic-rules-of-the-ui-thread&#34;&gt;Two basic rules of the UI thread
&lt;/h2&gt;&lt;p&gt;To avoid these situations, WPF developers should follow two key rules:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Any operation that may cause the UI thread to hang should be moved to a background thread as much as possible to ensure the UI thread can promptly respond to user input and render screen changes&lt;/li&gt;
&lt;li&gt;Due to WPF&amp;rsquo;s security mechanism, only the UI thread is authorized to modify UI elements. Attempting to directly change the UI state from another thread will result in an exception. Therefore, even after background threads complete calculations or data preparation, results must be displayed on the UI through appropriate cross-thread communication mechanisms.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;solution-asynchronous-programming-and-thread-safe-updates&#34;&gt;Solution: Asynchronous Programming and Thread-Safe Updates
&lt;/h2&gt;&lt;p&gt;WPF offers various asynchronous programming models and tools to help developers achieve this while maintaining a smooth UI&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The WPF Dispatcher class allows you to schedule work items for execution in the UI thread&amp;rsquo;s task queue. You can use the &lt;code&gt;Invoke&lt;/code&gt; method to safely update the UI from background threads.&lt;/li&gt;
&lt;li&gt;By leveraging C#&amp;rsquo;s asynchronous features, you can write asynchronous methods and use the &lt;code&gt;__INLINE_CODE_0__&lt;/code&gt; keyword to wait for background tasks to complete, automatically returning to the UI thread to execute subsequent UI update code upon completion&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;case-study&#34;&gt;Case study
&lt;/h2&gt;&lt;h3 id=&#34;update-ui-using-the-__inline_code_0__-method&#34;&gt;Update UI using the &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; method
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;private void Button_Click(object sender, RoutedEventArgs e)
{
    // å‡è®¾è¿™æ˜¯ä¸€ä¸ªè€—æ—¶æ“ä½œ
    Task.Run(() =&amp;gt;
    {
        var result = LongRunningOperation(); // è¿™é‡Œæ˜¯æ¨¡æ‹Ÿä¸€ä¸ªè€—æ—¶è®¡ç®—çš„æ–¹æ³•
        
        // å½“è€—æ—¶æ“ä½œå®Œæˆåï¼Œåœ¨UIçº¿ç¨‹ä¸Šæ›´æ–°UI
        Application.Current.Dispatcher.Invoke(() =&amp;gt;
        {
            LabelStatus.Text = $&amp;quot;è®¡ç®—ç»“æœ: {result}&amp;quot;;
        });
    });
}

private string LongRunningOperation()
{
    // æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ
    Thread.Sleep(5000);
    return &amp;quot;å·²å®Œæˆ&amp;quot;;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;use-__inline_code_0__bold_2taskrun&#34;&gt;Use __INLINE_CODE_0__BOLD_2&lt;code&gt;Task.Run&lt;/code&gt;
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;private async void Button_ClickAsync(object sender, RoutedEventArgs e)
{
    Button button = sender as Button;
    button.IsEnabled = false; // é˜²æ­¢ç”¨æˆ·é‡å¤ç‚¹å‡»

    try
    {
        // å¼€å¯åå°ä»»åŠ¡
        var result = await Task.Run(() =&amp;gt; LongRunningOperation());

        // åœ¨åå°ä»»åŠ¡å®Œæˆåï¼Œè‡ªåŠ¨åˆ‡æ¢å›UIçº¿ç¨‹æ›´æ–°UI
        LabelStatus.Text = $&amp;quot;è®¡ç®—ç»“æœ: {result}&amp;quot;;
    }
    catch (Exception ex)
    {
        MessageBox.Show($&amp;quot;å‘ç”Ÿé”™è¯¯: {ex.Message}&amp;quot;);
    }
    finally
    {
        button.IsEnabled = true; // é‡æ–°å¯ç”¨æŒ‰é’®
    }
}
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Upgrading GCC version leads to program crashes: Hidden dangers of non-compliant code</title>
        <link>https://ttf248.life/en/p/upgrade-gcc-version-causes-program-crash-code-irregularities/</link>
        <pubDate>Sun, 10 Mar 2024 23:19:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/upgrade-gcc-version-causes-program-crash-code-irregularities/</guid>
        <description>&lt;p&gt;The program compiled and ran normally in the CentOS 7 environment, but crashed when switched to CentOS 8 and compiled with a newer version of GCC. Notably, this issue only occurred under &lt;strong&gt;Release æ¨¡å¼&lt;/strong&gt;, while &lt;strong&gt;Debug æ¨¡å¼&lt;/strong&gt; was unaffected. This was the first time we encountered such a situation, and after three days of troubleshooting, we finally found the root cause.&lt;/p&gt;
&lt;h3 id=&#34;issue-identification&#34;&gt;Issue identification
&lt;/h3&gt;&lt;p&gt;The root cause of the problem lies in &lt;strong&gt;å‡½æ•°ç¼ºå°‘è¿”å›å€¼&lt;/strong&gt;. The increased optimization performed by newer versions of GCC in Release mode has introduced unknown logic into functions without explicit return values, leading to crashes. Our conclusion is that &lt;strong&gt;ç¼–è¯‘å™¨çš„è­¦å‘Šä¸å®¹å¿½è§†ï¼Œå°¤å…¶æ˜¯åœ¨è€é¡¹ç›®ä¸­ï¼Œéƒ¨åˆ†è­¦å‘Šå¯èƒ½è¢«æ— è§†ï¼Œä½†ä¹Ÿåº”å½“é¿å…å±è”½æ‰€æœ‰è­¦å‘Š&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;environmental-description&#34;&gt;Environmental Description
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39)
Copyright Â© 2015 Free Software Foundation, Inc.
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-21)
Copyright (C) 2018 Free Software Foundation, Inc.
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;crash-phenomenon&#34;&gt;Crash phenomenon
&lt;/h3&gt;&lt;p&gt;When analyzing the program crash stack, we observed the following stack information:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[New LWP 1385902]
[Thread debugging using libthread_db enabled]
Using host libthread_db library &amp;quot;/lib64/libthread_db.so.1&amp;quot;.
Core was generated by `./pstack_main`.
Program terminated with signal SIGSEGV, Segmentation fault.
#0  0x00007ffe894b4420 in ?? ()
(gdb) bt
#0  0x00007ffe894b4420 in ?? ()
#1  0x00000000004008e9 in main ()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This stack trace isn&amp;rsquo;t intuitive; the crash information shows as a &lt;code&gt;__INLINE_CODE_0&lt;/code&gt;, making debugging more difficult&lt;/p&gt;
&lt;h3 id=&#34;code-example&#34;&gt;Code example
&lt;/h3&gt;&lt;p&gt;To better understand the issue, here&amp;rsquo;s a minimal code example to reproduce the crash:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;map&amp;gt;

int test() {
    std::cout &amp;lt;&amp;lt; &amp;quot;1&amp;quot; &amp;lt;&amp;lt; std::endl;
}

int main() {
    test();
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When a ``test()&lt;code&gt; å‡½æ•°æ˜¾ç„¶æ²¡æœ‰æ˜¾å¼è¿”å›ä¸€ä¸ªå€¼ï¼Œè€Œå®ƒçš„è¿”å›ç±»å‹æ˜¯ __INLINE_CODE_1__ã€‚æ ¹æ® C++ è§„èŒƒï¼Œå½“ä¸€ä¸ªå‡½æ•°å£°æ˜ä¸º __INLINE_CODE_2__&lt;/code&gt; type is used, it must have a return value; otherwise, undefined behavior may occur&lt;/p&gt;
&lt;h3 id=&#34;compilation-warning&#34;&gt;Compilation warning
&lt;/h3&gt;&lt;p&gt;In our project, CMake scripts suppress many compile-time warnings, including the following message:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;/root/pstack/main.cpp: In function â€˜int test()â€™:
/root/pstack/main.cpp:7:1: warning: no return statement in function returning non-void [-Wreturn-type]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This warning indicates that the &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; function has no return value, which is the root of the problem. High-version GCC (such as 8.5.0) may perform unstable optimizations on this undefined behavior during code optimization, leading to program crashes.&lt;/p&gt;
&lt;h3 id=&#34;assembly-code-differences&#34;&gt;Assembly code differences
&lt;/h3&gt;&lt;p&gt;To explain the differences in GCC compiler optimization behavior, we compared assembly code generated by different versions of GCC&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The assembly code is lengthy and includes excessive optimizations for issues like the missing return value in functions such as __INLINE_CODE_0__BOLD_2&lt;code&gt;test()&lt;/code&gt;, which may have prevented a crash&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The new version of GCC includes more optimizations that reduce code size. However, these optimizations can lead to undefined behavior when executing functions lacking return values, potentially causing program crashes.&lt;/p&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h3&gt;&lt;p&gt;This troubleshooting has highlighted the importance of carefully addressing warnings in C++, particularly when functions are declared inline. It&amp;rsquo;s crucial to selectively handle these warnings, especially those related to function return values and type matching, rather than suppressing them all.&lt;/p&gt;
&lt;p&gt;The issue was resolved by adding a return value to the &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; function, and the program returned to normal operation&lt;/p&gt;</description>
        </item>
        <item>
        <title>VMware virtual machine CPU resource usage anomaly</title>
        <link>https://ttf248.life/en/p/vmware-virtual-machine-cpu-resource-usage-anomaly/</link>
        <pubDate>Sun, 10 Mar 2024 22:14:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/vmware-virtual-machine-cpu-resource-usage-anomaly/</guid>
        <description>&lt;p&gt;The local machine runs a Windows-based business system with approximately 5% CPU usage. A Linux-based business system deployed in VMware&amp;rsquo;s CentOS8 experiences abnormal resource utilization.&lt;/p&gt;
&lt;h2 id=&#34;problem-description&#34;&gt;Problem description
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Host machine: Windows 10 Enterprise Edition&lt;/li&gt;
&lt;li&gt;vmwareï¼š17.5&lt;/li&gt;
&lt;li&gt;Virtual machine: CentOS 8&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Virtual machine resource allocation is &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;, enabling the business system. The business system is deployed in a virtual machine Linux environment. Observing system resource usage within the VM using the top command shows low CPU utilization. However, the outer Windows system&amp;rsquo;s Task Manager indicates high CPU usage; investigating processes reveals that the VMware process consumes significant CPU resources.&lt;/p&gt;
&lt;p&gt;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+
|         Windows           |
|                           |
|   +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+  |
|   |      VMware        |  |
|   |      Program       |  |
|   +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+  |
|                           |
+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&lt;/p&gt;
&lt;h2 id=&#34;key-points&#34;&gt;Key points
&lt;/h2&gt;&lt;p&gt;Troubleshooting this issue proved difficult, as the root cause wasn&amp;rsquo;t in the business system itself but rather a problem with the virtual machine. This article will first explain relevant concepts, then provide a solution, detailing how to shift focus from typical business code to system load, identify anomalies in load data, pinpoint soft interrupts, and ultimately determine what factors impact VMware soft interrupt efficiency.&lt;/p&gt;
&lt;h3 id=&#34;hyper-v&#34;&gt;hyper-v
&lt;/h3&gt;&lt;p&gt;Virtualization technology for Windows has undergone a significant change. When Microsoft first released WSL, enabling the Hyper-V service would prevent the simultaneous use of VMware virtual machines. Compatibility between VMware and Hyper-V services wasn&amp;rsquo;t achieved until later versions.&lt;/p&gt;
&lt;h3 id=&#34;system-load&#34;&gt;System load
&lt;/h3&gt;&lt;p&gt;In a Linux system, &amp;ldquo;load&amp;rdquo; refers to the number of processes running or waiting to execute. It&amp;rsquo;s typically represented by three numbers indicating the average number of processes in the run queue over 1, 5, and 15-minute intervals. These figures can be viewed using commands like &amp;ldquo;uptime&amp;rdquo; or &amp;ldquo;top.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Specifically, these three numbers represent:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The average number of processes in the system&amp;rsquo;s run queue over the past minute&lt;/li&gt;
&lt;li&gt;Average number of processes in the running queue over the past 5 minutes&lt;/li&gt;
&lt;li&gt;Average number of processes in the running queue over the past 15 minutes&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Load refers to the number of processes waiting to run in a system. If this number exceeds the logical CPU count, it indicates high system load, meaning many processes are competing for processor resources. This can lead to sluggishness or unresponsiveness, depending on the severity of the load and the system&amp;rsquo;s configuration and performance.&lt;/p&gt;
&lt;p&gt;Ideally, the load should remain within the logical CPU count of the system to optimize performance. If the load consistently exceeds the CPU count, further analysis of processes is needed to identify the cause and take appropriate measures to adjust resource allocation or optimize process execution.&lt;/p&gt;
&lt;h3 id=&#34;analyzing-load-with-mpstat&#34;&gt;Analyzing load with mpstat
&lt;/h3&gt;&lt;p&gt;Steps for conducting a load analysis:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;å®‰è£… sysstat&lt;/strong&gt;:
If it is not installed on your system, you can install it using a package management tool suitable for your system&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;è¿è¡Œ mpstat&lt;/strong&gt;:
Indicates resource consumption&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;01:32:33 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
01:32:35 PM  all    0.00    0.00    0.26    0.00    3.73    0.26    0.00    0.00    0.00   95.76
01:32:35 PM    0    0.00    0.00    0.51    0.00    3.57    0.00    0.00    0.00    0.00   95.92
01:32:35 PM    1    0.00    0.00    0.00    0.00    3.59    0.51    0.00    0.00    0.00   95.90
01:32:35 PM    2    0.00    0.00    0.00    0.00    4.15    0.00    0.00    0.00    0.00   95.85
01:32:35 PM    3    0.00    0.00    0.52    0.00    3.61    0.52    0.00    0.00    0.00   95.36
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;åˆ†æè¾“å‡º&lt;/strong&gt;:
The output includes the utilization rate of each CPU and the system&amp;rsquo;s average load. Monitoring the average load and individual CPU utilization can help you understand system load. High loads warrant further analysis to identify contributing processes and potential performance bottlenecks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ç»“åˆå…¶ä»–å·¥å…·&lt;/strong&gt;:
In addition to tools like these, we can comprehensively analyze system performance. Combining the outputs of various tools allows for a more thorough understanding of system load and helps identify the root causes of performance issues.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;interruption&#34;&gt;Interruption
&lt;/h3&gt;&lt;p&gt;I won&amp;rsquo;t elaborate on the details here
Recommended: [LINK_0]&lt;/p&gt;
&lt;p&gt;Frequent triggering of soft interrupts will be reflected in system load&lt;/p&gt;
&lt;h2 id=&#34;troubleshooting&#34;&gt;troubleshooting
&lt;/h2&gt;&lt;p&gt;Given that analyzing the issue solely from a CPU perspective is insufficient, should we suspect a system anomaly? It could be due to excessive load on the Linux operating system, causing VMware to consume an excessive amount of CPU resources. The utilization percentage should be approximately 5%.&lt;/p&gt;
&lt;p&gt;His CentOS 7 deployment on VMware in the team&amp;rsquo;s development environment shows normal resource usage. However, in the Shanghai development environment, although also using VMware, we cannot directly observe the host CPU resources. This presents multiple variables: the VMware virtual machine, the Linux operating system, and the GCC version.&lt;/p&gt;
&lt;p&gt;Shifting focus to the testing environment, Shenzhen&amp;rsquo;s testing environment is deployed on physical machines running a low-version GCC compilation service and operating on CentOS 8. Interestingly, in the Shenzhen environment, &lt;code&gt;irq&lt;/code&gt; usage is normal.&lt;/p&gt;
&lt;p&gt;To investigate issues introduced by newer GCC versions, we deployed programs compiled with a higher version of GCC to the Shenzhen environment for testing, and the results were all normal&lt;/p&gt;
&lt;p&gt;The issue appears to be becoming clearer; we&amp;rsquo;re starting to suspect a problem with the operating system. After all, CentOS 8 is no longer officially supported. However, even after redeploying clean installations of both CentOS 7 and CentOS 8, the problem persists.&lt;/p&gt;
&lt;p&gt;At this point, we began to suspect the sole uncertainty: VMware virtualization software. Then it occurred to us â€“ Hyper-V technology. Could Hyper-V have been previously enabled but not fully shut down, causing this issue? After all, soft interrupts are implemented through virtualization software. Are there bugs in different virtualization technologies? These questions warrant further consideration and investigation.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h2&gt;&lt;p&gt;According to Microsoft&amp;rsquo;s official documentation, we completely shut down the local Hyper-V service and found that VMware then functioned normally on the host. This resolved the issue. As mentioned earlier, this experience was complex and arduous, requiring comprehensive analysis and judgment. It also marked our first time troubleshooting a problem and identifying it at the virtual machine level.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Disable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V-Hypervisor
bcdedit /set hypervisorlaunchtype off
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/troubleshoot/windows-client/application-management/virtualization-apps-not-work-with-hyper-v&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://learn.microsoft.com/zh-cn/troubleshoot/windows-client/application-management/virtualization-apps-not-work-with-hyper-v&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Traps in C&#43;&#43; Programming: Detailed Explanation of Program Crashes Due to Misusing `std::map`</title>
        <link>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</link>
        <pubDate>Sun, 10 Mar 2024 22:03:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</guid>
        <description>&lt;p&gt;This article aims to reveal how improper use of C++ containers can lead to program crashes. Attempting to access a non-existent key using the bracket operator automatically adds an empty element. We will analyze this misunderstanding and demonstrate its potential risks with example code.&lt;/p&gt;
&lt;p&gt;Storing simple values is fine, but problems arise when storing pointers. Since a pointer is an address, if it&amp;rsquo;s not initialized, the address is undefined, which can lead to program crashes.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;In the C++ standard library, &lt;code&gt;_ITERATOR_categories&lt;/code&gt; inserts a new key-value pair, and the default constructor will be used to initialize the value type corresponding to that key&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;map&amp;gt;

int main() {
    std::map&amp;lt;std::string, int&amp;gt; myMap;
    
    // é”™è¯¯çš„ç”¨æ³•ï¼šå‡è®¾è¿™é‡Œè¯•å›¾è®¿é—®ä¸€ä¸ªä¸å­˜åœ¨çš„é”®å¹¶è®¤ä¸ºä¼šå¾—åˆ°0
    std::cout &amp;lt;&amp;lt; &amp;quot;Value for &#39;nonexistent_key&#39;: &amp;quot; &amp;lt;&amp;lt; myMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;

    // å®é™…ä¸Šï¼Œä¸Šè¿°è¡Œä»£ç åˆ›å»ºäº†ä¸€ä¸ªæ–°çš„é”®å€¼å¯¹ï¼Œå…¶ä¸­å€¼è¢«é»˜è®¤åˆå§‹åŒ–ä¸ºintçš„é»˜è®¤å€¼ï¼ˆé€šå¸¸æ˜¯0ï¼‰
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;While this code doesn&amp;rsquo;t directly cause the program to crash, such implicit insertion behavior can potentially lead to unexpected side effects in certain situations, like resource leaks or state changes that don&amp;rsquo;t meet expectations. Worse still, concurrent access to uninitialized memory regions in a multithreaded environment could even trigger a program crash.&lt;/p&gt;
&lt;p&gt;To prevent such issues, it is recommended to explicitly insert elements using ____&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;std::map&amp;lt;std::string, int&amp;gt; safeMap;
if (safeMap.count(&amp;quot;nonexistent_key&amp;quot;) == 0) {
    std::cout &amp;lt;&amp;lt; &amp;quot;Key does not exist.&amp;quot; &amp;lt;&amp;lt; std::endl;
} else {
    std::cout &amp;lt;&amp;lt; &amp;quot;Value for existing key: &amp;quot; &amp;lt;&amp;lt; safeMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;
}

// æˆ–è€…æ˜ç¡®æ’å…¥ä¸€ä¸ªé”®å€¼å¯¹ï¼ŒæŒ‡å®šåˆå§‹å€¼
safeMap.insert({ &amp;quot;new_key&amp;quot;, 0 });
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the objects stored in a &lt;code&gt;map&lt;/code&gt; container are of pointer type, the automatic insertion behavior will save an uninitialized pointer, and any operation on this pointer will lead to program crashes&lt;/p&gt;</description>
        </item>
        <item>
        <title>Troubleshooting process hangs using pstack</title>
        <link>https://ttf248.life/en/p/pstack-troubleshooting-process-hang/</link>
        <pubDate>Sat, 24 Feb 2024 23:55:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/pstack-troubleshooting-process-hang/</guid>
        <description>&lt;p&gt;In software development and operations, process freezes are frequently encountered, leading to system performance degradation or service unavailability. This article introduces the use of the &lt;code&gt;pstack&lt;/code&gt; tool to troubleshoot frozen processes by analyzing stack information to identify and resolve root causes.&lt;/p&gt;
&lt;p&gt;The risk control system&amp;rsquo;s sub-service experienced a freeze, rendering the risk control service unavailable. Due to a lack of service availability monitoring, the frozen process was not detected promptly, leading to system unavailability.&lt;/p&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;A hung process is a state where the process stops responding but does not exit. This can be caused by various factors, such as deadlocks, resource exhaustion, or exceptions. To resolve these issues, we can use the pstack tool to analyze the process&amp;rsquo;s stack information and identify the root cause.&lt;/p&gt;
&lt;h2 id=&#34;steps&#34;&gt;Steps
&lt;/h2&gt;&lt;p&gt;pstack is a commonly used tool, typically provided with gdb (the GNU debugger). You can install it using the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt-get install gdb
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To obtain the process ID: First, we need to get the process ID (PID) of the frozen process. You can use the &lt;code&gt;ps&lt;/code&gt; command to list all processes and find the PID you want to troubleshoot.
Use the pstack tool to analyze process stacks. Once you have obtained the process ID, you can use pstack to retrieve stack information for that process. Run the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pstack &amp;lt;PID&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will output the process&amp;rsquo;s stack information, displaying the current sequence of function calls. Analyzing this information can reveal where the process is stalled and help locate the issue.&lt;/p&gt;
&lt;p&gt;Analyzing stack information can help identify the cause of process freezes. This may reveal deadlocks, infinite loops, or other anomalies. Take appropriate measures based on the specific situation, such as releasing locks or fixing code logic.&lt;/p&gt;
&lt;h2 id=&#34;case-study&#34;&gt;Case study
&lt;/h2&gt;&lt;p&gt;A simple demo where, after the main function starts, a new sub-thread is created. The actual execution function enters an infinite loop, causing the program to fail to terminate normally and enter a frozen state.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cmake_minimum_required(VERSION 3.0.0)
project(pstack_main VERSION 0.1.0 LANGUAGES C CXX)

include(CTest)
enable_testing()

# æŸ¥æ‰¾çº¿ç¨‹åº“
find_package(Threads REQUIRED)

add_executable(pstack_main main.cpp)

# é“¾æ¥çº¿ç¨‹åº“
target_link_libraries(pstack_main PRIVATE Threads::Threads)

set(CPACK_PROJECT_NAME ${PROJECT_NAME})
set(CPACK_PROJECT_VERSION ${PROJECT_VERSION})
include(CPack)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;thread&amp;gt;
#include &amp;lt;chrono&amp;gt;

void infiniteLoop() {
    while (true) {
        // ä¸»çº¿ç¨‹è¿›å…¥æ­»å¾ªç¯
    }
}

int main() {
    std::thread thread(infiniteLoop); // åˆ›å»ºä¸€ä¸ªçº¿ç¨‹ï¼Œæ‰§è¡Œæ­»å¾ªç¯å‡½æ•°
    thread.join(); // ç­‰å¾…çº¿ç¨‹ç»“æŸ
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Starting program, pstack result:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Thread 2 (Thread 0x7eff3619b700 (LWP 1315017)):
#0  infiniteLoop () at /root/pstack/main.cpp:6
#1  0x0000000000402ca9 in std::__invoke_impl&amp;lt;void, void (*)()&amp;gt; (__f=@0x2260eb8: 0x4029a6 &amp;lt;infiniteLoop()&amp;gt;) at /usr/include/c++/8/bits/invoke.h:60
#2  0x0000000000402b02 in std::__invoke&amp;lt;void (*)()&amp;gt; (__fn=@0x2260eb8: 0x4029a6 &amp;lt;infiniteLoop()&amp;gt;) at /usr/include/c++/8/bits/invoke.h:95
#3  0x0000000000403150 in std::thread::_Invoker&amp;lt;std::tuple&amp;lt;void (*)()&amp;gt; &amp;gt;::_M_invoke&amp;lt;0ul&amp;gt; (this=0x2260eb8) at /usr/include/c++/8/thread:244
#4  0x0000000000403126 in std::thread::_Invoker&amp;lt;std::tuple&amp;lt;void (*)()&amp;gt; &amp;gt;::operator() (this=0x2260eb8) at /usr/include/c++/8/thread:253
#5  0x000000000040310a in std::thread::_State_impl&amp;lt;std::thread::_Invoker&amp;lt;std::tuple&amp;lt;void (*)()&amp;gt; &amp;gt; &amp;gt;::_M_run (this=0x2260eb0) at /usr/include/c++/8/thread:196
#6  0x00007eff36bceb23 in execute_native_thread_routine () from /lib64/libstdc++.so.6
#7  0x00007eff36ea91ca in start_thread () from /lib64/libpthread.so.0
#8  0x00007eff361d58d3 in clone () from /lib64/libc.so.6
Thread 1 (Thread 0x7eff372e1740 (LWP 1315016)):
#0  0x00007eff36eaa6cd in __pthread_timedjoin_ex () from /lib64/libpthread.so.0
#1  0x00007eff36bceda7 in std::thread::join() () from /lib64/libstdc++.so.6
#2  0x00000000004029d2 in main () at /root/pstack/main.cpp:13
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The process froze because of a deadlock loop. The main thread entered a deadlock loop, preventing the child threads from exiting, which resulted in the process freeze.&lt;/p&gt;</description>
        </item>
        <item>
        <title>C&#43;&#43; function call time cost</title>
        <link>https://ttf248.life/en/p/cpp-function-call-timing/</link>
        <pubDate>Wed, 24 Jan 2024 14:11:33 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-function-call-timing/</guid>
        <description>&lt;p&gt;We conducted a time-consuming test of the design quote SDK, implementing different callback function approaches. Recently I&amp;rsquo;ve been looking at C++ functional programming â€“ what performance differences arise when functions become first-class citizens and circulate within a program?&lt;/p&gt;
&lt;p&gt;Previous article link:&lt;/p&gt;
&lt;p&gt;The expert also did similar testing and borrowed the code&lt;/p&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;The execution platform remains our old friend, [link placeholder]&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;cassert&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;functional&amp;gt;
#include &amp;lt;iostream&amp;gt;
#include &amp;lt;vector&amp;gt;

int add_one(int input) { return input + 1; }

bool validate_vector_add_one(std::vector&amp;lt;int&amp;gt; const&amp;amp; input_vector,
                             std::vector&amp;lt;int&amp;gt; const&amp;amp; output_vector)
{
    bool is_valid{true};
    for (size_t i{0}; i &amp;lt; input_vector.size(); ++i)
    {
        if (output_vector.at(i) != input_vector.at(i) + 1)
        {
            is_valid = false;
            break;
        }
    }
    return is_valid;
}

void reset_vector(std::vector&amp;lt;int&amp;gt;&amp;amp; input_vector)
{
    for (size_t i{0}; i &amp;lt; input_vector.size(); ++i)
    {
        input_vector.at(i) = 0;
    }
}

template &amp;lt;typename T, typename Func&amp;gt;
void unitary_function_pass_by_lambda_function(T&amp;amp; output, T const&amp;amp; input,
                                              Func const func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_std_function_value(T&amp;amp; output, T const&amp;amp; input,
                                                 std::function&amp;lt;T(T)&amp;gt; const func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_std_function_reference(
    T&amp;amp; output, T const&amp;amp; input, std::function&amp;lt;T(T)&amp;gt; const&amp;amp; func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_function_pointer(T&amp;amp; output, T const&amp;amp; input,
                                               T (*func)(T))
{
    output = func(input);
}

int main()
{
    // Set floating point format std::cout with 3 decimal places.
    std::cout.precision(3);

    size_t const num_elements{10000000};
    std::vector&amp;lt;int&amp;gt; input_vector(num_elements, 0);
    std::vector&amp;lt;int&amp;gt; output_vector(num_elements, 0);

    auto const lambda_function_add_one{[](int const&amp;amp; input) -&amp;gt; int
                                       { return input + 1; }};
    std::function&amp;lt;int(int)&amp;gt; const std_function_add_one{lambda_function_add_one};

    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a function pointer: &amp;quot; &amp;lt;&amp;lt; sizeof(&amp;amp;add_one)
              &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a std::function pointer: &amp;quot;
              &amp;lt;&amp;lt; sizeof(&amp;amp;std_function_add_one) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a std::function: &amp;quot; &amp;lt;&amp;lt; sizeof(std_function_add_one)
              &amp;lt;&amp;lt; std::endl;

    // Call function frequently in a vanilla way.
    // The compiler knows what function to call at compile time and can optimize
    // the code.
    // This is the best performance we could get.
    std::chrono::steady_clock::time_point const time_start_vanilla{
        std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        output_vector.at(i) = add_one(input_vector.at(i));
    }
    std::chrono::steady_clock::time_point const time_end_vanilla{
        std::chrono::steady_clock::now()};
    auto const time_elapsed_vanilla{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(time_end_vanilla -
                                                             time_start_vanilla)
            .count()};
    float const latency_vanilla{time_elapsed_vanilla /
                                static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass Vanilla: &amp;quot; &amp;lt;&amp;lt; latency_vanilla &amp;lt;&amp;lt; &amp;quot; ns&amp;quot;
              &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // Sometimes, we don&#39;t know what function to call at compile time.
    // We can use std::function to pass a function as an argument.
    // In this case, we pass the std::function by value.
    // Because the size of a std::function is 32 bytes, passing by value
    // results in a lot of copying and bad performance.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_std_function_value{std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_std_function_value(
            output_vector.at(i), input_vector.at(i), std_function_add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_std_function_value{std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_std_function_value{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_std_function_value -
            time_start_pass_by_std_function_value)
            .count()};
    float const latency_pass_by_std_function_value{
        time_elapsed_pass_by_std_function_value /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Std Function Value: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_std_function_value &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // Instead of passing the std::function by value, we can pass it by
    // reference (pointer). In this case, object copying is eliminated. The
    // performance is better than passing the std::function by value. However,
    // the performance is still not as good as the vanilla way.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_std_function_reference{
            std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_std_function_reference(
            output_vector.at(i), input_vector.at(i), std_function_add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_std_function_reference{
            std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_std_function_reference{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_std_function_reference -
            time_start_pass_by_std_function_reference)
            .count()};
    float const latency_pass_by_std_function_reference{
        time_elapsed_pass_by_std_function_reference /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Std Function Reference: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_std_function_reference &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // std::function is a general purpose wrapper for function pointers,
    // callable objects, and lambda functions. Because it&#39;s general purpose,
    // it&#39;s not as efficient as a function pointer. In this case, we pass a
    // function pointer to a function. The performance is better than passing
    // the std::function by reference.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_function_pointer{std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_function_pointer(output_vector.at(i),
                                                  input_vector.at(i), &amp;amp;add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_function_pointer{std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_function_pointer{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_function_pointer -
            time_start_pass_by_function_pointer)
            .count()};
    float const latency_pass_by_function_pointer{
        time_elapsed_pass_by_function_pointer /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Function Pointer: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_function_pointer &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // We can also pass a lambda function to a function.
    // The compiler knows what function to call at compile time and can optimize
    // the code. The performance is also better than passing the std::function
    // by reference.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_lambda_function{std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_lambda_function(
            output_vector.at(i), input_vector.at(i), lambda_function_add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_lambda_function{std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_lambda_function{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_lambda_function -
            time_start_pass_by_lambda_function)
            .count()};
    float const latency_pass_by_lambda_function{
        time_elapsed_pass_by_lambda_function /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Lambda Function: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_lambda_function &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# ç»„é‡Œå¸¸è§„ä¹Ÿå°±å¼€å¯ O2 ä¼˜åŒ–ï¼Œç¼–è¯‘é€‰ç”¨äº† gcc13ï¼Œä¸åŒç‰ˆæœ¬çš„ gcc æ€§èƒ½è€—æ—¶ç•¥æœ‰ä¸åŒï¼Œç‰ˆæœ¬è¶Šé«˜ lambda æ•ˆæœè¶Šå¥½
The size of a function pointer: 8
The size of a std::function pointer: 8
The size of a std::function: 32
Latency Pass Vanilla: 0.418 ns
Latency Pass By Std Function Value: 3.47 ns
Latency Pass By Std Function Reference: 1.36 ns
Latency Pass By Function Pointer: 0.396 ns
Latency Pass By Lambda Function: 0.44 ns
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leimao.github.io/blog/CPP-Function-Call-Performance/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://leimao.github.io/blog/CPP-Function-Call-Performance/&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>How to bypass debugging</title>
        <link>https://ttf248.life/en/p/program-how-to-anti-debug/</link>
        <pubDate>Tue, 23 Jan 2024 19:46:36 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/program-how-to-anti-debug/</guid>
        <description>&lt;p&gt;On a whim, I&amp;rsquo;m looking for new wallpaper. I usually go with black backgrounds, with some colored accents. Since there will be icons on the desktop, other color schemes would make them unclear.&lt;/p&gt;
&lt;p&gt;After pondering the assembly code, I couldn&amp;rsquo;t understand it. I tried asking &lt;code&gt;AI&lt;/code&gt; for an explanation of the instructions, but they didn&amp;rsquo;t explain the context. It must be a specific scenario where these instructions are used; this isn&amp;rsquo;t typical code.&lt;/p&gt;
&lt;p&gt;A search engine is better now; my assembly knowledge is lacking&lt;/p&gt;
&lt;h2 id=&#34;wallpaper&#34;&gt;Wallpaper
&lt;/h2&gt;&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;h2 id=&#34;assembly-code&#34;&gt;Assembly code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;PUSHFD
MOV DWORD PTR [ESP],0X100
POPFD
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Practical application scenarios&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;bool IsDebugged()
{
    __try
    {
        __asm
        {
            pushfd
            mov dword ptr [esp], 0x100
            popfd
            nop
        }
        return true;
    }
    __except(GetExceptionCode() == EXCEPTION_SINGLE_STEP
        ? EXCEPTION_EXECUTE_HANDLER
        : EXCEPTION_CONTINUE_EXECUTION)
    {
        return false;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;explanation&#34;&gt;Explanation
&lt;/h2&gt;&lt;p&gt;Because if we track the code, this flag will be cleared by the debugger, so we won&amp;rsquo;t see this exception&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In practical testing, skipping the detection and debugging functions results in undetected debugging; it is only detected when entering the execution of the detection function. (Information gathered, not yet practically verified.)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;The related Chinese materials are translations of website drafts, which explain various anti-debugging techniques&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://anti-debug.checkpoint.com/techniques/assembly.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://anti-debug.checkpoint.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://song-10.gitee.io/2021/08/08/Reverse-2021-08-08-anti-debug/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://song-10.gitee.io/2021/08/08/Reverse-2021-08-08-anti-debug/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>How to download Focus Interviews/CCTV video files</title>
        <link>https://ttf248.life/en/p/how-to-download-focus-interview-cctv-video-files/</link>
        <pubDate>Tue, 23 Jan 2024 19:23:35 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/how-to-download-focus-interview-cctv-video-files/</guid>
        <description>&lt;p&gt;Recently, someone asked how to download videos from &amp;ldquo;Focus Interviews.&amp;rdquo; I immediately thought it would be some form of encryption, but it was easily resolved&lt;/p&gt;
&lt;h2 id=&#34;downloader&#34;&gt;Downloader
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/nilaoda/N_m3u8DL-CLI&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/nilaoda/N_m3u8DL-CLI&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;An open-source command-line m3u8/HLS/DASH downloader supporting standard AES-128-CBC decryption, multi-threading, and custom request headers. Supports Simplified Chinese, Traditional Chinese, and English.&lt;/p&gt;
&lt;h2 id=&#34;browser-extension&#34;&gt;Browser extension
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://microsoftedge.microsoft.com/addons/detail/ngjclnbcdbahekojpkhancmiobdahemb&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Live Stream Downloader&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;honey-glazed-confidence&#34;&gt;Honey-glazed confidence
&lt;/h2&gt;&lt;p&gt;Once I had the address, I thought it was resolved, but it turned out to be nothing. Unable to parse the segmented content properly, research revealed that the official download address has been handled and requires manual replacementâ€”copying the &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; identified by the plugin and pasting it into the link below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;https://newcntv.qcloudcdn.com/asp/hls/2000/0303000a/3/default/***********************/2000.m3u8
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As of January 2024, address testing is valid. Any subsequent changes require self-analysis of the webpage.&lt;/p&gt;
&lt;p&gt;Historical Address Backup:&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://jln.cn/post/517.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://jln.cn/post/517.html&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>Batch modification of SQL Server database disk file permissions</title>
        <link>https://ttf248.life/en/p/bulk-modify-sqlserver-database-disk-file-permissions/</link>
        <pubDate>Tue, 23 Jan 2024 19:06:36 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/bulk-modify-sqlserver-database-disk-file-permissions/</guid>
        <description>&lt;p&gt;Company security policy adjustments have been made. Due to irregular activation methods, it seems fine without activating for personal use.&lt;/p&gt;
&lt;p&gt;Activation through unconventional means triggered Microsoft&amp;rsquo;s detection. The server ran for half a month before automatically shutting down after one hour of startup. Examining the system logs revealed it was due to piracy.&lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s no way around it; another system reinstall is needed, &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; faces a reinstall too. Each time is quite troublesome due to strict file permission controls, preventing normal database appending.&lt;/p&gt;
&lt;h2 id=&#34;error-message&#34;&gt;Error message
&lt;/h2&gt;&lt;p&gt;After system reinstallation, 5120 errors and operating system access denials may occur in the supplemental database&lt;/p&gt;
&lt;h2 id=&#34;process-script&#34;&gt;Process script
&lt;/h2&gt;&lt;p&gt;The previous link: &lt;a class=&#34;link&#34; href=&#34;https://ttf248.life/en/p/bulk-update-local-git-repository-and-legacy-permission-issues/&#34; &gt;æ‰¹é‡æ›´æ–°æœ¬åœ°Gitä»“åº“&lt;/a&gt;. It&amp;rsquo;s this familiar script again, modified to traverse folders while also changing file permissions â€“ currently granting full editing access.&lt;/p&gt;
&lt;p&gt;Most online tutorials require manual modification â€“ do they only need to change a few files each time? I have to handle batches of files, all manually. It&amp;rsquo;s enough to make you feel depressed.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$currentUserName = [System.Security.Principal.WindowsIdentity]::GetCurrent().Name
[Console]::OutputEncoding = [System.Text.Encoding]::UTF8
$rootDirectory = &amp;quot;D:\data\2013_RujiaInfo&amp;quot;

Get-ChildItem -Path $rootDirectory -Recurse | ForEach-Object {
    $itemPath = $_.FullName

    if ($_ -is [System.IO.DirectoryInfo]) {
        $icaclsResult = icacls $itemPath /setowner &amp;quot;$currentUserName&amp;quot; 2&amp;gt;&amp;amp;1
        if ($LASTEXITCODE -eq 0) {
            Write-Host &amp;quot;å·²æ›´æ”¹æ–‡ä»¶å¤¹ $itemPath çš„æ‰€æœ‰è€…ä¸º $currentUserName&amp;quot;
            # æˆäºˆå½“å‰ç”¨æˆ·å†™å…¥æƒé™
            Invoke-Expression &amp;quot;icacls `&amp;quot;$itemPath`&amp;quot; /grant `&amp;quot;$($currentUserName):(OI)(CI)F`&amp;quot;&amp;quot;
            Write-Host &amp;quot;å·²æˆäºˆ $currentUserName ç¼–è¾‘æ–‡ä»¶å¤¹çš„æƒé™&amp;quot;
        } else {
            Write-Host &amp;quot;æ— æ³•æ›´æ”¹æ–‡ä»¶å¤¹ $itemPath çš„æ‰€æœ‰è€…ã€‚é”™è¯¯ä¿¡æ¯: $icaclsResult&amp;quot;
        }
    } else {
        $takeownResult = icacls $itemPath /setowner &amp;quot;$currentUserName&amp;quot; 2&amp;gt;&amp;amp;1
        if ($LASTEXITCODE -eq 0) {
            # æˆäºˆå½“å‰ç”¨æˆ·å†™å…¥æƒé™
            Invoke-Expression &amp;quot;icacls `&amp;quot;$itemPath`&amp;quot; /grant `&amp;quot;$($currentUserName):(F)`&amp;quot;&amp;quot;
            Write-Host &amp;quot;å·²æˆäºˆ $currentUserName ç¼–è¾‘æ–‡ä»¶çš„æƒé™&amp;quot;
        } else {
            Write-Host &amp;quot;æ— æ³•æ›´æ”¹æ–‡ä»¶ $itemPath çš„æ‰€æœ‰è€…ã€‚é”™è¯¯ä¿¡æ¯: $takeownResult&amp;quot;
        }
    }
}

&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Linux system benchmark testing</title>
        <link>https://ttf248.life/en/p/linux-system-benchmark-test/</link>
        <pubDate>Tue, 09 Jan 2024 10:56:23 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-system-benchmark-test/</guid>
        <description>&lt;p&gt;The Windows platform has &amp;ldquo;Ruluzishi&amp;rdquo; (Entertainment Master), which isn&amp;rsquo;t entirely accurate but provides a reference. There are also other professional benchmarking tools, but suitable ones are lacking on the Linux system.&lt;/p&gt;
&lt;p&gt;Sysbench is a versatile benchmarking tool that can be used to test CPU, memory, file I/O, and thread performance. You can use Sysbench to perform various performance testing tasks.&lt;/p&gt;
&lt;p&gt;I currently have three machines available for testing: Mecha-Debug Mini local host, Alibaba Cloud Dev development cloud server, and Huawei Cloud development server&lt;/p&gt;
&lt;h2 id=&#34;installing-sysbench&#34;&gt;Installing Sysbench
&lt;/h2&gt;&lt;p&gt;In most Linux distributions, you can use a package management tool to install Sysbench. For example, on CentOS 8, you can use the following command for installation.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo dnf install sysbench
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;sysbench-usage-examples&#34;&gt;Sysbench Usage Examples
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Testing CPU performance:&lt;/li&gt;
&lt;li&gt;Testing memory read performance: &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Testing file I/O performance:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sysbench --test=fileio --file-test-mode=rndrw prepare
sysbench --test=fileio --file-test-mode=rndrw run
sysbench --test=fileio --file-test-mode=rndrw cleanup
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Testing multi-threaded performance: &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Testing MySQL database performance (requires adjusting the maximum number of connections)&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword --oltp-table-size=1000000 prepare
sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword --max-time=60 --oltp-read-only=off --oltp-test-mode=complex --max-requests=0 run
sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword cleanup
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;performance-data-report&#34;&gt;Performance Data Report
&lt;/h2&gt;&lt;meta http-equiv=&#34;Content-Type&#34; content=&#34;text/html; charset=utf-8&#34;&gt;&lt;link type=&#34;text/css&#34; rel=&#34;stylesheet&#34; href=&#34;resources/sheet.css&#34; &gt;
&lt;style type=&#34;text/css&#34;&gt;.ritz .waffle a { color: inherit; }.ritz .waffle .s0{background-color:#ffffff;text-align:left;color:#000000;font-family:&#39;Arial&#39;;font-size:10pt;vertical-align:bottom;white-space:nowrap;direction:ltr;padding:2px 3px 2px 3px;}&lt;/style&gt;&lt;div class=&#34;ritz grid-container&#34; dir=&#34;ltr&#34;&gt;&lt;table class=&#34;waffle&#34; cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th class=&#34;row-header freezebar-origin-ltr&#34;&gt;&lt;/th&gt;&lt;th id=&#34;0C0&#34; style=&#34;width:100px;&#34; class=&#34;column-headers-background&#34;&gt;A&lt;/th&gt;&lt;th id=&#34;0C1&#34; style=&#34;width:421px;&#34; class=&#34;column-headers-background&#34;&gt;B&lt;/th&gt;&lt;th id=&#34;0C2&#34; style=&#34;width:398px;&#34; class=&#34;column-headers-background&#34;&gt;C&lt;/th&gt;&lt;th id=&#34;0C3&#34; style=&#34;width:422px;&#34; class=&#34;column-headers-background&#34;&gt;D&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R0&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;1&lt;/div&gt;&lt;/th&gt;&lt;td&gt;&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;æœ¬åœ°æœºæ¢°å¸ˆ&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;é˜¿é‡Œäº‘&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;åä¸ºäº‘&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R1&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;2&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;ç³»ç»Ÿé…ç½®&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Information&lt;br&gt;  Operating System              Ubuntu 23.04&lt;br&gt;  Kernel                        Linux 6.2.0-36-generic x86_64&lt;br&gt;  Model                         Machenike Machenike DT Computer&lt;br&gt;  Motherboard                   Machenike Machenike DT Computer&lt;br&gt;  BIOS                          American Megatrends International, LLC.&lt;br&gt;DB19V012&lt;br&gt;&lt;br&gt;CPU Information&lt;br&gt;  Name                          Intel Core i7-12650H&lt;br&gt;  Topology                      1 Processor, 10 Cores, 16 Threads&lt;br&gt;  Identifier                    GenuineIntel Family 6 Model 154 Stepping 3&lt;br&gt;  Base Frequency                4.60 GHz&lt;br&gt;  L1 Instruction Cache          32.0 KB x 8&lt;br&gt;  L1 Data Cache                 48.0 KB x 8&lt;br&gt;  L2 Cache                      1.25 MB x 2&lt;br&gt;  L3 Cache                      24.0 MB&lt;br&gt;&lt;br&gt;Memory Information&lt;br&gt;  Size                          62.6 GB&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Information&lt;br&gt;  Operating System              CentOS Stream 8&lt;br&gt;  Kernel                        Linux 4.18.0-513.el8.x86_64 x86_64&lt;br&gt;  Model                         Alibaba Cloud Alibaba Cloud ECS&lt;br&gt;  Motherboard                   N/A&lt;br&gt;  BIOS                          SeaBIOS 449e491&lt;br&gt;&lt;br&gt;CPU Information&lt;br&gt;  Name                          Intel(R) Xeon(R) Platinum&lt;br&gt;  Topology                      1 Processor, 1 Core, 2 Threads&lt;br&gt;  Identifier                    GenuineIntel Family 6 Model 85 Stepping 4&lt;br&gt;  Base Frequency                2.50 GHz&lt;br&gt;  L1 Instruction Cache          32.0 KB&lt;br&gt;  L1 Data Cache                 32.0 KB&lt;br&gt;  L2 Cache                      1.00 MB&lt;br&gt;  L3 Cache                      33.0 MB&lt;br&gt;&lt;br&gt;Memory Information&lt;br&gt;  Size                          1.65 GB&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Information&lt;br&gt;  Operating System              Ubuntu 22.04.1 LTS&lt;br&gt;  Kernel                        Linux 5.15.0-60-generic x86_64&lt;br&gt;  Model                         OpenStack Foundation OpenStack Nova&lt;br&gt;  Motherboard                   N/A&lt;br&gt;  BIOS                          SeaBIOS&lt;br&gt;rel-1.10.2-0-g5f4c7b1-20181220_000000-szxrtosci10000&lt;br&gt;&lt;br&gt;CPU Information&lt;br&gt;  Name                          Intel(R) Xeon(R) Gold 6278C CPU @ 2.60GHz&lt;br&gt;  Topology                      1 Processor, 1 Core, 2 Threads&lt;br&gt;  Identifier                    GenuineIntel Family 6 Model 85 Stepping 7&lt;br&gt;  Base Frequency                2.60 GHz&lt;br&gt;  L1 Instruction Cache          32.0 KB&lt;br&gt;  L1 Data Cache                 32.0 KB&lt;br&gt;  L2 Cache                      1.00 MB&lt;br&gt;  L3 Cache                      35.8 MB&lt;br&gt;&lt;br&gt;Memory Information&lt;br&gt;  Size                          3.64 GB&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R2&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;3&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;CPU&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  4032.48&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0004s&lt;br&gt;    total number of events:              40330&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.25&lt;br&gt;         avg:                                    0.25&lt;br&gt;         max:                                    0.73&lt;br&gt;         95th percentile:                        0.25&lt;br&gt;         sum:                                 9997.55&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           40330.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9975/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  1062.51&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0008s&lt;br&gt;    total number of events:              10628&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.91&lt;br&gt;         avg:                                    0.94&lt;br&gt;         max:                                   22.84&lt;br&gt;         95th percentile:                        1.06&lt;br&gt;         sum:                                 9993.46&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           10628.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9935/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  1125.56&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0005s&lt;br&gt;    total number of events:              11258&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.86&lt;br&gt;         avg:                                    0.89&lt;br&gt;         max:                                    1.70&lt;br&gt;         95th percentile:                        0.99&lt;br&gt;         sum:                                 9995.40&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           11258.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9954/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R3&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;4&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;å†…å­˜&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 101993199 (10198146.52 per second)&lt;br&gt;&lt;br&gt;99602.73 MiB transferred (9959.13 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              101993199&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                    0.03&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4059.50&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           101993199.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.0595/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 48418803 (4841004.79 per second)&lt;br&gt;&lt;br&gt;47283.99 MiB transferred (4727.54 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              48418803&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                   25.26&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4578.95&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           48418803.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.5789/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 57056904 (5704765.11 per second)&lt;br&gt;&lt;br&gt;55719.63 MiB transferred (5571.06 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              57056904&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                    0.06&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4556.06&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           57056904.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.5561/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R4&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;5&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;ç¡¬ç›˜&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 1.81 seconds (1129.59 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      3373.41&lt;br&gt;    writes/s:                     2248.94&lt;br&gt;    fsyncs/s:                     7201.80&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  52.71&lt;br&gt;    written, MiB/s:               35.14&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0127s&lt;br&gt;    total number of events:              128288&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.08&lt;br&gt;         max:                                    5.14&lt;br&gt;         95th percentile:                        0.34&lt;br&gt;         sum:                                 9977.78&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           128288.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9778/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 19.29 seconds (106.16 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      1593.12&lt;br&gt;    writes/s:                     1062.08&lt;br&gt;    fsyncs/s:                     3406.64&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  24.89&lt;br&gt;    written, MiB/s:               16.60&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0164s&lt;br&gt;    total number of events:              60600&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.16&lt;br&gt;         max:                                   31.32&lt;br&gt;         95th percentile:                        0.54&lt;br&gt;         sum:                                 9956.30&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           60600.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9563/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 18.29 seconds (111.98 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      1665.88&lt;br&gt;    writes/s:                     1110.59&lt;br&gt;    fsyncs/s:                     3563.77&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  26.03&lt;br&gt;    written, MiB/s:               17.35&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0112s&lt;br&gt;    total number of events:              63355&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.16&lt;br&gt;         max:                                  205.01&lt;br&gt;         95th percentile:                        0.78&lt;br&gt;         sum:                                 9972.64&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           63355.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9726/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R5&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;6&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;å¤šçº¿ç¨‹&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0002s&lt;br&gt;    total number of events:              197956&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.16&lt;br&gt;         avg:                                    0.20&lt;br&gt;         max:                                    0.34&lt;br&gt;         95th percentile:                        0.21&lt;br&gt;         sum:                                39970.47&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           49489.0000/5.70&lt;br&gt;    execution time (avg/stddev):   9.9926/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0174s&lt;br&gt;    total number of events:              18360&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.57&lt;br&gt;         avg:                                    2.18&lt;br&gt;         max:                                   32.77&lt;br&gt;         95th percentile:                        2.61&lt;br&gt;         sum:                                40050.41&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           4590.0000/94.36&lt;br&gt;    execution time (avg/stddev):   10.0126/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0004s&lt;br&gt;    total number of events:              28536&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.23&lt;br&gt;         avg:                                    1.40&lt;br&gt;         max:                                    3.56&lt;br&gt;         95th percentile:                        1.47&lt;br&gt;         sum:                                39975.16&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           7134.0000/39.87&lt;br&gt;    execution time (avg/stddev):   9.9938/0.01&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;
&lt;h2 id=&#34;afterword&#34;&gt;Afterword
&lt;/h2&gt;&lt;p&gt;Without proper formatting, the display will be very poor. The custom theme limits the maximum page width, and I&amp;rsquo;ve adjusted the page configuration to use percentage-based width restrictions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Simple methods include using online tools like TablesGenerator to create HTML tables (unsuitable for complex content)&lt;/li&gt;
&lt;li&gt;Or use Google Docs, write there, then download as an HTML document and directly copy it into your blog (simple and direct, this is our final approach)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ensure the config is enabled with the unsafe option, and configure the width separately for each page&lt;/p&gt;
&lt;p&gt;In Hugo, you can set the width for individual pages. This can be achieved by adding a custom parameter in the page&amp;rsquo;s Front Matter. Hereâ€™s an example:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Add a custom parameter, such as &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;, in the Front Matter section of your Markdown page (typically at the beginning of the file)&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;---
title: &amp;quot;æˆ‘çš„é¡µé¢&amp;quot;
date: 2024-01-09
custom_width: &amp;quot;800px&amp;quot;  # è®¾ç½®å®½åº¦ä¸º 800 åƒç´ 
---

æ­£æ–‡å†…å®¹...
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;
&lt;p&gt;In your Hugo theme, locate or create the corresponding single-page template file (e.g., &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check if the page&amp;rsquo;s Front Matter contains &lt;code&gt;custom_width&lt;/code&gt; å‚æ•°ï¼Œå¹¶å°†å…¶åº”ç”¨åˆ°ç›¸åº”çš„ HTML å…ƒç´ ä¸Šï¼Œä¾‹å¦‚ &lt;code&gt;div&lt;/code&gt; in single-page templates:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;{{ define &amp;quot;main&amp;quot; }}
  &amp;lt;div style=&amp;quot;max-width: {{ with .Params.custom_width }}{{ . }}{{ else }}100%{{ end }}; margin: 0 auto;&amp;quot;&amp;gt;
    {{ .Content }}
  &amp;lt;/div&amp;gt;
{{ end }}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, we used inline styles to center the elements&lt;/p&gt;
&lt;p&gt;Please note that in practical applications, you may need to adjust the above examples according to your theme structure and CSS styles. Ensure consistency and readability when adjusting styles.&lt;/p&gt;
&lt;p&gt;The site&amp;rsquo;s custom &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; configuration was adjusted due to slight differences in the enabled theme&lt;/p&gt;</description>
        </item>
        <item>
        <title>git-disable-http-repositories</title>
        <link>https://ttf248.life/en/p/git-disable-http-repositories/</link>
        <pubDate>Mon, 08 Jan 2024 21:22:04 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/git-disable-http-repositories/</guid>
        <description>&lt;p&gt;Accustomed to updating software versions, unsure which version&amp;rsquo;s repository to pull code from&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;fatal: Unencrypted HTTP is not supported for GitLab. Ensure the repository remote URL is using HTTPS
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;background-introduction&#34;&gt;Background introduction
&lt;/h2&gt;&lt;p&gt;Environment: Windows platform, consistently using TortoiseGit for Git operations, including configuring SSH keys. Previously attempted a script to batch update local repositories.&lt;/p&gt;
&lt;p&gt;Previous article link:&lt;/p&gt;
&lt;p&gt;When updating the code today, I encountered the previous error and the repository failed to update properly. I thought of updating the repository using &lt;strong&gt;INLINE_CODE_0__åº”è¯¥æä¾›äº†é…ç½®ï¼Œè®©æˆ‘ç»§ç»­ä½¿ç”¨__INLINE_CODE_1&lt;/strong&gt;, but couldn&amp;rsquo;t find the corresponding configuration item after searching around.&lt;/p&gt;
&lt;p&gt;The simplest solution is, of course, to switch to the &lt;code&gt;ssh&lt;/code&gt;åè®®æ¥æ›´æ–°ä»“åº“ï¼Œå…¬å¸é…ç½®çš„&lt;code&gt;gitlab&lt;/code&gt;çŸ­æœŸå†…ä¸ä¼šæä¾›&lt;code&gt;https&lt;/code&gt;protocol&lt;/p&gt;
&lt;h2 id=&#34;outstanding-issues&#34;&gt;Outstanding issues
&lt;/h2&gt;&lt;p&gt;When writing the batch update script for the local repository, I initially intended to use the &lt;strong&gt;INLINE_CODE_0__çš„æ–¹å¼æ‹‰å–ä»“åº“ï¼Œä¹Ÿæ²¡ç»†æŸ¥æ˜¯å› ä¸ºä»€ä¹ˆï¼Œé€šè¿‡å°ä¹Œé¾Ÿé…ç½®çš„__INLINE_CODE_1&lt;/strong&gt; configuration information, but it wasn&amp;rsquo;t synchronized to the config, resulting in issues when executing via command line&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git pull #æç¤ºæ²¡æœ‰æƒé™ï¼Œæ— æ³•æ­£å¸¸æ›´æ–°ä»“åº“
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Checking the key configuration via command is also correct&lt;/p&gt;
&lt;p&gt;If you can successfully pull code using TortoiseGit but receive a &amp;ldquo;key incorrect&amp;rdquo; error when using the &lt;code&gt;git pull&lt;/code&gt; command in the command line, this is likely because TortoiseGit uses PuTTY&amp;rsquo;s SSH key while the command line uses OpenSSH&amp;rsquo;s SSH key&lt;/p&gt;
&lt;p&gt;The small turtle&amp;rsquo;s key configuration doesn&amp;rsquo;t read key file information from the system .ssh folder; instead, it configures the key file path separately when configuring the interface repository. A useful tip: configuring a key for the first repository being pulled allows other repositories to reuse this key file. After PuTTY loads the key, it doesnâ€™t immediately exit but starts an agent service.&lt;/p&gt;
&lt;p&gt;By adjusting the global configuration and not using the system default &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; setting, Git Bash will use TortoisePlink for SSH operations. This configuration is suitable when using the PuTTY tool that comes with TortoiseGit.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git config --global core.sshCommand &amp;quot;&#39;C:/Program Files/TortoiseGit/bin/TortoisePlink.exe&#39; -batch -ssh&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Modify the file path of the executable as needed to match your Little Turtle installation directory. Due to the full path configuration, no need to add it to system environment variables.&lt;/p&gt;</description>
        </item>
        <item>
        <title>AI programming and task decomposition</title>
        <link>https://ttf248.life/en/p/ai-programming-and-task-decomposition/</link>
        <pubDate>Fri, 22 Dec 2023 08:44:26 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/ai-programming-and-task-decomposition/</guid>
        <description>&lt;p&gt;Two years ago, I added a copy function for the site&amp;rsquo;s code area. It took nearly half a day, and the final rendering effect was not ideal. As an amateur front-end developer, I didnâ€™t bother to improve it; as long as it worked, that was fine. This year, using &lt;strong&gt;INLIN_ITALIC_1&lt;/strong&gt;__, I developed a mini program and became more familiar with front-end development. So, I rebuilt it (AI redesign).&lt;/p&gt;
&lt;p&gt;Understanding the Dao: Break down tasks into many smaller ones&lt;/p&gt;
&lt;h2 id=&#34;previous-text&#34;&gt;Previous text
&lt;/h2&gt;&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/p&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;Design CSS and JavaScript code to locate webpage elements with the class &amp;ldquo;highlight&amp;rdquo;. Within the container of these elements, add a copy button that implements the functionality to copy the code.&lt;/p&gt;
&lt;p&gt;The initial draft of the code had issues. A revised draft was generated, which is now basically functional, but contains incorrect copied content and redundant text. Further optimization is needed, including manual specification of core color design and effects.&lt;/p&gt;
&lt;p&gt;We understand you have specific requirements for button size and color. We can redesign the button style to accommodate these needs. Here&amp;rsquo;s an adjusted CSS style, incorporating your provided color scheme and optimizing the button dimensions:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.copy-btn {
  position: absolute;
  top: 2px; /* è°ƒæ•´ä½ç½® */
  right: 2px;
  padding: 3px 6px; /* ç¼©å°å°ºå¯¸ */
  font-size: 12px; /* å‡å°å­—ä½“å¤§å° */
  background-color: #8FD1E1; /* æŒ‰é’®èƒŒæ™¯è‰² */
  color: #272822; /* æ–‡å­—é¢œè‰² */
  border: 1px solid #272822; /* è¾¹æ¡†é¢œè‰² */
  border-radius: 3px; /* åœ†è§’ */
  cursor: pointer;
  opacity: 0.7; /* é»˜è®¤åŠé€æ˜ */
  transition: opacity 0.3s ease, background-color 0.3s ease; /* å¹³æ»‘è¿‡æ¸¡æ•ˆæœ */
}

.copy-btn:hover {
  opacity: 1; /* é¼ æ ‡æ‚¬åœæ—¶ä¸é€æ˜ */
  background-color: #A3D4E5; /* é¼ æ ‡æ‚¬åœæ—¶çš„èƒŒæ™¯è‰² */
}

.highlight {
  position: relative;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this style, Iâ€™ve reduced the button size and font to make it more refined. The default state is semi-transparent; hovering over the button makes it opaque with a slightly brighter background for visual feedback. This design meets your color requirements while maintaining a modern, user-friendly feel.&lt;/p&gt;
&lt;p&gt;A simpler version was provided accordingly&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-JavaScript&#34;&gt;document.addEventListener(&#39;DOMContentLoaded&#39;, function() {
  // æŸ¥æ‰¾æ‰€æœ‰ .highlight å…ƒç´ 
  const highlights = document.querySelectorAll(&#39;.highlight&#39;);

  highlights.forEach(function(highlight) {
    // åˆ›å»ºå¤åˆ¶æŒ‰é’®
    const copyBtn = document.createElement(&#39;button&#39;);
    copyBtn.textContent = &#39;å¤åˆ¶&#39;;
    copyBtn.classList.add(&#39;copy-btn&#39;);

    // å°†æŒ‰é’®æ·»åŠ åˆ°æ¯ä¸ª .highlight å…ƒç´ ä¸­
    highlight.appendChild(copyBtn);

    // æ·»åŠ ç‚¹å‡»äº‹ä»¶ç›‘å¬å™¨
    copyBtn.addEventListener(&#39;click&#39;, function() {
      // å‡è®¾ .highlight ä¸‹çš„ç¬¬ä¸€ä¸ª &amp;lt;code&amp;gt; å…ƒç´ åŒ…å«è¦å¤åˆ¶çš„ä»£ç 
      const code = highlight.querySelector(&#39;code&#39;) ? highlight.querySelector(&#39;code&#39;).textContent : &#39;&#39;;

      navigator.clipboard.writeText(code).then(() =&amp;gt; {
        // æ˜¾ç¤ºå¤åˆ¶æˆåŠŸä¿¡æ¯
        copyBtn.textContent = &#39;å·²å¤åˆ¶!&#39;;
        setTimeout(() =&amp;gt; {
          copyBtn.textContent = &#39;å¤åˆ¶&#39;;
        }, 2000);
      }).catch(err =&amp;gt; {
        console.error(&#39;å¤åˆ¶å¤±è´¥: &#39;, err);
      });
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;afterword&#34;&gt;Afterword
&lt;/h2&gt;&lt;p&gt;Although I&amp;rsquo;d prefer a copy button added to the top right of the code area, due to my limited frontend knowledge, I havenâ€™t been able to accurately describe the functionality with keywords, and several attempts have not yielded the desired result&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s uncertain what impact &lt;code&gt;AI&lt;/code&gt; will have on program development as time progresses&lt;/p&gt;</description>
        </item>
        <item>
        <title>Cloud server and script kiddie</title>
        <link>https://ttf248.life/en/p/cloud-servers-and-script-kids/</link>
        <pubDate>Mon, 20 Nov 2023 15:08:53 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cloud-servers-and-script-kids/</guid>
        <description>&lt;p&gt;Taking advantage of the Double Eleven promotion, Alibaba Cloud recently acquired a server: an economical version for 99 yuan per year. The configuration isn&amp;rsquo;t high-end, but itâ€™s suitable as a jump server proxying services for home use. The promotion lasts until 2026.&lt;/p&gt;
&lt;p&gt;I specifically chose a Shanghai server and proxied my home machine. It&amp;rsquo;s Windows 11 and Windows Server 2022 (the server version was deployed later). When I tried to use it, I suddenly received an &amp;ldquo;access denied&amp;rdquo; message. I initially thought it was a server update that would resolve itself shortly. After five minutes, the login was still rejected. Searching for related errors indicated someone was attempting to log in and, due to too many incorrect password attempts, access is now disabled.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve encountered security attack scripts before, and immediately thought these logins are likely not legitimate â€“ someone is attacking the service, attempting to brute-force the login server. The firewall configuration was convenient but lacked whitelisting; it proxied the 3389 ports of two machines, exposing them on the public networkâ€”like bait in a fishpond. Now that I know it&amp;rsquo;s a script kiddie attack, the next steps are simple: set up a firewall whitelist allowing access to the proxy service only from company and home IP addresses.&lt;/p&gt;
&lt;p&gt;The proxy server previously lacked logging. Enabling it revealed a lot â€“ proxy IPs from all over the country were attempting to log into my home server. Luckily, one was a server version, which alerted me to the issue. Otherwise, that Windows 11 machine would have been compromised eventually; the password was set too simply.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;2023/11/17 16:51:14 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [101.43.98.211:50486]
2023/11/17 16:51:14 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [218.93.202.63:56970]
2023/11/17 16:51:14 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [222.179.106.174:60812]
2023/11/17 16:51:15 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [58.16.204.238:2839]
2023/11/17 16:51:15 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [124.223.47.24:50274]
2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [43.248.128.22:55883]
2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [43.143.53.138:56955]
2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [43.228.7.250:61550]
2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [125.76.228.9:55842]
2023/11/17 16:51:17 [I] [proxy.go:204] [4dfcc2259937dcb9] [winserver-remote] get a user connection [91.240.118.187:49326]
2023/11/17 16:51:17 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [91.240.118.187:49324]
2023/11/17 16:51:17 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [89.248.163.79:51712]
2023/11/17 16:51:18 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [218.63.75.24:62387]
2023/11/17 16:51:19 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [103.186.109.227:51396]
2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [116.233.234.104:51567]
2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [222.187.193.202:51585]
2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [59.48.98.42:57489]
2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [146.56.241.134:53558]
2023/11/17 16:51:21 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [222.179.106.174:30620]
2023/11/17 16:51:23 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [183.14.214.51:62128]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I checked the login logs for Linux services; besides my Aliyun machine, a friend has a Huawei Cloud machine as well&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo grep &amp;quot;Failed password&amp;quot; /var/log/secure  centosç³»åˆ—
sudo grep &amp;quot;Failed password&amp;quot; /var/log/auth.log  ubuntuç³»åˆ—
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Nov 16 04:46:34 aliyun-sh sshd[156625]: Failed password for root from 120.55.164.64 port 53410 ssh2
Nov 16 04:46:34 aliyun-sh sshd[156623]: Failed password for root from 111.16.215.122 port 36548 ssh2
Nov 16 04:46:58 aliyun-sh sshd[156630]: Failed password for invalid user share from 139.9.233.78 port 53872 ssh2
Nov 16 04:47:23 aliyun-sh sshd[156634]: Failed password for invalid user spark from 139.9.233.78 port 36134 ssh2
Nov 16 04:47:26 aliyun-sh sshd[156636]: Failed password for root from 120.55.164.64 port 46142 ssh2
Nov 16 04:47:47 aliyun-sh sshd[156640]: Failed password for root from 111.16.215.122 port 42962 ssh2
Nov 16 04:48:24 aliyun-sh sshd[156652]: Failed password for root from 120.55.164.64 port 38868 ssh2
Nov 16 04:48:25 aliyun-sh sshd[156654]: Failed password for root from 111.16.215.122 port 46164 ssh2
Nov 16 04:48:39 aliyun-sh sshd[156657]: Failed password for invalid user test from 139.9.233.78 port 39386 ssh2
Nov 16 04:48:50 aliyun-sh sshd[156659]: Failed password for root from 111.16.215.122 port 38892 ssh2
Nov 16 04:48:53 aliyun-sh sshd[156662]: Failed password for root from 120.55.164.64 port 49348 ssh2
Nov 16 04:48:53 aliyun-sh sshd[156664]: Failed password for invalid user test from 139.9.233.78 port 49864 ssh2
Nov 16 04:50:02 aliyun-sh sshd[156672]: Failed password for root from 111.16.215.122 port 45294 ssh2
Nov 16 04:50:30 aliyun-sh sshd[156680]: Failed password for invalid user zabbix from 139.9.233.78 port 52206 ssh2
Nov 16 04:50:50 aliyun-sh sshd[156683]: Failed password for root from 120.55.164.64 port 34820 ssh2
Nov 16 04:50:51 aliyun-sh sshd[156685]: Failed password for root from 111.16.215.122 port 58978 ssh2
Nov 16 04:51:18 aliyun-sh sshd[156689]: Failed password for root from 120.55.164.64 port 45306 ssh2
Nov 16 04:51:25 aliyun-sh sshd[156692]: Failed password for root from 111.16.215.122 port 33938 ssh2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This Huawei Cloud machine has been running for a long time, is now in the mid-stage of dictionary brute-forcing, and various suspicious users are appearing&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Nov 16 20:30:35 hecs-411458 sshd[182965]: Failed password for invalid user oeh from 39.129.9.180 port 26459 ssh2
Nov 16 20:32:17 hecs-411458 sshd[182967]: Failed password for invalid user dnu from 39.129.9.180 port 27079 ssh2
Nov 16 20:34:12 hecs-411458 sshd[182971]: Failed password for invalid user rq from 39.129.9.180 port 27742 ssh2
Nov 16 20:36:07 hecs-411458 sshd[182979]: Failed password for invalid user zw from 39.129.9.180 port 28415 ssh2
Nov 16 20:37:59 hecs-411458 sshd[182981]: Failed password for invalid user egi from 39.129.9.180 port 29068 ssh2
Nov 16 20:39:52 hecs-411458 sshd[182984]: Failed password for invalid user bjb from 39.129.9.180 port 29723 ssh2
Nov 16 20:41:53 hecs-411458 sshd[182988]: Failed password for invalid user hna from 39.129.9.180 port 30375 ssh2
Nov 16 20:43:46 hecs-411458 sshd[182994]: Failed password for invalid user gar from 39.129.9.180 port 31036 ssh2
Nov 16 20:45:40 hecs-411458 sshd[183003]: Failed password for invalid user mze from 39.129.9.180 port 31703 ssh2
Nov 16 20:47:35 hecs-411458 sshd[183007]: Failed password for invalid user tmh from 39.129.9.180 port 32381 ssh2
Nov 16 21:23:01 hecs-411458 sshd[183047]: Failed password for invalid user amax from 112.4.65.118 port 41188 ssh2
Nov 16 22:31:20 hecs-411458 sshd[183116]: Failed password for root from 211.228.203.123 port 60213 ssh2
Nov 16 22:53:44 hecs-411458 sshd[183162]: Failed password for root from 112.132.249.164 port 39272 ssh2
Nov 17 11:44:26 hecs-411458 sshd[184811]: Failed password for invalid user jsh from 43.157.103.27 port 54608 ssh2
Nov 17 11:47:23 hecs-411458 sshd[184818]: Failed password for invalid user mrunal from 43.157.103.27 port 50448 ssh2
Nov 17 11:48:46 hecs-411458 sshd[184820]: Failed password for invalid user robertsheen from 43.157.103.27 port 50560 ssh2
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;afterword&#34;&gt;Afterword
&lt;/h2&gt;&lt;p&gt;Developing your own server: Windows requires whitelisting for public network access; Linux recommends disabling password login and enabling key file authentication&lt;/p&gt;</description>
        </item>
        <item>
        <title>Batch update of local Git repository and legacy permission issues</title>
        <link>https://ttf248.life/en/p/bulk-update-local-git-repository-and-legacy-permission-issues/</link>
        <pubDate>Thu, 19 Oct 2023 14:16:22 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/bulk-update-local-git-repository-and-legacy-permission-issues/</guid>
        <description>&lt;p&gt;Projects within the team have dependencies; due to historical reasons and a lack of dependency management using &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;, developers must manually update repository code sequentially, or they may encounter various issues&lt;/p&gt;
&lt;p&gt;Referencing online resources, the structure is generally similar. Maintain a local repository directory: &lt;strong&gt;git_list.txt&lt;/strong&gt;. Write a script to traverse the directory and perform an update in one go; run the script before starting work each time.&lt;/p&gt;
&lt;h2 id=&#34;linux&#34;&gt;linux
&lt;/h2&gt;&lt;p&gt;create new file: batch_pull.sh&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#!/bin/bash

echo &amp;quot;============ æ›´æ–°ä»“åº“ ===================&amp;quot;

# æ£€æŸ¥ git_list.txt æ˜¯å¦å­˜åœ¨
if [ ! -f &amp;quot;git_list.txt&amp;quot; ]; then
  echo &amp;quot;git_list.txt æ–‡ä»¶ä¸å­˜åœ¨ï¼è¯·åˆ›å»ºå¹¶æ·»åŠ è¦æ‹‰å–çš„ git ä»“åº“ URLã€‚&amp;quot;
  exit 1
else
  echo &amp;quot;============ æ£€æµ‹åˆ°äº† git ä»“åº“æ¸…å•æ–‡ä»¶ ====&amp;quot;
fi

# é€è¡Œè¯»å– git_list.txt ä¸­çš„ URLï¼Œå¹¶æ‰§è¡Œæ‹‰å–æ“ä½œ
while read -r url; do
  if [ -d &amp;quot;$url&amp;quot; ]; then
    cd &amp;quot;$url&amp;quot; || continue
    git pull
    cd ..
    echo &amp;quot;Pull $url å®Œæˆï¼&amp;quot;
    echo &amp;quot;========================================&amp;quot;
  else
    echo &amp;quot;ç›®å½• $url ä¸å­˜åœ¨ï¼Œè·³è¿‡æ‹‰å–ã€‚&amp;quot;
  fi
done &amp;lt; &amp;quot;git_list.txt&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;windows&#34;&gt;windows
&lt;/h2&gt;&lt;p&gt;create a new file: batch_pull.bat&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bat&#34;&gt;@echo off
chcp 65001 &amp;gt; nul
rem è¿›å…¥è„šæœ¬æ‰€åœ¨ç›®å½•
cd /d &amp;quot;%~dp0&amp;quot;

rem æ£€æŸ¥ git_list.txt æ˜¯å¦å­˜åœ¨
if not exist &amp;quot;git_list.txt&amp;quot; (
  echo git_list.txt æ–‡ä»¶ä¸å­˜åœ¨ï¼è¯·åˆ›å»ºå¹¶æ·»åŠ è¦æ‹‰å–çš„ git ä»“åº“ URLã€‚
  exit /b 1
) else (
  echo ============ æ£€æµ‹åˆ°äº† git ä»“åº“æ¸…å•æ–‡ä»¶ ====
)

rem é€è¡Œè¯»å– git_list.txt ä¸­çš„ URLï¼Œå¹¶æ‰§è¡Œæ‹‰å–æ“ä½œ
for /f %%i in (git_list.txt) do (
  if exist &amp;quot;%%i&amp;quot; (
    pushd &amp;quot;%%i&amp;quot;
    git pull
    popd
    echo Pull %%i å®Œæˆï¼
    echo ========================================
  ) else (
    echo ç›®å½• %%i ä¸å­˜åœ¨ï¼Œè·³è¿‡æ‹‰å–ã€‚
  )
)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;historical-legacies&#34;&gt;Historical legacies
&lt;/h3&gt;&lt;p&gt;Dealing with a &lt;strong&gt;Fatal error&lt;/strong&gt; &amp;ldquo;&lt;strong&gt;Unsafe repository (&amp;rsquo;/home/repon&amp;rsquo; is owned by someone else)&lt;/strong&gt;&amp;rdquo; after reinstalling the system&lt;/p&gt;
&lt;p&gt;Most online advice originates from &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Adding trusted directory&lt;/li&gt;
&lt;li&gt;Manually modify the configuration file &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; to add a trusted directory&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[safe]
    directory = /home/repon
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After addressing the issue, warehouse updates are now normal. However, each execution of __INLINE_CODE_0 console displays numerous warning messages indicating an owner error.&lt;/p&gt;
&lt;h3 id=&#34;reinstalling-windows-on-a-desktop-computer&#34;&gt;Reinstalling Windows on a desktop computer
&lt;/h3&gt;&lt;p&gt;The development machine hadn&amp;rsquo;t been reinstalled in a long time, resulting in a system disk overrun with junk files. I had to reinstall the system. Now Iâ€™m encountering this permission issue again; old scripts won&amp;rsquo;t run and the permissions are incomplete.&lt;/p&gt;
&lt;p&gt;Using the new scheme, directly adding &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;ï¼Œè¿™æ ·__INLINE_CODE_1__ will automatically trust all directories&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git config --global --add safe.directory &amp;quot;*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;Not sure if it&amp;rsquo;s a user permissions issue or that people aren&amp;rsquo;t accustomed to the command, but I changed the folder owner. If you donâ€™t have many directories, manually changing owners is also an option. However, this work computer has domain information added, so Iâ€™m not sure whether thereâ€™s an anomaly in the companyâ€™s deployed domain or a local system configuration issue. The user used for login couldn&amp;rsquo;t be found in the user list; ultimately, I resolved it using the command line.&lt;/p&gt;
&lt;p&gt;Administrator privileges, run __INLINE_CODE_0__è„šæœ¬__INLINE_CODE_1__BOLD_4&lt;code&gt;gbk&lt;/code&gt;, a Chinese operating system to avoid garbled characters&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;# è·å–å½“å‰ç”¨æˆ·çš„ç”¨æˆ·å
$currentUserName = [System.Security.Principal.WindowsIdentity]::GetCurrent().Name

# è®¾ç½® PowerShell çš„å­—ç¬¦ç¼–ç ä¸º UTF-8
[Console]::OutputEncoding = [System.Text.Encoding]::UTF8

# è¦æ›´æ”¹æ‰€æœ‰è€…çš„æ ¹ç›®å½•è·¯å¾„
$rootDirectory = &amp;quot;G:\workspace&amp;quot;  # æ›¿æ¢ä¸ºå®é™…çš„ç›®å½•è·¯å¾„

# é€’å½’éå†ç›®å½•å¹¶æ›´æ”¹æ–‡ä»¶å’Œæ–‡ä»¶å¤¹çš„æ‰€æœ‰è€…
Get-ChildItem -Path $rootDirectory -Recurse | ForEach-Object {
    $itemPath = $_.FullName

    # æ£€æŸ¥æ˜¯æ–‡ä»¶è¿˜æ˜¯æ–‡ä»¶å¤¹
    if ($_ -is [System.IO.DirectoryInfo]) {
        # å¦‚æœæ˜¯æ–‡ä»¶å¤¹ï¼Œä½¿ç”¨ icacls æ›´æ”¹æ‰€æœ‰è€…æƒé™
        $icaclsResult = icacls $itemPath /setowner &amp;quot;$currentUserName&amp;quot; 2&amp;gt;&amp;amp;1
        if ($LASTEXITCODE -eq 0) {
            Write-Host &amp;quot;å·²æ›´æ”¹æ–‡ä»¶å¤¹ $itemPath çš„æ‰€æœ‰è€…ä¸º $currentUserName&amp;quot;
        } else {
            Write-Host &amp;quot;æ— æ³•æ›´æ”¹æ–‡ä»¶å¤¹ $itemPath çš„æ‰€æœ‰è€…ã€‚é”™è¯¯ä¿¡æ¯: $icaclsResult&amp;quot;
        }
    } else {
        # å¦‚æœæ˜¯æ–‡ä»¶ï¼Œä½¿ç”¨ icacls æ›´æ”¹æ‰€æœ‰è€…æƒé™
        $takeownResult = icacls $itemPath /setowner &amp;quot;$currentUserName&amp;quot; 2&amp;gt;&amp;amp;1
        if ($LASTEXITCODE -eq 0) {
            # Write-Host &amp;quot;å·²æ›´æ”¹æ–‡ä»¶ $itemPath çš„æ‰€æœ‰è€…ä¸º $currentUserName&amp;quot;
        } else {
            Write-Host &amp;quot;æ— æ³•æ›´æ”¹æ–‡ä»¶ $itemPath çš„æ‰€æœ‰è€…ã€‚é”™è¯¯ä¿¡æ¯: $takeownResult&amp;quot;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As expected, something unexpected happened. The Chinese output from the script was garbled. I tried setting the console character encoding and adjusting the script&amp;rsquo;s encoding, but it remained gibberish. My thinking must have been off. I then tried enabling the beta feature in Control Panel - Region - Language settings and globally enabled Unicode encoding. The script ran normally, but several development software programs stopped working properly. Later, reviewing my notes, I realized I needed to adjust the script file&amp;rsquo;s encoding to &lt;em&gt;&lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id=&#34;materials&#34;&gt;Materials
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://ganzhixiong.com/p/f1b9f4fc/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ganzhixiong.com/p/f1b9f4fc/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://stackoverflow.com/questions/71901632/fatal-error-unsafe-repository-home-repon-is-owned-by-someone-else&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stackoverflow.com/questions/71901632/fatal-error-unsafe-repository-home-repon-is-owned-by-someone-else&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>wpf-learning-resources</title>
        <link>https://ttf248.life/en/p/wpf-learning-resources/</link>
        <pubDate>Tue, 17 Oct 2023 10:49:24 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/wpf-learning-resources/</guid>
        <description>&lt;p&gt;The bugs in the mini-program development weren&amp;rsquo;t fixed before a new one appeared. Recent company instability and inefficient communication during cross-location collaboration led to me taking on front-end development work.&lt;/p&gt;
&lt;h2 id=&#34;wpf&#34;&gt;WPF
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Recommended&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Having grasped the fundamental framework, the path ahead will be less prone to deviation&lt;/p&gt;
&lt;p&gt;Previously there was a [article/essay] suitable for experienced readers planning their learning path&lt;/p&gt;
&lt;p&gt;Recommended reading for readers with no prior knowledge: &lt;a class=&#34;link&#34; href=&#34;http://www.wpfsoft.com/introduction&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;WPF ä¸­æ–‡ç½‘&lt;/a&gt;. It introduces fundamental concepts, historical development, and the cognitive logic of underlying classes from scratch. Interestingly, this website was just launched by the author in August this year, coinciding perfectly with our timeline. If it were any later, we likely wouldn&amp;rsquo;t have had a chance to connect.&lt;/p&gt;
&lt;p&gt;For the most authentic learning materials, of course it&amp;rsquo;s Microsoftâ€™s official documentation. It can be dry, so new readers need to be patient.&lt;/p&gt;
&lt;p&gt;There are also many classic e-books, but I don&amp;rsquo;t really recommend them. With so much to handle in my daily work, I donâ€™t have a lot of time for reading, and it&amp;rsquo;s hard to get into the right mindset. Practicing with projects is more suitable.&lt;/p&gt;
&lt;h2 id=&#34;c-and-net-release-history&#34;&gt;C# and .NET release history
&lt;/h2&gt;&lt;p&gt;Recently, there have been quite a few new features released, and the language&amp;rsquo;s version undergoes annual iteration&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/C_Sharp_%28programming_language%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://en.wikipedia.org/wiki/C_Sharp_(programming_language)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Official learning materials:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/dotnet/csharp/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://learn.microsoft.com/zh-cn/dotnet/csharp/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/dotnet/core/tutorials/with-visual-studio?pivots=dotnet-7-0&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://learn.microsoft.com/zh-cn/dotnet/core/tutorials/with-visual-studio?pivots=dotnet-7-0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>ZeroTier for Remote Local Area Networks</title>
        <link>https://ttf248.life/en/p/zero-tier-remote-lan/</link>
        <pubDate>Tue, 19 Sep 2023 04:58:03 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/zero-tier-remote-lan/</guid>
        <description>&lt;p&gt;Acquired a new __INLINE_CODE_0__ä¸»æœºï¼Œæƒ³ç€é…ç½®é…ç½®ç¯å¢ƒæ–¹ä¾¿ï¼Œåœ¨å®¶å¶å°”ä¹Ÿæœ‰è®¿é—®çš„éœ€æ±‚ï¼Œä¸´æ—¶éƒ¨ç½²å†…ç½‘ç©¿é€ã€‚æŒ‰ç…§ä»¥å¾€çš„ç»éªŒï¼Œéƒ¨ç½²__INLINE_CODE_1__æœåŠ¡ï¼ŒæŒ‡å®šç«¯å£è½¬å‘ï¼Œéœ€è¦ä¸€å°å…¬ç½‘çš„æœåŠ¡å™¨ï¼Œè¿æ¥çš„è´¨é‡å–å†³äºå…¬ç½‘æœåŠ¡å™¨çš„å®½å¸¦è´¨é‡ã€‚æŠ˜è…¾ä¸€ç‚¹æ–°é²œçš„__INLINE_CODE_2__è™šæ‹Ÿæœºå±€åŸŸç½‘ï¼Œç±»ä¼¼äº&lt;code&gt;VPN&lt;/code&gt; in the office, created a virtual network card locally, and added all machines to a virtual network&lt;/p&gt;
&lt;h2 id=&#34;what-is-zerotier&#34;&gt;What is ZeroTier?
&lt;/h2&gt;&lt;p&gt;You can easily connect multiple computers, servers, and devices to a virtual, encrypted network as if they were on the same local area network. This allows programmers and IT professionals to securely share data and resources between different locations without complex network setups or VPN configurations.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;ZeroTier Network is a virtual, global local area network that allows different devices to connect together over the internet as if they were on the same physical network. This network can include multiple subnets, with all devices connected through ZeroTier&amp;rsquo;s technology.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Planet servers are key components of the ZeroTier network. They are global in scope, responsible for maintaining and managing the entire ZeroTier network&amp;rsquo;s topology, routing information, and network status. Planet servers act as a global network control center but do not directly transmit data. User devices need to connect to at least one planet server to participate in the ZeroTier network.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Relay servers are auxiliary nodes in the Zerotier network, helping devices establish direct communication channels. When devices cannot connect directly, they can transmit data through a relay server, improving network reachability and performance. Relay servers are typically located worldwide, acting as data transfer hubs.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Overall, Zerotier creates virtual local area networks globally, enabling secure and fast communication between devices through planetary and relay servers. Planetary servers manage the global network, while relay servers help establish connections when needed.&lt;/p&gt;
&lt;h2 id=&#34;installation-deployment&#34;&gt;Installation Deployment
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Visit the ZeroTier official website (link) for installation files and documentation&lt;/li&gt;
&lt;li&gt;Download and install the ZeroTier One client for your operating system. It supports Windows, macOS, Linux, and many other platforms.&lt;/li&gt;
&lt;li&gt;Launch the ZeroTier One client after installation&lt;/li&gt;
&lt;li&gt;Create a ZeroTier account if you don&amp;rsquo;t already have one. You can create an account within the client.&lt;/li&gt;
&lt;li&gt;Log in to your ZeroTier account and create a new network. The network will have a unique 16-character ID that you need to remember.&lt;/li&gt;
&lt;li&gt;Join this network on your device. You can enter the network ID in the client or use the QR code scanning function.&lt;/li&gt;
&lt;li&gt;Devices installed with and configured with the ZeroTier client will be added to the same virtual network. These devices can now communicate directly, as if they were on the same local area network.&lt;/li&gt;
&lt;li&gt;You can manage network settings, add devices, and monitor network traffic through ZeroTier&amp;rsquo;s control panel&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;install-deployment-moon&#34;&gt;Install deployment moon
&lt;/h2&gt;&lt;p&gt;Many domestic carriers prohibit this&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;curl -s https://install.zerotier.com/ | sudo bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Verify installation success&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;zerotier-cli info
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Join local network&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;zerotier-cli join network-id
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Create&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd /var/lib/zerotier-one &amp;amp;&amp;amp; sudo zerotier-idtool initmoon identity.public &amp;gt; moon.json
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Edit the configuration file, adjust the __INLINE_CODE_0 node, &amp;ldquo;public server IP/9993&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Generate signature configuration, create &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; folder, move existing files here, and restart the service&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo zerotier-idtool genmoon moon.json
mkdir moons.d &amp;amp;&amp;amp; mv 000000eb444ec0d8.moon moons.d/
systemctl restart zerotier-one.service
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Client nodes join the Moon server; their ID is taken from the ID field in the preceding JSON configuration file&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;zerotier-cli.bat orbit ztaddr ztaddr
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# è§‚å¯Ÿæ˜¯å¦å‡ºç°æ–°çš„ mooon èŠ‚ç‚¹ï¼Œid å’Œä¿¡æ¯ä¸ºæœåŠ¡å™¨é…ç½®çš„ç›¸åŒ
[root@idv-36f9d5 ~]# zerotier-cli listpeers
200 listpeers &amp;lt;ztaddr&amp;gt; &amp;lt;path&amp;gt; &amp;lt;latency&amp;gt; &amp;lt;version&amp;gt; &amp;lt;role&amp;gt;
200 listpeers 0cccb***** 35.236.*.*/64393;110;10726 327 1.6.3 LEAF
200 listpeers 3a46f***** 185.180.*.*/9993;110;757 -1 - PLANET
200 listpeers 3ed7c***** 39.97.*.*/9993;172;79 32 1.6.3 MOON
200 listpeers 4f838***** - -1 - LEAF
200 listpeers 62f86***** 50.7.*.*/9993;110;4796 351 - PLANET
200 listpeers 778cd***** 103.195.*.*/9993;5148;4887 253 - PLANET
200 listpeers 992fc***** 195.181.*.*/9993;10161;4921 226 - PLANET
200 listpeers 9d2b5***** - -1 - LEAF
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;On Windows, launch the terminal with administrator privileges and use the &lt;code&gt;zerotier-cli.bat&lt;/code&gt; command-line tool; on Linux, use the &lt;code&gt;zerotier-cli&lt;/code&gt; command. The &lt;code&gt;peers&lt;/code&gt; subcommand displays connections, and &lt;code&gt;listpeers&lt;/code&gt; shows all nodes. Nodes marked as &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; indicate successful joining.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;how-to-uninstall&#34;&gt;How to uninstall
&lt;/h2&gt;&lt;p&gt;It appears you&amp;rsquo;ve provided a string of formatting codes rather than actual Chinese text. Without the Chinese characters, I cannot translate. Please provide the Chinese text you want translated.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Remove zerotier-one service using dpkg&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo dpkg -P zerotier-one
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Deleting the zerotier-one folder, which stores the address, will result in a new address being obtained upon reinstallation&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo rm -rf /var/lib/zerotier-one/
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;afterword&#34;&gt;Afterword
&lt;/h2&gt;&lt;p&gt;Initially, everything was already uninstalled. When the server arrived, there were no suitable service agents available. To boost sales, Alibaba Cloud offered a developer-exclusive server with modest specs and an affordable price of $99 per year. We used it for two years, primarily because of the server&amp;rsquo;s bandwidth.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.wnark.com/archives/152.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.wnark.com/archives/152.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/Yogile/p/12642423.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.cnblogs.com/Yogile/p/12642423.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>VMware virtual machine disk space optimization</title>
        <link>https://ttf248.life/en/p/vmware-virtual-disk-space-optimization/</link>
        <pubDate>Wed, 21 Jun 2023 18:35:41 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/vmware-virtual-disk-space-optimization/</guid>
        <description>&lt;p&gt;When installing a development system on a virtual machine, it&amp;rsquo;s common to reserve extra disk space. Over time, the local storage consumed far exceeds the actual content of the virtual machine files.&lt;/p&gt;
&lt;h2 id=&#34;scene-description&#34;&gt;Scene description
&lt;/h2&gt;&lt;p&gt;The command showed the disk usage was 60GB. After deleting all snapshots and clones, the local virtual machine still occupies significantly more than 60GB, exacerbating the already limited disk space.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;The virtual machine installation did not select pre-allocated disk&lt;/li&gt;
&lt;li&gt;The local disk where the virtual machine is stored has more free space than the virtual machine currently occupies&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The remaining space is insufficient; consider temporarily moving the virtual machine to an external drive, then migrating it back after disk optimization&lt;/p&gt;
&lt;h2 id=&#34;tools&#34;&gt;Tools
&lt;/h2&gt;&lt;p&gt;An official package is provided, which can be installed via yum or a VMware Tools image package&lt;/p&gt;
&lt;h2 id=&#34;orders&#34;&gt;Orders
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;vmware-toolbox-cmd disk shrink /
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After execution, the virtual machine will automatically shut down, and the VMware host program will perform disk compression. The execution time depends on the size of the virtual machine and the speed of the disk access.&lt;/p&gt;
&lt;p&gt;The execution effect is still very good; the virtual machine&amp;rsquo;s disk space usage essentially matches the disk information of &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>Stable Diffusion â€“ A Saga of Installation Troubles</title>
        <link>https://ttf248.life/en/p/stable-diffusion-zero-install-saga/</link>
        <pubDate>Thu, 13 Apr 2023 00:23:54 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/stable-diffusion-zero-install-saga/</guid>
        <description>&lt;p&gt;Domestic resources generally recommend &lt;strong&gt;ç§‹å¶&lt;/strong&gt;&amp;rsquo;s one-click deployment package. Assuming they are based on &lt;code&gt;Python&lt;/code&gt; open-source projects, the deployment shouldn&amp;rsquo;t be too complex; let&amp;rsquo;s try starting from scratch.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;After messing around with AI-generated images, I specially replaced my graphics card, only to have it gloriously shut down&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The core encryption remains inactive&lt;/p&gt;
&lt;h2 id=&#34;pending&#34;&gt;Pending
&lt;/h2&gt;&lt;p&gt;Restructure the article, first introducing PyTorch, version compatibility, and how to check versions
How to create a new virtual environment from scratch and deploy PyTorch locally
Translate draft, starting from scratch, Stable Diffusion &lt;a class=&#34;link&#34; href=&#34;https://stable-diffusion-art.com/install-windows/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stable-diffusion-art.com/install-windows/&lt;/a&gt;
Organize reference materials&lt;/p&gt;
&lt;h2 id=&#34;steps&#34;&gt;Steps
&lt;/h2&gt;&lt;p&gt;You might not find a step-by-step installation tutorial by searching in Chinese. Then, you just download the repository and run the script with a double click.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/AUTOMATIC1111/stable-diffusion-webui&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For detailed usage instructions and FAQs, please refer to &lt;code&gt;issues&lt;/code&gt;ï¼Œ&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I don&amp;rsquo;t know why no one explained what this repository is for. Actually, itâ€™s not hard to tell from the nameâ€”it&amp;rsquo;s an interface console that makes it more convenient to use. In fact, during installation, it will download the official repository content and obtain the actual &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; code.&lt;/p&gt;
&lt;p&gt;The warehouse also includes an installation startup script that automatically detects the presence of &lt;code&gt;Python&lt;/code&gt;è™šæ‹Ÿç¯å¢ƒã€‚å¦‚æœæœ‰çš„è¯é»˜è®¤ä½¿ç”¨å½“å‰è·¯å¾„çš„çš„&lt;code&gt;python&lt;/code&gt; in the current folder&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;re a complete beginner, it is recommended that you check out: &lt;a class=&#34;link&#34; href=&#34;https://stable-diffusion-art.com/install-windows/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stable-diffusion-art.com/install-windows/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;pytorch&#34;&gt;pytorch
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/get-started/locally/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://pytorch.org/get-started/locally/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s what I wanted to say today: First, don&amp;rsquo;t just run the script directly based on their instructions. Python installs dependencies through requirement files â€“ thatâ€™s a minor issue. The core thing is your graphics card driver version needs to correspond with PyTorch. Many resources online explain this relationship; you can easily find it.&lt;/p&gt;
&lt;p&gt;Reference: &lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/weixin_40660408/article/details/129896700&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/weixin_40660408/article/details/129896700&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Creating a virtual environment firstâ€”an empty oneâ€”allows you to directly run the script from the official website to install PyTorch&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -c &amp;quot;import torch; print(torch.version.cuda)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -c &amp;quot;import torch; print(torch.__version__, torch.cuda.is_available())&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These two scripts can check your CUDA version and whether the installation was successful&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s not recommended to use complicated operations here. Just copy the logic from the official page and install it directly. Installing via pip may result in failure or CUDA activation issues.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Important: Ensure the folder path is clean; otherwise, PyTorch may not work properly&lt;/p&gt;
&lt;p&gt;It involved numerous installations and attempts to manually install the official files. The goal was to upgrade to version 2.0, as the official documentation states it offers improved speed. However, I wasn&amp;rsquo;t familiar with the software and unsure if the Python version or other factors were influencing performance. I also consulted the official manual, which recommends using version 3.8. This created a conflict since a previous one-click deployment package used version 3.10. Ultimately, I started from scratch: creating a new folder, establishing a virtual environment, and ensuring torch was successfully installed.&lt;/p&gt;
&lt;p&gt;Then move this installed virtual environment into the web UI folder. Starting the installation script again at this point should resolve most dependency issues.&lt;/p&gt;
&lt;p&gt;After moving, you need to run: python -m pip install &amp;ndash;upgrade &amp;ndash;force-reinstall pip to fix it&lt;/p&gt;
&lt;p&gt;It might seem odd, but I spent a while troubleshooting this. It couldn&amp;rsquo;t correctly identify my torch, so to eliminate all potential interference, I decided to install it first, before installing other dependencies.&lt;/p&gt;
&lt;h2 id=&#34;xformers&#34;&gt;Xformers
&lt;/h2&gt;&lt;p&gt;Recommended to enable; accelerates image generation and reduces current usage. Side effect: same parameter group, &lt;strong&gt;ç”Ÿæˆçš„å›¾åƒç›¸å¯¹ä¸æ˜¯é‚£ä¹ˆç¨³å®š&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;stable-diffusion-webui:Xformers&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/diffusers/optimization/xformers&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;huggingface optimization&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Optimization Ratio&lt;/th&gt;
&lt;th&gt;Time taken&lt;/th&gt;
&lt;th&gt;Torch active/reserved&lt;/th&gt;
&lt;th&gt;Sys VRAM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;100.00%&lt;/td&gt;
&lt;td&gt;2m 57.03s&lt;/td&gt;
&lt;td&gt;7440/10058 MiB&lt;/td&gt;
&lt;td&gt;12288/12288 MiB (100.0%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;51.02%&lt;/td&gt;
&lt;td&gt;1m 29.21s&lt;/td&gt;
&lt;td&gt;4547/7164 MiB&lt;/td&gt;
&lt;td&gt;9298/12288 MiB (75.67%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;((masterpiece)),((best quality)),((high detial)),((realistic,))
Industrial age city, deep canyons in the middle,chinese architectural streets,bazaars, Bridges, (rainy days:1.2), (steampunk:0.8), chinese architecture
Negative prompt: nsfw,((cowboy)),(((pubic))), ((((pubic_hair))))sketch, duplicate, ugly, huge eyes, text, logo, monochrome, worst face, (bad and mutated hands:1.3), (worst quality:2.0), (low quality:2.0), (blurry:2.0), horror, geometry, bad_prompt, (bad hands), (missing fingers), multiple limbs, bad anatomy, (interlocked fingers:1.2), Ugly Fingers, (extra digit and hands and fingers and legs and arms:1.4), crown braid, ((2girl)), (deformed fingers:1.2), (long fingers:1.2),succubus wings,horn,succubus horn,succubus hairstyle, (bad-artist-anime), bad-artist, bad hand, borrowed character, text focus, watermark, sample watermark, character watermark, lofter username, photo date watermark, movie poster, magazine cover, journal, cover, cover page, doujin cover, album cover, manga cover, brand name imitation, EasyNegative,Tights, silk stockings,shorts
Steps: 35, Sampler: DPM adaptive, CFG scale: 5.5, Seed: 2223996555, Size: 1088x1088, Model hash: 543bcbc212, Model: base_Anything-V3.0-pruned, Clip skip: 2, ENSD: 31337
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;afterword&#34;&gt;Afterword
&lt;/h2&gt;&lt;p&gt;It&amp;rsquo;s better to recommend the one-click deployment package. However, that package contains some custom settings from the author, which differ from the official, original version. If youâ€™re a beginner, you might not understand why itâ€™s best to start with the official parameters. As you gain experience, refer to the official documentation to learn which parameters need adjustment.&lt;/p&gt;
&lt;h2 id=&#34;graphics-card-selection&#34;&gt;Graphics card selection
&lt;/h2&gt;&lt;p&gt;After the cryptocurrency mining boom, graphics card prices are relatively lower now. For ordinary entry-level players, the amount of VRAM is sufficient.&lt;/p&gt;
&lt;p&gt;Also, &lt;strong&gt;é«˜æ¸…æ”¾å¤§&lt;/strong&gt; options require more detailed implementation, enriching screen details and demanding more video memory&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a summary table of single-precision (FP32), half-precision (FP16), and double-precision (FP64) floating-point compute capabilities for NVIDIA GeForce GTX 970, GeForce RTX 3060 Ti, GeForce RTX 3060, GeForce RTX 3080, and GeForce RTX 3080 Ti&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Release Year&lt;/th&gt;
&lt;th&gt;Single-Precision Floating-Point Performance (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating-Point Performance (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating-Point Performance (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;GeForce GTX 970&lt;/td&gt;
&lt;td&gt;2014&lt;/td&gt;
&lt;td&gt;3.49&lt;/td&gt;
&lt;td&gt;87.2&lt;/td&gt;
&lt;td&gt;0.109&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GeForce RTX 3060 Ti&lt;/td&gt;
&lt;td&gt;2020&lt;/td&gt;
&lt;td&gt;16.2&lt;/td&gt;
&lt;td&gt;32.4&lt;/td&gt;
&lt;td&gt;0.51&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GeForce RTX 3060&lt;/td&gt;
&lt;td&gt;2021&lt;/td&gt;
&lt;td&gt;12.7&lt;/td&gt;
&lt;td&gt;25.4&lt;/td&gt;
&lt;td&gt;0.39&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GeForce RTX 3080&lt;/td&gt;
&lt;td&gt;2020&lt;/td&gt;
&lt;td&gt;29.8&lt;/td&gt;
&lt;td&gt;58.9&lt;/td&gt;
&lt;td&gt;0.93&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GeForce RTX 3080 Ti&lt;/td&gt;
&lt;td&gt;2021&lt;/td&gt;
&lt;td&gt;34.8&lt;/td&gt;
&lt;td&gt;68.7&lt;/td&gt;
&lt;td&gt;1.36&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Quoted from&lt;/p&gt;
&lt;h2 id=&#34;update&#34;&gt;Update
&lt;/h2&gt;&lt;p&gt;After six months, I intended to review the installation steps and explain more basic concepts. However, it turns out that for ordinary people using AI image generation, it&amp;rsquo;s mostly about adjusting parameters based on images provided by experts or re-rendering existing images in a formatted way.&lt;/p&gt;
&lt;p&gt;We tried using AI to generate UI assets for a mini-program, but after all that effort, the results were unsatisfactory. It&amp;rsquo;s better to just pull resources directly from the official mini-program.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Optimize your code; dont fight the hardware</title>
        <link>https://ttf248.life/en/p/program-optimization-dont-fight-hardware/</link>
        <pubDate>Fri, 07 Apr 2023 16:30:15 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/program-optimization-dont-fight-hardware/</guid>
        <description>&lt;p&gt;At the microsecond level, replacing the server reduced packet backlog from a maximum of 60,000 to almost none&lt;/p&gt;
&lt;p&gt;In single-threaded data processing, CPU performance depends on factors such as clock speed, cache size, and instruction set architecture. Generally, CPUs with higher clock speeds, larger caches, and more advanced instruction set architectures offer better performance in single-threaded scenarios.&lt;/p&gt;
&lt;h2 id=&#34;single-threaded&#34;&gt;Single-threaded
&lt;/h2&gt;&lt;p&gt;Performance improvements don&amp;rsquo;t necessarily require increasing threads. Streamline project workflows, identify bottlenecks, and determine if single-threading is sufficient. Single-threading also involves fewer considerations and is less prone to issues.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Starting off by talking about adding threads, there&amp;rsquo;s definitely something wrong with that&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;event&#34;&gt;Event
&lt;/h2&gt;&lt;p&gt;Dealing with [or Handling] &lt;strong&gt;è¡Œæƒ…æ•°æ®ï¼Œå»¶è¿Ÿæ•æ„Ÿ&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Worked overtime all night, released a new optimized version. Local interface stripping tests are okay, with a TPS of 42,000.&lt;/p&gt;
&lt;p&gt;Deployed to the server, TPS plummeted: 21,000. Tried on my desktop at home, TPS: 79,000. Starting to suspect there might be an issue with the group&amp;rsquo;s service virtual machines, likely related to CPU frequency. The biggest difference between my desktop and the server &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; is the CPU frequency.&lt;/p&gt;
&lt;p&gt;Test Server A&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;processor	: 7
vendor_id	: GenuineIntel
cpu family	: 6
model		: 47
model name	: Intel(R) Xeon(R) CPU E7- 4807  @ 1.87GHz
stepping	: 2
microcode	: 0x34
cpu MHz		: 1866.733
cache size	: 18432 KB
physical id	: 1
siblings	: 4
core id		: 3
cpu cores	: 4
apicid		: 7
initial apicid	: 7
fpu		: yes
fpu_exception	: yes
cpuid level	: 11
wp		: yes
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss ht syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 cx16 sse4_1 sse4_2 popcnt aes hypervisor lahf_lm pti dtherm arat
bugs		: clflush_monitor cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit
bogomips	: 3733.46
clflush size	: 64
cache_alignment	: 64
address sizes	: 40 bits physical, 48 bits virtual
power management:
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Test Server B&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;processor	: 7
vendor_id	: GenuineIntel
cpu family	: 6
model		: 63
model name	: Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz
stepping	: 2
microcode	: 0x3c
cpu MHz		: 2599.998
cache size	: 20480 KB
physical id	: 14
siblings	: 1
core id		: 0
cpu cores	: 1
apicid		: 14
initial apicid	: 14
fpu		: yes
fpu_exception	: yes
cpuid level	: 15
wp		: yes
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cpuid_fault epb pti fsgsbase smep xsaveopt cqm_llc cqm_occup_llc dtherm ida arat pln pts
bugs		: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit
bogomips	: 5199.99
clflush size	: 64
cache_alignment	: 64
address sizes	: 40 bits physical, 48 bits virtual
power management:
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;consult-openai&#34;&gt;Consult OpenAI
&lt;/h2&gt;&lt;p&gt;Regarding core count and clock speed, the Intel(R) Xeon(R) CPU E7-4807 @ 1.87GHz has 6 physical cores and 12 logical cores with a clock speed of 1.87GHz; while the Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz has 8 physical cores and 16 logical cores with a clock speed of 2.60GHz. Therefore, in terms of core count and clock speed, the E5-2640 v3 should have an advantage over the E7-4807 when processing data on a single thread.&lt;/p&gt;
&lt;p&gt;Regarding cache size, the E7-4807 has 12MB compared to the E5-2640 v3&amp;rsquo;s 20MB. Consequently, the E5-2640 v3 offers greater cache space, potentially improving data access speed and cache hit rate.&lt;/p&gt;
&lt;p&gt;Finally, regarding architecture, the E5-2640 v3 uses the more advanced Haswell architecture, while the E7-4807 utilizes the older Nehalem architecture. The Haswell architecture offers performance improvements over Nehalem, which may positively impact the E5-2640 v3&amp;rsquo;s single-thread data processing capabilities.&lt;/p&gt;
&lt;p&gt;Therefore, considering all factors, in a single-threaded data processing scenario, the E5-2640 v3 should offer better performance than the E7-4807. However, specific performance differences will be influenced by various factors such as data processing algorithms, memory bandwidth, and system load; analysis must be tailored to each situation.&lt;/p&gt;
&lt;h2 id=&#34;hardware-materials&#34;&gt;Hardware materials
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cpubenchmark.net/compare/3786.2vs2365.2/%5BDual-CPU%5D-Intel-Xeon-E7%e2%80%934807-vs-%5BDual-CPU%5D-Intel-Xeon-E5-2640-v3&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.cpubenchmark.net/compare/3786.2vs2365.2/%5BDual-CPU%5D-Intel-Xeon-E7â€“4807-vs-%5BDual-CPU%5D-Intel-Xeon-E5-2640-v3&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Specification&lt;/th&gt;
&lt;th&gt;Xeon E7-4807 (LGA1567)&lt;/th&gt;
&lt;th&gt;Xeon E5-2640 v3 (LGA2011-v3)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Price&lt;/td&gt;
&lt;td&gt;Search Online  $78 - BUY&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Socket Type&lt;/td&gt;
&lt;td&gt;LGA1567&lt;/td&gt;
&lt;td&gt;LGA2011-v3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CPU Class&lt;/td&gt;
&lt;td&gt;Server&lt;/td&gt;
&lt;td&gt;Server&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Clockspeed&lt;/td&gt;
&lt;td&gt;1.9 GHz&lt;/td&gt;
&lt;td&gt;2.6 GHz&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Turbo Speed&lt;/td&gt;
&lt;td&gt;Not Supported&lt;/td&gt;
&lt;td&gt;Up to 3.4 GHz&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;# of Physical Cores&lt;/td&gt;
&lt;td&gt;6 (Threads: 12)&lt;/td&gt;
&lt;td&gt;8 (Threads: 16)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cache&lt;/td&gt;
&lt;td&gt;NA2&lt;/td&gt;
&lt;td&gt;NA2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Max TDP&lt;/td&gt;
&lt;td&gt;95W x 2&lt;/td&gt;
&lt;td&gt;90W x 2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Yearly Running Cost&lt;/td&gt;
&lt;td&gt;$34.68&lt;/td&gt;
&lt;td&gt;$32.85&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Other&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;First Seen on Chart&lt;/td&gt;
&lt;td&gt;Q3 2020&lt;/td&gt;
&lt;td&gt;Q3 2014&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;# of Samples&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;46&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CPU Value&lt;/td&gt;
&lt;td&gt;69.1&lt;/td&gt;
&lt;td&gt;225.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Single Thread Rating&lt;/td&gt;
&lt;td&gt;721 (-59.2%)&lt;/td&gt;
&lt;td&gt;1767 (0.0%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CPU Mark&lt;/td&gt;
&lt;td&gt;6223 (-64.6%)&lt;/td&gt;
&lt;td&gt;17600 (0.0%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</description>
        </item>
        <item>
        <title>prompt-engineer</title>
        <link>https://ttf248.life/en/p/prompt-engineer/</link>
        <pubDate>Sun, 26 Mar 2023 20:46:53 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/prompt-engineer/</guid>
        <description>&lt;p&gt;Just as we learned techniques for using search engines, we also need to learn communication skills â€“ providing reasonable and sufficient constraints to efficiently obtain the answers we need&lt;/p&gt;
&lt;p&gt;If you look at it from a different angle, the current situation will generate the desired result&lt;/p&gt;
&lt;h2 id=&#34;science-communication&#34;&gt;Science communication
&lt;/h2&gt;&lt;p&gt;Generative Pre-trained Transformer (GPT) is a deep learning model trained on publicly available internet data, used for tasks like question answering, text summarization, machine translation, classification, code generation, and conversational AI. There are currently various versions of GPT, including GPT-1, GPT-2, GPT-3, and GPT-4, each larger and more powerful than its predecessor.&lt;/p&gt;
&lt;h2 id=&#34;does-intelligence-truly-exist&#34;&gt;Does intelligence truly exist?
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;The higher the similarity, the greater the accuracy&lt;/li&gt;
&lt;li&gt;Basic, repetitive tasks no longer require human intervention after specific training&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Generative AI is a technology that utilizes existing data such as text, audio, and images to create new content. It can be applied to various tasks including text generation, speech synthesis, image generation, and conversational systems. The logic of generative AI depends on its training data and model structure. Generally, it can follow grammar, logic, and common sense to a certain extent, but may also produce errors, biases, or inaccurate information. Therefore, the output of generative AI requires human judgment and verification; it should not be blindly trusted or used.&lt;/p&gt;
&lt;h2 id=&#34;prompt-engineer&#34;&gt;prompt-engineer
&lt;/h2&gt;&lt;p&gt;The river of time doesn&amp;rsquo;t flow backward; people need to learn to adapt to the trend. You can consider &lt;em&gt;[INLIN]&lt;/em&gt; as unintelligent and lacking logic, often producing unusable code.&lt;/p&gt;
&lt;p&gt;If you look at it from a different angle, the current situation will generate the desired result&lt;/p&gt;
&lt;h2 id=&#34;dialogue-mode&#34;&gt;Dialogue mode
&lt;/h2&gt;&lt;p&gt;Two years ago, [something] dramatically emerged, allowing humanity to recognize the capabilities of large language models&lt;/p&gt;
&lt;p&gt;Based on &lt;strong&gt;åŸºäºæ³¨é‡Šçš„ç¼–ç¨‹&lt;/strong&gt; and &lt;strong&gt;åŸºäºå¯¹è¯çš„ç¼–ç¨‹&lt;/strong&gt;, the interactive logic is completely different; the dialogue pattern offers a user-friendly experience for novice users. It&amp;rsquo;s essential to mention &lt;code&gt;NewBing&lt;/code&gt;åœ¨æ¯ä¸ªé—®é¢˜ä¹‹åï¼Œç»™å‡ºçš„è¿½é—®æç¤ºï¼Œå¾®è½¯åœ¨å°è¯•å¼•å¯¼ç”¨æˆ·ï¼Œè·å–&lt;code&gt;AI&lt;/code&gt; within the knowledge base, with more content.&lt;/p&gt;
&lt;h2 id=&#34;for-example&#34;&gt;For example
&lt;/h2&gt;&lt;p&gt;A long journey on high-speed rail; coding is a good option. With limited data, processing a few images and obtaining image resources is manageable, but downloading software to process them is a bit of a luxury given the network conditions.&lt;/p&gt;
&lt;p&gt;A batch of image assets with transparent backgrounds are needed for a mini-program navigation bar. Selected states should be colored, unselected states black and white. The assets are currently in color and require preprocessing.&lt;/p&gt;
&lt;p&gt;Write a Python code snippet that reads all images from a folder, converts them to grayscale, preserves transparency, optimizes image quality and reduces file size upon saving, and displays the comparison of file sizes before and after optimization in the console&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# å¯¼å…¥å¿…è¦çš„åº“
import os
import PIL
from PIL import Image

# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œå°†å›¾ç‰‡è½¬æ¢æˆé»‘ç™½ï¼Œç»´æŒé€æ˜èƒŒæ™¯ï¼Œä¿å­˜å›¾ç‰‡ï¼Œå¹¶è¿”å›æ–‡ä»¶ä½“ç§¯
def convert_and_save(image_file):
    # æ‰“å¼€å›¾ç‰‡
    image = Image.open(image_file)
    # è·å–å›¾ç‰‡çš„æ¨¡å¼ï¼Œå¦‚æœæ˜¯ RGBA æ¨¡å¼ï¼Œè¯´æ˜æœ‰é€æ˜èƒŒæ™¯
    mode = image.mode
    if mode == &amp;quot;RGBA&amp;quot;:
        # åˆ›å»ºä¸€ä¸ªå’Œå›¾ç‰‡å¤§å°ä¸€è‡´çš„ç™½è‰²èƒŒæ™¯å›¾ç‰‡
        background = Image.new(&amp;quot;RGB&amp;quot;, image.size, (255, 255, 255))
        # å°†åŸå›¾ç‰‡ç²˜è´´åˆ°ç™½è‰²èƒŒæ™¯ä¸Šï¼Œå¿½ç•¥é€æ˜åƒç´ 
        background.paste(image, mask=image.split()[3])
        # å°†åˆæˆçš„å›¾ç‰‡è½¬æ¢æˆç°åº¦æ¨¡å¼
        gray_image = background.convert(&amp;quot;L&amp;quot;)
        # å°†ç°åº¦å›¾ç‰‡å†è½¬æ¢æˆ RGBA æ¨¡å¼ï¼Œä»¥ä¾¿ä¿ç•™é€æ˜èƒŒæ™¯
        final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
    else:
        # å¦‚æœä¸æ˜¯ RGBA æ¨¡å¼ï¼Œç›´æ¥å°†å›¾ç‰‡è½¬æ¢æˆç°åº¦æ¨¡å¼
        final_image = image.convert(&amp;quot;L&amp;quot;)
    # è·å–åŸå›¾ç‰‡çš„æ–‡ä»¶åå’Œæ‰©å±•å
    file_name, file_ext = os.path.splitext(image_file)
    # å®šä¹‰æ–°å›¾ç‰‡çš„æ–‡ä»¶åï¼Œæ·»åŠ  _bw åç¼€è¡¨ç¤ºé»‘ç™½
    new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # ä¿å­˜æ–°å›¾ç‰‡ï¼Œå¹¶ä¼˜åŒ–è´¨é‡ï¼Œå‡å°‘æ–‡ä»¶ä½“ç§¯
    final_image.save(new_file_name, optimize=True)
    # è·å–åŸå›¾ç‰‡å’Œæ–°å›¾ç‰‡çš„æ–‡ä»¶ä½“ç§¯ï¼Œå¹¶è¿”å›
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return old_size, new_size

# å®šä¹‰ä¸€ä¸ªæ–‡ä»¶å¤¹è·¯å¾„ï¼Œå­˜æ”¾æ‰€æœ‰çš„å›¾ç‰‡
folder_path = &amp;quot;images&amp;quot;
# éå†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶
for file in os.listdir(folder_path):
    # æ‹¼æ¥å®Œæ•´çš„æ–‡ä»¶è·¯å¾„
    file_path = os.path.join(folder_path, file)
    # åˆ¤æ–­æ˜¯å¦æ˜¯å›¾ç‰‡æ–‡ä»¶ï¼Œæ ¹æ®æ‰©å±•ååˆ¤æ–­ï¼Œå¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æˆ–ä¿®æ”¹æ‰©å±•å
    if file_path.endswith((&amp;quot;.png&amp;quot;, &amp;quot;.jpg&amp;quot;, &amp;quot;.jpeg&amp;quot;, &amp;quot;.gif&amp;quot;)):
        # è°ƒç”¨å‡½æ•°ï¼Œè½¬æ¢å¹¶ä¿å­˜å›¾ç‰‡ï¼Œå¹¶è·å–æ–‡ä»¶ä½“ç§¯
        old_size, new_size = convert_and_save(file_path)
        # åœ¨æ§åˆ¶å°å±•ç¤ºä¼˜åŒ–å‰åçš„æ–‡ä»¶ä½“ç§¯å¤§å°å¯¹æ¯”
        print(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Quickly provided an answer, looks good, and works fine. Experienced programmers will find the code lacks generality and isn&amp;rsquo;t suitable for production environments.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Parameters fixed&lt;/li&gt;
&lt;li&gt;No log files; information is printed to the console&lt;/li&gt;
&lt;li&gt;Image processing tasks are well-suited for multithreaded models&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Are there any improvements that can be made to this code?&lt;/p&gt;
&lt;p&gt;This answer, frankly, far exceeded expectations. It provides suggestions for optimizations that even a typical programmer would consider.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;è¿™æ®µä»£ç å¯èƒ½è¿˜æœ‰ä¸€äº›å¯ä»¥æ”¹è¿›çš„åœ°æ–¹ï¼Œæ¯”å¦‚ï¼š

å¯ä»¥ä½¿ç”¨ argparse åº“ï¼Œè®©ç”¨æˆ·å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šæ–‡ä»¶å¤¹è·¯å¾„å’Œæ‰©å±•åï¼Œè€Œä¸æ˜¯å†™æ­»åœ¨ä»£ç é‡Œã€‚
å¯ä»¥ä½¿ç”¨ logging åº“ï¼Œè®°å½•ç¨‹åºçš„è¿è¡Œæƒ…å†µï¼Œè€Œä¸æ˜¯ç›´æ¥æ‰“å°åˆ°æ§åˆ¶å°ã€‚
å¯ä»¥ä½¿ç”¨ try-except è¯­å¥ï¼Œæ•è·å¯èƒ½å‡ºç°çš„å¼‚å¸¸ï¼Œæ¯”å¦‚æ–‡ä»¶æ‰“å¼€å¤±è´¥ï¼Œå›¾ç‰‡è½¬æ¢å¤±è´¥ç­‰ï¼Œå¹¶åšç›¸åº”çš„å¤„ç†ã€‚
å¯ä»¥ä½¿ç”¨ multiprocessing åº“ï¼Œåˆ©ç”¨å¤šæ ¸å¤„ç†å™¨ï¼ŒåŠ é€Ÿå›¾ç‰‡çš„è½¬æ¢å’Œä¿å­˜è¿‡ç¨‹ã€‚
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A friendly response, considering deployment environments may vary, supporting only single-process execution is permitted&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;å½“ç„¶ï¼Œæˆ‘å¾ˆä¹æ„å¸®ä½ ä¿®æ”¹ä¸€ä¸‹ä»£ç ã€‚æˆ‘å°è¯•æ·»åŠ äº† argparse, logging å’Œ try-except è¯­å¥ï¼Œä½†æ²¡æœ‰æ·»åŠ  multiprocessing åº“ï¼Œå› ä¸ºæˆ‘ä¸ç¡®å®šä½ çš„ç”µè„‘æ˜¯å¦æ”¯æŒå¤šæ ¸å¤„ç†ã€‚ä¿®æ”¹åçš„ä»£ç å¦‚ä¸‹ï¼š
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# å¯¼å…¥å¿…è¦çš„åº“
import argparse
import logging
import multiprocessing
import os

from PIL import Image


# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œå°†å›¾ç‰‡è½¬æ¢æˆé»‘ç™½ï¼Œç»´æŒé€æ˜èƒŒæ™¯ï¼Œä¿å­˜å›¾ç‰‡ï¼Œå¹¶è¿”å›æ–‡ä»¶ä½“ç§¯
def convert_and_save(image_file):
    # æ‰“å¼€å›¾ç‰‡
    try:
        image = Image.open(image_file)
    except Exception as e:
        logging.error(f&amp;quot;Failed to open {image_file}: {e}&amp;quot;)
        return None, None
    # è·å–å›¾ç‰‡çš„æ¨¡å¼ï¼Œå¦‚æœæ˜¯ RGBA æ¨¡å¼ï¼Œè¯´æ˜æœ‰é€æ˜èƒŒæ™¯
    mode = image.mode
    if mode == &amp;quot;RGBA&amp;quot;:
        # åˆ›å»ºä¸€ä¸ªå’Œå›¾ç‰‡å¤§å°ä¸€è‡´çš„ç™½è‰²èƒŒæ™¯å›¾ç‰‡
        background = Image.new(&amp;quot;RGB&amp;quot;, image.size, (255, 255, 255))
        # å°†åŸå›¾ç‰‡ç²˜è´´åˆ°ç™½è‰²èƒŒæ™¯ä¸Šï¼Œå¿½ç•¥é€æ˜åƒç´ 
        background.paste(image, mask=image.split()[3])
        # å°†åˆæˆçš„å›¾ç‰‡è½¬æ¢æˆç°åº¦æ¨¡å¼
        gray_image = background.convert(&amp;quot;L&amp;quot;)
        # å°†ç°åº¦å›¾ç‰‡å†è½¬æ¢æˆ RGBA æ¨¡å¼ï¼Œä»¥ä¾¿ä¿ç•™é€æ˜èƒŒæ™¯
        final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
    else:
        # å¦‚æœä¸æ˜¯ RGBA æ¨¡å¼ï¼Œç›´æ¥å°†å›¾ç‰‡è½¬æ¢æˆç°åº¦æ¨¡å¼
        final_image = image.convert(&amp;quot;L&amp;quot;)
    # è·å–åŸå›¾ç‰‡çš„æ–‡ä»¶åå’Œæ‰©å±•å
    file_name, file_ext = os.path.splitext(image_file)
    # å®šä¹‰æ–°å›¾ç‰‡çš„æ–‡ä»¶åï¼Œæ·»åŠ  _bw åç¼€è¡¨ç¤ºé»‘ç™½
    new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # ä¿å­˜æ–°å›¾ç‰‡ï¼Œå¹¶ä¼˜åŒ–è´¨é‡ï¼Œå‡å°‘æ–‡ä»¶ä½“ç§¯
    try:
        final_image.save(new_file_name, optimize=True)
    except Exception as e:
        logging.error(f&amp;quot;Failed to save {new_file_name}: {e}&amp;quot;)
        return None, None
    # è·å–åŸå›¾ç‰‡å’Œæ–°å›¾ç‰‡çš„æ–‡ä»¶ä½“ç§¯ï¼Œå¹¶è¿”å›
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return file_name, old_size, new_size

# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œè§£æå‘½ä»¤è¡Œå‚æ•°ï¼Œå¹¶è¿”å›æ–‡ä»¶å¤¹è·¯å¾„å’Œæ‰©å±•ååˆ—è¡¨
def parse_args():
    # åˆ›å»ºä¸€ä¸ªè§£æå™¨å¯¹è±¡
    parser = argparse.ArgumentParser(description=&amp;quot;Convert images to black and white and optimize quality.&amp;quot;)
    # æ·»åŠ ä¸€ä¸ªå¿…é€‰çš„ä½ç½®å‚æ•°ï¼Œè¡¨ç¤ºæ–‡ä»¶å¤¹è·¯å¾„
    parser.add_argument(&amp;quot;folder_path&amp;quot;, help=&amp;quot;The path of the folder that contains the images.&amp;quot;)
    # æ·»åŠ ä¸€ä¸ªå¯é€‰çš„å‚æ•°ï¼Œè¡¨ç¤ºæ‰©å±•ååˆ—è¡¨ï¼Œé»˜è®¤ä¸º png, jpg, jpeg å’Œ gif
    parser.add_argument(&amp;quot;-e&amp;quot;, &amp;quot;--extensions&amp;quot;, nargs=&amp;quot;+&amp;quot;, default=[&amp;quot;.png&amp;quot;, &amp;quot;.jpg&amp;quot;, &amp;quot;.jpeg&amp;quot;, &amp;quot;.gif&amp;quot;], help=&amp;quot;The extensions of the image files.&amp;quot;)
    # è§£æå‘½ä»¤è¡Œå‚æ•°ï¼Œå¹¶è¿”å›ç»“æœå¯¹è±¡
    args = parser.parse_args()
    return args.folder_path, args.extensions

# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œæ‰“å°ä¼˜åŒ–å‰åçš„æ–‡ä»¶ä½“ç§¯å¤§å°å¯¹æ¯”
def print_result(result):
    # å¦‚æœç»“æœä¸ä¸ºç©ºï¼Œè¯´æ˜è½¬æ¢å’Œä¿å­˜æˆåŠŸ
    if result:
        # è§£åŒ…ç»“æœä¸ºæ–‡ä»¶åå’Œæ–‡ä»¶ä½“ç§¯å…ƒç»„
        if len(result) == 3:
            file, old_size, new_size = result
            # åœ¨æ§åˆ¶å°å±•ç¤ºä¼˜åŒ–å‰åçš„æ–‡ä»¶ä½“ç§¯å¤§å°å¯¹æ¯”
            logging.info(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)
        else:
            logging.info(f&amp;quot;{result}&amp;quot;)

# é…ç½®æ—¥å¿—è®°å½•å™¨ï¼Œå°†æ—¥å¿—è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶ä¸­ï¼Œè®¾ç½®æ—¥å¿—ç­‰çº§ä¸º INFO
logging.basicConfig(level=logging.INFO,
                    format=&amp;quot;%(asctime)s %(levelname)s %(message)s&amp;quot;,
                    handlers=[logging.StreamHandler(),
                              logging.FileHandler(&amp;quot;log.txt&amp;quot;)])

# è°ƒç”¨å‡½æ•°ï¼Œè·å–æ–‡ä»¶å¤¹è·¯å¾„å’Œæ‰©å±•ååˆ—è¡¨
folder_path, extensions = parse_args()

if __name__ == &amp;quot;__main__&amp;quot;:
    # Windows éœ€è¦è¿™ä¸ªå‡½æ•°çš„åŸå› æ˜¯ Windows ç¼ºä¹ fork() å‡½æ•°ï¼ˆè¿™ä¸å®Œå…¨æ­£ç¡®ï¼‰ã€‚
    # å› æ­¤ï¼Œåœ¨ Windows ä¸Šï¼Œfork() æ˜¯é€šè¿‡åˆ›å»ºä¸€ä¸ªæ–°çš„è¿›ç¨‹æ¥æ¨¡æ‹Ÿçš„ï¼Œè¿™ä¸ªæ–°çš„è¿›ç¨‹ä¸­è¿è¡Œçš„ä»£ç ï¼Œåœ¨ Linux ä¸Šæ˜¯åœ¨å­è¿›ç¨‹ä¸­è¿è¡Œçš„ã€‚
    # ç”±äºè¿™äº›ä»£ç è¦åœ¨æŠ€æœ¯ä¸Šæ— å…³çš„è¿›ç¨‹ä¸­è¿è¡Œï¼Œæ‰€ä»¥å®ƒå¿…é¡»åœ¨è¿è¡Œä¹‹å‰è¢«ä¼ é€’åˆ°é‚£é‡Œã€‚
    # ä¼ é€’çš„æ–¹å¼æ˜¯å…ˆå°†å®ƒä»¬åºåˆ—åŒ–ï¼Œç„¶åé€šè¿‡ç®¡é“ä»åŸå§‹è¿›ç¨‹å‘é€åˆ°æ–°çš„è¿›ç¨‹ã€‚
    # å¦å¤–ï¼Œè¿™ä¸ªæ–°çš„è¿›ç¨‹è¢«é€šçŸ¥å®ƒå¿…é¡»è¿è¡Œé€šè¿‡ç®¡é“ä¼ é€’çš„ä»£ç ï¼Œé€šè¿‡å‘å®ƒä¼ é€’ --multiprocessing-fork å‘½ä»¤è¡Œå‚æ•°ã€‚
    # å¦‚æœä½ çœ‹ä¸€ä¸‹ freeze_support() å‡½æ•°çš„å®ç°ï¼Œå®ƒçš„ä»»åŠ¡æ˜¯æ£€æŸ¥å®ƒè¿è¡Œåœ¨å“ªä¸ªè¿›ç¨‹ä¸­ï¼Œæ˜¯å¦åº”è¯¥è¿è¡Œé€šè¿‡ç®¡é“ä¼ é€’çš„ä»£ç 
    multiprocessing.freeze_support()

    # åˆ›å»ºä¸€ä¸ªè¿›ç¨‹æ± ï¼Œæ ¹æ®ç”µè„‘çš„æ ¸å¿ƒæ•°è‡ªåŠ¨åˆ†é…è¿›ç¨‹
    pool = multiprocessing.Pool()
    # åˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨ï¼Œç”¨äºå­˜æ”¾å¼‚æ­¥ä»»åŠ¡çš„ç»“æœå¯¹è±¡
    results = []
    # éå†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    for file in os.listdir(folder_path):
        # æ‹¼æ¥å®Œæ•´çš„æ–‡ä»¶è·¯å¾„
        file_path = os.path.join(folder_path, file)
        # åˆ¤æ–­æ˜¯å¦æ˜¯å›¾ç‰‡æ–‡ä»¶ï¼Œæ ¹æ®æ‰©å±•ååˆ¤æ–­ï¼Œå¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹æ‰©å±•ååˆ—è¡¨
        if any(file_path.endswith(ext) for ext in extensions):
            # è°ƒç”¨å‡½æ•°ï¼Œè½¬æ¢å¹¶ä¿å­˜å›¾ç‰‡ï¼Œå¹¶è·å–æ–‡ä»¶ä½“ç§¯ï¼Œä½¿ç”¨å¼‚æ­¥æ–¹å¼ï¼Œä¸é˜»å¡ä¸»è¿›ç¨‹
            result = pool.apply_async(convert_and_save, args=(file_path,), callback=print_result)
            # å°†ç»“æœå¯¹è±¡æ·»åŠ åˆ°åˆ—è¡¨ä¸­
            results.append((file, result))
    # å…³é—­è¿›ç¨‹æ± ï¼Œä¸å†æ¥å—æ–°çš„ä»»åŠ¡
    pool.close()
    # ç­‰å¾…æ‰€æœ‰çš„ä»»åŠ¡å®Œæˆ
    pool.join()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;afterword&#34;&gt;Afterword
&lt;/h2&gt;&lt;p&gt;Due to local development issues, the code was fixed by investigating reported errors&lt;/p&gt;
&lt;p&gt;Just as we learned techniques for using search engines, we also need to learn communication skills â€“ providing reasonable and sufficient constraints to efficiently obtain the answers we need&lt;/p&gt;
&lt;p&gt;Note:&lt;/p&gt;</description>
        </item>
        <item>
        <title>WeChat Mini Program Background and Development Environment</title>
        <link>https://ttf248.life/en/p/wechat-mini-program-background-and-development-environment/</link>
        <pubDate>Fri, 24 Mar 2023 21:59:11 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/wechat-mini-program-background-and-development-environment/</guid>
        <description>&lt;p&gt;Introduction to and Preparation for WeChat Mini Programs&lt;/p&gt;
&lt;h2 id=&#34;why-do-wechat-mini-programs-exist&#34;&gt;Why do WeChat mini programs exist?
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Improved experience: Slow loading of embedded webpages, blank screens; Native app experiences offer faster loading&lt;/li&gt;
&lt;li&gt;Standards and Management: For WeChat, accessing and managing&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Before the release of mini-programs, WeChat launched a &lt;em&gt;bold_italicized&lt;/em&gt; feature exposing its native capabilitiesâ€”WeChat Pay and Wechat Cards. However, developers used web development languages, allowing them to bypass some of WeChat&amp;rsquo;s regulations. Mini-programs have their own descriptive language.&lt;/p&gt;
&lt;h2 id=&#34;what-is-a-mini-program&#34;&gt;What is a mini program?
&lt;/h2&gt;&lt;p&gt;Mini-programs are applications that can be used without needing to be downloaded or installed, realizing the dream of app &lt;strong&gt;è§¦æ‰‹å¯åŠ&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Users can open the application by scanning a QR code or searching, which also embodies the &lt;strong&gt;ç”¨å®Œå³èµ°&lt;/strong&gt; concept&lt;/p&gt;
&lt;p&gt;unobtrusive&lt;/p&gt;
&lt;h2 id=&#34;the-difference-between-mini-programs-and-mobile-apps&#34;&gt;The difference between mini-programs and mobile apps
&lt;/h2&gt;&lt;p&gt;No installation, no memory usage, easy sharing: Scan code, mini-program card, search&lt;/p&gt;
&lt;h2 id=&#34;what-can-mini-programs-do&#34;&gt;What can mini programs do?
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Content Tools: Zhihu Trending, Weibo Hot Topics, Mobike, Jinri Toutiao, Tencent Map, Tencent Translate&lt;/li&gt;
&lt;li&gt;Retail: Pinduoduo, JD Shopping, Mogujie, Meili Fresh, Xiaomi Mall, Watson&amp;rsquo;s&lt;/li&gt;
&lt;li&gt;Games: Jump, Happy Landlord, Happy Mahjong, Douyu Live Streaming, YY Live Streaming&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;The course content is from 2018, and some of the applications mentioned have since closed down&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;development-preparation&#34;&gt;Development preparation
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Register for a mini-program account: Fill in the information as required, then click the activation link in your email&lt;/li&gt;
&lt;li&gt;Information Registration&lt;/li&gt;
&lt;li&gt;Log in to the Mini Program Management Console&lt;/li&gt;
&lt;li&gt;Complete mini-program information&lt;/li&gt;
&lt;li&gt;Binding Developer: Individual developers â€“ the WeChat account used for login is the administrator account, no additional binding is required&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Email addresses have limitations, so a new one is needed. However, &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; email allows for aliases, and WeChat&amp;rsquo;s backend doesnâ€™t verify them. I tried it out; the mini-program name was tricky, but anything involving trademarks easily fails review.&lt;/p&gt;
&lt;p&gt;Service categories can be selected or customized, with up to five categories per mini-program&lt;/p&gt;
&lt;p&gt;You can view information about the mini-program and enable message push within settings. Enabling message push allows you to use message templates.&lt;/p&gt;
&lt;h2 id=&#34;developer-tools-a-personal-account&#34;&gt;Developer Tools (A Personal Account)
&lt;/h2&gt;&lt;p&gt;Normal download and installation, no special notes. Briefly understand, enter directly in visitor mode. To enable phone debugging (viewing the development version of the mini-program), log in to the mini-program developer account and then click settings, switching to the specified mini-program within project details.&lt;/p&gt;
&lt;h2 id=&#34;code-structure&#34;&gt;Code structure
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;JS: Interaction logic&lt;/li&gt;
&lt;li&gt;JSON: Data Configuration&lt;/li&gt;
&lt;li&gt;UI elements&lt;/li&gt;
&lt;li&gt;Interface styles&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Office relocation, servers are inaccessible</title>
        <link>https://ttf248.life/en/p/office-migration-server-unavailable/</link>
        <pubDate>Sat, 11 Mar 2023 01:42:05 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/office-migration-server-unavailable/</guid>
        <description>&lt;p&gt;Office relocation notice: Moving from the second floor to the fifteenth floor, a routine desk move&lt;/p&gt;
&lt;h2 id=&#34;design-sense&#34;&gt;Design sense
&lt;/h2&gt;&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;h2 id=&#34;migration&#34;&gt;Migration
&lt;/h2&gt;&lt;p&gt;Packing up and moving on, setting up my new workstation â€“ adjusting cables and finding a comfortable posture before starting work&lt;/p&gt;
&lt;p&gt;Oh no! The internet connection is up, but I can&amp;rsquo;t access the usual servers in our group. Switching to Wi-Fi works fine.&lt;/p&gt;
&lt;p&gt;Initially, I thought it was a server network segment issue. The new workstation&amp;rsquo;s wired network wasnâ€™t in the firewall configuration, so I figured an IT colleague could adjust it. However, this network segment hosts multiple servers, and accessing others worked fine, which raised my suspicions. Professional matters should be handled by professionals; eventually, the operations team identified the problem: the server deployed &lt;code&gt;docker&lt;/code&gt;ï¼ŒæœåŠ¡çš„é»˜è®¤ç½‘ç»œ__INLINE_CODE_1__å’ŒåŠå…¬å®¤æœ‰çº¿ç½‘ç»œé…ç½®çš„ç½‘æ®µå†²çªäº†ï¼Œå¯¼è‡´å‘è¿‡å»çš„æ•°æ®åŒ…ï¼Œéƒ½æ”¶ä¸åˆ°åº”ç­”ï¼Œè¢«è·¯ç”±ç»™äº†__INLINE_CODE_2__ services.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s not unusual for addresses starting with &lt;strong&gt;INLINE_CODE_0__æœåŠ¡ï¼Œä¹Ÿå°±è¿™å°ï¼Œæˆ‘æ¯”è¾ƒå¸¸ç”¨ï¼Œå¶å°”ç”¨å®¹å™¨éƒ¨ç½²ä¸€äº›æµ‹è¯•æœåŠ¡ï¼Œæ²¡æƒ³åˆ°è¿˜èƒ½ç¢°åˆ°è¿™ä¸ªåœºæ™¯ã€‚åæ¥ç»†æƒ³æƒ³ï¼Œç”±äºæ•´ä¸ªé›†å›¢éƒ½åœ¨ä¸€ä¸ªåŠå…¬å¤§æ¥¼é‡Œé¢ï¼ŒITéƒ¨é—¨çš„åŒäº‹åˆ’åˆ†ç½‘æ®µï¼Œç”¨åˆ°äº†__INLINE_CODE_1&lt;/strong&gt; to not be deployed on other servers&lt;/p&gt;
&lt;h2 id=&#34;docker0&#34;&gt;docker0
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# vim /etc/docker/daemon.json
{
    &amp;quot;bip&amp;quot;:&amp;quot;172.200.0.1/24&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Restart the service, switch to a new network, and the server will return to normal access&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Embedded Systems: Introduction 1 - Professional Terminology</title>
        <link>https://ttf248.life/en/p/embedded-introduction-professional-terms/</link>
        <pubDate>Tue, 07 Mar 2023 13:42:36 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/embedded-introduction-professional-terms/</guid>
        <description>&lt;p&gt;Mentioning embedded systems, I still think of the 51 microcontroller and Freescale from my school lab days&lt;/p&gt;
&lt;p&gt;The LPA3399Pro is a visual host system developed on the Rockchip RK3399Pro platform, designed for portable computing in scenarios requiring extensive vision processing. It features an integrated NPU unit with 3.0 TOPS of computing power and supports various algorithm models.&lt;/p&gt;
&lt;p&gt;The RV1109 is a SoC from Realtek Semiconductor&amp;rsquo;s AI-driven machine vision branch, featuring an integrated NPU. It offers 1 TOPS of computing power.&lt;/p&gt;
&lt;h2 id=&#34;system-on-chip&#34;&gt;System on Chip
&lt;/h2&gt;&lt;p&gt;SoC is an abbreviation for &amp;ldquo;System on a Chip,&amp;rdquo; referring to a technology that integrates multiple electronic systems onto a single chip. This reduces the size and weight of electronic products while improving performance and reducing power consumption.&lt;/p&gt;
&lt;p&gt;SoCs (System on a Chip) and CPUs (Central Processing Units) are both important components of computer systems, but they have some differences&lt;/p&gt;
&lt;p&gt;The CPU is the core processor in a computer system, responsible for executing program instructions. It typically consists of basic components such as an arithmetic unit, control unit, and registers.&lt;/p&gt;
&lt;p&gt;System-on-a-Chip (SoC) integrates multiple electronic systems onto a single chip, including components like CPU, memory, graphics processors, and input/output interfaces. This reduces the size and weight of electronic products while improving performance and reducing power consumption.&lt;/p&gt;
&lt;p&gt;In short, the CPU is a component of the SoC, while the SoC is a more complex and highly integrated electronic system&lt;/p&gt;
&lt;h2 id=&#34;microcontroller-unit&#34;&gt;Microcontroller Unit
&lt;/h2&gt;&lt;p&gt;Both SoCs (Systems on a Chip) and MCUs (Microcontrollers) integrate multiple electronic systems onto a single chip, but they differ in several ways&lt;/p&gt;
&lt;p&gt;An MCU (Microcontroller Unit) typically includes basic components such as a CPU, memory, and input/output interfaces. It is commonly used to control other electronic devices like home appliances and automotive electronics systems.&lt;/p&gt;
&lt;p&gt;System-on-Chip (SoC) integrates more electronic systems onto a single chip, including basic MCU components and additional elements like graphics processors and wireless communication modules. This significantly reduces the size and weight of electronic products while improving performance and reducing power consumption.&lt;/p&gt;
&lt;p&gt;In short, an MCU is a simple microcontroller, while a SoC is a more complex, highly integrated electronic system&lt;/p&gt;</description>
        </item>
        <item>
        <title>AI-assisted programming, an evolution of productivity</title>
        <link>https://ttf248.life/en/p/ai-assisted-programming-productivity-evolution/</link>
        <pubDate>Tue, 28 Feb 2023 17:05:17 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/ai-assisted-programming-productivity-evolution/</guid>
        <description>&lt;p&gt;&lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; å‘å¸ƒä¹Ÿä¸åˆ°ä¸¤å¹´æ—¶é—´ï¼Œ&lt;strong&gt;INLINE_CODE_1&lt;/strong&gt; was released, and I don&amp;rsquo;t fully understand the underlying principles, but Iâ€™ve been using them for a while. The two tools offer completely different levels of assistance, but both significantly improve productivity.&lt;/p&gt;
&lt;p&gt;For overly complex matters, the effect can only be about nine-tenths successful&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;github copilot
&lt;/h2&gt;&lt;p&gt;When it was released, the website description &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; didn&amp;rsquo;t seem very smart, and after trying it out, it wasn&amp;rsquo;t very usable, so I gave up&lt;/p&gt;
&lt;p&gt;Before 2022, out of boredom, I switched to the new version for a try. The results are already pretty good, though the speed is slow in China, likely due to network issues. Code generated based on comments like &lt;code&gt;Python&lt;/code&gt; is quite decent and much faster than researching and writing it myself.&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;Still designing products from a programmer&amp;rsquo;s, or development, perspective. You need to understand how to code and gradually guide AI-assisted programming through comments.&lt;/p&gt;
&lt;p&gt;Let non-experts quickly get started. The conversational, interactive design allows you to ask questions, describe your needs, and continue asking if anything is unclear.&lt;/p&gt;
&lt;p&gt;For example, you understand the concept of tokenization but don&amp;rsquo;t know how to code it, and want to calculate string similarity&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Python åˆ†è¯è®¡ç®— ç¶­å¤©é‹é€š LOGORY å’Œ åˆè‚¥ç¶­å¤©é‹é€šä¿¡æ¯ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸ ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦ï¼›
æ¯”è¾ƒå‰ï¼Œç»Ÿä¸€å¤„ç†å­—ç¬¦ä¸²ï¼Œè‹±æ–‡è½¬æ¢ä¸ºå°å†™ï¼›
ç¬¬äºŒä¸ªå­—ç¬¦ä¸­å¦‚æœèƒ½æ‰¾åˆ°ç¬¬ä¸€ä¸ªå­—ç¬¦çš„é¦–å­—ç¬¦ï¼Œå°†ç¬¬äºŒä¸ªå­—ç¬¦ä¸²æˆªä½ï¼Œæˆªä½çš„é•¿åº¦ä¸ºç¬¬ä¸€ä¸ªå­—ç¬¦ä¸²çš„é•¿åº¦
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hello, this is Bing. ğŸ˜Š&lt;/p&gt;
&lt;p&gt;According to online information, Python tokenization can be implemented using the jieba library. Jieba supports three modes: precise mode, full mode, and search engine mode. You can choose the appropriate mode based on your needs.&lt;/p&gt;
&lt;p&gt;To compare the similarity of two strings, you first need to tokenize them and then calculate indicators such as word vectors or edit distance. You can use libraries like NumPy or SciPy for mathematical operations.&lt;/p&gt;
&lt;p&gt;To uniformly handle strings, converting them to lowercase can be achieved using Python&amp;rsquo;s built-in &lt;code&gt;lower()&lt;/code&gt; function&lt;/p&gt;
&lt;p&gt;To extract the second string, you can use Python&amp;rsquo;s slicing operator []&lt;/p&gt;
&lt;p&gt;Here is a possible code example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import jieba
import numpy as np
from scipy.spatial.distance import cosine

# å®šä¹‰ä¸¤ä¸ªå­—ç¬¦ä¸²
str1 = &amp;quot;ç¶­å¤©é‹é€š LOGORY&amp;quot;
str2 = &amp;quot;åˆè‚¥ç¶­å¤©é‹é€šä¿¡æ¯ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸&amp;quot;

# ç»Ÿä¸€å¤„ç†å­—ç¬¦ä¸²ï¼Œè‹±æ–‡è½¬æ¢ä¸ºå°å†™
str1 = str1.lower()
str2 = str2.lower()

# æ‰¾åˆ°ç¬¬äºŒä¸ªå­—ç¬¦ä¸²ä¸­ç¬¬ä¸€ä¸ªå­—ç¬¦çš„ä½ç½®
index = str2.find(str1[0])

# å¦‚æœæ‰¾åˆ°äº†ï¼Œæˆªå–ç¬¬äºŒä¸ªå­—ç¬¦ä¸²
if index != -1:
    str2 = str2[index:index+len(str1)]

# ä½¿ç”¨ jieba åº“è¿›è¡Œåˆ†è¯
words1 = list(jieba.cut(str1))
words2 = list(jieba.cut(str2))

# è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„è¯å‘é‡ï¼ˆä»¥è¯é¢‘ä½œä¸ºæƒé‡ï¼‰
vector1 = np.zeros(len(words1))
vector2 = np.zeros(len(words1))

for i, word in enumerate(words1):
    vector1[i] += 1 # ç»Ÿè®¡ç¬¬ä¸€ä¸ªå­—ç¬¦ä¸²ä¸­æ¯ä¸ªè¯å‡ºç°çš„æ¬¡æ•°
    if word in words2:
        vector2[i] += 1 # ç»Ÿè®¡ç¬¬äºŒä¸ªå­—ç¬¦ä¸²ä¸­æ¯ä¸ªè¯å‡ºç°çš„æ¬¡æ•°

# è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦ï¼ˆä»¥ä½™å¼¦è·ç¦»ä½œä¸ºæŒ‡æ ‡ï¼‰
similarity = 1 - cosine(vector1, vector2)

print(&amp;quot;ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦æ˜¯ï¼š&amp;quot;, similarity)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/p&gt;
&lt;h3 id=&#34;chestnut&#34;&gt;Chestnut
&lt;/h3&gt;&lt;p&gt;Find all records from the product code table where the product codes are within the range of 80000-89999&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;ä½ å¥½ï¼Œè¿™æ˜¯ Bingã€‚ğŸ˜Š

æ ¹æ®æœç´¢ç»“æœ12ï¼Œä½ å¯ä»¥ä½¿ç”¨ SQL BETWEEN è¿ç®—ç¬¦æ¥é€‰æ‹©ç»™å®šåŒºé—´å†…çš„å€¼ã€‚BETWEEN è¿ç®—ç¬¦åŒ…å«äº†å¼€å§‹å’Œç»“æŸçš„å€¼ã€‚

ä½ éœ€è¦å…ˆæŒ‡å®šè¦æŸ¥è¯¢çš„è¡¨åå’Œåˆ—åï¼Œç„¶ååœ¨ WHERE å­å¥ä¸­ä½¿ç”¨ BETWEEN è¿ç®—ç¬¦å’ŒåŒºé—´å€¼ã€‚

ä¾‹å¦‚ï¼Œå¦‚æœä½ è¦æŸ¥è¯¢äº§å“ä»£ç è¡¨ä¸­ï¼Œäº§å“ä»£ç åœ¨ 80000 åˆ° 89999 ä¹‹é—´çš„è®°å½•ï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹è¯­å¥ï¼š

SELECT * FROM product_code
WHERE code BETWEEN 80000 AND 89999;
è¿™é‡Œï¼Œ* è¡¨ç¤ºé€‰æ‹©æ‰€æœ‰åˆ—3ã€‚å¦‚æœä½ åªæƒ³é€‰æ‹©ç‰¹å®šçš„åˆ—ï¼Œæ¯”å¦‚äº§å“åç§°å’Œä»·æ ¼ï¼Œä½ å¯ä»¥ç”¨é€—å·åˆ†éš”å®ƒä»¬ï¼Œå¦‚ä¸‹ï¼š

SELECT name, price FROM product_code
WHERE code BETWEEN 80000 AND 89999;
å¸Œæœ›è¿™èƒ½å¸®åŠ©åˆ°ä½ ã€‚
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Keep asking, deny it: The product code is a string, your code is wrong&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ³¨æ„åˆ°äº§å“ä»£ç æ˜¯å­—ç¬¦ä¸²ã€‚å¦‚æœæ˜¯è¿™æ ·çš„è¯ï¼Œä½ éœ€è¦åœ¨åŒºé—´å€¼ä¸¤è¾¹åŠ ä¸Šå•å¼•å·ï¼Œå¦‚ä¸‹ï¼š

SELECT * FROM product_code
WHERE code BETWEEN &#39;80000&#39; AND &#39;89999&#39;;
è¯·åŸè°…æˆ‘çš„é”™è¯¯ã€‚ğŸ™
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Congratulations, it will be wrong&lt;/p&gt;</description>
        </item>
        <item>
        <title>A Summary of Several Less Commonly Used Git Commands</title>
        <link>https://ttf248.life/en/p/git-less-common-commands-summary/</link>
        <pubDate>Fri, 17 Feb 2023 10:08:57 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/git-less-common-commands-summary/</guid>
        <description>&lt;p&gt;Infrequently used, but very useful commands&lt;/p&gt;
&lt;h3 id=&#34;reinstalling-the-system-changes-ownership-information-for-all-folders&#34;&gt;Reinstalling the system changes ownership information for all folders
&lt;/h3&gt;&lt;p&gt;The new version added security checks, prompting a warning that prevents further operation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git config --global --add safe.directory
git config --global --add safe.directory &amp;quot;*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;new-computer-saves-account-password-information&#34;&gt;New computer saves account password information
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git config --global credential.helper store
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the saved information needs updating, clear the old records first&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git config --system --unset credential.helper
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Compiler, callback function, performance testing</title>
        <link>https://ttf248.life/en/p/compiler-callback-function-performance-testing/</link>
        <pubDate>Wed, 15 Feb 2023 13:59:25 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/compiler-callback-function-performance-testing/</guid>
        <description>&lt;p&gt;Last year, we designed a module responsible for handling event encapsulation and providing a class interface. During service initialization, the caller implements the corresponding class and passes the object pointer to the module.
Using function object callbacks offers greater flexibility compared to defining interfaces with pure virtual functions
The question arose: which grammar is faster in terms of performance? Without understanding compiler principles, let&amp;rsquo;s just try some code&lt;/p&gt;
&lt;h2 id=&#34;preface&#34;&gt;Preface
&lt;/h2&gt;&lt;p&gt;An online URL that allows you to select different compilers, compilation parameters, and run code on a specified platform, or view the corresponding assembly code&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sometimes, doing technical validations with small code snippets on webpages is very convenient&lt;/li&gt;
&lt;li&gt;Using different colors to distinguish code associated with different assemblies makes debugging easier than using a local debugger&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;The standards committee defines the grammar rules; how to implement them at the compilation level depends on each compiler. Microsoft&amp;rsquo;s compilers are quite impressive. Syntax sugar isn&amp;rsquo;t all-powerful, and with fewer callback interfaces, using &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; is more convenient and eliminates the need for empty callback function interfaces. When there are many types of callback interfaces, traditional virtual functions are better suited for unifying business interface definitions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The platforms have similar performance with little difference&lt;/li&gt;
&lt;li&gt;Comparison, increased by 1.35 ns per cycle&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In typical business system development, this level of performance loss is negligible. Signals and slots, logging, monitoring, business logic 1, and business logic 2 are completely decoupled.&lt;/p&gt;
&lt;h2 id=&#34;code&#34;&gt;Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Counter: 1000000
Time: 3966us
Counter: 1000000
Time: 5316us
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;memory&amp;gt;
#include &amp;lt;functional&amp;gt;
#include &amp;lt;atomic&amp;gt;
#include &amp;lt;string&amp;gt;

std::atomic_int64_t counter = 0;

// å®šä¹‰å›è°ƒæ¥å£
class UserInterface
{
public:
    virtual void name() = 0;
    virtual void full_name() = 0;
};

class User : public UserInterface
{
public:
    void name() {}
    void full_name() { counter++; }
};

void to_string(UserInterface* user)
{
    user-&amp;gt;name();
    user-&amp;gt;full_name();
}

using name_handler = std::function&amp;lt;void()&amp;gt;;
using full_name_handler = std::function&amp;lt;void()&amp;gt;;

class Test
{
    name_handler name_;
    full_name_handler full_name_;

public:
    void set_name_handler(name_handler name)
    {
        name_ = name;
    }

    void set_full_name_handler(full_name_handler full_name)
    {
        full_name_ = full_name;
    }

    void to_string()
    {
        name_();
        full_name_();
    }
};

int main()
{
    User user;

    auto start = std::chrono::high_resolution_clock::now();

    for (int i = 0; i &amp;lt; 1000000; i++)
    {
        to_string(&amp;amp;user);
    }

    auto end = std::chrono::high_resolution_clock::now();
    std::cout &amp;lt;&amp;lt; &amp;quot;Counter: &amp;quot; &amp;lt;&amp;lt; counter &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;Time: &amp;quot; &amp;lt;&amp;lt; std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(end - start).count() &amp;lt;&amp;lt; &amp;quot;us&amp;quot; &amp;lt;&amp;lt; std::endl;

    counter = 0;
    auto name = []() {};
    auto full_name = []() { counter++; };

    Test test;
    test.set_name_handler(name);
    test.set_full_name_handler(full_name);

    start = std::chrono::high_resolution_clock::now();

    for (int i = 0; i &amp;lt; 1000000; i++)
    {
        test.to_string();
    }

    end = std::chrono::high_resolution_clock::now();
    std::cout &amp;lt;&amp;lt; &amp;quot;Counter: &amp;quot; &amp;lt;&amp;lt; counter &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;Time: &amp;quot; &amp;lt;&amp;lt; std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(end - start).count() &amp;lt;&amp;lt; &amp;quot;us&amp;quot; &amp;lt;&amp;lt; std::endl;

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;afterword&#34;&gt;Afterword
&lt;/h2&gt;&lt;p&gt;While searching for information, I came across similar code snippets&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;memory&amp;gt;
#include &amp;lt;functional&amp;gt;

using namespace std;
using namespace std::chrono;

class Base
{
public:
	Base(){}
	virtual ~Base(){}
	virtual int func(int i) = 0;
};

class Derived : public Base
{
public:
	Derived(int base = 10) : base{base}
	{

	}
	~Derived(){}

	virtual int func(int i)
	{
		return i*base;
	}
private:
	int base;
};

struct Func
{
	int base;
	int operator()(int i)
	{
		return i*base;
	}
	Func(int base) : base {base}
	{

	}
};
const int base = 10;
int calculate(int i)
{
	return base*i;
}

int main()
{
	const int num = 10000;
	Base *p = new Derived{10};
	int total = 0;
	auto start = high_resolution_clock::now();
	for (int i = 0; i &amp;lt; num; ++i)
	{
		total += p-&amp;gt;func(i);
	}
	auto end = high_resolution_clock::now();
	std::cout&amp;lt;&amp;lt;&amp;quot;result: &amp;quot;&amp;lt;&amp;lt;total&amp;lt;&amp;lt;&amp;quot;\nvirtual call elapsed: \t&amp;quot;&amp;lt;&amp;lt;duration_cast&amp;lt;nanoseconds&amp;gt;(end-start).count()&amp;lt;&amp;lt;&amp;quot; nanoseconds.\n&amp;quot;&amp;lt;&amp;lt;std::endl;

	total = 0;
	start = high_resolution_clock::now();
	for (int i = 0; i &amp;lt; num; ++i)
	{
		total += calculate(i);
	}
	end = high_resolution_clock::now();
	std::cout&amp;lt;&amp;lt;&amp;quot;result: &amp;quot;&amp;lt;&amp;lt;total&amp;lt;&amp;lt;&amp;quot;\ndirect function call elapsed: \t&amp;quot;&amp;lt;&amp;lt;duration_cast&amp;lt;nanoseconds&amp;gt;(end-start).count()&amp;lt;&amp;lt;&amp;quot; nanoseconds.\n&amp;quot;&amp;lt;&amp;lt;std::endl;

	Func functor{10};
	total = 0;
	start = high_resolution_clock::now();
	for (int i = 0; i &amp;lt; num; ++i)
	{
		total += functor(i);
	}
	end = high_resolution_clock::now();
	std::cout&amp;lt;&amp;lt;&amp;quot;result: &amp;quot;&amp;lt;&amp;lt;total&amp;lt;&amp;lt;&amp;quot;\nfunctor call elapsed: \t&amp;quot;&amp;lt;&amp;lt;duration_cast&amp;lt;nanoseconds&amp;gt;(end-start).count()&amp;lt;&amp;lt;&amp;quot; nanoseconds.\n&amp;quot;&amp;lt;&amp;lt;std::endl;
	int base = 10;
	function&amp;lt;int(int)&amp;gt; lambda = [base](int i)
	{
		return i*base;
	};
	total = 0;
	start = high_resolution_clock::now();
	for (int i = 0; i &amp;lt; num; ++i)
	{
		total += lambda(i);
	}
	end = high_resolution_clock::now();
	std::cout&amp;lt;&amp;lt;&amp;quot;result: &amp;quot;&amp;lt;&amp;lt;total&amp;lt;&amp;lt;&amp;quot;\nlambda call elapsed: \t&amp;quot;&amp;lt;&amp;lt;duration_cast&amp;lt;nanoseconds&amp;gt;(end-start).count()&amp;lt;&amp;lt;&amp;quot; nanoseconds.\n&amp;quot;&amp;lt;&amp;lt;std::endl;
	return 0;
}

/*
test on mac mini i7 2.7GHz
clang++ -std=c++11 chronotest.cpp -O0
output:
result: 499950000
virtual call elapsed: 	43171 nanoseconds.

result: 499950000
direct function call elapsed: 	31379 nanoseconds.

result: 499950000
functor call elapsed: 	41497 nanoseconds.

result: 499950000
lambda call elapsed: 	207416 nanoseconds.
===================================================
clang++ -std=c++11 chronotest.cpp -O1
output:
result: 499950000
virtual call elapsed: 	26144 nanoseconds.

result: 499950000
direct function call elapsed: 	22384 nanoseconds.

result: 499950000
functor call elapsed: 	33477 nanoseconds.

result: 499950000
lambda call elapsed: 	55799 nanoseconds.
===================================================
clang++ -std=c++11 chronotest.cpp -O2
result: 499950000
virtual call elapsed: 	22284 nanoseconds.

result: 499950000
direct function call elapsed: 	36 nanoseconds.

result: 499950000
functor call elapsed: 	30 nanoseconds.

result: 499950000
lambda call elapsed: 	28292 nanoseconds.

===================================================
clang++ -std=c++11 chronotest.cpp -O3
result: 499950000
virtual call elapsed: 	18975 nanoseconds.

result: 499950000
direct function call elapsed: 	29 nanoseconds.

result: 499950000
functor call elapsed: 	30 nanoseconds.

result: 499950000
lambda call elapsed: 	22542 nanoseconds.
===================================================
clang++ -std=c++11 chronotest.cpp -O4

result: 499950000
virtual call elapsed: 	22141 nanoseconds.

result: 499950000
direct function call elapsed: 	30 nanoseconds.

result: 499950000
functor call elapsed: 	30 nanoseconds.

result: 499950000
lambda call elapsed: 	22584 nanoseconds.
*/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are two new modes: ordinary functions and emulated functions. There&amp;rsquo;s a significant performance differenceâ€”on the order of magnitudeâ€”between using interface callbacks and direct calls. Emulated function performance is close to that of regular functions, sometimes even better. This area (compiler principles) is a knowledge gap for me; my guess is that itâ€™s due to variables and functions being located adjacent in memory, which benefits &lt;strong&gt;INLINE&lt;/strong&gt; processing.&lt;/p&gt;
&lt;p&gt;Attached is the execution result&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;result: 499950000
virtual call elapsed: 6143 nanoseconds.

result: 499950000
direct function call elapsed: 30 nanoseconds.

result: 499950000
functor call elapsed: 31 nanoseconds.

result: 499950000
lambda call elapsed: 15134 nanoseconds.
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Host order, network order, observe directly through the debugger</title>
        <link>https://ttf248.life/en/p/host-order-network-order-debugger-observation/</link>
        <pubDate>Tue, 10 Jan 2023 14:18:12 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/host-order-network-order-debugger-observation/</guid>
        <description>&lt;p&gt;In the history of computer development, there has been no unified standard for data storage&lt;/p&gt;
&lt;p&gt;There are two common rules for byte ordering. For example, little-endian refers to arranging the lower digits of a multi-digit number at smaller addresses and the higher digits at larger addresses; conversely, big-endian is when this arrangement is reversed. Byte order is a factor that must be considered in network applications because different machine types may use different standards, so they are all converted according to the network standard.&lt;/p&gt;
&lt;p&gt;Big-endian byte order aligns better with the left-to-right reading habit&lt;/p&gt;
&lt;h2 id=&#34;please-provide-the-chinese-text-you-want-me-to-translate-i-am-ready-when-you-are-just-paste-the-text-here&#34;&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Processors such as x86, MOS Technology 6502, Z80, VAX, and PDP-11 are little-endian&lt;/li&gt;
&lt;li&gt;Processors such as Motorola 6800, Motorola 68000, and PowerPC 970 use big-endian order&lt;/li&gt;
&lt;li&gt;The byte order for ARM, PowerPC (excluding PowerPC 970), DEC Alpha, SPARC V9, MIPS, PA-RISC, and IA64 is configurable&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;network-preface&#34;&gt;Network Preface
&lt;/h2&gt;&lt;p&gt;Network transmission generally uses big-endian order, also known as network byte order or network order. Big-endian is defined as the network byte order in the IP protocol.
Socket definitions specify a set of conversion functions for transforming 16- and 32-bit integers between network byte order and host byte order&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;arpa/inet.h&amp;gt;

uint32_t htonl(uint32_t hostlong); //æŠŠuint32_tç±»å‹ä»ä¸»æœºåºè½¬æ¢åˆ°ç½‘ç»œåº
uint16_t htons(uint16_t hostshort); //æŠŠuint16_tç±»å‹ä»ä¸»æœºåºè½¬æ¢åˆ°ç½‘ç»œåº
uint32_t ntohl(uint32_t netlong); //æŠŠuint32_tç±»å‹ä»ç½‘ç»œåºè½¬æ¢åˆ°ä¸»æœºåº
uint16_t ntohs(uint16_t netshort); //æŠŠuint16_tç±»å‹ä»ç½‘ç»œåºè½¬æ¢åˆ°ä¸»æœºåº
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If &lt;strong&gt;INLIN_ITALIC_1&lt;/strong&gt;__ is chosen as the network library, the built-in namespace contains cross-platform adapted function names&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;boost::asio::detail::socket_ops::network_to_host_long&lt;/li&gt;
&lt;li&gt;boost::asio::detail::socket_ops::network_to_host_short&lt;/li&gt;
&lt;li&gt;boost::asio::detail::socket_ops::host_to_network_long&lt;/li&gt;
&lt;li&gt;boost::asio::detail::socket_ops::host_to_network_short&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;visual-studio-debugger&#34;&gt;Visual Studio debugger
&lt;/h2&gt;&lt;p&gt;In debug mode, select the Debug menu, then Window, and check Memory Window&lt;/p&gt;
&lt;p&gt;In &lt;strong&gt;INLIN_ITALIC_1&lt;/strong&gt;__, you can view data in memory directly within the debugger, as shown in the figure below&lt;/p&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;h3 id=&#34;how-to-check-memory&#34;&gt;How to check memory
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Prints the variable name and jumps to its address&lt;/li&gt;
&lt;li&gt;If the variable is already a pointer, select it by double-clicking, drag it to the memory window, and display the contents at that address&lt;/li&gt;
&lt;li&gt;If the variable is not a pointer, add it to the calculation window, obtain its address, then manually copy it to the memory window&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;for-example&#34;&gt;For example
&lt;/h3&gt;&lt;p&gt;Received data, stored in &lt;strong&gt;INLINE_CODE_0__å¯¹è±¡ä¸­ï¼Œå°†ç½‘ç»œåºè½¬æˆä¸»æœºåºï¼Œå¾—åˆ°__INLINE_CODE_1&lt;/strong&gt; equal to 30, and the server allocates four bytes for transmitting this data&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;bool NetworkMessage::decode_header()
{
    // ç½‘ç»œåºè½¬æˆä¸»æœºåº
    body_length_ = boost::asio::detail::socket_ops::network_to_host_long(*(int *)buffer_.data());
    return auto_reserve(body_length_);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;Observe the content of &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; in the memory window&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/host-order-network-order-debugger-observation/buffer_.png&#34;
	width=&#34;603&#34;
	height=&#34;318&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;buffer_&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;189&#34;
		data-flex-basis=&#34;455px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Observe the content of &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; in the memory window&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/host-order-network-order-debugger-observation/body_length_.png&#34;
	width=&#34;581&#34;
	height=&#34;333&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;body_length_&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;174&#34;
		data-flex-basis=&#34;418px&#34;
	
&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>C11: sleep for vs yield</title>
        <link>https://ttf248.life/en/p/c11-sleep-for-vs-yield/</link>
        <pubDate>Tue, 20 Sep 2022 20:54:51 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/c11-sleep-for-vs-yield/</guid>
        <description>&lt;p&gt;It was the first time I saw this, and I hadn&amp;rsquo;t noticed it before&lt;/p&gt;
&lt;p&gt;Without checking the manual, my first thought was whether it&amp;rsquo;s related to asynchronicity. The term __INLINE_CODE_0__appears in the Boost library&amp;rsquo;s coroutine implementation, but it certainly isn&amp;rsquo;t related to coroutines here; the control logic is likely related to ordinary threads.&lt;/p&gt;
&lt;h2 id=&#34;document&#34;&gt;Document
&lt;/h2&gt;&lt;h3 id=&#34;yield&#34;&gt;yield
&lt;/h3&gt;&lt;p&gt;The accuracy of this function depends on the implementation, particularly the OS scheduler mechanism and system state. For example, a first-in, first-out real-time scheduler (such as Linux&amp;rsquo;s SCHED_FIFO) will suspend the current thread and place it at the tail of the queue of threads with the same priority (and yield has no effect if there are no other threads at that priority).&lt;/p&gt;
&lt;h3 id=&#34;sleep_for&#34;&gt;sleep_for
&lt;/h3&gt;&lt;p&gt;Blocks the current thread&amp;rsquo;s execution for at least the specified sleep_duration
This function may block for longer than sleep_duration due to scheduling or resource contention
The standard library recommends measuring duration using a stable clock. If implemented with system time, wait times may also be sensitive to clock adjustments.&lt;/p&gt;
&lt;h3 id=&#34;analysis&#34;&gt;Analysis
&lt;/h3&gt;&lt;p&gt;Both functions release the current thread, and their effects depend on the platform. Still a bit unclear here; let&amp;rsquo;s run the code to see the execution results.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ThinkPad laptop (Visual Studio Community 2022), Tencent Cloud S2 standard server (gcc8.5)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Runtime Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First/Î¼s&lt;/th&gt;
&lt;th&gt;Second/Î¼s&lt;/th&gt;
&lt;th&gt;Third/Î¼s&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Windows&lt;/td&gt;
&lt;td&gt;sleep_for&lt;/td&gt;
&lt;td&gt;9872&lt;/td&gt;
&lt;td&gt;1884&lt;/td&gt;
&lt;td&gt;11302&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Windows&lt;/td&gt;
&lt;td&gt;yield&lt;/td&gt;
&lt;td&gt;119&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Linux&lt;/td&gt;
&lt;td&gt;sleep_for&lt;/td&gt;
&lt;td&gt;171&lt;/td&gt;
&lt;td&gt;168&lt;/td&gt;
&lt;td&gt;167&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Linux&lt;/td&gt;
&lt;td&gt;yield&lt;/td&gt;
&lt;td&gt;101&lt;/td&gt;
&lt;td&gt;102&lt;/td&gt;
&lt;td&gt;101&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Given the operating system implementation, &lt;strong&gt;INLINE_CODE_0__ç¨³å®šæ€§å·®å¼‚å·¨å¤§ï¼Œå¦‚æœæƒ³è¦é«˜ç²¾åº¦çš„ä¼‘çœ ï¼Œä½¿ç”¨__INLINE_CODE_1&lt;/strong&gt; is more suitable for high-precision sleep&lt;/p&gt;
&lt;p&gt;The difference is not significant when time accuracy is improved to &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;thread&amp;gt;
 
// å»ºè®®å…¶ä»–çº¿ç¨‹è¿è¡Œä¸€å°æ®µæ—¶é—´çš„â€œå¿™ç¡çœ â€
void little_sleep(std::chrono::microseconds us)
{
    auto start = std::chrono::high_resolution_clock::now();
    auto end = start + us;
    do {
        std::this_thread::yield();
    } while (std::chrono::high_resolution_clock::now() &amp;lt; end);
}
 
int main()
{
    auto start = std::chrono::high_resolution_clock::now();
 
    little_sleep(std::chrono::microseconds(100));
    std::this_thread::sleep_for(std::chrono::microseconds(100));
 
    auto elapsed = std::chrono::high_resolution_clock::now() - start;
    std::cout &amp;lt;&amp;lt; &amp;quot;waited for &amp;quot;
              &amp;lt;&amp;lt; std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(elapsed).count()
              &amp;lt;&amp;lt; &amp;quot; microseconds\n&amp;quot;;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Resetting MySQL password on a Linux server</title>
        <link>https://ttf248.life/en/p/linux-server-reset-mysql-password/</link>
        <pubDate>Tue, 20 Sep 2022 14:27:35 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-server-reset-mysql-password/</guid>
        <description>&lt;p&gt;I have an idle Tencent Cloud server that&amp;rsquo;s expiring at year-end, and I didnâ€™t plan to renew it. I deployed a MySQL database for development purposes. When reinstalling the system, I chose a third-party image from Tencent Cloud for convenienceâ€”it already had MySQL installed. I assumed there would be a Readme file or something similar explaining the password and deployment path.&lt;/p&gt;
&lt;p&gt;It quickly reinstalled the system on Tencent Cloud, notifying me it was ready in about a minute. Logging in, the service had already started. I searched for the password but couldn&amp;rsquo;t find it and slowly began to feel defeated.&lt;/p&gt;
&lt;p&gt;Having gained access to the server with those privileges, there must be a way to reset the password. I checked the documentation and found a post on the Alibaba Cloud forum; time to keep troubleshooting.&lt;/p&gt;
&lt;h2 id=&#34;reset-password&#34;&gt;Reset password
&lt;/h2&gt;&lt;p&gt;Edit configuration file&lt;/p&gt;
&lt;p&gt;Reuse the existing user password, while enabling remote login&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;USE mysql;
UPDATE user SET authentication_string = password (&#39;pass&#39;) WHERE User = &#39;root&#39;;
grant all privileges on *.* to &#39;root&#39;@&#39;%&#39; identified by &#39;pass&#39; with grant option;
flush privileges;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Reverted the configuration file, restarted the database, all done&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://help.aliyun.com/document_detail/42520.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://help.aliyun.com/document_detail/42520.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>A Brief Discussion on Automated Testing</title>
        <link>https://ttf248.life/en/p/shallow-discussion-on-automation-testing/</link>
        <pubDate>Thu, 04 Aug 2022 11:39:18 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/shallow-discussion-on-automation-testing/</guid>
        <description>&lt;p&gt;Testing investment for financial trading systems far exceeds that of other systems, with repetitive and cumbersome testing steps yielding too little value. As projects and personnel change, uncontrollable factors are inevitably introduced; a common scenario involves modifying a field in interface A, which unexpectedly impacts the results of interface B. With each version release, risks accumulate.&lt;/p&gt;
&lt;h2 id=&#34;theoretical-knowledge&#34;&gt;Theoretical knowledge
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The ROI of an automated test case = (Manual Execution Time) * (Number of Runs) / (Development Cost + Maintenance Cost)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Focus on automating tests for frequently used, stable features â€“ this yields the greatest return&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It&amp;rsquo;s not suitable now, as it&amp;rsquo;s like fetching water from afar to quench a thirst. Automation is a long-term benefit model. The project is already live and entering a stable release cycle; this is the best time for it.&lt;/p&gt;
&lt;h2 id=&#34;framework-selection&#34;&gt;Framework Selection
&lt;/h2&gt;&lt;p&gt;Being assigned an automation testing task without relevant practical experience often leads to this: opening a search engine, looking for tools and frameworks compatible with the current system, reviewing user manuals, and starting off on what seems like a good note. If you can quickly find a suitable tool, congratulations, you&amp;rsquo;re lucky.&lt;/p&gt;
&lt;p&gt;I apologize; it&amp;rsquo;s not that the resources don&amp;rsquo;t exist, but rather that the framework itself is too complex and consumes excessive resources. What beginners need is something small and streamlined. Consulting with colleagues on the testing team suggested building a custom frameworkâ€”essentially, encapsulating existing unit testing frameworks into an automated testing framework.&lt;/p&gt;
&lt;p&gt;Refer to the design concept of this project: &lt;a class=&#34;link&#34; href=&#34;https://github.com/wintests/pytestDemo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/wintests/pytestDemo&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;why-do-we-need-frameworks&#34;&gt;Why do we need frameworks?
&lt;/h2&gt;&lt;p&gt;The service has multiple deployment environments â€“ development, testing, and pre-production â€“ with the framework&amp;rsquo;s role being to provide a layer of abstraction, separating test cases and data. It supports environment-specific configurations for case data while also allowing shared data.&lt;/p&gt;
&lt;p&gt;The underlying logic is to improve automation utilization. For more complex scenarios where data varies across different environments and has no inherent relationship, simply add a &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; tag when configuring the case data to specify the supported environment.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Why learn a new language?</title>
        <link>https://ttf248.life/en/p/why-learn-a-new-language/</link>
        <pubDate>Thu, 04 Aug 2022 11:27:30 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/why-learn-a-new-language/</guid>
        <description>&lt;p&gt;Why learn other programming languages after more than ten years of experience with [this/it]?&lt;/p&gt;
&lt;p&gt;Lack of experience in elegant module design, grammar is flexible, and learning other languages can guide the creation of more elegant designs&lt;/p&gt;
&lt;p&gt;I often find myself using these tools when writing code&lt;/p&gt;
&lt;p&gt;Whether it&amp;rsquo;s the underlying library design or the business module implementation, the design principles are consistent&lt;/p&gt;</description>
        </item>
        <item>
        <title>Character Set Compilation in Visual Studio [Translated]</title>
        <link>https://ttf248.life/en/p/visual-studio-compilation-character-set-translation/</link>
        <pubDate>Thu, 04 Aug 2022 10:51:43 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/visual-studio-compilation-character-set-translation/</guid>
        <description>&lt;p&gt;Constants contain line breaks&lt;/p&gt;
&lt;h2 id=&#34;visual-studio&#34;&gt;visual studio
&lt;/h2&gt;&lt;p&gt;Therefore, it is so&lt;/p&gt;
&lt;p&gt;The cited references provide a detailed explanation of the cause of the problem, based on principles&lt;/p&gt;
&lt;p&gt;Regarding encoding, __INLINE_CODE_0__BOLD_3&lt;code&gt;/source-charset&lt;/code&gt;BOLD_4&lt;code&gt;/execution-charset&lt;/code&gt; addresses the file&amp;rsquo;s original encoding and the encoding of bytes within the character array after compilation. These two options generally resolve encoding issues.&lt;/p&gt;
&lt;p&gt;For example, Chinese characters are displayed normally on the console&lt;/p&gt;
&lt;h2 id=&#34;cmake-settings-for-visual-studio&#34;&gt;CMake settings for Visual Studio
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cmake&#34;&gt;if( WIN32 )
    message( STATUS &amp;quot;Configuring trade on WIN32&amp;quot;)
    set( CMAKE_CXX_FLAGS &amp;quot;${CMAKE_CXX_FLAGS} /source-charset:utf-8 /execution-charset:gbk&amp;quot;)
endif()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/146543940&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://zhuanlan.zhihu.com/p/146543940&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Quickly calculate folder size on Windows platform</title>
        <link>https://ttf248.life/en/p/windows-platform-quick-folder-size-statistics/</link>
        <pubDate>Mon, 01 Aug 2022 19:54:18 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/windows-platform-quick-folder-size-statistics/</guid>
        <description>&lt;p&gt;What to do? With many disks and files, the system&amp;rsquo;s built-in File Explorer is too slow when trying to calculate folder sizes, making you want to give up&lt;/p&gt;
&lt;h2 id=&#34;everything&#34;&gt;Everything
&lt;/h2&gt;&lt;p&gt;You should also have heard of it from friends. Its search speed far surpasses the system&amp;rsquo;s built-in File Explorer. Since the system supports fast file indexing, there must be similar tools available that can establish a file index and simultaneously calculate file sizes.&lt;/p&gt;
&lt;h2 id=&#34;wiztree&#34;&gt;WizTree
&lt;/h2&gt;&lt;p&gt;Website: &lt;a class=&#34;link&#34; href=&#34;https://www.diskanalyzer.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.diskanalyzer.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Extract and run the standard installation or green version&lt;/p&gt;
&lt;p&gt;Fast speed, diverse data display types â€“ a tree diagram on the left, file types on the right, and graphical visualizations in the software&amp;rsquo;s bottom bar&lt;/p&gt;
&lt;h2 id=&#34;spacesniffer-no-longer-maintained-as-of-update-2023&#34;&gt;SpaceSniffer (no longer maintained as of update 2023)
&lt;/h2&gt;&lt;p&gt;Software website: &lt;a class=&#34;link&#34; href=&#34;http://www.uderzo.it/main_products/space_sniffer/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://www.uderzo.it/main_products/space_sniffer/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The operation is simple: select the corresponding disk, and the software will graphically display folder sizes. Larger volumes correspond to larger matrices in the image. Other operations are self-explanatory with a few clicks. It supports filtering files by input conditions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;File size filtering&lt;/li&gt;
&lt;li&gt;File date filtering&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://moe.best/software/spacesniffer.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://moe.best/software/spacesniffer.html&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>How to Copy Webpage Style Sheets (CSS): Element Inspection</title>
        <link>https://ttf248.life/en/p/how-to-copy-webpage-css-element-inspection/</link>
        <pubDate>Sun, 31 Jul 2022 23:36:48 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/how-to-copy-webpage-css-element-inspection/</guid>
        <description>&lt;p&gt;Static blog themes predominantly rely on foreign templates with minor modifications, without much consideration for typesetting Chinese content&lt;/p&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;About two weeks ago, I made some adjustments to my blog&amp;rsquo;s stylesheet. Having worked in backend service development for many years, Iâ€™m a complete novice when it comes to frontend. After fiddling with it all day, the design still wasn&amp;rsquo;t quite right. Then I had an idea â€“ inspired by technical blogs like InfoQ and Open Source China, whose layouts are excellent. Could I borrow some of their techniques? I looked at the source code for a while, trying to locate the relevant elements, but ended up completely confused.&lt;/p&gt;
&lt;p&gt;Frontend developers seeing this might be laughing&amp;hellip; don&amp;rsquo;t understand how to locate specific elements. No worries, I have plenty of time on the weekend; thinking back, I seem to have used something similar when writing crawlers before.&lt;/p&gt;
&lt;h3 id=&#34;elemental-review&#34;&gt;Elemental Review
&lt;/h3&gt;&lt;p&gt;Indeed, it&amp;rsquo;s the browser&amp;rsquo;s built-in element inspection toolâ€”copying style sheets and locating specific elements are quick tasks&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Copy element&lt;/li&gt;
&lt;li&gt;Copy outerHTML&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;li&gt;Copy JS path&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/li&gt;
&lt;li&gt;Copy XPath&lt;/li&gt;
&lt;li&gt;Copy full XPath&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Editing Large Files on Windows: EmEditor (Text Editor)</title>
        <link>https://ttf248.life/en/p/windows-platform-editing-large-files-emeditor-text-editor/</link>
        <pubDate>Sun, 31 Jul 2022 23:21:24 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/windows-platform-editing-large-files-emeditor-text-editor/</guid>
        <description>&lt;p&gt;The Shanghai National Security database incident has been buzzing around the hacker circles, though it&amp;rsquo;s unclear if itâ€™s true or not. Let&amp;rsquo;s see if we remember it in a couple of years and revisit then. Based on past experience, after updating local social engineering (SOC) databases, I saw a massive SQL file: 17.9GB. Even previewing it is problematic with standard text editors, let alone opening it. Chatting online with some users, someone mentioned EmEditor.&lt;/p&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;Website: &lt;a class=&#34;link&#34; href=&#34;https://www.emeditor.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.emeditor.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I tried it out during my weekend free time â€“ it&amp;rsquo;s quite convenient. The design supports editing large files, and with sufficient memory, the entire file loads into memory, making searching and editing fast. It also supports splitting files.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Add a code copy button for what seems like a simple thing</title>
        <link>https://ttf248.life/en/p/add-code-copy-button/</link>
        <pubDate>Fri, 25 Feb 2022 01:23:39 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/add-code-copy-button/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;After working on it for four hours, seeing that sentence made me laughâ€”how could it possibly take so long? Then I checked the time: three hours&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is the first draft of 2022. It&amp;rsquo;s not a complicated project, just as the title states (I was quite young then). I thought simply saving &lt;a class=&#34;link&#34; href=&#34;https://ouuan.github.io/post/from-hexo-to-hugo/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ä½œä¸š&lt;/a&gt; would be enough, so I put it in my favorites and waited over a month before remembering this task.&lt;/p&gt;
&lt;p&gt;Moving to &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;, I always felt there were too few plugins. The inability to copy code snippets made migrating notes from Notion a hassle, as copying code became cumbersome and significantly dampened my motivation to update my blog.&lt;/p&gt;
&lt;h2 id=&#34;prologue&#34;&gt;Prologue
&lt;/h2&gt;&lt;p&gt;Let&amp;rsquo;s carefully review the original author&amp;rsquo;s manuscript, read it through and check their introduction. Wow, Iâ€™ve stumbled upon a big shot â€“ a current undergraduate student at Tsinghua who started with computers early on. Hmm, just browsing this blog now; completely forgot what I was supposed to do. By the way, let&amp;rsquo;s also check out the author&amp;rsquo;s &lt;em&gt;__INLINE_CODE_0__BOLD_2&lt;code&gt;even&lt;/code&gt;&lt;/em&gt; theme â€“ itâ€™s much better than the current one and has more features. Let&amp;rsquo;s get it running; first merge the relevant code.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/add-code-copy-button/2022-02-25-02-08-19.png&#34;
	width=&#34;215&#34;
	height=&#34;150&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;143&#34;
		data-flex-basis=&#34;344px&#34;
	
&gt; &lt;img src=&#34;https://ttf248.life/p/add-code-copy-button/2022-02-25-02-08-40.png&#34;
	width=&#34;217&#34;
	height=&#34;167&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;129&#34;
		data-flex-basis=&#34;311px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;new-feature-view-article-history-related-submission-records&#34;&gt;New feature: View article history, related submission records
&lt;/h3&gt;&lt;p&gt;The effect is pretty good; you can experience it by reading to the end of the article&lt;/p&gt;
&lt;p&gt;I didn&amp;rsquo;t really look at the author&amp;rsquo;s repository history before starting, assuming a simple merge would fix it. Ended up merging a lot of code, with conflicts and numerous iterations. I just overwrote everything blindly, prioritizing my own code for frontend and rendering templates.&lt;/p&gt;
&lt;p&gt;Warehouse address: &lt;a class=&#34;link&#34; href=&#34;https://github.com/TianlongXiang/hugo-theme-even&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/TianlongXiang/hugo-theme-even&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A pitfall in Chinese, &lt;strong&gt;&lt;em&gt;italicized text&lt;/em&gt;&lt;/strong&gt;, leads to the failure of historical link generation; generating a complete article history also requires modifying the auto-integration script. Remember to pull all historical records from the current repository.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;name: Build Github
run: git config --global core.quotePath false &amp;amp;&amp;amp; hugo -b &amp;quot;https://www.xiangtianlong.com/&amp;quot; -d &amp;quot;github_public&amp;quot; &amp;amp;&amp;amp; ls
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;style-adjustments&#34;&gt;Style adjustments
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Adjusted the site content width. The previous design was suitable for both mobile and desktop, but in reality, no one views it on their phone; I mostly use it on my computer.&lt;/li&gt;
&lt;li&gt;The directory bar supports auto-sizing&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;I spent over half an hour looking at the code record for &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;, but still couldn&amp;rsquo;t figure out how to add the copy button&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Time passes, and after a month, I thought of it again&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Since I don&amp;rsquo;t understand this assignment, I might as well copy another one; eventually, Iâ€™ll figure it out. The search results were surprisingly __INLINE_CODE_0__å®˜æ–¹çš„è®ºå›é‡Œé¢å°±æœ‰ä¸ªå¸–å­æåˆ°äº†å¦‚ä½•å¢åŠ å¤åˆ¶æŒ‰é’®ï¼Œè·‘è¿‡å»ä¸€çœ‹ï¼Œé€»è¾‘æ¸…æ™°ã€‚æ‡µé€¼çš„äº‹æƒ…æ¥äº†ï¼Œå›åˆ°çš„ç«™ç‚¹ä¸€çœ‹__INLINE_CODE_1__revealing a difference in the code block styling and the description in the materialsâ€”this part is quite tedious, so I&amp;rsquo;m just noting it briefly.&lt;/p&gt;
&lt;p&gt;Because I barely understand front-end development, I kept the browser open &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;ï¼Œå¯¹ç€ä»£ç åˆ†æã€é ç€å³è¾¹çš„æ ·å¼å™¨ä¿¡æ¯ï¼Œæ…¢æ…¢ä¹Ÿåˆ†ææ‡‚äº†é€»è¾‘ï¼›__INLINE_CODE_1__and couldn&amp;rsquo;t understand it, so I checked the console for logs. There were many things I didn&amp;rsquo;t understand, but I calmed down and slowly sorted out and broke down the logic; eventually, I could find a solution.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Multiple nodes exist; here, this refers to a single code block. The theme generated line numbers, resulting in two copy buttons appearing.&lt;/li&gt;
&lt;li&gt;I want code highlighting, but I&amp;rsquo;m not familiar with how to set it up in this theme&lt;/li&gt;
&lt;li&gt;Settings to control code highlighting&lt;/li&gt;
&lt;li&gt;Adjusting the configuration file, it&amp;rsquo;s consistently wrong; the rendering doesn&amp;rsquo;t match expectations&lt;/li&gt;
&lt;li&gt;Finding these settings, I&amp;rsquo;ll continue reviewing materials and adjusting themâ€”letâ€™s remove line numbers first&lt;/li&gt;
&lt;li&gt;Configure custom &lt;code&gt;css&lt;/code&gt;BOLD_2&lt;code&gt;js&lt;/code&gt;scripts&lt;/li&gt;
&lt;li&gt;Since we&amp;rsquo;ve gotten things to this point, it suddenly occurred to me that I saw a nice color scheme recently â€“ letâ€™s update the button styles with a Chinese-style celadon blue&lt;/li&gt;
&lt;/ol&gt;
&lt;img class=&#34;special-img-class&#34; style=&#34;width:20%&#34; src=&#34;2022-02-25-02-01-22.png&#34; /&gt;
&lt;img class=&#34;special-img-class&#34; style=&#34;width:20%&#34; src=&#34;2022-02-25-02-01-33.png&#34; /&gt;
&lt;p&gt;It took four hours, and when I saw that sentence, I thought it was funny â€“ how could it take so long? Then I looked at the time: three hours&lt;/p&gt;
&lt;h2 id=&#34;reference-link&#34;&gt;Reference link
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://ouuan.github.io/post/from-hexo-to-hugo/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ouuan.github.io/post/from-hexo-to-hugo/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://gohugobrasil.netlify.app/content-management/syntax-highlighting/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://gohugobrasil.netlify.app/content-management/syntax-highlighting/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://gohugo.io/getting-started/configuration-markup#highlight&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://gohugo.io/getting-started/configuration-markup#highlight&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.dannyguo.com/blog/how-to-add-copy-to-clipboard-buttons-to-code-blocks-in-hugo/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.dannyguo.com/blog/how-to-add-copy-to-clipboard-buttons-to-code-blocks-in-hugo/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>chaos-engineering</title>
        <link>https://ttf248.life/en/p/chaos-engineering/</link>
        <pubDate>Wed, 28 Jul 2021 14:35:07 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/chaos-engineering/</guid>
        <description>&lt;p&gt;A method for disrupting systems, used for system stability testing&lt;/p&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;China&amp;rsquo;s internet industry always likes to create something new; sometimes you hear a term and have no idea what it refers to&lt;/p&gt;
&lt;p&gt;I found the definition of Chaos Engineering&amp;rsquo;s early stages most relatable after reviewing some articles&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Early explorations of chaos engineering have existed within the industry, previously appearing as fault testing and disaster recovery drills. With the continuous development of microservice architectures and the increasing scale of distributed systems, chaos engineering has begun to emerge and gain increasing attention. Following Netflix&amp;rsquo;s formal introduction of the concept, related theories rapidly expanded. Their practices have demonstrated the significant value of chaos engineering in ensuring stability.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;reference-link&#34;&gt;Reference link
&lt;/h2&gt;&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/p&gt;</description>
        </item>
        <item>
        <title>kubernetes-pause-pod</title>
        <link>https://ttf248.life/en/p/kubernetes-pause-pod/</link>
        <pubDate>Mon, 12 Jul 2021 11:23:09 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/kubernetes-pause-pod/</guid>
        <description>&lt;p&gt;Deployment controllers implement a crucial function in Kubernetes clusters: horizontal pod scaling (expansion and contraction). This capability is essential for modern cloud platforms.&lt;/p&gt;
&lt;p&gt;When encountering a business scenario requiring database modifications and Pod restarts, we need to temporarily pause the application&amp;rsquo;s updates to the table while data is being adjusted, then resume the Pod after the adjustments are complete&lt;/p&gt;
&lt;p&gt;Are there other ways to achieve a similar effect to pausing, besides forcefully deleting Deployments?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubectl scale --replicas=0 deployment/&amp;lt;your-deployment&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before seeing the answer, many people probably wouldn&amp;rsquo;t have thought of it. Once they see it, a smile comes to mind â€“ their thinking hasnâ€™t caught up, still stuck in an era focused on directly manipulating processes and wanting to operate business processes that way.&lt;/p&gt;
&lt;h2 id=&#34;reference-link&#34;&gt;Reference link
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://stackoverflow.com/questions/54821044/how-to-stop-pause-a-pod-in-kubernetes&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;how to stop/pause a pod in kubernetes&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>docker-two-three-things</title>
        <link>https://ttf248.life/en/p/docker-two-three-things/</link>
        <pubDate>Thu, 21 Jan 2021 09:26:07 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/docker-two-three-things/</guid>
        <description>&lt;p&gt;After working for many years, I&amp;rsquo;ve encountered numerous users, and some content is not applicable&lt;/p&gt;
&lt;p&gt;Installation can refer to the manual from Tsinghua University: &lt;a class=&#34;link&#34; href=&#34;https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;install&#34;&gt;Install
&lt;/h2&gt;&lt;p&gt;Due to an unknown mysterious force, it is recommended to use cloud vendor-provided repository addresses for Docker installations within China; here, we recommend &lt;strong&gt;é˜¿é‡Œäº‘&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;set-repository-source-address&#34;&gt;Set repository source address
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum install yum-utils device-mapper-persistent-data lvm2 &amp;amp;&amp;amp; \
sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;deploy-the-latest-version&#34;&gt;Deploy the latest version
&lt;/h3&gt;&lt;p&gt;Docker, as a commonly used background service, is recommended to be set up for startup on boot. This command applies to CentOS 7.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo yum install -y docker-ce docker-ce-cli containerd.io &amp;amp;&amp;amp; systemctl enable --now docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;deploy-specified-version&#34;&gt;Deploy specified version
&lt;/h3&gt;&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum list docker-ce --showduplicates | sort -r
sudo yum install -y docker-ce-18.09.2-3.el7 docker-ce-cli-18.09.2-3.el7 containerd.io-18.09.2-3.el7 &amp;amp;&amp;amp; systemctl enable --now docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;add-docker-permissions-for-regular-users&#34;&gt;Add Docker permissions for regular users
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo usermod -aG docker ${USER}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;uninstall&#34;&gt;Uninstall
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo yum erase -y docker-ce docker-ce-cli containerd.io
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;everyday-use&#34;&gt;Everyday use
&lt;/h2&gt;&lt;h3 id=&#34;mirror-acceleration&#34;&gt;Mirror Acceleration
&lt;/h3&gt;&lt;p&gt;There are still unknown mysterious forces causing slow image pulls. Domestic cloud providers have stepped up, offering many acceleration services; I still recommend them.&lt;/p&gt;
&lt;p&gt;To obtain the accelerated access addresses, please register for an Alibaba Cloud account. This service is free, and Alibaba Cloud also provides a free image building service.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cat &amp;gt; /etc/docker/daemon.json &amp;lt;&amp;lt;EOF
{
  &amp;quot;registry-mirrors&amp;quot;: [
    &amp;quot;https://docker.nju.edu.cn&amp;quot;,
    &amp;quot;https://mirror.baidubce.com&amp;quot;,
    &amp;quot;https://docker.m.daocloud.io&amp;quot;,
    &amp;quot;https://docker.mirrors.sjtug.sjtu.edu.cn&amp;quot;
  ]
}
EOF
systemctl daemon-reload &amp;amp;&amp;amp; \
systemctl restart docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;highly-recommended-control-panel&#34;&gt;Highly recommended control panel
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker volume create portainer_data &amp;amp;&amp;amp; \
docker run -d --name=portainer --restart=always -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:2.20.3-alpine
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;commonly-used-image-pulls&#34;&gt;Commonly Used Image Pulls
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker pull rancher/rancher:stable &amp;amp;&amp;amp; docker pull  portainer/portainer-ce:2.0.1 &amp;amp;&amp;amp; \
docker pull centos:7 &amp;amp;&amp;amp; docker pull ubuntu:20.04 &amp;amp;&amp;amp; docker pull ubuntu:18.04 &amp;amp;&amp;amp; \
docker pull redis:5 &amp;amp;&amp;amp; docker pull redis:6 &amp;amp;&amp;amp; \
docker pull alpine:3.11 &amp;amp;&amp;amp; docker pull busybox:1.32 &amp;amp;&amp;amp; \
docker pull rabbitmq:3.7-management &amp;amp;&amp;amp; \
docker pull mariadb:10.2 &amp;amp;&amp;amp; \
docker pull nginx:1.18 &amp;amp;&amp;amp; docker pull nginx:1.19 &amp;amp;&amp;amp; \
docker pull mysql:5.6 &amp;amp;&amp;amp; docker pull mysql:8 &amp;amp;&amp;amp; \
docker pull elasticsearch:6.8.11 &amp;amp;&amp;amp; docker pull logstash:6.8.11 &amp;amp;&amp;amp; docker pull kibana:6.8.11 &amp;amp;&amp;amp; \
docker pull zookeeper:3.4 &amp;amp;&amp;amp; \
docker pull influxdb:1.7 &amp;amp;&amp;amp; docker pull grafana/grafana:7.3.1 &amp;amp;&amp;amp; \
docker pull percona:8 &amp;amp;&amp;amp; docker pull percona:5.6 &amp;amp;&amp;amp; \
docker pull cloverzrg/frps-docker:0.34.3 &amp;amp;&amp;amp; docker pull cloverzrg/frpc-docker:0.34.3
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;common-command-combinations&#34;&gt;Common Command Combinations
&lt;/h3&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.docker.com/engine/reference/commandline/docker/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://docs.docker.com/engine/reference/commandline/docker/&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Check container runtime status, add the __INLINE_CODE_0 parameter, view detailed container information; ignore image information at this time&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker ps --format &amp;quot;{{.Names}}: {{.Ports}}: {{.Size}}&amp;quot;
#portainer: 0.0.0.0:8000-&amp;gt;8000/tcp, 0.0.0.0:9000-&amp;gt;9000/tcp: 0B (virtual 172MB)
#influxdb: 0.0.0.0:8086-&amp;gt;8086/tcp: 183B (virtual 311MB)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;Stop all containers&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker stop $(docker ps -a -q)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Delete all images&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;dokcer rmi $(docker images -a -q)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;Export image&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker save &amp;lt;IMAGE NAME&amp;gt;:&amp;lt;IMAGE TAG&amp;gt; &amp;gt; -o XXX.tar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Export image and compress&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker save &amp;lt;IMAGE NAME&amp;gt;:&amp;lt;IMAGE TAG&amp;gt; | gzip &amp;gt; XXX.tar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Import image&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker load -i XXX.tar
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Setting up a JMeter Testing Environment on Linux</title>
        <link>https://ttf248.life/en/p/linux-setup-jmeter-testing-environment/</link>
        <pubDate>Tue, 22 Dec 2020 10:12:50 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-setup-jmeter-testing-environment/</guid>
        <description>&lt;p&gt;The author, with a strong interest in hardware, conducted performance testing using JMeter and documented the deployment process of JMeter, InfluxDB, and Grafana on CentOS 7. They shared details on JMeter installation and command usage, InfluxDB features and Docker installation, as well as simple Grafana deployment and configuration. The document summarizes experiences and references for high-performance programming patterns.&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background
&lt;/h2&gt;&lt;p&gt;What use is a web panel in addition to data display?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You won&amp;rsquo;t understand until you try it yourself
Don&amp;rsquo;t use GUI mode for load testing! only for Test creation and Test debuggin.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The official recommendation is to obtain the load test report via command line and display it with a GUI, which may introduce data errors? I don&amp;rsquo;t have a deep understanding of JMeter, but at least this gives me a reason to experiment with the console panel in version &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The deployment method of Open Source China&amp;rsquo;s posts is not user-friendly, and the required files for installation also need to be downloaded via a public account. As a new generation, I naturally chose an alternative. Ultimately, itâ€™s still slow accessing cross-border sources due to servers being located domestically; at least mirror services offer acceleration, like the free one from Alibaba Cloud.&lt;/p&gt;
&lt;p&gt;Installation deployment of &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; is not detailed here; please refer to previous articles for guidance&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;The following content is divided into two parts: building basic testing environment components and a brief introduction to each component&lt;/p&gt;
&lt;h2 id=&#34;jmeter&#34;&gt;Jmeter
&lt;/h2&gt;&lt;p&gt;Apache JMeter is a load testing tool developed by the Apache organization, based on Java. It was initially designed for web application testing but has since been extended to other testing areas. It can be used to test static and dynamic resources such as static files, Java microservices, CGI scripts, Java objects, databases, FTP servers, etc. JMeter can simulate a large load on servers, networks, or objects to test their strength and analyze overall performance under different stress categories. Additionally, JMeter can perform functional/regression testing by creating scripts with assertions to verify that your program returns the expected results. For maximum flexibility, JMeter allows the use of regular expressions for creating assertions.&lt;/p&gt;
&lt;p&gt;Apache JMeter can be used to test the performance of static and dynamic resources (files, Servlets, Perl scripts, Java objects, databases and queries, FTP servers, etc.). It can simulate heavy loads on servers, networks, or objects to test their resilience or analyze overall performance under different types of stress. You can use it for graphical analysis of performance or to load test your servers/scripts/objects with high concurrency.&lt;/p&gt;
&lt;h3 id=&#34;jmeter-deployment-on-centos-7&#34;&gt;JMeter deployment on CentOS 7
&lt;/h3&gt;&lt;p&gt;Installation package&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum install java-1.8.0-openjdk -y &amp;amp;&amp;amp; \
wget https://mirrors.bfsu.edu.cn/apache//jmeter/binaries/apache-jmeter-5.4.tgz &amp;amp;&amp;amp; tar -xf apache-jmeter-5.4.tgz
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Configure environment variables&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export JMETER_HOME=$HOME/jmeter/apache-jmeter-5.4
export PATH=$JMETER_HOME/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;jmeter-commands&#34;&gt;JMeter commands
&lt;/h3&gt;&lt;p&gt;Finally, observe data on the control panel&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;jmeter -n -t /tmp/order-500-10s.jmx -l /tmp/jmeter-order-report-20200109/order-500-10s.jtl
# ä¸€èˆ¬ä¸ç”¨æµ‹è¯•ç»“æœå’Œæµ‹è¯•æŠ¥å‘Šï¼Œç®€åŒ–å‘½ä»¤
jmeter -n -t /tmp/order-500-10s.jmx
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;influxdb&#34;&gt;InfluxDB
&lt;/h2&gt;&lt;p&gt;InfluxDB is an open-source distributed time series, event, and metrics database written in Go, requiring no external dependencies. It&amp;rsquo;s now primarily used to store large volumes of timestamped data, such as DevOps monitoring data, app metrics, IoT sensor data, and real-time analytics data.&lt;/p&gt;
&lt;h3 id=&#34;influxdb-features&#34;&gt;InfluxDB Features
&lt;/h3&gt;&lt;p&gt;The features of InfluxDB can be summarized into 9 aspects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Unstructured (no pattern): Can have an arbitrary number of columns;&lt;/li&gt;
&lt;li&gt;The retention period for metrics can be configured&lt;/li&gt;
&lt;li&gt;Supports time-related functions (e.g., min, max, sum, count, mean, median) for statistical analysis&lt;/li&gt;
&lt;li&gt;Supports storage policies: Can be used for data deletion and modification (InfluxDB does not provide methods for deleting or modifying data)&lt;/li&gt;
&lt;li&gt;Continuous queries are a set of statements that automatically start on a schedule in the database, and when paired with storage policies, can reduce InfluxDB system resource usage&lt;/li&gt;
&lt;li&gt;Native HTTP support, built-in HTTP API&lt;/li&gt;
&lt;li&gt;Supports SQL-like syntax&lt;/li&gt;
&lt;li&gt;Allows configuring the number of data replicas within the cluster&lt;/li&gt;
&lt;li&gt;Supports periodic sampling data, writing it to another measurement for granular storage&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;installing-influxdb-docker&#34;&gt;Installing InfluxDB Docker
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mkdir influxdb &amp;amp;&amp;amp; cd influxdb &amp;amp;&amp;amp; \
docker run -p 8086:8086 -d --name influxdb -v $PWD:/var/lib/influxdb influxdb:1.7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Enter container, execute command, manually create database&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;root@bce0a55bbc72:/# influx
Connected to http://localhost:8086 version 1.7.10
InfluxDB shell version: 1.7.10
&amp;gt; äº¤äº’é¢æ¿æ‰§è¡Œå‘½ä»¤
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;creating-databases-and-users-in-influxdb&#34;&gt;Creating databases and users in InfluxDB
&lt;/h3&gt;&lt;p&gt;Create database jmeter_t2
View databases
Switch database: use jmeter_t2
Create user &amp;ldquo;admin&amp;rdquo; with password &amp;lsquo;admin&amp;rsquo; and all privileges
View Users&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;&amp;gt; show users
user  admin
----  -----
admin true
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If user permissions are displayed, database preparation is complete&lt;/p&gt;
&lt;h2 id=&#34;grafana&#34;&gt;Grafana
&lt;/h2&gt;&lt;p&gt;The need for chart display is not essential; the &lt;strong&gt;INLINE_CODE_0&lt;/strong&gt; data from the interface can already be observed when executed in the command line, and it&amp;rsquo;s more about understanding the program&amp;rsquo;s internal execution time&lt;/p&gt;
&lt;p&gt;Simple deployment&lt;/p&gt;
&lt;p&gt;The console supports filtering test results by tag, and typically only requires configuring one database&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Application Name&lt;/li&gt;
&lt;li&gt;Test Case Name&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/linux-setup-jmeter-testing-environment/Snipaste_2021-03-09_19-44-22.png&#34;
	width=&#34;861&#34;
	height=&#34;357&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;grafana&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;241&#34;
		data-flex-basis=&#34;578px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -d --name=grafana -p 3000:3000 grafana/grafana:7.3.1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Web version calculations are affected by sampler interval&lt;/p&gt;
&lt;p&gt;The document also describes how to customize __INLINE_CODE_0&lt;/p&gt;
&lt;h2 id=&#34;afterword&#34;&gt;Afterword
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;High-performance programming inherently relies on a single loop thread; any locks, queuing (for entry and exit), will cause unnecessary performance loss&lt;/li&gt;
&lt;li&gt;The time spent on core business logic exceeds the time spent on introducing other code; concurrency is effective only when this core processing time is sufficiently small, and otherwise, introducing additional code should be approached cautiously&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/@jasonli.studio/to-install-apache-jmeter-in-centos7-294bc72a97ba&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;To install Apache JMeter in CentOS7&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Red Hat and CentOS lifecycles</title>
        <link>https://ttf248.life/en/p/redhat-centos-lifecycle/</link>
        <pubDate>Tue, 21 Jul 2020 20:02:35 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/redhat-centos-lifecycle/</guid>
        <description>&lt;p&gt;Red Hat and CentOS are popular choices for online production environment operating systems. Links to the official lifecycle information for both systems are provided, along with experience upgrading from CentOS 8 to CentOS 8 Stream.&lt;/p&gt;
&lt;h2 id=&#34;preface&#34;&gt;Preface
&lt;/h2&gt;&lt;p&gt;In online production environments, Red Hat and CentOS are currently the mainstream choices in China. Following the retirement of Red Hat 6 in recent years, here are links to the official life cycle websites for both systems.&lt;/p&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://access.redhat.com/support/policy/updates/errata&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Red Hat Enterprise Linux Life Cycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Red Hat Enterprise Linux (RHEL) and CentOS are popular choices for enterprise server operating systems. RHEL offers stable support and update cycles, suitable for enterprise applications. CentOS, as a community version of RHEL, provides similar functionality and stability but lacks official support.&lt;/p&gt;
&lt;h2 id=&#34;chase-for-more&#34;&gt;Chase for more
&lt;/h2&gt;&lt;p&gt;When publishing this article, I never thought I would update it again after two years. Just the other day, I upgraded my daily-use virtual machine from CentOS 8 to CentOS 8 Stream. I won&amp;rsquo;t elaborate on production choices, but I still prefer the latest versions for local environments.&lt;/p&gt;
&lt;p&gt;CentOS 8 Stream is a rolling release offering faster updates and new features compared to traditional CentOS, making it suitable for development and testing environments&lt;/p&gt;</description>
        </item>
        <item>
        <title>Building computers</title>
        <link>https://ttf248.life/en/p/computer-assembly-tips/</link>
        <pubDate>Sat, 18 Jul 2020 14:33:46 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/computer-assembly-tips/</guid>
        <description>&lt;p&gt;The author developed an early interest in assembling computers and began exploring hardware during university. They recommend a website for comparing hardware performance and offer purchasing advice on components like CPUs, SSDs, HDDs, and memory frequency. The text also shares hardware selection experience and important considerations.&lt;/p&gt;
&lt;h3 id=&#34;fate-beyond-words&#34;&gt;Fate, beyond words
&lt;/h3&gt;&lt;p&gt;Ever since I was little, I wanted to build my own computer, but the financial situation wouldn&amp;rsquo;t allow it. Finally making it to university, I opted for a laptop for portability. If you want a specific time, it all started at my hometown library. Itâ€™s a district-level library with not only an electronic reading room (which I never actually used â€“ they charged by the hour) but also a magazine reading room. That&amp;rsquo;s where I stumbled upon magazines like &amp;ldquo;å¤§ä¼—è½¯ä»¶&amp;rdquo; (Popular Software) and &amp;ldquo;ç”µè„‘æŠ¥&amp;rdquo; (Computer News). For someone with limited exposure to computers, these were essentially divine resources. Seeing chapters about raiding dungeons made me want to build my own computer so I could pull mobs and be a main damage dealer; seeing the â€œblack technologyâ€ sparked fantasies of replicating what was described in the books (a discussion on using hacking tools). Though high school coursework was demanding, with my limited knowledge at the time, I felt I needed to both study and play. I spent a carefree youth often strolling to the library under the guise of reading, carrying a small bag. The city wasn&amp;rsquo;t large, so I usually walked. Once there, Iâ€™d enjoy the air conditioning while browsing novels, comics, and gaming magazines, occasionally looking at more serious books.&lt;/p&gt;
&lt;p&gt;As you get older, forgetfulness becomes more common; this isn&amp;rsquo;t the first time something like this has happened at the library. When I was in middle school, my relatives assembled a computer â€“ I donâ€™t remember why they built it. It ran Windows 2003 and had Solitaire and Age of Empires. We spent countless hours trying to sneak away with the key to play games with my cousin.&lt;/p&gt;
&lt;p&gt;Entering junior high, the school offered introductory computer training. Later, when I transferred schools, I was briefly exposed to the idea of computer competitions. By high school, I participated in NOIP once. Speaking of which, it&amp;rsquo;s impossible not to mention the power of alumni â€“ the high schoolâ€™s computer building, including classrooms and a library, was funded by alumni donations. It was also during the initial wave of Chinaâ€™s internet boom. School leaders supported participation in computer competitions, as several senior students from the previous two years had been admitted to top universities through computer-related pathways.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I&amp;rsquo;ve never looked back at my relationship with computers like this before. No wonder I switched from automation to the computer industry after graduating â€“ the seeds were already sown, though those involved didnâ€™t realize it. Having been exposed to them since childhood, I thought I knew a lot, but in reality, I only grasped the basics. My biggest advantage was that initial passion.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;hardware-assembly&#34;&gt;Hardware assembly
&lt;/h3&gt;&lt;p&gt;Browse the forums on Cardekho, Chiphell, and Zhihu&amp;rsquo;s computer assembly sections; beginners can easily create a list of components they need. If your budget is limited and you want higher performance when buying a CPU after 2019, AMD is generally the best choice.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a translation of the provided Chinese text: &amp;ldquo;I recommend a useful website for comparing hardware performance: &lt;a class=&#34;link&#34; href=&#34;https://cpu.userbenchmark.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://cpu.userbenchmark.com/&lt;/a&gt;. You can generally compare prices with those on Xianyu (é—²é±¼, eBay China) there. Serious enthusiasts can find great deals on used items on Xianyu, saving a lot of money. However, if you&amp;rsquo;re not very knowledgeable, I donâ€™t recommend it; I bought fake memory there myself. Although it seems to be working fine now, Iâ€™m not entirely sure, as the model and specifications are completely mismatched.&amp;rdquo;&lt;/p&gt;
&lt;h4 id=&#34;sn550-vs-sn750&#34;&gt;SN550 VS SN750
&lt;/h4&gt;&lt;p&gt;The difference between the SN550 1TB and SN750 1TB is that their sustained read/write speeds are about half â€“ one at 850MB, the other at 1.6GB. However, there&amp;rsquo;s no noticeable difference in everyday use because both have the same 4K performance. This refers to the 1TB capacity SN550; the 500GB and 250GB versions are slower. Unless youâ€™re not concerned about cost, the SN550 is perfectly fine for daily use. My main reason for not buying it wasn&amp;rsquo;t its sequential read/write speed, but rather that it only comes in a maximum of 1TB capacity, while the SN750 offers 2TB. For me, the value of having an extra M.2 NVMe slot on my motherboard is greater than the price difference between these SSDs, without needing to expand further.&lt;/p&gt;
&lt;p&gt;With consensus from online users, purchasing an adapter allows a B150 motherboard to support an M.2 SSD&lt;/p&gt;
&lt;h4 id=&#34;choosing-a-mechanical-hard-drive&#34;&gt;Choosing a Mechanical Hard Drive
&lt;/h4&gt;&lt;p&gt;Currently, mechanical hard drives are priced stably. For users with high storage needs, selecting a suitable mechanical hard drive is necessary. Frequent downloaders are recommended to choose enterprise-grade hard drives, such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Western Digital Gold&lt;/li&gt;
&lt;li&gt;Seagate Exos&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are!&lt;/p&gt;
&lt;p&gt;Seagate series&lt;/p&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;h4 id=&#34;memory-frequency&#34;&gt;Memory frequency
&lt;/h4&gt;&lt;p&gt;From a daily work perspective, frequency won&amp;rsquo;t significantly impact performance&lt;/p&gt;
&lt;p&gt;!&lt;strong&gt;Link 0&lt;/strong&gt; Link 1&lt;/p&gt;
&lt;p&gt;Memory timings (or RAM timings) are four parametersâ€”CL, TRCD, TRP, and TRASâ€”measured in clock cycles that describe the performance of synchronous dynamic random-access memory (SDRAM). They are typically written as four numbers separated by hyphens, such as 7-8-8-24. The fourth parameter (RAS) is often omitted, and a fifth parameter, Command rate (typically 2T or 1T, also written as 2N or 1N), may be included. These parameters specify latency values that affect random access memory speed. Lower numbers generally indicate faster performance. The ultimate determinant of system performance is the actual latency, usually expressed in nanoseconds.&lt;/p&gt;
&lt;p&gt;When converting memory timings to actual latency, it&amp;rsquo;s crucial to remember they are measured in clock cycles. Without knowing the duration of a clock cycle, itâ€™s impossible to determine if one set of numbers is faster than another.&lt;/p&gt;
&lt;p&gt;For example, DDR3-2000 memory has a clock frequency of 1000 MHz and a clock cycle of 1 ns. Based on this 1 ns clock, a CL=7 results in an absolute latency of 7 ns. Faster DDR3-2666 (clocked at 1333 MHz with a 0.75 ns cycle) may use a larger CL=9, but still achieves a shorter absolute latency of 6.75 ns.&lt;/p&gt;
&lt;p&gt;Modern DIMMs include a Serial Presence Detect (SPD) ROM chip containing memory timings recommended for automatic configuration. The PC BIOS may allow users to adjust these timings to improve performance (with the risk of reduced stability) or, in some cases, increase stability (such as using suggested timings).&lt;/p&gt;
&lt;p&gt;Note: Memory bandwidth measures memory throughput and is typically limited by transfer rate rather than latency. Interleaving access to multiple internal banks of SDRAM allows for continuous transmission at peak rates. Bandwidth can be increased at the expense of increased latency. Specifically, each new generation of DDR memory features higher transfer rates, but absolute latency doesn&amp;rsquo;t change significantly â€“ especially in the first batch of products on the market, which often have longer latencies than the previous generation.&lt;/p&gt;
&lt;p&gt;Increasing memory bandwidth can improve the performance of multi-processor or multi-threaded computer systems, even with increased memory latency. Higher bandwidth will also enhance the performance of integrated graphics cards without dedicated video memory.&lt;/p&gt;
&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;h3 id=&#34;references&#34;&gt;References
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Website Acceleration and Domain Settings</title>
        <link>https://ttf248.life/en/p/website-acceleration-and-domain-setup/</link>
        <pubDate>Sat, 20 Jun 2020 10:36:27 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/website-acceleration-and-domain-setup/</guid>
        <description>&lt;p&gt;Due to slow access speeds within China for GitHub Pages, the author applied for a personal domain and purchased CDN acceleration services from a domestic cloud hosting provider. During configuration, they encountered an issue where the www subdomain was inaccessible, ultimately resolved by removing wildcard domain resolution and setting up the second-level domain separately. The author also shared the principles and configuration experience of CDN acceleration, as well as their attempts and lessons learned using Nginx reverse proxy.&lt;/p&gt;
&lt;h3 id=&#34;background&#34;&gt;Background
&lt;/h3&gt;&lt;p&gt;The website is hosted on GitHub Pages, which can be slow to access from within China for certain well-known reasons. Therefore, I applied for a personal domain and purchased CDN acceleration services from a domestic cloud hosting provider. While setting up the acceleration service, I realized I had a development machine with Docker, frp, k8s, and other services deployed â€“ all of which have dashboards. Following the principle of not letting resources go to waste, I configured several reverse proxies and linked them to subdomains.&lt;/p&gt;
&lt;p&gt;When I was happily using my second-level domain, I suddenly found that the www subdomain was inaccessible. The DNS configuration in Alibaba Cloud resolves both &lt;a class=&#34;link&#34; href=&#34;https://www.xiangtianlong.com&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;www.xiangtianlong.com&lt;/a&gt; and xiangtianlong.com simultaneously. Before enabling CDN acceleration, both domains worked correctly.&lt;/p&gt;
&lt;p&gt;When configuring CDN acceleration, enabling a wildcard domain rule due to having too many subdomains resulted in the www subdomain also failing. Yes, you read that right â€“ the www prefix is considered a subdomain. The actual website is deployed on GitHub Pages, and the development machine has no cached web content.&lt;/p&gt;
&lt;p&gt;Using GitHub Actions for automated deployment is surprisingly convenient for a static blog&lt;/p&gt;
&lt;h3 id=&#34;domain&#34;&gt;domain
&lt;/h3&gt;&lt;p&gt;Non-professional web development doesn&amp;rsquo;t involve understanding SEO or cross-domain issues. For a blog site, using a bare domain can highlight the bloggerâ€™s siteâ€”which is exactly my situation with using Chinese pinyin as a domain nameâ€”and also helps reduce character input, especially given the prevalence of mobile access.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The desktop version allows you to skip typing &amp;ldquo;www&amp;rdquo; and &amp;ldquo;com&amp;rdquo; using keyboard shortcuts&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;cdn&#34;&gt;CDN
&lt;/h3&gt;&lt;p&gt;I&amp;rsquo;ve used both Alibaba Cloud and Tencent Cloud; they are easy for new users to get started with. Tencent Cloud even has a video explaining the related concepts. The principle of CDN acceleration is the same as that of JD&amp;rsquo;s warehouse: when launching new products, they are pre-distributed to warehouses across the country, and delivery requests are fulfilled from the nearest location.&lt;/p&gt;
&lt;p&gt;Return address: The original location where website resources were stored&lt;/p&gt;
&lt;p&gt;Cache file settings, browser F12, management console, simple analysis of static and dynamic resources&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;All 0-day validity&lt;/li&gt;
&lt;li&gt;0-day validity&lt;/li&gt;
&lt;li&gt;1-day validity&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Tencent Cloud Configuration Rules:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Up to 10 cache expiration rules can be configured&lt;/li&gt;
&lt;li&gt;The priority of cache expiration rules is bottom-up&lt;/li&gt;
&lt;li&gt;Cache expiration time can be set up to 365 days&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;a-lamentable-confession&#34;&gt;A Lamentable Confession
&lt;/h3&gt;&lt;p&gt;I hadn&amp;rsquo;t used Nginx before and thought I could understand reverse proxy configuration just by searching online. However, it was confusing; after a lot of effort, I couldn&amp;rsquo;t even get a 302 redirect working, rendering the whole thing useless. So, I decided on a simple solution: removing the wildcard domain resolution and setting up each subdomain independently. Thatâ€™s when I noticed Aliyun DNS had a &amp;ldquo;Display URL Jump&amp;rdquo; mode â€“ exactly what I needed for a 302 redirect.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;After setting up the first subdomain and confirming it worked, I ran into issues with the second. I almost started doubting myself, but then it suddenly started working after a wait. It seems Aliyun&amp;rsquo;s DNS propagation occasionally glitches.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;references&#34;&gt;References
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Blog IDE Environment and Random Thoughts</title>
        <link>https://ttf248.life/en/p/blog-ide-environment-and-ramblings/</link>
        <pubDate>Tue, 31 Mar 2020 13:54:27 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/blog-ide-environment-and-ramblings/</guid>
        <description>&lt;p&gt;This article introduces the basic concepts of Markdown and its applications in various software. It recommends using VSCode as an IDE and lists recommended plugins. The author shares their experience switching from Hexo to Hugo, emphasizing Hugo&amp;rsquo;s flexibility and customization capabilities. Finally, it provides tips for quickly getting started with new technologies and shares a trick for resolving Hugo theme styling update issues.&lt;/p&gt;
&lt;h2 id=&#34;preface&#34;&gt;Preface
&lt;/h2&gt;&lt;h3 id=&#34;markdown&#34;&gt;Markdown
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;A lightweight markup language that allows people to write documents in an easy-to-read and write plain text format&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Detailed Markdown syntax is not elaborated on here; instead, an ebook is recommended: &lt;a class=&#34;link&#34; href=&#34;https://markdown-zh.readthedocs.io/en/latest/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ç‚¹å‡»æ­¤å¤„&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Many software programs already support md as a writing format. The CSDN blog system launched an online editor that supports md syntax, and it includes a helpful introductory article on md syntax when you first use it. Evernote added md note support in 2018, with various md markup options readily available, making the experience similar to editing regular articles and suitable for beginners.&lt;/p&gt;
&lt;h3 id=&#34;recommended-ides&#34;&gt;Recommended IDEs
&lt;/h3&gt;&lt;p&gt;By the time this article was written, it was 2020. You&amp;rsquo;ve likely heard of VS Codeâ€”after all, anyone considering using Git Page to build a blog system is an industry professional. While Sublime and Atom were good choices in earlier years, with two years of community support, VS Code has rapidly developed and become the preferred starting point for beginners.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Microsoft&amp;rsquo;s relationship with the open-source community has transitioned from a fractured state to a honeymoon period: embracing open source. The company I work for has also actively adopted the Java ecosystem in recent years; in other words, the current Java landscape is genuinely appealing within China.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;vs-code-plugin-recommendations&#34;&gt;VS Code plugin recommendations
&lt;/h3&gt;&lt;p&gt;Please provide the Chinese text you want me to translate. I am ready when you are.&lt;/p&gt;
&lt;p&gt;Plugins typically include Readme files detailing basic usage, core features, and sometimes dynamic effect demonstrations provided by the plugin authors&lt;/p&gt;
&lt;p&gt;It easily integrates images, complementing Hugo&amp;rsquo;s image plugin approach&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Can&amp;rsquo;t remember the shortcuts, open the VS Code shortcut management menu, search for &amp;ldquo;md,&amp;rdquo; look at it several times; review the plugin instructions again&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;hugo&#34;&gt;hugo
&lt;/h2&gt;&lt;p&gt;I&amp;rsquo;m naturally restless; I canâ€™t just sit still and write articles&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Hugo supports placing images and Markdown documents in separate folders&lt;/li&gt;
&lt;li&gt;Academic themes support various article styles in design&lt;/li&gt;
&lt;li&gt;Various convenient custom extensions&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;academic&#34;&gt;academic
&lt;/h2&gt;&lt;p&gt;The website defaults to ______&lt;/p&gt;
&lt;p&gt;The URL structure allows single-page navigation, avoiding scrolling on the homepageâ€”a matter of personal preference&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Formats: Essays, speeches, ebooks&lt;/li&gt;
&lt;li&gt;Flexibility: Customize overall style, customize CSS styles&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This theme&amp;rsquo;s support for Chinese is not yet fully mature, mainly from a visual perspective â€“ the font size isn&amp;rsquo;t ideal for Chinese reading habits. However, it benefits from being developed by mostly Chinese developers, giving it an advantage over Hugo.&lt;/p&gt;
&lt;p&gt;However, it&amp;rsquo;s best to do things yourself â€“ inspect the browser elements. Once youâ€™ve located an element, clicking on &lt;strong&gt;Insert Style Rule Below&lt;/strong&gt; in the sidebar allows you to easily retrieve the CSS style name, even for deeply nested styles.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;li&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text here.&lt;/li&gt;
&lt;li&gt;Theme-specific syntax highlighting settings, &lt;a class=&#34;link&#34; href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/#highlighting-options.&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;å®˜æ–¹é“¾æ¥&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h2&gt;&lt;p&gt;The child is about to complain again â€“ why are you being so vague from beginning to end, without mentioning any details?&lt;/p&gt;
&lt;p&gt;I want to say that these things are enough for you&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Official Manual&lt;/li&gt;
&lt;li&gt;Plugin Description&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To quickly get started with new technology, it&amp;rsquo;s recommended to first read the official documentation. Donâ€™t feel pressured to understand everything in one go; at least aim for a general understanding. Search engine results may not always align with the latest version and could be misleading. The same applies to new books â€“ start by looking at the table of contents to grasp what the author intends to cover. Sometimes, reading the preface first is helpful; in some foreign works translated into Chinese, the translator&amp;rsquo;s preface often summarizes the bookâ€™s core content.&lt;/p&gt;
&lt;h2 id=&#34;easter-egg&#34;&gt;Easter egg
&lt;/h2&gt;&lt;p&gt;Switching Hugo Academic&amp;rsquo;s built-in style and publishing to the site didnâ€™t change the appearance. Clever users likely figured out that clearing the browser cache would solve the problem. And me, being ingenious: F12 developer mode, switched to &lt;code&gt;network&lt;/code&gt;BOLD_2&lt;code&gt;disable cache&lt;/code&gt;, refreshed, and it&amp;rsquo;s done!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/blog-ide-environment-and-ramblings/2020-03-31-14-27-15.png&#34;
	width=&#34;399&#34;
	height=&#34;142&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;network&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;280&#34;
		data-flex-basis=&#34;674px&#34;
	
&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>Automatic System Switchover</title>
        <link>https://ttf248.life/en/p/auto-integration-system-switch/</link>
        <pubDate>Sun, 29 Mar 2020 02:11:33 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/auto-integration-system-switch/</guid>
        <description>&lt;p&gt;Automatically deploy a Hugo blog to GitHub Pages and Gitee using GitHub Actions&lt;/p&gt;
&lt;h4 id=&#34;background-introduction&#34;&gt;Background introduction
&lt;/h4&gt;&lt;p&gt;While updating my blog yesterday, I noticed that the Travis service was unavailable. Checking the Travis website, I saw the progress was stuck on pulling source code. This reminded me of GitHub&amp;rsquo;s Actions service.&lt;/p&gt;
&lt;p&gt;Given it will be quite busy and requires an application to use, now that it&amp;rsquo;s officially launched, and with a free weekend, why not try out a new toy?&lt;/p&gt;
&lt;p&gt;You can find official information on the website. I won&amp;rsquo;t be reposting it further. If youâ€™ve used Kubernetes before, youâ€™ll notice that the action YAML configuration is quite similar.&lt;/p&gt;
&lt;p&gt;For beginner tutorials or introductory materials in Chinese, search for &lt;strong&gt;é˜®ä¸€å³°çš„åšå®¢&lt;/strong&gt;. There are two articles: the first introduces basic grammar, and the second presents a practical case study.&lt;/p&gt;
&lt;h4 id=&#34;main-body&#34;&gt;Main body
&lt;/h4&gt;&lt;p&gt;Required knowledge points&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;github secrets&lt;/li&gt;
&lt;li&gt;Action grammar&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The core job is completed using existing components, pushed to the domestic Gitee with commands. The command portion is rather crude, utilizing force pushes and inheriting logic from Travis.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;name: github pages and gitee pages

on:
  push:
    branches:
      - hugo

jobs:
  deploy:
    runs-on: ubuntu-18.04
    steps:
      - uses: actions/checkout@v2
        with:
          submodules: true

      - name: Setup Hugo
        uses: peaceiris/actions-hugo@v2
        with:
          hugo-version: &#39;latest&#39;
          extended: true

      - name: Build Github and Gitee ## å•ä¸ªstepåªèƒ½å†™ä¸€ä¸ªrunå‘½ä»¤
        run: hugo -b &amp;quot;https://www.xiangtianlong.com/&amp;quot; -d &amp;quot;github_public&amp;quot; &amp;amp;&amp;amp; hugo -b &amp;quot;https://www.xiangtianlong.com/&amp;quot; -d &amp;quot;gitee_public&amp;quot; &amp;amp;&amp;amp; ls

      - name: Deploy Github
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.BLOG_TOKEN }}
          publish_dir: ./github_public
          publish_branch: master
          cname: xiangtianlong.com

      - name: Deploy Gitee
        run: cd ./gitee_public &amp;amp;&amp;amp; git init &amp;amp;&amp;amp; git config user.name &amp;quot;TianlongXiang&amp;quot; &amp;amp;&amp;amp; git config user.email &amp;quot;tianlongxiang51@gmail.com&amp;quot; &amp;amp;&amp;amp; git add . &amp;amp;&amp;amp; git commit -m &amp;quot;Update TianlongXiang&#39;s Blog&amp;quot; &amp;amp;&amp;amp; git push --force &amp;quot;https://xiangtianlong:${{ secrets.GITEE_PASSWORD }}@gitee.com/xiangtianlong/xiangtianlong.git&amp;quot; master:master   
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;afterword&#34;&gt;Afterword
&lt;/h4&gt;&lt;p&gt;Based on the actions provided by the official market, there are currently many supported features. After building a Docker image, you no longer need to rely on services from Docker Hub.&lt;/p&gt;
&lt;p&gt;Reviewing Hugo&amp;rsquo;s issues, I found that for automatically deploying Git Pages using GitHub Actions, the final published webpage needs to be on the master branch. If deployed to another branch, GitHub will indicate a syntax issue with the deployment page in the settings.&lt;/p&gt;
&lt;p&gt;The issue is that Hugo&amp;rsquo;s source files were located in the master branch, causing GitHub to treat them as Jelly blog code and fail checks&lt;/p&gt;
&lt;p&gt;The solution is simple: Hugo source files are placed on another branch, and static files are published on the master branch&lt;/p&gt;</description>
        </item>
        <item>
        <title>Allocator for standard library containers</title>
        <link>https://ttf248.life/en/p/standard-library-container-memory-allocator/</link>
        <pubDate>Mon, 30 Dec 2019 13:26:19 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/standard-library-container-memory-allocator/</guid>
        <description>&lt;p&gt;Custom allocators can improve performance, enhance memory efficiency, and address issues with frequent small memory allocations&lt;/p&gt;
&lt;h4 id=&#34;cause&#34;&gt;Cause
&lt;/h4&gt;&lt;p&gt;Recently, I&amp;rsquo;ve been working on network packet development, which requires frequent allocation and release of small memory blocks. I initially considered using a memory pool but examined existing implementations and found this&amp;hellip;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/cacay/MemoryPool&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/cacay/MemoryPool&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Seeing the interface, I was quite puzzled by this memory pool&amp;rsquo;s implementationâ€”the concept of &lt;code&gt;MemoryPool&lt;/code&gt;çš„å®ç°é€»è¾‘ï¼Œæ˜¯åœ¨ç”³è¯·å›ºå®šå¤§å°çš„å†…å­˜ç©ºé—´ã€‚çœ‹è¿‡boostçš„å†…å­˜æ± æ¥å£ï¼Œæä¾›çš„æ˜¯ä¸€ä¸ªæ¨¡æ¿ï¼Œç”¨çš„æ—¶å€™è¿›è¡Œå®ä¾‹åŒ–ã€‚æ­£å·§è¿™ä¸ªåº“å·²ç»æœ‰æ–‡ç« è¿›è¡Œè¿‡ä»‹ç»ï¼Œæåˆ°äº†__INLINE_CODE_1&lt;/p&gt;
&lt;h4 id=&#34;wikihttpszhwikipediaorgwikie58886e9858de599a8_c2b2b&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;wiki&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;In C++ programming, an allocator is a crucial component of the C++ standard library. Containers (such as linked lists and sets) are data structures defined in the C++ library that share a common characteristic: their size can change at runtime. Dynamic memory allocation is essential to achieve this, and allocators handle memory allocation and deallocation requests for containers. In other words, an allocator encapsulates the low-level details of memory management for Standard Template Library (STL) containers. By default, the C++ standard library uses its own generic allocator, but programmers can also customize their own allocators as needed.&lt;/p&gt;
&lt;p&gt;The allocator was originally invented by Alexander Stepanov as part of the C++ Standard Template Library (STL) with the goal of creating a way to make the library more flexible and independent of the underlying data model, allowing programmers to utilize custom pointer and reference types within the library. However, when incorporating the STL into the C++ standard, the C++ standards committee realized that complete abstraction of the data model would result in unacceptable performance losses. As a compromise, restrictions on allocators were tightened in the standard. Consequently, the current standard describes allocators with significantly less customization than Stepanov originally envisioned.&lt;/p&gt;
&lt;p&gt;While customization of allocators is limited, custom allocators are often necessary to manage access to different memory spaces (such as shared and recycled memory) or to improve performance when using memory pools. Furthermore, in programs with frequent small allocations, introducing a specialized allocator can yield significant benefits in terms of memory footprint and runtime.&lt;/p&gt;
&lt;h4 id=&#34;please-provide-the-chinese-text-you-want-me-to-translate-i-am-ready-when-you-are-just-paste-the-text-after-ä½¿ç”¨éœ€æ±‚httpszhwikipediaorgwikie58886e9858de599a8_c2b2b&#34;&gt;Please provide the Chinese text you want me to translate. I am ready when you are! Just paste the text after &amp;ldquo;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ä½¿ç”¨éœ€æ±‚&lt;/a&gt;.
&lt;/h4&gt;&lt;p&gt;One primary reason for defining custom allocators is to improve performance. Utilizing a dedicated custom allocator can enhance program performance, increase memory efficiency, or both [4][8]. The default allocator uses the &lt;code&gt;new&lt;/code&gt; operator to allocate storage space [Reference 5], often implemented using C&amp;rsquo;s heap allocation functions (malloc()) [9]. While the default allocator generally performs well when allocating memory for containers requiring large, infrequent allocations (e.g., vectors, double-ended queues) [8], it can be inefficient when used with containers that require frequent small allocations (e.g., associative containers and doubly linked lists) [4][9]. Furthermore, malloc()-based default allocators suffer from issues such as poor locality of reference [4] and potential memory fragmentation [4][9].&lt;/p&gt;
&lt;p&gt;In short, this section is like a &amp;ldquo;I Have a Dream&amp;rdquo; speech for the standard&amp;rsquo;s approach to allocators. Before that dream comes true, programmers concerned with portability will limit themselves to stateless custom allocators.
Scott Meyers, &lt;em&gt;Effective STL&lt;/em&gt;
Given this situation, memory pool allocators are often used to address frequent small allocations [8]. Unlike the default &amp;ldquo;on-demand&amp;rdquo; allocation approach, with a memory pool allocator, the program pre-allocates a large block of memory (the â€œmemory poolâ€), and the custom allocator simply returns a pointer to memory within the pool when an allocation is requested; no actual deallocation is performed during object destruction but is deferred until the end of the memory pool&amp;rsquo;s lifecycle [Note 1] [8].&lt;/p&gt;
&lt;p&gt;The topic of &amp;ldquo;custom allocators&amp;rdquo; has been extensively discussed by C++ experts and authors, such as Scott Meyers&amp;rsquo; &amp;ldquo;Effective STL&amp;rdquo; and Andrei Alexandrescu&amp;rsquo;s &amp;ldquo;Modern C++ Design.&amp;rdquo; Meyers observed that if all instances of an allocator for a given type T must be equal, then portable allocator instances must not contain state. While the C++ standard encourages library implementers to support allocators with state [reference 4], Meyers calls this related passage a â€œseemingly wonderful ideaâ€ but almost empty rhetoric, and considers the restriction on allocators &amp;ldquo;too strict&amp;rdquo; [4]. For example, STL&amp;rsquo;s list allows the splice method, where nodes of one list object A can be directly moved into another list object B, requiring that the memory allocated by Aâ€™s allocator can be released by Bâ€™s allocator, thus inferring that the allocator instances of A and B must be equal. Meyers concludes that allocators are best defined as types using static methods. For example, according to the C++ standard, an allocator must provide an other class template that implements the rebind method.&lt;/p&gt;
&lt;p&gt;Additionally, in &amp;ldquo;The C++ Programming Language,&amp;rdquo; Bjarne Stroustrup argues that â€œstrictly limiting the allocator to avoid object information differencesâ€ is not a significant issue (in essence), and notes that many allocators do not require state; performance can even be better without it. He proposes three use cases for custom allocators: memory pool allocators, shared-memory allocators, and garbage collection allocators, and demonstrates an implementation utilizing an internal memory pool for rapid allocation/deallocation of small amounts of memory. However, he also mentions that such optimization may already be achieved in the example allocator he provides [3].&lt;/p&gt;
&lt;p&gt;Another use of custom allocators is debugging memory-related errors [10]. This can be achieved by writing an allocator that allocates extra memory during allocation to store debug information. Such an allocator not only ensures that memory is allocated/deallocated by the same type of allocator, but also helps protect the program from buffer overflows [11].&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>

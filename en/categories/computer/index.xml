<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Computer on Uncle Xiang&#39;s Notebook</title>
        <link>https://ttf248.life/en/categories/computer/</link>
        <description>Recent content in Computer on Uncle Xiang&#39;s Notebook</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Sun, 25 May 2025 03:15:22 +0800</lastBuildDate><atom:link href="https://ttf248.life/en/categories/computer/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Claude4 release, attempting development: hugo tags, hyperlink translation assistant</title>
        <link>https://ttf248.life/en/p/claude-4-release-and-experimentation-hugo-tags-hyperlink-translation-assistant/</link>
        <pubDate>Sat, 24 May 2025 03:05:31 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/claude-4-release-and-experimentation-hugo-tags-hyperlink-translation-assistant/</guid>
        <description>&lt;p&gt;This site is built with Hugo, but I&amp;rsquo;ve always used Chinese titles, which results in unfriendly URLs for the articles. To put it simply, they don&amp;rsquo;t look very good when shared; Chinese characters are encoded as %E4%BD%A0%E5%A5%BD and so on in the links. While this can be solved by setting slugs, it’s too much trouble to do manually each time.&lt;/p&gt;
&lt;p&gt;So, today I tried using Claude4 to develop a translation assistant that automatically converts Chinese titles into English slugs and adds hyperlinks in articles. This can avoid manual setup.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Claude 4 is truly impressive; its ability to understand context has been significantly improved, and its efficiency in handling complex tasks has also increased dramatically&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;project-address&#34;&gt;Project address
&lt;/h2&gt;&lt;p&gt;Domestic project address: [https://cnb.cool/ttf248/hugo-slug-auto]
Foreign project address: [https://github.com/ttf248/hugo-slug-auto]&lt;/p&gt;
&lt;h2 id=&#34;code-implementation&#34;&gt;Code implementation
&lt;/h2&gt;&lt;p&gt;First, let me outline the implementation approach: we need to scan all articles, extract tag information and article titles, and then call a local large language model (such as gemma-3-12b-it) for translation&lt;/p&gt;
&lt;p&gt;In practical development, &lt;code&gt;Claude4&lt;/code&gt; demonstrates several significant advantages compared to previous generations of large models. Due to the diverse functional requirements, &lt;code&gt;Claude4&lt;/code&gt; automatically designs an interactive menu, comprehensively considering various use cases. For example, in terms of tag processing, &lt;code&gt;Claude4&lt;/code&gt; not only supports tag statistics and analysis but also includes classification statistics and can even detect &lt;strong&gt;untagged articles&lt;/strong&gt;. Furthermore, it provides &lt;strong&gt;preview&lt;/strong&gt; and generate tag page functions.&lt;/p&gt;
&lt;p&gt;Whether it&amp;rsquo;s connecting to local large models, adding new translation caches, or conducting large-scale code refactoring, &lt;code&gt;Claude4&lt;/code&gt; completed everything in one go with virtually no issues. Although the project is not large in scale, it includes many small features. In the past, large language models often forgot previous content during development, but &lt;code&gt;Claude4&lt;/code&gt; performed exceptionally well this time, &lt;strong&gt;with almost no instances of forgetting context.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In short, intelligence has improved, and we are preparing to switch to &lt;code&gt;Claude4&lt;/code&gt; for more development work as the primary model for daily coding&lt;/p&gt;
&lt;h2 id=&#34;translation-cache&#34;&gt;Translation cache
&lt;/h2&gt;&lt;p&gt;Speaking of this, apart from reducing the number of large model calls, running a 12b model locally is quite efficient and doesn&amp;rsquo;t cause delays. However, if you need to call the large model each time, it will still be a bit slow. Secondly, in order to keep the article links consistent, when performing a full update operation, long article titles can occasionally lead to different translation results, causing the article link to change – which is quite awkward.&lt;/p&gt;
&lt;h2 id=&#34;feature-optimization&#34;&gt;Feature optimization
&lt;/h2&gt;&lt;p&gt;The entire project was thrown to &lt;code&gt;Claude4&lt;/code&gt;, and it analyzed potential areas for optimization, resulting in the following suggestions:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;配置外置化 - 提高可维护性和灵活性
结构化日志 - 便于问题排查和监控
性能监控 - 了解系统运行状况
用户体验 - 进度条等视觉反馈
错误处理 - 更完善的异常处理机制
代码组织 - 更清晰的模块划分
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I reviewed the code, and everything is fine. For example, with configuration files, I know how to convert the original code&amp;rsquo;s configurations into default ones. When reading the configuration file, if a corresponding file doesn’t exist, it will automatically generate a default one, avoiding user errors.&lt;/p&gt;
&lt;h3 id=&#34;performance-statistics-menu&#34;&gt;Performance Statistics Menu
&lt;/h3&gt;&lt;p&gt;The newly added &lt;strong&gt;performance statistics menu&lt;/strong&gt;, which I designed myself, might not even be this well-designed&lt;/p&gt;
&lt;p&gt;Performance Statistics:
Translation count: 360
Cache hit rate: 1.4% (5/365)
Average translation time: 315.927234ms
File Operations: 73
Incorrect attempts: 0&lt;/p&gt;
&lt;h3 id=&#34;progress-bar-display&#34;&gt;Progress bar display
&lt;/h3&gt;&lt;p&gt;The new &lt;strong&gt;progress bar display&lt;/strong&gt; shows detailed progress, elapsed time, and estimated remaining time&lt;/p&gt;
&lt;p&gt;Please select function (0-13): 10
Collecting translation target..
Cached file loaded, containing 0 translation records&lt;/p&gt;
&lt;p&gt;Translation cache statistics:
Total number of tags: 229
Total number of articles: 131
Cached: 0 items
360&lt;/p&gt;
&lt;p&gt;Confirm generating the full translation cache? (y/n): y
Generating full translation cache..
Cached file loaded, containing 0 translation records
Checking for translations in cache..
Need to translate 360 new tags
5/360 (1.4%) - Time taken: 3s - Estimated remaining: 3m8s💾 Saved cache file, containing 5 translation records
10/360 (2.8%) - Time taken: 6s - Estimated remaining time: 3m28s💾 Saved cache file, containing 10 translation records
[██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 15/360 (4.2%) - Time taken: 9s - Estimated remaining: 3m30s💾 Saved cache file, containing 15 translation records
[██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 20/360 (5.6%) - Time taken: 13s - Estimated remaining: 3m36s💾 Saved cache file, containing 20 translation records
[███░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 25/360 (6.9%) - Time taken: 16s - Estimated remaining: 3m33s💾 Saved cache file, containing 25 translation records
[████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 30/360 (8.3%) - Time elapsed: 19s - Estimated remaining: 3m30s💾 Saved cache file, containing 30 translation records
[████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 35/360 (9.7%) - Time elapsed: 22s - Estimated remaining: 3m25s💾 Saved cache file, containing 35 translation records&lt;/p&gt;
&lt;hr&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;=== 博客标签管理工具 ===

📊 数据查看
  1. 标签统计与分析
  2. 分类统计
  3. 无标签文章

🏷️  标签页面管理
  4. 预览标签页面
  5. 生成标签页面

📝 文章Slug管理
  6. 预览文章Slug
  7. 生成文章Slug

💾 缓存管理
  8. 查看缓存状态
  9. 预览全量翻译缓存
 10. 生成全量翻译缓存
 11. 清空翻译缓存

🔧 系统工具
 12. 查看性能统计
 13. 重置性能统计

  0. 退出程序
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;hugo-tag-automation-management-tool&#34;&gt;Hugo tag automation management tool
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;A smart tag management tool designed specifically for Hugo blogs, supporting AI translation, local caching, and a user-friendly interface&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;key-features&#34;&gt;Key Features
&lt;/h2&gt;&lt;h3 id=&#34;ai-intelligent-translation&#34;&gt;AI intelligent translation
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Local AI model translation based on LM Studio&lt;/li&gt;
&lt;li&gt;Chinese tags are automatically converted into SEO-friendly English slugs&lt;/li&gt;
&lt;li&gt;Supports batch translation, improving processing efficiency&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;intelligent-cache-system&#34;&gt;Intelligent Cache System
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Local JSON cache to avoid repeated translations&lt;/li&gt;
&lt;li&gt;Automatically detects cache status, saving API calls&lt;/li&gt;
&lt;li&gt;Support for cache management and clearing functions&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;friendly-user-interface&#34;&gt;Friendly user interface
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Intuitive command-line menu system&lt;/li&gt;
&lt;li&gt;Colored output, clear and easy to read&lt;/li&gt;
&lt;li&gt;Preview function, safe and reliable&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;data-analysis-and-statistics&#34;&gt;Data analysis and statistics
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Tag Usage Frequency Analysis&lt;/li&gt;
&lt;li&gt;Categorized Statistics and Visualization&lt;/li&gt;
&lt;li&gt;Untagged Article Detection&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;get-started-quickly&#34;&gt;Get Started Quickly
&lt;/h2&gt;&lt;h3 id=&#34;environmental-requirements&#34;&gt;Environmental requirements
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Go 1.21+&lt;/li&gt;
&lt;li&gt;LM Studio (Optional, for AI Translation)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;install-and-run&#34;&gt;Install and run
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 克隆项目
git clone https://github.com/ttf248/hugo-slug-auto.git
cd hugo-slug-auto

# 安装依赖
go mod tidy

# 运行工具
go run main.go [content目录路径]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;basic-usage&#34;&gt;Basic Usage
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Tag Analysis: View blog tag usage statistics&lt;/li&gt;
&lt;li&gt;Generate tag pages: Create dedicated pages for each tag&lt;/li&gt;
&lt;li&gt;Article Slug Management: Generate SEO-friendly URLs for article titles&lt;/li&gt;
&lt;li&gt;Cache Management: View and manage translation cache&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;project-architecture&#34;&gt;Project Architecture
&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;hugo-slug-auto/
├── main.go              # 主程序入口
├── models/              # 数据模型
├── scanner/             # 文章扫描解析
├── stats/               # 统计分析
├── translator/          # AI翻译模块
├── generator/           # 内容生成器
├── display/             # 界面显示
└── docs/               # 详细文档
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;main-features&#34;&gt;Main Features
&lt;/h2&gt;&lt;h3 id=&#34;tag-management&#34;&gt;Tag Management
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Tag Statistics Analysis&lt;/li&gt;
&lt;li&gt;Automatically Generated Tag Page&lt;/li&gt;
&lt;li&gt;Batch Translation Processing&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;article-management&#34;&gt;Article Management
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Automatic Slug Generation&lt;/li&gt;
&lt;li&gt;Article Content Analysis&lt;/li&gt;
&lt;li&gt;Batch processing support&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;smart-features&#34;&gt;Smart features
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;AI-powered translation&lt;/li&gt;
&lt;li&gt;Intelligent caching mechanism&lt;/li&gt;
&lt;li&gt;Precise content identification&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;document-link&#34;&gt;Document link
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Installation Guide&lt;/li&gt;
&lt;li&gt;Function Usage Instructions&lt;/li&gt;
&lt;li&gt;[API Interface Documentation]&lt;/li&gt;
&lt;li&gt;Troubleshooting&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;contribution-guidelines&#34;&gt;Contribution Guidelines
&lt;/h2&gt;&lt;p&gt;Welcome to submit Issues and Pull Requests! Please refer to &lt;a class=&#34;link&#34; href=&#34;docs/contributing.md&#34; &gt;Contributing Guide&lt;/a&gt; for details&lt;/p&gt;
&lt;h2 id=&#34;license&#34;&gt;License
&lt;/h2&gt;&lt;p&gt;MIT License - see &lt;a class=&#34;link&#34; href=&#34;LICENSE&#34; &gt;LICENSE&lt;/a&gt; file&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;If this project is helpful to you, please give it a star to support it!&lt;/p&gt;</description>
        </item>
        <item>
        <title>Merge Pull Request into forked repository</title>
        <link>https://ttf248.life/en/p/merge-pullrequest-to-fork-repository/</link>
        <pubDate>Wed, 07 May 2025 18:44:03 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/merge-pullrequest-to-fork-repository/</guid>
        <description>&lt;p&gt;&lt;code&gt;github-readme-stats&lt;/code&gt; is a statistics generator for GitHub profiles, allowing users to display various statistics and charts on their GitHub profile. It offers multiple customization options that can be adjusted according to user needs.&lt;/p&gt;
&lt;p&gt;I manage my warehouse by grouping them into projects. GitHub doesn&amp;rsquo;t support warehouse grouping, so I have to achieve this by splitting them into different organizations. The latest branch of &lt;code&gt;github-readme-stats&lt;/code&gt; cannot support statistics across different organizations’ warehouses, so I forked a branch and merged the corresponding code.&lt;/p&gt;
&lt;h2 id=&#34;final-effect&#34;&gt;Final effect
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://github-readme-stats-chi-one-17.vercel.app/api?username=ttf248&amp;amp;hide_title=true&amp;amp;show_icons=true&amp;amp;hide=contribs&amp;amp;line_height=24&amp;amp;include_all_commits=true&amp;amp;count_private=true&amp;amp;bg_color=0000&amp;amp;text_color=8A919F&amp;amp;locale=cn&amp;amp;role=OWNER,COLLABORATOR,ORGANIZATION_MEMBER&amp;amp;timstamp=1746608356&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;GitHub Stats&#34;
	
	
&gt;
&lt;img src=&#34;https://github-readme-stats-chi-one-17.vercel.app/api/top-langs/?username=ttf248&amp;amp;hide_title=true&amp;amp;hide=html,javascript,css&amp;amp;layout=compact&amp;amp;bg_color=0000&amp;amp;text_color=8A919F&amp;amp;locale=cn&amp;amp;role=OWNER,COLLABORATOR,ORGANIZATION_MEMBER&amp;amp;timstamp=1746608356&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Top Languages&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;original-pull-request-address&#34;&gt;Original Pull Request address
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/anuraghazra/github-readme-stats/pull/2459&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Adds the ability to include data from organization repositories&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;merge-pull-request-into-the-forked-repository&#34;&gt;Merge Pull Request into the forked repository
&lt;/h2&gt;&lt;p&gt;There are several ways to merge a &lt;strong&gt;Pull Request (PR)&lt;/strong&gt; into your &lt;strong&gt;forked repository&lt;/strong&gt;, depending on what you want to do&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Merge the PR from the &lt;strong&gt;upstream repository&lt;/strong&gt; into your fork, or&lt;/li&gt;
&lt;li&gt;Merge a PR from another person&amp;rsquo;s fork into your fork, or&lt;/li&gt;
&lt;li&gt;Merge a PR opened on your fork (e.g., someone submitted a PR from their fork to you)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here&amp;rsquo;s a common scenario: &lt;strong&gt;You forked a repository, and you want to merge a specific pull request from the upstream into your fork.&lt;/strong&gt; Here’s the workflow 👇:&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;method-1-command-line-method-most-universal&#34;&gt;Method 1: Command-line method (most universal)
&lt;/h3&gt;&lt;h4 id=&#34;step-1-clone-your-own-fork&#34;&gt;Step 1: Clone your own fork
&lt;/h4&gt;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/你的用户名/仓库名.git
cd 仓库名
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;step-2-add-upstream-original-repository-address&#34;&gt;Step 2: Add upstream (original repository address)
&lt;/h4&gt;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git remote add upstream https://github.com/原作者用户名/仓库名.git
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;step-3-fetch-the-upstreams-pr-branch&#34;&gt;Step 3: Fetch the upstream&amp;rsquo;s PR branch
&lt;/h4&gt;&lt;p&gt;Find the PR number you want to merge, for example, PR #123&lt;/p&gt;
&lt;p&gt;You can pull the code for this PR like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git fetch upstream pull/123/head:pr-123
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;step-4-switch-and-merge-branches&#34;&gt;Step 4: Switch and Merge Branches
&lt;/h4&gt;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git checkout main    # 或者你自己的目标分支
git merge pr-123
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If everything is normal, you can push to your forked GitHub repository&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git push origin main
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h3 id=&#34;method-two-github-web-interface-simple-but-limited&#34;&gt;Method Two: GitHub Web Interface (Simple but Limited)
&lt;/h3&gt;&lt;p&gt;If you see a pull request on the GitHub website that is for an upstream repository, you can:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to that PR page&lt;/li&gt;
&lt;li&gt;Click &amp;ldquo;Commits&amp;rdquo; or &amp;ldquo;Files changed&amp;rdquo; in the upper right corner to see which branch this PR is based on&lt;/li&gt;
&lt;li&gt;On your fork page, create a new branch and then manually cherry-pick the PR’s commits (this requires some Git knowledge)&lt;/li&gt;
&lt;li&gt;Or click &amp;ldquo;&lt;strong&gt;Open in GitHub Desktop&lt;/strong&gt;&amp;rdquo; to merge using a graphical user interface tool&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id=&#34;if-someone-has-submitted-a-pull-request-for-your-fork&#34;&gt;If someone has submitted a pull request for your fork
&lt;/h3&gt;&lt;p&gt;Just go directly to the PR page and click the &amp;ldquo;&lt;strong&gt;Merge pull request&lt;/strong&gt;&amp;rdquo; button&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Would you like me to walk you through it step-by-step based on your current situation (e.g., a PR link, whether you&amp;rsquo;re using a web page or command line)? You can also give me specific links, and I’ll help you analyze the simplest approach&lt;/p&gt;</description>
        </item>
        <item>
        <title>Modifying commit messages in Git history</title>
        <link>https://ttf248.life/en/p/git-modify-commit-message/</link>
        <pubDate>Wed, 07 May 2025 18:38:31 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/git-modify-commit-message/</guid>
        <description>&lt;p&gt;The script is used to batch modify the author information of Git history commits by rewriting commit records using git filter-branch&lt;/p&gt;
&lt;p&gt;The script you provided is intended to batch modify the author information in Git repository history, and the overall idea is correct. However, using arrays (like &lt;code&gt;OLD_EMAILS=(&amp;quot;...&amp;quot;)&lt;/code&gt;) in &lt;code&gt;--env-filter&lt;/code&gt; of &lt;code&gt;git filter-branch&lt;/code&gt; may cause compatibility issues because some shell environments (such as &lt;code&gt;/bin/sh&lt;/code&gt;) do not support array syntax.&lt;/p&gt;
&lt;p&gt;To improve compatibility, it is recommended that you replace the array with a space-separated string and iterate through each old email address using a &lt;code&gt;for&lt;/code&gt; loop. Here&amp;rsquo;s an example of the modified script:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/sh

git filter-branch --env-filter &#39;
OLD_EMAILS=&amp;quot;TianlongXiang51@gmail.com nick@qq.com tianlongxiang51@gmail.com&amp;quot;
CORRECT_NAME=&amp;quot;tianlong.xiang&amp;quot;
CORRECT_EMAIL=&amp;quot;tianlong.xiang@foxmail.com&amp;quot;

for OLD_EMAIL in $OLD_EMAILS
do
    if [ &amp;quot;$GIT_COMMITTER_EMAIL&amp;quot; = &amp;quot;$OLD_EMAIL&amp;quot; ]
    then
        export GIT_COMMITTER_NAME=&amp;quot;$CORRECT_NAME&amp;quot;
        export GIT_COMMITTER_EMAIL=&amp;quot;$CORRECT_EMAIL&amp;quot;
    fi
    if [ &amp;quot;$GIT_AUTHOR_EMAIL&amp;quot; = &amp;quot;$OLD_EMAIL&amp;quot; ]
    then
        export GIT_AUTHOR_NAME=&amp;quot;$CORRECT_NAME&amp;quot;
        export GIT_AUTHOR_EMAIL=&amp;quot;$CORRECT_EMAIL&amp;quot;
    fi
done
&#39; --tag-name-filter cat -- --branches --tags
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Precautions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;It is recommended to back up your repository before running this script to prevent unexpected situations&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;This operation will rewrite the Git history, modify the author information of commits, and may cause changes to commit hash values&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you have already pushed changes to the remote repository, you need to use a force push&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git push --force --tags origin &#39;refs/heads/*&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Please use force push cautiously, especially in collaborative projects, to avoid impacting others&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Find all unique author email addresses in the warehouse statistics&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git log --format=&#39;%an &amp;lt;%ae&amp;gt;&#39; | sort -u
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Bored and wanting to design a traditional Chinese ink-wash painting style theme</title>
        <link>https://ttf248.life/en/p/chinese-ink-style-theme/</link>
        <pubDate>Tue, 08 Apr 2025 03:42:47 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/chinese-ink-style-theme/</guid>
        <description>&lt;p&gt;I&amp;rsquo;m tired of those colorful and flashy homepages, suddenly I want to go for a minimalist style and design a theme in Chinese ink-wash painting style&lt;/p&gt;
&lt;p&gt;Because the stylesheet is heavily modified, specific styles are configured for different elements to override the theme&amp;rsquo;s default styles&lt;/p&gt;
&lt;p&gt;Without refactoring, trying to directly generate a new theme using AI results in something that is very unstable&lt;/p&gt;
&lt;p&gt;It just so happened I ran into the queue for the trae claude large model, switched to VS Code agent mode, and the results were really bad – whatever was modified lacked any sense of design&lt;/p&gt;
&lt;p&gt;Ultimately, it&amp;rsquo;s because I don&amp;rsquo;t understand frontend well enough to effectively break down tasks for AI&lt;/p&gt;</description>
        </item>
        <item>
        <title>Design and develop a customizable stock selection module without coding</title>
        <link>https://ttf248.life/en/p/no-code-design-develop-custom-stock-module/</link>
        <pubDate>Thu, 27 Feb 2025 23:20:39 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/no-code-design-develop-custom-stock-module/</guid>
        <description>&lt;p&gt;Last month we tested Cursor, but due to limitations on the free tier, we didn&amp;rsquo;t do any complex feature development, just some simple testing. At that time, we also discovered that ByteDance released a similar product, and both used the same underlying large language model – Claude-3.5.&lt;/p&gt;
&lt;p&gt;Byte&amp;rsquo;s product is called Trae, first launched for Mac, and finally released a Windows version this February. Products from big companies are just good – you can use them for free, without paying, with unlimited access to Claude-3.5. This model has a very nice effect.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Ultimately, I got stuck on the development of the K-line chart. Due to my basic lack of knowledge in React, I had to give up. To continue developing it, I need to supplement some fundamental front-end knowledge and break down the tasks more finely, rather than giving a large task: develop the K-line chart.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;issues-found&#34;&gt;Issues found
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Due to insufficient training data for Vue3 + Element-Plus due to the use of foreign AI models, we chose React as the front-end framework&lt;/li&gt;
&lt;li&gt;There may be occasional grammatical errors that need manual correction&lt;/li&gt;
&lt;li&gt;Solutions to some complex problems require human guidance&lt;/li&gt;
&lt;li&gt;Code structure optimization requires human guidance&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The most time-consuming part was packaging the frontend code into a container. As the author has no foundation, I had no concept of &lt;code&gt;.env.production&lt;/code&gt; or &lt;code&gt;tsconfig.json&lt;/code&gt;. I only managed to understand the corresponding logic with help from Bean. There&amp;rsquo;s a big difference in how the frontend development (dev) mode and build mode check the code. The container scripts for the backend database and services took about five minutes altogether.&lt;/p&gt;
&lt;p&gt;Currently, AI primarily improves development efficiency; having a foundation is best, as AI won&amp;rsquo;t solve all your problems&lt;/p&gt;
&lt;h2 id=&#34;warehouse-address&#34;&gt;Warehouse address
&lt;/h2&gt;&lt;p&gt;As the title says, this time we&amp;rsquo;re avoiding writing code and directly engaging with AI to design and develop a customizable stock selection module. Let’s see what kind of results we can achieve in the end.&lt;/p&gt;
&lt;p&gt;Repository address: [https://github.com/ttf248/trae-demo]&lt;/p&gt;
&lt;p&gt;Detailed usage instructions can be found in the README.md file in the repository&lt;/p&gt;
&lt;p&gt;The warehouse contains many submission records, mostly conversations between me and Trae, as well as my tests of some of Trae&amp;rsquo;s functions, with notes indicating whether manual intervention was required to achieve the corresponding functionality&lt;/p&gt;
&lt;h2 id=&#34;prompt&#34;&gt;Prompt
&lt;/h2&gt;&lt;p&gt;The project was created from scratch, here&amp;rsquo;s the prompt for the project:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;基于项目原型图，开发功能：自选股，需要支持合约的新增、删除、修改、查询。自选股界面需要展示基础的行情数据。支持多个不同的市场切换。

前端：react
后端：golang gin gorm
数据库：PostgreSQL

服务端需要支持跨域请求，同时需要考虑数据的校验和错误处理，如果后端服务不可用，前端需要告警提示。

后端需要展示请求和应答的日志；前端也打印通讯的日志，方便排查问题。
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;ui-and-interaction-optimization&#34;&gt;UI and interaction optimization
&lt;/h2&gt;&lt;p&gt;The design of the front-end interface is completely dependent on Grok. We first created a prototype in Trae, but it lacked aesthetic appeal. Due to the model&amp;rsquo;s strong coding capabilities but relatively weak other abilities, we need to use Grok to optimize the front-end UI.&lt;/p&gt;
&lt;p&gt;By taking a screenshot of the current interface, uploading it to Grok, and having it help us optimize the UI, we can potentially receive many optimization suggestions at once. We will manually evaluate them and then copy them into Trae for execution, observing the effects of the optimization.&lt;/p&gt;
&lt;h3 id=&#34;technology-stack&#34;&gt;Technology stack
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Frontend: React + TypeScript&lt;/li&gt;
&lt;li&gt;Backend: Golang + Gin + GORM&lt;/li&gt;
&lt;li&gt;Database: PostgreSQL 17&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;system-architecture&#34;&gt;System architecture
&lt;/h2&gt;&lt;h2 id=&#34;backend-architecture&#34;&gt;Backend architecture
&lt;/h2&gt;&lt;p&gt;The backend is implemented using the Go Gin framework for a RESTful API, with main modules including:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Database module&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use GORM as an ORM framework&lt;/li&gt;
&lt;li&gt;Support configuring database connections through environment variables&lt;/li&gt;
&lt;li&gt;Automatically migrate database tables&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Routing module&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RESTful API Design&lt;/li&gt;
&lt;li&gt;Unified error handling mechanism&lt;/li&gt;
&lt;li&gt;Built-in request logging&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cross-domain handling&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Support cross-domain in local development environments&lt;/li&gt;
&lt;li&gt;Configurable CORS policy&lt;/li&gt;
&lt;li&gt;Support cross-domain cookies&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;frontend-architecture&#34;&gt;Frontend Architecture
&lt;/h2&gt;&lt;p&gt;Built with React + TypeScript, it achieves:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stock list display&lt;/li&gt;
&lt;li&gt;Self-selected stock management&lt;/li&gt;
&lt;li&gt;Market Data Display&lt;/li&gt;
&lt;li&gt;Error prompt mechanism&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Protobuf Zero-Value Trap: When Defaults Become Silent Killers of Business Logic</title>
        <link>https://ttf248.life/en/p/protobuf-zero-value-traps/</link>
        <pubDate>Thu, 20 Feb 2025 15:26:51 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/protobuf-zero-value-traps/</guid>
        <description>&lt;p&gt;US stocks have three trading periods: pre-market, intra-market, and after-hours. The data push interface uses an incremental logic (to minimize bandwidth usage), sending the full dataset only once initially, and then pushing all subsequent fields as increments.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Why not use the optimal solution? It involves different project teams, some of which have been live for many years. We are newly connected, so we can only try our best to ensure compatibility.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;a-series-of-questions&#34;&gt;A series of questions
&lt;/h2&gt;&lt;p&gt;Looking at the abstract alone, there might not seem to be any issues. However, bringing the system architecture into the problem-solving group has led to a series of problems. Just as one problem was resolved, a new one emerged, and this new problem stemmed from the previous ones.&lt;/p&gt;
&lt;h3 id=&#34;unable-to-identify-trading-period&#34;&gt;Unable to identify trading period
&lt;/h3&gt;&lt;p&gt;The known issue is that the stage in the table is defined as 0 in &lt;code&gt;protobuf&lt;/code&gt;, but due to incremental push when receiving data, the business side cannot effectively identify whether this 0 is a default value or a real business value&lt;/p&gt;
&lt;p&gt;A layman&amp;rsquo;s understanding: Each time we receive a 0, it’s impossible to determine whether this 0 is the value of a newly set quote or the default value of Protobuf&lt;/p&gt;
&lt;h3 id=&#34;introduce-optional&#34;&gt;Introduce optional
&lt;/h3&gt;&lt;p&gt;Since protobuf release 3.15, proto3 supports using the optional keyword (just as in proto2) to give a scalar field presence information&lt;/p&gt;
&lt;p&gt;The communication protocol within the group is based on &lt;code&gt;protobuf&lt;/code&gt;, but due to historical reasons, an older version was chosen that doesn&amp;rsquo;t support the &lt;code&gt;optional&lt;/code&gt; keyword. Those who understand know that because &lt;code&gt;protobuf&lt;/code&gt; was introduced from the bottom up and the project is released as a static library, upgrading the entire compilation chain would be very costly.&lt;/p&gt;
&lt;h3 id=&#34;gcc-version-issue&#34;&gt;GCC version issue
&lt;/h3&gt;&lt;p&gt;After much effort, we devised a plan to release two different versions at the underlying level, attempting to control the propagation of compilation dependencies for the new version of &lt;code&gt;protobuf&lt;/code&gt;. However, during compilation, we discovered that the &lt;code&gt;gcc&lt;/code&gt; version was too low and did not support the new features of &lt;code&gt;protobuf&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Commonly used server types within the group: CentOS 7, CentOS 8. The default &lt;code&gt;gcc&lt;/code&gt; version for CentOS 7 is 4.8, and the default &lt;code&gt;gcc&lt;/code&gt; version for CentOS 8 is 8.3. Because new features of &lt;code&gt;protobuf&lt;/code&gt; require a &lt;code&gt;gcc&lt;/code&gt; version above 7.4, CentOS 7 cannot be supported.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://gcc.gnu.org/bugzilla/show_bug.cgi?id=82461&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Bug 82461 - [7 Regression] Temporary required for brace-initializing (non-literal-type) member variable&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;After some troubleshooting, I moved the deployment and compilation servers for related services to CentOS 8, which resolved the issue&lt;/p&gt;
&lt;h2 id=&#34;reasonable-enumeration&#34;&gt;Reasonable enumeration
&lt;/h2&gt;&lt;p&gt;Looking back at the whole issue, there&amp;rsquo;s actually a simpler and more efficient solution: adjust the enumeration definition to start numbering from 1 instead of 0. This can effectively distinguish between default values and business values, avoiding the aforementioned series of problems.&lt;/p&gt;
&lt;h3 id=&#34;why-is-it-more-reasonable-to-start-from-1&#34;&gt;Why is it more reasonable to start from 1?
&lt;/h3&gt;&lt;p&gt;In &lt;code&gt;protobuf&lt;/code&gt;, enumeration types default to a value of 0. If we define a meaningful business value as 0 (for example, &amp;ldquo;in-play&amp;rdquo;), the receiving party cannot determine whether the received 0 is a business value or an unset default value during incremental push. However, if we start defining enumerations from 1, 0 can be reserved for a meaningless default value or an &amp;ldquo;unknown&amp;rdquo; state, and the problem is easily resolved.&lt;/p&gt;
&lt;p&gt;Suggested practices:&lt;/p&gt;
&lt;p&gt;When designing protobuf enums, always define 0 as a meaningless default value (such as &lt;code&gt;UNKNOWN&lt;/code&gt; or &lt;code&gt;RESERVED&lt;/code&gt;)
Assign actual business values starting from 1, ensuring they are distinct from the default value of 0&lt;/p&gt;
&lt;p&gt;This small adjustment not only resolved the issue of identifying trading periods, but also provided a valuable lesson for future protocol design&lt;/p&gt;</description>
        </item>
        <item>
        <title>Troubleshooting TCP Communication Abnormalities in Backend Services</title>
        <link>https://ttf248.life/en/p/backend-service-tcp-communication-troubleshooting/</link>
        <pubDate>Fri, 14 Feb 2025 22:54:13 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/backend-service-tcp-communication-troubleshooting/</guid>
        <description>&lt;p&gt;The business model involves backend services establishing a connection with the group&amp;rsquo;s market gateway via TCP. Each connection requires sending an authorization request first, followed by continuously sending heartbeat packets to maintain the connection status.
However, one day, we received an alert message indicating a service disconnection. After carefully checking the logs, we discovered that the backend service was continuously sending heartbeat packets, but there was no response from the other party, yet the connection never disconnected.&lt;/p&gt;
&lt;h2 id=&#34;brief-description-of-the-scene&#34;&gt;Brief description of the scene
&lt;/h2&gt;&lt;p&gt;I was originally working overtime at the company to push forward project progress when an alarm message suddenly popped up in the work group. At first glance, I thought it was just the usual issue – likely a network timeout causing heartbeat failures and subsequently disconnecting the service. However, after carefully checking the logs, I found that the actual situation was not like that. The backend had sent authorization login messages, but received no response. Meanwhile, heartbeats continued to be sent incessantly, yet the other party never replied with any heartbeat data. In-depth analysis of the logs revealed the following key issues:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Authorization message received no response: It is very likely that the other party&amp;rsquo;s system is restarting, preventing the authorization message from being processed in a timely manner&lt;/li&gt;
&lt;li&gt;The heartbeat data was sent even though authorization failed: After investigation, we found a flaw in the program logic. The judgment logic of the heartbeat sending function is flawed; it only checks the connection status but overlooks the authorization status check.&lt;/li&gt;
&lt;li&gt;If the service can be disconnected, it will trigger a reconnection mechanism and resend the authorization message&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Currently, there remains one last urgent issue that needs resolving—why the connection has not been disconnected. Solving this problem requires more in-depth and detailed troubleshooting work.&lt;/p&gt;
&lt;h2 id=&#34;analyzing-network-packets&#34;&gt;Analyzing network packets
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;tcpdump&lt;/code&gt; is a very powerful network packet capture tool that can be used to capture network data packets. By analyzing these network data packets, we can gain a more intuitive understanding of the details of network communication. Here, we can use &lt;code&gt;tcpdump&lt;/code&gt; to capture network data packets for further analysis.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/backend-service-tcp-communication-troubleshooting/20250220151952.png&#34;
	width=&#34;1126&#34;
	height=&#34;202&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;tcpdump&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;557&#34;
		data-flex-basis=&#34;1337px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Analyzing the data in the graph, I can see that the heartbeat is consistently being sent, but the other server isn&amp;rsquo;t responding with any data, yet it’s sending an &lt;code&gt;ACK&lt;/code&gt;. This prevents the connection from disconnecting on its own.&lt;/p&gt;
&lt;h2 id=&#34;common-flag-explanations&#34;&gt;Common Flag Explanations
&lt;/h2&gt;&lt;p&gt;In the TCP protocol, &lt;code&gt;PSH&lt;/code&gt; (Push) and &lt;code&gt;ACK&lt;/code&gt; (Acknowledgment) are two important flags used to control data transmission and flow confirmation. Their functions are as follows:&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;1-pshpush-flag&#34;&gt;&lt;strong&gt;1. PSH（Push Flag）&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Features
The purpose of the &lt;code&gt;PSH&lt;/code&gt; flag is to &lt;strong&gt;request that the receiver immediately push data from the buffer to the upper layer application&lt;/strong&gt; (instead of waiting for the buffer to fill up). This means that once a data segment with the &lt;code&gt;PSH&lt;/code&gt; flag is received, the receiver will process and pass it to the application as quickly as possible, rather than storing it in the operating system buffer.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Typical Scenarios&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HTTP/HTTPS requests: When a client sends a request (such as &lt;code&gt;GET /index.html&lt;/code&gt;), it sets the &lt;code&gt;PSH&lt;/code&gt; flag, hoping that the server will respond immediately&lt;/li&gt;
&lt;li&gt;The SSH protocol: Each keyboard input triggers a &lt;code&gt;PSH&lt;/code&gt;, ensuring that input characters are transmitted in real-time&lt;/li&gt;
&lt;li&gt;Real-time communication: Low-latency scenarios such as video streams and online games may use &lt;code&gt;PSH&lt;/code&gt; to reduce latency&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Note:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PSH is not mandatory; the receiving party can choose to ignore this flag (but still needs to process the data normally)&lt;/li&gt;
&lt;li&gt;The sender may not set the &lt;code&gt;PSH&lt;/code&gt;, in which case the receiver will decide when to push data based on its own buffering strategy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;2-ackacknowledgment-flag&#34;&gt;&lt;strong&gt;2. ACK（Acknowledgment Flag）&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Features
The ACK flag indicates that &lt;strong&gt;the preceding segment of data has been received correctly&lt;/strong&gt;. Each ACK contains an acknowledgment number (Acknowledgment Number), which represents the next expected byte sequence number. It is a core mechanism for reliable transmission in TCP.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Working principle:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When the sender sends a data segment, it carries the expected receiver&amp;rsquo;s &lt;code&gt;ACK&lt;/code&gt; value (for example, &lt;code&gt;ACK = sequence number + data length&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Upon receiving data, the receiver generates an &lt;code&gt;ACK&lt;/code&gt; segment confirming the received sequence number&lt;/li&gt;
&lt;li&gt;The sender will only retransmit unacknowledged data after receiving the corresponding ACK&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If the sender sends a data segment with sequence number &lt;code&gt;100~199&lt;/code&gt;, the expected &lt;code&gt;ACK&lt;/code&gt; from the receiver should be &lt;code&gt;200&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;If the receiving party fails to receive some of the data within the range of &lt;code&gt;100~199&lt;/code&gt;, it will inform the sending party to retransmit via &lt;code&gt;ACK=150&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;the-combination-of-psh-and-ack&#34;&gt;The combination of PSH and ACK
&lt;/h3&gt;&lt;p&gt;In TCP packets, &lt;code&gt;PSH&lt;/code&gt; and &lt;code&gt;ACK&lt;/code&gt; can appear simultaneously, commonly seen in the following scenarios:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;HTTP request response
When the client sends a &lt;code&gt;POST&lt;/code&gt; request (with data), it sets &lt;code&gt;PSH&lt;/code&gt; and &lt;code&gt;ACK&lt;/code&gt; (acknowledgment of previous responses)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-plaintext&#34;&gt;Client → Server: SYN, ACK=1 → 建立连接
Client → Server: PSH, ACK=1, 数据 → 发送请求数据
Server → Client: PSH, ACK=数据长度+1 → 返回响应
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Transmit commands after SSH handshake
After the client enters a command, it sends a data segment with &lt;code&gt;PSH&lt;/code&gt; and &lt;code&gt;ACK&lt;/code&gt; to ensure that the command is immediately transmitted and processed by the server&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;other-flag-bit-associations&#34;&gt;Other flag bit associations
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Flag&lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Brief Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;SYN Synchronization Initialization Connection (Three-Way Handshake)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;FIN&lt;/td&gt;
&lt;td&gt;End&lt;/td&gt;
&lt;td&gt;Gracefully close connection&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Reset&lt;/td&gt;
&lt;td&gt;Force connection termination (abnormal situation)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mark urgent pointer (rarely used)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;PSH focuses on getting data to the application layer as quickly as possible, reducing latency&lt;/li&gt;
&lt;li&gt;ACK focuses on reliable data transmission, avoiding packet loss or out-of-order delivery&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;They work together to balance the efficiency and reliability of the TCP protocol&lt;/p&gt;</description>
        </item>
        <item>
        <title>Deploy DeepSeek-R1 locally</title>
        <link>https://ttf248.life/en/p/ollama-local-deployment-deepseek-r1/</link>
        <pubDate>Fri, 07 Feb 2025 22:41:02 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/ollama-local-deployment-deepseek-r1/</guid>
        <description>&lt;p&gt;Ollama is an open-source AI tool designed to enable users to run and deploy large language models (LLMs) locally. Its goal is to provide a convenient and efficient way for developers to use models like GPT on their local machines without relying on cloud services. Ollama supports various models and focuses on optimizing performance, ensuring that even resource-constrained devices can run these models smoothly.&lt;/p&gt;
&lt;p&gt;With Ollama, users can use text-based AI applications and interact with locally deployed models without worrying about data privacy or high API usage fees. You can call different models through the command-line interface (CLI) to perform tasks such as natural language processing and question answering.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Ollama is suitable for trying out different models. The Windows version, after testing, doesn&amp;rsquo;t fully utilize the hardware&amp;rsquo;s performance; this may be due to the Windows version itself. The Linux version might be better. When deploying a 32b parameter model, with low memory and GPU load, the response speed is very slow.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;hardware-overview&#34;&gt;Hardware Overview
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Operating system: win11&lt;/li&gt;
&lt;li&gt;CPU：i7-10700K&lt;/li&gt;
&lt;li&gt;Memory: 40GB&lt;/li&gt;
&lt;li&gt;Graphics card: RTX 3060 12GB&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;environmental-preparation&#34;&gt;Environmental preparation
&lt;/h2&gt;&lt;p&gt;Add a new system environment variable for convenient use later&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_MODELS=E:\ollama&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
This variable specifies the storage path for the Ollama model. &lt;code&gt;E:\ollama&lt;/code&gt; is a folder path indicating that all local model files are stored in this directory. Ollama will load and use your downloaded or deployed language models based on this path. You can store the model files in other locations, just change this path.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_HOST=127.0.0.1:8000&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
This environment variable sets the host and port for the Ollama service&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;127.0.0.1&lt;/code&gt; is the local address (localhost), meaning that the Ollama service will only listen for requests from the local machine&lt;/li&gt;
&lt;li&gt;The port number 8000 is the designated port, indicating that the Ollama service will listen for and process requests on port 8000. You can change the port number as needed, but make sure it is not occupied by other applications.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;set OLLAMA_ORIGINS=*&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
This environment variable controls which sources of requests are allowed to access the Ollama service&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;*&lt;/code&gt; indicates that any source (i.e., all domains and IP addresses) is allowed to access the Ollama service. This is typically used in development and debugging environments; in production, you would usually specify stricter source control, limiting access only to specific domains or IPs to improve security.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;deepseek-r1-model-deployment&#34;&gt;DeepSeek-R1 Model Deployment
&lt;/h2&gt;&lt;p&gt;Ollama installation is straightforward and will not be elaborated on here&lt;/p&gt;
&lt;p&gt;Post-installation verification&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core&amp;gt;ollama -v
ollama version is 0.5.11
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Model deployment, refer to the official website model page and select the corresponding parameters for the model: &lt;code&gt;ollama run deepseek-r1:14b&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The 14B parameter model can effectively remember conversation context, while smaller parameter versions cannot. The 32B parameter version is very slow when deployed locally, so I didn&amp;rsquo;t conduct further testing.&lt;/p&gt;
&lt;h2 id=&#34;reference-materials&#34;&gt;Reference materials
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ollama.com/library/deepseek-r1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.ollama.com/library/deepseek-r1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/SPEvYTmTBxhoEkJqm1yPmw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/x18990027/article/details/145368094&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/x18990027/article/details/145368094&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>PowerShell 7 and Persistent Settings Command-Line Prediction View</title>
        <link>https://ttf248.life/en/p/powershell-7-persisting-settings-command-line-prediction-view/</link>
        <pubDate>Fri, 07 Feb 2025 22:19:12 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/powershell-7-persisting-settings-command-line-prediction-view/</guid>
        <description>&lt;p&gt;I&amp;rsquo;m used to zsh on Linux, and when writing a blog post the other day, I suddenly discovered that PowerShell 7 also supports persistent settings for command-line prediction views. So I tried it out, and found it quite useful.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I don&amp;rsquo;t know what operation was performed, but this feature is enabled – it just appeared&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In today&amp;rsquo;s diverse operating system environment, system administrators and developers have been seeking a tool that is cross-platform, efficient, and powerful to meet their needs in system management and automation tasks. PowerShell 7 is precisely such a highly anticipated tool; it not only provides robust scripting capabilities but also enables operation across Windows, Linux, and macOS operating systems, bringing users unprecedented convenience.&lt;/p&gt;
&lt;h2 id=&#34;powershell-7-a-powerful-cross-platform-tool&#34;&gt;PowerShell 7: A Powerful Cross-Platform Tool
&lt;/h2&gt;&lt;h3 id=&#34;cross-platform-features&#34;&gt;Cross-platform features
&lt;/h3&gt;&lt;p&gt;PowerShell 7 breaks platform limitations, allowing users to utilize a single PowerShell 7 tool whether managing enterprise-level servers on Windows systems, performing system maintenance in Linux environments, or tackling everyday development tasks on macOS. This significantly improves work efficiency and reduces the learning curve and operational complexity caused by platform differences.&lt;/p&gt;
&lt;h3 id=&#34;powerful-features&#34;&gt;Powerful features
&lt;/h3&gt;&lt;p&gt;It possesses powerful scripting capabilities, supporting object-oriented programming, functions, modules, and other advanced programming features. Through PowerShell 7, users can easily operate the file system, creating, deleting, copying, and moving files and folders; access and modify the registry to make in-depth adjustments to the system configuration; and manage processes and services to effectively monitor and control the system&amp;rsquo;s running state. In addition, PowerShell 7 can also interact with various Windows and non-Windows technologies, such as user and permission management in Active Directory, resource allocation and management on the Azure cloud platform, etc.&lt;/p&gt;
&lt;h3 id=&#34;open-source-ecosystem&#34;&gt;Open-source ecosystem
&lt;/h3&gt;&lt;p&gt;PowerShell 7 is open-source, a feature that allows developers and enthusiasts worldwide to actively participate in its development and improvement. A large number of open-source modules and tools are constantly emerging, enriching the functionality and application scenarios of PowerShell 7. Users can find suitable modules within the open-source community to extend PowerShell 7&amp;rsquo;s capabilities based on their needs, or contribute their own code to promote the development of the entire community.&lt;/p&gt;
&lt;h3 id=&#34;compatibility-and-stability&#34;&gt;Compatibility and Stability
&lt;/h3&gt;&lt;p&gt;PowerShell 7 introduces many new features and improvements while maintaining compatibility with older versions of PowerShell. These enhancements not only improve performance but also enhance stability, allowing users to complete various tasks more smoothly and reducing work interruptions caused by software failures.&lt;/p&gt;
&lt;h2 id=&#34;open-command-line-prediction-view&#34;&gt;Open command-line prediction view
&lt;/h2&gt;&lt;p&gt;Among the many useful features of PowerShell 7, the &lt;code&gt;Set-PSReadLineOption -PredictionViewStyle ListView&lt;/code&gt; command is a practical tool that can enhance the user&amp;rsquo;s command-line input experience&lt;/p&gt;
&lt;p&gt;Without enabling commands, inline auto-completion is still possible. However, this only provides completion within the current line. When enabled, it offers predictive suggestions displayed as a list of all potential options. Users can select the desired option using up and down arrow keys, thereby improving the accuracy and efficiency of command input.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/powershell-7-persisting-settings-command-line-prediction-view/20250207222546.png&#34;
	width=&#34;814&#34;
	height=&#34;205&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;powershell7&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;397&#34;
		data-flex-basis=&#34;952px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;how-to-make-commands-persistent&#34;&gt;How to make commands persistent
&lt;/h2&gt;&lt;p&gt;To ensure that the &lt;code&gt;Set-PSReadLineOption -PredictionViewStyle ListView&lt;/code&gt; command takes effect every time PowerShell starts, we can add it to PowerShell&amp;rsquo;s profile. A PowerShell profile is a special script that automatically executes its commands when PowerShell starts.&lt;/p&gt;
&lt;h3 id=&#34;confirm-configuration-file-path&#34;&gt;Confirm configuration file path
&lt;/h3&gt;&lt;p&gt;In PowerShell, we can use the &lt;code&gt;$PROFILE&lt;/code&gt; variable to view the configuration file path. If the file does not exist at that path, users can manually create one.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;echo $PROFILE
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;open-the-configuration-file&#34;&gt;Open the configuration file
&lt;/h3&gt;&lt;p&gt;Open the file corresponding to the configuration file path obtained through the &lt;code&gt;$PROFILE&lt;/code&gt; variable using a text editor, such as the powerful Notepad++ or the lightweight Visual Studio Code&lt;/p&gt;
&lt;h3 id=&#34;add-command&#34;&gt;Add command
&lt;/h3&gt;&lt;p&gt;In the open configuration file, add the command &lt;code&gt;Set-PSReadLineOption -PredictionViewStyle ListView&lt;/code&gt;. Ensure the command is written accurately to guarantee that the configuration takes effect correctly when executed.&lt;/p&gt;
&lt;h3 id=&#34;save-configuration-file&#34;&gt;Save configuration file
&lt;/h3&gt;&lt;p&gt;After completing the command addition, save the configuration file and close the text editor. At this point, the configuration file already contains the commands we want to execute each time PowerShell starts.&lt;/p&gt;
&lt;h3 id=&#34;verification-settings&#34;&gt;Verification Settings
&lt;/h3&gt;&lt;p&gt;Close the current PowerShell window and restart PowerShell. In the newly started PowerShell, when entering commands, the command-line input prediction view style should be displayed in list view, indicating that our settings have taken effect successfully.&lt;/p&gt;
&lt;p&gt;Through the above steps, we not only gained a deeper understanding of the powerful features and capabilities of PowerShell 7, but also learned how to enhance the user experience by setting command-line input prediction views, and how to make these settings persistent. We hope this knowledge will help you become more proficient in using PowerShell 7 and efficiently complete various system management and automation tasks.&lt;/p&gt;
&lt;h2 id=&#34;reference-materials&#34;&gt;Reference materials
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/PowerShell/PowerShell/releases&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/PowerShell/PowerShell/releases&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.v2ex.com/t/911909&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.v2ex.com/t/911909&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>A Complete Guide to Monitoring Linux System Metrics with the atop Tool: Installation, Configuration, and Usage</title>
        <link>https://ttf248.life/en/p/using-atop-to-monitor-linux-system-metrics-installation-configuration-and-usage-guide/</link>
        <pubDate>Thu, 06 Feb 2025 22:48:55 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/using-atop-to-monitor-linux-system-metrics-installation-configuration-and-usage-guide/</guid>
        <description>&lt;p&gt;Real-time and comprehensive monitoring of system resources and process status is crucial in Linux system maintenance. As a powerful monitoring tool, atop can help us easily achieve this goal. This article will detail how to install, configure, and use the atop monitoring tool on a Linux instance.&lt;/p&gt;
&lt;h2 id=&#34;introduction-to-atop-tool&#34;&gt;Introduction to atop tool
&lt;/h2&gt;&lt;p&gt;Atop is a tool specifically designed for monitoring Linux system resources and processes. It records system and process activity, reporting the status of all running processes. The data collected covers resource usage such as CPU, memory, disk, and network, as well as process states. This data can also be saved to disk in log file format. For each process, we can obtain key information such as CPU utilization, memory growth, disk usage, priority, username, status, and exit code. Furthermore, through the atop configuration file, we can customize parameters such as logging frequency, log file storage path, and rotation policy.&lt;/p&gt;
&lt;h2 id=&#34;ii-installing-the-atop-tool&#34;&gt;II. Installing the atop tool
&lt;/h2&gt;&lt;p&gt;The installation methods of atop vary slightly across different Linux distributions; the following introduces it using a common operating system as an example&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Alibaba Cloud Linux 3/2、CentOS 7/8、Fedora、Rocky Linux 9&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Execute installation command: &lt;code&gt;sudo yum install -y atop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ubuntu / Debian&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Update software sources: &lt;code&gt;sudo apt update&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Execute the installation command: &lt;code&gt;sudo apt install -y atop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;CentOS Stream 9&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download and install: &lt;code&gt;sudo wget https://www.atoptool.nl/download/atop-2.11.0-1.el9.x86_64.rpm &amp;amp;&amp;amp; sudo rpm -i atop-2.11.0-1.el9.x86_64.rpm&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;openSUSE&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Execute installation command: &lt;code&gt;sudo zypper install -y atop atop-daemon&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the atop service: &lt;code&gt;sudo systemctl start atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If the operating systems listed above do not include your distribution, you can visit the atop official website for installation information&lt;/p&gt;
&lt;h2 id=&#34;iii-configuring-monitoring-cycle-and-log-retention-time&#34;&gt;III. Configuring Monitoring Cycle and Log Retention Time
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Configuration file location: On Alibaba Cloud Linux 3/2, CentOS 7/8, and Fedora systems, the atop configuration file is /etc/sysconfig/atop; on Ubuntu, Debian, and openSUSE systems, the configuration file is /etc/default/atop&lt;/li&gt;
&lt;li&gt;Default Configuration Parameters Description
&lt;ul&gt;
&lt;li&gt;LOGOPTS: Used to control log file recording options, defaults to empty&lt;/li&gt;
&lt;li&gt;The monitoring cycle, default is 600 seconds. If you need to collect historical logs to track issues, adjust this frequency according to your actual needs.&lt;/li&gt;
&lt;li&gt;LOGGENERATIONS: Log retention time, default 28 days&lt;/li&gt;
&lt;li&gt;LOGPATH: The path where log files are stored, default /var/log/atop&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Configuration Steps
&lt;ul&gt;
&lt;li&gt;Execute the command to open the configuration file:
&lt;ul&gt;
&lt;li&gt;On Alibaba Cloud Linux 3/2, CentOS 7/8, Fedora systems: &lt;code&gt;sudo vim /etc/sysconfig/atop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;In Ubuntu, Debian, openSUSE, CentOS Stream 9, Rocky Linux 9 systems: &lt;code&gt;sudo vim /etc/default/atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;i&lt;/code&gt; to enter edit mode and adjust configuration parameters as needed. For example, change the monitoring cycle to 30 seconds, set the log retention time to 7 days, and keep the log path at its default setting:&lt;/li&gt;
&lt;li&gt;Press the &lt;code&gt;Esc&lt;/code&gt; key, enter &lt;code&gt;:wq&lt;/code&gt;, save and exit editing&lt;/li&gt;
&lt;li&gt;Restarting the atop service will apply the configuration: &lt;code&gt;sudo systemctl restart atop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;LOGOPTS=&amp;quot;&amp;quot;
LOGINTERVAL=30
LOGGENERATIONS=7
LOGPATH=/var/log/atop 
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;four-using-the-atop-tool&#34;&gt;Four, Using the atop tool
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Introduction to Common Commands: In interactive command mode, the following are common commands:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Switch back to the default composite output view&lt;/li&gt;
&lt;li&gt;Displays the full command line of processes&lt;/li&gt;
&lt;li&gt;Sort by process memory usage in descending order&lt;/li&gt;
&lt;li&gt;Sort by process disk usage in descending order&lt;/li&gt;
&lt;li&gt;Sort in descending order based on the comprehensive utilization rate of processes and resources&lt;/li&gt;
&lt;li&gt;Sort by process network usage in descending order&lt;/li&gt;
&lt;li&gt;Go to the next monitoring point&lt;/li&gt;
&lt;li&gt;Go to the previous monitoring point&lt;/li&gt;
&lt;li&gt;b: Specifies a point in time, formatted as &lt;code&gt;YYYYMMDDhhmm&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Introduction to Resource Monitoring Fields&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Host name, information sampling date and time&lt;/li&gt;
&lt;li&gt;Overall process runtime status, including kernel and user space running time, total number of processes, and the number of processes in different states&lt;/li&gt;
&lt;li&gt;The CPU utilization shows the overall usage, with each field&amp;rsquo;s numerical sum resulting in &lt;code&gt;N*100%&lt;/code&gt; (where N is the number of CPU cores), including kernel time, user time, interrupt time, idle time, and wait for disk I/O time proportions&lt;/li&gt;
&lt;li&gt;CPL: CPU load information, such as the average number of processes in the run queue over the past 1 minute, 5 minutes, and 15 minutes, context switch count, and interrupt occurrence count&lt;/li&gt;
&lt;li&gt;MEM: Memory usage, including total physical memory, idle memory, page cache memory, file cache memory, and kernel occupied memory&lt;/li&gt;
&lt;li&gt;SWP: Swap space usage, including total swap area and free swap space size&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PAG&lt;/strong&gt;: Virtual memory paging status, such as the number of pages swapped in and out&lt;/li&gt;
&lt;li&gt;DSK: Disk Usage, each disk device corresponds to a row, displaying device identifier, busy time ratio, and read/write request count&lt;/li&gt;
&lt;li&gt;NET: Network conditions, displaying receive and send packet sizes for the transport layer TCP and UDP, IP layer, and active network interfaces&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;View real-time system metrics&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Check system metrics every 5 seconds: &lt;code&gt;atop 5&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Check system metrics within the next 5 minutes (total of 30 times, with a 10-second interval): &lt;code&gt;atop -M 10 30&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Check system metrics after 10 minutes (10 times, with a 60-second interval) and write the results to a file: &lt;code&gt;atop -M 60 10 &amp;gt; /log/atop.mem&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To view historical indicator logs: After atop starts, the collection records are stored by default in the &lt;code&gt;/var/log/atop&lt;/code&gt; directory. When viewing, be sure to check that the log file for the specified date exists; otherwise, an error will occur.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;View daily history indicators log: &lt;code&gt;atop -r&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View yesterday&amp;rsquo;s historical indicator logs: &lt;code&gt;atop -r y&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View historical indicator logs for a specified date, such as November 6, 2024: &lt;code&gt;atop -r 20241106&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View historical indicator logs from a specified time within a specified date, such as starting at 14:00 on November 6, 2024: &lt;code&gt;atop -r 20241106 -b 14:00&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View the historical indicator logs for a specified time period within a specific date, such as November 5, 2024 from 00:04 to 00:08: &lt;code&gt;atop -r 20241105 -b 00:04 -e 00:08&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;View System Activity Report&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Check the CPU utilization report of the current system within 1 minute (12 times, interval 5 seconds): &lt;code&gt;atopsar -c 5 12&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;To view the memory metrics report for a specified time period on that day, such as from 18:00 to 18:01: &lt;code&gt;atopsar -m -b 18:00 -e 18:01&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;View memory metrics reports for a specified date and time period, such as November 5, 2024, from 18:00 to 18:01: &lt;code&gt;atopsar -m -r 20241105 -b 18:00 -e 18:01&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;v-other-operations&#34;&gt;V. Other Operations
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Configure a Tian-level log rotation policy: If you want to generate an atop index log file every day, you can perform the following operations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(Optional) Adjust the monitoring cycle, log retention time, and log storage path as needed&lt;/li&gt;
&lt;li&gt;Run command to set daily log rotation related services to start on boot and start the services: &lt;code&gt;sudo systemctl enable --now atop atopacct atop-rotate.timer&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;If the business has more complex requirements for log processing, it can be combined with logrotate or custom scripts to implement log management&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Load the optional netatop kernel module: If you need to monitor network usage, you can install the netatop module (this module is not installed by default in atop). Taking Alibaba Cloud Linux 3 as an example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Install the kernel development package and software environment required for compilation: &lt;code&gt;sudo yum install -y kernel-devel dkms elfutils-libelf-devel&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Download the latest version of netatop source code to a designated directory: &lt;code&gt;cd /usr/src/ &amp;amp;&amp;amp; sudo wget https://www.atoptool.nl/download/netatop-3.2.2.tar.gz --no-check-certificate&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Extract the source code and enter the source directory: &lt;code&gt;sudo tar -zxvf netatop-3.2.2.tar.gz &amp;amp;&amp;amp; cd netatop-3.2.2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Build and install the module and daemon from source code: &lt;code&gt;sudo make &amp;amp;&amp;amp; sudo make install&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start the netatop service: &lt;code&gt;sudo systemctl start netatop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The atop tool is powerful and flexible. With proper installation, configuration, and usage, we can better understand the operating status of the Linux system, promptly discover and resolve potential issues. We hope this article will help everyone improve their skills in Linux system monitoring.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;[atop official website]&lt;/li&gt;
&lt;li&gt;Installing, Configuring, and Using the atop Monitoring Tool&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Loading mismatched PDB files in Visual Studio</title>
        <link>https://ttf248.life/en/p/visual-studio-loading-unmatched-pdb-files/</link>
        <pubDate>Thu, 23 Jan 2025 20:04:33 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/visual-studio-loading-unmatched-pdb-files/</guid>
        <description>&lt;p&gt;When debugging a program in Visual Studio on Windows, if the PDB file does not match the executable file, Visual Studio will prompt &amp;ldquo;Unable to load symbol file.&amp;rdquo; If the program crashes and a crash dump file is generated, Visual Studio may also fail to smoothly enter the crash site if the PDB file is mismatched&lt;/p&gt;
&lt;h2 id=&#34;what-is-a-pdb-file&#34;&gt;What is a pdb file?
&lt;/h2&gt;&lt;p&gt;PDB files are debugging information files created by Microsoft, used for debugging programs. They contain information such as program symbol tables, source file names, and line numbers. PDB files can be generated during program compilation for debugging purposes.&lt;/p&gt;
&lt;h2 id=&#34;debugging-with-windbg&#34;&gt;Debugging with WinDbg
&lt;/h2&gt;&lt;p&gt;WinDbg is a debugging tool from Microsoft that can be used to debug Windows programs. WinDbg can load mismatched PDB files, but they need to be loaded manually. The &lt;code&gt;.reload /f /i&lt;/code&gt; command can force the loading of mismatched PDB files.&lt;/p&gt;
&lt;p&gt;However, WinDbg is not as convenient to use as Visual Studio, so we hope that Visual Studio can also load mismatched PDB files&lt;/p&gt;
&lt;h2 id=&#34;visual-studio-loading-mismatched-pdb-file&#34;&gt;Visual Studio loading mismatched PDB file
&lt;/h2&gt;&lt;p&gt;Source code is generally managed through git now, so it&amp;rsquo;s possible to find the corresponding version of the code, recompile it, and generate the corresponding pdb file. Why can’t it be loaded? It’s mainly due to metadata mismatches.&lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s a small tool that can modify metadata, generate a new PDB file based on the executable file information, allowing Visual Studio to load it&lt;/p&gt;
&lt;p&gt;chkmatch download address: [https://www.debuginfo.com/tools/chkmatch.html]&lt;/p&gt;
&lt;p&gt;Site cache address: &lt;a class=&#34;link&#34; href=&#34;chkmatch.zip&#34; &gt;chkmatch.zip&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;ChkMatch utility can be used to check whether an executable and debug information file match. It can also be used to enforce matching between an executable and debug information file, if they are compatible.

For more information about debug information matching and related issues, see this article.

Supported debug information formats: DBG, PDB 2.0, PDB 7.0.

chkmatch [-c ExeFile DebugInfoFile ] |
         [-m ExeFile DebugInfoFile]
-c
Check matching between the executable and the debug information file.
-m
Make the executable and the debug information file match.
ExeFile
The name of the executable file.
DebugInfoFile
The name of the debug information file.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;use-chkmatch&#34;&gt;Use chkmatch
&lt;/h2&gt;&lt;p&gt;First, perform a verification check, analyze the reason for the mismatch, and prompt that the signature does not match&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\tianlong.xiang\Downloads\chkmatch&amp;gt;ChkMatch.exe -c &amp;quot;D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe&amp;quot; E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb
ChkMatch - version 1.0
Copyright (C) 2004 Oleg Starodumov
http://www.debuginfo.com/


Executable: D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe
Debug info file: E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb

Executable:
TimeDateStamp: c26d9be3
Debug info: 2 ( CodeView )
TimeStamp: f86b0a4f  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 122  RVA: 001cdc44  FileOffset: 001cbe44
CodeView format: RSDS
Signature: {428c9b95-39a3-4a8d-a8e5-7be453684757}  Age: 1
PdbFile: D:\stock_UAT\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\obj\Release\YinTrade.Main.pdb
Debug info: 16 ( Unknown )
TimeStamp: 00000000  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 0  RVA: 00000000  FileOffset: 00000000

Debug information file:
Format: PDB 7.00
Signature: {06fae08e-c0a2-4f3d-9c7c-dfc684445dd1}  Age: 1

Result: Unmatched (reason: Signature mismatch)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then perform modification operations to make the PDB file match the EXE file&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\tianlong.xiang\Downloads\chkmatch&amp;gt;ChkMatch.exe -m &amp;quot;D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe&amp;quot; E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb
ChkMatch - version 1.0
Copyright (C) 2004 Oleg Starodumov
http://www.debuginfo.com/


Executable: D:\Program Files\Rolan\trade\UAT_YinStrade\YinTrade.Main.exe
Debug info file: E:\YinTech\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\bin\Release\YinTrade.Main.pdb

Executable:
TimeDateStamp: c26d9be3
Debug info: 2 ( CodeView )
TimeStamp: f86b0a4f  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 122  RVA: 001cdc44  FileOffset: 001cbe44
CodeView format: RSDS
Signature: {428c9b95-39a3-4a8d-a8e5-7be453684757}  Age: 1
PdbFile: D:\stock_UAT\ykcz_securities_trading_client\Sec_Trade\YinTrade.Main\obj\Release\YinTrade.Main.pdb
Debug info: 16 ( Unknown )
TimeStamp: 00000000  Characteristics: 0  MajorVer: 0  MinorVer: 0
Size: 0  RVA: 00000000  FileOffset: 00000000

Debug information file:
Format: PDB 7.00
Signature: {06fae08e-c0a2-4f3d-9c7c-dfc684445dd1}  Age: 1

Writing to the debug information file...
Result: Success.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;reference-materials&#34;&gt;Reference materials
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://stackoverflow.com/questions/38147487/forcing-to-load-unmatched-symbols-in-visual-studio-2015-debugger&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;forcing-to-load-unmatched-symbols-in-visual-studio-2015-debugger&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Cursor AI programming IDE trial</title>
        <link>https://ttf248.life/en/p/cursor-ai-programming-ide-trial/</link>
        <pubDate>Thu, 23 Jan 2025 19:30:13 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cursor-ai-programming-ide-trial/</guid>
        <description>&lt;p&gt;Another year has gone by. The biggest change at work is the noticeably increased involvement of AI. Previously, switching between different development languages required developers to be familiar with various languages&amp;rsquo; distinct APIs. Now, these basic codes can all be generated through AI, which is a great boon for developers.&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;Back in 2023, I revised two simple introductory articles. Now it&amp;rsquo;s 2025, and honestly, I haven’t perceived any significant progress. It still requires developing your own understanding, being able to reasonably break down tasks, and most importantly, identifying whether there are bugs in the AI-generated code.&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;Github copilot
&lt;/h2&gt;&lt;p&gt;I forgot what day it is, but I saw in the documentation that Singapore deployed servers. For domestic use, we no longer need to constantly use a VPN. Of course, you still need a VPN to log in, but this VPN only needs to be used once for login and can then be turned off.&lt;/p&gt;
&lt;p&gt;I use Github Copilot more often on a daily basis; this plugin can be used directly in VS Code and Visual Studio, without switching between the two programs. Compared to ChatGPT, Github Copilot offers better project support and a friendlier interaction. You can choose parts of local files to &amp;ldquo;train&amp;rdquo; the AI, so the generated code is more aligned with your project.&lt;/p&gt;
&lt;h2 id=&#34;cursor-ai&#34;&gt;Cursor AI
&lt;/h2&gt;&lt;p&gt;I recently saw a new AI programming IDE, Cursor AI. This IDE is also based on GitHub Copilot, but this IDE is even more intelligent and can help you create files directly.&lt;/p&gt;
&lt;p&gt;I tried it briefly, and it feels pretty good, but my understanding of the existing project is still not enough. When there are many local project files, large refactoring and optimization adjustments still require &lt;strong&gt;developers to break down tasks&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s an example: Switch to curso’s engineering mode, enter the following content: Create a personal resume webpage that supports switching between multiple different styles. Remember to fill in some personal information for data display.&lt;/p&gt;
&lt;p&gt;After a few back-and-forths, you can obtain the following webpage. Of course, this webpage is still relatively simple, but it&amp;rsquo;s quite good for beginners.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Currently, registered users can enjoy 150 free trials of the advanced API, while paying users are limited to 5000 calls&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Resume&lt;/p&gt;</description>
        </item>
        <item>
        <title>C&#43;&#43; Bitwise Operations Basics: Bit Extraction and Flag Setting</title>
        <link>https://ttf248.life/en/p/cpp-bitwise-operations-basics-flags/</link>
        <pubDate>Fri, 17 Jan 2025 02:23:56 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-bitwise-operations-basics-flags/</guid>
        <description>&lt;p&gt;In practical C++ development, bit operations are a common technique, especially when dealing with system states, flags, or control bits. Bit operations can provide very efficient solutions. This article will explain how to use bit operations to get and set specific flag bits through an example.&lt;/p&gt;
&lt;h3 id=&#34;basic-operating-concepts&#34;&gt;Basic operating concepts
&lt;/h3&gt;&lt;p&gt;In computers, data is stored in binary digits (bits) of 0 and 1. Bitwise operations are operations performed on these binary digits. C++ has several commonly used bitwise operators:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bitwise AND (&amp;amp;): Used to check if a bit is 1&lt;/li&gt;
&lt;li&gt;Bitwise OR (|): Used to set a bit to 1&lt;/li&gt;
&lt;li&gt;XOR (exclusive OR) by bit: Used to invert a specific bit&lt;/li&gt;
&lt;li&gt;Bitwise NOT (~) : Inverts all bits&lt;/li&gt;
&lt;li&gt;Shift all bits left by several positions&lt;/li&gt;
&lt;li&gt;Shifts all bits to the right by several positions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this example, we need to perform a series of bit operations on an &lt;code&gt;unsigned short&lt;/code&gt; type variable &lt;code&gt;wInfo&lt;/code&gt;, using different flag bits to represent different states&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;flowchart LR
    A[原始数值: 00010000] --&amp;gt; B[左移: 00010000 &amp;lt;&amp;lt; 1]
    B --&amp;gt; C[结果: 00100000]
    C --&amp;gt; D[右移: 00100000 &amp;gt;&amp;gt; 1]
    D --&amp;gt; E[结果: 00010000]

    subgraph 左移操作
        direction LR
        A --&amp;gt; B --&amp;gt; C
    end

    subgraph 右移操作
        direction LR
        C --&amp;gt; D --&amp;gt; E
    end
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;requirements-analysis&#34;&gt;Requirements Analysis
&lt;/h3&gt;&lt;p&gt;According to the description in the question, we have a 16-bit flag used to represent different states. These states are represented by various binary bits, each corresponding to a specific meaning. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Has bit0 failed?&lt;/li&gt;
&lt;li&gt;Is bit1 compressed?&lt;/li&gt;
&lt;li&gt;Is bit2 incremental?&lt;/li&gt;
&lt;li&gt;Does bit3 have any follow-up packages?&lt;/li&gt;
&lt;li&gt;Normal request or logout&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;implement-using-bit-operations&#34;&gt;Implement using bit operations
&lt;/h3&gt;&lt;p&gt;We will use bit operations to set and get these flag bits. Specifically:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Extracting bit values: Obtain the value of a specific bit (0 or 1)&lt;/li&gt;
&lt;li&gt;Set a bit to 1&lt;/li&gt;
&lt;li&gt;Set a bit to 0&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We first define an &lt;code&gt;unsigned short&lt;/code&gt; type variable &lt;code&gt;wInfo&lt;/code&gt; to store these flags. Then, we use bit operations to check and set the corresponding flags.&lt;/p&gt;
&lt;h3 id=&#34;c-example-code&#34;&gt;C++ example code
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;bitset&amp;gt;

// 定义标志位常量
const unsigned short BIT_0_FAIL = 1 &amp;lt;&amp;lt; 0;    // bit0 是否失败
const unsigned short BIT_1_COMPRESSED = 1 &amp;lt;&amp;lt; 1; // bit1 是否压缩
const unsigned short BIT_2_INCREMENT = 1 &amp;lt;&amp;lt; 2;  // bit2 是否增量
const unsigned short BIT_3_HAS_MORE = 1 &amp;lt;&amp;lt; 3;   // bit3 是否有后续包
const unsigned short BIT_5_CANCEL = 1 &amp;lt;&amp;lt; 5;     // bit5 正常请求(0)或注销(1)

// 检查某一位是否为1
bool isBitSet(unsigned short wInfo, unsigned short bitMask) {
    return (wInfo &amp;amp; bitMask) != 0;
}

// 设置某一位为1
void setBit(unsigned short&amp;amp; wInfo, unsigned short bitMask) {
    wInfo |= bitMask;
}

// 清除某一位（设置为0）
void clearBit(unsigned short&amp;amp; wInfo, unsigned short bitMask) {
    wInfo &amp;amp;= ~bitMask;
}

int main() {
    // 假设wInfo的初始值为0
    unsigned short wInfo = 0;

    // 设置bit0（失败标志）
    setBit(wInfo, BIT_0_FAIL);
    
    // 设置bit1（压缩标志）
    setBit(wInfo, BIT_1_COMPRESSED);
    
    // 打印wInfo的二进制值
    std::cout &amp;lt;&amp;lt; &amp;quot;wInfo (in binary): &amp;quot; &amp;lt;&amp;lt; std::bitset&amp;lt;16&amp;gt;(wInfo) &amp;lt;&amp;lt; std::endl;

    // 检查各个标志位
    std::cout &amp;lt;&amp;lt; &amp;quot;bit0 (是否失败): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_0_FAIL) ? &amp;quot;是&amp;quot; : &amp;quot;否&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit1 (是否压缩): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_1_COMPRESSED) ? &amp;quot;是&amp;quot; : &amp;quot;否&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit2 (是否增量): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_2_INCREMENT) ? &amp;quot;是&amp;quot; : &amp;quot;否&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit3 (是否有后续包): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_3_HAS_MORE) ? &amp;quot;是&amp;quot; : &amp;quot;否&amp;quot;) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;bit5 (是否注销): &amp;quot; &amp;lt;&amp;lt; (isBitSet(wInfo, BIT_5_CANCEL) ? &amp;quot;是&amp;quot; : &amp;quot;否&amp;quot;) &amp;lt;&amp;lt; std::endl;

    // 清除bit1（压缩标志）
    clearBit(wInfo, BIT_1_COMPRESSED);
    
    // 打印更新后的wInfo
    std::cout &amp;lt;&amp;lt; &amp;quot;Updated wInfo (in binary): &amp;quot; &amp;lt;&amp;lt; std::bitset&amp;lt;16&amp;gt;(wInfo) &amp;lt;&amp;lt; std::endl;

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Execute code, recommended by an old friend: &lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;wInfo (in binary): 0000000000000011
bit0 (是否失败): 是
bit1 (是否压缩): 是
bit2 (是否增量): 否
bit3 (是否有后续包): 否
bit5 (是否注销): 否
Updated wInfo (in binary): 0000000000000001
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;code-explanation&#34;&gt;Code explanation
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Flag bits are defined using bit shift operations (&lt;code&gt;1 &amp;lt;&amp;lt; n&lt;/code&gt;). For example, &lt;code&gt;1 &amp;lt;&amp;lt; 0&lt;/code&gt; corresponds to &lt;code&gt;bit0&lt;/code&gt;, &lt;code&gt;1 &amp;lt;&amp;lt; 1&lt;/code&gt; corresponds to &lt;code&gt;bit1&lt;/code&gt;, and so on. This assigns a unique binary position to each flag bit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;code&gt;isBitSet&lt;/code&gt; function checks if a specific flag is set to 1 by performing a bitwise AND operation &lt;code&gt;wInfo &amp;amp; bitMask&lt;/code&gt;. If the bit is 1, the function returns &lt;code&gt;true&lt;/code&gt;; otherwise, it returns &lt;code&gt;false&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;code&gt;setBit&lt;/code&gt; function sets a specific flag to 1 using a bitwise OR operation &lt;code&gt;wInfo |= bitMask&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;code&gt;clearBit&lt;/code&gt; function sets a specific flag to 0 using a bitwise AND operation: &lt;code&gt;wInfo &amp;amp;= ~bitMask&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary
&lt;/h3&gt;&lt;p&gt;Through bit manipulation, we can efficiently handle multiple status flag bits. This technique is particularly useful in practical development. For example, it is often used in scenarios such as embedded development, network protocols, and system state management, where bit flags are used to represent multiple binary states, saving space and improving efficiency.&lt;/p&gt;
&lt;p&gt;I hope this blog helps you understand how to use bitwise operations in C++ to achieve bit extraction and setting. Mastering these skills is very helpful for writing efficient and maintainable code!&lt;/p&gt;</description>
        </item>
        <item>
        <title>Desktop upgrade to 2.5G network card, accelerating local area network interconnection</title>
        <link>https://ttf248.life/en/p/desktop-upgrade-to-25g-network-card-accelerate-lan-interconnection/</link>
        <pubDate>Fri, 10 Jan 2025 00:37:52 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/desktop-upgrade-to-25g-network-card-accelerate-lan-interconnection/</guid>
        <description>&lt;p&gt;We previously mentioned the PCIe adapter for solid-state drives, so where did the old SSDs go? They weren&amp;rsquo;t wasted; they were removed and installed in the &lt;code&gt;Mechanical Master Creator Mini-3765H&lt;/code&gt; (purchased a year ago)&lt;/p&gt;
&lt;p&gt;The new machine still has impressive hardware specs: 2.5G dual network ports, PCIE4.0, and WiFi6&lt;/p&gt;
&lt;p&gt;Recently moved, and the room doesn&amp;rsquo;t have a separate router for networking. The machines are all connected via wireless network. The ASUS motherboard desktop’s wireless card performance isn’t good enough, or it could be due to the router&amp;rsquo;s wireless access; the upload speed between local area networks is poor, which results in slow speeds between the machines. I purchased a 2.5G network card and installed it on the desktop.&lt;/p&gt;
&lt;p&gt;At this point, all of the motherboard&amp;rsquo;s slots are used up: graphics card, wireless network card, 2.5G network card, and a solid-state drive PCIe adapter&lt;/p&gt;
&lt;h2 id=&#34;network-instructions&#34;&gt;Network instructions
&lt;/h2&gt;&lt;p&gt;The two machines still use the original wireless network card for internet access, but they are directly connected with a network cable, and both ends have 2.5G network cards. How to connect the two machines with a network cable doesn&amp;rsquo;t need much explanation; there are many tutorials online. Remember to disable the firewall. You can choose either machine as the gateway.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TD;
    A[机器1&amp;lt;br&amp;gt;IP: 192.168.4.1&amp;lt;br&amp;gt;子网掩码: 255.255.255.0&amp;lt;br&amp;gt;默认网关: - &amp;lt;br&amp;gt;自动获取DNS] --&amp;gt;|网线直连（2.5G）| B[机器2&amp;lt;br&amp;gt;IP: 192.168.4.2&amp;lt;br&amp;gt;子网掩码: 255.255.255.0&amp;lt;br&amp;gt;默认网关: 192.168.4.1&amp;lt;br&amp;gt;自动获取DNS];
    A --&amp;gt;|无线网卡| Internet;
    B --&amp;gt;|无线网卡| Internet;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;speed-test-of-two-network-segments&#34;&gt;Speed test of two network segments
&lt;/h2&gt;&lt;h3 id=&#34;router-local-area-network&#34;&gt;Router local area network
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core\Desktop\iperf-3.1.3-win32&amp;gt;iperf3.exe -c 192.168.3.237
Connecting to host 192.168.3.237, port 5201
[  4] local 192.168.3.122 port 1656 connected to 192.168.3.237 port 5201
[ ID] Interval           Transfer     Bandwidth
[  4]   0.00-1.00   sec  9.17 MBytes  76.7 Mbits/sec
[  4]   1.00-2.00   sec  9.91 MBytes  83.2 Mbits/sec
[  4]   2.00-3.00   sec  8.74 MBytes  73.3 Mbits/sec
[  4]   3.00-4.00   sec  10.2 MBytes  85.2 Mbits/sec
[  4]   4.00-5.00   sec  9.23 MBytes  77.1 Mbits/sec
[  4]   5.00-6.00   sec  8.80 MBytes  73.9 Mbits/sec
[  4]   6.00-7.01   sec  8.00 MBytes  66.8 Mbits/sec
[  4]   7.01-8.00   sec  7.69 MBytes  64.9 Mbits/sec
[  4]   8.00-9.01   sec  9.72 MBytes  81.1 Mbits/sec
[  4]   9.01-10.01  sec  7.63 MBytes  63.6 Mbits/sec
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bandwidth
[  4]   0.00-10.01  sec  89.0 MBytes  74.6 Mbits/sec                  sender
[  4]   0.00-10.01  sec  89.0 MBytes  74.6 Mbits/sec                  receiver

iperf Done.
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;direct-lan-connection&#34;&gt;Direct LAN connection
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;C:\Users\core\Desktop\iperf-3.1.3-win32&amp;gt;iperf3.exe -c 192.168.4.1
Connecting to host 192.168.4.1, port 5201
[  4] local 192.168.4.2 port 1524 connected to 192.168.4.1 port 5201
[ ID] Interval           Transfer     Bandwidth
[  4]   0.00-1.01   sec   178 MBytes  1.48 Gbits/sec
[  4]   1.01-2.00   sec   204 MBytes  1.72 Gbits/sec
[  4]   2.00-3.00   sec   214 MBytes  1.80 Gbits/sec
[  4]   3.00-4.00   sec   229 MBytes  1.92 Gbits/sec
[  4]   4.00-5.00   sec   202 MBytes  1.69 Gbits/sec
[  4]   5.00-6.00   sec   213 MBytes  1.79 Gbits/sec
[  4]   6.00-7.00   sec   230 MBytes  1.93 Gbits/sec
[  4]   7.00-8.00   sec   192 MBytes  1.61 Gbits/sec
[  4]   8.00-9.00   sec   220 MBytes  1.84 Gbits/sec
[  4]   9.00-10.00  sec   230 MBytes  1.93 Gbits/sec
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bandwidth
[  4]   0.00-10.00  sec  2.06 GBytes  1.77 Gbits/sec                  sender
[  4]   0.00-10.00  sec  2.06 GBytes  1.77 Gbits/sec                  receiver

iperf Done.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;reference-materials&#34;&gt;Reference materials
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Adding Mermaid Support to Hugo&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Occasional disk recognition issues due to too many disks installed on ASUS Z490 motherboards</title>
        <link>https://ttf248.life/en/p/asus-motherboard-z490-too-many-disks-intermittent-disk-recognition/</link>
        <pubDate>Fri, 10 Jan 2025 00:08:51 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/asus-motherboard-z490-too-many-disks-intermittent-disk-recognition/</guid>
        <description>&lt;p&gt;Following on from the previous discussion, I encountered a problem where the wireless network card was not being recognized. Before rebuilding the partitions, I also searched online for other solutions, such as removing the motherboard battery and disconnecting power for fifteen minutes; or upgrading to the latest BOIS driver, but all of these had issues.&lt;/p&gt;
&lt;p&gt;Thinking there were still things to deal with, I switched to a limited network and ran the ethernet cable from the living room to the room. At this point, another problem arose – the wired network couldn&amp;rsquo;t be recognized either. I tried a drastic measure of reinstalling the system, which resulted in a missing partition error. If these problems consistently occurred, I wouldn’t have bothered troubleshooting for so long. This ASUS disk conflict is intermittent and triggered by unstable system restarts.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The desktop computer had a new disk added last week, a 2TB solid-state drive from Yangtze Memory (YMTC), M.2 interface. It hasn&amp;rsquo;t been restarted since then until yesterday when it was shut down once.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Disk Family Portrait&lt;/p&gt;
&lt;h2 id=&#34;reinstall-system&#34;&gt;Reinstall system
&lt;/h2&gt;&lt;p&gt;It&amp;rsquo;s been two years since I last reinstalled the system. The C drive is full, and Windows has its usual problems – various software likes to save things on the C drive. So, I decided to reinstall the system. After reinstalling the system, the network card issues were resolved normally. The next day, I restored my development environment and prepared to back up the system. That&amp;rsquo;s when a new problem arose: after restarting the system, the boot partition was lost.&lt;/p&gt;
&lt;p&gt;Following the steps in the previous article, I rebuilt the boot partition, but it&amp;rsquo;s not very stable. After restarting, the boot partition might fail to load at any time. I started suspecting issues with the computer case, when I noticed the hard drive cable was loose, but after checking several times, there’s no problem.&lt;/p&gt;
&lt;h2 id=&#34;memory-revival&#34;&gt;Memory revival
&lt;/h2&gt;&lt;p&gt;Many years ago, this machine had an SSD installed once. At that time, I bought a PCIe adapter (plugged into the graphics card slot) instead of installing the drive directly on the motherboard. This time, installing it directly on the motherboard might be due to a problem with the motherboard.&lt;/p&gt;
&lt;p&gt;Solid-state transformer&lt;/p&gt;
&lt;h2 id=&#34;motherboard-manual&#34;&gt;Motherboard Manual
&lt;/h2&gt;&lt;p&gt;The motherboard manual has an issue: the location of the SATA ports indicated in the manual doesn&amp;rsquo;t match the actual locations. Because I have too many disks, they are all installed on the interfaces. The older SSDs use SATA interfaces. According to the motherboard manual, there is a conflict between these interfaces. After testing, this conflict is triggered unstably. When it triggers, the corresponding disk cannot be loaded. This happens to be the system disk, and the bootloader is also on that disk, so the system fails to boot.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/asus-motherboard-z490-too-many-disks-intermittent-disk-recognition/20250110002401.png&#34;
	width=&#34;807&#34;
	height=&#34;847&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Z490&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;95&#34;
		data-flex-basis=&#34;228px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;solution&#34;&gt;Solution
&lt;/h2&gt;&lt;p&gt;Reinstalled the solid-state drive onto the PCIe adapter, and at that point, there was no conflict with the SATA interface on the motherboard anymore, so the system started up normally&lt;/p&gt;</description>
        </item>
        <item>
        <title>Unveiling the Secrets of ESP Partitioning, GPT Partition Tables, and the Windows Operating System&#39;s Collaboration</title>
        <link>https://ttf248.life/en/p/exploring-esp-gpt-and-windows-cooperation/</link>
        <pubDate>Thu, 09 Jan 2025 23:58:20 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/exploring-esp-gpt-and-windows-cooperation/</guid>
        <description>&lt;p&gt;Yesterday after work, I got home and turned on my desktop as usual. The system booted up normally, but the wireless network card failed to load. I thought the card might have come loose, so I opened the case and reinstalled it. That&amp;rsquo;s when things went wrong – the system wouldn’t boot at all; the bootloader failed.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s been a while since I messed with desktop computers, so partitioning is a bit unfamiliar. I used DisGenius to create a new blank partition (usually partitioned towards the front of the disk) and allocated it as an ESP partition (default 300M). Then, I rebuilt the boot in the PE system. You can find relevant information online.&lt;/p&gt;
&lt;p&gt;Create New ESP Partition&lt;/p&gt;
&lt;p&gt;Can remove MSR partition&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;In the world of computer storage, ESP partitions, GPT partition tables, and Windows operating systems are closely linked, each playing a unique and crucial role, jointly supporting the stable operation and efficient management of the system. However, before delving into them, it is necessary to mention the &amp;ldquo;predecessor&amp;rdquo; in the long history of computer partitioning—the MBR partition table format. It reflects the evolution of technology by contrasting with later technologies. Today, let&amp;rsquo;s deeply analyze their inherent connections and subtleties.&lt;/p&gt;
&lt;h2 id=&#34;i-mbr-partition-table--the-foundation-of-traditional-disk-partitioning&#34;&gt;I. MBR Partition Table – The &amp;ldquo;Foundation&amp;rdquo; of Traditional Disk Partitioning
&lt;/h2&gt;&lt;p&gt;MBR, which stands for Master Boot Record, has existed since the early days of personal computers and has dominated the hard drive partitioning field for decades&lt;/p&gt;
&lt;h3 id=&#34;basic-architecture&#34;&gt;Basic architecture
&lt;/h3&gt;&lt;p&gt;It is located in the first sector of the hard drive, also known as sector 0, and occupies 512 bytes. These 512 bytes are mainly divided into three parts: firstly, the boot program code, which is responsible for loading the operating system&amp;rsquo;s boot loader when the computer starts up, typically occupying 446 bytes; secondly, the disk partition table, occupying 64 bytes, which can define a maximum of 4 primary partition entries, each entry occupying 16 bytes and recording key parameters such as the starting head, sector, cylinder, and type and size of the partition; finally, the last 2 bytes are the MBR termination flag &amp;ldquo;55 AA&amp;rdquo;, used to identify this sector as a valid MBR.&lt;/p&gt;
&lt;h3 id=&#34;historical-achievements-and-limitations&#34;&gt;Historical achievements and limitations
&lt;/h3&gt;&lt;p&gt;Initially, the MBR partition table fully met the relatively simple storage needs of personal computers. It allowed operating systems to smoothly recognize hard drive partitions and implement orderly data storage and retrieval. However, as times evolved, its limitations became increasingly apparent. On one hand, limited by the 64-byte space of the partition table, it could only support a maximum of four primary partitions. To create more partitions, complex methods such as extended partitions and logical partitions were required, which brought inconvenience to disk management; on the other hand, it supported a maximum hard drive capacity of only 2TB, which seemed inadequate in the face of high-capacity drives that are now often several TB or even tens of TB, becoming a bottleneck restricting further development of storage technology.&lt;/p&gt;
&lt;h2 id=&#34;ii-esp-partition--the-systems-invisible-boot-key&#34;&gt;II. ESP Partition – The System&amp;rsquo;s &amp;ldquo;Invisible Boot Key&amp;rdquo;
&lt;/h2&gt;&lt;p&gt;ESP, which stands for EFI System Partition, is a special partition required by computers based on the UEFI (Unified Extensible Firmware Interface) standard&lt;/p&gt;
&lt;h3 id=&#34;features&#34;&gt;Features
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;The boot process: When the computer is powered on, the UEFI firmware first searches for the ESP partition on the hard drive and reads the boot loader stored there (such as Windows Boot Manager), then starts the operating system. It&amp;rsquo;s like a precise key that opens the door to system startup; without it, the system will be lost and confused at startup, not knowing where to go.&lt;/li&gt;
&lt;li&gt;The storage drive also stores some drivers essential for the system startup process, ensuring that hardware devices such as hard disk controllers and graphics cards function properly during the early boot phase, laying the foundation for the subsequent smooth takeover by the operating system&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;space-requirements-and-format&#34;&gt;Space requirements and format
&lt;/h3&gt;&lt;p&gt;Typically, the recommended size for the ESP partition is between 100MB and 500MB, and allocating around 200MB is usually sufficient to meet basic needs. Its file system format must be FAT32 because UEFI firmware can only recognize FAT32 when reading boot files, ensuring compatibility and cross-platform support.&lt;/p&gt;
&lt;h2 id=&#34;iii-gpt-partition-table--the-smart-manager-of-your-hard-drive&#34;&gt;III. GPT Partition Table – The &amp;ldquo;Smart Manager&amp;rdquo; of Your Hard Drive
&lt;/h2&gt;&lt;p&gt;GPT (GUID Partition Table), also known as a Global Unique Identifier Partition Table, is a new partitioning scheme designed to replace traditional MBR partition tables&lt;/p&gt;
&lt;h3 id=&#34;advantages-revealed&#34;&gt;Advantages revealed
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;High Capacity Support:&lt;/strong&gt; In today&amp;rsquo;s era of data explosion, high-capacity hard drives are constantly emerging. The GPT partition table breaks through the 2TB capacity limitation of MBR and theoretically supports up to 9.4ZB (Zettabytes, 1 ZB = 1024 EB, 1 EB = 1024 PB, 1 PB = 1024 TB) of extremely large storage space, making it possible to store massive amounts of data.&lt;/li&gt;
&lt;li&gt;Unlike MBR, which can only have a maximum of four primary partitions, GPT allows for the creation of up to 128 partitions, providing users and system administrators with great flexibility. Whether it&amp;rsquo;s partitioning multiple system partitions, data partitions, or reserving partitions for special purposes, it handles everything smoothly.&lt;/li&gt;
&lt;li&gt;High reliability: The GPT partition table utilizes a redundant backup mechanism, storing partition information in both the head and tail of the hard drive. When one partition table is damaged, the system can automatically recover from another backup, significantly reducing the risk of data loss due to partition table failures and safeguarding data security.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;structural-analysis&#34;&gt;Structural Analysis
&lt;/h3&gt;&lt;p&gt;The GPT partition table consists of several parts, including a protective MBR (retained for compatibility with traditional BIOS as a small portion of the MBR structure but not used for actual partitioning management), a GPT header (which stores basic information about the GPT partition table, such as the partition table version, number of partitions, and partition table size), and an array of partition entries (each partition entry details key information such as the starting sector, ending sector, partition type GUID, and unique partition identifier). These structures work together to precisely plan and manage disk space.&lt;/p&gt;
&lt;h2 id=&#34;four-windows-operating-system--a-digital-interaction-realm-for-users&#34;&gt;Four, Windows Operating System – A “Digital Interaction Realm” for Users
&lt;/h2&gt;&lt;p&gt;Windows, as a globally widely used operating system, builds a friendly bridge between people and computer hardware&lt;/p&gt;
&lt;h3 id=&#34;integration-with-esp-partitions-and-gpt-partition-tables&#34;&gt;Integration with ESP partitions and GPT partition tables
&lt;/h3&gt;&lt;p&gt;During the Windows installation process on systems booting based on UEFI, the installer automatically creates an ESP (EFI System Partition) and deploys boot files within it. At the same time, the hard drive is initialized with a GPT (GUID Partition Table), partitioning out a system reserved partition (used to store system critical files, similar to the system boot file area in traditional BIOS), a Windows system partition (where the system core files are installed), and other user-defined data partitions. The Windows system relies on the GPT partition table to accurately identify each partition, smoothly booting through the ESP partition, with seamless integration between the three, providing users with a smooth startup and usage experience.&lt;/p&gt;
&lt;h3 id=&#34;reliance-on-system-management-and-optimization&#34;&gt;Reliance on system management and optimization
&lt;/h3&gt;&lt;p&gt;Windows leverages the advantages of the GPT partition table for disk management during operation. For example, in the Disk Management tool, GPT partitions can be easily recognized, allowing users to conveniently create, delete, format partitions, and adjust their sizes, meeting data storage needs at different stages. Furthermore, system updates, software installations, and other processes are closely related to the partition layout; a reasonable partitioning scheme helps improve system performance and stability, reducing problems caused by insufficient disk space or partition confusion.&lt;/p&gt;
&lt;h2 id=&#34;v-practical-tips-maintenance-and-troubleshooting&#34;&gt;V. Practical Tips: Maintenance and Troubleshooting
&lt;/h2&gt;&lt;p&gt;Understanding their close relationship makes troubleshooting and maintenance more systematic&lt;/p&gt;
&lt;h3 id=&#34;disk-space-management&#34;&gt;Disk space management
&lt;/h3&gt;&lt;p&gt;Regularly check the ESP partition space to avoid issues caused by insufficient space due to installing too many startup items or related software, which can affect system boot. For data partitions under GPT partitioning, plan storage reasonably and promptly clean up unnecessary files to prevent a single partition from becoming full and affecting system operation.&lt;/p&gt;
&lt;h3 id=&#34;troubleshooting-startup-issues&#34;&gt;Troubleshooting startup issues
&lt;/h3&gt;&lt;p&gt;If the system fails to start, first check if the ESP partition is damaged or files are missing. You can use the startup repair tool built into the UEFI firmware, or enter the recovery environment through a Windows installation medium to rebuild the boot files of the ESP partition. If you suspect a GPT partition table failure, use professional disk tools (such as DiskGenius) to check the integrity of the partition table and attempt to repair and restore backup partition information to recover lost partitions.&lt;/p&gt;
&lt;p&gt;ESP partitions, GPT partition tables, and the Windows operating system are like a precise team working together, each playing their part to create a stable and efficient computing environment for us. A deep understanding of them not only helps us feel confident during system installation and maintenance but also allows us to understand the underlying logic of computer operation and freely explore the digital world. At the same time, reflecting on the rise and fall of the MBR partition table further reminds us of the power of technological progress, which drives storage technology forward to adapt to the ever-increasing demand for data storage.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Understanding GCC, GLIBC, and C&#43;&#43; Program Compatibility Issues</title>
        <link>https://ttf248.life/en/p/deep-understanding-gcc-glibc-cpp-compatibility-issues/</link>
        <pubDate>Mon, 06 Jan 2025 19:51:16 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/deep-understanding-gcc-glibc-cpp-compatibility-issues/</guid>
        <description>&lt;p&gt;In the field of C++ development, GCC and GLIBC are two indispensable key elements, and compatibility issues after program release often trouble developers. This article will deeply analyze their essence, explore the root causes of compatibility problems, and discuss coping strategies.&lt;/p&gt;
&lt;h2 id=&#34;i-gcc-a-powerful-compiler-foundation&#34;&gt;I. GCC: A Powerful Compiler Foundation
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Definition and Function&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GCC, which stands for GNU Compiler Collection, is an open-source compiler suite developed by the GNU project. It&amp;rsquo;s far from a typical compiler; it supports various mainstream languages including C, C++, Objective-C, Fortran, Ada, and Go, providing a one-stop solution for cross-language development.&lt;/li&gt;
&lt;li&gt;For example, with C++, when we write a source file containing complex features such as classes, templates, and function overloading, GCC can convert the high-level C++ code into an instruction sequence that the underlying machine can understand and execute, based on C++&amp;rsquo;s strict syntax and semantic rules. This process involves multiple fine-grained stages including lexical analysis, syntactic analysis, semantic analysis, optimization, and code generation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compilation Process Explained&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The preprocessing stage: GCC first performs preprocessing on the source file. During this period, it handles all directives that begin with &lt;code&gt;#&lt;/code&gt;. For example, the &lt;code&gt;#include&lt;/code&gt; directive embeds the entire content of the specified header file (such as &lt;code&gt;&amp;lt;iostream&amp;gt;&lt;/code&gt; for C++ input/output stream operations) into the corresponding position in the source file, allowing the program to use the functions, classes, and other resources declared in the header file; macros defined by the &lt;code&gt;#define&lt;/code&gt; directive are also expanded and replaced at this stage. For example, &lt;code&gt;#define PI 3.14159&lt;/code&gt;; all occurrences of &lt;code&gt;PI&lt;/code&gt; in the source file will be replaced with &lt;code&gt;3.14159&lt;/code&gt;. After preprocessing, the source file is initially “expanded.”&lt;/li&gt;
&lt;li&gt;The compilation stage: The preprocessed file enters the compilation link, where GCC, based on the C++ language standard, converts the source file into assembly language code. It carefully checks the code structure to ensure correct class inheritance, polymorphism implementation, and function call parameter matching. If it finds any errors that do not conform to syntax or semantics, it will promptly report an error and terminate the compilation process. For example, if there is a mismatch between the function declaration and definition&amp;rsquo;s parameter list, GCC will precisely point out the problem.&lt;/li&gt;
&lt;li&gt;The assembly phase: The assembler converts the assembly code generated in the previous step into machine code, producing target files with a &lt;code&gt;.o&lt;/code&gt; extension. These target files contain binary instructions that can be directly executed by the machine, but they cannot run independently because a complete program typically consists of multiple modules with unresolved function and variable references between them.&lt;/li&gt;
&lt;li&gt;The linking phase: This is the final sprint stage in generating an executable file. The linker integrates multiple object files and required library files (static or dynamic libraries) together. For example, when we use container classes from the C++ Standard Template Library, the linker needs to find the corresponding library implementation code during linking to ensure that the program can correctly call the functions of &lt;code&gt;vector&lt;/code&gt;, &lt;code&gt;list&lt;/code&gt; and other containers at runtime, ultimately generating a complete executable program.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;ii-glibc-the-behind-the-scenes-pillar-for-c-program-execution&#34;&gt;II. GLIBC: The Behind-the-Scenes Pillar for C++ Program Execution
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Essence and Function
&lt;ul&gt;
&lt;li&gt;GLIBC, or the GNU C Library, is a specific implementation of the C standard library within the GNU ecosystem. Although the name highlights its connection to C, C++ programs are equally reliant on it because C++ inherits the foundational aspects of C. It provides a vast number of basic functions, such as &lt;code&gt;malloc&lt;/code&gt; (dynamic memory allocation) and &lt;code&gt;free&lt;/code&gt; (memory release), which are essential when creating dynamic arrays and objects in C++; string processing functions like &lt;code&gt;strcpy&lt;/code&gt; (string copy) and &lt;code&gt;strcat&lt;/code&gt; (string concatenation), even though C++ has more advanced &lt;code&gt;string&lt;/code&gt; classes, are still used for interacting with C code at a lower level or pursuing extreme performance; and standard input/output functions such as &lt;code&gt;printf&lt;/code&gt; and &lt;code&gt;scanf&lt;/code&gt;, which frequently appear in early C++ development and in scenarios that are sensitive to performance and prioritize simplicity.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Coordination with the operating system
&lt;ul&gt;
&lt;li&gt;GLIBC acts as a crucial bridge between the operating system and applications. In Linux systems, when a C++ program makes a system call, such as opening a file (using the &lt;code&gt;open&lt;/code&gt; function, which relies on GLIBC implementation), GLIBC encapsulates the program&amp;rsquo;s request in a way that the operating system kernel expects and passes it to the kernel. After the kernel processes the request, GLIBC returns the result to the application. It allows applications to use various system resources, such as file systems, networks, and process management functions, conveniently without needing to understand the complex details of the underlying system call interfaces of the operating system.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;iii-analysis-of-compatibility-issues-after-c-program-release&#34;&gt;III. Analysis of Compatibility Issues After C++ Program Release
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Compatibility Issues Caused by GLIBC Version Differences
&lt;ul&gt;
&lt;li&gt;Different Linux distributions often use different versions of GLIBC. When a C++ program is compiled in a high-version GLIBC environment, it may inadvertently use certain new features or rely on more optimized function implementations added in that version. For example, newer GLIBC versions have improved memory allocation algorithms, and programs frequently take advantage of these new algorithms to improve performance at runtime. Once this program is ported to a system with an older GLIBC version, it may encounter issues such as missing functions (because the function was not introduced in the older version) or abnormal function behavior (due to discrepancies between the old and new implementations), leading to program crashes or incorrect results.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Compatibility issues caused by compiler differences
&lt;ul&gt;
&lt;li&gt;Even when using the same GCC compiler, different versions of GCC can vary in code generation, standard library support, and implementation details regarding C++ features. Newer GCC versions may offer complete support for the latest C++ standards (such as new features like modules and coroutines in C++20). If a program utilizes these cutting-edge features and is compiled under an older version of GCC, the compiler will report errors due to its inability to recognize these new syntax structures; even if there are no syntax errors, different optimization strategies across GCC versions can result in machine code that differs significantly in execution efficiency and memory usage. This difference can lead to vastly different program behavior in demanding performance scenarios.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Challenges Brought by System Architecture Differences
&lt;ul&gt;
&lt;li&gt;C++ programs may need to run on different hardware system architectures, such as x86, ARM, and PowerPC. Different architectures have their own unique instruction sets, memory layouts, and data alignment requirements. For example, the storage layout of a structure that runs normally on the x86 architecture can cause abnormal memory access and subsequent program errors on the ARM architecture due to different alignment rules; moreover, the machine code generated by GCC when compiling for different architectures differs greatly. If the program contains hardcoded architecture-specific instructions or assumptions, cross-architecture runtime failures are inevitable.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;strategies-for-addressing-compatibility-issues&#34;&gt;Strategies for Addressing Compatibility Issues
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;The Use of Static Link Libraries
&lt;ul&gt;
&lt;li&gt;Consider using a static library, which directly packages the code of libraries such as GLIBC that the program depends on into the executable file. This eliminates the program&amp;rsquo;s dependence on a specific version of GLIBC on the target system, effectively avoiding issues caused by GLIBC version mismatches. However, static linking significantly increases the size of the executable file and requires weighing the pros and cons in scenarios with limited storage resources.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Containerized Deployment
&lt;ul&gt;
&lt;li&gt;By leveraging containerization technologies like Docker, the C++ program and its required runtime environment (including specific versions of GCC, GLIBC, etc.) are encapsulated within a standalone container. Regardless of the underlying operating system it is deployed on, the container consistently maintains the environment as it was during development, ensuring the program runs as expected and greatly simplifying cross-environment deployment complexity.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Compatibility Testing and Continuous Integration
&lt;ul&gt;
&lt;li&gt;Establish a comprehensive compatibility testing system covering different GLIBC versions, GCC versions, and common system architectures. During the development process, use continuous integration tools to regularly perform automated tests in multiple environments. Address any compatibility issues promptly to eliminate potential risks at their inception and ensure stability after program launch.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In conclusion, a deep understanding of the workings of GCC and GLIBC, an accurate grasp of the root causes of C++ program compatibility issues, and the ability to apply appropriate strategies are essential skills for every C++ developer aiming to build robust, cross-platform applications. Only in this way can our C++ works navigate diverse technical ecosystems smoothly.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Windows&#39; built-in Disk Cleanup tool: Storage</title>
        <link>https://ttf248.life/en/p/windows-disk-cleanup-storage/</link>
        <pubDate>Mon, 06 Jan 2025 19:29:45 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/windows-disk-cleanup-storage/</guid>
        <description>&lt;p&gt;I&amp;rsquo;m not entirely sure from what version it started, but in &lt;code&gt;Windows 11&lt;/code&gt;, the Disk Cleanup tool has been significantly improved and is now much smarter&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s an official tool, so it won’t delete files by mistake, has no ads, no pop-ups, no background processes, and nothing unnecessary&lt;/p&gt;
&lt;p&gt;In Windows 11, you can open Disk Cleanup through Settings - System - Storage - Temporary files&lt;/p&gt;
&lt;p&gt;Storage interface&lt;/p&gt;
&lt;p&gt;Ordinary users can simply select &amp;ldquo;Clean-up Suggestions,&amp;rdquo; and the system will provide recommendations based on your usage&lt;/p&gt;
&lt;p&gt;As a developer, I have many temporary files on my disk, so I chose &amp;ldquo;Temporary Files,&amp;rdquo; which contains various temporary files such as those from &lt;code&gt;Visual Studio&lt;/code&gt; and &lt;code&gt;Windows Update&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Temporary file&lt;/p&gt;</description>
        </item>
        <item>
        <title>Docker domestic image proxy failure</title>
        <link>https://ttf248.life/en/p/docker-domestic-mirror-failure/</link>
        <pubDate>Sat, 04 Jan 2025 18:29:25 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/docker-domestic-mirror-failure/</guid>
        <description>&lt;p&gt;Deploying Docker on domestic servers. If the company doesn&amp;rsquo;t provide an image registry, developers must first configure a domestic mirror acceleration address. Conveniently, I have a server today that has been configured with a mirror acceleration address, but it can’t pull images.&lt;/p&gt;
&lt;p&gt;Error response from daemon: Get &amp;ldquo;&lt;a class=&#34;link&#34; href=&#34;https://registry-1.docker.io/v2/%22&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://registry-1.docker.io/v2/&#34;&lt;/a&gt;: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)&lt;/p&gt;
&lt;p&gt;After two days, all servers have been restored, and surprisingly this didn&amp;rsquo;t trend. All domestic mirror proxies are down.&lt;/p&gt;
&lt;h2 id=&#34;troubleshooting-and-repair-attempts&#34;&gt;Troubleshooting and Repair Attempts
&lt;/h2&gt;&lt;p&gt;Initially, I tried switching to other mirror acceleration addresses hoping to resolve the issue, but it backfired and the problem persists&lt;/p&gt;
&lt;p&gt;Immediately, I began modifying the local DNS configuration, attempting to find a breakthrough at the network resolution level; unfortunately, after some debugging, the fault still persisted&lt;/p&gt;
&lt;p&gt;At this point, the stability of the local network was seriously questioned, so I immediately switched to my phone&amp;rsquo;s hotspot in an attempt to bypass any potential issues with the local network. However, the result was still frustrating; there were no signs of improvement.&lt;/p&gt;
&lt;h2 id=&#34;the-problem-is-spreading&#34;&gt;The problem is spreading
&lt;/h2&gt;&lt;p&gt;We still have several servers deployed domestically, all with Docker environments installed. I tried pulling images on these servers, hoping to find an alternative solution, but without exception, they failed to pull successfully. The error messages were identical across all devices, indicating the problem wasn&amp;rsquo;t limited to a single machine.&lt;/p&gt;
&lt;p&gt;Further investigation revealed that the mirror proxy seemed to have failed instantly. At this critical moment, we quickly switched to an overseas machine for a trial attempt. Fortunately, image pulling resumed here, which suggests the problem likely lies within the domestic network link or related configuration.&lt;/p&gt;
&lt;h2 id=&#34;strategic-adjustment-resolving-issues-indirectly&#34;&gt;Strategic adjustment: resolving issues indirectly
&lt;/h2&gt;&lt;p&gt;Given the numerous obstacles to directly pulling images within China, while foreign mirrors are accessible, in order to expedite project progress, we have decided to adopt a circumspect approach. First, switch to a foreign server to successfully pull the required images, then push them to a domestic mirror repository, thereby establishing a &amp;ldquo;data bridge.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;At the same time, I modified the Dockerfile and replaced the image address with one suitable for domestic environments, then rebuilt the image and successfully deployed it&lt;/p&gt;</description>
        </item>
        <item>
        <title>CentOS 8 Stream EOL</title>
        <link>https://ttf248.life/en/p/centos-8-stream-eol/</link>
        <pubDate>Sat, 16 Nov 2024 23:24:50 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/centos-8-stream-eol/</guid>
        <description>&lt;p&gt;CentOS Stream is an upstream open-source development platform prior to Red Hat Enterprise Linux releases
First noticed the open source operating system lifecycle [Red Hat and CentOS lifecycle]({relref &amp;ldquo;/post/2020/07-redhat and centos life cycle&amp;rdquo;})&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It&amp;rsquo;s expired, what&amp;rsquo;s the problem? Besides security issues, DNF is no longer working. I noticed it failed when I installed a tool recently, and checking the mirror source revealed that &lt;code&gt;CentOS 8 Stream&lt;/code&gt; has expired.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;introduction-to-centos-stream&#34;&gt;Introduction to CentOS Stream
&lt;/h2&gt;&lt;h3 id=&#34;positioning-and-role&#34;&gt;Positioning and Role
&lt;/h3&gt;&lt;p&gt;CentOS Stream sits between Fedora Linux (upstream development) and RHEL (Red Hat Enterprise Linux, downstream development), acting as a bridge&lt;/p&gt;
&lt;p&gt;It can be seen as a version for experiencing the latest Red Hat Enterprise Linux features, suitable for early adopters&lt;/p&gt;
&lt;h3 id=&#34;birth-and-background&#34;&gt;Birth and Background
&lt;/h3&gt;&lt;p&gt;As time went on, Red Hat began seeking more effective ways to develop its enterprise-level Linux platform and launched CentOS Stream&lt;/p&gt;
&lt;p&gt;After CentOS 8 ended maintenance at the end of 2021, CentOS Stream continued to be updated as its successor and has become the future direction of the CentOS project&lt;/p&gt;
&lt;h3 id=&#34;features-and-advantages&#34;&gt;Features and Advantages
&lt;/h3&gt;&lt;p&gt;CentOS Stream is a rolling-release Linux distribution that provides faster updates. It offers greater transparency and more opportunities for community, partner, and customer involvement, allowing users to contribute to Red Hat Enterprise Linux more quickly and directly.&lt;/p&gt;
&lt;p&gt;The content of CentOS Stream is software that Red Hat intends to include in a subsequent stable version of RHEL, so it can provide community members with a stable ABI/API for development and testing&lt;/p&gt;
&lt;h3 id=&#34;use-cases-and-target-users&#34;&gt;Use Cases and Target Users
&lt;/h3&gt;&lt;p&gt;CentOS Stream is suitable for CentOS users who want to continue receiving the latest Linux feature updates, as well as developers and partners who wish to participate in Red Hat Enterprise Linux development&lt;/p&gt;
&lt;p&gt;It also aims to assist community members, Red Hat partners, and others in fully leveraging innovative open-source programs within a more stable and predictable Linux ecosystem&lt;/p&gt;
&lt;h2 id=&#34;expiration-date&#34;&gt;Expiration Date
&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Release&lt;/th&gt;
&lt;th&gt;Released&lt;/th&gt;
&lt;th&gt;Active Support&lt;/th&gt;
&lt;th&gt;Security Support&lt;/th&gt;
&lt;th&gt;Latest&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;3 years ago (15 Sep 2021)&lt;/td&gt;
&lt;td&gt;Ends in 2 years and 6 months (31 May 2027)&lt;/td&gt;
&lt;td&gt;Ends in 2 years and 6 months (31 May 2027)&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;5 years ago (24 Sep 2019)&lt;/td&gt;
&lt;td&gt;Ended 5 months and 3 weeks ago (31 May 2024)&lt;/td&gt;
&lt;td&gt;Ended 5 months and 3 weeks ago (31 May 2024)&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;solution&#34;&gt;Solution
&lt;/h2&gt;&lt;p&gt;I didn&amp;rsquo;t bother troubleshooting upgrade issues, so I chose the long-term support version of Ubuntu 24.04&lt;/p&gt;</description>
        </item>
        <item>
        <title>Customizing Hugo Themes with Modules: An Explanation of Ideas</title>
        <link>https://ttf248.life/en/p/hugo-module-custom-theme-ideas/</link>
        <pubDate>Fri, 15 Nov 2024 22:01:17 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/hugo-module-custom-theme-ideas/</guid>
        <description>&lt;p&gt;Looking back at the historical commit records, the site has switched themes many times. Each time a theme is switched, there are some custom modifications. Here&amp;rsquo;s a record of the思路 for customizing themes. The author’s &lt;code&gt;Github&lt;/code&gt; also has a repository where they briefly maintained the even theme. Later, due to obsessive-compulsive tendencies and a desire to upgrade the &lt;code&gt;hugo&lt;/code&gt; compiler to the latest version, it became incompatible with the even theme, so they switched back to the &lt;code&gt;stack&lt;/code&gt; theme.&lt;/p&gt;
&lt;h2 id=&#34;hugos-modularity&#34;&gt;Hugo&amp;rsquo;s modularity
&lt;/h2&gt;&lt;p&gt;When it comes to modularity, people might think of Nginx modules or IDEA plugins, etc. Typically, I can satisfy my differentiated needs by uploading some modules. The reason everyone likes this kind of module is mainly because it&amp;rsquo;s flexible enough and can meet their own needs without too much effort. Because often, although they are generally similar, there are always some differences in the details. This also illustrates the complexity of software, which includes not only technical complexity but also business complexity. In most cases, we face business complexity. This is the best explanation for the saying &amp;ldquo;different industries are like different mountains&amp;rdquo; in the software field. Nowadays, not only the internet industry and financial industry, but even traditional manufacturing has adopted information systems to help with corporate production and management. Even for a leave application system, there will be differences between companies, even within the same industry.&lt;/p&gt;
&lt;p&gt;Hugo&amp;rsquo;s modules are a bit different from what people typically think of as modules; they aren’t organized around functionality to meet diverse needs. Instead, they primarily rely on directory structure to identify common structures.&lt;/p&gt;
&lt;p&gt;Link to materials: &lt;a class=&#34;link&#34; href=&#34;https://medium.com/@sunwei.xyz/07-hugo%E6%9E%B6%E6%9E%84-hugo%E7%9A%84%E6%A8%A1%E5%9D%97-8ef5a520a822&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;07. Hugo Architecture — Hugo&amp;rsquo;s Modules&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[[imports]]
path = &amp;quot;github.com/CaiJimmy/hugo-theme-stack/v3&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;git submodule&lt;/code&gt; method still works, but this article does not recommend using it. If there are updates to the introduced theme, maintenance will be more complicated, requiring a separate git repository to manage the theme.&lt;/p&gt;
&lt;h2 id=&#34;modifying-theme-logic&#34;&gt;Modifying Theme Logic
&lt;/h2&gt;&lt;p&gt;With a foundational understanding of modularity, understanding custom themes becomes much easier. The current themes in &lt;code&gt;hugo&lt;/code&gt; are also assembled from multiple different modules; to modify one, simply locate the corresponding template file and make changes.&lt;/p&gt;
&lt;p&gt;Quoted from the &lt;code&gt;stack&lt;/code&gt; official documentation:&lt;/p&gt;
&lt;p&gt;Using this method, there won&amp;rsquo;t be any file under &lt;code&gt;themes&lt;/code&gt; directory. In order to modify the theme, you will have to copy the file you want to modify to the same directory under &lt;code&gt;layouts&lt;/code&gt; directory.&lt;/p&gt;
&lt;p&gt;For example, in order to modify the &lt;code&gt;themes/hugo-theme-stack/layouts/partials/head/custom.html&lt;/code&gt; file, you will have to copy it to &lt;code&gt;layouts/partials/head/custom.html&lt;/code&gt; and modify it there (copy the code from theme&amp;rsquo;s repository). The same applies to &lt;code&gt;assets&lt;/code&gt; and &lt;code&gt;static&lt;/code&gt; directories。&lt;/p&gt;
&lt;h2 id=&#34;how-to-find-the-template-file&#34;&gt;How to find the template file
&lt;/h2&gt;&lt;h3 id=&#34;orthodox-thinking&#34;&gt;Orthodox thinking
&lt;/h3&gt;&lt;p&gt;Browse the theme&amp;rsquo;s source files, understand the design concept, find the corresponding template file, and make modifications&lt;/p&gt;
&lt;h3 id=&#34;brute-force-approach&#34;&gt;Brute force approach
&lt;/h3&gt;&lt;p&gt;I&amp;rsquo;m not very familiar with front-end code, so sometimes I use a crude approach. For example, I open the corresponding page directly in the browser, find the place I want to modify, locate the &lt;code&gt;css name&lt;/code&gt; using &amp;ldquo;Inspect Element,&amp;rdquo; search for it in the theme source code, find the corresponding file, copy it to the site directory, and then make the changes.&lt;/p&gt;
&lt;h2 id=&#34;little-tips&#34;&gt;Little tips
&lt;/h2&gt;&lt;p&gt;The official default provides a file for customizing styles, and we can split the places that need to be modified into multiple files, introducing our other files through the &lt;code&gt;custom.scss&lt;/code&gt; file, which allows for better management of style files&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/hugo-module-custom-theme-ideas/image.png&#34;
	width=&#34;141&#34;
	height=&#34;375&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;37&#34;
		data-flex-basis=&#34;90px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;summary-of-revisions-6h&#34;&gt;Summary of revisions (6h)
&lt;/h2&gt;&lt;p&gt;It&amp;rsquo;s already the first year of AI coding. I won’t go into detailed content here, but just briefly list some modifications to this site, such as adjusting the style of the copy button and reconfiguring the code block styles – ChatGPT can easily handle these tasks.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Overall: Global text style, inheriting the display style of the previous &lt;code&gt;even&lt;/code&gt; merged with &lt;code&gt;info cn&lt;/code&gt;, friendly to Chinese&lt;/li&gt;
&lt;li&gt;Homepage: Add mouse interaction animation to the right navigation&lt;/li&gt;
&lt;li&gt;Homepage: Articles now have abstract previews (implemented with a somewhat expedient method due to the time it took)&lt;/li&gt;
&lt;li&gt;Scroll bar: I&amp;rsquo;ve styled the scroll bar&lt;/li&gt;
&lt;li&gt;The code block introduces the &lt;code&gt;highlight.js&lt;/code&gt; code highlighting plugin and beautifies the style of the code blocks&lt;/li&gt;
&lt;li&gt;Article details: Some content is reproduced, with added display of original author information and original link&lt;/li&gt;
&lt;li&gt;Archive page: Remove the theme&amp;rsquo;s color overlay and display the original image for the category picture at the top&lt;/li&gt;
&lt;li&gt;The archive page now features a statistics display panel categorized by year&lt;/li&gt;
&lt;li&gt;Archive page: Two-column layout&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The component reusability of the &lt;code&gt;stack&lt;/code&gt; theme is high, which also led to significant time consumption when adding summary previews for homepage articles. After modifying the corresponding components, changes occurred on the article details page, resulting in duplicate content being displayed. I&amp;rsquo;m not very familiar with &lt;code&gt;golang template&lt;/code&gt; syntax, so it took a considerable amount of time. I couldn’t resolve parameter passing between components, and ultimately, I used a workaround: introducing a separate &lt;code&gt;JavaScript&lt;/code&gt; script for the homepage and implementing summary previews through custom special variables.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Sometimes, excessive code reuse can also be a problem, leading to changes in one area affecting others. Therefore, when modifying the theme, it is important to pay attention and avoid disrupting the original logic.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;comments-section&#34;&gt;Comments section
&lt;/h3&gt;&lt;p&gt;This guy&amp;rsquo;s modifications are more complete: [https://blog.reincarnatey.net/2024/0719-better-waline/]&lt;/p&gt;
&lt;p&gt;This site simply enables the &lt;code&gt;Waline&lt;/code&gt; comment system. The &lt;code&gt;stack&lt;/code&gt; theme natively supports &lt;code&gt;Waline&lt;/code&gt;, just configure it in &lt;code&gt;config.toml&lt;/code&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Recommended homepage, email contact. This site does not open its comment section.&lt;/p&gt;
&lt;/blockquote&gt;</description>
        </item>
        <item>
        <title>Slow efficiency when processing large string data in Linux backend services</title>
        <link>https://ttf248.life/en/p/linux-backend-slow-string-processing/</link>
        <pubDate>Wed, 13 Nov 2024 19:42:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-backend-slow-string-processing/</guid>
        <description>&lt;p&gt;In C++ development projects, we used a custom protocol for communication that adopted a two-dimensional array pattern. When processing large amounts of data, the protocol needed to traverse and serialize arrays internally to generate logs. Due to low efficiency, this caused noticeable lag in the system under high load, which was reported by the business department.&lt;/p&gt;
&lt;h2 id=&#34;problem-identification&#34;&gt;Problem identification
&lt;/h2&gt;&lt;p&gt;When troubleshooting the issue, we first performed a performance analysis of the system and found that the CPU utilization increased significantly when processing large amounts of data, and the system response time lengthened. By analyzing the system logs, we discovered numerous serialization operations, which were inefficient when handling two-dimensional arrays, leading to decreased system performance.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;pstack&lt;/code&gt; tool captured thread information for the service, revealing that the log thread spends most of its time processing string concatenation&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Here&amp;rsquo;s the key point for today: different accumulation methods can make a huge difference in efficiency. The historical code uses the &lt;code&gt;+&lt;/code&gt; operator, which frequently creates temporary objects and is very inefficient. You know it’s inefficient, but you don’t realize just how inefficient it is.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;demo-verification&#34;&gt;Demo verification
&lt;/h2&gt;&lt;p&gt;Based on the project code, we extracted the business logic and wrote a simple demo to verify the efficiency of string concatenation. Compile and run with the &lt;code&gt;vs2022&lt;/code&gt; compiler under &lt;code&gt;windows&lt;/code&gt;, the &lt;code&gt;gcc8.5&lt;/code&gt; compiler under &lt;code&gt;linux&lt;/code&gt;, in &lt;code&gt;Release&lt;/code&gt; mode, and compare their efficiencies.&lt;/p&gt;
&lt;h3 id=&#34;key-points-explanation&#34;&gt;Key points explanation
&lt;/h3&gt;&lt;p&gt;The project uses method four. Before receiving the test data, readers can first think about which method is most efficient and which is least efficient? I was still very surprised when I saw the results.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Method 1 (Concatenation using +=): Directly concatenate each field to the string using +=&lt;/li&gt;
&lt;li&gt;Method 2 (using &lt;code&gt;std::ostringstream&lt;/code&gt; concatenation): This method uses streams (&lt;code&gt;std::ostringstream&lt;/code&gt;) to concatenate each field, which is more efficient, especially when concatenating large amounts of data&lt;/li&gt;
&lt;li&gt;Method 3 (Pre-allocated Memory with &lt;code&gt;+=&lt;/code&gt;) involves allocating sufficient memory for the string in advance using &lt;code&gt;reserve&lt;/code&gt;, which reduces the overhead of memory reallocation and improves performance&lt;/li&gt;
&lt;li&gt;Method 4 (&lt;code&gt;bodys = bodys + body + &amp;quot;\n&amp;quot;&lt;/code&gt;): Creating a new temporary string object with each concatenation leads to performance degradation, especially when concatenating strings on a large scale, because each concatenation involves a new memory allocation and copy&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;According to the results, the project selected the least efficient method&lt;/p&gt;
&lt;p&gt;To take things a step further, let&amp;rsquo;s analyze the optimization efficiency of different platform compilers. Microsoft&amp;rsquo;s &lt;code&gt;Visual Studio&lt;/code&gt; remains consistently excellent, with very high optimization efficiency for strings, while the &lt;code&gt;GCC&lt;/code&gt; compiler is somewhat lacking in this area.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The code runs on different machines, and there is no direct comparison between the two sets of data. You can compare the differences between different concatenation methods separately.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;windows 平台下的 vs2022 编译器

----------------------------------------
Data Generation Time: 0.054 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.053 seconds.
+ ostringstream Data merging took: 0.054 seconds.
+ Pre-reserved Data merging took: 0.045 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 16.108 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;linux 平台下的 gcc8.5 编译器
----------------------------------------
Data Generation Time: 0.108 seconds.
----------------------------------------

----------------------------------------
Data Merging Performance:
----------------------------------------
+ Data merging (+=) took: 0.100 seconds.
+ ostringstream Data merging took: 0.083 seconds.
+ Pre-reserved Data merging took: 0.057 seconds.
+ Data merging (bodys = bodys + body + &amp;quot;\n&amp;quot;) took: 29.298 seconds.

----------------------------------------
Data Merging Complete.
----------------------------------------

Program finished.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;complete-code&#34;&gt;Complete code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;random&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;sstream&amp;gt;
#include &amp;lt;iomanip&amp;gt;

typedef std::vector&amp;lt;std::string&amp;gt; DataRow;
typedef std::vector&amp;lt;DataRow&amp;gt; DataGroup;

struct ResponsePackage
{
    std::string ErrorInfo;
    DataRow Head;
    std::string ClientId;
    std::string UUID;
    std::string MsgID;
    std::string SessionID;
    std::string ExtraInfo1;
    std::string ExtraInfo2;
    DataGroup DataBody;
};

// Generate specified length of random string
std::string generateRandomString(size_t length)
{
    const char charset[] = &amp;quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&amp;quot;;
    const size_t max_index = sizeof(charset) - 1;
    std::string random_string;
    random_string.reserve(length);

    std::random_device rd;
    std::mt19937 generator(rd());
    std::uniform_int_distribution&amp;lt;&amp;gt; distribution(0, max_index);

    for (size_t i = 0; i &amp;lt; length; ++i)
    {
        random_string += charset[distribution(generator)];
    }

    return random_string;
}

void create_large_string()
{
    // Example request package with 50 fields
    ResponsePackage requestPackage;

    requestPackage.Head = {
        &amp;quot;Field1&amp;quot;, &amp;quot;Field2&amp;quot;, &amp;quot;Field3&amp;quot;, &amp;quot;Field4&amp;quot;, &amp;quot;Field5&amp;quot;,
        &amp;quot;Field6&amp;quot;, &amp;quot;Field7&amp;quot;, &amp;quot;Field8&amp;quot;, &amp;quot;Field9&amp;quot;, &amp;quot;Field10&amp;quot;,
        &amp;quot;Field11&amp;quot;, &amp;quot;Field12&amp;quot;, &amp;quot;Field13&amp;quot;, &amp;quot;Field14&amp;quot;, &amp;quot;Field15&amp;quot;,
        &amp;quot;Field16&amp;quot;, &amp;quot;Field17&amp;quot;, &amp;quot;Field18&amp;quot;, &amp;quot;Field19&amp;quot;, &amp;quot;Field20&amp;quot;,
        &amp;quot;Field21&amp;quot;, &amp;quot;Field22&amp;quot;, &amp;quot;Field23&amp;quot;, &amp;quot;Field24&amp;quot;, &amp;quot;Field25&amp;quot;,
        &amp;quot;Field26&amp;quot;, &amp;quot;Field27&amp;quot;, &amp;quot;Field28&amp;quot;, &amp;quot;Field29&amp;quot;, &amp;quot;Field30&amp;quot;,
        &amp;quot;Field31&amp;quot;, &amp;quot;Field32&amp;quot;, &amp;quot;Field33&amp;quot;, &amp;quot;Field34&amp;quot;, &amp;quot;Field35&amp;quot;,
        &amp;quot;Field36&amp;quot;, &amp;quot;Field37&amp;quot;, &amp;quot;Field38&amp;quot;, &amp;quot;Field39&amp;quot;, &amp;quot;Field40&amp;quot;,
        &amp;quot;Field41&amp;quot;, &amp;quot;Field42&amp;quot;, &amp;quot;Field43&amp;quot;, &amp;quot;Field44&amp;quot;, &amp;quot;Field45&amp;quot;,
        &amp;quot;Field46&amp;quot;, &amp;quot;Field47&amp;quot;, &amp;quot;Field48&amp;quot;, &amp;quot;Field49&amp;quot;, &amp;quot;Field50&amp;quot;
    };

    requestPackage.ClientId = &amp;quot;ClientID&amp;quot;;
    requestPackage.UUID = &amp;quot;UUID&amp;quot;;
    requestPackage.MsgID = &amp;quot;MsgID&amp;quot;;
    requestPackage.SessionID = &amp;quot;SessionID&amp;quot;;
    requestPackage.ExtraInfo1 = &amp;quot;ExtraInfo1&amp;quot;;
    requestPackage.ExtraInfo2 = &amp;quot;ExtraInfo2&amp;quot;;

    // Start timing for data generation
    auto start_gen = std::chrono::high_resolution_clock::now();

    // Generate 10,000 rows of data, each with 50 fields
    for (size_t i = 0; i &amp;lt; 10000; ++i)
    {
        DataRow dataRow(50, &amp;quot;This is a test string&amp;quot;);
        requestPackage.DataBody.push_back(dataRow);
    }

    // End timing for data generation
    auto end_gen = std::chrono::high_resolution_clock::now();
    std::chrono::duration&amp;lt;double&amp;gt; duration_gen = end_gen - start_gen;

    // Display result generation time
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Generation Time: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_gen.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    // Data merging using different methods
    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Performance:\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;

    {
        // Method 1: Using &#39;+=&#39; string concatenation
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys(&amp;quot;&amp;quot;);
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (+=) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 2: Using ostringstream
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::ostringstream bodys;
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::ostringstream body;
            body &amp;lt;&amp;lt; &amp;quot;This is a test string&amp;quot;;
            for (auto&amp;amp; item : vec)
            {
                body &amp;lt;&amp;lt; item &amp;lt;&amp;lt; &amp;quot; &amp;quot;;
            }
            bodys &amp;lt;&amp;lt; body.str() &amp;lt;&amp;lt; &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ ostringstream Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 3: Pre-allocated memory
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys;
        bodys.reserve(1000 * 50 * 20); // Pre-allocate enough memory
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            body.reserve(50 * 20); // Pre-allocate memory for each row
            for (auto&amp;amp; item : vec)
            {
                body += item + &amp;quot; &amp;quot;;
            }
            bodys += body + &amp;quot;\n&amp;quot;;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Pre-reserved Data merging took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    {
        // Method 4: Using &#39;bodys = bodys + body + &amp;quot;\n&amp;quot;&#39;
        auto start_merge = std::chrono::high_resolution_clock::now();
        std::string bodys(&amp;quot;&amp;quot;);
        for (auto&amp;amp; vec : requestPackage.DataBody)
        {
            std::string body(&amp;quot;This is a test string&amp;quot;);
            for (auto&amp;amp; item : vec)
            {
                body = body + item + &amp;quot; &amp;quot;; // Note the use of &#39;body = body + item&#39;
            }
            bodys = bodys + body + &amp;quot;\n&amp;quot;; // Again, using &#39;bodys = bodys + body&#39;
        }
        auto end_merge = std::chrono::high_resolution_clock::now();
        std::chrono::duration&amp;lt;double&amp;gt; duration_merge = end_merge - start_merge;
        std::cout &amp;lt;&amp;lt; &amp;quot;+ Data merging (bodys = bodys + body + \&amp;quot;\\n\&amp;quot;) took: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(3) &amp;lt;&amp;lt; duration_merge.count() &amp;lt;&amp;lt; &amp;quot; seconds.\n&amp;quot;;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\n----------------------------------------\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;Data Merging Complete.\n&amp;quot;;
    std::cout &amp;lt;&amp;lt; &amp;quot;----------------------------------------\n&amp;quot;;
}

int main()
{
    try
    {
        create_large_string();
    }
    catch (const std::exception&amp;amp; e)
    {
        std::cerr &amp;lt;&amp;lt; &amp;quot;Caught exception: &amp;quot; &amp;lt;&amp;lt; e.what() &amp;lt;&amp;lt; std::endl;
    }

    std::cout &amp;lt;&amp;lt; &amp;quot;\nProgram finished.\n&amp;quot;;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Lambda expression parameter lifetime in C&#43;&#43;</title>
        <link>https://ttf248.life/en/p/cpp-lambda-parameter-lifetime/</link>
        <pubDate>Wed, 13 Nov 2024 19:23:02 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-lambda-parameter-lifetime/</guid>
        <description>&lt;p&gt;In C++, lambda expressions are convenient anonymous functions that can capture external variables and use them within their bodies. This makes lambdas a flexible programming tool. However, the lifetime of lambda expression parameters is an aspect that requires special attention, especially when capturing and passing parameters.&lt;/p&gt;
&lt;h3 id=&#34;the-lifecycle-of-parameters-in-lambda-expressions&#34;&gt;The lifecycle of parameters in lambda expressions
&lt;/h3&gt;&lt;p&gt;The lifetime of lambda expression parameters is typically the same as that of other C++ functions. Function parameters exist during the function call and end when the function call completes. However, because lambda expressions may capture external variables, the lifetime of the parameters can also be affected by the capturing method.&lt;/p&gt;
&lt;h3 id=&#34;the-relationship-between-capture-and-parameter-lifecycle&#34;&gt;The relationship between capture and parameter lifecycle
&lt;/h3&gt;&lt;h4 id=&#34;21-capturing-external-variables&#34;&gt;2.1 Capturing External Variables
&lt;/h4&gt;&lt;p&gt;C++ lambda expressions allow capturing external variables in two ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Value capturing: Through value capture, the values of external variables are copied into the lambda, and the lifecycle of these copies is controlled by the lifecycle of the lambda&lt;/li&gt;
&lt;li&gt;Closure: Through closure capturing, references to external variables are preserved; references within a lambda point to the original external variables, and their lifecycle depends on the external variables&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int x = 10;
auto lambda_by_value = [x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };  // 捕获x的副本
auto lambda_by_reference = [&amp;amp;x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };  // 捕获x的引用

lambda_by_value();  // 打印10
lambda_by_reference();  // 打印10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The lifecycle of captured variables is as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;By-value capture: When capturing, the values of external variables are copied into the lambda, and when the lambda&amp;rsquo;s lifecycle ends, these copies are destroyed&lt;/li&gt;
&lt;li&gt;Capture by reference: A lambda holding a reference to an external variable must have the external variable be valid before the lambda is used, otherwise it can lead to undefined behavior&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;22-lambda-parameters&#34;&gt;2.2 Lambda Parameters
&lt;/h4&gt;&lt;p&gt;Lambda parameters are similar to regular function parameters, their lifecycle is limited to within the lambda function. That is, lambda parameters are created when the lambda is called and their lifecycle ends after the lambda call is completed.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;auto lambda = [](int a, int b) {
    std::cout &amp;lt;&amp;lt; a + b &amp;lt;&amp;lt; std::endl;
};
lambda(5, 10);  // a和b在这里是lambda的参数
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; are parameters of the lambda expression, they are created when the lambda is called and destroyed after the lambda execution ends&lt;/p&gt;
&lt;h3 id=&#34;lifecycle-issues-when-capturing-external-variables&#34;&gt;Lifecycle issues when capturing external variables
&lt;/h3&gt;&lt;h4 id=&#34;whether-captured-variables-can-be-valid-outside-of-a-lambda&#34;&gt;Whether captured variables can be valid outside of a lambda
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Capture by value: Even if external variables are destroyed after a lambda call, the lambda still holds a copy of the external variable. Therefore, the copy inside the lambda can be used safely, even if the external variable no longer exists.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int x = 10;
auto lambda = [x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };
x = 20;  // x 在lambda调用后修改
lambda();  // 打印10，捕获的是x的副本
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;By reference capture: If a variable is captured by reference, the lambda&amp;rsquo;s access to that reference depends on the lifetime of the external variable. If the external variable is destroyed before the lambda executes, this can lead to a dangling reference and undefined behavior.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int x = 10;
auto lambda = [&amp;amp;x]() { std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl; };
x = 20;  // x 在lambda调用前修改
lambda();  // 打印20，捕获的是x的引用
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;It is very important to ensure that captured external variables remain valid when the lambda function executes if the order of execution of lambdas is uncertain&lt;/p&gt;
&lt;/blockquote&gt;</description>
        </item>
        <item>
        <title>Win11 Logitech G431 Headphone Driver Installation</title>
        <link>https://ttf248.life/en/p/win11-logitech-g431-headphone-driver-installation/</link>
        <pubDate>Wed, 05 Jun 2024 07:20:17 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/win11-logitech-g431-headphone-driver-installation/</guid>
        <description>&lt;p&gt;Picking up where we left off, I came back to find that Ghub had been updated, which made me a little happy. The customer service said they fixed the issue of not being able to load problem drivers properly, but after messing around with it for a while – reinstalling and uninstalling – it still doesn&amp;rsquo;t work normally.&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background
&lt;/h2&gt;&lt;p&gt;I continued to contact customer service for a solution, but was told that an engineer could provide remote assistance. However, the engineer&amp;rsquo;s working hours were exactly the same as mine, so I had no choice but to give up. I reviewed the materials from the previous troubleshooting and prepared to try installing the driver manually.&lt;/p&gt;
&lt;h2 id=&#34;get-the-driver-installation-package&#34;&gt;Get the driver installation package
&lt;/h2&gt;&lt;p&gt;How can I obtain the driver files since Logitech doesn&amp;rsquo;t provide a separate driver installation package for their devices?&lt;/p&gt;
&lt;p&gt;With the system image installation package left over from the last system reinstallation, we can reinstall the system in a local virtual machine. In the cleanest system, deploy Ghub separately, insert the headset device into the virtual machine, find the driver path, and copy it out.&lt;/p&gt;
&lt;p&gt;Related paths:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C:\ProgramData\LGHUB&lt;/li&gt;
&lt;li&gt;C:\Windows\System32\DriverStore\FileRepository\logi_audio.inf_amd64_010b035044e24be4&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;device-manager&#34;&gt;Device Manager
&lt;/h2&gt;&lt;p&gt;The key is how to find the second path. Let&amp;rsquo;s first briefly review how to manually manage driver files in Win11 systems. This content was identified using the control variable method, by constantly plugging and unplugging devices and analyzing device information in Device Manager within a virtual machine. We identified that three drivers need to be handled for the headset. Two of these drivers are built-in system drivers, and only one is provided by Logitech.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Driver Manager&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;The second driver in the image is provided by Logitech. We analyze the current device drivers, and search through all driver paths within the virtual machine. Of course, you first need to find files starting with &amp;ldquo;logi,&amp;rdquo; then compare the files. You&amp;rsquo;ll be able to locate the driver file. Copy the entire folder, and you’ve got the driver installation package.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Driver installation package&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;install-driver&#34;&gt;Install driver
&lt;/h2&gt;&lt;p&gt;Still in the Device Manager interface, click: Update Driver, click: Browse My Computer for Drivers, and you will enter the following interface:&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Driver Installation&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Of course, when you open it, you can only see a drive – that&amp;rsquo;s the standard USB drive. Choose &amp;ldquo;Install from disk,&amp;rdquo; and the path is the folder we copied earlier. After installation, a Logitech-specific driver will appear in the drop-down list. Switch the device driver to the newly installed one.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Disk Installation&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;anatomy-equipment-drivers&#34;&gt;Anatomy equipment drivers
&lt;/h2&gt;&lt;p&gt;The drivers for this device are provided by the system. You only need to check if there&amp;rsquo;s an exclamation mark in front of the device driver; if there is, go into the driver selection interface and switch to a different type of driver, then change it back to restore normal functionality.&lt;/p&gt;
&lt;h2 id=&#34;completed&#34;&gt;Completed
&lt;/h2&gt;&lt;p&gt;The headset microphone volume has returned to normal, and the familiar ear monitoring function is back as well&lt;/p&gt;
&lt;p&gt;Side sound&lt;/p&gt;</description>
        </item>
        <item>
        <title>Logitech headset driver installation failed</title>
        <link>https://ttf248.life/en/p/logitech-headset-driver-installation-failed/</link>
        <pubDate>Fri, 31 May 2024 21:46:12 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/logitech-headset-driver-installation-failed/</guid>
        <description>&lt;p&gt;If you didn&amp;rsquo;t understand these things at all, you wouldn&amp;rsquo;t have wasted several hours troubleshooting; you would have contacted official customer service right away&lt;/p&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/logitech-headset-driver-installation-failed/20240531220709.png&#34;
	width=&#34;693&#34;
	height=&#34;489&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;GHUB&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;141&#34;
		data-flex-basis=&#34;340px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Recently, the C drive on my home desktop computer used for development ran out of space. I specially allocated a 256GB SSD that was partially retired for exclusive use by the C drive, but it&amp;rsquo;s been frequently messed with. Since moving to Shanghai, I’ve been busy with various matters, and finally last week I found time to reinstall the system.&lt;/p&gt;
&lt;p&gt;The system reinstall went smoothly, and there were no issues with installing everyday software or deploying the development environment. A few days later, I planned to relax and play a few games, when it occurred to me that the drivers for my mouse and headphones hadn&amp;rsquo;t been installed yet. Both devices are Logitech, so I downloaded GHUB software, which automatically recognizes hardware and installs drivers.&lt;/p&gt;
&lt;p&gt;However, an unexpected issue occurred. The mouse driver installed smoothly, but the headset driver kept displaying &amp;ldquo;Loading.&amp;rdquo; I suspect that incompatibility between the latest version of Windows 11 and Logitech&amp;rsquo;s drivers caused the installation to fail. So, I started searching for information and tried to manually install the driver, but the problem remained unresolved.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a simple explanation of what each of these devices’ drivers do&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The mouse driver is mainly used to adjust functions such as mouse movement speed. I rarely use macro functions, only needing to restore previously saved parameters.&lt;/li&gt;
&lt;li&gt;The driver for the headphones is mainly used for the monitor function, which is very useful during team voice communication as it allows me to hear my own voice. Although there&amp;rsquo;s a similar listening feature in the system’s microphone settings, it doesn&amp;rsquo;t work as well as the driver implementation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Despite repeated attempts, the drivers for my headphones consistently fail to load. Today, I finally thought to contact customer service to inquire about the situation and see if there was a solution. Customer service told me that their servers have recently been experiencing issues, causing abnormal driver downloads. They are working on this problem and asked me not to worry, saying the issue should be resolved after the next update.&lt;/p&gt;
&lt;p&gt;Although the issue with the headphone drivers hasn&amp;rsquo;t been resolved yet, at least we know the cause, and I hope the problem can be fixed as soon as possible&lt;/p&gt;
&lt;h2 id=&#34;mouse-driver-settings&#34;&gt;Mouse driver settings
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/logitech-headset-driver-installation-failed/20240531220930.png&#34;
	width=&#34;1024&#34;
	height=&#34;768&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;G502&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/logitech-headset-driver-installation-failed/20240531220903.png&#34;
	width=&#34;1024&#34;
	height=&#34;768&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;G502&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>Storing Custom Objects in Python Dictionaries: The Importance of References and Deep Copies</title>
        <link>https://ttf248.life/en/p/python-dictionary-custom-objects-reference-vs-deepcopy/</link>
        <pubDate>Fri, 22 Mar 2024 01:08:05 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/python-dictionary-custom-objects-reference-vs-deepcopy/</guid>
        <description>&lt;p&gt;In Python programming, dictionaries are a very powerful data structure that allows us to associate key-value pairs and efficiently find and manipulate this data. When we try to store custom objects in a dictionary, we often encounter a key concept: object assignment in Python is actually reference assignment, not a deep copy of the object itself. This means that when you put a custom object into a dictionary, the dictionary stores a reference to that object, rather than a brand new copy of the object.&lt;/p&gt;
&lt;h2 id=&#34;storing-custom-objects---a-basic-example&#34;&gt;Storing Custom Objects - A Basic Example
&lt;/h2&gt;&lt;p&gt;Suppose we have a simple &lt;code&gt;Person&lt;/code&gt; class:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Person:
    def __init__(self, name, age):
        self.name = name
        self.age = age

# 创建一个 Person 对象
p1 = Person(&amp;quot;Alice&amp;quot;, 30)

# 将对象存储到字典中
people_dict = {}
people_dict[&amp;quot;alice&amp;quot;] = p1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, the &lt;code&gt;people_dict&lt;/code&gt; dictionary now contains an item with the key &lt;code&gt;&amp;quot;alice&amp;quot;&lt;/code&gt; and a value that is a reference to the &lt;code&gt;Person&lt;/code&gt; type object &lt;code&gt;p1&lt;/code&gt;. If we modify the attributes of &lt;code&gt;p1&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;p1.age = 31
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When accessing this object through the dictionary, we will find that its age has also been updated:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(people_dict[&amp;quot;alice&amp;quot;].age)  # 输出：31
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is because the dictionary stores not independent copies of &lt;code&gt;Person&lt;/code&gt; objects, but references pointing to the same memory address&lt;/p&gt;
&lt;h2 id=&#34;the-difference-between-deep-copy-and-shallow-copy&#34;&gt;The difference between deep copy and shallow copy
&lt;/h2&gt;&lt;p&gt;This referencing behavior can lead to unexpected results when dealing with nested data structures or custom objects. For example, if a custom object contains mutable attributes (such as lists or another custom object), directly storing such an object in a dictionary and modifying it will affect the object retrieved through the dictionary.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Address:
    def __init__(self, street, city):
        self.street = street
        self.city = city

class Person:
    def __init__(self, name, age, address):
        self.name = name
        self.age = age
        self.address = address

address = Address(&amp;quot;Main St.&amp;quot;, &amp;quot;Springfield&amp;quot;)
p1 = Person(&amp;quot;Bob&amp;quot;, 40, address)
people_dict[&amp;quot;bob&amp;quot;] = p1

# 修改原始地址对象
address.city = &amp;quot;Shelbyville&amp;quot;

# 字典中的人的地址也变了
print(people_dict[&amp;quot;bob&amp;quot;].address.city)  # 输出：Shelbyville
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Solution: Deep Copy&lt;/p&gt;
&lt;p&gt;To avoid problems caused by this shared state, sometimes we need to ensure that the dictionary stores a complete copy of an object, rather than a reference. Python provides the &lt;code&gt;deepcopy&lt;/code&gt; function in the &lt;code&gt;copy&lt;/code&gt; module to achieve this goal:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import copy

# 使用深拷贝存储对象
people_dict[&amp;quot;bob_deepcopy&amp;quot;] = copy.deepcopy(p1)

# 此时即使修改原始地址对象，深拷贝的对象不会受影响
address.city = &amp;quot;Capital City&amp;quot;
print(people_dict[&amp;quot;bob&amp;quot;].address.city)  # 输出：Capital City
print(people_dict[&amp;quot;bob_deepcopy&amp;quot;].address.city)  # 输出：Shelbyville
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In short, when using dictionaries to store custom objects in Python, be mindful that object references are stored by default. For situations requiring independent state, use &lt;code&gt;deepcopy&lt;/code&gt; for a deep copy to avoid unexpected data changes due to shared references.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Why is the speed test result only 100 Mbps for a newly installed Gigabit fiber connection?</title>
        <link>https://ttf248.life/en/p/new-gigabit-fiber-slow-speed/</link>
        <pubDate>Mon, 18 Mar 2024 00:29:02 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/new-gigabit-fiber-slow-speed/</guid>
        <description>&lt;p&gt;Want your home network to be as fast as lightning? The key lies in understanding the choice of network cables, configuring the optical network terminal and router, and those seemingly insignificant details. This blog will guide you through how to build a Gigabit network with Cat6 Ethernet cable and how to ensure your network speed is not limited by simple device checks and configurations. Let&amp;rsquo;s explore together and make your home internet fly!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Manual Repair&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;chapter-1-in-depth-analysis-of-network-transmission-media&#34;&gt;Chapter 1: In-Depth Analysis of Network Transmission Media
&lt;/h2&gt;&lt;p&gt;When we talk about achieving gigabit network access, the carrier of information at high speed – the network cable – plays a crucial role. The following will provide a detailed explanation of Cat 5, Cat 6, and Cat 7 cables:&lt;/p&gt;
&lt;h3 id=&#34;cat-5-network-cable&#34;&gt;Cat 5 network cable
&lt;/h3&gt;&lt;p&gt;Category 5 network cables, also known as CAT5, are an early type of twisted-pair cable that uses a precise spiral structure design to reduce crosstalk. It is mainly used for 10/100Mbps fast Ethernet, with a maximum transmission frequency of approximately 100MHz. Although widely used in the past, Category 5 network cables cannot meet current requirements for gigabit and higher speeds due to physical limitations.&lt;/p&gt;
&lt;h3 id=&#34;six-category-ethernet-cable-cat6&#34;&gt;Six-Category Ethernet Cable (CAT6)
&lt;/h3&gt;&lt;p&gt;With the development of technology, Cat6 cabling emerged. Compared to Cat5 cabling, Cat6 cables adopted stricter manufacturing standards and more advanced structural designs, significantly improving anti-interference capabilities and transmission efficiency. They can support a transmission rate of up to 1Gbps and, under ideal conditions, achieve a transmission distance of 100 meters – perfectly meeting the access requirements of Gigabit networks.&lt;/p&gt;
&lt;h3 id=&#34;seven-category-ethernet-cable-cat7&#34;&gt;Seven-Category Ethernet Cable (CAT7)
&lt;/h3&gt;&lt;p&gt;Seven categories of network cable represent the pinnacle of current twisted-pair technology. It not only boasts a significant improvement in transmission rate, theoretically supporting up to 10Gbps of ultra-high speed, but also incorporates a complete shielding system in its design, including shielding between each pair of wires and overall outer layer shielding, thereby greatly reducing external electromagnetic interference and near-end crosstalk, ensuring the stability and accuracy of data transmission. However, seven categories of network cable is mainly used for future 10 Gigabit Ethernet or specific high-demand scenarios.&lt;/p&gt;
&lt;p&gt;When building a Gigabit home network, choosing Cat6 cabling is the most economical and efficient option to fully unleash the potential of the Gigabit fiber. Ensuring that all connecting cables are of qualified quality and strictly following standard wiring practices is also an important link in ensuring network performance.&lt;/p&gt;
&lt;h2 id=&#34;chapter-2-delving-into-network-core-devicesthe-impact-of-optical-network-terminal-ont-and-router-lan-port-bandwidth&#34;&gt;Chapter 2: Delving into Network Core Devices—The Impact of Optical Network Terminal (ONT) and Router LAN Port Bandwidth
&lt;/h2&gt;&lt;h3 id=&#34;the-importance-of-the-optical-network-terminal-and-its-lan-port-bandwidth&#34;&gt;The importance of the optical network terminal and its LAN port bandwidth
&lt;/h3&gt;&lt;p&gt;The Optical Network Terminal (ONT), also known as an optical modem, is the core device for home broadband access. Its function is to convert the light signal from fiber into a digital signal for use by home network devices. For users with gigabit fiber connections, whether the ONT supports gigabit transmission is particularly important. If the ONT&amp;rsquo;s WAN port only supports 100Mbps, even if the fiber-to-the-home rate is higher, it will be limited to within 100Mbps due to this bottleneck. Similarly, the ONT’s LAN port also needs to have gigabit output capabilities; otherwise, routers or other devices connected to it cannot achieve true gigabit speeds.&lt;/p&gt;
&lt;h3 id=&#34;the-role-of-bandwidth-for-the-lan-ports-on-a-router&#34;&gt;The role of bandwidth for the LAN ports on a router
&lt;/h3&gt;&lt;p&gt;The router&amp;rsquo;s LAN port is responsible for distributing received data to various terminal devices. When the router’s LAN port is limited to gigabit speed, even if other equipment is well-configured, it can only achieve gigabit network communication. Therefore, when building a Gigabit home network, ensure that the router’s WAN port can receive Gigabit data and that the LAN port can also provide Gigabit-level output capabilities so that all smart devices in your home can enjoy the smooth experience brought by high-speed networks.&lt;/p&gt;
&lt;p&gt;In addition, it is important to note that some older or low-end routers may have an auto-negotiation mechanism for the LAN port rate. This means that even if the router itself supports gigabit speeds, it may downgrade to 100Mbps mode due to factors such as cabling and device compatibility. Therefore, correctly configuring the router parameters, enabling forced gigabit mode, and using a gigabit switch or direct connection are key steps in achieving an all-gigabit network.&lt;/p&gt;
&lt;p&gt;After upgrading to Gigabit fiber, be sure to check and replace your Optical Network Terminal (ONT) and router with Gigabit devices, ensuring that all device interfaces meet the Gigabit standard&lt;/p&gt;
&lt;h2 id=&#34;chapter-3-the-mystery-of-latency--how-a-broken-thread-can-affect-gigabit-network-speed&#34;&gt;Chapter 3: The Mystery of Latency – How a Broken Thread Can Affect Gigabit Network Speed
&lt;/h2&gt;&lt;h3 id=&#34;subnet-cable-failure-and-network-performance-degradation&#34;&gt;Subnet cable failure and network performance degradation
&lt;/h3&gt;&lt;p&gt;The network remained connected throughout the speed test, with no obvious disconnections. As it&amp;rsquo;s a newly installed broadband connection, the wiring closet is quite cluttered, and I occasionally adjust the fiber modem’s cabling and power outlet location, which has resulted in speeds reaching gigabit on rare occasions.&lt;/p&gt;
&lt;p&gt;Based on the previous information, we analyzed and ruled out various factors such as network cable model and optical modem LAN port speed, ultimately discovering that the culprit was a broken brown internal wire within the network cable&lt;/p&gt;
&lt;p&gt;The reason for the disconnection: When the technician installed the crystal head, they pulled on this network cable a little too hard, causing one of the wires to break in half. It didn&amp;rsquo;t completely disconnect at the time, but subsequent adjustments to the optical modem’s position and repeated movement caused it to finally break.&lt;/p&gt;
&lt;h3 id=&#34;analysis-of-the-functions-of-eight-wires-in-six-categories-of-network-cables&#34;&gt;Analysis of the Functions of Eight Wires in Six Categories of Network Cables
&lt;/h3&gt;&lt;p&gt;Six categories of network cables follow the TIA/EIA-568-B standard, consisting of eight twisted pairs with the following color coding:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;White Orange / Orange&lt;/li&gt;
&lt;li&gt;White and green / Green&lt;/li&gt;
&lt;li&gt;White and blue / Blue&lt;/li&gt;
&lt;li&gt;Tan / Brown&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Under the Gigabit Ethernet (1000BASE-T) standard, four pairs of wires within these eight lines work simultaneously, with the following specific functions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The white-orange and orange pair of wires (1 &amp;amp; 2) are used for sending data (Tx+/–)&lt;/li&gt;
&lt;li&gt;The white-green and green-green pair of wires (3 &amp;amp; 6) are used for receiving data (Rx+/-);&lt;/li&gt;
&lt;li&gt;The white-blue and blue pair (4&amp;amp;5) as well as the white-brown and brown pair (7&amp;amp;8) are not originally designated for use in Gigabit Ethernet, but may be enabled in certain advanced applications (such as partial PoE power supply or future technology extensions). In traditional 100Mbps networks, only the four wires 1, 2, 3, and 6 are actually needed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;the-impact-of-broken-chains-on-network-speed&#34;&gt;The impact of broken chains on network speed
&lt;/h3&gt;&lt;p&gt;In the above situation, if a brown sub-line (brown or brown-white wire) is broken, it will theoretically cause a speed reduction in a Gigabit network environment because a Gigabit network requires all four pairs of wires to transmit bidirectionally at full speed. However, due to the automatic negotiation function often found in home network devices, when a cable problem is detected, it will revert to a lower rate mode that can operate normally, which is 100Mbps mode. This explains why even with one sub-line broken, the network can remain connected and operate at 100Mbps speed.&lt;/p&gt;
&lt;p&gt;In short, while a broken brown fiber strand does not affect the basic operation of a 100-megabit network, it can be a key factor limiting network speed in a gigabit environment. Only through thorough diagnosis and repair can the full potential of the gigabit fiber optic cable be realized. This also reminds us that when encountering similar situations, we should not overlook any potential network infrastructure issues, even seemingly minor faults that do not affect basic connectivity, as they may become hidden obstacles to high-speed network experiences.&lt;/p&gt;</description>
        </item>
        <item>
        <title>UI thread issues and solutions in WPF</title>
        <link>https://ttf248.life/en/p/wpf-ui-thread-and-freezing-issues-solutions/</link>
        <pubDate>Tue, 12 Mar 2024 07:12:21 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/wpf-ui-thread-and-freezing-issues-solutions/</guid>
        <description>&lt;p&gt;When developing desktop applications, especially when building rich client applications using the Windows Presentation Foundation (WPF) framework, correctly handling the user interface (UI) thread is crucial for ensuring application smoothness and responsiveness. The UI thread, also known as the main thread, is the core thread responsible for processing window and control events, layout calculations, and rendering the interface. Any operation that interacts with UI elements should be executed on the UI thread; this is a fundamental principle followed by WPF and most other GUI frameworks.&lt;/p&gt;
&lt;h2 id=&#34;what-is-the-ui-thread&#34;&gt;What is the UI thread?
&lt;/h2&gt;&lt;p&gt;The UI thread is created and initialized by the operating system when a WPF application starts, and it initializes the application&amp;rsquo;s main window. It’s the only thread that can directly access and modify the state of UI components in the application. This means all user interactions, such as button clicks, text box input, and window resizing, are handled within this thread&amp;rsquo;s context. Simultaneously, WPF&amp;rsquo;s dependency property system, data binding mechanism, and layout logic also execute synchronously on the UI thread.&lt;/p&gt;
&lt;h2 id=&#34;stuttering-phenomenon-and-its-causes&#34;&gt;Stuttering phenomenon and its causes
&lt;/h2&gt;&lt;p&gt;When the UI thread is occupied or blocked for an extended period, such as when performing time-consuming calculations, loading large amounts of data, querying databases, or other I/O-intensive tasks, it can prevent the UI thread from responding to user interactions in a timely manner, resulting in a frozen interface (Freeze), which we commonly refer to as &amp;ldquo;lag.&amp;rdquo; In this situation, users will noticeably feel the application&amp;rsquo;s delay and sluggishness, and severe cases may even trigger an “Application Not Responding” (ANR) warning&lt;/p&gt;
&lt;h2 id=&#34;the-two-basic-rules-of-the-ui-thread&#34;&gt;The two basic rules of the UI thread
&lt;/h2&gt;&lt;p&gt;To avoid these situations, WPF developers should follow these two key rules:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Avoid performing time-consuming operations on the UI thread. Any operation that may cause the UI thread to freeze should be moved to a background thread as much as possible to ensure that the UI thread can respond to user input and render screen changes in a timely manner.&lt;/li&gt;
&lt;li&gt;Do not directly update UI elements on non-UI threads. Due to the security mechanism design of WPF, only the UI thread is authorized to modify UI elements. Attempting to change the UI state directly from another thread will throw an exception. Therefore, even if a background thread has completed calculations or data preparation, it needs to display the results on the UI through appropriate cross-thread communication mechanisms.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;solution-asynchronous-programming-and-thread-safe-updates&#34;&gt;Solution: Asynchronous Programming and Thread-Safe Updates
&lt;/h2&gt;&lt;p&gt;To maintain a smooth UI while executing time-consuming tasks, WPF provides various asynchronous programming models and tools to help developers achieve this goal&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Dispatcher object: The WPF Dispatcher class allows you to schedule work items for execution in the UI thread&amp;rsquo;s task queue. You can safely update the UI from background threads using the &lt;code&gt;Dispatcher.Invoke&lt;/code&gt; or &lt;code&gt;Dispatcher.BeginInvoke&lt;/code&gt; methods.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;async/await&lt;/code&gt; keywords allow you to write asynchronous methods and use the &lt;code&gt;await&lt;/code&gt; keyword to wait for background tasks to complete, automatically returning to the UI thread to execute subsequent UI update code upon completion&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;case-study&#34;&gt;Case study
&lt;/h2&gt;&lt;h3 id=&#34;use-the-dispatcherinvoke-method-to-update-the-ui&#34;&gt;Use the &lt;code&gt;Dispatcher.Invoke&lt;/code&gt; method to update the UI
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;private void Button_Click(object sender, RoutedEventArgs e)
{
    // 假设这是一个耗时操作
    Task.Run(() =&amp;gt;
    {
        var result = LongRunningOperation(); // 这里是模拟一个耗时计算的方法
        
        // 当耗时操作完成后，在UI线程上更新UI
        Application.Current.Dispatcher.Invoke(() =&amp;gt;
        {
            LabelStatus.Text = $&amp;quot;计算结果: {result}&amp;quot;;
        });
    });
}

private string LongRunningOperation()
{
    // 模拟耗时操作
    Thread.Sleep(5000);
    return &amp;quot;已完成&amp;quot;;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;use-asyncawait-keywords-with-taskrun&#34;&gt;Use &lt;code&gt;async/await&lt;/code&gt; keywords with &lt;code&gt;Task.Run&lt;/code&gt;
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;private async void Button_ClickAsync(object sender, RoutedEventArgs e)
{
    Button button = sender as Button;
    button.IsEnabled = false; // 防止用户重复点击

    try
    {
        // 开启后台任务
        var result = await Task.Run(() =&amp;gt; LongRunningOperation());

        // 在后台任务完成后，自动切换回UI线程更新UI
        LabelStatus.Text = $&amp;quot;计算结果: {result}&amp;quot;;
    }
    catch (Exception ex)
    {
        MessageBox.Show($&amp;quot;发生错误: {ex.Message}&amp;quot;);
    }
    finally
    {
        button.IsEnabled = true; // 重新启用按钮
    }
}
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Upgrading GCC version leads to program crashes: Hidden dangers of non-compliant code</title>
        <link>https://ttf248.life/en/p/upgrade-gcc-version-causes-program-crash-code-irregularities/</link>
        <pubDate>Sun, 10 Mar 2024 23:19:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/upgrade-gcc-version-causes-program-crash-code-irregularities/</guid>
        <description>&lt;p&gt;In the same business code segment, the program compiled and ran normally in the CentOS 7 environment, but when switched to CentOS 8 and compiled with an updated version of GCC, it crashed. It is worth noting that the problem only occurred in &lt;strong&gt;Release mode&lt;/strong&gt;, there were no issues at all in &lt;strong&gt;Debug mode&lt;/strong&gt;. This was the first time we encountered a situation like this, and after three days of troubleshooting, we finally found the root cause.&lt;/p&gt;
&lt;h3 id=&#34;problem-identification&#34;&gt;Problem identification
&lt;/h3&gt;&lt;p&gt;After some troubleshooting, the root cause of the problem is that &lt;strong&gt;the function lacks a return value&lt;/strong&gt;. In Release mode, newer versions of GCC perform more optimizations, which leads to undefined behavior in functions that originally lacked explicit return values during execution, resulting in crashes. Our conclusion is that &lt;strong&gt;compiler warnings should not be ignored, especially in older projects where some warnings may have been overlooked; however, we should avoid suppressing all warnings&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;environmental-description&#34;&gt;Environmental Description
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;CentOS 7 GCC version:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39)
Copyright © 2015 Free Software Foundation, Inc.
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CentOS 8 GCC version:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-21)
Copyright (C) 2018 Free Software Foundation, Inc.
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;crash-phenomenon&#34;&gt;Crash phenomenon
&lt;/h3&gt;&lt;p&gt;When analyzing the crash stack of the program, we observed the following stack information:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[New LWP 1385902]
[Thread debugging using libthread_db enabled]
Using host libthread_db library &amp;quot;/lib64/libthread_db.so.1&amp;quot;.
Core was generated by `./pstack_main`.
Program terminated with signal SIGSEGV, Segmentation fault.
#0  0x00007ffe894b4420 in ?? ()
(gdb) bt
#0  0x00007ffe894b4420 in ?? ()
#1  0x00000000004008e9 in main ()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This stack looks far from intuitive; the crash function&amp;rsquo;s stack information is displayed as a &lt;code&gt;??&lt;/code&gt;, which makes troubleshooting even more complicated&lt;/p&gt;
&lt;h3 id=&#34;code-example&#34;&gt;Code example
&lt;/h3&gt;&lt;p&gt;To better understand the issue, here&amp;rsquo;s a minimal code example to reproduce the crash:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;map&amp;gt;

int test() {
    std::cout &amp;lt;&amp;lt; &amp;quot;1&amp;quot; &amp;lt;&amp;lt; std::endl;
}

int main() {
    test();
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;test()&lt;/code&gt; function in this code apparently does not explicitly return a value, while its return type is declared as &lt;code&gt;int&lt;/code&gt;. According to the C++ specification, when a function is declared as type &lt;code&gt;int&lt;/code&gt;, it must have a return value; otherwise, undefined behavior may occur.&lt;/p&gt;
&lt;h3 id=&#34;compilation-warning&#34;&gt;Compilation warning
&lt;/h3&gt;&lt;p&gt;In our project, CMake scripts have suppressed many compile-time warnings, including the following warning message:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;/root/pstack/main.cpp: In function ‘int test()’:
/root/pstack/main.cpp:7:1: warning: no return statement in function returning non-void [-Wreturn-type]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This warning indicates that the &lt;code&gt;test()&lt;/code&gt; function does not return a value, which is the root of the problem. High versions of GCC (such as 8.5.0) may make unstable optimizations when optimizing code due to this undefined behavior, leading to program crashes.&lt;/p&gt;
&lt;h3 id=&#34;assembly-code-differences&#34;&gt;Assembly code differences
&lt;/h3&gt;&lt;p&gt;To explain the differences in GCC compiler optimization behavior, we compared the assembly code generated by different versions of GCC&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Assembly code generated by GCC 4.8.5:&lt;/p&gt;
&lt;p&gt;Assembly code is relatively verbose and includes handling logic for the standard output stream (such as &lt;code&gt;std::cout&lt;/code&gt;). This indicates that the compiler performed more conservative optimizations, did not extensively optimize the missing return value issue in the &lt;code&gt;test()&lt;/code&gt; function, possibly to avoid crashes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Assembly code generated by GCC 8.5.0:&lt;/p&gt;
&lt;p&gt;The new version of GCC has undergone more optimizations, reducing code volume. However, this optimization may cause undefined behavior when functions lacking return values are executed, potentially leading to program crashes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h3&gt;&lt;p&gt;Through this issue investigation, we deeply realized that in C++, &lt;strong&gt;function return values must be explicit&lt;/strong&gt;, especially when a function is declared as &lt;code&gt;int&lt;/code&gt;, it must provide a return value. Projects using older compilers may encounter more optimizations and stricter warning mechanisms when upgrading to newer versions of GCC. Therefore, we recommend against suppressing all warnings during compilation; instead, they should be handled selectively, particularly common issues such as function return values and type matching.&lt;/p&gt;
&lt;p&gt;Ultimately, the issue was resolved by adding a return value to the &lt;code&gt;test()&lt;/code&gt; function, and the program returned to normal operation&lt;/p&gt;</description>
        </item>
        <item>
        <title>VMware virtual machine CPU resource usage anomaly</title>
        <link>https://ttf248.life/en/p/vmware-virtual-machine-cpu-resource-usage-anomaly/</link>
        <pubDate>Sun, 10 Mar 2024 22:14:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/vmware-virtual-machine-cpu-resource-usage-anomaly/</guid>
        <description>&lt;p&gt;The background is that the locally deployed Windows version of the business system occupies about 5% of CPU resources. The Linux version of the business system deployed in VMware-installed CentOS8 has abnormal resource occupancy.&lt;/p&gt;
&lt;h2 id=&#34;problem-description&#34;&gt;Problem description
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Host machine: Windows 10 Enterprise Edition&lt;/li&gt;
&lt;li&gt;vmware：17.5&lt;/li&gt;
&lt;li&gt;Virtual machine: CentOS 8&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Virtual machine resources are allocated as &lt;code&gt;4C8GB&lt;/code&gt;, and the business system is started. The business system is deployed in a virtual machine Linux environment. Inside the virtual machine, the top command observes system resource usage, and CPU utilization is not high. However, in the outer Windows system, Task Manager shows very high CPU resource utilization. Checking processes reveals that the VMware process consumes a lot of CPU resources.&lt;/p&gt;
&lt;p&gt;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+
|         Windows           |
|                           |
|   +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+  |
|   |      VMware        |  |
|   |      Program       |  |
|   +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+  |
|                           |
+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&lt;/p&gt;
&lt;h2 id=&#34;key-points&#34;&gt;Key points
&lt;/h2&gt;&lt;p&gt;Troubleshooting this issue has not been smooth, as the root cause wasn&amp;rsquo;t in the business system itself but rather a problem with the virtual machine. How to shift focus from routine business code to system load, then from anomalies in load data to soft interrupts, and finally pinpoint the key factor: what could affect the efficiency of VMware soft interrupts? This article will first explain the relevant knowledge points and then provide a solution.&lt;/p&gt;
&lt;h3 id=&#34;hyper-v&#34;&gt;hyper-v
&lt;/h3&gt;&lt;p&gt;Virtualization technology for Windows operating systems has undergone a significant change. When Microsoft first released WSL, enabling the Hyper-V service would prevent the simultaneous use of VMware virtual machines. It wasn&amp;rsquo;t until subsequent versions that VMware became compatible with the Hyper-V service.&lt;/p&gt;
&lt;h3 id=&#34;system-load&#34;&gt;System load
&lt;/h3&gt;&lt;p&gt;In a Linux system, &amp;ldquo;load&amp;rdquo; refers to the number of processes that are running or waiting to be executed in the system. Load is typically represented by three numbers, which represent the average number of processes in the run queue over 1 minute, 5 minutes, and 15 minutes. These numbers can be viewed by running the &amp;ldquo;uptime&amp;rdquo; command or the &amp;ldquo;top&amp;rdquo; command.&lt;/p&gt;
&lt;p&gt;Specifically, these three numbers represent:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Average number of processes in the run queue over the past 1 minute&lt;/li&gt;
&lt;li&gt;Average number of processes in the run queue over the past 5 minutes&lt;/li&gt;
&lt;li&gt;Average number of processes in the run queue over the past 15 minutes&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The meaning of load is the number of processes waiting to run in the system. If this number exceeds the logical CPU count of the system, it indicates a high system load, meaning that many processes are waiting for processor resources. This can lead to the system becoming slow or unresponsive, depending on the degree of the load and the system&amp;rsquo;s configuration and performance.&lt;/p&gt;
&lt;p&gt;Ideally, the load should be maintained within the logical CPU count of the system to optimize performance. If the load consistently exceeds the number of CPUs, further analysis of processes in the system may be necessary to identify the cause of the high load and take appropriate measures to adjust system resource allocation or optimize process execution methods.&lt;/p&gt;
&lt;h3 id=&#34;analyzing-load-with-mpstat&#34;&gt;Analyzing load with mpstat
&lt;/h3&gt;&lt;p&gt;The &lt;code&gt;mpstat&lt;/code&gt; command is used to report multiple pieces of information for single or multiple processors, including average load, CPU utilization, interrupts, and context switching. As a useful tool in the &lt;code&gt;sysstat&lt;/code&gt; package, &lt;code&gt;mpstat&lt;/code&gt; can be used to analyze system load conditions. The following are the steps for using &lt;code&gt;mpstat&lt;/code&gt; to perform load analysis:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Installing sysstat
If &lt;code&gt;sysstat&lt;/code&gt; is not installed on your system, you can use a package management tool suitable for your system to install it&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run mpstat
Use the &lt;code&gt;mpstat&lt;/code&gt; command to view CPU usage and load. By default, &lt;code&gt;mpstat&lt;/code&gt; displays the average CPU usage every second. You can adjust the output frequency by specifying a time interval. For example, to run &lt;code&gt;mpstat&lt;/code&gt; once per second, you can use the following command: &lt;code&gt;mpstat -P ALL 2&lt;/code&gt;, where &lt;code&gt;irq&lt;/code&gt; indicates resource occupancy.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;01:32:33 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
01:32:35 PM  all    0.00    0.00    0.26    0.00    3.73    0.26    0.00    0.00    0.00   95.76
01:32:35 PM    0    0.00    0.00    0.51    0.00    3.57    0.00    0.00    0.00    0.00   95.92
01:32:35 PM    1    0.00    0.00    0.00    0.00    3.59    0.51    0.00    0.00    0.00   95.90
01:32:35 PM    2    0.00    0.00    0.00    0.00    4.15    0.00    0.00    0.00    0.00   95.85
01:32:35 PM    3    0.00    0.00    0.52    0.00    3.61    0.52    0.00    0.00    0.00   95.36
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Analysis output
The output of &lt;code&gt;mpstat&lt;/code&gt; includes the utilization rate for each CPU and the system&amp;rsquo;s average load. Paying particular attention to the average load and the utilization rate of each CPU can help you understand the system’s load situation. If the load is high, further analysis can identify which processes are causing it and whether there are any performance bottlenecks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Combining with other tools
In addition to &lt;code&gt;mpstat&lt;/code&gt;, tools such as &lt;code&gt;sar&lt;/code&gt;, &lt;code&gt;pidstat&lt;/code&gt;, and &lt;code&gt;iostat&lt;/code&gt; can also be used for comprehensive system performance analysis. By combining the output of multiple tools, you can gain a more complete understanding of system load and identify the root causes of performance issues.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;interruption&#34;&gt;Interruption
&lt;/h3&gt;&lt;p&gt;I won&amp;rsquo;t elaborate on the content here
Recommended: &lt;a class=&#34;link&#34; href=&#34;https://www.codedump.info/post/20200522-sgfap-softirq/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;System Guide for Application Developers - CPU Part on Soft Interrupts&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Frequent triggering of soft interrupts will also be reflected in system load&lt;/p&gt;
&lt;h2 id=&#34;troubleshooting&#34;&gt;Troubleshooting
&lt;/h2&gt;&lt;p&gt;Considering that analyzing the problem solely from a CPU perspective is unable to pinpoint the issue, should we start suspecting an anomaly in the system? It&amp;rsquo;s possible that the Linux operating system has an excessively high load, leading VMware to consume excessive CPU resources. By using &lt;code&gt;mpstat&lt;/code&gt; to analyze the local virtual machine, we found abnormal &lt;code&gt;irq&lt;/code&gt; usage, approaching 25% on a single core. Under normal circumstances, when running business processes without any load, the &lt;code&gt;irq&lt;/code&gt; percentage should be around 5%.&lt;/p&gt;
&lt;p&gt;Within the development environment of his team, CentOS 7 is deployed on VMware and resource usage appears normal. On the other hand, in the Shanghai development environment, although it&amp;rsquo;s also VMware, we cannot directly observe the CPU resources of the host machine. We are now facing multiple variables: the VMware virtual machine, the Linux operating system, and the GCC version.&lt;/p&gt;
&lt;p&gt;Turning to analyze the test environment, Shenzhen&amp;rsquo;s test environment is deployed on physical machines and runs a low-version GCC compilation service, and it operates on CentOS 8. Interestingly, in the Shenzhen environment, &lt;code&gt;irq&lt;/code&gt; occupancy is normal.&lt;/p&gt;
&lt;p&gt;To investigate issues introduced by GCC versions, we deployed programs compiled with a newer version of GCC to the Shenzhen environment for testing, and the results were also normal&lt;/p&gt;
&lt;p&gt;The issue seems to be becoming clearer, and we&amp;rsquo;ve started to suspect there might be a problem with the operating system. After all, CentOS 8 is no longer officially supported. But even after redeploying clean installations of both CentOS 7 and CentOS 8, the problem persists.&lt;/p&gt;
&lt;p&gt;At this point, we began to suspect the only remaining uncertainty: VMware virtualization software. Suddenly, an idea struck us – Hyper-V technology. Could Hyper-V have been enabled previously but not completely shut down, leading to this issue? After all, soft interrupts are also implemented through virtualization software. Are there bugs in different virtualization technologies? These questions warrant further thought and investigation.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h2&gt;&lt;p&gt;According to the Microsoft official manual, we completely shut down the local Hyper-V service and found that VMware recovered normally on the host machine. With this, the problem was finally resolved. As mentioned earlier, this experience was tortuous and arduous, requiring comprehensive analysis and judgment. This was also the first time we troubleshooted the issue and located it at the virtual machine level.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Disable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V-Hypervisor
bcdedit /set hypervisorlaunchtype off
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/troubleshoot/windows-client/application-management/virtualization-apps-not-work-with-hyper-v&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://learn.microsoft.com/zh-cn/troubleshoot/windows-client/application-management/virtualization-apps-not-work-with-hyper-v&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Traps in C&#43;&#43; Programming: Detailed Explanation of Program Crashes Caused by Misusing `std::map`</title>
        <link>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</link>
        <pubDate>Sun, 10 Mar 2024 22:03:06 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-programming-traps-std-map-crash-details/</guid>
        <description>&lt;p&gt;This article aims to reveal the potential for program crashes when &lt;code&gt;std::map&lt;/code&gt; containers are incorrectly used in C++ programming. Attempting to access a non-existent key through the bracket operator automatically adds an empty element. We will delve into this misunderstanding and demonstrate its potential risks with example code.&lt;/p&gt;
&lt;p&gt;Storing simple values is fine, but if you&amp;rsquo;re storing pointers, there will be problems. Because a pointer is an address, and if it’s not initialized, the address is uncertain, which can lead to program crashes.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;In the C++ standard library, &lt;code&gt;std::map&lt;/code&gt; is an associative container that stores elements in ascending order based on their keys (key) and provides efficient keyword lookup functionality. However, novice developers sometimes encounter difficulties due to a misunderstanding of the behavior of the &lt;code&gt;std::map&lt;/code&gt; bracket operator &lt;code&gt;[]&lt;/code&gt;. In fact, when using &lt;code&gt;[]&lt;/code&gt; to access a non-existent key, &lt;code&gt;std::map&lt;/code&gt; will insert a new key-value pair, and the default constructor will be used to initialize the value type corresponding to that key.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;map&amp;gt;

int main() {
    std::map&amp;lt;std::string, int&amp;gt; myMap;
    
    // 错误的用法：假设这里试图访问一个不存在的键并认为会得到0
    std::cout &amp;lt;&amp;lt; &amp;quot;Value for &#39;nonexistent_key&#39;: &amp;quot; &amp;lt;&amp;lt; myMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;

    // 实际上，上述行代码创建了一个新的键值对，其中值被默认初始化为int的默认值（通常是0）
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Although the above code does not directly cause the program to crash, this implicit insertion behavior can potentially lead to unexpected side effects in certain situations, such as resource leaks or state changes that do not meet expectations. Worse still, concurrent access to uninitialized memory regions in a multithreaded environment can even lead to program crashes.&lt;/p&gt;
&lt;p&gt;To prevent such issues, it is recommended to use the &lt;code&gt;std::map::find()&lt;/code&gt; or &lt;code&gt;std::map::count()&lt;/code&gt; methods to check if a key exists, or to explicitly insert elements using &lt;code&gt;std::map::insert()&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;std::map&amp;lt;std::string, int&amp;gt; safeMap;
if (safeMap.count(&amp;quot;nonexistent_key&amp;quot;) == 0) {
    std::cout &amp;lt;&amp;lt; &amp;quot;Key does not exist.&amp;quot; &amp;lt;&amp;lt; std::endl;
} else {
    std::cout &amp;lt;&amp;lt; &amp;quot;Value for existing key: &amp;quot; &amp;lt;&amp;lt; safeMap[&amp;quot;nonexistent_key&amp;quot;] &amp;lt;&amp;lt; std::endl;
}

// 或者明确插入一个键值对，指定初始值
safeMap.insert({ &amp;quot;new_key&amp;quot;, 0 });
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the objects stored within a map container are of pointer type, the automatic insertion behavior will save an uninitialized pointer, and any operation on this pointer will lead to program crashes&lt;/p&gt;</description>
        </item>
        <item>
        <title>Troubleshooting process freezing with pstack</title>
        <link>https://ttf248.life/en/p/pstack-troubleshooting-process-hang/</link>
        <pubDate>Sat, 24 Feb 2024 23:55:59 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/pstack-troubleshooting-process-hang/</guid>
        <description>&lt;p&gt;In software development and operations, you often encounter situations where processes appear to be frozen. This can lead to system performance degradation or service unavailability. This article introduces how to use the pstack tool to troubleshoot these frozen process issues by analyzing the process&amp;rsquo;s stack information to identify the cause of the problem and resolve it.&lt;/p&gt;
&lt;p&gt;Background: A subsystem of the risk control system experienced a freeze, rendering the risk control service unavailable. Due to the lack of service availability monitoring, the frozen process was not detected in time, leading to system unavailability.&lt;/p&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;A hung process refers to a state where the process stops responding but does not exit. This situation can be caused by various factors, such as deadlock, resource exhaustion, or exceptions. To resolve these issues, we can use the pstack tool to analyze the process&amp;rsquo;s stack information and identify the root cause of the problem.&lt;/p&gt;
&lt;h2 id=&#34;steps&#34;&gt;Steps
&lt;/h2&gt;&lt;p&gt;pstack is a commonly used tool, typically provided with gdb (the GNU debugger). You can install it using the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt-get install gdb
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To obtain the process ID: First, we need to get the process ID (PID) of the frozen process. You can use the &lt;code&gt;ps&lt;/code&gt; command to list all processes and find the process ID that needs troubleshooting.
Use the pstack tool to analyze process stacks; once you obtain the process ID, you can use the pstack tool to retrieve the stack information for that process. Run the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pstack &amp;lt;PID&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will output the process&amp;rsquo;s stack information, displaying the current sequence of function calls. By analyzing this information, you can identify where the process is stalled and thus locate the problem.&lt;/p&gt;
&lt;p&gt;Analyzing stack information can help identify the cause of a process freeze. You might discover deadlocks, infinite loops, or other anomalies. Take appropriate measures based on the specific situation, such as releasing locks or fixing code logic.&lt;/p&gt;
&lt;h2 id=&#34;case-study&#34;&gt;Case study
&lt;/h2&gt;&lt;p&gt;This simple demo, after the main function starts, creates a child thread that enters a dead loop when executing the actual function, causing the program to fail to end normally and fall into a frozen state&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cmake_minimum_required(VERSION 3.0.0)
project(pstack_main VERSION 0.1.0 LANGUAGES C CXX)

include(CTest)
enable_testing()

# 查找线程库
find_package(Threads REQUIRED)

add_executable(pstack_main main.cpp)

# 链接线程库
target_link_libraries(pstack_main PRIVATE Threads::Threads)

set(CPACK_PROJECT_NAME ${PROJECT_NAME})
set(CPACK_PROJECT_VERSION ${PROJECT_VERSION})
include(CPack)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;thread&amp;gt;
#include &amp;lt;chrono&amp;gt;

void infiniteLoop() {
    while (true) {
        // 主线程进入死循环
    }
}

int main() {
    std::thread thread(infiniteLoop); // 创建一个线程，执行死循环函数
    thread.join(); // 等待线程结束
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Starting the program, execution of pstack results:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Thread 2 (Thread 0x7eff3619b700 (LWP 1315017)):
#0  infiniteLoop () at /root/pstack/main.cpp:6
#1  0x0000000000402ca9 in std::__invoke_impl&amp;lt;void, void (*)()&amp;gt; (__f=@0x2260eb8: 0x4029a6 &amp;lt;infiniteLoop()&amp;gt;) at /usr/include/c++/8/bits/invoke.h:60
#2  0x0000000000402b02 in std::__invoke&amp;lt;void (*)()&amp;gt; (__fn=@0x2260eb8: 0x4029a6 &amp;lt;infiniteLoop()&amp;gt;) at /usr/include/c++/8/bits/invoke.h:95
#3  0x0000000000403150 in std::thread::_Invoker&amp;lt;std::tuple&amp;lt;void (*)()&amp;gt; &amp;gt;::_M_invoke&amp;lt;0ul&amp;gt; (this=0x2260eb8) at /usr/include/c++/8/thread:244
#4  0x0000000000403126 in std::thread::_Invoker&amp;lt;std::tuple&amp;lt;void (*)()&amp;gt; &amp;gt;::operator() (this=0x2260eb8) at /usr/include/c++/8/thread:253
#5  0x000000000040310a in std::thread::_State_impl&amp;lt;std::thread::_Invoker&amp;lt;std::tuple&amp;lt;void (*)()&amp;gt; &amp;gt; &amp;gt;::_M_run (this=0x2260eb0) at /usr/include/c++/8/thread:196
#6  0x00007eff36bceb23 in execute_native_thread_routine () from /lib64/libstdc++.so.6
#7  0x00007eff36ea91ca in start_thread () from /lib64/libpthread.so.0
#8  0x00007eff361d58d3 in clone () from /lib64/libc.so.6
Thread 1 (Thread 0x7eff372e1740 (LWP 1315016)):
#0  0x00007eff36eaa6cd in __pthread_timedjoin_ex () from /lib64/libpthread.so.0
#1  0x00007eff36bceda7 in std::thread::join() () from /lib64/libstdc++.so.6
#2  0x00000000004029d2 in main () at /root/pstack/main.cpp:13
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It can be seen that the reason for the process freeze is a dead loop. The main thread enters a dead loop, and the child thread cannot exit, leading to the process freezing.&lt;/p&gt;</description>
        </item>
        <item>
        <title>C&#43;&#43; function call time consumption</title>
        <link>https://ttf248.life/en/p/cpp-function-call-timing/</link>
        <pubDate>Wed, 24 Jan 2024 14:11:33 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cpp-function-call-timing/</guid>
        <description>&lt;p&gt;We conducted a time-consuming test of the Design Quotation SDK, implementing different callback function approaches. Recently I&amp;rsquo;ve been looking at C++ functional programming – what difference does it make in terms of performance when functions become first-class citizens and circulate within a program?&lt;/p&gt;
&lt;p&gt;Previous link: [Compiler, Callback Functions, Performance Testing]&lt;/p&gt;
&lt;p&gt;lemao also did similar tests and borrowed the code for use&lt;/p&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;The execution platform remains our old friend, &lt;a class=&#34;link&#34; href=&#34;https://wandbox.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wandbox.org/&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;cassert&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;functional&amp;gt;
#include &amp;lt;iostream&amp;gt;
#include &amp;lt;vector&amp;gt;

int add_one(int input) { return input + 1; }

bool validate_vector_add_one(std::vector&amp;lt;int&amp;gt; const&amp;amp; input_vector,
                             std::vector&amp;lt;int&amp;gt; const&amp;amp; output_vector)
{
    bool is_valid{true};
    for (size_t i{0}; i &amp;lt; input_vector.size(); ++i)
    {
        if (output_vector.at(i) != input_vector.at(i) + 1)
        {
            is_valid = false;
            break;
        }
    }
    return is_valid;
}

void reset_vector(std::vector&amp;lt;int&amp;gt;&amp;amp; input_vector)
{
    for (size_t i{0}; i &amp;lt; input_vector.size(); ++i)
    {
        input_vector.at(i) = 0;
    }
}

template &amp;lt;typename T, typename Func&amp;gt;
void unitary_function_pass_by_lambda_function(T&amp;amp; output, T const&amp;amp; input,
                                              Func const func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_std_function_value(T&amp;amp; output, T const&amp;amp; input,
                                                 std::function&amp;lt;T(T)&amp;gt; const func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_std_function_reference(
    T&amp;amp; output, T const&amp;amp; input, std::function&amp;lt;T(T)&amp;gt; const&amp;amp; func)
{
    output = func(input);
}

template &amp;lt;typename T&amp;gt;
void unitary_function_pass_by_function_pointer(T&amp;amp; output, T const&amp;amp; input,
                                               T (*func)(T))
{
    output = func(input);
}

int main()
{
    // Set floating point format std::cout with 3 decimal places.
    std::cout.precision(3);

    size_t const num_elements{10000000};
    std::vector&amp;lt;int&amp;gt; input_vector(num_elements, 0);
    std::vector&amp;lt;int&amp;gt; output_vector(num_elements, 0);

    auto const lambda_function_add_one{[](int const&amp;amp; input) -&amp;gt; int
                                       { return input + 1; }};
    std::function&amp;lt;int(int)&amp;gt; const std_function_add_one{lambda_function_add_one};

    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a function pointer: &amp;quot; &amp;lt;&amp;lt; sizeof(&amp;amp;add_one)
              &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a std::function pointer: &amp;quot;
              &amp;lt;&amp;lt; sizeof(&amp;amp;std_function_add_one) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;The size of a std::function: &amp;quot; &amp;lt;&amp;lt; sizeof(std_function_add_one)
              &amp;lt;&amp;lt; std::endl;

    // Call function frequently in a vanilla way.
    // The compiler knows what function to call at compile time and can optimize
    // the code.
    // This is the best performance we could get.
    std::chrono::steady_clock::time_point const time_start_vanilla{
        std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        output_vector.at(i) = add_one(input_vector.at(i));
    }
    std::chrono::steady_clock::time_point const time_end_vanilla{
        std::chrono::steady_clock::now()};
    auto const time_elapsed_vanilla{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(time_end_vanilla -
                                                             time_start_vanilla)
            .count()};
    float const latency_vanilla{time_elapsed_vanilla /
                                static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass Vanilla: &amp;quot; &amp;lt;&amp;lt; latency_vanilla &amp;lt;&amp;lt; &amp;quot; ns&amp;quot;
              &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // Sometimes, we don&#39;t know what function to call at compile time.
    // We can use std::function to pass a function as an argument.
    // In this case, we pass the std::function by value.
    // Because the size of a std::function is 32 bytes, passing by value
    // results in a lot of copying and bad performance.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_std_function_value{std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_std_function_value(
            output_vector.at(i), input_vector.at(i), std_function_add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_std_function_value{std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_std_function_value{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_std_function_value -
            time_start_pass_by_std_function_value)
            .count()};
    float const latency_pass_by_std_function_value{
        time_elapsed_pass_by_std_function_value /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Std Function Value: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_std_function_value &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // Instead of passing the std::function by value, we can pass it by
    // reference (pointer). In this case, object copying is eliminated. The
    // performance is better than passing the std::function by value. However,
    // the performance is still not as good as the vanilla way.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_std_function_reference{
            std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_std_function_reference(
            output_vector.at(i), input_vector.at(i), std_function_add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_std_function_reference{
            std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_std_function_reference{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_std_function_reference -
            time_start_pass_by_std_function_reference)
            .count()};
    float const latency_pass_by_std_function_reference{
        time_elapsed_pass_by_std_function_reference /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Std Function Reference: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_std_function_reference &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // std::function is a general purpose wrapper for function pointers,
    // callable objects, and lambda functions. Because it&#39;s general purpose,
    // it&#39;s not as efficient as a function pointer. In this case, we pass a
    // function pointer to a function. The performance is better than passing
    // the std::function by reference.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_function_pointer{std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_function_pointer(output_vector.at(i),
                                                  input_vector.at(i), &amp;amp;add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_function_pointer{std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_function_pointer{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_function_pointer -
            time_start_pass_by_function_pointer)
            .count()};
    float const latency_pass_by_function_pointer{
        time_elapsed_pass_by_function_pointer /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Function Pointer: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_function_pointer &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);

    // We can also pass a lambda function to a function.
    // The compiler knows what function to call at compile time and can optimize
    // the code. The performance is also better than passing the std::function
    // by reference.
    std::chrono::steady_clock::time_point const
        time_start_pass_by_lambda_function{std::chrono::steady_clock::now()};
    for (size_t i{0}; i &amp;lt; num_elements; ++i)
    {
        unitary_function_pass_by_lambda_function(
            output_vector.at(i), input_vector.at(i), lambda_function_add_one);
    }
    std::chrono::steady_clock::time_point const
        time_end_pass_by_lambda_function{std::chrono::steady_clock::now()};
    auto const time_elapsed_pass_by_lambda_function{
        std::chrono::duration_cast&amp;lt;std::chrono::nanoseconds&amp;gt;(
            time_end_pass_by_lambda_function -
            time_start_pass_by_lambda_function)
            .count()};
    float const latency_pass_by_lambda_function{
        time_elapsed_pass_by_lambda_function /
        static_cast&amp;lt;float&amp;gt;(num_elements)};
    std::cout &amp;lt;&amp;lt; &amp;quot;Latency Pass By Lambda Function: &amp;quot;
              &amp;lt;&amp;lt; latency_pass_by_lambda_function &amp;lt;&amp;lt; &amp;quot; ns&amp;quot; &amp;lt;&amp;lt; std::endl;
    assert(validate_vector_add_one(input_vector, output_vector));
    reset_vector(output_vector);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 组里常规也就开启 O2 优化，编译选用了 gcc13，不同版本的 gcc 性能耗时略有不同，版本越高 lambda 效果越好
The size of a function pointer: 8
The size of a std::function pointer: 8
The size of a std::function: 32
Latency Pass Vanilla: 0.418 ns
Latency Pass By Std Function Value: 3.47 ns
Latency Pass By Std Function Reference: 1.36 ns
Latency Pass By Function Pointer: 0.396 ns
Latency Pass By Lambda Function: 0.44 ns
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;reference-materials&#34;&gt;Reference materials
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leimao.github.io/blog/CPP-Function-Call-Performance/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://leimao.github.io/blog/CPP-Function-Call-Performance/&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>How to anti-debug a program</title>
        <link>https://ttf248.life/en/p/program-how-to-anti-debug/</link>
        <pubDate>Tue, 23 Jan 2024 19:46:36 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/program-how-to-anti-debug/</guid>
        <description>&lt;p&gt;On a whim, I thought about finding new wallpaper. I usually go with black backgrounds, with some colored areas. Since there will be icons on the desktop, other color schemes would make them unclear.&lt;/p&gt;
&lt;p&gt;Stared at the assembly code for a while, couldn&amp;rsquo;t understand it. Tried throwing it to &lt;code&gt;AI&lt;/code&gt;, which explained the instructions but not the context. It must be an instruction used in some specific scenario; it wouldn’t appear in regular code.&lt;/p&gt;
&lt;p&gt;AI is not as good as search engines now; it lacks sufficient knowledge accumulated through assembly&lt;/p&gt;
&lt;h2 id=&#34;wallpaper&#34;&gt;Wallpaper
&lt;/h2&gt;&lt;p&gt;Black assembly wallpaper&lt;/p&gt;
&lt;h2 id=&#34;assembly-code&#34;&gt;Assembly code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;PUSHFD
MOV DWORD PTR [ESP],0X100
POPFD
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Actual application scenarios&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;bool IsDebugged()
{
    __try
    {
        __asm
        {
            pushfd
            mov dword ptr [esp], 0x100
            popfd
            nop
        }
        return true;
    }
    __except(GetExceptionCode() == EXCEPTION_SINGLE_STEP
        ? EXCEPTION_EXECUTE_HANDLER
        : EXCEPTION_CONTINUE_EXECUTION)
    {
        return false;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;explanation&#34;&gt;Explanation
&lt;/h2&gt;&lt;p&gt;The &lt;code&gt;TrapFlag&lt;/code&gt; is a flag in the status register. When this flag is set, an exception &lt;code&gt;SINGLE_STEP&lt;/code&gt; is thrown. Because if we are tracing code, the debugger clears this flag, so we won&amp;rsquo;t see this exception.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In actual testing, if you step over the detection and debugging functions directly, the debugging will not be detected; it is only detected when stepping into the execution of the detection function (literature query, not yet actually verified)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;reference-materials&#34;&gt;Reference materials
&lt;/h2&gt;&lt;p&gt;The relevant materials in Chinese are translations of website drafts, and the site explains many anti-debugging techniques&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://anti-debug.checkpoint.com/techniques/assembly.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://anti-debug.checkpoint.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://song-10.gitee.io/2021/08/08/Reverse-2021-08-08-anti-debug/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://song-10.gitee.io/2021/08/08/Reverse-2021-08-08-anti-debug/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>How to download Focus Interviews/CCTV video files</title>
        <link>https://ttf248.life/en/p/how-to-download-focus-interview-cctv-video-files/</link>
        <pubDate>Tue, 23 Jan 2024 19:23:35 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/how-to-download-focus-interview-cctv-video-files/</guid>
        <description>&lt;p&gt;Recently, some people have asked how to download CCTV’s “Focus Interviews” videos. I immediately thought it was likely encrypted using the &lt;code&gt;m3u8&lt;/code&gt; method, so I quickly dealt with it.&lt;/p&gt;
&lt;h2 id=&#34;downloader&#34;&gt;Downloader
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/nilaoda/N_m3u8DL-CLI&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/nilaoda/N_m3u8DL-CLI&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;An open-source command-line m3u8/HLS/DASH downloader that supports standard AES-128-CBC decryption, multi-threading, custom request headers, etc. Supports Simplified Chinese, Traditional Chinese and English. English Supported.&lt;/p&gt;
&lt;h2 id=&#34;browser-extension&#34;&gt;Browser extension
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://microsoftedge.microsoft.com/addons/detail/ngjclnbcdbahekojpkhancmiobdahemb&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Live Stream Downloader&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;honey-glazed-confidence&#34;&gt;Honey-glazed confidence
&lt;/h2&gt;&lt;p&gt;I got the address, thought I was done with it, but it turned out to be nothing. It couldn&amp;rsquo;t normally parse the segmented content. After checking the information, I found that the official side had handled the download address and required manual replacement. The &lt;code&gt;key&lt;/code&gt; parsed by the plugin needs to be manually copied and replaced in the link below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;https://newcntv.qcloudcdn.com/asp/hls/2000/0303000a/3/default/***********************/2000.m3u8
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As of January 2024, address testing is valid. If there are any changes afterward, analyze the webpage yourself.&lt;/p&gt;
&lt;p&gt;Historical address backup: &lt;code&gt;https://hlswx.cntv.kcdnvip.com/asp/hls/main/0303000a/3/default/A string of characters/main.m3u8?maxbr=2000&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;reference-materials&#34;&gt;Reference materials
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://jln.cn/post/517.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://jln.cn/post/517.html&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>Batch modification of SQL Server database disk file permissions</title>
        <link>https://ttf248.life/en/p/bulk-modify-sqlserver-database-disk-file-permissions/</link>
        <pubDate>Tue, 23 Jan 2024 19:06:36 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/bulk-modify-sqlserver-database-disk-file-permissions/</guid>
        <description>&lt;p&gt;The company&amp;rsquo;s security policy has been adjusted, and &lt;code&gt;Mechanical Master mini&lt;/code&gt; was ultimately moved back home as a backup server. The machine system was also reinstalled, and &lt;code&gt;Ubuntu&lt;/code&gt; switched to &lt;code&gt;Windows Server&lt;/code&gt;. Since the activation method wasn’t legitimate, it seems fine without activating when used at home.&lt;/p&gt;
&lt;p&gt;Activating through unconventional means triggered Microsoft&amp;rsquo;s detection (it had been running normally for half a month). The server shut down automatically after one hour of being turned on. After checking the system logs, it was discovered to be due to piracy.&lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s no way around it, I have to reinstall the system again. &lt;code&gt;SqlServer&lt;/code&gt; also needs a reinstall. Each time is quite troublesome; strict file permission controls prevent me from properly attaching the database.&lt;/p&gt;
&lt;h2 id=&#34;error-message&#34;&gt;Error message
&lt;/h2&gt;&lt;p&gt;After reinstalling the system, an error of 5120 and access denied may occur when attaching a database in &lt;code&gt;SqlServer&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;process-script&#34;&gt;Process script
&lt;/h2&gt;&lt;p&gt;The link to the previous article: &lt;a class=&#34;link&#34; href=&#34;https://ttf248.life/en/p/bulk-update-local-git-repository-and-legacy-permission-issues/&#34; &gt;Batch Update Local Git Repository&lt;/a&gt;. It&amp;rsquo;s this familiar script again, modified so that while we traverse the folders, we also change the file permissions to grant full editing rights.&lt;/p&gt;
&lt;p&gt;Most of the online tutorials require you to manually modify things. Do they only need to change a few files each time? I have to deal with batches of files every time, all manually – it&amp;rsquo;s enough to make someone feel depressed.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$currentUserName = [System.Security.Principal.WindowsIdentity]::GetCurrent().Name
[Console]::OutputEncoding = [System.Text.Encoding]::UTF8
$rootDirectory = &amp;quot;D:\data\2013_RujiaInfo&amp;quot;

Get-ChildItem -Path $rootDirectory -Recurse | ForEach-Object {
    $itemPath = $_.FullName

    if ($_ -is [System.IO.DirectoryInfo]) {
        $icaclsResult = icacls $itemPath /setowner &amp;quot;$currentUserName&amp;quot; 2&amp;gt;&amp;amp;1
        if ($LASTEXITCODE -eq 0) {
            Write-Host &amp;quot;已更改文件夹 $itemPath 的所有者为 $currentUserName&amp;quot;
            # 授予当前用户写入权限
            Invoke-Expression &amp;quot;icacls `&amp;quot;$itemPath`&amp;quot; /grant `&amp;quot;$($currentUserName):(OI)(CI)F`&amp;quot;&amp;quot;
            Write-Host &amp;quot;已授予 $currentUserName 编辑文件夹的权限&amp;quot;
        } else {
            Write-Host &amp;quot;无法更改文件夹 $itemPath 的所有者。错误信息: $icaclsResult&amp;quot;
        }
    } else {
        $takeownResult = icacls $itemPath /setowner &amp;quot;$currentUserName&amp;quot; 2&amp;gt;&amp;amp;1
        if ($LASTEXITCODE -eq 0) {
            # 授予当前用户写入权限
            Invoke-Expression &amp;quot;icacls `&amp;quot;$itemPath`&amp;quot; /grant `&amp;quot;$($currentUserName):(F)`&amp;quot;&amp;quot;
            Write-Host &amp;quot;已授予 $currentUserName 编辑文件的权限&amp;quot;
        } else {
            Write-Host &amp;quot;无法更改文件 $itemPath 的所有者。错误信息: $takeownResult&amp;quot;
        }
    }
}

&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Linux system benchmark testing</title>
        <link>https://ttf248.life/en/p/linux-system-benchmark-test/</link>
        <pubDate>Tue, 09 Jan 2024 10:56:23 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-system-benchmark-test/</guid>
        <description>&lt;p&gt;The Windows platform has a program called &amp;ldquo;Rulu Master&amp;rdquo; (Entertainment Master), which isn&amp;rsquo;t necessarily accurate with its data, but it does provide some reference. Of course, there are other professional benchmarking software available. On the Linux system, I haven’t found any particularly suitable benchmarking software yet.&lt;/p&gt;
&lt;p&gt;Sysbench is a versatile benchmarking tool that can be used to test CPU, memory, file I/O, thread performance, and more. You can use Sysbench to perform various performance testing tasks.&lt;/p&gt;
&lt;p&gt;I just happen to have three machines available for testing: Mecha-Debug Mini local host, Alibaba Cloud Dev development cloud server, and Huawei Cloud development server&lt;/p&gt;
&lt;h2 id=&#34;installing-sysbench&#34;&gt;Installing Sysbench
&lt;/h2&gt;&lt;p&gt;In most Linux distributions, you can use a package management tool to install Sysbench. For example, on CentOS 8, you can use the following command for installation.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo dnf install sysbench
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;examples-of-using-sysbench&#34;&gt;Examples of Using Sysbench
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Test CPU performance: &lt;code&gt;sysbench --test=cpu run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Test memory read performance: &lt;code&gt;sysbench --test=memory run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Testing File I/O Performance:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sysbench --test=fileio --file-test-mode=rndrw prepare
sysbench --test=fileio --file-test-mode=rndrw run
sysbench --test=fileio --file-test-mode=rndrw cleanup
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Testing multi-threading performance: &lt;code&gt;sysbench --test=threads --num-threads=4 run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Testing MySQL database performance (requires adjusting the maximum number of connections):&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword --oltp-table-size=1000000 prepare
sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword --max-time=60 --oltp-read-only=off --oltp-test-mode=complex --max-requests=0 run
sysbench --test=oltp --db-driver=mysql --mysql-db=test --mysql-user=yourusername --mysql-password=yourpassword cleanup
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;benchmark-data-report&#34;&gt;Benchmark Data Report
&lt;/h2&gt;&lt;meta http-equiv=&#34;Content-Type&#34; content=&#34;text/html; charset=utf-8&#34;&gt;&lt;link type=&#34;text/css&#34; rel=&#34;stylesheet&#34; href=&#34;resources/sheet.css&#34; &gt;
&lt;style type=&#34;text/css&#34;&gt;.ritz .waffle a { color: inherit; }.ritz .waffle .s0{background-color:#ffffff;text-align:left;color:#000000;font-family:&#39;Arial&#39;;font-size:10pt;vertical-align:bottom;white-space:nowrap;direction:ltr;padding:2px 3px 2px 3px;}&lt;/style&gt;&lt;div class=&#34;ritz grid-container&#34; dir=&#34;ltr&#34;&gt;&lt;table class=&#34;waffle&#34; cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th class=&#34;row-header freezebar-origin-ltr&#34;&gt;&lt;/th&gt;&lt;th id=&#34;0C0&#34; style=&#34;width:100px;&#34; class=&#34;column-headers-background&#34;&gt;A&lt;/th&gt;&lt;th id=&#34;0C1&#34; style=&#34;width:421px;&#34; class=&#34;column-headers-background&#34;&gt;B&lt;/th&gt;&lt;th id=&#34;0C2&#34; style=&#34;width:398px;&#34; class=&#34;column-headers-background&#34;&gt;C&lt;/th&gt;&lt;th id=&#34;0C3&#34; style=&#34;width:422px;&#34; class=&#34;column-headers-background&#34;&gt;D&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R0&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;1&lt;/div&gt;&lt;/th&gt;&lt;td&gt;&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;本地机械师&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;阿里云&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;华为云&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R1&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;2&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;系统配置&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Information&lt;br&gt;  Operating System              Ubuntu 23.04&lt;br&gt;  Kernel                        Linux 6.2.0-36-generic x86_64&lt;br&gt;  Model                         Machenike Machenike DT Computer&lt;br&gt;  Motherboard                   Machenike Machenike DT Computer&lt;br&gt;  BIOS                          American Megatrends International, LLC.&lt;br&gt;DB19V012&lt;br&gt;&lt;br&gt;CPU Information&lt;br&gt;  Name                          Intel Core i7-12650H&lt;br&gt;  Topology                      1 Processor, 10 Cores, 16 Threads&lt;br&gt;  Identifier                    GenuineIntel Family 6 Model 154 Stepping 3&lt;br&gt;  Base Frequency                4.60 GHz&lt;br&gt;  L1 Instruction Cache          32.0 KB x 8&lt;br&gt;  L1 Data Cache                 48.0 KB x 8&lt;br&gt;  L2 Cache                      1.25 MB x 2&lt;br&gt;  L3 Cache                      24.0 MB&lt;br&gt;&lt;br&gt;Memory Information&lt;br&gt;  Size                          62.6 GB&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Information&lt;br&gt;  Operating System              CentOS Stream 8&lt;br&gt;  Kernel                        Linux 4.18.0-513.el8.x86_64 x86_64&lt;br&gt;  Model                         Alibaba Cloud Alibaba Cloud ECS&lt;br&gt;  Motherboard                   N/A&lt;br&gt;  BIOS                          SeaBIOS 449e491&lt;br&gt;&lt;br&gt;CPU Information&lt;br&gt;  Name                          Intel(R) Xeon(R) Platinum&lt;br&gt;  Topology                      1 Processor, 1 Core, 2 Threads&lt;br&gt;  Identifier                    GenuineIntel Family 6 Model 85 Stepping 4&lt;br&gt;  Base Frequency                2.50 GHz&lt;br&gt;  L1 Instruction Cache          32.0 KB&lt;br&gt;  L1 Data Cache                 32.0 KB&lt;br&gt;  L2 Cache                      1.00 MB&lt;br&gt;  L3 Cache                      33.0 MB&lt;br&gt;&lt;br&gt;Memory Information&lt;br&gt;  Size                          1.65 GB&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;System Information&lt;br&gt;  Operating System              Ubuntu 22.04.1 LTS&lt;br&gt;  Kernel                        Linux 5.15.0-60-generic x86_64&lt;br&gt;  Model                         OpenStack Foundation OpenStack Nova&lt;br&gt;  Motherboard                   N/A&lt;br&gt;  BIOS                          SeaBIOS&lt;br&gt;rel-1.10.2-0-g5f4c7b1-20181220_000000-szxrtosci10000&lt;br&gt;&lt;br&gt;CPU Information&lt;br&gt;  Name                          Intel(R) Xeon(R) Gold 6278C CPU @ 2.60GHz&lt;br&gt;  Topology                      1 Processor, 1 Core, 2 Threads&lt;br&gt;  Identifier                    GenuineIntel Family 6 Model 85 Stepping 7&lt;br&gt;  Base Frequency                2.60 GHz&lt;br&gt;  L1 Instruction Cache          32.0 KB&lt;br&gt;  L1 Data Cache                 32.0 KB&lt;br&gt;  L2 Cache                      1.00 MB&lt;br&gt;  L3 Cache                      35.8 MB&lt;br&gt;&lt;br&gt;Memory Information&lt;br&gt;  Size                          3.64 GB&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R2&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;3&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;CPU&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  4032.48&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0004s&lt;br&gt;    total number of events:              40330&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.25&lt;br&gt;         avg:                                    0.25&lt;br&gt;         max:                                    0.73&lt;br&gt;         95th percentile:                        0.25&lt;br&gt;         sum:                                 9997.55&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           40330.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9975/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  1062.51&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0008s&lt;br&gt;    total number of events:              10628&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.91&lt;br&gt;         avg:                                    0.94&lt;br&gt;         max:                                   22.84&lt;br&gt;         95th percentile:                        1.06&lt;br&gt;         sum:                                 9993.46&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           10628.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9935/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Prime numbers limit: 10000&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;CPU speed:&lt;br&gt;    events per second:  1125.56&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0005s&lt;br&gt;    total number of events:              11258&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.86&lt;br&gt;         avg:                                    0.89&lt;br&gt;         max:                                    1.70&lt;br&gt;         95th percentile:                        0.99&lt;br&gt;         sum:                                 9995.40&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           11258.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9954/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R3&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;4&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;内存&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 101993199 (10198146.52 per second)&lt;br&gt;&lt;br&gt;99602.73 MiB transferred (9959.13 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              101993199&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                    0.03&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4059.50&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           101993199.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.0595/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 48418803 (4841004.79 per second)&lt;br&gt;&lt;br&gt;47283.99 MiB transferred (4727.54 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              48418803&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                   25.26&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4578.95&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           48418803.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.5789/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Running memory speed test with the following options:&lt;br&gt;  block size: 1KiB&lt;br&gt;  total size: 102400MiB&lt;br&gt;  operation: write&lt;br&gt;  scope: global&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;Total operations: 57056904 (5704765.11 per second)&lt;br&gt;&lt;br&gt;55719.63 MiB transferred (5571.06 MiB/sec)&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0001s&lt;br&gt;    total number of events:              57056904&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.00&lt;br&gt;         max:                                    0.06&lt;br&gt;         95th percentile:                        0.00&lt;br&gt;         sum:                                 4556.06&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           57056904.0000/0.00&lt;br&gt;    execution time (avg/stddev):   4.5561/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R4&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;5&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;硬盘&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 1.81 seconds (1129.59 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      3373.41&lt;br&gt;    writes/s:                     2248.94&lt;br&gt;    fsyncs/s:                     7201.80&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  52.71&lt;br&gt;    written, MiB/s:               35.14&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0127s&lt;br&gt;    total number of events:              128288&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.08&lt;br&gt;         max:                                    5.14&lt;br&gt;         95th percentile:                        0.34&lt;br&gt;         sum:                                 9977.78&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           128288.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9778/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 19.29 seconds (106.16 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      1593.12&lt;br&gt;    writes/s:                     1062.08&lt;br&gt;    fsyncs/s:                     3406.64&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  24.89&lt;br&gt;    written, MiB/s:               16.60&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0164s&lt;br&gt;    total number of events:              60600&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.16&lt;br&gt;         max:                                   31.32&lt;br&gt;         95th percentile:                        0.54&lt;br&gt;         sum:                                 9956.30&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           60600.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9563/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;2147483648 bytes written in 18.29 seconds (111.98 MiB/sec).&lt;br&gt;&lt;br&gt;Running the test with following options:&lt;br&gt;Number of threads: 1&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Extra file open flags: (none)&lt;br&gt;128 files, 16MiB each&lt;br&gt;2GiB total file size&lt;br&gt;Block size 16KiB&lt;br&gt;Number of IO requests: 0&lt;br&gt;Read/Write ratio for combined random IO test: 1.50&lt;br&gt;Periodic FSYNC enabled, calling fsync() each 100 requests.&lt;br&gt;Calling fsync() at the end of test, Enabled.&lt;br&gt;Using synchronous I/O mode&lt;br&gt;Doing random r/w test&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;File operations:&lt;br&gt;    reads/s:                      1665.88&lt;br&gt;    writes/s:                     1110.59&lt;br&gt;    fsyncs/s:                     3563.77&lt;br&gt;&lt;br&gt;Throughput:&lt;br&gt;    read, MiB/s:                  26.03&lt;br&gt;    written, MiB/s:               17.35&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0112s&lt;br&gt;    total number of events:              63355&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.00&lt;br&gt;         avg:                                    0.16&lt;br&gt;         max:                                  205.01&lt;br&gt;         95th percentile:                        0.78&lt;br&gt;         sum:                                 9972.64&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           63355.0000/0.00&lt;br&gt;    execution time (avg/stddev):   9.9726/0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&#34;height: 20px&#34;&gt;&lt;th id=&#34;0R5&#34; style=&#34;height: 20px;&#34; class=&#34;row-headers-background&#34;&gt;&lt;div class=&#34;row-header-wrapper&#34; style=&#34;line-height: 20px&#34;&gt;6&lt;/div&gt;&lt;/th&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;多线程&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0002s&lt;br&gt;    total number of events:              197956&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.16&lt;br&gt;         avg:                                    0.20&lt;br&gt;         max:                                    0.34&lt;br&gt;         95th percentile:                        0.21&lt;br&gt;         sum:                                39970.47&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           49489.0000/5.70&lt;br&gt;    execution time (avg/stddev):   9.9926/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0174s&lt;br&gt;    total number of events:              18360&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.57&lt;br&gt;         avg:                                    2.18&lt;br&gt;         max:                                   32.77&lt;br&gt;         95th percentile:                        2.61&lt;br&gt;         sum:                                40050.41&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           4590.0000/94.36&lt;br&gt;    execution time (avg/stddev):   10.0126/0.00&lt;/td&gt;&lt;td class=&#34;s0&#34; dir=&#34;ltr&#34;&gt;Running the test with following options:&lt;br&gt;Number of threads: 4&lt;br&gt;Initializing random number generator from current time&lt;br&gt;&lt;br&gt;&lt;br&gt;Initializing worker threads...&lt;br&gt;&lt;br&gt;Threads started!&lt;br&gt;&lt;br&gt;&lt;br&gt;General statistics:&lt;br&gt;    total time:                          10.0004s&lt;br&gt;    total number of events:              28536&lt;br&gt;&lt;br&gt;Latency (ms):&lt;br&gt;         min:                                    0.23&lt;br&gt;         avg:                                    1.40&lt;br&gt;         max:                                    3.56&lt;br&gt;         95th percentile:                        1.47&lt;br&gt;         sum:                                39975.16&lt;br&gt;&lt;br&gt;Threads fairness:&lt;br&gt;    events (avg/stddev):           7134.0000/39.87&lt;br&gt;    execution time (avg/stddev):   9.9938/0.01&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;
&lt;h2 id=&#34;afterword&#34;&gt;Afterword
&lt;/h2&gt;&lt;p&gt;ChatGPT is still a good thing. The table there cannot be arranged according to the previously mastered Markdown; if it&amp;rsquo;s not made into a table, the display effect will be very poor. Custom themes limited the maximum page width, and I adjusted the page configuration in sync, changing the width to a percentage limit.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A simple method is to use online tools like TablesGenerator to generate HTML tables (not suitable for complex content)&lt;/li&gt;
&lt;li&gt;Or use Google Docs online, then download and save as an HTML document, and directly copy it into the blog (simple and direct, this is the method we adopted)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Make sure the config is enabled with the unsafe setting, and configure the width separately for each page&lt;/p&gt;
&lt;p&gt;In Hugo, you can set the width for pages individually. This can be achieved by adding a custom parameter in the page&amp;rsquo;s Front Matter. Here is an example:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Add a custom parameter, such as &lt;code&gt;custom_width&lt;/code&gt;, in the Front Matter section of your Markdown page (usually at the beginning of the file)&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;---
title: &amp;quot;我的页面&amp;quot;
date: 2024-01-09
custom_width: &amp;quot;800px&amp;quot;  # 设置宽度为 800 像素
---

正文内容...
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;
&lt;p&gt;In your Hugo theme, find or create the corresponding single-page template file (for example, &lt;code&gt;layouts/_default/single.html&lt;/code&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In single-page templates, check for a &lt;code&gt;custom_width&lt;/code&gt; parameter in the page&amp;rsquo;s Front Matter and apply it to the corresponding HTML element, such as a &lt;code&gt;div&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;{{ define &amp;quot;main&amp;quot; }}
  &amp;lt;div style=&amp;quot;max-width: {{ with .Params.custom_width }}{{ . }}{{ else }}100%{{ end }}; margin: 0 auto;&amp;quot;&amp;gt;
    {{ .Content }}
  &amp;lt;/div&amp;gt;
{{ end }}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, we used inline styles (the &lt;code&gt;style&lt;/code&gt; attribute) to set the &lt;code&gt;max-width&lt;/code&gt; property for the &lt;code&gt;div&lt;/code&gt; element, so that when the &lt;code&gt;custom_width&lt;/code&gt; parameter is not specified, its width defaults to 100%. &lt;code&gt;margin: 0 auto;&lt;/code&gt; is used to center the &lt;code&gt;div&lt;/code&gt; element.&lt;/p&gt;
&lt;p&gt;Please note that in practical applications, you may need to adjust the above examples according to your theme structure and CSS style details. Ensure consistency and readability of your theme when adjusting styles.&lt;/p&gt;
&lt;p&gt;Due to slight differences in the enabled theme, the site&amp;rsquo;s custom &lt;code&gt;CSS&lt;/code&gt; configuration was adjusted&lt;/p&gt;</description>
        </item>
        <item>
        <title>Disable HTTP repositories in Git</title>
        <link>https://ttf248.life/en/p/git-disable-http-repositories/</link>
        <pubDate>Mon, 08 Jan 2024 21:22:04 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/git-disable-http-repositories/</guid>
        <description>&lt;p&gt;I&amp;rsquo;ve gotten used to updating software versions, but I don’t know from which version of &lt;code&gt;Git&lt;/code&gt; onwards it started prohibiting pulling code from &lt;code&gt;HTTP&lt;/code&gt; repositories&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;fatal: Unencrypted HTTP is not supported for GitLab. Ensure the repository remote URL is using HTTPS
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;background-introduction&#34;&gt;Background introduction
&lt;/h2&gt;&lt;p&gt;Environment: Windows platform, I&amp;rsquo;ve always used TortoiseGit to operate git, and configured keys through TortoiseGit as well. I previously set up a script to batch update local repositories.&lt;/p&gt;
&lt;p&gt;Previous link: [Batch Update Local Git Repository]({relref &amp;ldquo;/post/2023/10-19-批量更新本地git仓库&amp;rdquo;})&lt;/p&gt;
&lt;p&gt;When I tried to deploy a code update at home today, the error mentioned earlier occurred, and the repository could not be updated normally. I thought &lt;code&gt;Git&lt;/code&gt; should provide a configuration option to allow me to continue updating the repository using the &lt;code&gt;http&lt;/code&gt; protocol, but I searched around and couldn&amp;rsquo;t find the corresponding setting.&lt;/p&gt;
&lt;p&gt;The simplest solution is of course to switch to the &lt;code&gt;ssh&lt;/code&gt; protocol to update the repository, as the company&amp;rsquo;s configuration will not provide the &lt;code&gt;https&lt;/code&gt; protocol for &lt;code&gt;gitlab&lt;/code&gt; in the short term&lt;/p&gt;
&lt;h2 id=&#34;outstanding-issues&#34;&gt;Outstanding issues
&lt;/h2&gt;&lt;p&gt;When writing the batch update local repository script earlier, I originally intended to pull the repository using &lt;code&gt;ssh&lt;/code&gt;, but didn&amp;rsquo;t investigate why it failed. It turned out that the &lt;code&gt;git&lt;/code&gt; configuration information configured in TortoiseGit wasn&amp;rsquo;t synchronized to the config file, which caused issues when executing through the command line.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git pull #提示没有权限，无法正常更新仓库
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Checking the key configuration with a command is also correct: &lt;code&gt;ssh -T git@gitlab.yintech.net&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If you can normally pull code using TortoiseGit, but are prompted with a key error when using the &lt;code&gt;git pull&lt;/code&gt; command in the command line, this may be because TortoiseGit uses PuTTY’s SSH key while the command line uses OpenSSH’s SSH key&lt;/p&gt;
&lt;p&gt;The small turtle&amp;rsquo;s key configuration does not read key file information from the system .ssh folder, but instead configures the key file path separately when configuring the interface repository. A useful tip: configuring a key for the first repository being pulled allows other repositories to reuse this key file. After PuTTY loads the key, it doesn’t immediately exit but starts an agent service.&lt;/p&gt;
&lt;p&gt;By adjusting the global configuration and not using the system&amp;rsquo;s default &lt;code&gt;ssh&lt;/code&gt; configuration, Git Bash will use TortoisePlink for SSH operations with this configuration. This setup is suitable for situations where you are using the PuTTY tool that comes with TortoiseGit.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git config --global core.sshCommand &amp;quot;&#39;C:/Program Files/TortoiseGit/bin/TortoisePlink.exe&#39; -batch -ssh&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Modify the execution file path as needed to correspond with your Little Turtle installation directory. Since a full path is configured, you do not need to add it to your system environment variables.&lt;/p&gt;</description>
        </item>
        <item>
        <title>AI programming and task decomposition</title>
        <link>https://ttf248.life/en/p/ai-programming-and-task-decomposition/</link>
        <pubDate>Fri, 22 Dec 2023 08:44:26 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/ai-programming-and-task-decomposition/</guid>
        <description>&lt;p&gt;Two years ago, I added a copy function for the code area on the site. It took almost half a day of effort, and the final rendering effect was not ideal. As a novice front-end developer, I didn&amp;rsquo;t bother to improve it; as long as it worked, that was fine. This year, using &lt;code&gt;AI&lt;/code&gt; to develop a mini program, I’m also more familiar with front-end development, so I rebuilt (redesigned by AI) it.&lt;/p&gt;
&lt;p&gt;Understanding the Dao: The task has been broken down into many small tasks, and AI development is still smooth. For a previously defunct mini-program, 75% of the code was provided by AI, and it was delivered through multiple tasks, with manual assembly of project code.&lt;/p&gt;
&lt;h2 id=&#34;previous-text&#34;&gt;Previous text
&lt;/h2&gt;&lt;p&gt;Adding a code copy button to what seems like a simple thing&lt;/p&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;Design CSS and JavaScript code to locate webpage elements with the class &amp;ldquo;highlight&amp;rdquo;. Within the container of these elements, add a copy button to implement the functionality of copying the code.&lt;/p&gt;
&lt;p&gt;The first draft of the code looks problematic at a glance. A second draft was generated, which is basically usable, but contains incorrect copied content and redundant text. Further optimization is needed, with manual specification of core color design and included effects.&lt;/p&gt;
&lt;p&gt;We understand you have specific requirements for the button&amp;rsquo;s size and color. We can redesign the button style to accommodate these requirements. Here is an adjusted CSS style, which includes the color scheme you provided and optimizes the button’s dimensions.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.copy-btn {
  position: absolute;
  top: 2px; /* 调整位置 */
  right: 2px;
  padding: 3px 6px; /* 缩小尺寸 */
  font-size: 12px; /* 减小字体大小 */
  background-color: #8FD1E1; /* 按钮背景色 */
  color: #272822; /* 文字颜色 */
  border: 1px solid #272822; /* 边框颜色 */
  border-radius: 3px; /* 圆角 */
  cursor: pointer;
  opacity: 0.7; /* 默认半透明 */
  transition: opacity 0.3s ease, background-color 0.3s ease; /* 平滑过渡效果 */
}

.copy-btn:hover {
  opacity: 1; /* 鼠标悬停时不透明 */
  background-color: #A3D4E5; /* 鼠标悬停时的背景色 */
}

.highlight {
  position: relative;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this style, I have reduced the size of the buttons and font size to make them more refined. At the same time, the default state of the button is semi-transparent, and when the mouse hovers over it, it becomes opaque, and the background color will become slightly brighter to provide visual feedback. This design both meets your color requirements and maintains a modern and user-friendly feel.&lt;/p&gt;
&lt;p&gt;A simpler JavaScript was provided accordingly&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-JavaScript&#34;&gt;document.addEventListener(&#39;DOMContentLoaded&#39;, function() {
  // 查找所有 .highlight 元素
  const highlights = document.querySelectorAll(&#39;.highlight&#39;);

  highlights.forEach(function(highlight) {
    // 创建复制按钮
    const copyBtn = document.createElement(&#39;button&#39;);
    copyBtn.textContent = &#39;复制&#39;;
    copyBtn.classList.add(&#39;copy-btn&#39;);

    // 将按钮添加到每个 .highlight 元素中
    highlight.appendChild(copyBtn);

    // 添加点击事件监听器
    copyBtn.addEventListener(&#39;click&#39;, function() {
      // 假设 .highlight 下的第一个 &amp;lt;code&amp;gt; 元素包含要复制的代码
      const code = highlight.querySelector(&#39;code&#39;) ? highlight.querySelector(&#39;code&#39;).textContent : &#39;&#39;;

      navigator.clipboard.writeText(code).then(() =&amp;gt; {
        // 显示复制成功信息
        copyBtn.textContent = &#39;已复制!&#39;;
        setTimeout(() =&amp;gt; {
          copyBtn.textContent = &#39;复制&#39;;
        }, 2000);
      }).catch(err =&amp;gt; {
        console.error(&#39;复制失败: &#39;, err);
      });
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;afterword&#34;&gt;Afterword
&lt;/h2&gt;&lt;p&gt;Although I would prefer a copy button to be added in the top area of the code region, due to my lack of understanding of frontend development, I couldn&amp;rsquo;t accurately describe the function based on keywords. After several rounds of troubleshooting with &lt;code&gt;AI&lt;/code&gt;, it still didn’t reach the expected result.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s just that I don&amp;rsquo;t know how much impact AI will have on software development as time goes on&lt;/p&gt;</description>
        </item>
        <item>
        <title>Cloud server and script kiddie</title>
        <link>https://ttf248.life/en/p/cloud-servers-and-script-kids/</link>
        <pubDate>Mon, 20 Nov 2023 15:08:53 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/cloud-servers-and-script-kids/</guid>
        <description>&lt;p&gt;Taking advantage of the Double Eleven promotion, Alibaba Cloud has purchased a new server: an economical version, costing 99 yuan per year. The configuration isn&amp;rsquo;t high-end, but it’s good as a jump server to proxy services for home use. The promotion lasts until 2026.&lt;/p&gt;
&lt;p&gt;I specifically chose a server in the Shanghai area, proxying my home machine with low latency. It&amp;rsquo;s Windows 11 and Windows Server 2022; the server version was deployed later. When I tried to use it, I suddenly received an &amp;ldquo;access denied&amp;rdquo; message. I initially thought it was due to a server update and would return to normal shortly. After waiting five minutes, I tried again, but still couldn&amp;rsquo;t log in. Searching for related errors indicated that someone was attempting to log in, and now login is unavailable due to too many incorrect password attempts.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve previously dealt with security attack scripts, and immediately thought that these logins are likely not normal behavior – someone is attacking the service, attempting to brute-force the login server. The server firewall settings were convenient but didn’t set up whitelists. It proxied the 3389 ports of two machines, exposing them on the public network—just like bait in a fishpond. Now that I know it&amp;rsquo;s a script kiddie attacking, the next steps are simple: configure the firewall whitelist to only allow access to the proxy service from company IP addresses and home IP addresses.&lt;/p&gt;
&lt;p&gt;The frps agent server wasn&amp;rsquo;t configured with running logs before. After enabling the logs, I was quite surprised to see proxy IPs from all over the country attempting to log in to my home server. Luckily, one of them was a server version, which alerted me to the problem. Otherwise, that Windows 11 machine would have been compromised eventually – the password was set up pretty simply.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;2023/11/17 16:51:14 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [101.43.98.211:50486]
2023/11/17 16:51:14 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [218.93.202.63:56970]
2023/11/17 16:51:14 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [222.179.106.174:60812]
2023/11/17 16:51:15 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [58.16.204.238:2839]
2023/11/17 16:51:15 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [124.223.47.24:50274]
2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [43.248.128.22:55883]
2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [43.143.53.138:56955]
2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [43.228.7.250:61550]
2023/11/17 16:51:16 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [125.76.228.9:55842]
2023/11/17 16:51:17 [I] [proxy.go:204] [4dfcc2259937dcb9] [winserver-remote] get a user connection [91.240.118.187:49326]
2023/11/17 16:51:17 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [91.240.118.187:49324]
2023/11/17 16:51:17 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [89.248.163.79:51712]
2023/11/17 16:51:18 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [218.63.75.24:62387]
2023/11/17 16:51:19 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [103.186.109.227:51396]
2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [116.233.234.104:51567]
2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [222.187.193.202:51585]
2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [59.48.98.42:57489]
2023/11/17 16:51:20 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [146.56.241.134:53558]
2023/11/17 16:51:21 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [222.179.106.174:30620]
2023/11/17 16:51:23 [I] [proxy.go:204] [639d8947325142ac] [host-remote] get a user connection [183.14.214.51:62128]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I checked the login logs for the Linux service as an afterthought, and besides Aliyun&amp;rsquo;s machine, there&amp;rsquo;s also a friend&amp;rsquo;s Huawei Cloud machine&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo grep &amp;quot;Failed password&amp;quot; /var/log/secure  centos系列
sudo grep &amp;quot;Failed password&amp;quot; /var/log/auth.log  ubuntu系列
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Nov 16 04:46:34 aliyun-sh sshd[156625]: Failed password for root from 120.55.164.64 port 53410 ssh2
Nov 16 04:46:34 aliyun-sh sshd[156623]: Failed password for root from 111.16.215.122 port 36548 ssh2
Nov 16 04:46:58 aliyun-sh sshd[156630]: Failed password for invalid user share from 139.9.233.78 port 53872 ssh2
Nov 16 04:47:23 aliyun-sh sshd[156634]: Failed password for invalid user spark from 139.9.233.78 port 36134 ssh2
Nov 16 04:47:26 aliyun-sh sshd[156636]: Failed password for root from 120.55.164.64 port 46142 ssh2
Nov 16 04:47:47 aliyun-sh sshd[156640]: Failed password for root from 111.16.215.122 port 42962 ssh2
Nov 16 04:48:24 aliyun-sh sshd[156652]: Failed password for root from 120.55.164.64 port 38868 ssh2
Nov 16 04:48:25 aliyun-sh sshd[156654]: Failed password for root from 111.16.215.122 port 46164 ssh2
Nov 16 04:48:39 aliyun-sh sshd[156657]: Failed password for invalid user test from 139.9.233.78 port 39386 ssh2
Nov 16 04:48:50 aliyun-sh sshd[156659]: Failed password for root from 111.16.215.122 port 38892 ssh2
Nov 16 04:48:53 aliyun-sh sshd[156662]: Failed password for root from 120.55.164.64 port 49348 ssh2
Nov 16 04:48:53 aliyun-sh sshd[156664]: Failed password for invalid user test from 139.9.233.78 port 49864 ssh2
Nov 16 04:50:02 aliyun-sh sshd[156672]: Failed password for root from 111.16.215.122 port 45294 ssh2
Nov 16 04:50:30 aliyun-sh sshd[156680]: Failed password for invalid user zabbix from 139.9.233.78 port 52206 ssh2
Nov 16 04:50:50 aliyun-sh sshd[156683]: Failed password for root from 120.55.164.64 port 34820 ssh2
Nov 16 04:50:51 aliyun-sh sshd[156685]: Failed password for root from 111.16.215.122 port 58978 ssh2
Nov 16 04:51:18 aliyun-sh sshd[156689]: Failed password for root from 120.55.164.64 port 45306 ssh2
Nov 16 04:51:25 aliyun-sh sshd[156692]: Failed password for root from 111.16.215.122 port 33938 ssh2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This Huawei Cloud machine has been running for a long time and is now in the mid-stage of dictionary brute-forcing, with all sorts of strange users starting to appear&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Nov 16 20:30:35 hecs-411458 sshd[182965]: Failed password for invalid user oeh from 39.129.9.180 port 26459 ssh2
Nov 16 20:32:17 hecs-411458 sshd[182967]: Failed password for invalid user dnu from 39.129.9.180 port 27079 ssh2
Nov 16 20:34:12 hecs-411458 sshd[182971]: Failed password for invalid user rq from 39.129.9.180 port 27742 ssh2
Nov 16 20:36:07 hecs-411458 sshd[182979]: Failed password for invalid user zw from 39.129.9.180 port 28415 ssh2
Nov 16 20:37:59 hecs-411458 sshd[182981]: Failed password for invalid user egi from 39.129.9.180 port 29068 ssh2
Nov 16 20:39:52 hecs-411458 sshd[182984]: Failed password for invalid user bjb from 39.129.9.180 port 29723 ssh2
Nov 16 20:41:53 hecs-411458 sshd[182988]: Failed password for invalid user hna from 39.129.9.180 port 30375 ssh2
Nov 16 20:43:46 hecs-411458 sshd[182994]: Failed password for invalid user gar from 39.129.9.180 port 31036 ssh2
Nov 16 20:45:40 hecs-411458 sshd[183003]: Failed password for invalid user mze from 39.129.9.180 port 31703 ssh2
Nov 16 20:47:35 hecs-411458 sshd[183007]: Failed password for invalid user tmh from 39.129.9.180 port 32381 ssh2
Nov 16 21:23:01 hecs-411458 sshd[183047]: Failed password for invalid user amax from 112.4.65.118 port 41188 ssh2
Nov 16 22:31:20 hecs-411458 sshd[183116]: Failed password for root from 211.228.203.123 port 60213 ssh2
Nov 16 22:53:44 hecs-411458 sshd[183162]: Failed password for root from 112.132.249.164 port 39272 ssh2
Nov 17 11:44:26 hecs-411458 sshd[184811]: Failed password for invalid user jsh from 43.157.103.27 port 54608 ssh2
Nov 17 11:47:23 hecs-411458 sshd[184818]: Failed password for invalid user mrunal from 43.157.103.27 port 50448 ssh2
Nov 17 11:48:46 hecs-411458 sshd[184820]: Failed password for invalid user robertsheen from 43.157.103.27 port 50560 ssh2
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;afterword&#34;&gt;Afterword
&lt;/h2&gt;&lt;p&gt;Developing a self-built server, Windows requires setting up a whitelist for public network access, and Linux recommends disabling password login and enabling key file login&lt;/p&gt;</description>
        </item>
        <item>
        <title>Batch update local Git repository and legacy permission issues</title>
        <link>https://ttf248.life/en/p/bulk-update-local-git-repository-and-legacy-permission-issues/</link>
        <pubDate>Thu, 19 Oct 2023 14:16:22 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/bulk-update-local-git-repository-and-legacy-permission-issues/</guid>
        <description>&lt;p&gt;The projects within the team have dependencies on each other. Due to historical reasons, &lt;code&gt;submodules&lt;/code&gt; were not used to manage these dependencies. As a result, developers need to manually update the repository code sequentially during daily development; otherwise, they may encounter various strange issues.&lt;/p&gt;
&lt;p&gt;Referencing online resources, the structures are generally similar. Maintain a local repository directory manually: &lt;strong&gt;git_list.txt&lt;/strong&gt;. Write a script to traverse the directory and perform an update in one go. Before starting work, run the script first.&lt;/p&gt;
&lt;h2 id=&#34;linux&#34;&gt;linux
&lt;/h2&gt;&lt;p&gt;create new file: batch_pull.sh&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#!/bin/bash

echo &amp;quot;============ 更新仓库 ===================&amp;quot;

# 检查 git_list.txt 是否存在
if [ ! -f &amp;quot;git_list.txt&amp;quot; ]; then
  echo &amp;quot;git_list.txt 文件不存在！请创建并添加要拉取的 git 仓库 URL。&amp;quot;
  exit 1
else
  echo &amp;quot;============ 检测到了 git 仓库清单文件 ====&amp;quot;
fi

# 逐行读取 git_list.txt 中的 URL，并执行拉取操作
while read -r url; do
  if [ -d &amp;quot;$url&amp;quot; ]; then
    cd &amp;quot;$url&amp;quot; || continue
    git pull
    cd ..
    echo &amp;quot;Pull $url 完成！&amp;quot;
    echo &amp;quot;========================================&amp;quot;
  else
    echo &amp;quot;目录 $url 不存在，跳过拉取。&amp;quot;
  fi
done &amp;lt; &amp;quot;git_list.txt&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;windows&#34;&gt;windows
&lt;/h2&gt;&lt;p&gt;create a new file: batch_pull.bat&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bat&#34;&gt;@echo off
chcp 65001 &amp;gt; nul
rem 进入脚本所在目录
cd /d &amp;quot;%~dp0&amp;quot;

rem 检查 git_list.txt 是否存在
if not exist &amp;quot;git_list.txt&amp;quot; (
  echo git_list.txt 文件不存在！请创建并添加要拉取的 git 仓库 URL。
  exit /b 1
) else (
  echo ============ 检测到了 git 仓库清单文件 ====
)

rem 逐行读取 git_list.txt 中的 URL，并执行拉取操作
for /f %%i in (git_list.txt) do (
  if exist &amp;quot;%%i&amp;quot; (
    pushd &amp;quot;%%i&amp;quot;
    git pull
    popd
    echo Pull %%i 完成！
    echo ========================================
  ) else (
    echo 目录 %%i 不存在，跳过拉取。
  )
)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;historical-legacies&#34;&gt;Historical legacies
&lt;/h3&gt;&lt;p&gt;Handling the &lt;code&gt;git&lt;/code&gt; folder permission files after reinstalling the system: &lt;strong&gt;Fatal error &amp;ldquo;unsafe repository (&amp;rsquo;/home/repon&amp;rsquo; is owned by someone else)&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Most of the suggested practices online come from &lt;code&gt;stack overflow&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Add trusted directory: &lt;code&gt;git config --global --add safe.directory /home/repon&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Manually modify the &lt;code&gt;.gitconfig&lt;/code&gt; configuration file and specify the directory to be trusted&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[safe]
    directory = /home/repon
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After handling it in the above manner, the warehouse update is normal, but there are a lot of warning messages in the console when executing &lt;code&gt;git pull&lt;/code&gt;, indicating an owner error&lt;/p&gt;
&lt;h3 id=&#34;reinstalling-the-system-on-a-desktop-computer&#34;&gt;Reinstalling the system on a desktop computer
&lt;/h3&gt;&lt;p&gt;The development machine hasn&amp;rsquo;t been reinstalled in a long time, and the system disk is full of junk files. There was nothing I could do, so I took the time to reinstall the system. I encountered this permission issue again, and previous scripts won’t run because the permissions are incomplete.&lt;/p&gt;
&lt;p&gt;Use the new scheme, directly add &lt;code&gt;*&lt;/code&gt;, and &lt;code&gt;git&lt;/code&gt; will automatically trust all directories&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git config --global --add safe.directory &amp;quot;*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;I&amp;rsquo;m not sure if it’s a user permissions issue, or whether people aren&amp;rsquo;t used to the fact that the &lt;code&gt;windows&lt;/code&gt; platform also has commands similar to &lt;code&gt;chown&lt;/code&gt;. You can modify the folder owner, of course. If you don’t have many directories, manually modifying the owners is fine. However, this work computer has domain information added, and I’m not sure if it&amp;rsquo;s an anomaly with the company&amp;rsquo;s deployed domain or a local system setting issue. The user used for login couldn&amp;rsquo;t be found in the user list, so I ultimately handled it through the command line.&lt;/p&gt;
&lt;p&gt;Administrator privileges, execute the &lt;code&gt;powershell&lt;/code&gt; script &lt;code&gt;change_ower.ps1&lt;/code&gt;. Remember to adjust the script file encoding to &lt;code&gt;gbk&lt;/code&gt;, for Chinese operating systems, otherwise it will display garbled characters.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;# 获取当前用户的用户名
$currentUserName = [System.Security.Principal.WindowsIdentity]::GetCurrent().Name

# 设置 PowerShell 的字符编码为 UTF-8
[Console]::OutputEncoding = [System.Text.Encoding]::UTF8

# 要更改所有者的根目录路径
$rootDirectory = &amp;quot;G:\workspace&amp;quot;  # 替换为实际的目录路径

# 递归遍历目录并更改文件和文件夹的所有者
Get-ChildItem -Path $rootDirectory -Recurse | ForEach-Object {
    $itemPath = $_.FullName

    # 检查是文件还是文件夹
    if ($_ -is [System.IO.DirectoryInfo]) {
        # 如果是文件夹，使用 icacls 更改所有者权限
        $icaclsResult = icacls $itemPath /setowner &amp;quot;$currentUserName&amp;quot; 2&amp;gt;&amp;amp;1
        if ($LASTEXITCODE -eq 0) {
            Write-Host &amp;quot;已更改文件夹 $itemPath 的所有者为 $currentUserName&amp;quot;
        } else {
            Write-Host &amp;quot;无法更改文件夹 $itemPath 的所有者。错误信息: $icaclsResult&amp;quot;
        }
    } else {
        # 如果是文件，使用 icacls 更改所有者权限
        $takeownResult = icacls $itemPath /setowner &amp;quot;$currentUserName&amp;quot; 2&amp;gt;&amp;amp;1
        if ($LASTEXITCODE -eq 0) {
            # Write-Host &amp;quot;已更改文件 $itemPath 的所有者为 $currentUserName&amp;quot;
        } else {
            Write-Host &amp;quot;无法更改文件 $itemPath 的所有者。错误信息: $takeownResult&amp;quot;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As expected, something unexpected still happened. The Chinese information output by the script execution was garbled. I tried setting the console character encoding and adjusting the script encoding, but everything was still garbled. It felt like my brain wasn&amp;rsquo;t working properly. I then tried enabling the beta feature of Control Panel-Region-Language settings and globally enabled Unicode encoding. The script executed normally, but several development software stopped working correctly. Later, when reviewing the materials, I remembered to adjust the script file’s encoding to &lt;code&gt;gbk&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;materials&#34;&gt;Materials
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://ganzhixiong.com/p/f1b9f4fc/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ganzhixiong.com/p/f1b9f4fc/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://stackoverflow.com/questions/71901632/fatal-error-unsafe-repository-home-repon-is-owned-by-someone-else&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stackoverflow.com/questions/71901632/fatal-error-unsafe-repository-home-repon-is-owned-by-someone-else&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>WPF learning materials</title>
        <link>https://ttf248.life/en/p/wpf-learning-resources/</link>
        <pubDate>Tue, 17 Oct 2023 10:49:24 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/wpf-learning-resources/</guid>
        <description>&lt;p&gt;The pitfalls of mini-program development weren&amp;rsquo;t resolved yet, and now I’m diving into &lt;strong&gt;WPF&lt;/strong&gt;, on top of recent turbulence at the company. Inter-location collaboration and communication have been inefficient, so I’ve taken on client interface development.&lt;/p&gt;
&lt;h2 id=&#34;wpf&#34;&gt;WPF
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Recommended &lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/dotnet/desktop/wpf/introduction-to-wpf?view=netframeworkdesktop-4.8&amp;amp;preserve-view=true&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;WPF Microsoft Official Learning Resources&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Summary of WPF Basics (Learning Suggestions)&lt;/li&gt;
&lt;li&gt;WPF Chinese Website&lt;/li&gt;
&lt;li&gt;Summary and Learning Recommendations for WPF&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Many concepts used in WPF interface design are similar to those in web frontend design. The goal is to separate UI design from business logic as much as possible, allowing the UI to be independent—this is also how internet companies expect tasks to be divided. I just spent some time working on mini-programs this year, and many of the concepts are universal, making it relatively easy to get started. These are considered the &lt;strong&gt;principles&lt;/strong&gt; in modern UI design. Mastering the basic framework concepts will keep you from going astray later on.&lt;/p&gt;
&lt;p&gt;Readers with prior experience in &lt;code&gt;Winform&lt;/code&gt; development are recommended to read: &lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/zh7791/p/11502696.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;WPF Basics Summary (Learning Suggestions)&lt;/a&gt;. It&amp;rsquo;s not a long article and suitable for experienced readers planning their learning path.&lt;/p&gt;
&lt;p&gt;For readers with no prior knowledge, it is recommended to read: &lt;a class=&#34;link&#34; href=&#34;http://www.wpfsoft.com/introduction&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;WPF Chinese Net&lt;/a&gt;, which introduces basic concepts, the history of development, and the logic of understanding underlying classes from scratch. It&amp;rsquo;s quite a coincidence that this website was just released by the author in August this year, and it aligns perfectly with our timeline. If it were any later, we probably wouldn’t have had the chance to connect.&lt;/p&gt;
&lt;p&gt;If you want the most authentic learning materials, of course it&amp;rsquo;s the documentation from Microsoft’s official website; it can be a bit dry, so new readers need to have patience&lt;/p&gt;
&lt;p&gt;There are also many classic e-books, but I don&amp;rsquo;t really recommend them. I have a lot of work to do every day, so I don’t have much time to sit down and read. It&amp;rsquo;s difficult to get into the reading mood; practicing with projects is more suitable.&lt;/p&gt;
&lt;h2 id=&#34;c-and-net-release-history&#34;&gt;C# and .NET release history
&lt;/h2&gt;&lt;p&gt;In recent years, there have been quite a few new features released, and the language&amp;rsquo;s version is iterating annually, similar to previously learned languages&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/C_Sharp_%28programming_language%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://en.wikipedia.org/wiki/C_Sharp_(programming_language)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Official learning materials:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/dotnet/csharp/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://learn.microsoft.com/zh-cn/dotnet/csharp/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/zh-cn/dotnet/core/tutorials/with-visual-studio?pivots=dotnet-7-0&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://learn.microsoft.com/zh-cn/dotnet/core/tutorials/with-visual-studio?pivots=dotnet-7-0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>ZeroTier local area network across locations</title>
        <link>https://ttf248.life/en/p/zero-tier-remote-lan/</link>
        <pubDate>Tue, 19 Sep 2023 04:58:03 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/zero-tier-remote-lan/</guid>
        <description>&lt;p&gt;I recently got a mini desktop for the office, thinking it would be convenient to set up an environment and occasionally access things from home. So I temporarily deployed an intranet penetration tool. Based on my past experience, I deployed the &lt;code&gt;frp&lt;/code&gt; service with port forwarding, which requires a public server – the connection quality depends on the bandwidth of that public server. Then I decided to try something new: a &lt;code&gt;Zerotier&lt;/code&gt; virtual machine local area network, similar to a &lt;code&gt;VPN&lt;/code&gt;. I created a new virtual network card locally and added all machines to a virtual network.&lt;/p&gt;
&lt;h2 id=&#34;what-is-zerotier&#34;&gt;What is ZeroTier?
&lt;/h2&gt;&lt;p&gt;ZeroTier is a software-defined wide area network (SD-WAN) solution that allows users to create secure virtual networks between devices in different geographical locations. With ZeroTier, you can easily connect multiple computers, servers, and devices into a virtual, encrypted network as if they were on the same local area network. This helps programmers and IT professionals securely share data and resources across different locations without complex network setups and VPN configurations.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Zerotier Network: Zerotier Network is a virtual, global local area network that allows different devices to connect together over the internet as if they were on the same physical network. This network can contain multiple subnets, and all devices are connected through Zerotier&amp;rsquo;s technology.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Planet servers are one of the key components of the Zerotier network. They are global and responsible for maintaining and managing the topology, routing information, and network status of the entire Zerotier network. Planet servers act as a global network control center but do not directly transmit data. User devices need to connect to at least one planet server to participate in the Zerotier network.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Relay servers are auxiliary nodes in the Zerotier network, used to help devices establish direct communication channels. When devices cannot connect directly, they can transmit data through relay servers. This helps improve network reachability and performance. Relay servers are typically located around the world, acting as transit points for data transmission.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Overall, Zerotier uses planetary and relay servers to enable devices to create a virtual local area network globally, achieving secure and fast communication between devices. Planetary servers are responsible for global network management, while relay servers help devices establish communication connections when needed.&lt;/p&gt;
&lt;h2 id=&#34;installation-and-deployment&#34;&gt;Installation and deployment
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Visit the ZeroTier official website (&lt;a class=&#34;link&#34; href=&#34;https://www.zerotier.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.zerotier.com/&lt;/a&gt;) to obtain installation files and documentation&lt;/li&gt;
&lt;li&gt;Download and install the ZeroTier One client according to your operating system. It supports Windows, macOS, Linux, and many other platforms.&lt;/li&gt;
&lt;li&gt;After installation, start the ZeroTier One client&lt;/li&gt;
&lt;li&gt;Register a ZeroTier account, if you don&amp;rsquo;t already have one. You can create an account within the client.&lt;/li&gt;
&lt;li&gt;Log in to your ZeroTier account and create a new network. The network will have a unique 16-character ID that you need to remember.&lt;/li&gt;
&lt;li&gt;Join this network on your device. You can enter the network ID in the client or use the QR code scanning function.&lt;/li&gt;
&lt;li&gt;Devices installed with and configured with the ZeroTier client will be added to the same virtual network. These devices can now communicate directly as if they were on the same local area network.&lt;/li&gt;
&lt;li&gt;You can manage network settings, add devices, and monitor network traffic in ZeroTier&amp;rsquo;s control panel&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;install-and-deploy-moon&#34;&gt;Install and deploy Moon
&lt;/h2&gt;&lt;p&gt;Many domestic carriers prohibit UDP tunneling, but frp service is stable. Because it uses the TCP protocol, a similar effect can be achieved by deploying a Zerotier relay server. The firewall needs to open udp 9993.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;curl -s https://install.zerotier.com/ | sudo bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Check if the installation was successful&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;zerotier-cli info
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Join the local area network&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;zerotier-cli join network-id
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Create &lt;code&gt;moon&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd /var/lib/zerotier-one &amp;amp;&amp;amp; sudo zerotier-idtool initmoon identity.public &amp;gt; moon.json
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Edit the configuration file, adjust the &lt;code&gt;stableEndpoints&lt;/code&gt; node, &amp;ldquo;public IP address of the server/9993&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Generate signature configuration, create a &lt;code&gt;moons.d&lt;/code&gt; folder, move the previous files into it, and restart the service&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo zerotier-idtool genmoon moon.json
mkdir moons.d &amp;amp;&amp;amp; mv 000000eb444ec0d8.moon moons.d/
systemctl restart zerotier-one.service
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Client nodes join the Moon server; their ID is taken from the ID field in the preceding JSON configuration file&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;zerotier-cli.bat orbit ztaddr ztaddr
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 观察是否出现新的 mooon 节点，id 和信息为服务器配置的相同
[root@idv-36f9d5 ~]# zerotier-cli listpeers
200 listpeers &amp;lt;ztaddr&amp;gt; &amp;lt;path&amp;gt; &amp;lt;latency&amp;gt; &amp;lt;version&amp;gt; &amp;lt;role&amp;gt;
200 listpeers 0cccb***** 35.236.*.*/64393;110;10726 327 1.6.3 LEAF
200 listpeers 3a46f***** 185.180.*.*/9993;110;757 -1 - PLANET
200 listpeers 3ed7c***** 39.97.*.*/9993;172;79 32 1.6.3 MOON
200 listpeers 4f838***** - -1 - LEAF
200 listpeers 62f86***** 50.7.*.*/9993;110;4796 351 - PLANET
200 listpeers 778cd***** 103.195.*.*/9993;5148;4887 253 - PLANET
200 listpeers 992fc***** 195.181.*.*/9993;10161;4921 226 - PLANET
200 listpeers 9d2b5***** - -1 - LEAF
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;On Windows, launch the terminal with administrator privileges and use the zerotier-cli.bat command-line tool; on Linux, use the zerotier-cli command. The peers subcommand shows connections, listpeers displays all nodes, and successful joining is indicated by the normal display of the &lt;code&gt;moon&lt;/code&gt; node.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;how-to-uninstall&#34;&gt;How to uninstall
&lt;/h2&gt;&lt;p&gt;There&amp;rsquo;s no need to elaborate on how to uninstall software on Windows; it’s a standard procedure that can be done through the Control Panel. We will focus on Ubuntu instead.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Remove the zerotier-one service using dpkg&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo dpkg -P zerotier-one
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Delete the zerotier-one folder, which stores the address; deleting it and reinstalling will obtain a new address&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo rm -rf /var/lib/zerotier-one/
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;afterword&#34;&gt;Afterword
&lt;/h2&gt;&lt;p&gt;They were all already uninstalled. When the server arrived, there weren&amp;rsquo;t any suitable services available as proxy nodes. Aliyun, pushing for performance, offered developer-exclusive servers with modest configurations at a reasonable price of 99 yuan per year. We used them for two years, primarily because of the bandwidth the servers provided.&lt;/p&gt;
&lt;h2 id=&#34;reference-materials&#34;&gt;Reference materials
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.wnark.com/archives/152.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.wnark.com/archives/152.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/Yogile/p/12642423.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.cnblogs.com/Yogile/p/12642423.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>VMware virtual machine disk space optimization</title>
        <link>https://ttf248.life/en/p/vmware-virtual-disk-space-optimization/</link>
        <pubDate>Wed, 21 Jun 2023 18:35:41 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/vmware-virtual-disk-space-optimization/</guid>
        <description>&lt;p&gt;When installing a VMware virtual machine development system, it&amp;rsquo;s common practice to reserve extra disk space. Over time, the local disk space occupied far exceeds the actual content of the virtual machine files.&lt;/p&gt;
&lt;h2 id=&#34;scene-description&#34;&gt;Scene description
&lt;/h2&gt;&lt;p&gt;The &lt;code&gt;df -h&lt;/code&gt; command shows the disk information of the current machine, which is actually using 60GB. After deleting all snapshots and clone images, the local virtual machine still occupies far more than 60GB of disk space, adding insult to injury for a hard drive that was already not spacious enough.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;The virtual machine was installed without allocating the disk space in advance&lt;/li&gt;
&lt;li&gt;The hard drive where the virtual machine is stored has remaining disk space greater than the space currently occupied by the virtual machine&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The remaining space is insufficient; you could consider temporarily moving the virtual machine to an external hard drive, and then migrate it back after optimizing the disk&lt;/p&gt;
&lt;h2 id=&#34;tools&#34;&gt;Tools
&lt;/h2&gt;&lt;p&gt;The official provider offers the &lt;code&gt;open-vm-tools&lt;/code&gt; package, which can be installed via yum or through the VMware Tools ISO image&lt;/p&gt;
&lt;h2 id=&#34;command&#34;&gt;Command
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;vmware-toolbox-cmd disk shrink /
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After execution, the virtual machine will automatically shut down, and the VMware host program will perform disk compression. The execution time depends on the size of the virtual machine and the access speed of the disk.&lt;/p&gt;
&lt;p&gt;The execution result is still very good, and the virtual machine&amp;rsquo;s disk space usage is basically equal to the disk information from &lt;code&gt;df -h&lt;/code&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>Stable Diffusion - The ups and downs of installing from scratch</title>
        <link>https://ttf248.life/en/p/stable-diffusion-zero-install-saga/</link>
        <pubDate>Thu, 13 Apr 2023 00:23:54 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/stable-diffusion-zero-install-saga/</guid>
        <description>&lt;p&gt;Domestic resources generally recommend &lt;strong&gt;Chuyou&amp;rsquo;s&lt;/strong&gt; one-click deployment package. Thinking it’s an open-source project based on &lt;code&gt;Python&lt;/code&gt;, I figured the deployment wouldn&amp;rsquo;t be too complex, so I decided to try starting from scratch.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I messed around with AI image generation, specifically upgraded my graphics card to an entry-level &lt;code&gt;3060 12g&lt;/code&gt;; the &lt;code&gt;960&lt;/code&gt;, which served faithfully for seven years, has now been retired&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The core &lt;code&gt;pytorch CUDA&lt;/code&gt; installation, I had installed it locally before when writing &lt;code&gt;Python&lt;/code&gt; game assistant scripts, but still encountered problems – the &lt;code&gt;CUDA&lt;/code&gt; license could not be activated&lt;/p&gt;
&lt;h2 id=&#34;pending&#34;&gt;Pending
&lt;/h2&gt;&lt;p&gt;Reorganize the article structure, first introducing PyTorch, version compatibility, and how to check versions
How to create a new virtual environment from scratch and deploy PyTorch locally
Translate drafts from scratch, stable diffusion &lt;a class=&#34;link&#34; href=&#34;https://stable-diffusion-art.com/install-windows/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stable-diffusion-art.com/install-windows/&lt;/a&gt;
Organize reference materials&lt;/p&gt;
&lt;h2 id=&#34;steps&#34;&gt;Steps
&lt;/h2&gt;&lt;p&gt;You might not find a step-by-step installation tutorial by searching in Chinese. If you search in English on &lt;code&gt;Google&lt;/code&gt;, there are many similar tutorials that start from scratch. It briefly introduced the need to install &lt;code&gt;git&lt;/code&gt;, then explained the need to install &lt;code&gt;python&lt;/code&gt;. Then, it just involved downloading the repository and running the script with a double click.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/AUTOMATIC1111/stable-diffusion-webui&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For detailed usage and troubleshooting, please refer to the &lt;code&gt;issues&lt;/code&gt; section: &lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I also don&amp;rsquo;t know why no one explained what this repository is for. Actually, it’s not hard to tell from the name – it’s an interface console that makes it more convenient for us to use. In fact, when installing, it will download the official repository content and obtain the actual &lt;code&gt;SD&lt;/code&gt; code.&lt;/p&gt;
&lt;p&gt;The warehouse also includes an installation startup script. It automatically detects whether there is a &lt;code&gt;Python&lt;/code&gt; virtual environment in the current folder. If so, it defaults to using the &lt;code&gt;python&lt;/code&gt; from the current path.&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;re a complete beginner, it’s recommended that you check out: &lt;a class=&#34;link&#34; href=&#34;https://stable-diffusion-art.com/install-windows/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stable-diffusion-art.com/install-windows/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;pytorch&#34;&gt;pytorch
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/get-started/locally/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://pytorch.org/get-started/locally/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is what I wanted to talk about today. First, don&amp;rsquo;t listen to their instructions and start the script directly. Python installs dependencies through requirement files, which are minor issues. The core issue is your graphics card driver version, which needs to correspond with PyTorch. Many people have already explained this relationship; you can find it online if you search for it.&lt;/p&gt;
&lt;p&gt;Reference: &lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/weixin_40660408/article/details/129896700&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/weixin_40660408/article/details/129896700&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Creating a virtual environment is like having an empty space where you can directly run the script from the official website to install PyTorch&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -c &amp;quot;import torch; print(torch.version.cuda)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -c &amp;quot;import torch; print(torch.__version__, torch.cuda.is_available())&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The two scripts above can check the CUDA version you need to install and whether the installation was successful&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s not recommended to use fancy operations here. Just copy the logic from the official page and install it directly. Install it directly using pip, and your PyTorch is likely to fail or CUDA might not be activated.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Important: Make sure the folder path doesn&amp;rsquo;t contain any unnecessary characters, otherwise it may prevent PyTorch from working properly&lt;/p&gt;
&lt;p&gt;I installed it many times back and forth, and also tried downloading the official installation file and installing it manually. I was just thinking about upgrading to version 2.0 because the official documentation says that version 2.0 will be faster. But I haven&amp;rsquo;t used it much before, and I don’t know if the Python version or something else is affecting it. In the meantime, I also checked the official manual, which recommends using version 3.8. This created a small conflict because the one-click installation package previously used had version 3.10. Finally, I started from scratch by creating a new folder, creating a virtual environment, and ensuring that torch was installed successfully.&lt;/p&gt;
&lt;p&gt;Then move this installed virtual environment into the web UI folder. After that, when you start the installation script, most of the dependency issues should be resolved.&lt;/p&gt;
&lt;p&gt;After moving, you need to run: python -m pip install &amp;ndash;upgrade &amp;ndash;force-reinstall pip to fix it&lt;/p&gt;
&lt;p&gt;It might seem a bit strange, but I spent quite a while troubleshooting this. It couldn&amp;rsquo;t correctly identify my torch, so to eliminate all possible interference factors, I decided to install it first and then the other dependencies.&lt;/p&gt;
&lt;h2 id=&#34;xformers&#34;&gt;Xformers
&lt;/h2&gt;&lt;p&gt;It is recommended to enable it, as it can accelerate image generation and reduce existing usage. The side effect is that &lt;strong&gt;images generated with the same parameters may not be as stable&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;stable-diffusion-webui:Xformers&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/diffusers/optimization/xformers&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;huggingface optimization&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Optimization Ratio&lt;/th&gt;
&lt;th&gt;Time taken&lt;/th&gt;
&lt;th&gt;Torch active/reserved&lt;/th&gt;
&lt;th&gt;Sys VRAM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;100.00%&lt;/td&gt;
&lt;td&gt;2m 57.03s&lt;/td&gt;
&lt;td&gt;7440/10058 MiB&lt;/td&gt;
&lt;td&gt;12288/12288 MiB (100.0%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;51.02%&lt;/td&gt;
&lt;td&gt;1m 29.21s&lt;/td&gt;
&lt;td&gt;4547/7164 MiB&lt;/td&gt;
&lt;td&gt;9298/12288 MiB (75.67%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;((masterpiece)),((best quality)),((high detial)),((realistic,))
Industrial age city, deep canyons in the middle,chinese architectural streets,bazaars, Bridges, (rainy days:1.2), (steampunk:0.8), chinese architecture
Negative prompt: nsfw,((cowboy)),(((pubic))), ((((pubic_hair))))sketch, duplicate, ugly, huge eyes, text, logo, monochrome, worst face, (bad and mutated hands:1.3), (worst quality:2.0), (low quality:2.0), (blurry:2.0), horror, geometry, bad_prompt, (bad hands), (missing fingers), multiple limbs, bad anatomy, (interlocked fingers:1.2), Ugly Fingers, (extra digit and hands and fingers and legs and arms:1.4), crown braid, ((2girl)), (deformed fingers:1.2), (long fingers:1.2),succubus wings,horn,succubus horn,succubus hairstyle, (bad-artist-anime), bad-artist, bad hand, borrowed character, text focus, watermark, sample watermark, character watermark, lofter username, photo date watermark, movie poster, magazine cover, journal, cover, cover page, doujin cover, album cover, manga cover, brand name imitation, EasyNegative,Tights, silk stockings,shorts
Steps: 35, Sampler: DPM adaptive, CFG scale: 5.5, Seed: 2223996555, Size: 1088x1088, Model hash: 543bcbc212, Model: base_Anything-V3.0-pruned, Clip skip: 2, ENSD: 31337
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;afterword&#34;&gt;Afterword
&lt;/h2&gt;&lt;p&gt;Why not recommend the one-click deployment package? Because that package contains some settings that were custom-made by the author, and they are not the same as the official original version. If you&amp;rsquo;re a beginner, you may not know why it’s best to start with the parameters provided by the official source first. As you use it for longer, refer to the official manual more often, and you will understand which parameters need adjustment.&lt;/p&gt;
&lt;h2 id=&#34;choosing-a-graphics-card&#34;&gt;Choosing a Graphics Card
&lt;/h2&gt;&lt;p&gt;After the cryptocurrency mining boom, graphics card prices are relatively lower now. For ordinary entry-level players choosing between a 3060 and a 3060 Ti, it&amp;rsquo;s generally recommended to go with the 3060 version with 12GB of VRAM because it can generate images at higher resolutions. Why do you need a higher resolution? Because you can increase the resolution during generation, resulting in clearer and more detailed images. If you’re just generating smaller images, 8GB of VRAM is sufficient.&lt;/p&gt;
&lt;p&gt;Also, the &lt;strong&gt;high-definition enhancement&lt;/strong&gt; option refines details, making the picture more detailed and also requiring more video memory&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a summary table of the single-precision (FP32), half-precision (FP16), and double-precision (FP64) floating-point compute capabilities specifications for NVIDIA GeForce GTX 970, GeForce RTX 3060 Ti, GeForce RTX 3060, GeForce RTX 3080, and GeForce RTX 3080 Ti&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Graphics Card Model&lt;/th&gt;
&lt;th&gt;Year of Release&lt;/th&gt;
&lt;th&gt;Single-Precision Floating-Point Calculation Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Half-Precision Floating-Point Calculation Capability (TFLOPS)&lt;/th&gt;
&lt;th&gt;Double-Precision Floating-Point Calculation Capability (TFLOPS)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;GeForce GTX 970&lt;/td&gt;
&lt;td&gt;2014&lt;/td&gt;
&lt;td&gt;3.49&lt;/td&gt;
&lt;td&gt;87.2&lt;/td&gt;
&lt;td&gt;0.109&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GeForce RTX 3060 Ti&lt;/td&gt;
&lt;td&gt;2020&lt;/td&gt;
&lt;td&gt;16.2&lt;/td&gt;
&lt;td&gt;32.4&lt;/td&gt;
&lt;td&gt;0.51&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GeForce RTX 3060&lt;/td&gt;
&lt;td&gt;2021&lt;/td&gt;
&lt;td&gt;12.7&lt;/td&gt;
&lt;td&gt;25.4&lt;/td&gt;
&lt;td&gt;0.39&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GeForce RTX 3080&lt;/td&gt;
&lt;td&gt;2020&lt;/td&gt;
&lt;td&gt;29.8&lt;/td&gt;
&lt;td&gt;58.9&lt;/td&gt;
&lt;td&gt;0.93&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GeForce RTX 3080 Ti&lt;/td&gt;
&lt;td&gt;2021&lt;/td&gt;
&lt;td&gt;34.8&lt;/td&gt;
&lt;td&gt;68.7&lt;/td&gt;
&lt;td&gt;1.36&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Extracted, &lt;a class=&#34;link&#34; href=&#34;https://docs.google.com/spreadsheets/d/1Zlv4UFiciSgmJZncCujuXKHwc4BcxbjbSBg71-SdeNk/edit#gid=0&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;various graphics card performance test data&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;update&#34;&gt;Update
&lt;/h2&gt;&lt;p&gt;After six months, I had intended to review the installation steps and explain more basic concepts, but it turns out that for ordinary people using AI image generation, it really just involves adjusting parameters based on images provided by experts or re-rendering existing images in a formatted way&lt;/p&gt;
&lt;p&gt;We tried using AI to generate UI assets for a mini-program, but after all that effort, the results weren&amp;rsquo;t satisfactory. It’s better if I just pull the resource images directly from the official mini-program.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Don&#39;t try to fight against hardware in program optimization</title>
        <link>https://ttf248.life/en/p/program-optimization-dont-fight-hardware/</link>
        <pubDate>Fri, 07 Apr 2023 16:30:15 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/program-optimization-dont-fight-hardware/</guid>
        <description>&lt;p&gt;One loop thread, the time consumption is already at the &lt;strong&gt;microsecond&lt;/strong&gt; level. We switched servers, and the backlog of data packets went from a maximum of six hundred thousand to almost none.&lt;/p&gt;
&lt;p&gt;In a single-threaded loop processing data scenario, the CPU&amp;rsquo;s performance depends on factors such as clock speed, cache size, and instruction set architecture. Generally speaking, CPUs with higher clock speeds, larger caches, and more advanced instruction set architectures perform better when handling data in a single thread.&lt;/p&gt;
&lt;h2 id=&#34;single-threaded&#34;&gt;Single-threaded
&lt;/h2&gt;&lt;p&gt;Performance improvements don&amp;rsquo;t necessarily require increasing threads; it’s better to streamline project workflows, identify bottlenecks, and determine if single-threaded operation is sufficient. Single-threading also involves fewer considerations and is less prone to issues.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Starting off by talking about adding threads, there&amp;rsquo;s definitely something wrong with that&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;event&#34;&gt;Event
&lt;/h2&gt;&lt;p&gt;Dealing with &lt;strong&gt;market data, latency-sensitive&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Worked overtime all night, releasing a new optimized version. Tested the local interface stripping, and the speed is decent, TPS: 42,000.&lt;/p&gt;
&lt;p&gt;Deployed to the server, TPS plummeted: 21,000. Tried on a desktop at home, TPS: 79,000. Started suspecting there might be some issues with the group&amp;rsquo;s service virtual machines, initially suspecting it’s due to frequency. The biggest difference between the CPU of the home desktop and the server is the frequency.&lt;/p&gt;
&lt;p&gt;Test Server A&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;processor	: 7
vendor_id	: GenuineIntel
cpu family	: 6
model		: 47
model name	: Intel(R) Xeon(R) CPU E7- 4807  @ 1.87GHz
stepping	: 2
microcode	: 0x34
cpu MHz		: 1866.733
cache size	: 18432 KB
physical id	: 1
siblings	: 4
core id		: 3
cpu cores	: 4
apicid		: 7
initial apicid	: 7
fpu		: yes
fpu_exception	: yes
cpuid level	: 11
wp		: yes
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss ht syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 cx16 sse4_1 sse4_2 popcnt aes hypervisor lahf_lm pti dtherm arat
bugs		: clflush_monitor cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit
bogomips	: 3733.46
clflush size	: 64
cache_alignment	: 64
address sizes	: 40 bits physical, 48 bits virtual
power management:
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Test Server B&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;processor	: 7
vendor_id	: GenuineIntel
cpu family	: 6
model		: 63
model name	: Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz
stepping	: 2
microcode	: 0x3c
cpu MHz		: 2599.998
cache size	: 20480 KB
physical id	: 14
siblings	: 1
core id		: 0
cpu cores	: 1
apicid		: 14
initial apicid	: 14
fpu		: yes
fpu_exception	: yes
cpuid level	: 15
wp		: yes
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cpuid_fault epb pti fsgsbase smep xsaveopt cqm_llc cqm_occup_llc dtherm ida arat pln pts
bugs		: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit
bogomips	: 5199.99
clflush size	: 64
cache_alignment	: 64
address sizes	: 40 bits physical, 48 bits virtual
power management:
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;consult-openai&#34;&gt;Consult OpenAI
&lt;/h2&gt;&lt;p&gt;Firstly, in terms of core count and clock speed, the Intel(R) Xeon(R) CPU E7-4807 @ 1.87GHz has 6 physical cores and 12 logical cores with a clock speed of 1.87GHz; while the Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz has 8 physical cores and 16 logical cores with a clock speed of 2.60GHz. Therefore, in terms of core count and clock speed, the E5-2640 v3 should have an advantage over the E7-4807 when processing data in single thread.&lt;/p&gt;
&lt;p&gt;Secondly, in terms of cache size, the E7-4807 has a 12MB cache, while the E5-2640 v3 has a 20MB cache. Therefore, the E5-2640 v3 offers more cache space, which can improve data access speed and cache hit rate.&lt;/p&gt;
&lt;p&gt;Finally, regarding the architecture, the E5-2640 v3 uses a more advanced Haswell architecture, while the E7-4807 uses the older Nehalem architecture. The Haswell architecture offers performance improvements over the Nehalem architecture, which may also impact the performance of the E5-2640 v3 when processing data in single thread.&lt;/p&gt;
&lt;p&gt;Therefore, considering all factors, in scenarios where data is processed in a single-threaded loop, the E5-2640 v3 should offer better performance than the E7-4807. However, specific performance differences will be affected by various factors, including the data processing algorithm, memory bandwidth, system load, and so on; each case requires individual analysis.&lt;/p&gt;
&lt;h2 id=&#34;hardware-materials&#34;&gt;Hardware materials
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cpubenchmark.net/compare/3786.2vs2365.2/%5BDual-CPU%5D-Intel-Xeon-E7%e2%80%934807-vs-%5BDual-CPU%5D-Intel-Xeon-E5-2640-v3&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.cpubenchmark.net/compare/3786.2vs2365.2/%5BDual-CPU%5D-Intel-Xeon-E7–4807-vs-%5BDual-CPU%5D-Intel-Xeon-E5-2640-v3&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Specification&lt;/th&gt;
&lt;th&gt;Xeon E7-4807 (LGA1567)&lt;/th&gt;
&lt;th&gt;Xeon E5-2640 v3 (LGA2011-v3)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Price&lt;/td&gt;
&lt;td&gt;Search Online  $78 - BUY&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Socket Type&lt;/td&gt;
&lt;td&gt;LGA1567&lt;/td&gt;
&lt;td&gt;LGA2011-v3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CPU Class&lt;/td&gt;
&lt;td&gt;Server&lt;/td&gt;
&lt;td&gt;Server&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Clockspeed&lt;/td&gt;
&lt;td&gt;1.9 GHz&lt;/td&gt;
&lt;td&gt;2.6 GHz&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Turbo Speed&lt;/td&gt;
&lt;td&gt;Not Supported&lt;/td&gt;
&lt;td&gt;Up to 3.4 GHz&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;# of Physical Cores&lt;/td&gt;
&lt;td&gt;6 (Threads: 12)&lt;/td&gt;
&lt;td&gt;8 (Threads: 16)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cache&lt;/td&gt;
&lt;td&gt;NA2&lt;/td&gt;
&lt;td&gt;NA2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Max TDP&lt;/td&gt;
&lt;td&gt;95W x 2&lt;/td&gt;
&lt;td&gt;90W x 2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Yearly Running Cost&lt;/td&gt;
&lt;td&gt;$34.68&lt;/td&gt;
&lt;td&gt;$32.85&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Other&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;First Seen on Chart&lt;/td&gt;
&lt;td&gt;Q3 2020&lt;/td&gt;
&lt;td&gt;Q3 2014&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;# of Samples&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;46&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CPU Value&lt;/td&gt;
&lt;td&gt;69.1&lt;/td&gt;
&lt;td&gt;225.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Single Thread Rating&lt;/td&gt;
&lt;td&gt;721 (-59.2%)&lt;/td&gt;
&lt;td&gt;1767 (0.0%)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CPU Mark&lt;/td&gt;
&lt;td&gt;6223 (-64.6%)&lt;/td&gt;
&lt;td&gt;17600 (0.0%)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</description>
        </item>
        <item>
        <title>Prompt Engineer</title>
        <link>https://ttf248.life/en/p/prompt-engineer/</link>
        <pubDate>Sun, 26 Mar 2023 20:46:53 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/prompt-engineer/</guid>
        <description>&lt;p&gt;Just as we learned techniques for using search engines back in the day, we also need to learn some techniques for communicating with AI – providing reasonable and sufficient constraints to efficiently obtain the answers we need&lt;/p&gt;
&lt;p&gt;If you look at it from a different angle, the current AI is like a child with excellent memory; it has the ability to remember everything and can copy homework. What we need to do is learn how to communicate with AI correctly and effectively, describe our needs precisely, and help AI generate the expected results.&lt;/p&gt;
&lt;h2 id=&#34;popular-science&#34;&gt;Popular science
&lt;/h2&gt;&lt;p&gt;The &lt;code&gt;AI&lt;/code&gt; that bursts forth like a shooting star, more accurately known as &lt;code&gt;Generative Pre-Training&lt;/code&gt;, translates literally to generative pre-training. It is a text generation deep learning model trained on internet-available data and used for tasks such as question answering, text summarization, machine translation, classification, code generation, and conversational AI. There are currently different versions of the model, including GPT-1, GPT-2, GPT-3, and GPT-4, each version being larger and more powerful than its predecessor.&lt;/p&gt;
&lt;h2 id=&#34;does-it-really-have-intelligence&#34;&gt;Does it really have intelligence?
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;The higher the similarity, the higher the accuracy&lt;/li&gt;
&lt;li&gt;Basic, repetitive tasks no longer require human intervention after specific training&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Generative AI is a technology that utilizes existing data such as text, audio, and images to create new content. It can be used for various tasks including text generation, speech synthesis, image generation, and dialogue systems. The logic of generative AI depends on its training data and model structure. Generally speaking, generative AI can follow grammar, logic, and common sense to a certain extent, but it may also produce errors, biases, or untrue content. Therefore, the output of generative AI requires human judgment and verification and should not be blindly trusted or used.&lt;/p&gt;
&lt;h2 id=&#34;prompt-engineer&#34;&gt;Prompt Engineer
&lt;/h2&gt;&lt;p&gt;The river of time doesn&amp;rsquo;t flow backward; people need to learn to adapt to the trend. You can think of &lt;code&gt;AI&lt;/code&gt; as not intelligent, lacking logic, and often producing unusable code.&lt;/p&gt;
&lt;p&gt;If you look at it from a different angle, the current AI is like a child with excellent memory; it has the ability to remember everything and can copy homework. What we need to do is learn how to communicate with AI correctly and effectively, describe our needs precisely, and help AI generate the expected results.&lt;/p&gt;
&lt;h2 id=&#34;dialogue-mode&#34;&gt;Dialogue mode
&lt;/h2&gt;&lt;p&gt;Two years after &lt;code&gt;GitHub Copilot&lt;/code&gt; was released, no one could have predicted that two years later, &lt;code&gt;OpenAI&lt;/code&gt; would emerge, allowing humans to recognize the capabilities of large language models&lt;/p&gt;
&lt;p&gt;Based on &lt;strong&gt;annotation-based programming&lt;/strong&gt; and &lt;strong&gt;dialogue-based programming&lt;/strong&gt;, the interactive logic is completely different. Dialogue&amp;rsquo;s pattern provides a user-friendly interaction experience for novice users. It must be mentioned that &lt;code&gt;NewBing&lt;/code&gt; offers follow-up prompts after each question, with Microsoft attempting to guide users to obtain more content from the &lt;code&gt;AI&lt;/code&gt; knowledge base.&lt;/p&gt;
&lt;h2 id=&#34;for-example&#34;&gt;For example
&lt;/h2&gt;&lt;p&gt;The high-speed train journey is long, and coding is a good option. With limited data, processing several images and obtaining image resources is fine, but downloading software to process them would be a bit extravagant, and the network conditions don&amp;rsquo;t allow it.&lt;/p&gt;
&lt;p&gt;We have a batch of image assets with transparent backgrounds to be used as navigation bar icons for a mini-program. The selected state should be in color, and the unselected state should be black and white. The original assets are all in color and need some preprocessing.&lt;/p&gt;
&lt;p&gt;Write a Python code to read all images from a folder, convert them to black and white, maintain the transparent background, optimize the image quality when saving to reduce file size, and display the comparison of the file sizes before and after optimization in the console&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 导入必要的库
import os
import PIL
from PIL import Image

# 定义一个函数，将图片转换成黑白，维持透明背景，保存图片，并返回文件体积
def convert_and_save(image_file):
    # 打开图片
    image = Image.open(image_file)
    # 获取图片的模式，如果是 RGBA 模式，说明有透明背景
    mode = image.mode
    if mode == &amp;quot;RGBA&amp;quot;:
        # 创建一个和图片大小一致的白色背景图片
        background = Image.new(&amp;quot;RGB&amp;quot;, image.size, (255, 255, 255))
        # 将原图片粘贴到白色背景上，忽略透明像素
        background.paste(image, mask=image.split()[3])
        # 将合成的图片转换成灰度模式
        gray_image = background.convert(&amp;quot;L&amp;quot;)
        # 将灰度图片再转换成 RGBA 模式，以便保留透明背景
        final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
    else:
        # 如果不是 RGBA 模式，直接将图片转换成灰度模式
        final_image = image.convert(&amp;quot;L&amp;quot;)
    # 获取原图片的文件名和扩展名
    file_name, file_ext = os.path.splitext(image_file)
    # 定义新图片的文件名，添加 _bw 后缀表示黑白
    new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # 保存新图片，并优化质量，减少文件体积
    final_image.save(new_file_name, optimize=True)
    # 获取原图片和新图片的文件体积，并返回
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return old_size, new_size

# 定义一个文件夹路径，存放所有的图片
folder_path = &amp;quot;images&amp;quot;
# 遍历文件夹中的所有文件
for file in os.listdir(folder_path):
    # 拼接完整的文件路径
    file_path = os.path.join(folder_path, file)
    # 判断是否是图片文件，根据扩展名判断，可以根据需要添加或修改扩展名
    if file_path.endswith((&amp;quot;.png&amp;quot;, &amp;quot;.jpg&amp;quot;, &amp;quot;.jpeg&amp;quot;, &amp;quot;.gif&amp;quot;)):
        # 调用函数，转换并保存图片，并获取文件体积
        old_size, new_size = convert_and_save(file_path)
        # 在控制台展示优化前后的文件体积大小对比
        print(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;AI quickly provided an answer, it looks good and works fine, but experienced programmers will find the code below not very general and unsuitable for production environments&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Parameters are fixed&lt;/li&gt;
&lt;li&gt;There are no log files; the information is printed to the console&lt;/li&gt;
&lt;li&gt;Image processing tasks are suitable for multithreaded models&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;NewBing is here, following prompts, and selected a question: &lt;strong&gt;Are there any areas for improvement in this code?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Honestly, this answer completely exceeded expectations. The AI provided corresponding suggestions for optimizations that a typical programmer would think of.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;这段代码可能还有一些可以改进的地方，比如：

可以使用 argparse 库，让用户可以通过命令行参数指定文件夹路径和扩展名，而不是写死在代码里。
可以使用 logging 库，记录程序的运行情况，而不是直接打印到控制台。
可以使用 try-except 语句，捕获可能出现的异常，比如文件打开失败，图片转换失败等，并做相应的处理。
可以使用 multiprocessing 库，利用多核处理器，加速图片的转换和保存过程。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A very friendly response, considering the differences in deployment environments, supporting single-process execution is permitted&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;当然，我很乐意帮你修改一下代码。我尝试添加了 argparse, logging 和 try-except 语句，但没有添加 multiprocessing 库，因为我不确定你的电脑是否支持多核处理。修改后的代码如下：
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 导入必要的库
import argparse
import logging
import multiprocessing
import os

from PIL import Image


# 定义一个函数，将图片转换成黑白，维持透明背景，保存图片，并返回文件体积
def convert_and_save(image_file):
    # 打开图片
    try:
        image = Image.open(image_file)
    except Exception as e:
        logging.error(f&amp;quot;Failed to open {image_file}: {e}&amp;quot;)
        return None, None
    # 获取图片的模式，如果是 RGBA 模式，说明有透明背景
    mode = image.mode
    if mode == &amp;quot;RGBA&amp;quot;:
        # 创建一个和图片大小一致的白色背景图片
        background = Image.new(&amp;quot;RGB&amp;quot;, image.size, (255, 255, 255))
        # 将原图片粘贴到白色背景上，忽略透明像素
        background.paste(image, mask=image.split()[3])
        # 将合成的图片转换成灰度模式
        gray_image = background.convert(&amp;quot;L&amp;quot;)
        # 将灰度图片再转换成 RGBA 模式，以便保留透明背景
        final_image = gray_image.convert(&amp;quot;RGBA&amp;quot;)
    else:
        # 如果不是 RGBA 模式，直接将图片转换成灰度模式
        final_image = image.convert(&amp;quot;L&amp;quot;)
    # 获取原图片的文件名和扩展名
    file_name, file_ext = os.path.splitext(image_file)
    # 定义新图片的文件名，添加 _bw 后缀表示黑白
    new_file_name = file_name + &amp;quot;_bw&amp;quot; + file_ext
    # 保存新图片，并优化质量，减少文件体积
    try:
        final_image.save(new_file_name, optimize=True)
    except Exception as e:
        logging.error(f&amp;quot;Failed to save {new_file_name}: {e}&amp;quot;)
        return None, None
    # 获取原图片和新图片的文件体积，并返回
    old_size = os.path.getsize(image_file)
    new_size = os.path.getsize(new_file_name)
    return file_name, old_size, new_size

# 定义一个函数，解析命令行参数，并返回文件夹路径和扩展名列表
def parse_args():
    # 创建一个解析器对象
    parser = argparse.ArgumentParser(description=&amp;quot;Convert images to black and white and optimize quality.&amp;quot;)
    # 添加一个必选的位置参数，表示文件夹路径
    parser.add_argument(&amp;quot;folder_path&amp;quot;, help=&amp;quot;The path of the folder that contains the images.&amp;quot;)
    # 添加一个可选的参数，表示扩展名列表，默认为 png, jpg, jpeg 和 gif
    parser.add_argument(&amp;quot;-e&amp;quot;, &amp;quot;--extensions&amp;quot;, nargs=&amp;quot;+&amp;quot;, default=[&amp;quot;.png&amp;quot;, &amp;quot;.jpg&amp;quot;, &amp;quot;.jpeg&amp;quot;, &amp;quot;.gif&amp;quot;], help=&amp;quot;The extensions of the image files.&amp;quot;)
    # 解析命令行参数，并返回结果对象
    args = parser.parse_args()
    return args.folder_path, args.extensions

# 定义一个函数，打印优化前后的文件体积大小对比
def print_result(result):
    # 如果结果不为空，说明转换和保存成功
    if result:
        # 解包结果为文件名和文件体积元组
        if len(result) == 3:
            file, old_size, new_size = result
            # 在控制台展示优化前后的文件体积大小对比
            logging.info(f&amp;quot;{file}: {old_size} bytes -&amp;gt; {new_size} bytes&amp;quot;)
        else:
            logging.info(f&amp;quot;{result}&amp;quot;)

# 配置日志记录器，将日志输出到控制台和文件中，设置日志等级为 INFO
logging.basicConfig(level=logging.INFO,
                    format=&amp;quot;%(asctime)s %(levelname)s %(message)s&amp;quot;,
                    handlers=[logging.StreamHandler(),
                              logging.FileHandler(&amp;quot;log.txt&amp;quot;)])

# 调用函数，获取文件夹路径和扩展名列表
folder_path, extensions = parse_args()

if __name__ == &amp;quot;__main__&amp;quot;:
    # Windows 需要这个函数的原因是 Windows 缺乏 fork() 函数（这不完全正确）。
    # 因此，在 Windows 上，fork() 是通过创建一个新的进程来模拟的，这个新的进程中运行的代码，在 Linux 上是在子进程中运行的。
    # 由于这些代码要在技术上无关的进程中运行，所以它必须在运行之前被传递到那里。
    # 传递的方式是先将它们序列化，然后通过管道从原始进程发送到新的进程。
    # 另外，这个新的进程被通知它必须运行通过管道传递的代码，通过向它传递 --multiprocessing-fork 命令行参数。
    # 如果你看一下 freeze_support() 函数的实现，它的任务是检查它运行在哪个进程中，是否应该运行通过管道传递的代码
    multiprocessing.freeze_support()

    # 创建一个进程池，根据电脑的核心数自动分配进程
    pool = multiprocessing.Pool()
    # 创建一个空列表，用于存放异步任务的结果对象
    results = []
    # 遍历文件夹中的所有文件
    for file in os.listdir(folder_path):
        # 拼接完整的文件路径
        file_path = os.path.join(folder_path, file)
        # 判断是否是图片文件，根据扩展名判断，可以根据需要修改扩展名列表
        if any(file_path.endswith(ext) for ext in extensions):
            # 调用函数，转换并保存图片，并获取文件体积，使用异步方式，不阻塞主进程
            result = pool.apply_async(convert_and_save, args=(file_path,), callback=print_result)
            # 将结果对象添加到列表中
            results.append((file, result))
    # 关闭进程池，不再接受新的任务
    pool.close()
    # 等待所有的任务完成
    pool.join()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;afterword&#34;&gt;Afterword
&lt;/h2&gt;&lt;p&gt;Because local development is on a &lt;code&gt;Windows&lt;/code&gt; system, the AI&amp;rsquo;s initial answer didn&amp;rsquo;t include a &lt;code&gt;main&lt;/code&gt; function or &lt;code&gt;multiprocessing.freeze_support&lt;/code&gt;. The code was fixed by tracing the error messages that occurred through follow-up questions.&lt;/p&gt;
&lt;p&gt;Just as we learned techniques for using search engines back in the day, we also need to learn some techniques for communicating with AI – providing reasonable and sufficient constraints to efficiently obtain the answers we need&lt;/p&gt;
&lt;p&gt;Note: &lt;strong&gt;If you are a programming novice and have any questions about the code based on the comments, feel free to ask for clarification.&lt;/strong&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>WeChat Mini Program Background and Development Environment</title>
        <link>https://ttf248.life/en/p/wechat-mini-program-background-and-development-environment/</link>
        <pubDate>Fri, 24 Mar 2023 21:59:11 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/wechat-mini-program-background-and-development-environment/</guid>
        <description>&lt;p&gt;Introduction to and Preparation for WeChat Mini Programs&lt;/p&gt;
&lt;h2 id=&#34;why-do-wechat-mini-programs-exist&#34;&gt;Why do WeChat mini programs exist?
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;A better experience: Slow loading of embedded webpages, white screens; Native app experiences offer faster loading&lt;/li&gt;
&lt;li&gt;Standards and Management: For WeChat, accessing and managing&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Before the release of mini-programs, WeChat released an SDK called JSSDK, which exposed WeChat&amp;rsquo;s native capabilities such as Wechat Pay and cards. However, developers developed based on web development language logic, allowing them to bypass some of WeChat’s regulations. Mini-programs have their own description language.&lt;/p&gt;
&lt;h2 id=&#34;what-is-a-mini-program&#34;&gt;What is a mini program?
&lt;/h2&gt;&lt;p&gt;Mini programs are applications that can be used without downloading or installing, realizing the dream of apps being readily accessible&lt;/p&gt;
&lt;p&gt;Users can open the application by scanning a QR code or searching for it, which also embodies the &amp;ldquo;use and leave&amp;rdquo; concept&lt;/p&gt;
&lt;p&gt;Users don&amp;rsquo;t need to worry about whether they have installed too many applications. Applications will be everywhere, readily available, but without the need for installation or uninstallation.&lt;/p&gt;
&lt;h2 id=&#34;the-difference-between-mini-programs-and-mobile-apps&#34;&gt;The difference between mini-programs and mobile apps
&lt;/h2&gt;&lt;p&gt;No installation required, doesn&amp;rsquo;t take up memory space, easy to share: scan a code, mini-program card, search&lt;/p&gt;
&lt;h2 id=&#34;what-can-mini-programs-do&#34;&gt;What can mini programs do?
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Content Tools: Zhihu Hot List, Weibo Trending Topics, Mobike, Jinri Toutiao, Tencent Map, Tencent Translate&lt;/li&gt;
&lt;li&gt;Retail: Pinduoduo, JD Shopping, Mogujie, Meili Fresh, Xiaomi Mall, Watson&amp;rsquo;s&lt;/li&gt;
&lt;li&gt;Games: Jump Jump, Happy Landlord, Happy Mahjong, Douyu Live Streaming, YY Live Streaming&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;The course content is from 2018, and now some of the application vendors have already gone out of business&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;development-preparation&#34;&gt;Development preparation
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Registering a mini-program account: You can register by filling in the information normally, and activate your account by clicking on the activation link in the email&lt;/li&gt;
&lt;li&gt;Information Registration&lt;/li&gt;
&lt;li&gt;Log in to the Mini Program Management Console&lt;/li&gt;
&lt;li&gt;Perfect/Complete Mini Program Information&lt;/li&gt;
&lt;li&gt;Binding Developer: For individual developers, the WeChat account used for login is the administrator account and does not require any additional binding operations&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Email addresses have certain limitations, so a new email address is needed. QQ email allows for aliases, and the WeChat backend doesn&amp;rsquo;t verify them. I tried it out, but changing the name of the mini-program is tricky; anything involving trademarks tends to fail during review.&lt;/p&gt;
&lt;p&gt;Service categories can be selected, or you can add your own; a mini-program can include five categories&lt;/p&gt;
&lt;p&gt;You can view the applet’s &lt;code&gt;ID&lt;/code&gt; information and enable message push notifications within settings. Enabling message push notifications allows you to use message template functions.&lt;/p&gt;
&lt;h2 id=&#34;developer-tools-a-personal-account&#34;&gt;Developer Tools (A Personal Account)
&lt;/h2&gt;&lt;p&gt;The download and installation are normal, with no special notes. A quick understanding is sufficient; you can directly enter in visitor mode. If you want to enable phone debugging, which allows viewing the development version of the mini-program on your phone, you need to log in to the mini-program developer account and then click on settings, switch to the specified mini-program &lt;code&gt;ID&lt;/code&gt; within project details.&lt;/p&gt;
&lt;h2 id=&#34;code-structure&#34;&gt;Code structure
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;JS: Interaction logic&lt;/li&gt;
&lt;li&gt;JSON: Data Configuration&lt;/li&gt;
&lt;li&gt;WXML: The elements of the interface&lt;/li&gt;
&lt;li&gt;wxss: Styles for the interface&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>The office relocation caused server inaccessibility</title>
        <link>https://ttf248.life/en/p/office-migration-server-unavailable/</link>
        <pubDate>Sat, 11 Mar 2023 01:42:05 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/office-migration-server-unavailable/</guid>
        <description>&lt;p&gt;Administrative notice, office relocation. Moving from the original second floor to the fifteenth floor, a routine desk move.&lt;/p&gt;
&lt;h2 id=&#34;sense-of-design&#34;&gt;Sense of design
&lt;/h2&gt;&lt;p&gt;Office building&lt;/p&gt;
&lt;h2 id=&#34;migration&#34;&gt;Migration
&lt;/h2&gt;&lt;p&gt;Packing up and moving on, setting up a new workstation, adjusting computer cables, and starting work in a comfortable position&lt;/p&gt;
&lt;p&gt;Oh no! I connected the network cable, but the server commonly used by our group is inaccessible. I tried switching to a wireless network and it works fine again.&lt;/p&gt;
&lt;p&gt;Initially, I thought it was a server network segment configuration issue. The wired network of the new workstation wasn&amp;rsquo;t on the firewall’s configured list, and contacting IT colleagues to make adjustments should have resolved it. However, this network segment hosts more than one server, and accessing other servers worked fine. This gradually raised my suspicions. Professional matters should be handled by professionals. Eventually, the operations team identified that because this server had &lt;code&gt;docker&lt;/code&gt; deployed, there was a conflict between the default Docker network &lt;code&gt;docker0&lt;/code&gt; and the network segment configured for the office’s wired network. As a result, data packets sent to the server received no response and were routed to the &lt;code&gt;docker&lt;/code&gt; service.&lt;/p&gt;
&lt;p&gt;The other servers don&amp;rsquo;t have &lt;code&gt;docker&lt;/code&gt; deployed, so it’s just this one that I use frequently. I occasionally deploy some test services using containers, and never expected to encounter this situation. Thinking about it more carefully, since the entire group is in the same office building, and the IT department divided network segments using addresses starting with &lt;code&gt;172&lt;/code&gt;, it&amp;rsquo;s not surprising.&lt;/p&gt;
&lt;h2 id=&#34;docker0&#34;&gt;docker0
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# vim /etc/docker/daemon.json
{
    &amp;quot;bip&amp;quot;:&amp;quot;172.200.0.1/24&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Restart the service, switch to the new network, and the server will return to normal access&lt;/p&gt;
&lt;h2 id=&#34;reference-materials&#34;&gt;Reference materials
&lt;/h2&gt;&lt;p&gt;Docker from Entry to Practice - docker0&lt;/p&gt;</description>
        </item>
        <item>
        <title>Embedded Entry 1 - Professional Terms</title>
        <link>https://ttf248.life/en/p/embedded-introduction-professional-terms/</link>
        <pubDate>Tue, 07 Mar 2023 13:42:36 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/embedded-introduction-professional-terms/</guid>
        <description>&lt;p&gt;Mentioning embedded systems, what comes to mind are still the 51 microcontrollers and Freescale from my school lab days&lt;/p&gt;
&lt;p&gt;The LPA3399Pro is a visual host developed on the Rockchip RK3399Pro platform, designed for portable computing hosts requiring extensive vision processing scenarios. It features an integrated NPU computing unit with 3.0 TOPS of computing power and supports various algorithm models.&lt;/p&gt;
&lt;p&gt;RV1109 is Realtek&amp;rsquo;s AI-specific machine vision SoC branch, featuring an integrated independent NPU. RV1109 can provide 1 TOPS of computing power.&lt;/p&gt;
&lt;h2 id=&#34;system-on-chip&#34;&gt;System on Chip
&lt;/h2&gt;&lt;p&gt;SoC is an abbreviation for &amp;ldquo;System on a Chip,&amp;rdquo; meaning &amp;ldquo;on-chip system.&amp;rdquo; It&amp;rsquo;s a technology that integrates multiple electronic systems onto a single chip. This technology can significantly reduce the size and weight of electronic products while improving performance and reducing power consumption.&lt;/p&gt;
&lt;p&gt;SoCs (System on a Chip) and CPUs (Central Processing Units) are both important components of computer systems, but there are some differences between them&lt;/p&gt;
&lt;p&gt;The CPU is the core processor in a computer system, responsible for executing program instructions. It typically includes only basic components such as an arithmetic unit, control unit, and registers.&lt;/p&gt;
&lt;p&gt;SoCs integrate multiple electronic systems onto a single chip, and in addition to including a CPU, they can also incorporate other components such as memory, graphics processors, and input/output interfaces. This significantly reduces the size and weight of electronic products while improving performance and reducing power consumption.&lt;/p&gt;
&lt;p&gt;In short, a CPU is a component of an SoC, while an SoC is a more complex and highly integrated electronic system&lt;/p&gt;
&lt;h2 id=&#34;microcontroller-unit&#34;&gt;Microcontroller Unit
&lt;/h2&gt;&lt;p&gt;SoC (System on a Chip) and MCU (Microcontroller Unit) are technologies that integrate multiple electronic systems onto a single chip, but there are some differences between them&lt;/p&gt;
&lt;p&gt;An MCU is a microcontroller, typically including basic components such as a CPU, memory, and input/output interfaces. It is commonly used to control other electronic devices, such as home appliances and automotive electronics systems.&lt;/p&gt;
&lt;p&gt;SoCs integrate more electronic systems onto a single chip, including basic components like MCUs and other elements such as graphics processors and wireless communication modules. This significantly reduces the size and weight of electronic products while improving performance and reducing power consumption.&lt;/p&gt;
&lt;p&gt;In short, an MCU is a simple microcontroller, while a SoC is a more complex and highly integrated electronic system&lt;/p&gt;</description>
        </item>
        <item>
        <title>AI-assisted programming, an evolution of productivity</title>
        <link>https://ttf248.life/en/p/ai-assisted-programming-productivity-evolution/</link>
        <pubDate>Tue, 28 Feb 2023 17:05:17 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/ai-assisted-programming-productivity-evolution/</guid>
        <description>&lt;p&gt;GitHub Copilot was released less than two years ago, and then ChatGPT appeared. I don&amp;rsquo;t fully understand the underlying principles, but I’ve used both for a while. The two tools offer completely different levels of assistance, but they both significantly improve productivity.&lt;/p&gt;
&lt;p&gt;Very complex things, AI still can&amp;rsquo;t do. After all, they lack logic; things that are routine or have a fixed paradigm, if the training data is sufficient, AI can achieve about 90% effectiveness.&lt;/p&gt;
&lt;h2 id=&#34;github-copilot&#34;&gt;github copilot
&lt;/h2&gt;&lt;p&gt;When it was released, looking at the demo introduction on the official website, it didn&amp;rsquo;t seem very smart, and after trying it out, it wasn&amp;rsquo;t very usable, so I gave up&lt;/p&gt;
&lt;p&gt;Before 2022, when I had nothing else to do, I switched to the new version to try it out, and the effect is already pretty good. The only problem is that the speed in China is a bit slow, probably due to network issues. Code written based on comments using languages like &lt;code&gt;Python&lt;/code&gt; is quite decent; it&amp;rsquo;s much faster than looking up information myself and writing code from scratch.&lt;/p&gt;
&lt;h2 id=&#34;chatgpt&#34;&gt;ChatGPT
&lt;/h2&gt;&lt;p&gt;GitHub Copilot is still designed from a programmer&amp;rsquo;s, or developer&amp;rsquo;s, perspective. You need to understand how to program and gradually guide the AI with comments to assist in programming.&lt;/p&gt;
&lt;p&gt;ChatGPT has reached the next level, &lt;strong&gt;making it easy for even non-experts to get started&lt;/strong&gt;. With its conversational and interactive design, you can freely ask questions, describe your needs, and continue asking if there&amp;rsquo;s anything you don&amp;rsquo;t understand.&lt;/p&gt;
&lt;p&gt;For example, you understand the concept of tokenization but don&amp;rsquo;t know how to code it, and want to calculate string similarity:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Python 分词计算 維天運通 LOGORY 和 合肥維天運通信息科技股份有限公司 两个字符串的相似度；
比较前，统一处理字符串，英文转换为小写；
第二个字符中如果能找到第一个字符的首字符，将第二个字符串截位，截位的长度为第一个字符串的长度
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hello, this is Bing. 😊&lt;/p&gt;
&lt;p&gt;According to online information 123, Python tokenization can be implemented using the jieba library. The jieba library supports three segmentation modes: precise mode, full mode, and search engine mode. You can choose the appropriate mode based on your needs.&lt;/p&gt;
&lt;p&gt;To compare the similarity of two strings, you first need to tokenize them and then calculate indicators such as word vectors or edit distance. You can use libraries like NumPy or SciPy for mathematical operations.&lt;/p&gt;
&lt;p&gt;To uniformly handle strings, converting them to lowercase can be achieved using Python&amp;rsquo;s built-in function lower()&lt;/p&gt;
&lt;p&gt;To extract the second string, you can use Python&amp;rsquo;s slicing operator []&lt;/p&gt;
&lt;p&gt;Here is a possible code example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import jieba
import numpy as np
from scipy.spatial.distance import cosine

# 定义两个字符串
str1 = &amp;quot;維天運通 LOGORY&amp;quot;
str2 = &amp;quot;合肥維天運通信息科技股份有限公司&amp;quot;

# 统一处理字符串，英文转换为小写
str1 = str1.lower()
str2 = str2.lower()

# 找到第二个字符串中第一个字符的位置
index = str2.find(str1[0])

# 如果找到了，截取第二个字符串
if index != -1:
    str2 = str2[index:index+len(str1)]

# 使用 jieba 库进行分词
words1 = list(jieba.cut(str1))
words2 = list(jieba.cut(str2))

# 计算两个字符串的词向量（以词频作为权重）
vector1 = np.zeros(len(words1))
vector2 = np.zeros(len(words1))

for i, word in enumerate(words1):
    vector1[i] += 1 # 统计第一个字符串中每个词出现的次数
    if word in words2:
        vector2[i] += 1 # 统计第二个字符串中每个词出现的次数

# 计算两个字符串的相似度（以余弦距离作为指标）
similarity = 1 - cosine(vector1, vector2)

print(&amp;quot;两个字符串的相似度是：&amp;quot;, similarity)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To take it a step further, I consulted the results of the run and congratulated you on discovering a problem – the results were fabricated. It didn&amp;rsquo;t actually execute any code but gave a decent result.&lt;/p&gt;
&lt;h3 id=&#34;chestnuts&#34;&gt;Chestnuts
&lt;/h3&gt;&lt;p&gt;Question: SQL statement, retrieve records from the product code table where the product codes are within the range of 80000-89999&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;你好，这是 Bing。😊

根据搜索结果12，你可以使用 SQL BETWEEN 运算符来选择给定区间内的值。BETWEEN 运算符包含了开始和结束的值。

你需要先指定要查询的表名和列名，然后在 WHERE 子句中使用 BETWEEN 运算符和区间值。

例如，如果你要查询产品代码表中，产品代码在 80000 到 89999 之间的记录，你可以使用以下语句：

SELECT * FROM product_code
WHERE code BETWEEN 80000 AND 89999;
这里，* 表示选择所有列3。如果你只想选择特定的列，比如产品名称和价格，你可以用逗号分隔它们，如下：

SELECT name, price FROM product_code
WHERE code BETWEEN 80000 AND 89999;
希望这能帮助到你。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Keep asking, negate it: The product code is a string, your code is wrong&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;抱歉，我没有注意到产品代码是字符串。如果是这样的话，你需要在区间值两边加上单引号，如下：

SELECT * FROM product_code
WHERE code BETWEEN &#39;80000&#39; AND &#39;89999&#39;;
请原谅我的错误。🙏
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Congratulations, it will make a mistake&lt;/p&gt;</description>
        </item>
        <item>
        <title>A summary of several less commonly used Git commands</title>
        <link>https://ttf248.life/en/p/git-less-common-commands-summary/</link>
        <pubDate>Fri, 17 Feb 2023 10:08:57 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/git-less-common-commands-summary/</guid>
        <description>&lt;p&gt;Not frequently used, but very useful &lt;code&gt;git&lt;/code&gt; commands&lt;/p&gt;
&lt;h3 id=&#34;reinstalling-the-system-resulted-in-changes-to-folder-ownership-information-in-windows&#34;&gt;Reinstalling the system resulted in changes to folder ownership information in Windows
&lt;/h3&gt;&lt;p&gt;The new version of &lt;code&gt;git&lt;/code&gt; added security checks, prompting an insecurity message, which prevents further operations&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git config --global --add safe.directory
git config --global --add safe.directory &amp;quot;*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;new-computer-saves-account-password-information&#34;&gt;New computer saves account password information
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git config --global credential.helper store
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the saved information needs to be updated, clear the old records first&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git config --system --unset credential.helper
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Compiler, callback function, performance testing</title>
        <link>https://ttf248.life/en/p/compiler-callback-function-performance-testing/</link>
        <pubDate>Wed, 15 Feb 2023 13:59:25 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/compiler-callback-function-performance-testing/</guid>
        <description>&lt;p&gt;Last year, we designed an SDK that handles event encapsulation and provides a class interface. During service initialization, the caller implements the corresponding class and passes the object pointer to the module.
Having experience with &lt;code&gt;C11&lt;/code&gt;, driven by curiosity, I wondered what the results would be if these interfaces were implemented using &lt;code&gt;lambda&lt;/code&gt; function objects as callbacks compared to defining interfaces with pure virtual functions – it seems more flexible
Questions then arose: which grammar is faster from a performance perspective? Without understanding compiler principles, let&amp;rsquo;s just try some code&lt;/p&gt;
&lt;h2 id=&#34;preface&#34;&gt;Preface
&lt;/h2&gt;&lt;p&gt;An online URL that allows you to choose different compilers, compilation parameters, run code on the &lt;code&gt;Linux&lt;/code&gt; platform, or view the corresponding assembly code&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sometimes it&amp;rsquo;s convenient to run small code snippets on a webpage for technical verification&lt;/li&gt;
&lt;li&gt;Godbolt.org uses different colors to distinguish the code corresponding to different assembly, making it easier to view than a local debugger&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;The standards committee defines the rules of grammar. How to implement this at the compilation level depends on each compiler. I have to say, Microsoft&amp;rsquo;s compilers are quite impressive. Syntactic sugar isn&amp;rsquo;t all-powerful; with fewer callback interfaces, &lt;code&gt;lambda&lt;/code&gt; is more convenient and eliminates the need to define empty callback function interfaces. When there are many types of callback interfaces, traditional virtual functions are more beneficial for unifying business interface definitions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Both perform similarly on the Windows platform, with little difference&lt;/li&gt;
&lt;li&gt;Comparison of virtual functions and lambda expressions on the &lt;code&gt;linux&lt;/code&gt; platform, a difference of 1.35 ns per execution&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In typical business system development, this level of performance loss can be ignored. Introducing &lt;code&gt;lambda&lt;/code&gt; brings more convenience in design. This is particularly noticeable when designing multi-signal processing scenarios. With event triggers at the bottom layer and a need to persist logs, the handling function for entering and exiting log objects is involved. When more business processing interfaces are required, a &lt;code&gt;vector&lt;/code&gt; stores &lt;code&gt;lambda&lt;/code&gt; objects at the bottom layer. Upon event triggering, they are traversed and invoked sequentially, similar to signals and slots in &lt;code&gt;QT&lt;/code&gt;. This allows for complete decoupling between logging, monitoring, business 1, and business 2.&lt;/p&gt;
&lt;h2 id=&#34;code&#34;&gt;Code
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Counter: 1000000
Time: 3966us
Counter: 1000000
Time: 5316us
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;memory&amp;gt;
#include &amp;lt;functional&amp;gt;
#include &amp;lt;atomic&amp;gt;
#include &amp;lt;string&amp;gt;

std::atomic_int64_t counter = 0;

// 定义回调接口
class UserInterface
{
public:
    virtual void name() = 0;
    virtual void full_name() = 0;
};

class User : public UserInterface
{
public:
    void name() {}
    void full_name() { counter++; }
};

void to_string(UserInterface* user)
{
    user-&amp;gt;name();
    user-&amp;gt;full_name();
}

using name_handler = std::function&amp;lt;void()&amp;gt;;
using full_name_handler = std::function&amp;lt;void()&amp;gt;;

class Test
{
    name_handler name_;
    full_name_handler full_name_;

public:
    void set_name_handler(name_handler name)
    {
        name_ = name;
    }

    void set_full_name_handler(full_name_handler full_name)
    {
        full_name_ = full_name;
    }

    void to_string()
    {
        name_();
        full_name_();
    }
};

int main()
{
    User user;

    auto start = std::chrono::high_resolution_clock::now();

    for (int i = 0; i &amp;lt; 1000000; i++)
    {
        to_string(&amp;amp;user);
    }

    auto end = std::chrono::high_resolution_clock::now();
    std::cout &amp;lt;&amp;lt; &amp;quot;Counter: &amp;quot; &amp;lt;&amp;lt; counter &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;Time: &amp;quot; &amp;lt;&amp;lt; std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(end - start).count() &amp;lt;&amp;lt; &amp;quot;us&amp;quot; &amp;lt;&amp;lt; std::endl;

    counter = 0;
    auto name = []() {};
    auto full_name = []() { counter++; };

    Test test;
    test.set_name_handler(name);
    test.set_full_name_handler(full_name);

    start = std::chrono::high_resolution_clock::now();

    for (int i = 0; i &amp;lt; 1000000; i++)
    {
        test.to_string();
    }

    end = std::chrono::high_resolution_clock::now();
    std::cout &amp;lt;&amp;lt; &amp;quot;Counter: &amp;quot; &amp;lt;&amp;lt; counter &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &amp;quot;Time: &amp;quot; &amp;lt;&amp;lt; std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(end - start).count() &amp;lt;&amp;lt; &amp;quot;us&amp;quot; &amp;lt;&amp;lt; std::endl;

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;afterword&#34;&gt;Afterword
&lt;/h2&gt;&lt;p&gt;While searching for information, I came across a similar code snippet &lt;a class=&#34;link&#34; href=&#34;https://gist.githubusercontent.com/benloong/8050171/raw/fa577ec923b460862078b8b40233a42a1c619eeb/functionperformance.cpp&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;functionperformance.cpp&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;memory&amp;gt;
#include &amp;lt;functional&amp;gt;

using namespace std;
using namespace std::chrono;

class Base
{
public:
	Base(){}
	virtual ~Base(){}
	virtual int func(int i) = 0;
};

class Derived : public Base
{
public:
	Derived(int base = 10) : base{base}
	{

	}
	~Derived(){}

	virtual int func(int i)
	{
		return i*base;
	}
private:
	int base;
};

struct Func
{
	int base;
	int operator()(int i)
	{
		return i*base;
	}
	Func(int base) : base {base}
	{

	}
};
const int base = 10;
int calculate(int i)
{
	return base*i;
}

int main()
{
	const int num = 10000;
	Base *p = new Derived{10};
	int total = 0;
	auto start = high_resolution_clock::now();
	for (int i = 0; i &amp;lt; num; ++i)
	{
		total += p-&amp;gt;func(i);
	}
	auto end = high_resolution_clock::now();
	std::cout&amp;lt;&amp;lt;&amp;quot;result: &amp;quot;&amp;lt;&amp;lt;total&amp;lt;&amp;lt;&amp;quot;\nvirtual call elapsed: \t&amp;quot;&amp;lt;&amp;lt;duration_cast&amp;lt;nanoseconds&amp;gt;(end-start).count()&amp;lt;&amp;lt;&amp;quot; nanoseconds.\n&amp;quot;&amp;lt;&amp;lt;std::endl;

	total = 0;
	start = high_resolution_clock::now();
	for (int i = 0; i &amp;lt; num; ++i)
	{
		total += calculate(i);
	}
	end = high_resolution_clock::now();
	std::cout&amp;lt;&amp;lt;&amp;quot;result: &amp;quot;&amp;lt;&amp;lt;total&amp;lt;&amp;lt;&amp;quot;\ndirect function call elapsed: \t&amp;quot;&amp;lt;&amp;lt;duration_cast&amp;lt;nanoseconds&amp;gt;(end-start).count()&amp;lt;&amp;lt;&amp;quot; nanoseconds.\n&amp;quot;&amp;lt;&amp;lt;std::endl;

	Func functor{10};
	total = 0;
	start = high_resolution_clock::now();
	for (int i = 0; i &amp;lt; num; ++i)
	{
		total += functor(i);
	}
	end = high_resolution_clock::now();
	std::cout&amp;lt;&amp;lt;&amp;quot;result: &amp;quot;&amp;lt;&amp;lt;total&amp;lt;&amp;lt;&amp;quot;\nfunctor call elapsed: \t&amp;quot;&amp;lt;&amp;lt;duration_cast&amp;lt;nanoseconds&amp;gt;(end-start).count()&amp;lt;&amp;lt;&amp;quot; nanoseconds.\n&amp;quot;&amp;lt;&amp;lt;std::endl;
	int base = 10;
	function&amp;lt;int(int)&amp;gt; lambda = [base](int i)
	{
		return i*base;
	};
	total = 0;
	start = high_resolution_clock::now();
	for (int i = 0; i &amp;lt; num; ++i)
	{
		total += lambda(i);
	}
	end = high_resolution_clock::now();
	std::cout&amp;lt;&amp;lt;&amp;quot;result: &amp;quot;&amp;lt;&amp;lt;total&amp;lt;&amp;lt;&amp;quot;\nlambda call elapsed: \t&amp;quot;&amp;lt;&amp;lt;duration_cast&amp;lt;nanoseconds&amp;gt;(end-start).count()&amp;lt;&amp;lt;&amp;quot; nanoseconds.\n&amp;quot;&amp;lt;&amp;lt;std::endl;
	return 0;
}

/*
test on mac mini i7 2.7GHz
clang++ -std=c++11 chronotest.cpp -O0
output:
result: 499950000
virtual call elapsed: 	43171 nanoseconds.

result: 499950000
direct function call elapsed: 	31379 nanoseconds.

result: 499950000
functor call elapsed: 	41497 nanoseconds.

result: 499950000
lambda call elapsed: 	207416 nanoseconds.
===================================================
clang++ -std=c++11 chronotest.cpp -O1
output:
result: 499950000
virtual call elapsed: 	26144 nanoseconds.

result: 499950000
direct function call elapsed: 	22384 nanoseconds.

result: 499950000
functor call elapsed: 	33477 nanoseconds.

result: 499950000
lambda call elapsed: 	55799 nanoseconds.
===================================================
clang++ -std=c++11 chronotest.cpp -O2
result: 499950000
virtual call elapsed: 	22284 nanoseconds.

result: 499950000
direct function call elapsed: 	36 nanoseconds.

result: 499950000
functor call elapsed: 	30 nanoseconds.

result: 499950000
lambda call elapsed: 	28292 nanoseconds.

===================================================
clang++ -std=c++11 chronotest.cpp -O3
result: 499950000
virtual call elapsed: 	18975 nanoseconds.

result: 499950000
direct function call elapsed: 	29 nanoseconds.

result: 499950000
functor call elapsed: 	30 nanoseconds.

result: 499950000
lambda call elapsed: 	22542 nanoseconds.
===================================================
clang++ -std=c++11 chronotest.cpp -O4

result: 499950000
virtual call elapsed: 	22141 nanoseconds.

result: 499950000
direct function call elapsed: 	30 nanoseconds.

result: 499950000
functor call elapsed: 	30 nanoseconds.

result: 499950000
lambda call elapsed: 	22584 nanoseconds.
*/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are two new modes, ordinary functions and emulated functions. There&amp;rsquo;s a significant performance difference—on the order of magnitude—between using interface callbacks and direct calls. Emulated function performance is close to that of regular functions, and sometimes even better. This area (compiler principles) is a knowledge blind spot for me. My guess is that it’s due to the fact that the variables accessed and the function are located next to each other in memory, which benefits CPU processing.&lt;/p&gt;
&lt;p&gt;Attached is the output of &lt;code&gt;wandbox&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;result: 499950000
virtual call elapsed: 6143 nanoseconds.

result: 499950000
direct function call elapsed: 30 nanoseconds.

result: 499950000
functor call elapsed: 31 nanoseconds.

result: 499950000
lambda call elapsed: 15134 nanoseconds.
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Host order, network order, observe directly through a debugger</title>
        <link>https://ttf248.life/en/p/host-order-network-order-debugger-observation/</link>
        <pubDate>Tue, 10 Jan 2023 14:18:12 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/host-order-network-order-debugger-observation/</guid>
        <description>&lt;p&gt;In the history of computer development, there has not been a unified standard for how to store data&lt;/p&gt;
&lt;p&gt;There are two common rules for arranging bytes. For example, if the low-order digits of a multi-digit number are placed at smaller addresses and the high-order digits are placed at larger addresses, it is called little-endian; otherwise, it is called big-endian. In network applications, byte order is a factor that must be considered because different machine types may adopt different standards, so they are all converted according to the network standard.&lt;/p&gt;
&lt;p&gt;Following reading habits, big-endian byte order is more consistent with the left-to-right reading sequence&lt;/p&gt;
&lt;h2 id=&#34;processor-architecture&#34;&gt;Processor architecture
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Processors such as x86, MOS Technology 6502, Z80, VAX, and PDP-11 are little-endian&lt;/li&gt;
&lt;li&gt;Processors such as Motorola 6800, Motorola 68000, and PowerPC 970 are big-endian&lt;/li&gt;
&lt;li&gt;The byte order is configurable for ARM, PowerPC (except PowerPC 970), DEC Alpha, SPARC V9, MIPS, PA-RISC, and IA64&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;network-preface&#34;&gt;Network Preface
&lt;/h2&gt;&lt;p&gt;Network transmission generally uses big-endian order, also known as network byte order or network order. Big-endian is defined as the network byte order in the IP protocol.
Berkeley sockets define a set of conversion functions for converting between network byte order and host byte order for 16- and 32-bit integers&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;arpa/inet.h&amp;gt;

uint32_t htonl(uint32_t hostlong); //把uint32_t类型从主机序转换到网络序
uint16_t htons(uint16_t hostshort); //把uint16_t类型从主机序转换到网络序
uint32_t ntohl(uint32_t netlong); //把uint32_t类型从网络序转换到主机序
uint16_t ntohs(uint16_t netshort); //把uint16_t类型从网络序转换到主机序
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you choose &lt;code&gt;asio&lt;/code&gt; as your networking library, there are cross-platform compatible function names in the built-in namespace&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;boost::asio::detail::socket_ops::network_to_host_long&lt;/li&gt;
&lt;li&gt;boost::asio::detail::socket_ops::network_to_host_short&lt;/li&gt;
&lt;li&gt;boost::asio::detail::socket_ops::host_to_network_long&lt;/li&gt;
&lt;li&gt;boost::asio::detail::socket_ops::host_to_network_short&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;visual-studio-debugger&#34;&gt;Visual Studio debugger
&lt;/h2&gt;&lt;p&gt;In debug mode, select the Debug menu, then Window, and check Memory Window&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;Visual Studio&lt;/code&gt;, you can directly view data in memory within the debugger, as shown in the figure below&lt;/p&gt;
&lt;p&gt;Debugger Menu&lt;/p&gt;
&lt;h3 id=&#34;how-to-check-memory&#34;&gt;How to check memory
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Prints the variable name directly in the window and jumps to its corresponding address&lt;/li&gt;
&lt;li&gt;If the variable is already a pointer, double-click on the variable, drag it to the memory window, and display the contents at that address&lt;/li&gt;
&lt;li&gt;If the variable is not a pointer, add it to the calculation window, get its address, and then manually copy it to the memory window&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;for-example&#34;&gt;For example
&lt;/h3&gt;&lt;p&gt;Received a data segment, stored in the &lt;code&gt;buffer&lt;/code&gt; object, converted from network byte order to host byte order, resulting in &lt;code&gt;body_length&lt;/code&gt; equal to 30. The server has allocated four bytes for transmitting this data.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;bool NetworkMessage::decode_header()
{
    // 网络序转成主机序
    body_length_ = boost::asio::detail::socket_ops::network_to_host_long(*(int *)buffer_.data());
    return auto_reserve(body_length_);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;Big-endian byte order: Observe the contents of &lt;code&gt;buffer_&lt;/code&gt; in the memory window&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/host-order-network-order-debugger-observation/buffer_.png&#34;
	width=&#34;603&#34;
	height=&#34;318&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;buffer_&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;189&#34;
		data-flex-basis=&#34;455px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Little-endian byte order: Observe the contents of &lt;code&gt;body_length_&lt;/code&gt; in the memory window&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/host-order-network-order-debugger-observation/body_length_.png&#34;
	width=&#34;581&#34;
	height=&#34;333&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;body_length_&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;174&#34;
		data-flex-basis=&#34;418px&#34;
	
&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>C11: sleep for vs yield</title>
        <link>https://ttf248.life/en/p/c11-sleep-for-vs-yield/</link>
        <pubDate>Tue, 20 Sep 2022 20:54:51 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/c11-sleep-for-vs-yield/</guid>
        <description>&lt;p&gt;While reviewing the code, &lt;code&gt;std::this_thread::yield()&lt;/code&gt; suddenly caught my eye – a syntactic sugar feature from &lt;code&gt;C11&lt;/code&gt;. I&amp;rsquo;ve used quite a bit of it, but this is the first time seeing &lt;code&gt;yield&lt;/code&gt;, and I hadn’t noticed it before.&lt;/p&gt;
&lt;p&gt;Without checking the manual, my first thought was whether it&amp;rsquo;s related to asynchrony. The word &lt;code&gt;yield&lt;/code&gt; is used in the coroutine implementation of the Boost library, but this definitely has nothing to do with coroutines here; the control logic is likely related to ordinary threads.&lt;/p&gt;
&lt;h2 id=&#34;document&#34;&gt;Document
&lt;/h2&gt;&lt;h3 id=&#34;yield&#34;&gt;yield
&lt;/h3&gt;&lt;p&gt;The accuracy of this function depends on the implementation, particularly the OS scheduler mechanism and system state in use. For example, a first-in, first-out real-time scheduler (SCHED_FIFO in Linux) will suspend the current thread and place it at the tail of the queue of threads with the same priority (and yield has no effect if there are no other threads at the same priority).&lt;/p&gt;
&lt;h3 id=&#34;sleep_for&#34;&gt;sleep_for
&lt;/h3&gt;&lt;p&gt;Blocks the current thread&amp;rsquo;s execution for at least the specified sleep_duration
This function may block for longer than sleep_duration due to scheduling delays or resource contention
The standard library recommends measuring duration using a stable clock. If implemented with system time, wait times may also be sensitive to clock adjustments.&lt;/p&gt;
&lt;h3 id=&#34;analysis&#34;&gt;Analysis
&lt;/h3&gt;&lt;p&gt;Are both functions designed to release the current thread, and the effect depends on the platform? Still a bit hazy here, let&amp;rsquo;s run the code to see the execution results&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ThinkPad laptop (Visual Studio Community Edition 2022), Tencent Cloud S2 standard server (gcc8.5)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Operating Platform&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;First Time/μs&lt;/th&gt;
&lt;th&gt;Second Time/μs&lt;/th&gt;
&lt;th&gt;Third Time/μs&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Windows&lt;/td&gt;
&lt;td&gt;sleep_for&lt;/td&gt;
&lt;td&gt;9872&lt;/td&gt;
&lt;td&gt;1884&lt;/td&gt;
&lt;td&gt;11302&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Windows&lt;/td&gt;
&lt;td&gt;yield&lt;/td&gt;
&lt;td&gt;119&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Linux&lt;/td&gt;
&lt;td&gt;sleep_for&lt;/td&gt;
&lt;td&gt;171&lt;/td&gt;
&lt;td&gt;168&lt;/td&gt;
&lt;td&gt;167&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Linux&lt;/td&gt;
&lt;td&gt;yield&lt;/td&gt;
&lt;td&gt;101&lt;/td&gt;
&lt;td&gt;102&lt;/td&gt;
&lt;td&gt;101&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It&amp;rsquo;s easy to understand from the execution results that there are huge differences in the stability of &lt;code&gt;sleep_for&lt;/code&gt; at high precision due to different operating system implementations. If you need high-precision sleep, using &lt;code&gt;yield&lt;/code&gt; is more appropriate.&lt;/p&gt;
&lt;p&gt;When the time precision is increased to &lt;code&gt;ms&lt;/code&gt;, there is no significant difference between them&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;chrono&amp;gt;
#include &amp;lt;thread&amp;gt;
 
// 建议其他线程运行一小段时间的“忙睡眠”
void little_sleep(std::chrono::microseconds us)
{
    auto start = std::chrono::high_resolution_clock::now();
    auto end = start + us;
    do {
        std::this_thread::yield();
    } while (std::chrono::high_resolution_clock::now() &amp;lt; end);
}
 
int main()
{
    auto start = std::chrono::high_resolution_clock::now();
 
    little_sleep(std::chrono::microseconds(100));
    std::this_thread::sleep_for(std::chrono::microseconds(100));
 
    auto elapsed = std::chrono::high_resolution_clock::now() - start;
    std::cout &amp;lt;&amp;lt; &amp;quot;waited for &amp;quot;
              &amp;lt;&amp;lt; std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(elapsed).count()
              &amp;lt;&amp;lt; &amp;quot; microseconds\n&amp;quot;;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/header/thread.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://qingcms.gitee.io/cppreference/20210212/zh/cpp/thread/sleep_for.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Resetting MySQL password on a Linux server</title>
        <link>https://ttf248.life/en/p/linux-server-reset-mysql-password/</link>
        <pubDate>Tue, 20 Sep 2022 14:27:35 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-server-reset-mysql-password/</guid>
        <description>&lt;p&gt;I have an idle Tencent Cloud server that is due to expire at the end of the year, and I didn&amp;rsquo;t plan on renewing it. I deployed a MySQL database for development purposes. When reinstalling the system, I chose a third-party image provided by Tencent Cloud to save time; it already had the MySQL database installed. I assumed there would be a Readme file or something similar in the system, explaining the password and deployment path.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s quick to reinstall the system on Tencent Cloud, it notifies you that it’s been reinstalled in about a minute. I logged in and &lt;code&gt;systemctl status mysql&lt;/code&gt; shows the service has already started. I looked everywhere for the password but couldn&amp;rsquo;t find it, and slowly started feeling hopeless.&lt;/p&gt;
&lt;p&gt;Thinking about it, I&amp;rsquo;ve already gained access to the server with &lt;code&gt;root&lt;/code&gt; privileges; there has to be a way to reset the password. I flipped through some documents and found a post on the Alibaba Cloud forum – time to keep troubleshooting.&lt;/p&gt;
&lt;h2 id=&#34;reset-password&#34;&gt;Reset password
&lt;/h2&gt;&lt;p&gt;Edit the configuration file &lt;code&gt;vim /etc/my.cnf&lt;/code&gt;, add the following configuration to the &lt;code&gt;mysqld&lt;/code&gt; node: &lt;code&gt;skip-grant-tables&lt;/code&gt;, and execute the command to restart the data: &lt;code&gt;systemctl restart mysql&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Use &lt;code&gt;mysql&lt;/code&gt; to log in to the data again, and then proceed with normal operations. Reset the &lt;code&gt;root&lt;/code&gt; user password and enable remote login as well.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;USE mysql;
UPDATE user SET authentication_string = password (&#39;pass&#39;) WHERE User = &#39;root&#39;;
grant all privileges on *.* to &#39;root&#39;@&#39;%&#39; identified by &#39;pass&#39; with grant option;
flush privileges;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Revert the configuration file, restart the database, and it&amp;rsquo;s done&lt;/p&gt;
&lt;h2 id=&#34;reference-materials&#34;&gt;Reference materials
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://help.aliyun.com/document_detail/42520.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://help.aliyun.com/document_detail/42520.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>A Brief Discussion on Automated Testing</title>
        <link>https://ttf248.life/en/p/shallow-discussion-on-automation-testing/</link>
        <pubDate>Thu, 04 Aug 2022 11:39:18 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/shallow-discussion-on-automation-testing/</guid>
        <description>&lt;p&gt;Investment in testing for financial trading systems far exceeds that of other systems, with tedious testing steps repeated endlessly and a very low ROI. As projects and personnel change, uncontrollable factors are inevitably introduced. A common scenario is modifying a field output by interface A, which unexpectedly affects the result of interface B. With each version release, risks accumulate.&lt;/p&gt;
&lt;h2 id=&#34;theoretical-knowledge&#34;&gt;Theoretical knowledge
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;How do you measure the value of automation?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The ROI of an automated test case = (Manual execution time) * (Number of executions) / (Development cost + Maintenance cost)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Which features need automated testing?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Features that users commonly use and which don&amp;rsquo;t change frequently. Writing automated test code for this type of interface yields the highest return.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Why choose this time to promote automated testing?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It&amp;rsquo;s definitely not suitable now, as we approach the project launch. Relying on distant water to quench immediate thirst doesn’t work; automation is a long-term benefit model. The project is already live in the &lt;strong&gt;production environment&lt;/strong&gt; and entering a stable release cycle – this is the most appropriate time.&lt;/p&gt;
&lt;h2 id=&#34;framework-selection&#34;&gt;Framework Selection
&lt;/h2&gt;&lt;p&gt;Without relevant practical experience, being assigned a task like automation testing is typically approached as follows: open a search engine, look for tools and frameworks compatible with the current system&amp;rsquo;s &lt;strong&gt;technology stack&lt;/strong&gt;, go through the user manuals, and get started. If you can quickly find a suitable tool, congratulations, a &lt;strong&gt;perfect start&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;I apologize first. I checked the relevant materials, and it&amp;rsquo;s not that there isn&amp;rsquo;t any [solution], but rather the framework itself is too complex, and deploying it consumes excessive resources. What beginners need is something compact and streamlined. I consulted with colleagues in the testing team, who suggested building a framework using &lt;code&gt;Python&lt;/code&gt; – essentially encapsulating existing unit testing frameworks into an automated testing framework.&lt;/p&gt;
&lt;p&gt;Refer to the design of this project: &lt;a class=&#34;link&#34; href=&#34;https://github.com/wintests/pytestDemo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/wintests/pytestDemo&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;why-do-we-need-frameworks&#34;&gt;Why do we need frameworks?
&lt;/h2&gt;&lt;p&gt;The service has multiple deployment environments, including a development environment, a testing environment, and a pre-production testing environment. The framework&amp;rsquo;s role is to provide an abstraction layer, separating test cases and data. It allows for different case data configurations for each environment, while also supporting shared data.&lt;/p&gt;
&lt;p&gt;The core logic is all about improving the utilization of automation. Even if the scenario becomes more complex, and data between different environments is inconsistent and unrelated, simply add a &lt;code&gt;label&lt;/code&gt; tag when configuring case data to specify the environment supported by the current data.&lt;/p&gt;
&lt;h2 id=&#34;reference-materials&#34;&gt;Reference materials
&lt;/h2&gt;&lt;p&gt;How to Do Cost-Effective Automation Testing&lt;/p&gt;</description>
        </item>
        <item>
        <title>Why learn a new language?</title>
        <link>https://ttf248.life/en/p/why-learn-a-new-language/</link>
        <pubDate>Thu, 04 Aug 2022 11:27:30 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/why-learn-a-new-language/</guid>
        <description>&lt;p&gt;Why learn other programming languages after having used C++ for over ten years, starting from my school days?&lt;/p&gt;
&lt;p&gt;Work Experience: Lacks experience in elegant module design, C++ syntax is flexible, and learning other languages can help guide the creation of more elegant designs&lt;/p&gt;
&lt;p&gt;I often find myself using these tools when writing them&lt;/p&gt;
&lt;p&gt;Whether it&amp;rsquo;s the design of the underlying libraries or the implementation of business modules, the design principles are consistent&lt;/p&gt;</description>
        </item>
        <item>
        <title>Visual Studio character set compilation [transfer]</title>
        <link>https://ttf248.life/en/p/visual-studio-compilation-character-set-translation/</link>
        <pubDate>Thu, 04 Aug 2022 10:51:43 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/visual-studio-compilation-character-set-translation/</guid>
        <description>&lt;p&gt;Cross-platform development in C++ often encounters on Chinese operating systems: &lt;code&gt;error C2001&lt;/code&gt; newline character in constant&lt;/p&gt;
&lt;h2 id=&#34;visual-studio&#34;&gt;visual studio
&lt;/h2&gt;&lt;p&gt;CMake organizes project compilation scripts; when developing on the Windows system, it temporarily generates a solution; due to cross-platform reasons, the file encoding is chosen as UTF-8&lt;/p&gt;
&lt;p&gt;The cited materials provide a detailed explanation of the cause of the problem from a theoretical perspective&lt;/p&gt;
&lt;p&gt;Regarding encoding, &lt;code&gt;MSVC&lt;/code&gt; has specific compilation options &lt;code&gt;/source-charset&lt;/code&gt; and &lt;code&gt;/execution-charset&lt;/code&gt;. The former indicates the encoding of the file itself, while the latter indicates what encoding the bytes within the character array are after compilation. Encoding issues can generally be resolved using these two options.&lt;/p&gt;
&lt;p&gt;For example, the &lt;code&gt;cmd&lt;/code&gt; console in &lt;code&gt;windows&lt;/code&gt; can only display &lt;code&gt;GBK&lt;/code&gt; encoding by default, but the code file itself is &lt;code&gt;UTF-8&lt;/code&gt;. Due to cross-platform compatibility, it&amp;rsquo;s not convenient to directly modify it to &lt;code&gt;GBK&lt;/code&gt;. Of course, this doesn&amp;rsquo;t include methods like writing encoding conversion code for different platforms. On &lt;code&gt;Win10&lt;/code&gt;, you can set these two compilation options to &lt;code&gt;/source-charset:utf-8 /execution-charset:gbk&lt;/code&gt;, which means letting the compiler read in with &lt;code&gt;UTF-8&lt;/code&gt; encoding and then convert it to &lt;code&gt;GBK&lt;/code&gt; and save it in an array, so that &lt;code&gt;printf&lt;/code&gt; can directly display Chinese characters normally on the &lt;code&gt;cmd&lt;/code&gt; console.&lt;/p&gt;
&lt;h2 id=&#34;cmake-settings-for-visual-studio&#34;&gt;CMake settings for Visual Studio
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-cmake&#34;&gt;if( WIN32 )
    message( STATUS &amp;quot;Configuring trade on WIN32&amp;quot;)
    set( CMAKE_CXX_FLAGS &amp;quot;${CMAKE_CXX_FLAGS} /source-charset:utf-8 /execution-charset:gbk&amp;quot;)
endif()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;reference-materials&#34;&gt;Reference materials
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/146543940&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://zhuanlan.zhihu.com/p/146543940&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Quickly statistics folder size on Windows platform</title>
        <link>https://ttf248.life/en/p/windows-platform-quick-folder-size-statistics/</link>
        <pubDate>Mon, 01 Aug 2022 19:54:18 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/windows-platform-quick-folder-size-statistics/</guid>
        <description>&lt;p&gt;The Linux platform is very simple; one line of code with &lt;code&gt;du -sh *&lt;/code&gt; gets the job done. What about Windows? With many disks and a desire to clean them up, especially when there are lots of files, the built-in resource manager&amp;rsquo;s folder size statistics are so slow you want to give up.&lt;/p&gt;
&lt;h2 id=&#34;everything&#34;&gt;Everything
&lt;/h2&gt;&lt;p&gt;Developers on the Windows platform should have either used or heard of Everything. Its search speed is much faster than the system&amp;rsquo;s built-in File Explorer. Since the operating system supports fast file indexing, there must be similar tools that can establish a file index and also calculate the size of the files.&lt;/p&gt;
&lt;h2 id=&#34;wiztree&#34;&gt;WizTree
&lt;/h2&gt;&lt;p&gt;Website: &lt;a class=&#34;link&#34; href=&#34;https://www.diskanalyzer.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.diskanalyzer.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Extract and run in standard installation mode or green version&lt;/p&gt;
&lt;p&gt;Fast speed, a variety of data display types, with a tree diagram mode on the left, file types on the right, and of course, graphical displays at the bottom of the software&lt;/p&gt;
&lt;h2 id=&#34;spacesniffer-no-longer-receiving-updates-as-of-2023&#34;&gt;SpaceSniffer (no longer receiving updates as of 2023)
&lt;/h2&gt;&lt;p&gt;Software website: [http://www.uderzo.it/main_products/space_sniffer/]&lt;/p&gt;
&lt;p&gt;The operation is very simple, select the corresponding disk drive, and the software will display folder sizes in a graphical way. The larger the size, the larger the corresponding matrix in the image. You&amp;rsquo;ll understand the rest with a few clicks. It supports entering conditions to filter files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;File size filtering&lt;/li&gt;
&lt;li&gt;File date filtering&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Basic Usage&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Advanced Usage&lt;/p&gt;
&lt;h2 id=&#34;reference-materials&#34;&gt;Reference materials
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://moe.best/software/spacesniffer.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://moe.best/software/spacesniffer.html&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>How to Copy Webpage Style Sheets (CSS): Element Inspection</title>
        <link>https://ttf248.life/en/p/how-to-copy-webpage-css-element-inspection/</link>
        <pubDate>Sun, 31 Jul 2022 23:36:48 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/how-to-copy-webpage-css-element-inspection/</guid>
        <description>&lt;p&gt;The themes for static blogs are mostly based on foreign templates, with modifications and adjustments, without much consideration for the layout of Chinese content&lt;/p&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;About half a month ago, I made some adjustments to the blog&amp;rsquo;s stylesheet. Having worked in backend service development for many years, I’m quite the newbie when it comes to frontend. After fiddling with it all day, the design wasn&amp;rsquo;t very reasonable. Suddenly, I had an idea – remembering the technical blogs I often read: InfoQ and Open Source China, their layouts are really good. Could I borrow some of their ideas? I looked at the source code for a while, trying to locate the relevant elements, but ended up completely confused.&lt;/p&gt;
&lt;p&gt;Frontend developers seeing this might be laughing&amp;hellip; not understanding how to locate specified elements. It&amp;rsquo;s okay if you don&amp;rsquo;t understand, there&amp;rsquo;s plenty of time on the weekend, so let me pause and think – it seems I used something similar when writing Python crawlers before.&lt;/p&gt;
&lt;h3 id=&#34;elemental-review&#34;&gt;Elemental Review
&lt;/h3&gt;&lt;p&gt;It&amp;rsquo;s true, it’s the browser’s built-in element inspection tool – copying style sheets and locating specific elements are done in a flash; &lt;code&gt;selector&lt;/code&gt; locates elements, &lt;code&gt;hugo&lt;/code&gt; creates &lt;code&gt;user define css&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Copy element&lt;/li&gt;
&lt;li&gt;Copy outerHTML&lt;/li&gt;
&lt;li&gt;Copy selector&lt;/li&gt;
&lt;li&gt;Copy JS path&lt;/li&gt;
&lt;li&gt;Copy Style&lt;/li&gt;
&lt;li&gt;Copy XPath&lt;/li&gt;
&lt;li&gt;Copy the complete XPath&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Editing Large Files on Windows Platform: EmEditor (Text Editor)</title>
        <link>https://ttf248.life/en/p/windows-platform-editing-large-files-emeditor-text-editor/</link>
        <pubDate>Sun, 31 Jul 2022 23:21:24 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/windows-platform-editing-large-files-emeditor-text-editor/</guid>
        <description>&lt;p&gt;The Shanghai Guoan database incident has been buzzing around in the black market circles, and it&amp;rsquo;s unclear whether it’s true or not. Let&amp;rsquo;s see if we remember it in two years and take another look. Based on past experience, a wave of local social engineering database information was updated, and I saw a huge SQL file: 17.9G. A regular text editor would have trouble even previewing it, let alone opening it. While chatting with netizens, someone mentioned: EmEditor.&lt;/p&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;Website: [https://www.emeditor.com/]&lt;/p&gt;
&lt;p&gt;I tried it out during my free time on the weekend, and it&amp;rsquo;s quite convenient. The design supports editing large files, and with sufficient memory, the entire file is loaded into memory, making searching and editing fast. It also supports splitting files.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Add a code copy button for something that seems simple</title>
        <link>https://ttf248.life/en/p/add-code-copy-button/</link>
        <pubDate>Fri, 25 Feb 2022 01:23:39 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/add-code-copy-button/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;I spent four hours on it, and when I saw that sentence, I thought it was funny – how could it take so long? Then I looked at the time: three hours&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It&amp;rsquo;s considered the first draft of 2022. Nothing complicated to do, just exactly as the title says (I was still quite young then). I thought simply copying &lt;a class=&#34;link&#34; href=&#34;https://ouuan.github.io/post/from-hexo-to-hugo/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;the assignment&lt;/a&gt; would be enough, saved it in my bookmarks, and waited for over a month before finally remembering this thing.&lt;/p&gt;
&lt;p&gt;I always felt that Hugo had too few plugins when I migrated to it, and the inability to copy code made migrating notes from Evernote to my blog a cumbersome process. Copying code for those notes became tedious, seriously hindering my motivation to update my blog.&lt;/p&gt;
&lt;h2 id=&#34;prologue&#34;&gt;Prologue
&lt;/h2&gt;&lt;p&gt;Let&amp;rsquo;s take a close look at the original author&amp;rsquo;s draft, read it through and then check out their introduction. Wow, I’ve stumbled upon an expert – a full-time undergraduate student at Tsinghua who started working with computers very early on. Man, they&amp;rsquo;re really something. Let me check out this blog first; I completely forgot what I was supposed to do. Oh, and let&amp;rsquo;s also take a look at the author&amp;rsquo;s &lt;code&gt;Github&lt;/code&gt; repository. This modified &lt;code&gt;even&lt;/code&gt; theme is much better than the current one – it has so many new features. Let’s get it done. First, merge the relevant code over here.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/add-code-copy-button/2022-02-25-02-08-19.png&#34;
	width=&#34;215&#34;
	height=&#34;150&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;143&#34;
		data-flex-basis=&#34;344px&#34;
	
&gt; &lt;img src=&#34;https://ttf248.life/p/add-code-copy-button/2022-02-25-02-08-40.png&#34;
	width=&#34;217&#34;
	height=&#34;167&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;129&#34;
		data-flex-basis=&#34;311px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;new-feature-view-article-history-and-related-submission-records&#34;&gt;New feature: View article history and related submission records
&lt;/h3&gt;&lt;p&gt;The effect is still pretty good; you can experience it by scrolling to the end of the article&lt;/p&gt;
&lt;p&gt;I didn&amp;rsquo;t really look at the author’s repository history before starting, thinking a simple merge would be fine. In the end, I merged a bunch of code, with conflicts and numerous iterations. I blindly overwrote things, mostly frontend and rendering templates, prioritizing what I wanted.&lt;/p&gt;
&lt;p&gt;Repository address: &lt;a class=&#34;link&#34; href=&#34;https://github.com/TianlongXiang/hugo-theme-even&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/TianlongXiang/hugo-theme-even&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A pitfall with Chinese documentation is that if you don&amp;rsquo;t adjust this parameter, &lt;code&gt;git&lt;/code&gt; won&amp;rsquo;t be able to retrieve the current article&amp;rsquo;s &lt;code&gt;commit hash&lt;/code&gt;, leading to failed generation of historical links. You also need to modify the automated integration script when generating a complete history of articles; remember to pull all historical records from the current repository.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Attempting to pull the complete GitHub repository for dynamically updating the record of last modification time for articles&lt;/li&gt;
&lt;li&gt;Path exists in Chinese, Hugo GitInfo needs this setting enabled&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;name: Build Github
run: git config --global core.quotePath false &amp;amp;&amp;amp; hugo -b &amp;quot;https://www.xiangtianlong.com/&amp;quot; -d &amp;quot;github_public&amp;quot; &amp;amp;&amp;amp; ls
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;style-adjustments&#34;&gt;Style adjustments
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Adjust the site content width. The previous design was suitable for both mobile and desktop, but in reality, no one views it on their phone; I even view it on my computer myself.&lt;/li&gt;
&lt;li&gt;The directory bar supports auto-sizing&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;I spent over half an hour looking at &lt;code&gt;ouuan&lt;/code&gt;&amp;rsquo;s code, but I still don’t really understand how to add the copy button&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Time passes, and after a month, I thought of this again&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Since I didn&amp;rsquo;t understand this assignment, let’s just copy another one; I should be able to figure it out eventually. The search results were surprisingly good – there was even a post in the &lt;code&gt;hugo&lt;/code&gt; official forum mentioning how to add a copy button. After checking it out, the logic is clear. Then something unexpected happened: when I looked at the site, the code block style rendered by &lt;code&gt;even&lt;/code&gt; differed from the description in the documentation. This part is a bit complicated, so here’s a brief record.&lt;/p&gt;
&lt;p&gt;Because I barely understood front-end development, whenever I didn&amp;rsquo;t understand something, I would open the browser&amp;rsquo;s &amp;ldquo;Inspect Element,&amp;rdquo; analyze the code, and rely on the style information on the right. Slowly, I began to understand the logic. I didn’t understand JavaScript, so I added some logs in the console. There were many things I didn&amp;rsquo;t understand, but I calmed down, slowly sorted out and broke down the logic, and eventually found a way forward.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;There are multiple &lt;code&gt;pre&lt;/code&gt; nodes, referring here to a single code block. The theme renders line numbers, resulting in two copy buttons appearing.&lt;/li&gt;
&lt;li&gt;I want code highlighting in the theme, but I&amp;rsquo;m not familiar with how to set it up in this theme&lt;/li&gt;
&lt;li&gt;I looked at the documentation on the Hugo website, and I understand that there&amp;rsquo;s a markup setting to control code highlighting&lt;/li&gt;
&lt;li&gt;Adjusting the configuration file, it&amp;rsquo;s always been wrong, and the rendering doesn&amp;rsquo;t match expectations&lt;/li&gt;
&lt;li&gt;I found these settings for &lt;code&gt;pygmentsOptions&lt;/code&gt;, continued researching, adjusted the settings, and first removed the line numbers&lt;/li&gt;
&lt;li&gt;Configure custom CSS stylesheets and configure custom JS scripts&lt;/li&gt;
&lt;li&gt;Since we&amp;rsquo;ve gotten things to this point, it suddenly occurred to me that I saw a color scheme recently that was pretty good. Let’s change the button style: going with a Chinese-style celadon blue.&lt;/li&gt;
&lt;/ol&gt;
&lt;img class=&#34;special-img-class&#34; style=&#34;width:20%&#34; src=&#34;2022-02-25-02-01-22.png&#34; /&gt;
&lt;img class=&#34;special-img-class&#34; style=&#34;width:20%&#34; src=&#34;2022-02-25-02-01-33.png&#34; /&gt;
&lt;p&gt;I spent four hours on it, and when I saw that sentence, I thought it was funny – how could it take so long? Then I looked at the time: three hours&lt;/p&gt;
&lt;h2 id=&#34;reference-link&#34;&gt;Reference link
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://ouuan.github.io/post/from-hexo-to-hugo/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ouuan.github.io/post/from-hexo-to-hugo/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://gohugobrasil.netlify.app/content-management/syntax-highlighting/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://gohugobrasil.netlify.app/content-management/syntax-highlighting/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://gohugo.io/getting-started/configuration-markup#highlight&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://gohugo.io/getting-started/configuration-markup#highlight&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.dannyguo.com/blog/how-to-add-copy-to-clipboard-buttons-to-code-blocks-in-hugo/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.dannyguo.com/blog/how-to-add-copy-to-clipboard-buttons-to-code-blocks-in-hugo/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Chaos Engineering</title>
        <link>https://ttf248.life/en/p/chaos-engineering/</link>
        <pubDate>Wed, 28 Jul 2021 14:35:07 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/chaos-engineering/</guid>
        <description>&lt;p&gt;A method for disrupting systems, used for system stability testing&lt;/p&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;p&gt;The domestic internet industry always likes to come up with something new, sometimes you hear a term and most people wouldn&amp;rsquo;t know what it is&lt;/p&gt;
&lt;p&gt;After reading some articles, I still find this definition of chaos engineering in its early stages relatively easy to accept&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The early explorations of Chaos Engineering have actually existed within the industry all along, previously appearing as fault testing and disaster recovery drills. However, with the continuous development of microservice architectures and the increasing complexity of distributed systems, Chaos Engineering has begun to emerge and gain increasing attention. After Netflix formally proposed the concept of Chaos Engineering, related theories began to rapidly enrich. Netflix&amp;rsquo;s practices have also proven the immense significance of Chaos Engineering in the field of stability.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;reference-link&#34;&gt;Reference link
&lt;/h2&gt;&lt;p&gt;ByteDance&amp;rsquo;s Chaos Engineering Practices Summary&lt;/p&gt;</description>
        </item>
        <item>
        <title>Suspend pod in Kubernetes</title>
        <link>https://ttf248.life/en/p/kubernetes-pause-pod/</link>
        <pubDate>Mon, 12 Jul 2021 11:23:09 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/kubernetes-pause-pod/</guid>
        <description>&lt;p&gt;The Deployment controller implements a very important function in Kubernetes clusters: the horizontal scaling and shrinking of Pods. This capability is essential for platforms in the traditional cloud era.&lt;/p&gt;
&lt;p&gt;Encountered a business scenario where data in the database needs to be modified and Pod nodes need to be restarted after adjustment. However, while the Pod is running, table fields are constantly being modified. It&amp;rsquo;s necessary to temporarily pause the application’s updates to the table, adjust the data, and then restore the Pod.&lt;/p&gt;
&lt;p&gt;Are there other ways to achieve a similar effect as pausing, besides forcefully deleting Deployments?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubectl scale --replicas=0 deployment/&amp;lt;your-deployment&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before seeing the answer, many people probably wouldn&amp;rsquo;t have thought of it. After seeing the answer, they might smile and realize their thinking hasn’t moved on – still stuck in an era focused on directly manipulating processes, wanting to operate business processes directly.&lt;/p&gt;
&lt;h2 id=&#34;reference-link&#34;&gt;Reference link
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://stackoverflow.com/questions/54821044/how-to-stop-pause-a-pod-in-kubernetes&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;how to stop/pause a pod in kubernetes&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>Docker tales</title>
        <link>https://ttf248.life/en/p/docker-two-three-things/</link>
        <pubDate>Thu, 21 Jan 2021 09:26:07 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/docker-two-three-things/</guid>
        <description>&lt;p&gt;Having worked for many years, I&amp;rsquo;ve primarily encountered the &lt;code&gt;CentOS&lt;/code&gt; operating system. If you are a &lt;code&gt;Mac&lt;/code&gt; or &lt;code&gt;Ubuntu&lt;/code&gt; user, some of this content may not be applicable.&lt;/p&gt;
&lt;p&gt;The installation section can refer to the manual from Tsinghua University: [https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/]&lt;/p&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation
&lt;/h2&gt;&lt;p&gt;Due to an unknown and mysterious force, it is recommended to use the repository addresses provided by cloud vendors for Docker installations within China. Here, &lt;strong&gt;Alibaba Cloud&lt;/strong&gt; is recommended.&lt;/p&gt;
&lt;h3 id=&#34;set-warehouse-source-address&#34;&gt;Set warehouse source address
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum install yum-utils device-mapper-persistent-data lvm2 &amp;amp;&amp;amp; \
sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;deploy-the-latest-version&#34;&gt;Deploy the latest version
&lt;/h3&gt;&lt;p&gt;As a commonly used background service, Docker is recommended to be set as a startup item; the current command applies to CentOS 7&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo yum install -y docker-ce docker-ce-cli containerd.io &amp;amp;&amp;amp; systemctl enable --now docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;deploy-specified-version&#34;&gt;Deploy specified version
&lt;/h3&gt;&lt;p&gt;The release of &lt;code&gt;kubernetes&lt;/code&gt; and &lt;code&gt;docker&lt;/code&gt; are not fully synchronized. If you need to deploy &lt;code&gt;kubernetes&lt;/code&gt; next, please refer to the &lt;code&gt;kubernetes&lt;/code&gt; deployment instructions and install the specified version of &lt;code&gt;docker&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum list docker-ce --showduplicates | sort -r
sudo yum install -y docker-ce-18.09.2-3.el7 docker-ce-cli-18.09.2-3.el7 containerd.io-18.09.2-3.el7 &amp;amp;&amp;amp; systemctl enable --now docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;adding-docker-permissions-for-regular-users&#34;&gt;Adding Docker permissions for regular users
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo usermod -aG docker ${USER}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;uninstall&#34;&gt;Uninstall
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo yum erase -y docker-ce docker-ce-cli containerd.io
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;everyday-use&#34;&gt;Everyday use
&lt;/h2&gt;&lt;h3 id=&#34;mirror-acceleration&#34;&gt;Mirror acceleration
&lt;/h3&gt;&lt;p&gt;There are still unknown mysterious forces causing slow image pulls. At this time, domestic cloud vendors have stepped up and provided many acceleration services. I still recommend &lt;strong&gt;Alibaba Cloud&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;To obtain the accelerated address, please register for an Alibaba Cloud account yourself. This service is free, and Alibaba Cloud also provides a free image building service.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cat &amp;gt; /etc/docker/daemon.json &amp;lt;&amp;lt;EOF
{
  &amp;quot;registry-mirrors&amp;quot;: [
    &amp;quot;https://docker.nju.edu.cn&amp;quot;,
    &amp;quot;https://mirror.baidubce.com&amp;quot;,
    &amp;quot;https://docker.m.daocloud.io&amp;quot;,
    &amp;quot;https://docker.mirrors.sjtug.sjtu.edu.cn&amp;quot;
  ]
}
EOF
systemctl daemon-reload &amp;amp;&amp;amp; \
systemctl restart docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;highly-recommended-control-panel&#34;&gt;Highly recommended control panel
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker volume create portainer_data &amp;amp;&amp;amp; \
docker run -d --name=portainer --restart=always -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:2.20.3-alpine
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;commonly-used-image-pull-collection&#34;&gt;Commonly Used Image Pull Collection
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker pull rancher/rancher:stable &amp;amp;&amp;amp; docker pull  portainer/portainer-ce:2.0.1 &amp;amp;&amp;amp; \
docker pull centos:7 &amp;amp;&amp;amp; docker pull ubuntu:20.04 &amp;amp;&amp;amp; docker pull ubuntu:18.04 &amp;amp;&amp;amp; \
docker pull redis:5 &amp;amp;&amp;amp; docker pull redis:6 &amp;amp;&amp;amp; \
docker pull alpine:3.11 &amp;amp;&amp;amp; docker pull busybox:1.32 &amp;amp;&amp;amp; \
docker pull rabbitmq:3.7-management &amp;amp;&amp;amp; \
docker pull mariadb:10.2 &amp;amp;&amp;amp; \
docker pull nginx:1.18 &amp;amp;&amp;amp; docker pull nginx:1.19 &amp;amp;&amp;amp; \
docker pull mysql:5.6 &amp;amp;&amp;amp; docker pull mysql:8 &amp;amp;&amp;amp; \
docker pull elasticsearch:6.8.11 &amp;amp;&amp;amp; docker pull logstash:6.8.11 &amp;amp;&amp;amp; docker pull kibana:6.8.11 &amp;amp;&amp;amp; \
docker pull zookeeper:3.4 &amp;amp;&amp;amp; \
docker pull influxdb:1.7 &amp;amp;&amp;amp; docker pull grafana/grafana:7.3.1 &amp;amp;&amp;amp; \
docker pull percona:8 &amp;amp;&amp;amp; docker pull percona:5.6 &amp;amp;&amp;amp; \
docker pull cloverzrg/frps-docker:0.34.3 &amp;amp;&amp;amp; docker pull cloverzrg/frpc-docker:0.34.3
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;commonly-used-command-combinations&#34;&gt;Commonly Used Command Combinations
&lt;/h3&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.docker.com/engine/reference/commandline/docker/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://docs.docker.com/engine/reference/commandline/docker/&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Check the container running status, add the &lt;code&gt;format&lt;/code&gt; parameter to view detailed container information; ignore image information at this time&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker ps --format &amp;quot;{{.Names}}: {{.Ports}}: {{.Size}}&amp;quot;
#portainer: 0.0.0.0:8000-&amp;gt;8000/tcp, 0.0.0.0:9000-&amp;gt;9000/tcp: 0B (virtual 172MB)
#influxdb: 0.0.0.0:8086-&amp;gt;8086/tcp: 183B (virtual 311MB)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;Stop all containers with one click&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker stop $(docker ps -a -q)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Delete all images with one click&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;dokcer rmi $(docker images -a -q)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;Export image&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker save &amp;lt;IMAGE NAME&amp;gt;:&amp;lt;IMAGE TAG&amp;gt; &amp;gt; -o XXX.tar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Export image and compress&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker save &amp;lt;IMAGE NAME&amp;gt;:&amp;lt;IMAGE TAG&amp;gt; | gzip &amp;gt; XXX.tar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Import image&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker load -i XXX.tar
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        <item>
        <title>Setting up a JMeter testing environment on Linux</title>
        <link>https://ttf248.life/en/p/linux-setup-jmeter-testing-environment/</link>
        <pubDate>Tue, 22 Dec 2020 10:12:50 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/linux-setup-jmeter-testing-environment/</guid>
        <description>&lt;p&gt;The author has a strong interest in hardware and used JMeter to conduct stress testing, documenting the process of deploying JMeter, InfluxDB, and Grafana on CentOS 7. They shared information on JMeter installation and command usage, InfluxDB features and Docker installation methods, as well as simple deployment and configuration of Grafana. The document summarizes experiences and references for high-performance programming patterns.&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background
&lt;/h2&gt;&lt;p&gt;As you all know, I have a strong interest in hardware. By chance, the testing team was using JMeter for performance testing and found that the performance wasn&amp;rsquo;t improving. As a curious person, I decided to jump in and see how our company does pressure testing. There’s also a little story here: at some point in the distant past, I saw a post on Open Source China about how to create high-end performance test charts. The testers have already seen the Windows version execute tests and achieve visualized TPS data display. What use would there be for configuring another web panel?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Whatever you think is right, you won&amp;rsquo;t understand until you try it yourself
Don&amp;rsquo;t use GUI mode for load testing! only for Test creation and Test debuggin.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The official recommendation is to obtain the load test report through the command line and display it with a GUI, which may introduce data errors? I don&amp;rsquo;t have a very deep understanding of JMeter, but at least it gives me a reason to tinker with the &lt;code&gt;Linux&lt;/code&gt; console panel&lt;/p&gt;
&lt;p&gt;The posts on Open Source China indicate that the deployment method for the core components is not user-friendly, and you need to follow a public account to download the required files. As a young generation, of course, I replaced it with &lt;code&gt;Docker&lt;/code&gt;. To put it simply, the servers are still located within mainland China, so accessing cross-border sources is very slow. At least for image services, Alibaba Cloud has a free accelerator.&lt;/p&gt;
&lt;p&gt;Regarding the installation and deployment of &lt;code&gt;docker&lt;/code&gt;, details will not be repeated here; please refer to previous articles for more information&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;The following content is divided into two main parts: building the basic test environment components and a simple explanation of each component&lt;/p&gt;
&lt;h2 id=&#34;jmeter&#34;&gt;Jmeter
&lt;/h2&gt;&lt;p&gt;Apache JMeter is a load testing tool developed by the Apache organization based on Java. It is used for stress testing software and was originally designed for web application testing, but has since been extended to other testing areas. It can be used to test static and dynamic resources such as static files, small Java services, CGI scripts, Java objects, databases, FTP servers, etc. JMeter can simulate a huge load on servers, networks or objects to test their strength under different stress categories and analyze overall performance. In addition, JMeter can perform functional/regression testing of applications by creating scripts with assertions to verify that your program returns the expected results. For maximum flexibility, JMeter allows the use of regular expressions to create assertions.&lt;/p&gt;
&lt;p&gt;Apache JMeter can be used to test the performance of static and dynamic resources (files, Servlets, Perl scripts, Java objects, databases and queries, FTP servers, etc.). It can be used to simulate heavy loads on servers, networks or objects to test their strength or analyze overall performance under different types of stress. You can use it for graphical analysis of performance or for load testing your servers/scripts/objects with high concurrency.&lt;/p&gt;
&lt;h3 id=&#34;jmeter-deployment-on-centos-7&#34;&gt;JMeter deployment on CentOS 7
&lt;/h3&gt;&lt;p&gt;Install the &lt;code&gt;JDK&lt;/code&gt; runtime environment, download the &lt;code&gt;JMeter&lt;/code&gt; installation package&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum install java-1.8.0-openjdk -y &amp;amp;&amp;amp; \
wget https://mirrors.bfsu.edu.cn/apache//jmeter/binaries/apache-jmeter-5.4.tgz &amp;amp;&amp;amp; tar -xf apache-jmeter-5.4.tgz
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Configure environment variables&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export JMETER_HOME=$HOME/jmeter/apache-jmeter-5.4
export PATH=$JMETER_HOME/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;jmeter-commands&#34;&gt;JMeter commands
&lt;/h3&gt;&lt;p&gt;Finally, it will connect to the &lt;code&gt;Grafana&lt;/code&gt; control panel. You can omit the &lt;code&gt;-l&lt;/code&gt; parameter and observe the data in the &lt;code&gt;web&lt;/code&gt; console.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;jmeter -n -t /tmp/order-500-10s.jmx -l /tmp/jmeter-order-report-20200109/order-500-10s.jtl
# 一般不用测试结果和测试报告，简化命令
jmeter -n -t /tmp/order-500-10s.jmx
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;influxdb&#34;&gt;InfluxDB
&lt;/h2&gt;&lt;p&gt;InfluxDB is an open-source distributed time series, event and metrics database written in Go, requiring no external dependencies. This database is now primarily used to store large volumes of timestamped data, such as DevOps monitoring data, APP metrics, IoT sensor data, and real-time analytics data.&lt;/p&gt;
&lt;h3 id=&#34;influxdb-features&#34;&gt;InfluxDB Features
&lt;/h3&gt;&lt;p&gt;The characteristics of InfluxDB can be summarized into 9 aspects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Unstructured (patternless): can be any number of columns;&lt;/li&gt;
&lt;li&gt;The retention period for metrics can be configured&lt;/li&gt;
&lt;li&gt;Supports time-related functions (such as min, max, sum, count, mean, median, etc.) for statistical analysis&lt;/li&gt;
&lt;li&gt;Support for storage policies: can be used for data deletion and modification. (InfluxDB does not provide methods for deleting or modifying data.)&lt;/li&gt;
&lt;li&gt;Supporting continuous queries: a set of statements that are automatically started on a schedule in the database, and when paired with storage policies, can reduce InfluxDB&amp;rsquo;s system footprint&lt;/li&gt;
&lt;li&gt;Native HTTP support, built-in HTTP API&lt;/li&gt;
&lt;li&gt;Supports SQL-like syntax&lt;/li&gt;
&lt;li&gt;Supports setting the number of data replicas in the cluster&lt;/li&gt;
&lt;li&gt;Support periodic sampling data and write it to another measurement for granular storage of data&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;influxdb-docker-installation&#34;&gt;InfluxDB Docker installation
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mkdir influxdb &amp;amp;&amp;amp; cd influxdb &amp;amp;&amp;amp; \
docker run -p 8086:8086 -d --name influxdb -v $PWD:/var/lib/influxdb influxdb:1.7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Enter the container, execute a command, and manually create a database&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;root@bce0a55bbc72:/# influx
Connected to http://localhost:8086 version 1.7.10
InfluxDB shell version: 1.7.10
&amp;gt; 交互面板执行命令
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;creating-databases-and-users-in-influxdb&#34;&gt;Creating Databases and Users in InfluxDB
&lt;/h3&gt;&lt;p&gt;Create database: create database jmeter_t2
View databases
Switch database: use jmeter_t2
Create user &amp;ldquo;admin&amp;rdquo; with password &amp;lsquo;admin&amp;rsquo; with all privileges
View users&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;&amp;gt; show users
user  admin
----  -----
admin true
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the user permission &lt;code&gt;admin&lt;/code&gt; is displayed as &lt;code&gt;true&lt;/code&gt;, the database preparation is complete&lt;/p&gt;
&lt;h2 id=&#34;grafana&#34;&gt;Grafana
&lt;/h2&gt;&lt;p&gt;When writing test cases, I realized that the chart display isn&amp;rsquo;t really necessary. The &lt;code&gt;tps&lt;/code&gt; data for the interface can already be observed when executed in the command line; mostly, I just want to know the internal execution time of the program.&lt;/p&gt;
&lt;p&gt;Quickly deploy a Grafana dashboard, import configuration files, and connect to InfluxDB&lt;/p&gt;
&lt;p&gt;The console supports filtering test results by tag, and generally only an &lt;code&gt;InfluxDB&lt;/code&gt; database needs to be configured&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Application Name&lt;/li&gt;
&lt;li&gt;Test Case Name&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/linux-setup-jmeter-testing-environment/Snipaste_2021-03-09_19-44-22.png&#34;
	width=&#34;861&#34;
	height=&#34;357&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;grafana&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;241&#34;
		data-flex-basis=&#34;578px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -d --name=grafana -p 3000:3000 grafana/grafana:7.3.1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;TPS&lt;/code&gt; and related values calculated in the web version can be inconsistent with the aggregated report in &lt;code&gt;JMeter&lt;/code&gt; due to the sampler interval, see reference link: &lt;a class=&#34;link&#34; href=&#34;https://www.vinsguru.com/jmeter-real-time-results-influxdb-grafana/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.vinsguru.com/jmeter-real-time-results-influxdb-grafana/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The document also describes how to customize listeners&lt;/p&gt;
&lt;h2 id=&#34;afterword&#34;&gt;Afterword
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;High-performance programming inherently relies on a single loop thread; any locks, queuing for entry, and queuing for exit will cause unnecessary performance loss&lt;/li&gt;
&lt;li&gt;The time spent on core business logic is greater than the time spent introducing other code; concurrency can effectively improve efficiency, and if the core processing time is sufficiently small, it&amp;rsquo;s best to be cautious when introducing other code&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;reference-materials&#34;&gt;Reference materials
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Real-time Monitoring with JMeter + Grafana + InfluxDB&lt;/li&gt;
&lt;li&gt;InfluxDB official image&lt;/li&gt;
&lt;li&gt;Grafana official image&lt;/li&gt;
&lt;li&gt;Apache JMeter Official Website&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/@jasonli.studio/to-install-apache-jmeter-in-centos7-294bc72a97ba&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;To install Apache JMeter in CentOS7&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Red Hat and CentOS lifecycles</title>
        <link>https://ttf248.life/en/p/redhat-centos-lifecycle/</link>
        <pubDate>Tue, 21 Jul 2020 20:02:35 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/redhat-centos-lifecycle/</guid>
        <description>&lt;p&gt;Online production environments typically use Red Hat and CentOS as their operating systems. Links to the official websites documenting the lifecycles of these two systems are provided, along with shared experiences upgrading from CentOS 8 to CentOS 8 Stream.&lt;/p&gt;
&lt;h2 id=&#34;preface&#34;&gt;Preface
&lt;/h2&gt;&lt;p&gt;In online production environments, Red Hat and CentOS are currently the mainstream choices in China. Following the retirement of Red Hat 6 in recent years, here are links to the official websites for the lifecycles of these two systems.&lt;/p&gt;
&lt;h2 id=&#34;main-body&#34;&gt;Main body
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://access.redhat.com/support/policy/updates/errata&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Red Hat Enterprise Linux Life Cycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;CentOS Product Specification&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Red Hat Enterprise Linux (RHEL) and CentOS are popular choices for enterprise-grade server operating systems. RHEL offers a stable support and update cycle, suitable for enterprise applications. CentOS, as the community version of RHEL, provides similar functionality and stability but lacks official support.&lt;/p&gt;
&lt;h2 id=&#34;chase-for-more&#34;&gt;Chase for more
&lt;/h2&gt;&lt;p&gt;When I published this article, I never thought I would update it two years later. Just the other day, I upgraded my daily-use virtual machine from CentOS 8 to CentOS 8 Stream. I won&amp;rsquo;t say much about how to choose for production environments, but I still prefer the latest versions for local environments.&lt;/p&gt;
&lt;p&gt;CentOS 8 Stream is a rolling release version that offers faster updates and new features compared to traditional CentOS, making it suitable for development and testing environments&lt;/p&gt;</description>
        </item>
        <item>
        <title>Building computers</title>
        <link>https://ttf248.life/en/p/computer-assembly-tips/</link>
        <pubDate>Sat, 18 Jul 2020 14:33:46 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/computer-assembly-tips/</guid>
        <description>&lt;p&gt;The author was fascinated by assembling computers from a young age and began learning about hardware assembly after starting university. They recommended websites for comparing hardware performance and provided purchasing suggestions, including CPU, solid-state drives, mechanical hard drives, and memory frequency. They also shared their experience and precautions regarding hardware selection.&lt;/p&gt;
&lt;h3 id=&#34;destiny-beyond-words&#34;&gt;Destiny, beyond words
&lt;/h3&gt;&lt;p&gt;Ever since I was little, I wanted to build my own computer, but the economic conditions just wouldn&amp;rsquo;t allow it. It wasn’t until college that I finally had the chance, and for portability reasons, I got a laptop. If you want a specific time frame, when did I start wanting to build a computer? It all started at the library back home. It was a pretty decent-sized library for a city district – it had an electronic reading room (though I never went, as it charged by the hour) and a magazine reading room. That’s where I stumbled upon magazines like “大众软件” (Popular Software) and “电脑报” (Computer News). For someone with limited exposure to computers, they were essentially divine educational resources. Seeing chapters about raiding dungeons made me want to build my own computer so I could pull mobs and be a main damage dealer; seeing the &amp;ldquo;black technology&amp;rdquo; sparked fantasies of recreating what was described in the books (a discussion on using hacking tools). Though high school coursework was demanding, with my limited knowledge at the time, I felt I needed to both study and play. It was a pretty carefree time. I’d often use going to the library as an excuse, grabbing a small bag and strolling over there. The city wasn&amp;rsquo;t that big, so I usually walked. Once inside, I’d enjoy the air conditioning while reading novels, comics, and gaming magazines, occasionally glancing at some serious books.&lt;/p&gt;
&lt;p&gt;As you get older, it&amp;rsquo;s easy to forget things. This isn&amp;rsquo;t the first time something like this has happened at the library. When I was in junior high school, my relatives assembled a computer, and I don’t remember why they built that machine back then. The operating system was Windows 2003, and the games included the card game and Age of Empires. I spent all sorts of time trying to sneak the keys and play games with my cousin.&lt;/p&gt;
&lt;p&gt;Entering junior high, the school offered basic computer training. Later, when I transferred schools, I was also introduced to the concept of computer competitions. By the time I reached high school, I participated in NOIP once. Speaking of this, it&amp;rsquo;s impossible not to mention the power of alumni – the high school’s computer building was funded by alumni donations and included a computer lab and library. It was actually during the initial wave of China&amp;rsquo;s internet boom at that time. School leaders also supported participation in computer competitions; after all, several seniors from the previous two years had been admitted to key universities through computer-related programs.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I&amp;rsquo;ve never looked back at my relationship with computers like this before. No wonder I made such a complete shift from the automation major to the computer industry after graduation – the seeds were already sown, though those involved didn’t realize it. Having been exposed to them since childhood, I thought I was quite knowledgeable, but in reality, I only understood the basics. My biggest advantage was that initial passion.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;hardware-assembly&#34;&gt;Hardware assembly
&lt;/h3&gt;&lt;p&gt;Browse Carrefour, Chiphell, and Zhihu&amp;rsquo;s computer building sections; a beginner can relatively easily create a list of the machine they need. When purchasing a CPU after 2019, if your financial situation isn’t abundant, AMD is the best choice for higher performance.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a translation of the provided Chinese text: I recommend a commonly used hardware performance comparison website: &lt;a class=&#34;link&#34; href=&#34;https://cpu.userbenchmark.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://cpu.userbenchmark.com/&lt;/a&gt;, which is comparable to Xianyu (闲鱼) for pricing. True experts can find great deals on used items on Xianyu, saving a lot of money. If you&amp;rsquo;re not very knowledgeable, I don’t recommend using it; I bought fake memory there myself. Although it seems to be working fine so far, I’m not entirely sure, and the model and parameters are completely mismatched.&lt;/p&gt;
&lt;h4 id=&#34;sn550-vs-sn750&#34;&gt;SN550 VS SN750
&lt;/h4&gt;&lt;p&gt;The difference between the SN550 1TB and the SN750 1TB is that their sustained read/write speeds differ by a factor of two – one reaches 850MB, the other 1.6GB. However, there&amp;rsquo;s no noticeable difference in daily use because both have the same 4K performance. Of course, this refers to the 1TB capacity SN550; the 500GB and 250GB versions have slower sequential read/write speeds. Honestly, unless you’re not worried about cost, the SN550 is fine for everyday use. The main reason I didn&amp;rsquo;t buy it isn&amp;rsquo;t its sequential read/write speed, but rather that it only comes in a maximum of 1TB capacity, while the SN750 offers 2TB. For me, the value lies more in having an extra M.2 NVMe slot on my motherboard than in the price difference between these SSDs, without needing to expand further.&lt;/p&gt;
&lt;p&gt;Based on the consensus of online users, purchasing an adapter board will allow a B150 motherboard to support an M.2 SSD&lt;/p&gt;
&lt;h4 id=&#34;choosing-a-mechanical-hard-drive&#34;&gt;Choosing a Mechanical Hard Drive
&lt;/h4&gt;&lt;p&gt;Currently, mechanical hard drives are priced stably. For users with large storage needs, it is recommended to select a suitable mechanical hard drive. Frequent downloaders are advised to consider enterprise-grade hard drives, such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Western Digital Gold&lt;/li&gt;
&lt;li&gt;Seagate Exos&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It&amp;rsquo;s recommended to partition large-capacity mechanical hard drives. Frequent download operations should be directed to a specific partition. If bad sectors appear later, they can be concentrated in one partition, and that partition can then be discarded, effectively extending the lifespan of the mechanical hard drive.&lt;/p&gt;
&lt;p&gt;Seagate &lt;a class=&#34;link&#34; href=&#34;https://www.seagate.com/cn/zh/enterprise-storage/exos-drives/exos-e-drives/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Official Introduction&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Overview of Seagate Enterprise Hard Drives&lt;/p&gt;
&lt;p&gt;Overview of Seagate Enterprise Hard Drives&lt;/p&gt;
&lt;h4 id=&#34;memory-frequency&#34;&gt;Memory frequency
&lt;/h4&gt;&lt;p&gt;Starting from the perspective of daily work, frequency will not have a significant impact on performance&lt;/p&gt;
&lt;p&gt;Memory Timing Memory (Salted Fish Memory)&lt;/p&gt;
&lt;p&gt;Memory timings (or RAM timings) are four parameters describing the performance of synchronous dynamic random-access memory (SDRAM): CL, TRCD, TRP, and TRAS, measured in clock cycles. They are typically written as four numbers separated by hyphens, such as 7-8-8-24. The fourth parameter (RAS) is often omitted, and a fifth parameter may be added: Command rate, usually 2T or 1T, also written as 2N or 1N. These parameters specify latency times that affect random access memory speed. Lower numbers generally indicate faster performance. The ultimate element determining system performance is the actual latency time, typically measured in nanoseconds.&lt;/p&gt;
&lt;p&gt;When converting memory timings to actual delays, it&amp;rsquo;s most important to note that they are measured in clock cycles. Without knowing the duration of a clock cycle, it’s impossible to determine if one set of numbers is faster than another.&lt;/p&gt;
&lt;p&gt;For example, the clock frequency of DDR3-2000 memory is 1000 MHz, and its clock cycle is 1 ns. Based on this 1 ns clock, a CL=7 results in an absolute latency of 7 ns. Faster DDR3-2666 (clocking at 1333 MHz with a 0.75 ns cycle) may use a larger CL=9, but still produce a shorter absolute latency of 6.75 ns.&lt;/p&gt;
&lt;p&gt;Modern DIMMs include a serial presence detect (SPD) ROM chip, which contains memory timings recommended for automatic configuration. The PC&amp;rsquo;s BIOS may allow users to adjust these timings to improve performance (with the risk of reducing stability), or in some cases increase stability (such as using the recommended timings).&lt;/p&gt;
&lt;p&gt;Note: Memory bandwidth measures memory throughput and is typically limited by transfer rate rather than latency. It is possible to continuously transmit at peak rates by interleaving access to multiple internal banks of SDRAM. Bandwidth can be increased at the expense of increased latency. Specifically, each new generation of DDR memory has a higher transfer rate, but absolute latency does not change significantly, especially for the first batch of products in a new generation, which often have longer latencies than the previous generation.&lt;/p&gt;
&lt;p&gt;Even with increased memory latency, increasing memory bandwidth can improve the performance of computer systems with multiple processors or multiple execution threads. Higher bandwidth will also enhance the performance of integrated graphics cards without dedicated video memory.&lt;/p&gt;
&lt;p&gt;Memory Timing Parameter Explanation&lt;/p&gt;
&lt;h3 id=&#34;reference-materials&#34;&gt;Reference materials
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Memory timing parameters&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Website acceleration and domain settings</title>
        <link>https://ttf248.life/en/p/website-acceleration-and-domain-setup/</link>
        <pubDate>Sat, 20 Jun 2020 10:36:27 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/website-acceleration-and-domain-setup/</guid>
        <description>&lt;p&gt;Due to slow access to GitHub Pages within China, the author applied for a personal domain name and purchased CDN acceleration services from a domestic cloud hosting provider. During the configuration process, the author encountered an issue where the www subdomain was inaccessible. The problem was eventually resolved by deleting the wildcard domain resolution and setting up the second-level domain separately. The author also shared the principles and configuration experience of CDN acceleration, as well as the attempts and lessons learned from using Nginx reverse proxy.&lt;/p&gt;
&lt;h3 id=&#34;background&#34;&gt;Background
&lt;/h3&gt;&lt;p&gt;The website is hosted on GitHub Pages, and due to some well-known reasons, accessing GitHub Pages from within China can be slow. Therefore, I applied for a personal domain name and purchased CDN acceleration services from a domestic cloud hosting provider. When setting up the acceleration service, I remembered that I had a development machine with Docker, frp, k8s, and other services deployed, all of which have corresponding dashboards. Following the principle of not wasting resources, I configured several reverse proxies and linked them to subdomains.&lt;/p&gt;
&lt;p&gt;When I was happily using my second-level domain, I suddenly found that the www subdomain was inaccessible. In Alibaba Cloud, DNS was configured to resolve simultaneously to both &lt;a class=&#34;link&#34; href=&#34;https://www.xiangtianlong.com&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;www.xiangtianlong.com&lt;/a&gt; and xiangtianlong.com. When CDN acceleration had not been enabled yet, both domains worked normally.&lt;/p&gt;
&lt;p&gt;When configuring CDN acceleration, due to having too many subdomains, a wildcard domain rule was enabled, routing everything to the development machine. This resulted in the www subdomain also going down. Yes, you read that right, www is a subdomain. The actual website is deployed on GitHub Pages, and the development machine has no cached web content.&lt;/p&gt;
&lt;p&gt;Regarding why the site wasn&amp;rsquo;t deployed on the development machine, it’s because it’s a static blog and paired with GitHub Actions, which automatically integrates and publishes – it’s really great&lt;/p&gt;
&lt;h3 id=&#34;domain-name&#34;&gt;Domain name
&lt;/h3&gt;&lt;p&gt;Non-professional web development doesn&amp;rsquo;t involve SEO or cross-domain issues when it comes to understanding domain names. For a blog site, using a bare domain can highlight the blogger’s site—this refers to people like me who use Chinese pinyin as their domain name—and with most access now being mobile, it allows for fewer characters to be entered.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The desktop version allows you to skip typing www and com using keyboard shortcuts&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;cdn&#34;&gt;CDN
&lt;/h3&gt;&lt;p&gt;I&amp;rsquo;ve used both Aliyun and Tencent Cloud, it’s not difficult for new users to get started. Tencent Cloud even has a video explaining the related concepts. The principle of CDN acceleration is the same as that of JD&amp;rsquo;s warehouse: when launching new products, they are pre-distributed to warehouses across the country, and when a delivery request is triggered, they are distributed from the nearest location.&lt;/p&gt;
&lt;p&gt;Return address: The original address where website resources were stored&lt;/p&gt;
&lt;p&gt;Cache file settings, browser F12, management console, simple analysis of static and dynamic resources&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;All 0 days validity&lt;/li&gt;
&lt;li&gt;0-day validity for .php, .jsp, .asp, .aspx&lt;/li&gt;
&lt;li&gt;.jpg, .png, .js, .css, .woff2 1-day validity&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Tencent Cloud Configuration Rules:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cache expiration rules can be configured up to 10 entries&lt;/li&gt;
&lt;li&gt;The priority among multiple cache expiration rules is bottom-up&lt;/li&gt;
&lt;li&gt;The cache expiration time can be set up to a maximum of 365 days&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;a-lamentable-confession&#34;&gt;A Lamentable Confession
&lt;/h3&gt;&lt;p&gt;I hadn&amp;rsquo;t used Nginx before, and I thought I could understand the configuration of reverse proxy by simply searching online. But it was a bit confusing, and after fiddling with it for half a day, I couldn&amp;rsquo;t even figure out a 302 redirect. It was useless. So I decided to try a simple approach: deleting the wildcard domain resolution mode and setting up each second-level domain independently. That’s when I suddenly noticed that Alibaba Cloud DNS had a feature called &amp;ldquo;Display URL Jump,&amp;rdquo; and after trying it, it turned out to be exactly what I wanted – a 302 redirect.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I got the first secondary domain working fine, but when I tried to set up the second one, it didn&amp;rsquo;t work. I was almost starting to doubt myself. Then suddenly it started working after a while. It seems like Aliyun’s DNS propagation occasionally glitches out.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;reference-materials&#34;&gt;Reference materials
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Why are more and more website domains not adding the &amp;ldquo;www&amp;rdquo; prefix?&lt;/li&gt;
&lt;li&gt;What is the difference between a domain with www and one without www?&lt;/li&gt;
&lt;li&gt;Docker nginx Reverse Proxy Setup&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Blog IDE environment and random thoughts</title>
        <link>https://ttf248.life/en/p/blog-ide-environment-and-ramblings/</link>
        <pubDate>Tue, 31 Mar 2020 13:54:27 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/blog-ide-environment-and-ramblings/</guid>
        <description>&lt;p&gt;This article introduces the basic concepts of Markdown and its applications in various software. It recommends using VSCode as an IDE and lists recommended plugins. The author shares their experience switching from Hexo to Hugo, emphasizing Hugo&amp;rsquo;s flexibility and customization capabilities. Finally, it provides some tips for quickly getting started with new technologies and shares a trick for resolving the issue of Hugo theme styles not updating.&lt;/p&gt;
&lt;h2 id=&#34;preface&#34;&gt;Preface
&lt;/h2&gt;&lt;h3 id=&#34;markdown&#34;&gt;Markdown
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;A lightweight markup language that allows people to write documents in a readable and writable plain text format&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Detailed Markdown syntax will not be elaborated on in this article; a recommended ebook is available, &lt;a class=&#34;link&#34; href=&#34;https://markdown-zh.readthedocs.io/en/latest/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;click here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Many software on the market already support md as a writing format. The CSDN blog system launched an online editor that supports md syntax, and it comes with an introductory article about md syntax when you use it for the first time, which I think is pretty good; Evernote added support for md notes in 2018, with various md tag options in the quick bar, making it feel similar to editing regular articles, and the overall interactive process is friendly to beginners.&lt;/p&gt;
&lt;h3 id=&#34;ide-recommendations&#34;&gt;IDE recommendations
&lt;/h3&gt;&lt;p&gt;When writing this article, it&amp;rsquo;s already 2020. You must have heard of VS Code, after all, anyone who considers using Git Page to build a blog system is an industry professional. In earlier years, Sublime and Atom were also good choices. With two years of community support, VS Code has developed rapidly and gradually become the preferred entry point for beginners.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The relationship between Microsoft and the open-source community has transitioned from a state of separation to a honeymoon period: embracing open source. The company I work for has also actively introduced the Java ecosystem in recent years; in other words, the Java ecosystem is genuinely appealing for business development within China now.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;vs-code-extension-recommendations&#34;&gt;VS Code extension recommendations
&lt;/h3&gt;&lt;p&gt;Plugin List&lt;/p&gt;
&lt;p&gt;Plugins all have their own Readme files, introducing basic usage and core features; some plugin authors also provide dynamic effect demonstration images&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s very convenient to introduce images using the image plugin method of Hugo&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I haven&amp;rsquo;t memorized the shortcuts, so I opened the VS Code shortcut management menu and searched for &amp;ldquo;md,&amp;rdquo; looking at it several times; I reviewed the plugin usage instructions again&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;hugo&#34;&gt;hugo
&lt;/h2&gt;&lt;p&gt;As a writer, I&amp;rsquo;ve switched from &lt;code&gt;Hexo&lt;/code&gt; to &lt;code&gt;Hugo&lt;/code&gt;. My nature is to tinker and I simply couldn’t stand writing articles quietly without constantly experimenting.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Hugo supports placing images and md documents in separate folders&lt;/li&gt;
&lt;li&gt;Academic themes support various types of article styles in design&lt;/li&gt;
&lt;li&gt;Various convenient custom extensions&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;academic&#34;&gt;academic
&lt;/h2&gt;&lt;p&gt;The website defaults to &lt;code&gt;exampleSite&lt;/code&gt;, menu integration uses the &lt;code&gt;#component&lt;/code&gt; method, and using &lt;code&gt;url&lt;/code&gt; is recommended&lt;/p&gt;
&lt;p&gt;The URL pattern allows for single-page jumps when clicking on navigation, rather than scrolling on the homepage—this is purely a matter of personal preference&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Styles: Essays, Speeches, E-books&lt;/li&gt;
&lt;li&gt;Flexibility: Customize overall style, customize CSS styles&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This theme&amp;rsquo;s support for Chinese is not yet very complete, mainly from a visual perspective – the font size isn&amp;rsquo;t quite in line with Chinese reading habits. However, Hexo’s developers are mostly Chinese, which gives it an advantage over Hugo in this regard.&lt;/p&gt;
&lt;p&gt;However, it&amp;rsquo;s about doing things yourself and providing for your own needs. Inspect the browser elements. Once you’ve located the element, to know the CSS style name that needs modification, click &lt;strong&gt;Insert Style Rule Below&lt;/strong&gt; in the sidebar. Even with deeply nested CSS, you can easily get the node name.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Introducing &lt;strong&gt;custom.css&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Introducing &lt;strong&gt;custom_js&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;The theme&amp;rsquo;s built-in syntax highlighting settings, &lt;a class=&#34;link&#34; href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/#highlighting-options.&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;official link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h2&gt;&lt;p&gt;The little one is about to complain again – why are you being so vague from beginning to end, not mentioning any details?&lt;/p&gt;
&lt;p&gt;What I want to say is, these things will be enough for you&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Official manual&lt;/li&gt;
&lt;li&gt;Plugin Description&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To quickly get started with new technologies, it&amp;rsquo;s recommended to first read the official documentation. Don’t worry about understanding everything on the first pass; at least get a general idea. Search engine results may not always be consistent with the latest version and could potentially mislead you. The same applies to reading new books – look at the table of contents first to understand what the author intends to cover. Sometimes, reading the preface is helpful; in some foreign works translated into Chinese, the translator&amp;rsquo;s preface often summarizes the book’s content and core ideas.&lt;/p&gt;
&lt;h2 id=&#34;easter-egg&#34;&gt;Easter egg
&lt;/h2&gt;&lt;p&gt;Switching to the built-in Hugo Academic style didn&amp;rsquo;t change the appearance when published to the site. Clever users probably already figured it out: clear your local browser cache, and the problem is solved. The ingenious me: F12 developer mode, switch to &lt;code&gt;network&lt;/code&gt;, check &lt;code&gt;disable cache&lt;/code&gt;, refresh, done!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ttf248.life/p/blog-ide-environment-and-ramblings/2020-03-31-14-27-15.png&#34;
	width=&#34;399&#34;
	height=&#34;142&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;network&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;280&#34;
		data-flex-basis=&#34;674px&#34;
	
&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>Automatic system switchover</title>
        <link>https://ttf248.life/en/p/auto-integration-system-switch/</link>
        <pubDate>Sun, 29 Mar 2020 02:11:33 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/auto-integration-system-switch/</guid>
        <description>&lt;p&gt;Automatically deploy a Hugo blog to GitHub Pages and Gitee using GitHub Actions&lt;/p&gt;
&lt;h4 id=&#34;background-introduction&#34;&gt;Background introduction
&lt;/h4&gt;&lt;p&gt;While updating my blog yesterday, I discovered that the Travis service was unavailable. Checking the Travis webpage, I saw that the progress was stuck on pulling the source code. Suddenly, I remembered the action service recently launched by GitHub.&lt;/p&gt;
&lt;p&gt;Given that it will be quite busy and requires an application to use action, now that it has officially launched, and with free time this weekend, why not try out a new toy?&lt;/p&gt;
&lt;p&gt;You can find all official documents on the website, so I won&amp;rsquo;t reproduce them here. If you’ve used Kubernetes before, you’ll notice that the YAML configuration for actions is very similar to it.&lt;/p&gt;
&lt;p&gt;For introductory tutorials or Chinese language resources, I recommend searching &lt;strong&gt;阮一峰&amp;rsquo;s blog&lt;/strong&gt;. There are two articles: the first is an introduction to basic grammar, and the second is a practical case study.&lt;/p&gt;
&lt;h4 id=&#34;main-body&#34;&gt;Main body
&lt;/h4&gt;&lt;p&gt;Required knowledge points&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;github secrets&lt;/li&gt;
&lt;li&gt;action grammar&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The core job is completed using existing components, pushed to domestic Gitee using commands. The command part is quite rough, all force pushes, and inherits the logic used with Travis.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;name: github pages and gitee pages

on:
  push:
    branches:
      - hugo

jobs:
  deploy:
    runs-on: ubuntu-18.04
    steps:
      - uses: actions/checkout@v2
        with:
          submodules: true

      - name: Setup Hugo
        uses: peaceiris/actions-hugo@v2
        with:
          hugo-version: &#39;latest&#39;
          extended: true

      - name: Build Github and Gitee ## 单个step只能写一个run命令
        run: hugo -b &amp;quot;https://www.xiangtianlong.com/&amp;quot; -d &amp;quot;github_public&amp;quot; &amp;amp;&amp;amp; hugo -b &amp;quot;https://www.xiangtianlong.com/&amp;quot; -d &amp;quot;gitee_public&amp;quot; &amp;amp;&amp;amp; ls

      - name: Deploy Github
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.BLOG_TOKEN }}
          publish_dir: ./github_public
          publish_branch: master
          cname: xiangtianlong.com

      - name: Deploy Gitee
        run: cd ./gitee_public &amp;amp;&amp;amp; git init &amp;amp;&amp;amp; git config user.name &amp;quot;TianlongXiang&amp;quot; &amp;amp;&amp;amp; git config user.email &amp;quot;tianlongxiang51@gmail.com&amp;quot; &amp;amp;&amp;amp; git add . &amp;amp;&amp;amp; git commit -m &amp;quot;Update TianlongXiang&#39;s Blog&amp;quot; &amp;amp;&amp;amp; git push --force &amp;quot;https://xiangtianlong:${{ secrets.GITEE_PASSWORD }}@gitee.com/xiangtianlong/xiangtianlong.git&amp;quot; master:master   
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;afterword&#34;&gt;Afterword
&lt;/h4&gt;&lt;p&gt;Based on the actions provided by the official market, there are quite a few supported features currently available, and after building a Docker image, you no longer need to rely on services provided by Docker Hub&lt;/p&gt;
&lt;p&gt;I checked Hugo&amp;rsquo;s issues and found that when using GitHub Actions to automatically deploy Git Pages, the final published webpage needs to be on the master branch. If deployed to other branches, GitHub will display a message indicating that there are syntax problems with the deployment webpage in the settings interface.&lt;/p&gt;
&lt;p&gt;In reality, it&amp;rsquo;s because Hugo&amp;rsquo;s source files are located in the master branch, and GitHub is treating them as the source code for the Jelly blog, leading to errors that prevent checking and passing&lt;/p&gt;
&lt;p&gt;The solution is also simple: put the Hugo source files on another branch and publish the static files on the master branch&lt;/p&gt;</description>
        </item>
        <item>
        <title>Allocator for standard library containers</title>
        <link>https://ttf248.life/en/p/standard-library-container-memory-allocator/</link>
        <pubDate>Mon, 30 Dec 2019 13:26:19 +0800</pubDate>
        
        <guid>https://ttf248.life/en/p/standard-library-container-memory-allocator/</guid>
        <description>&lt;p&gt;Custom allocators can improve performance, increase memory efficiency, and solve problems related to frequent small memory allocations&lt;/p&gt;
&lt;h4 id=&#34;cause&#34;&gt;Cause
&lt;/h4&gt;&lt;p&gt;Recently, I&amp;rsquo;ve been working on network packet development and frequently need to allocate and release small blocks of memory. I initially thought about using a memory pool, but after reviewing several existing ones, I found this&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/cacay/MemoryPool&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/cacay/MemoryPool&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Seeing the interface, I was a bit puzzled – the implementation of this memory pool seems a little strange. The &lt;code&gt;MemoryPool&lt;/code&gt;&amp;rsquo;s implementation logic allocates fixed-size memory spaces. Having looked at the boost memory pool interface, it provides a template that is instantiated when used. Fortunately, there are already articles introducing this library, mentioning the concept of &lt;code&gt;allocator&lt;/code&gt;.&lt;/p&gt;
&lt;h4 id=&#34;wikihttpszhwikipediaorgwikie58886e9858de599a8_c2b2b&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E5%88%86%E9%85%8D%E5%99%A8_%28C%2B%2B%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;wiki&lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;In C++ programming, an allocator (in English: allocator) is an important component of the C++ standard library. The C++ library defines various data structures collectively referred to as &amp;ldquo;containers&amp;rdquo; (such as linked lists, sets, etc.), and a common feature of these containers is that their size can change at runtime; to achieve this, dynamic memory allocation becomes particularly necessary, and allocators are used to handle the container&amp;rsquo;s memory allocation and release requests. In other words, an allocator encapsulates the low-level details of memory management for Standard Template Library (STL) containers. By default, the C++ standard library uses its own built-in general allocator, but according to specific needs, programmers can also customize allocators to replace it.&lt;/p&gt;
&lt;p&gt;The allocator was originally invented by Alexander Stepanov as part of the C++ Standard Template Library (STL), with the initial goal of creating a way to &amp;ldquo;make the library more flexible and independent of the underlying data model,&amp;rdquo; allowing programmers to utilize custom pointer and reference types within the library; however, when incorporating the Standard Template Library into the C++ standard, the C++ Standards Committee realized that complete abstraction of the data model would result in unacceptable performance losses. As a compromise, the restrictions on allocators in the standard became stricter, and as a result, the current standard describes allocators with significantly less customizability than Stepanov originally envisioned.&lt;/p&gt;
&lt;p&gt;Although there are limitations on allocator customization, custom allocators are often necessary in many cases, typically to encapsulate access methods for different types of memory spaces (such as shared memory and recycled memory) or to improve performance when using memory pools for memory allocation. In addition, introducing a dedicated custom allocator in programs that frequently allocate small amounts of memory can also be greatly beneficial from the perspectives of memory usage and runtime.&lt;/p&gt;
&lt;h4 id=&#34;requirements&#34;&gt;Requirements
&lt;/h4&gt;&lt;p&gt;One of the primary reasons for defining custom allocators is to improve performance. Utilizing a dedicated custom allocator can enhance program performance, or increase memory efficiency, or both [4][8]. The default allocator allocates storage space using the new operator, which is often implemented using C language heap allocation functions (malloc()) [Wen 5]. Because heap allocation functions are often optimized for occasional large memory allocations, the default allocator generally performs well when allocating memory for containers that require a large amount of memory to be allocated at once (such as vectors and double-ended queues) [8]. However, for associative containers and doubly linked lists, which require frequent allocation of small amounts of memory, using the default allocator can often result in low efficiency [4][9]. In addition, malloc()-based default allocators have many problems, such as poor locality of reference [4] and potential memory fragmentation [4][9].&lt;/p&gt;
&lt;p&gt;In short, this section (……) is like a &amp;ldquo;I Have a Dream&amp;rdquo; speech for this standard regarding allocators. Before the dream comes true, programmers concerned with portability will limit themselves to stateless custom allocators.
——Scott Meyers, 《Effective STL》
In light of this, in such situations, memory pool allocators are often used to address the problem of frequent small allocations [8]. Unlike the default &amp;ldquo;on-demand allocation&amp;rdquo; approach, when using a memory pool allocator, the program pre-allocates a large block of memory (the &amp;ldquo;memory pool&amp;rdquo;), and then, when memory is requested, the custom allocator simply returns a pointer to memory within the pool; during object destruction, no actual deallocation is required, but it is delayed until the end of the memory pool&amp;rsquo;s lifecycle [Note 1][8].&lt;/p&gt;
&lt;p&gt;The topic of &amp;ldquo;custom allocators&amp;rdquo; has seen considerable discussion among C++ experts and authors, such as Scott Meyers&amp;rsquo; work &amp;ldquo;Effective STL&amp;rdquo; and Andrei Alexandrescu&amp;rsquo;s &amp;ldquo;Modern C++ Design.&amp;rdquo; Meyers observed that if you require all instances of an allocator for a given type T to be equal, then the allocator instances must not contain state. Although the C++ standard encourages library implementers to support allocators with state [Reference 4], Meyers calls this related passage a “seemingly wonderful idea” but also almost empty talk, and he considers the restriction on allocators &amp;ldquo;too strict&amp;rdquo; [4]. For example, STL&amp;rsquo;s list allows the splice method, where nodes of one list object A can be directly moved into another list object B, which requires that the memory allocated by A’s allocator can be released by B’s allocator, thus inferring that the allocator instances of A and B must be equal. Meyers concludes that allocators are best defined as types using static methods. For example, according to the C++ standard, an allocator must provide an other class template that implements the rebind method.&lt;/p&gt;
&lt;p&gt;Additionally, in &amp;ldquo;The C++ Programming Language,&amp;rdquo; Bjarne Stroustrup argues that “&amp;lsquo;strictly limiting the allocator to avoid different object information&amp;rsquo; is clearly not a big deal” (in essence) and points out that most allocators do not need state, and performance may even be better in the absence of state. He proposes three use cases for custom allocators: memory pool-based allocators, shared memory allocators, and garbage collection allocators, and demonstrates an implementation of an allocator that utilizes an internal memory pool to quickly allocate/deallocate small amounts of memory. However, he also mentions that such optimization may already be implemented in the sample allocator he provides [3].&lt;/p&gt;
&lt;p&gt;Another use of a custom allocator is debugging memory-related errors [10]. To do this, you can write an allocator that allocates extra memory when allocating, and use it to store debug information. This type of allocator not only ensures that memory is allocated/deallocated by the same allocator, but also protects the program from cache overflows to a certain extent [11].&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>
